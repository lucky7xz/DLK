{"textgrid.poem.48204": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Was mir fehlte", "genre": "verse", "period": "N.A.", "pub_year": 1858, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn andre Fortunens Schiff gekapert,", "tokens": ["Wenn", "and\u00b7re", "For\u00b7tu\u00b7nens", "Schiff", "ge\u00b7ka\u00b7pert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "NN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Auf halbem Weg', auf der Enterbr\u00fccke,", "tokens": ["Auf", "hal\u00b7bem", "Weg'", ",", "auf", "der", "En\u00b7ter\u00b7br\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Glitt immer ich aus. War's Schicksalst\u00fccke?", "tokens": ["Glitt", "im\u00b7mer", "ich", "aus", ".", "Wa\u00b7r's", "Schick\u00b7sal\u00b7st\u00fc\u00b7cke", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "PTKVZ", "$.", "NE", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "War's irgend ein gro\u00dfes Unterlassen?", "tokens": ["Wa\u00b7r's", "ir\u00b7gend", "ein", "gro\u00b7\u00dfes", "Un\u00b7ter\u00b7las\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Ein falsches die Sach' am Schopfe Fassen?", "tokens": ["Ein", "fal\u00b7sches", "die", "Sach'", "am", "Schop\u00b7fe", "Fas\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "NN", "APPRART", "NN", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "War's Schwachsein in den vier Elementen,", "tokens": ["Wa\u00b7r's", "Schwach\u00b7sein", "in", "den", "vier", "E\u00b7le\u00b7men\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "ART", "CARD", "NN", "$,"], "meter": "+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.8": {"text": "In Wissen, Ordnung, Flei\u00df und Talenten?", "tokens": ["In", "Wis\u00b7sen", ",", "Ord\u00b7nung", ",", "Flei\u00df", "und", "Ta\u00b7len\u00b7ten", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+----", "measure": "unknown.measure.tri"}, "line.9": {"text": "Oder war's \u2013 ach, suche nicht zu weit,", "tokens": ["O\u00b7der", "wa\u00b7r's", "\u2013", "ach", ",", "su\u00b7che", "nicht", "zu", "weit", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$(", "XY", "$,", "VVFIN", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Was mir fehlte, war: Sinn f\u00fcr ", "tokens": ["Was", "mir", "fehl\u00b7te", ",", "war", ":", "Sinn", "f\u00fcr"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "$.", "NN", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich blicke zur\u00fcck. Gott sei gesegnet,", "tokens": ["Ich", "bli\u00b7cke", "zu\u00b7r\u00fcck", ".", "Gott", "sei", "ge\u00b7seg\u00b7net", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wem bin ich nicht alles im Leben begegnet!", "tokens": ["Wem", "bin", "ich", "nicht", "al\u00b7les", "im", "Le\u00b7ben", "be\u00b7geg\u00b7net", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "PIS", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Machthabern aller Arten und Grade,", "tokens": ["Macht\u00b7ha\u00b7bern", "al\u00b7ler", "Ar\u00b7ten", "und", "Gra\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Vom Hof, von der B\u00f6rse, von der Parade,", "tokens": ["Vom", "Hof", ",", "von", "der", "B\u00f6r\u00b7se", ",", "von", "der", "Pa\u00b7ra\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "\u00bbdamens\u00ab mit und ohne Schnitzer,", "tokens": ["\u00bb", "da\u00b7mens", "\u00ab", "mit", "und", "oh\u00b7ne", "Schnit\u00b7zer", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$(", "APPR", "KON", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Portiers, Hauswirte, Hausbesitzer,", "tokens": ["Por\u00b7ti\u00b7ers", ",", "Haus\u00b7wir\u00b7te", ",", "Haus\u00b7be\u00b7sit\u00b7zer", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,"], "meter": "+-++--+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Ich konnte mich allen bequem bequemen,", "tokens": ["Ich", "konn\u00b7te", "mich", "al\u00b7len", "be\u00b7quem", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PIAT", "ADJA", "ADJA", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Aber feierlich konnt' ich sie nicht nehmen.", "tokens": ["A\u00b7ber", "fei\u00b7er\u00b7lich", "konnt'", "ich", "sie", "nicht", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Das r\u00e4cht sich schlie\u00dflich bei den Leuten,", "tokens": ["Das", "r\u00e4cht", "sich", "schlie\u00df\u00b7lich", "bei", "den", "Leu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein jeder m\u00f6chte was Rechts bedeuten,", "tokens": ["Ein", "je\u00b7der", "m\u00f6ch\u00b7te", "was", "Rechts", "be\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VMFIN", "PIS", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und steht mal was in Sicht oder Frage,", "tokens": ["Und", "steht", "mal", "was", "in", "Sicht", "o\u00b7der", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PWS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So sagt ein Reskript am n\u00e4chsten Tage:", "tokens": ["So", "sagt", "ein", "Res\u00b7kript", "am", "n\u00e4chs\u00b7ten", "Ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "\u00bbnach bestem Wissen und Gewissen,", "tokens": ["\u00bb", "nach", "bes\u00b7tem", "Wis\u00b7sen", "und", "Ge\u00b7wis\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Er l\u00e4\u00dft doch den rechten Ernst vermissen,", "tokens": ["Er", "l\u00e4\u00dft", "doch", "den", "rech\u00b7ten", "Ernst", "ver\u00b7mis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Alle Dinge sind ihm immer nur Schein,", "tokens": ["Al\u00b7le", "Din\u00b7ge", "sind", "ihm", "im\u00b7mer", "nur", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "ADV", "ADV", "NN", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Er ist ein Fremdling, er pa\u00dft nicht hinein,", "tokens": ["Er", "ist", "ein", "Fremd\u00b7ling", ",", "er", "pa\u00dft", "nicht", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und ob das Feierlichste gescheh',", "tokens": ["Und", "ob", "das", "Fei\u00b7er\u00b7lichs\u00b7te", "ge\u00b7scheh'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Er sagt von jedem nur: Fa il Re.\u00ab", "tokens": ["Er", "sagt", "von", "je\u00b7dem", "nur", ":", "Fa", "il", "Re", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIS", "ADV", "$.", "FM", "FM", "FM", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Suche nicht weiter. Man bringt es nicht weit", "tokens": ["Su\u00b7che", "nicht", "wei\u00b7ter", ".", "Man", "bringt", "es", "nicht", "weit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "PTKVZ", "$.", "PIS", "VVFIN", "PPER", "PTKNEG", "ADJD"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Bei fehlendem Sinn f\u00fcr Feierlichkeit.", "tokens": ["Bei", "feh\u00b7len\u00b7dem", "Sinn", "f\u00fcr", "Fei\u00b7er\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Wenn andre Fortunens Schiff gekapert,", "tokens": ["Wenn", "and\u00b7re", "For\u00b7tu\u00b7nens", "Schiff", "ge\u00b7ka\u00b7pert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "NN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Auf halbem Weg', auf der Enterbr\u00fccke,", "tokens": ["Auf", "hal\u00b7bem", "Weg'", ",", "auf", "der", "En\u00b7ter\u00b7br\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Glitt immer ich aus. War's Schicksalst\u00fccke?", "tokens": ["Glitt", "im\u00b7mer", "ich", "aus", ".", "Wa\u00b7r's", "Schick\u00b7sal\u00b7st\u00fc\u00b7cke", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "PTKVZ", "$.", "NE", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "War's irgend ein gro\u00dfes Unterlassen?", "tokens": ["Wa\u00b7r's", "ir\u00b7gend", "ein", "gro\u00b7\u00dfes", "Un\u00b7ter\u00b7las\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Ein falsches die Sach' am Schopfe Fassen?", "tokens": ["Ein", "fal\u00b7sches", "die", "Sach'", "am", "Schop\u00b7fe", "Fas\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "NN", "APPRART", "NN", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "War's Schwachsein in den vier Elementen,", "tokens": ["Wa\u00b7r's", "Schwach\u00b7sein", "in", "den", "vier", "E\u00b7le\u00b7men\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "ART", "CARD", "NN", "$,"], "meter": "+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.8": {"text": "In Wissen, Ordnung, Flei\u00df und Talenten?", "tokens": ["In", "Wis\u00b7sen", ",", "Ord\u00b7nung", ",", "Flei\u00df", "und", "Ta\u00b7len\u00b7ten", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+----", "measure": "unknown.measure.tri"}, "line.9": {"text": "Oder war's \u2013 ach, suche nicht zu weit,", "tokens": ["O\u00b7der", "wa\u00b7r's", "\u2013", "ach", ",", "su\u00b7che", "nicht", "zu", "weit", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$(", "XY", "$,", "VVFIN", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Was mir fehlte, war: Sinn f\u00fcr ", "tokens": ["Was", "mir", "fehl\u00b7te", ",", "war", ":", "Sinn", "f\u00fcr"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "$.", "NN", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich blicke zur\u00fcck. Gott sei gesegnet,", "tokens": ["Ich", "bli\u00b7cke", "zu\u00b7r\u00fcck", ".", "Gott", "sei", "ge\u00b7seg\u00b7net", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wem bin ich nicht alles im Leben begegnet!", "tokens": ["Wem", "bin", "ich", "nicht", "al\u00b7les", "im", "Le\u00b7ben", "be\u00b7geg\u00b7net", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "PIS", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Machthabern aller Arten und Grade,", "tokens": ["Macht\u00b7ha\u00b7bern", "al\u00b7ler", "Ar\u00b7ten", "und", "Gra\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Vom Hof, von der B\u00f6rse, von der Parade,", "tokens": ["Vom", "Hof", ",", "von", "der", "B\u00f6r\u00b7se", ",", "von", "der", "Pa\u00b7ra\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "\u00bbdamens\u00ab mit und ohne Schnitzer,", "tokens": ["\u00bb", "da\u00b7mens", "\u00ab", "mit", "und", "oh\u00b7ne", "Schnit\u00b7zer", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$(", "APPR", "KON", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Portiers, Hauswirte, Hausbesitzer,", "tokens": ["Por\u00b7ti\u00b7ers", ",", "Haus\u00b7wir\u00b7te", ",", "Haus\u00b7be\u00b7sit\u00b7zer", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,"], "meter": "+-++--+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Ich konnte mich allen bequem bequemen,", "tokens": ["Ich", "konn\u00b7te", "mich", "al\u00b7len", "be\u00b7quem", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PIAT", "ADJA", "ADJA", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Aber feierlich konnt' ich sie nicht nehmen.", "tokens": ["A\u00b7ber", "fei\u00b7er\u00b7lich", "konnt'", "ich", "sie", "nicht", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Das r\u00e4cht sich schlie\u00dflich bei den Leuten,", "tokens": ["Das", "r\u00e4cht", "sich", "schlie\u00df\u00b7lich", "bei", "den", "Leu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein jeder m\u00f6chte was Rechts bedeuten,", "tokens": ["Ein", "je\u00b7der", "m\u00f6ch\u00b7te", "was", "Rechts", "be\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VMFIN", "PIS", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und steht mal was in Sicht oder Frage,", "tokens": ["Und", "steht", "mal", "was", "in", "Sicht", "o\u00b7der", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PWS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So sagt ein Reskript am n\u00e4chsten Tage:", "tokens": ["So", "sagt", "ein", "Res\u00b7kript", "am", "n\u00e4chs\u00b7ten", "Ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "\u00bbnach bestem Wissen und Gewissen,", "tokens": ["\u00bb", "nach", "bes\u00b7tem", "Wis\u00b7sen", "und", "Ge\u00b7wis\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Er l\u00e4\u00dft doch den rechten Ernst vermissen,", "tokens": ["Er", "l\u00e4\u00dft", "doch", "den", "rech\u00b7ten", "Ernst", "ver\u00b7mis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Alle Dinge sind ihm immer nur Schein,", "tokens": ["Al\u00b7le", "Din\u00b7ge", "sind", "ihm", "im\u00b7mer", "nur", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "ADV", "ADV", "NN", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Er ist ein Fremdling, er pa\u00dft nicht hinein,", "tokens": ["Er", "ist", "ein", "Fremd\u00b7ling", ",", "er", "pa\u00dft", "nicht", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und ob das Feierlichste gescheh',", "tokens": ["Und", "ob", "das", "Fei\u00b7er\u00b7lichs\u00b7te", "ge\u00b7scheh'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Er sagt von jedem nur: Fa il Re.\u00ab", "tokens": ["Er", "sagt", "von", "je\u00b7dem", "nur", ":", "Fa", "il", "Re", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIS", "ADV", "$.", "FM", "FM", "FM", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Suche nicht weiter. Man bringt es nicht weit", "tokens": ["Su\u00b7che", "nicht", "wei\u00b7ter", ".", "Man", "bringt", "es", "nicht", "weit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "PTKVZ", "$.", "PIS", "VVFIN", "PPER", "PTKNEG", "ADJD"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Bei fehlendem Sinn f\u00fcr Feierlichkeit.", "tokens": ["Bei", "feh\u00b7len\u00b7dem", "Sinn", "f\u00fcr", "Fei\u00b7er\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}}}}