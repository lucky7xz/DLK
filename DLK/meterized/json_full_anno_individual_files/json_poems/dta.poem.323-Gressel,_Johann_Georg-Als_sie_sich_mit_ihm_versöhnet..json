{"dta.poem.323": {"metadata": {"author": {"name": "Gressel, Johann Georg", "birth": "N.A.", "death": "N.A."}, "title": "Als sie sich mit ihm vers\u00f6hnet.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1716", "urn": "urn:nbn:de:kobv:b4-200905199041", "language": ["de:0.99"], "booktitle": "Celander [i. e. Gressel, Johann Georg]: Verliebte-Galante/ Sinn-Vermischte und Grab-Gedichte. Hamburg u. a., 1716."}, "poem": {"stanza.1": {"line.1": {"text": "Nach dem Regen scheint die Sonne/", "tokens": ["Nach", "dem", "Re\u00b7gen", "scheint", "die", "Son\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf das Ungl\u00fcck folget Wonne;", "tokens": ["Auf", "das", "Un\u00b7gl\u00fcck", "fol\u00b7get", "Won\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lachen l\u00f6\u00dft das Weinen ab;", "tokens": ["La\u00b7chen", "l\u00f6\u00dft", "das", "Wei\u00b7nen", "ab", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Blitz und Donner f\u00e4lt ins Grab", "tokens": ["Blitz", "und", "Don\u00b7ner", "f\u00e4lt", "ins", "Grab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn des ", "tokens": ["Wenn", "des"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Diese dunckle Welt bemahlen.", "tokens": ["Die\u00b7se", "dunck\u00b7le", "Welt", "be\u00b7mah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Auf das Hassen kommt das Lieben/", "tokens": ["Auf", "das", "Has\u00b7sen", "kommt", "das", "Lie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles will den Wechsel \u00fcben/", "tokens": ["Al\u00b7les", "will", "den", "Wech\u00b7sel", "\u00fc\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer da trotzt dem Unbestand/", "tokens": ["Wer", "da", "trotzt", "dem", "Un\u00b7be\u00b7stand", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der kommt ins gelobte Land/", "tokens": ["Der", "kommt", "ins", "ge\u00b7lob\u00b7te", "Land", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPRART", "ADJA", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wo sich nach vergangnen Schmertzen", "tokens": ["Wo", "sich", "nach", "ver\u00b7gang\u00b7nen", "Schmert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Lust und Freude lieblich hertzen.", "tokens": ["Lust", "und", "Freu\u00b7de", "lieb\u00b7lich", "hert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Scheinen gleich der Liebsten Augen", "tokens": ["Schei\u00b7nen", "gleich", "der", "Liebs\u00b7ten", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur zum sauren Blick zu taugen/", "tokens": ["Nur", "zum", "sau\u00b7ren", "Blick", "zu", "tau\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lindert doch ein sanffter Strahl", "tokens": ["Lin\u00b7dert", "doch", "ein", "sanff\u00b7ter", "Strahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bald die heisse Liebes-Quaal/", "tokens": ["Bald", "die", "heis\u00b7se", "Lie\u00b7bes\u00b7Quaal", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da/ wo Dornen sonst gestanden", "tokens": ["Da", "/", "wo", "Dor\u00b7nen", "sonst", "ge\u00b7stan\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$(", "PWAV", "NN", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sind denn Rosen gnug verhanden.", "tokens": ["Sind", "denn", "Ro\u00b7sen", "gnug", "ver\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "So verkehren sich die Zeiten/", "tokens": ["So", "ver\u00b7keh\u00b7ren", "sich", "die", "Zei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die s\u00fcssen Eitelkeiten", "tokens": ["Und", "die", "s\u00fcs\u00b7sen", "Ei\u00b7tel\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn ein Ku\u00df das Trauren hemmt;", "tokens": ["Wenn", "ein", "Ku\u00df", "das", "Trau\u00b7ren", "hemmt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Angst und Schmertze wird gestemmt", "tokens": ["Angst", "und", "Schmert\u00b7ze", "wird", "ge\u00b7stemmt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn ein Hertz/ das fast vergangen/", "tokens": ["Wenn", "ein", "Hertz", "/", "das", "fast", "ver\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$(", "PDS", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit gew\u00fcnschter Huld kan prangen.", "tokens": ["Mit", "ge\u00b7w\u00fcnschter", "Huld", "kan", "pran\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "VVFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.5": {"line.1": {"text": "Wenn der Anblick von den Br\u00fcsten/", "tokens": ["Wenn", "der", "An\u00b7blick", "von", "den", "Br\u00fcs\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die den Engeln selbst gel\u00fcsten", "tokens": ["Die", "den", "En\u00b7geln", "selbst", "ge\u00b7l\u00fcs\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Frey und unverwehret ist/", "tokens": ["Frey", "und", "un\u00b7ver\u00b7weh\u00b7ret", "ist", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn man Mund und Lippen k\u00fc\u00dft/", "tokens": ["Wenn", "man", "Mund", "und", "Lip\u00b7pen", "k\u00fc\u00dft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "KON", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Alsdenn hat man \u00fcberstanden", "tokens": ["Als\u00b7denn", "hat", "man", "\u00fc\u00b7bers\u00b7tan\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Den Verdru\u00df der schweren Banden.", "tokens": ["Den", "Ver\u00b7dru\u00df", "der", "schwe\u00b7ren", "Ban\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Das/ was man vor dem verfluchet/", "tokens": ["Das", "/", "was", "man", "vor", "dem", "ver\u00b7flu\u00b7chet", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "PWS", "PIS", "APPR", "ART", "VVFIN", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wird alsdenn mit Ernst gesuchet/", "tokens": ["Wird", "als\u00b7denn", "mit", "Ernst", "ge\u00b7su\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NE", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn zeigt Ketten/ Strick und Band", "tokens": ["Denn", "zeigt", "Ket\u00b7ten", "/", "Strick", "und", "Band"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "NN", "$(", "NN", "KON", "NN"], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Einen recht vergn\u00fcgten Stand/", "tokens": ["Ei\u00b7nen", "recht", "ver\u00b7gn\u00fcg\u00b7ten", "Stand", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Solche Sclaven sind befreyet", "tokens": ["Sol\u00b7che", "Scla\u00b7ven", "sind", "be\u00b7fre\u00b7yet"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "VVFIN"], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}, "line.6": {"text": "Wenn der ander Zetter schreyet.", "tokens": ["Wenn", "der", "an\u00b7der", "Zet\u00b7ter", "schre\u00b7yet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.7": {"line.1": {"text": "In so s\u00fcsser Knechtschafft leben/", "tokens": ["In", "so", "s\u00fcs\u00b7ser", "Knecht\u00b7schafft", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heist in steter Freyheit schweben", "tokens": ["Heist", "in", "ste\u00b7ter", "Frey\u00b7heit", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein Dienst ohne Selaverey/", "tokens": ["Ein", "Dienst", "oh\u00b7ne", "Se\u00b7la\u00b7ve\u00b7rey", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Gantz bestricket und doch frey/", "tokens": ["Gantz", "be\u00b7stri\u00b7cket", "und", "doch", "frey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "ADV", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sonnenschein bey Wind und St\u00fcrmen/", "tokens": ["Son\u00b7nen\u00b7schein", "bey", "Wind", "und", "St\u00fcr\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und vor Eyfersucht ein Schirmen.", "tokens": ["Und", "vor", "Ey\u00b7fer\u00b7sucht", "ein", "Schir\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Lieb\u2019 und leb mein Hertz vergn\u00fcget", "tokens": ["Lieb'", "und", "leb", "mein", "Hertz", "ver\u00b7gn\u00fc\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deine Sch\u00f6ne ist besieget/", "tokens": ["Dei\u00b7ne", "Sch\u00f6\u00b7ne", "ist", "be\u00b7sie\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Keine List und keine Macht", "tokens": ["Kei\u00b7ne", "List", "und", "kei\u00b7ne", "Macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist auf deinen Fall bedacht", "tokens": ["Ist", "auf", "dei\u00b7nen", "Fall", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Jhre wunder-sch\u00f6nen Gaben", "tokens": ["Ih\u00b7re", "wun\u00b7der\u00b7sch\u00f6\u00b7nen", "Ga\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sollen dich erfreulich laben.", "tokens": ["Sol\u00b7len", "dich", "er\u00b7freu\u00b7lich", "la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}