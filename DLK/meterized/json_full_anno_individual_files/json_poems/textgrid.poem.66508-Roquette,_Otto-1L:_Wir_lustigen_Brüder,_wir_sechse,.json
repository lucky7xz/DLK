{"textgrid.poem.66508": {"metadata": {"author": {"name": "Roquette, Otto", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wir lustigen Br\u00fcder, wir sechse,", "genre": "verse", "period": "N.A.", "pub_year": 1860, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir lustigen Br\u00fcder, wir sechse,", "tokens": ["Wir", "lus\u00b7ti\u00b7gen", "Br\u00fc\u00b7der", ",", "wir", "sech\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir tragen hohen Mut,", "tokens": ["Wir", "tra\u00b7gen", "ho\u00b7hen", "Mut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wir trinken gern gut Gew\u00e4chse,", "tokens": ["Wir", "trin\u00b7ken", "gern", "gut", "Ge\u00b7w\u00e4ch\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "NN", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Und essen auch gerne gut.", "tokens": ["Und", "es\u00b7sen", "auch", "ger\u00b7ne", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und kommen auf Schusters Rappen", "tokens": ["Und", "kom\u00b7men", "auf", "Schus\u00b7ters", "Rap\u00b7pen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wir all' von verschiedener Bahn,", "tokens": ["Wir", "all'", "von", "ver\u00b7schie\u00b7de\u00b7ner", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "So tragen wir gleiche Kappen,", "tokens": ["So", "tra\u00b7gen", "wir", "glei\u00b7che", "Kap\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und gleiche Schellen daran.", "tokens": ["Und", "glei\u00b7che", "Schel\u00b7len", "da\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PAV", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.2": {"line.1": {"text": "Wir lustigen Br\u00fcder, wir sechse,", "tokens": ["Wir", "lus\u00b7ti\u00b7gen", "Br\u00fc\u00b7der", ",", "wir", "sech\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir lachen schon manches Jahr,", "tokens": ["Wir", "la\u00b7chen", "schon", "man\u00b7ches", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wir bringen die Milz und die Flechse", "tokens": ["Wir", "brin\u00b7gen", "die", "Milz", "und", "die", "Flech\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Den Leuten und uns in Gefahr.", "tokens": ["Den", "Leu\u00b7ten", "und", "uns", "in", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPER", "APPR", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Wir athmen die reinste Begl\u00fccktheit,", "tokens": ["Wir", "ath\u00b7men", "die", "reins\u00b7te", "Be\u00b7gl\u00fcck\u00b7theit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Wenn Jeder darauf bedacht,", "tokens": ["Wenn", "Je\u00b7der", "da\u00b7rauf", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Wie er des Andern Verr\u00fccktheit", "tokens": ["Wie", "er", "des", "An\u00b7dern", "Ver\u00b7r\u00fcckt\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "Zum Spiegel der Weisheit macht.", "tokens": ["Zum", "Spie\u00b7gel", "der", "Weis\u00b7heit", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Wir lustigen Br\u00fcder, wir sechse,", "tokens": ["Wir", "lus\u00b7ti\u00b7gen", "Br\u00fc\u00b7der", ",", "wir", "sech\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir feiern all' unsre Fest'", "tokens": ["Wir", "fei\u00b7ern", "all'", "uns\u00b7re", "Fest'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "PPOSAT", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Mit witzigem Versegeklexe,", "tokens": ["Mit", "wit\u00b7zi\u00b7gem", "Ver\u00b7se\u00b7ge\u00b7kle\u00b7xe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und Griffel und Pinsel auf's Best!", "tokens": ["Und", "Grif\u00b7fel", "und", "Pin\u00b7sel", "auf's", "Best", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Und wer am tollsten l\u00e4\u00dft sausen", "tokens": ["Und", "wer", "am", "tolls\u00b7ten", "l\u00e4\u00dft", "sau\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPRART", "ADJA", "VVFIN", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Im Kopf seinen Kreisel und Querl,", "tokens": ["Im", "Kopf", "sei\u00b7nen", "Krei\u00b7sel", "und", "Querl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Die Weiblein lachen der Flausen,", "tokens": ["Die", "Weib\u00b7lein", "la\u00b7chen", "der", "Flau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und \u00fcber den n\u00e4rrischen Kerl.", "tokens": ["Und", "\u00fc\u00b7ber", "den", "n\u00e4r\u00b7ri\u00b7schen", "Kerl", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "Wir lustigen Br\u00fcder, wir sechse,", "tokens": ["Wir", "lus\u00b7ti\u00b7gen", "Br\u00fc\u00b7der", ",", "wir", "sech\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir haben die Weiblein gar lieb,", "tokens": ["Wir", "ha\u00b7ben", "die", "Weib\u00b7lein", "gar", "lieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Da\u00df jegliches an uns verhexe,", "tokens": ["Da\u00df", "jeg\u00b7li\u00b7ches", "an", "uns", "ver\u00b7he\u00b7xe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Was noch zu verhexen blieb.", "tokens": ["Was", "noch", "zu", "ver\u00b7he\u00b7xen", "blieb", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und weil sie die Narrheit best\u00e4tigt", "tokens": ["Und", "weil", "sie", "die", "Nar\u00b7rheit", "be\u00b7st\u00e4\u00b7tigt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "An Jedem hundertmal schier,", "tokens": ["An", "Je\u00b7dem", "hun\u00b7dert\u00b7mal", "schier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADV", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "So sei sie f\u00fcr immer beth\u00e4tigt", "tokens": ["So", "sei", "sie", "f\u00fcr", "im\u00b7mer", "be\u00b7th\u00e4\u00b7tigt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zu ihrem Dienst und Pl\u00e4sir!", "tokens": ["Zu", "ih\u00b7rem", "Dienst", "und", "Pl\u00e4\u00b7sir", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wir lustigen Br\u00fcder, wir sechse,", "tokens": ["Wir", "lus\u00b7ti\u00b7gen", "Br\u00fc\u00b7der", ",", "wir", "sech\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir stehen uns allzeit bereit", "tokens": ["Wir", "ste\u00b7hen", "uns", "all\u00b7zeit", "be\u00b7reit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Chronisten und Versifexe", "tokens": ["Als", "Chro\u00b7nis\u00b7ten", "und", "Ver\u00b7si\u00b7fe\u00b7xe"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Der eigenen Herrlichkeit.", "tokens": ["Der", "ei\u00b7ge\u00b7nen", "Herr\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "L\u00e4ngst sind wir unsterblich geworden", "tokens": ["L\u00e4ngst", "sind", "wir", "uns\u00b7terb\u00b7lich", "ge\u00b7wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VAPP"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Auf ewig ureignem Gebiet,", "tokens": ["Auf", "e\u00b7wig", "ur\u00b7eig\u00b7nem", "Ge\u00b7biet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Denn die Narrheit ist erblicher Orden", "tokens": ["Denn", "die", "Nar\u00b7rheit", "ist", "er\u00b7bli\u00b7cher", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Bis in's hunderttausendste Glied.", "tokens": ["Bis", "in's", "hun\u00b7dert\u00b7tau\u00b7sends\u00b7te", "Glied", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.6": {"line.1": {"text": "Wir lustigen Br\u00fcder, wir sechse,", "tokens": ["Wir", "lus\u00b7ti\u00b7gen", "Br\u00fc\u00b7der", ",", "wir", "sech\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir tragen hohen Mut,", "tokens": ["Wir", "tra\u00b7gen", "ho\u00b7hen", "Mut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wir trinken gern gut Gew\u00e4chse,", "tokens": ["Wir", "trin\u00b7ken", "gern", "gut", "Ge\u00b7w\u00e4ch\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "NN", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Und essen auch gerne gut.", "tokens": ["Und", "es\u00b7sen", "auch", "ger\u00b7ne", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und kommen auf Schusters Rappen", "tokens": ["Und", "kom\u00b7men", "auf", "Schus\u00b7ters", "Rap\u00b7pen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wir all' von verschiedener Bahn,", "tokens": ["Wir", "all'", "von", "ver\u00b7schie\u00b7de\u00b7ner", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "So tragen wir gleiche Kappen,", "tokens": ["So", "tra\u00b7gen", "wir", "glei\u00b7che", "Kap\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und gleiche Schellen daran.", "tokens": ["Und", "glei\u00b7che", "Schel\u00b7len", "da\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PAV", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.7": {"line.1": {"text": "Wir lustigen Br\u00fcder, wir sechse,", "tokens": ["Wir", "lus\u00b7ti\u00b7gen", "Br\u00fc\u00b7der", ",", "wir", "sech\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir lachen schon manches Jahr,", "tokens": ["Wir", "la\u00b7chen", "schon", "man\u00b7ches", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wir bringen die Milz und die Flechse", "tokens": ["Wir", "brin\u00b7gen", "die", "Milz", "und", "die", "Flech\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Den Leuten und uns in Gefahr.", "tokens": ["Den", "Leu\u00b7ten", "und", "uns", "in", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPER", "APPR", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Wir athmen die reinste Begl\u00fccktheit,", "tokens": ["Wir", "ath\u00b7men", "die", "reins\u00b7te", "Be\u00b7gl\u00fcck\u00b7theit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Wenn Jeder darauf bedacht,", "tokens": ["Wenn", "Je\u00b7der", "da\u00b7rauf", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Wie er des Andern Verr\u00fccktheit", "tokens": ["Wie", "er", "des", "An\u00b7dern", "Ver\u00b7r\u00fcckt\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "Zum Spiegel der Weisheit macht.", "tokens": ["Zum", "Spie\u00b7gel", "der", "Weis\u00b7heit", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Wir lustigen Br\u00fcder, wir sechse,", "tokens": ["Wir", "lus\u00b7ti\u00b7gen", "Br\u00fc\u00b7der", ",", "wir", "sech\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir feiern all' unsre Fest'", "tokens": ["Wir", "fei\u00b7ern", "all'", "uns\u00b7re", "Fest'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "PPOSAT", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Mit witzigem Versegeklexe,", "tokens": ["Mit", "wit\u00b7zi\u00b7gem", "Ver\u00b7se\u00b7ge\u00b7kle\u00b7xe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und Griffel und Pinsel auf's Best!", "tokens": ["Und", "Grif\u00b7fel", "und", "Pin\u00b7sel", "auf's", "Best", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Und wer am tollsten l\u00e4\u00dft sausen", "tokens": ["Und", "wer", "am", "tolls\u00b7ten", "l\u00e4\u00dft", "sau\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPRART", "ADJA", "VVFIN", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Im Kopf seinen Kreisel und Querl,", "tokens": ["Im", "Kopf", "sei\u00b7nen", "Krei\u00b7sel", "und", "Querl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Die Weiblein lachen der Flausen,", "tokens": ["Die", "Weib\u00b7lein", "la\u00b7chen", "der", "Flau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und \u00fcber den n\u00e4rrischen Kerl.", "tokens": ["Und", "\u00fc\u00b7ber", "den", "n\u00e4r\u00b7ri\u00b7schen", "Kerl", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.9": {"line.1": {"text": "Wir lustigen Br\u00fcder, wir sechse,", "tokens": ["Wir", "lus\u00b7ti\u00b7gen", "Br\u00fc\u00b7der", ",", "wir", "sech\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir haben die Weiblein gar lieb,", "tokens": ["Wir", "ha\u00b7ben", "die", "Weib\u00b7lein", "gar", "lieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Da\u00df jegliches an uns verhexe,", "tokens": ["Da\u00df", "jeg\u00b7li\u00b7ches", "an", "uns", "ver\u00b7he\u00b7xe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Was noch zu verhexen blieb.", "tokens": ["Was", "noch", "zu", "ver\u00b7he\u00b7xen", "blieb", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und weil sie die Narrheit best\u00e4tigt", "tokens": ["Und", "weil", "sie", "die", "Nar\u00b7rheit", "be\u00b7st\u00e4\u00b7tigt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "An Jedem hundertmal schier,", "tokens": ["An", "Je\u00b7dem", "hun\u00b7dert\u00b7mal", "schier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADV", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "So sei sie f\u00fcr immer beth\u00e4tigt", "tokens": ["So", "sei", "sie", "f\u00fcr", "im\u00b7mer", "be\u00b7th\u00e4\u00b7tigt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zu ihrem Dienst und Pl\u00e4sir!", "tokens": ["Zu", "ih\u00b7rem", "Dienst", "und", "Pl\u00e4\u00b7sir", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Wir lustigen Br\u00fcder, wir sechse,", "tokens": ["Wir", "lus\u00b7ti\u00b7gen", "Br\u00fc\u00b7der", ",", "wir", "sech\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir stehen uns allzeit bereit", "tokens": ["Wir", "ste\u00b7hen", "uns", "all\u00b7zeit", "be\u00b7reit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Chronisten und Versifexe", "tokens": ["Als", "Chro\u00b7nis\u00b7ten", "und", "Ver\u00b7si\u00b7fe\u00b7xe"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Der eigenen Herrlichkeit.", "tokens": ["Der", "ei\u00b7ge\u00b7nen", "Herr\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "L\u00e4ngst sind wir unsterblich geworden", "tokens": ["L\u00e4ngst", "sind", "wir", "uns\u00b7terb\u00b7lich", "ge\u00b7wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VAPP"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Auf ewig ureignem Gebiet,", "tokens": ["Auf", "e\u00b7wig", "ur\u00b7eig\u00b7nem", "Ge\u00b7biet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Denn die Narrheit ist erblicher Orden", "tokens": ["Denn", "die", "Nar\u00b7rheit", "ist", "er\u00b7bli\u00b7cher", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Bis in's hunderttausendste Glied.", "tokens": ["Bis", "in's", "hun\u00b7dert\u00b7tau\u00b7sends\u00b7te", "Glied", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}}}}