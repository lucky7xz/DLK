{"textgrid.poem.46178": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "An H. Oliver Fleming, Rittern, K\u00f6n. Mayt. Gesandten etc.", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wider willen und gewissen,", "tokens": ["Wi\u00b7der", "wil\u00b7len", "und", "ge\u00b7wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "eben so torecht als alt,", "tokens": ["e\u00b7ben", "so", "to\u00b7recht", "als", "alt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KOKOM", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ich mich noch zu hof aushalt,", "tokens": ["ich", "mich", "noch", "zu", "hof", "aus\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "andern dienend so geflissen,", "tokens": ["an\u00b7dern", "die\u00b7nend", "so", "ge\u00b7flis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df mir nicht ein st\u00fcndlein frei,", "tokens": ["da\u00df", "mir", "nicht", "ein", "st\u00fcnd\u00b7lein", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "got und mir selbs recht zu leben,", "tokens": ["got", "und", "mir", "selbs", "recht", "zu", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "da doch mir f\u00fcr meine treu,", "tokens": ["da", "doch", "mir", "f\u00fcr", "mei\u00b7ne", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "PPOSAT", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "m\u00fch und sorg kaum dank gegeben:", "tokens": ["m\u00fch", "und", "sorg", "kaum", "dank", "ge\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVFIN", "ADV", "APPR", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "und zwar billich; dan wer gern", "tokens": ["und", "zwar", "bil\u00b7lich", ";", "dan", "wer", "gern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "$.", "ADV", "PWS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "seinen tag bei hof wil enden,", "tokens": ["sei\u00b7nen", "tag", "bei", "hof", "wil", "en\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "der hat weder heil noch stern", "tokens": ["der", "hat", "we\u00b7der", "heil", "noch", "stern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "KON", "ADJD", "ADV", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "seinen lauf wol zu vollenden.", "tokens": ["sei\u00b7nen", "lauf", "wol", "zu", "voll\u00b7en\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich sih ja, noch nicht verblindet,", "tokens": ["Ich", "sih", "ja", ",", "noch", "nicht", "ver\u00b7blin\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "da\u00df die tugend gar umsunst,", "tokens": ["da\u00df", "die", "tu\u00b7gend", "gar", "um\u00b7sunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df allein die bosheit gunst,", "tokens": ["da\u00df", "al\u00b7lein", "die", "bos\u00b7heit", "gunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "lieb und vortheil bei hof findet.", "tokens": ["lieb", "und", "vor\u00b7theil", "bei", "hof", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "dise marbrine pall\u00e4st,", "tokens": ["di\u00b7se", "mar\u00b7bri\u00b7ne", "pal\u00b7l\u00e4st", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "underproppet mit albaster,", "tokens": ["un\u00b7der\u00b7prop\u00b7pet", "mit", "al\u00b7bas\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "halten in sich manches nest", "tokens": ["hal\u00b7ten", "in", "sich", "man\u00b7ches", "nest"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PRF", "PIS", "VVFIN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.8": {"text": "f\u00fcr verruchte lust und laster:", "tokens": ["f\u00fcr", "ver\u00b7ruch\u00b7te", "lust", "und", "las\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "under seiden, silber, gold,", "tokens": ["un\u00b7der", "sei\u00b7den", ",", "sil\u00b7ber", ",", "gold", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "ADV", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "damit sich der hof bedecket,", "tokens": ["da\u00b7mit", "sich", "der", "hof", "be\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "als in seiner lastern sold,", "tokens": ["als", "in", "sei\u00b7ner", "las\u00b7tern", "sold", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "nichts dan \u00fcbels sich verstecket.", "tokens": ["nichts", "dan", "\u00fc\u00b7bels", "sich", "ver\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "APPR", "PRF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Lang zu hof mu\u00df der nicht bleiben,", "tokens": ["Lang", "zu", "hof", "mu\u00df", "der", "nicht", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VMFIN", "ART", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "welcher redlich bleiben will:", "tokens": ["wel\u00b7cher", "red\u00b7lich", "blei\u00b7ben", "will", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "welcher, eingezogen, still,", "tokens": ["wel\u00b7cher", ",", "ein\u00b7ge\u00b7zo\u00b7gen", ",", "still", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAT", "$,", "VVPP", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht will narrenbossen treiben;", "tokens": ["nicht", "will", "nar\u00b7ren\u00b7bos\u00b7sen", "trei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VMFIN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "welcher nicht sein haupt und kn\u00fce", "tokens": ["wel\u00b7cher", "nicht", "sein", "haupt", "und", "kn\u00fce"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "PPOSAT", "NN", "KON", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "kan f\u00fcr jedem Haman biegen,", "tokens": ["kan", "f\u00fcr", "je\u00b7dem", "Ha\u00b7man", "bie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "welcher nicht kan spat und fr\u00fc", "tokens": ["wel\u00b7cher", "nicht", "kan", "spat", "und", "fr\u00fc"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "VMFIN", "VVFIN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "glei\u00dfnen, liegen und betriegen:", "tokens": ["glei\u00df\u00b7nen", ",", "lie\u00b7gen", "und", "be\u00b7trie\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "k\u00fcrzlich: welcher gut und from", "tokens": ["k\u00fcrz\u00b7lich", ":", "wel\u00b7cher", "gut", "und", "from"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "PRELS", "ADJD", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "will das \u00fcbel \u00fcbel nennen", "tokens": ["will", "das", "\u00fc\u00b7bel", "\u00fc\u00b7bel", "nen\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "ADJD", "ADJD", "VVINF"], "meter": "+-+-----", "measure": "unknown.measure.di"}, "line.11": {"text": "und nicht will, blind, taub und stum,", "tokens": ["und", "nicht", "will", ",", "blind", ",", "taub", "und", "stum", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "VMFIN", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "alles b\u00f6s f\u00fcr gut erkennen.", "tokens": ["al\u00b7les", "b\u00f6s", "f\u00fcr", "gut", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "APPR", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Darf ich andern wol anzeigen", "tokens": ["Darf", "ich", "an\u00b7dern", "wol", "an\u00b7zei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PIS", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "des hofmans religion,", "tokens": ["des", "hof\u00b7mans", "re\u00b7li\u00b7gi\u00b7on", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und f\u00fcr welcher gotheit thron", "tokens": ["und", "f\u00fcr", "wel\u00b7cher", "got\u00b7heit", "thron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PWAT", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "sich die h\u00f6flingherzen neigen?", "tokens": ["sich", "die", "h\u00f6f\u00b7ling\u00b7her\u00b7zen", "nei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "reichtum, ehrgeiz und wollust,", "tokens": ["reich\u00b7tum", ",", "ehr\u00b7geiz", "und", "wol\u00b7lust", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["FM.la", "$,", "ADJD", "KON", "VMFIN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "deren erste drei buchstaben", "tokens": ["de\u00b7ren", "ers\u00b7te", "drei", "buch\u00b7sta\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "merklich, seind in ihrer brust", "tokens": ["merk\u00b7lich", ",", "seind", "in", "ih\u00b7rer", "brust"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "als gotheiten tief gegraben:", "tokens": ["als", "got\u00b7hei\u00b7ten", "tief", "ge\u00b7gra\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "alles lebens seligkeit,", "tokens": ["al\u00b7les", "le\u00b7bens", "se\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "glauben sie, sei hier auf erden,", "tokens": ["glau\u00b7ben", "sie", ",", "sei", "hier", "auf", "er\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VAFIN", "ADV", "APPR", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.11": {"text": "die in des hofs herrlichkeit", "tokens": ["die", "in", "des", "hofs", "herr\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "wohnend, mu\u00df gefunden werden.", "tokens": ["woh\u00b7nend", ",", "mu\u00df", "ge\u00b7fun\u00b7den", "wer\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Warlich bei hof seind sehr wenig,", "tokens": ["War\u00b7lich", "bei", "hof", "seind", "sehr", "we\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "VAFIN", "ADV", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die in b\u00f6sem \u00fcberflu\u00df", "tokens": ["die", "in", "b\u00f6\u00b7sem", "\u00fc\u00b7berf\u00b7lu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und in k\u00fctzelndem verdru\u00df", "tokens": ["und", "in", "k\u00fct\u00b7zeln\u00b7dem", "ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00fcber ihre l\u00fcste k\u00f6nig:", "tokens": ["\u00fc\u00b7ber", "ih\u00b7re", "l\u00fcs\u00b7te", "k\u00f6\u00b7nig", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "und die f\u00fcrsten mehrer theils,", "tokens": ["und", "die", "f\u00fcrs\u00b7ten", "meh\u00b7rer", "theils", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "PIAT", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "folgend ihrem schn\u00f6den willen,", "tokens": ["fol\u00b7gend", "ih\u00b7rem", "schn\u00f6\u00b7den", "wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "der ein werkzeug des unheils", "tokens": ["der", "ein", "werk\u00b7zeug", "des", "un\u00b7heils"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "ihren lust mit lastern f\u00fcllen:", "tokens": ["ih\u00b7ren", "lust", "mit", "las\u00b7tern", "f\u00fcl\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "und dan der hofleuten wohn,", "tokens": ["und", "dan", "der", "hof\u00b7leu\u00b7ten", "wohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "affen gleich, ist mit cramanzen", "tokens": ["af\u00b7fen", "gleich", ",", "ist", "mit", "cra\u00b7man\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "VAFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "nach so hipscher herren ton", "tokens": ["nach", "so", "hip\u00b7scher", "her\u00b7ren", "ton"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADJA", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "stets zu singen und zu danzen.", "tokens": ["stets", "zu", "sin\u00b7gen", "und", "zu", "dan\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Daher t\u00e4glich mehr beth\u00f6ret", "tokens": ["Da\u00b7her", "t\u00e4g\u00b7lich", "mehr", "be\u00b7th\u00f6\u00b7ret"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ADJD", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "narren, ohn verstand, witz, ruh,", "tokens": ["nar\u00b7ren", ",", "ohn", "ver\u00b7stand", ",", "witz", ",", "ruh", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "KOUI", "VVFIN", "$,", "VVIMP", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "danzen sie dem teufel zu,", "tokens": ["dan\u00b7zen", "sie", "dem", "teu\u00b7fel", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wan ihr danz nicht wird verst\u00f6ret:", "tokens": ["wan", "ihr", "danz", "nicht", "wird", "ver\u00b7st\u00f6\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PTKNEG", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "ja sie danzen so lang fort,", "tokens": ["ja", "sie", "dan\u00b7zen", "so", "lang", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "bis sie in die grub gest\u00fcrzet,", "tokens": ["bis", "sie", "in", "die", "grub", "ge\u00b7st\u00fcr\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "wa nicht ihren danz ein wort,", "tokens": ["wa", "nicht", "ih\u00b7ren", "danz", "ein", "wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "PTKNEG", "PPOSAT", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "sie abrufend, schnell verk\u00fcrzet;", "tokens": ["sie", "ab\u00b7ru\u00b7fend", ",", "schnell", "ver\u00b7k\u00fcr\u00b7zet", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "ADJD", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "wa sie nicht schuld, schmach, spot, schand", "tokens": ["wa", "sie", "nicht", "schuld", ",", "schmach", ",", "spot", ",", "schand"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "PPER", "PTKNEG", "ADJD", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "oder krankheit davon rei\u00dfet,", "tokens": ["o\u00b7der", "krank\u00b7heit", "da\u00b7von", "rei\u00b7\u00dfet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PAV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "oder der ungnaden hand", "tokens": ["o\u00b7der", "der", "ung\u00b7na\u00b7den", "hand"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "wegen eines strohs zerschmei\u00dfet.", "tokens": ["we\u00b7gen", "ei\u00b7nes", "strohs", "zer\u00b7schmei\u00b7\u00dfet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Doch wan einer, hoch ankommen,", "tokens": ["Doch", "wan", "ei\u00b7ner", ",", "hoch", "an\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "$,", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u00fcber andre herschen kan,", "tokens": ["\u00fc\u00b7ber", "and\u00b7re", "her\u00b7schen", "kan", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "so will er stracks sein der hahn,", "tokens": ["so", "will", "er", "stracks", "sein", "der", "hahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPOSAT", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "wan schon andre um ihn brummen:", "tokens": ["wan", "schon", "and\u00b7re", "um", "ihn", "brum\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIS", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wird ihm schon der ganz hof feind,", "tokens": ["wird", "ihm", "schon", "der", "ganz", "hof", "feind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "ADV", "VVFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "will er doch den hof ganz zwingen;", "tokens": ["will", "er", "doch", "den", "hof", "ganz", "zwin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "basen, vetter, esel, freind,", "tokens": ["ba\u00b7sen", ",", "vet\u00b7ter", ",", "e\u00b7sel", ",", "freind", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "$,", "NE", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "dieb und kuppler hoch anbringen:", "tokens": ["dieb", "und", "kupp\u00b7ler", "hoch", "an\u00b7brin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "KON", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "bis da\u00df des hofs unbestand", "tokens": ["bis", "da\u00df", "des", "hofs", "un\u00b7be\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "ihm erwecket einen dunder,", "tokens": ["ihm", "er\u00b7we\u00b7cket", "ei\u00b7nen", "dun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "der durch des volks schwere hand", "tokens": ["der", "durch", "des", "volks", "schwe\u00b7re", "hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.12": {"text": "st\u00fcrzet endlich ihn herunder.", "tokens": ["st\u00fcr\u00b7zet", "end\u00b7lich", "ihn", "her\u00b7un\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "St\u00fcrzet! ja, eh er gedenket,", "tokens": ["St\u00fcr\u00b7zet", "!", "ja", ",", "eh", "er", "ge\u00b7den\u00b7ket", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PTKANT", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "wird er schnell mit h\u00f6chstem spot", "tokens": ["wird", "er", "schnell", "mit", "h\u00f6chs\u00b7tem", "spot"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADJD", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "weggeraufet zu dem tod", "tokens": ["weg\u00b7ger\u00b7au\u00b7fet", "zu", "dem", "tod"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "oder Haman gleich gehenket:", "tokens": ["o\u00b7der", "Ha\u00b7man", "gleich", "ge\u00b7hen\u00b7ket", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "da ihn dan des p\u00f6fels rach,", "tokens": ["da", "ihn", "dan", "des", "p\u00f6\u00b7fels", "rach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "welches sterbend ihn verfluchet,", "tokens": ["wel\u00b7ches", "ster\u00b7bend", "ihn", "ver\u00b7flu\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "lehret spat mit schimpf und schmach,", "tokens": ["leh\u00b7ret", "spat", "mit", "schimpf", "und", "schmach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "was er torecht lang gesuchet.", "tokens": ["was", "er", "to\u00b7recht", "lang", "ge\u00b7su\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "dan gewi\u00dflich, wer zu hoch", "tokens": ["dan", "ge\u00b7wi\u00df\u00b7lich", ",", "wer", "zu", "hoch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "PWS", "PTKA", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "steiget, der mu\u00df endlich fallen,", "tokens": ["stei\u00b7get", ",", "der", "mu\u00df", "end\u00b7lich", "fal\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "daher dan kan das hofjoch", "tokens": ["da\u00b7her", "dan", "kan", "das", "hof\u00b7joch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VMFIN", "ART", "NN"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "keinem weisen lang gefallen.", "tokens": ["kei\u00b7nem", "wei\u00b7sen", "lang", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Der mag spilen, singen, lachen", "tokens": ["Der", "mag", "spi\u00b7len", ",", "sin\u00b7gen", ",", "la\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PDS", "VMFIN", "VVINF", "$,", "VVFIN", "$,", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mit des sch\u00f6nen tags anfang,", "tokens": ["mit", "des", "sch\u00f6\u00b7nen", "tags", "an\u00b7fang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "den der sonnen nidergang", "tokens": ["den", "der", "son\u00b7nen", "ni\u00b7der\u00b7gang"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "k\u00fcrzlich kan verzweiflen machen:", "tokens": ["k\u00fcrz\u00b7lich", "kan", "ver\u00b7zwei\u00b7flen", "ma\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "und daher ist jener weis,", "tokens": ["und", "da\u00b7her", "ist", "je\u00b7ner", "weis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PDS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "der stets bleibet auf der erden", "tokens": ["der", "stets", "blei\u00b7bet", "auf", "der", "er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und der, haltend ma\u00df und weis,", "tokens": ["und", "der", ",", "hal\u00b7tend", "ma\u00df", "und", "weis", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "ADJD", "NN", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "weder gro\u00df noch reich will werden.", "tokens": ["we\u00b7der", "gro\u00df", "noch", "reich", "will", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ADJD", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "wie vil doch zu unsrer zeit", "tokens": ["wie", "vil", "doch", "zu", "uns\u00b7rer", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "sah ich trotzige Sejanen,", "tokens": ["sah", "ich", "trot\u00b7zi\u00b7ge", "Se\u00b7ja\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "deren werk uns nah und weit", "tokens": ["de\u00b7ren", "werk", "uns", "nah", "und", "weit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPER", "ADJD", "KON", "ADJD"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.12": {"text": "billich von dem hof abmahnen.", "tokens": ["bil\u00b7lich", "von", "dem", "hof", "ab\u00b7mah\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Flemming, du bist so erfahren,", "tokens": ["Flem\u00b7ming", ",", "du", "bist", "so", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "ADV", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "so verst\u00e4ndig, weis und klug,", "tokens": ["so", "ver\u00b7st\u00e4n\u00b7dig", ",", "weis", "und", "klug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PTKVZ", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df ich mehr mit gutem fug", "tokens": ["da\u00df", "ich", "mehr", "mit", "gu\u00b7tem", "fug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "dir zu sagen, wol mag sparen:", "tokens": ["dir", "zu", "sa\u00b7gen", ",", "wol", "mag", "spa\u00b7ren", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "alle h\u00f6f, ja alle welt", "tokens": ["al\u00b7le", "h\u00f6f", ",", "ja", "al\u00b7le", "welt"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "ADV", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "hast du flei\u00dfig durchgezogen,", "tokens": ["hast", "du", "flei\u00b7\u00dfig", "durch\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und w\u00fcrd der Ithakisch held", "tokens": ["und", "w\u00fcrd", "der", "It\u00b7ha\u00b7kisch", "held"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "VVFIN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "leichtlicher, dan du, betrogen.", "tokens": ["leicht\u00b7li\u00b7cher", ",", "dan", "du", ",", "be\u00b7tro\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "PPER", "$,", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.9": {"text": "was vil nationen dich", "tokens": ["was", "vil", "na\u00b7ti\u00b7o\u00b7nen", "dich"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "h\u00f6ren ihre sprachen reden,", "tokens": ["h\u00f6\u00b7ren", "ih\u00b7re", "spra\u00b7chen", "re\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "will bald ihrer jede sich,", "tokens": ["will", "bald", "ih\u00b7rer", "je\u00b7de", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "PIAT", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "da\u00df du ihr landkind, bereden.", "tokens": ["da\u00df", "du", "ihr", "land\u00b7kind", ",", "be\u00b7re\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Daher hast du auch befunden,", "tokens": ["Da\u00b7her", "hast", "du", "auch", "be\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df dir deine h\u00f6flichkeit,", "tokens": ["da\u00df", "dir", "dei\u00b7ne", "h\u00f6f\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "sprachen und erfahrenheit", "tokens": ["spra\u00b7chen", "und", "er\u00b7fah\u00b7ren\u00b7heit"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "deinen k\u00f6nig selbs verbunden,", "tokens": ["dei\u00b7nen", "k\u00f6\u00b7nig", "selbs", "ver\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "welcher dich dan hin und her", "tokens": ["wel\u00b7cher", "dich", "dan", "hin", "und", "her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "PTKVZ", "KON", "ADV"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "als gesandten ausgeschicket,", "tokens": ["als", "ge\u00b7sand\u00b7ten", "aus\u00b7ge\u00b7schi\u00b7cket", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "doch zu seiner schlechten ehr", "tokens": ["doch", "zu", "sei\u00b7ner", "schlech\u00b7ten", "ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "mehr entgl\u00fccket, dan begl\u00fccket;", "tokens": ["mehr", "ent\u00b7gl\u00fc\u00b7cket", ",", "dan", "be\u00b7gl\u00fc\u00b7cket", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "zwar mag er zu seiner zeit", "tokens": ["zwar", "mag", "er", "zu", "sei\u00b7ner", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "alles wider zurecht bringen;", "tokens": ["al\u00b7les", "wi\u00b7der", "zu\u00b7recht", "brin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "auch kan mit der tugend beut,", "tokens": ["auch", "kan", "mit", "der", "tu\u00b7gend", "beut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "welche dein, dir nicht mislingen.", "tokens": ["wel\u00b7che", "dein", ",", "dir", "nicht", "mis\u00b7lin\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAT", "PPOSAT", "$,", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Der, wie du weis, kan ihm schmiden", "tokens": ["Der", ",", "wie", "du", "weis", ",", "kan", "ihm", "schmi\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "$,", "PWAV", "PPER", "PTKVZ", "$,", "VMFIN", "PPER", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "allenthalb sein eigen gl\u00fcck;", "tokens": ["al\u00b7len\u00b7thalb", "sein", "ei\u00b7gen", "gl\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "keines f\u00fcrsten saurer blick", "tokens": ["kei\u00b7nes", "f\u00fcrs\u00b7ten", "sau\u00b7rer", "blick"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "hindert seines herzens friden:", "tokens": ["hin\u00b7dert", "sei\u00b7nes", "her\u00b7zens", "fri\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "ja dein redliches gesicht,", "tokens": ["ja", "dein", "red\u00b7li\u00b7ches", "ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "welches deinen mut bezeuget,", "tokens": ["wel\u00b7ches", "dei\u00b7nen", "mut", "be\u00b7zeu\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "da\u00df von dir wahr mein bericht", "tokens": ["da\u00df", "von", "dir", "wahr", "mein", "be\u00b7richt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPER", "ADJD", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "keinem weisen man verschweiget;", "tokens": ["kei\u00b7nem", "wei\u00b7sen", "man", "ver\u00b7schwei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "und weil du der tugend hold,", "tokens": ["und", "weil", "du", "der", "tu\u00b7gend", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "m\u00e4nniglich dich billich liebet;", "tokens": ["m\u00e4n\u00b7nig\u00b7lich", "dich", "bil\u00b7lich", "lie\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "dan die lieb ist dessen sold,", "tokens": ["dan", "die", "lieb", "ist", "des\u00b7sen", "sold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "VAFIN", "PDS", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "der stets wol zu thun sich \u00fcbet.", "tokens": ["der", "stets", "wol", "zu", "thun", "sich", "\u00fc\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PTKZU", "VVINF", "PRF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Was ich schreib von dem hofleben,", "tokens": ["Was", "ich", "schreib", "von", "dem", "hof\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "APPR", "ART", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ist dir mehr, dan mir, bewust:", "tokens": ["ist", "dir", "mehr", ",", "dan", "mir", ",", "be\u00b7wust", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "ADV", "PPER", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "du wei\u00dft, ob es mehr unlust", "tokens": ["du", "wei\u00dft", ",", "ob", "es", "mehr", "un\u00b7lust"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "oder wollust uns kan geben:", "tokens": ["o\u00b7der", "wol\u00b7lust", "uns", "kan", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "jedoch welcher weis, wie du,", "tokens": ["je\u00b7doch", "wel\u00b7cher", "weis", ",", "wie", "du", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PWAT", "PTKVZ", "$,", "PWAV", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "kan aus b\u00f6sem gutes ziehen", "tokens": ["kan", "aus", "b\u00f6\u00b7sem", "gu\u00b7tes", "zie\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ADJA", "ADJA", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und, o wunder! der unruh,", "tokens": ["und", ",", "o", "wun\u00b7der", "!", "der", "un\u00b7ruh", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "FM", "NN", "$.", "ART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.8": {"text": "ruhig innerlich, entfliehen;", "tokens": ["ru\u00b7hig", "in\u00b7ner\u00b7lich", ",", "ent\u00b7flie\u00b7hen", ";"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "aber durch der lastern heer", "tokens": ["a\u00b7ber", "durch", "der", "las\u00b7tern", "heer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "wie vil sehen wir hinsterben!", "tokens": ["wie", "vil", "se\u00b7hen", "wir", "hins\u00b7ter\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.11": {"text": "und in des hofs wildem meer", "tokens": ["und", "in", "des", "hofs", "wil\u00b7dem", "meer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.12": {"text": "wie vil sehen wir verderben!", "tokens": ["wie", "vil", "se\u00b7hen", "wir", "ver\u00b7der\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Zwar ist dem meer, wan es tobet", "tokens": ["Zwar", "ist", "dem", "meer", ",", "wan", "es", "to\u00b7bet"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "oder ruhet, der hof gleich,", "tokens": ["o\u00b7der", "ru\u00b7het", ",", "der", "hof", "gleich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "NN", "ADV", "$,"], "meter": "+-+-+++", "measure": "unknown.measure.penta"}, "line.3": {"text": "darauf fahret arm und reich,", "tokens": ["da\u00b7rauf", "fah\u00b7ret", "arm", "und", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "der uns sch\u00e4ndet, der uns lobet;", "tokens": ["der", "uns", "sch\u00e4n\u00b7det", ",", "der", "uns", "lo\u00b7bet", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wie das meer ganz ungest\u00fcm,", "tokens": ["wie", "das", "meer", "ganz", "un\u00b7ge\u00b7st\u00fcm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df die schif oft untergehen:", "tokens": ["da\u00df", "die", "schif", "oft", "un\u00b7ter\u00b7ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "VVFIN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "also kan zu hof der grim", "tokens": ["al\u00b7so", "kan", "zu", "hof", "der", "grim"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "APPR", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "eines f\u00fcrsten \u00e4rger wehen;", "tokens": ["ei\u00b7nes", "f\u00fcrs\u00b7ten", "\u00e4r\u00b7ger", "we\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "auf dem meer man seine fahrt", "tokens": ["auf", "dem", "meer", "man", "sei\u00b7ne", "fahrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIS", "PPOSAT", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "nach der sternen lauf regieret,", "tokens": ["nach", "der", "ster\u00b7nen", "lauf", "re\u00b7gie\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "zu hof der Sirenen art", "tokens": ["zu", "hof", "der", "Si\u00b7re\u00b7nen", "art"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "auf die felsen uns verf\u00fchret.", "tokens": ["auf", "die", "fel\u00b7sen", "uns", "ver\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Doch der felsen, der Sirenen", "tokens": ["Doch", "der", "fel\u00b7sen", ",", "der", "Si\u00b7re\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und der wellen pracht und macht,", "tokens": ["und", "der", "wel\u00b7len", "pracht", "und", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "auch der nebeln dicke nacht", "tokens": ["auch", "der", "ne\u00b7beln", "di\u00b7cke", "nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "APPR", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "(die gemeinglich allen denen,", "tokens": ["(", "die", "ge\u00b7mein\u00b7glich", "al\u00b7len", "de\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJD", "PIAT", "PDS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "welche nicht f\u00fcrsichtig seind,", "tokens": ["wel\u00b7che", "nicht", "f\u00fcr\u00b7sich\u00b7tig", "seind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRELS", "PTKNEG", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "den weg weisen zu dem leiden)", "tokens": ["den", "weg", "wei\u00b7sen", "zu", "dem", "lei\u00b7den", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "APPR", "ART", "VVINF", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "weil sie dein und du ihr feind,", "tokens": ["weil", "sie", "dein", "und", "du", "ihr", "feind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "KON", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "kanst du, Tiphis gleich, vermeiden;", "tokens": ["kanst", "du", ",", "Ti\u00b7phis", "gleich", ",", "ver\u00b7mei\u00b7den", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "NE", "ADV", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "dan du wei\u00dft, wie sich sehr schnell", "tokens": ["dan", "du", "wei\u00dft", ",", "wie", "sich", "sehr", "schnell"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "$,", "PWAV", "PRF", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "gl\u00fcck und lieb zu hof verkehret,", "tokens": ["gl\u00fcck", "und", "lieb", "zu", "hof", "ver\u00b7keh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "da\u00df der tag, sch\u00f6n, heiter, hell,", "tokens": ["da\u00df", "der", "tag", ",", "sch\u00f6n", ",", "hei\u00b7ter", ",", "hell", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "kaum ohn sturm bis abend wehret.", "tokens": ["kaum", "ohn", "sturm", "bis", "a\u00b7bend", "weh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Dises lied nun zu beschlie\u00dfen", "tokens": ["Di\u00b7ses", "lied", "nun", "zu", "be\u00b7schlie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "von des hofs f\u00fc\u00dfbittern speis,", "tokens": ["von", "des", "hofs", "f\u00fc\u00df\u00b7bit\u00b7tern", "speis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "so la\u00df, ich bit, dise weis", "tokens": ["so", "la\u00df", ",", "ich", "bit", ",", "di\u00b7se", "weis"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "PPER", "ADJD", "$,", "PDS", "PTKVZ"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "dich, herr Flemming, nicht verdrie\u00dfen.", "tokens": ["dich", ",", "herr", "Flem\u00b7ming", ",", "nicht", "ver\u00b7drie\u00b7\u00dfen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "NE", "$,", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df mit deines namens ehr", "tokens": ["da\u00df", "mit", "dei\u00b7nes", "na\u00b7mens", "ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "meinen namen zu besch\u00f6nen", "tokens": ["mei\u00b7nen", "na\u00b7men", "zu", "be\u00b7sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "ich (hofvogel) auch begehr,", "tokens": ["ich", "(", "hof\u00b7vo\u00b7gel", ")", "auch", "be\u00b7gehr", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$(", "NE", "$(", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "federn von dir zu entlehnen;", "tokens": ["fe\u00b7dern", "von", "dir", "zu", "ent\u00b7leh\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "weil wir beed von got die gnad,", "tokens": ["weil", "wir", "beed", "von", "got", "die", "gnad", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "NE", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "da\u00df der hof uns nicht umtreibet.", "tokens": ["da\u00df", "der", "hof", "uns", "nicht", "um\u00b7trei\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "selig, der bei dem hofrad", "tokens": ["se\u00b7lig", ",", "der", "bei", "dem", "hof\u00b7rad"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "aufrecht und best\u00e4ndig bleibet!", "tokens": ["auf\u00b7recht", "und", "be\u00b7st\u00e4n\u00b7dig", "blei\u00b7bet", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Wider willen und gewissen,", "tokens": ["Wi\u00b7der", "wil\u00b7len", "und", "ge\u00b7wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "eben so torecht als alt,", "tokens": ["e\u00b7ben", "so", "to\u00b7recht", "als", "alt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KOKOM", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ich mich noch zu hof aushalt,", "tokens": ["ich", "mich", "noch", "zu", "hof", "aus\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "andern dienend so geflissen,", "tokens": ["an\u00b7dern", "die\u00b7nend", "so", "ge\u00b7flis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df mir nicht ein st\u00fcndlein frei,", "tokens": ["da\u00df", "mir", "nicht", "ein", "st\u00fcnd\u00b7lein", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "got und mir selbs recht zu leben,", "tokens": ["got", "und", "mir", "selbs", "recht", "zu", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "da doch mir f\u00fcr meine treu,", "tokens": ["da", "doch", "mir", "f\u00fcr", "mei\u00b7ne", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "PPOSAT", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "m\u00fch und sorg kaum dank gegeben:", "tokens": ["m\u00fch", "und", "sorg", "kaum", "dank", "ge\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVFIN", "ADV", "APPR", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "und zwar billich; dan wer gern", "tokens": ["und", "zwar", "bil\u00b7lich", ";", "dan", "wer", "gern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "$.", "ADV", "PWS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "seinen tag bei hof wil enden,", "tokens": ["sei\u00b7nen", "tag", "bei", "hof", "wil", "en\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "der hat weder heil noch stern", "tokens": ["der", "hat", "we\u00b7der", "heil", "noch", "stern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "KON", "ADJD", "ADV", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "seinen lauf wol zu vollenden.", "tokens": ["sei\u00b7nen", "lauf", "wol", "zu", "voll\u00b7en\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Ich sih ja, noch nicht verblindet,", "tokens": ["Ich", "sih", "ja", ",", "noch", "nicht", "ver\u00b7blin\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "da\u00df die tugend gar umsunst,", "tokens": ["da\u00df", "die", "tu\u00b7gend", "gar", "um\u00b7sunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df allein die bosheit gunst,", "tokens": ["da\u00df", "al\u00b7lein", "die", "bos\u00b7heit", "gunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "lieb und vortheil bei hof findet.", "tokens": ["lieb", "und", "vor\u00b7theil", "bei", "hof", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "dise marbrine pall\u00e4st,", "tokens": ["di\u00b7se", "mar\u00b7bri\u00b7ne", "pal\u00b7l\u00e4st", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "underproppet mit albaster,", "tokens": ["un\u00b7der\u00b7prop\u00b7pet", "mit", "al\u00b7bas\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "halten in sich manches nest", "tokens": ["hal\u00b7ten", "in", "sich", "man\u00b7ches", "nest"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PRF", "PIS", "VVFIN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.8": {"text": "f\u00fcr verruchte lust und laster:", "tokens": ["f\u00fcr", "ver\u00b7ruch\u00b7te", "lust", "und", "las\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "under seiden, silber, gold,", "tokens": ["un\u00b7der", "sei\u00b7den", ",", "sil\u00b7ber", ",", "gold", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "ADV", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "damit sich der hof bedecket,", "tokens": ["da\u00b7mit", "sich", "der", "hof", "be\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "als in seiner lastern sold,", "tokens": ["als", "in", "sei\u00b7ner", "las\u00b7tern", "sold", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "nichts dan \u00fcbels sich verstecket.", "tokens": ["nichts", "dan", "\u00fc\u00b7bels", "sich", "ver\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "APPR", "PRF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Lang zu hof mu\u00df der nicht bleiben,", "tokens": ["Lang", "zu", "hof", "mu\u00df", "der", "nicht", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VMFIN", "ART", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "welcher redlich bleiben will:", "tokens": ["wel\u00b7cher", "red\u00b7lich", "blei\u00b7ben", "will", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "welcher, eingezogen, still,", "tokens": ["wel\u00b7cher", ",", "ein\u00b7ge\u00b7zo\u00b7gen", ",", "still", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAT", "$,", "VVPP", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht will narrenbossen treiben;", "tokens": ["nicht", "will", "nar\u00b7ren\u00b7bos\u00b7sen", "trei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VMFIN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "welcher nicht sein haupt und kn\u00fce", "tokens": ["wel\u00b7cher", "nicht", "sein", "haupt", "und", "kn\u00fce"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "PPOSAT", "NN", "KON", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "kan f\u00fcr jedem Haman biegen,", "tokens": ["kan", "f\u00fcr", "je\u00b7dem", "Ha\u00b7man", "bie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "welcher nicht kan spat und fr\u00fc", "tokens": ["wel\u00b7cher", "nicht", "kan", "spat", "und", "fr\u00fc"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "VMFIN", "VVFIN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "glei\u00dfnen, liegen und betriegen:", "tokens": ["glei\u00df\u00b7nen", ",", "lie\u00b7gen", "und", "be\u00b7trie\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "k\u00fcrzlich: welcher gut und from", "tokens": ["k\u00fcrz\u00b7lich", ":", "wel\u00b7cher", "gut", "und", "from"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "PRELS", "ADJD", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "will das \u00fcbel \u00fcbel nennen", "tokens": ["will", "das", "\u00fc\u00b7bel", "\u00fc\u00b7bel", "nen\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "ADJD", "ADJD", "VVINF"], "meter": "+-+-----", "measure": "unknown.measure.di"}, "line.11": {"text": "und nicht will, blind, taub und stum,", "tokens": ["und", "nicht", "will", ",", "blind", ",", "taub", "und", "stum", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "VMFIN", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "alles b\u00f6s f\u00fcr gut erkennen.", "tokens": ["al\u00b7les", "b\u00f6s", "f\u00fcr", "gut", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "APPR", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Darf ich andern wol anzeigen", "tokens": ["Darf", "ich", "an\u00b7dern", "wol", "an\u00b7zei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PIS", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "des hofmans religion,", "tokens": ["des", "hof\u00b7mans", "re\u00b7li\u00b7gi\u00b7on", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und f\u00fcr welcher gotheit thron", "tokens": ["und", "f\u00fcr", "wel\u00b7cher", "got\u00b7heit", "thron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PWAT", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "sich die h\u00f6flingherzen neigen?", "tokens": ["sich", "die", "h\u00f6f\u00b7ling\u00b7her\u00b7zen", "nei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "reichtum, ehrgeiz und wollust,", "tokens": ["reich\u00b7tum", ",", "ehr\u00b7geiz", "und", "wol\u00b7lust", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["FM.la", "$,", "ADJD", "KON", "VMFIN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "deren erste drei buchstaben", "tokens": ["de\u00b7ren", "ers\u00b7te", "drei", "buch\u00b7sta\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "merklich, seind in ihrer brust", "tokens": ["merk\u00b7lich", ",", "seind", "in", "ih\u00b7rer", "brust"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "als gotheiten tief gegraben:", "tokens": ["als", "got\u00b7hei\u00b7ten", "tief", "ge\u00b7gra\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "alles lebens seligkeit,", "tokens": ["al\u00b7les", "le\u00b7bens", "se\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "glauben sie, sei hier auf erden,", "tokens": ["glau\u00b7ben", "sie", ",", "sei", "hier", "auf", "er\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VAFIN", "ADV", "APPR", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.11": {"text": "die in des hofs herrlichkeit", "tokens": ["die", "in", "des", "hofs", "herr\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "wohnend, mu\u00df gefunden werden.", "tokens": ["woh\u00b7nend", ",", "mu\u00df", "ge\u00b7fun\u00b7den", "wer\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Warlich bei hof seind sehr wenig,", "tokens": ["War\u00b7lich", "bei", "hof", "seind", "sehr", "we\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "VAFIN", "ADV", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die in b\u00f6sem \u00fcberflu\u00df", "tokens": ["die", "in", "b\u00f6\u00b7sem", "\u00fc\u00b7berf\u00b7lu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und in k\u00fctzelndem verdru\u00df", "tokens": ["und", "in", "k\u00fct\u00b7zeln\u00b7dem", "ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00fcber ihre l\u00fcste k\u00f6nig:", "tokens": ["\u00fc\u00b7ber", "ih\u00b7re", "l\u00fcs\u00b7te", "k\u00f6\u00b7nig", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "und die f\u00fcrsten mehrer theils,", "tokens": ["und", "die", "f\u00fcrs\u00b7ten", "meh\u00b7rer", "theils", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "PIAT", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "folgend ihrem schn\u00f6den willen,", "tokens": ["fol\u00b7gend", "ih\u00b7rem", "schn\u00f6\u00b7den", "wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "der ein werkzeug des unheils", "tokens": ["der", "ein", "werk\u00b7zeug", "des", "un\u00b7heils"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "ihren lust mit lastern f\u00fcllen:", "tokens": ["ih\u00b7ren", "lust", "mit", "las\u00b7tern", "f\u00fcl\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "und dan der hofleuten wohn,", "tokens": ["und", "dan", "der", "hof\u00b7leu\u00b7ten", "wohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "affen gleich, ist mit cramanzen", "tokens": ["af\u00b7fen", "gleich", ",", "ist", "mit", "cra\u00b7man\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "VAFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "nach so hipscher herren ton", "tokens": ["nach", "so", "hip\u00b7scher", "her\u00b7ren", "ton"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADJA", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "stets zu singen und zu danzen.", "tokens": ["stets", "zu", "sin\u00b7gen", "und", "zu", "dan\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Daher t\u00e4glich mehr beth\u00f6ret", "tokens": ["Da\u00b7her", "t\u00e4g\u00b7lich", "mehr", "be\u00b7th\u00f6\u00b7ret"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ADJD", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "narren, ohn verstand, witz, ruh,", "tokens": ["nar\u00b7ren", ",", "ohn", "ver\u00b7stand", ",", "witz", ",", "ruh", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "KOUI", "VVFIN", "$,", "VVIMP", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "danzen sie dem teufel zu,", "tokens": ["dan\u00b7zen", "sie", "dem", "teu\u00b7fel", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wan ihr danz nicht wird verst\u00f6ret:", "tokens": ["wan", "ihr", "danz", "nicht", "wird", "ver\u00b7st\u00f6\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PTKNEG", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "ja sie danzen so lang fort,", "tokens": ["ja", "sie", "dan\u00b7zen", "so", "lang", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "bis sie in die grub gest\u00fcrzet,", "tokens": ["bis", "sie", "in", "die", "grub", "ge\u00b7st\u00fcr\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "wa nicht ihren danz ein wort,", "tokens": ["wa", "nicht", "ih\u00b7ren", "danz", "ein", "wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "PTKNEG", "PPOSAT", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "sie abrufend, schnell verk\u00fcrzet;", "tokens": ["sie", "ab\u00b7ru\u00b7fend", ",", "schnell", "ver\u00b7k\u00fcr\u00b7zet", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "ADJD", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "wa sie nicht schuld, schmach, spot, schand", "tokens": ["wa", "sie", "nicht", "schuld", ",", "schmach", ",", "spot", ",", "schand"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "PPER", "PTKNEG", "ADJD", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "oder krankheit davon rei\u00dfet,", "tokens": ["o\u00b7der", "krank\u00b7heit", "da\u00b7von", "rei\u00b7\u00dfet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PAV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "oder der ungnaden hand", "tokens": ["o\u00b7der", "der", "ung\u00b7na\u00b7den", "hand"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "wegen eines strohs zerschmei\u00dfet.", "tokens": ["we\u00b7gen", "ei\u00b7nes", "strohs", "zer\u00b7schmei\u00b7\u00dfet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Doch wan einer, hoch ankommen,", "tokens": ["Doch", "wan", "ei\u00b7ner", ",", "hoch", "an\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "$,", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u00fcber andre herschen kan,", "tokens": ["\u00fc\u00b7ber", "and\u00b7re", "her\u00b7schen", "kan", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "so will er stracks sein der hahn,", "tokens": ["so", "will", "er", "stracks", "sein", "der", "hahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPOSAT", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "wan schon andre um ihn brummen:", "tokens": ["wan", "schon", "and\u00b7re", "um", "ihn", "brum\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIS", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wird ihm schon der ganz hof feind,", "tokens": ["wird", "ihm", "schon", "der", "ganz", "hof", "feind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "ADV", "VVFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "will er doch den hof ganz zwingen;", "tokens": ["will", "er", "doch", "den", "hof", "ganz", "zwin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "basen, vetter, esel, freind,", "tokens": ["ba\u00b7sen", ",", "vet\u00b7ter", ",", "e\u00b7sel", ",", "freind", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "$,", "NE", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "dieb und kuppler hoch anbringen:", "tokens": ["dieb", "und", "kupp\u00b7ler", "hoch", "an\u00b7brin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "KON", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "bis da\u00df des hofs unbestand", "tokens": ["bis", "da\u00df", "des", "hofs", "un\u00b7be\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "ihm erwecket einen dunder,", "tokens": ["ihm", "er\u00b7we\u00b7cket", "ei\u00b7nen", "dun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "der durch des volks schwere hand", "tokens": ["der", "durch", "des", "volks", "schwe\u00b7re", "hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.12": {"text": "st\u00fcrzet endlich ihn herunder.", "tokens": ["st\u00fcr\u00b7zet", "end\u00b7lich", "ihn", "her\u00b7un\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "St\u00fcrzet! ja, eh er gedenket,", "tokens": ["St\u00fcr\u00b7zet", "!", "ja", ",", "eh", "er", "ge\u00b7den\u00b7ket", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PTKANT", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "wird er schnell mit h\u00f6chstem spot", "tokens": ["wird", "er", "schnell", "mit", "h\u00f6chs\u00b7tem", "spot"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADJD", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "weggeraufet zu dem tod", "tokens": ["weg\u00b7ger\u00b7au\u00b7fet", "zu", "dem", "tod"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "oder Haman gleich gehenket:", "tokens": ["o\u00b7der", "Ha\u00b7man", "gleich", "ge\u00b7hen\u00b7ket", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "da ihn dan des p\u00f6fels rach,", "tokens": ["da", "ihn", "dan", "des", "p\u00f6\u00b7fels", "rach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "welches sterbend ihn verfluchet,", "tokens": ["wel\u00b7ches", "ster\u00b7bend", "ihn", "ver\u00b7flu\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "lehret spat mit schimpf und schmach,", "tokens": ["leh\u00b7ret", "spat", "mit", "schimpf", "und", "schmach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "was er torecht lang gesuchet.", "tokens": ["was", "er", "to\u00b7recht", "lang", "ge\u00b7su\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "dan gewi\u00dflich, wer zu hoch", "tokens": ["dan", "ge\u00b7wi\u00df\u00b7lich", ",", "wer", "zu", "hoch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "PWS", "PTKA", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "steiget, der mu\u00df endlich fallen,", "tokens": ["stei\u00b7get", ",", "der", "mu\u00df", "end\u00b7lich", "fal\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "daher dan kan das hofjoch", "tokens": ["da\u00b7her", "dan", "kan", "das", "hof\u00b7joch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VMFIN", "ART", "NN"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "keinem weisen lang gefallen.", "tokens": ["kei\u00b7nem", "wei\u00b7sen", "lang", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Der mag spilen, singen, lachen", "tokens": ["Der", "mag", "spi\u00b7len", ",", "sin\u00b7gen", ",", "la\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PDS", "VMFIN", "VVINF", "$,", "VVFIN", "$,", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mit des sch\u00f6nen tags anfang,", "tokens": ["mit", "des", "sch\u00f6\u00b7nen", "tags", "an\u00b7fang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "den der sonnen nidergang", "tokens": ["den", "der", "son\u00b7nen", "ni\u00b7der\u00b7gang"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "k\u00fcrzlich kan verzweiflen machen:", "tokens": ["k\u00fcrz\u00b7lich", "kan", "ver\u00b7zwei\u00b7flen", "ma\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "und daher ist jener weis,", "tokens": ["und", "da\u00b7her", "ist", "je\u00b7ner", "weis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PDS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "der stets bleibet auf der erden", "tokens": ["der", "stets", "blei\u00b7bet", "auf", "der", "er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und der, haltend ma\u00df und weis,", "tokens": ["und", "der", ",", "hal\u00b7tend", "ma\u00df", "und", "weis", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "ADJD", "NN", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "weder gro\u00df noch reich will werden.", "tokens": ["we\u00b7der", "gro\u00df", "noch", "reich", "will", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ADJD", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "wie vil doch zu unsrer zeit", "tokens": ["wie", "vil", "doch", "zu", "uns\u00b7rer", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "sah ich trotzige Sejanen,", "tokens": ["sah", "ich", "trot\u00b7zi\u00b7ge", "Se\u00b7ja\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "deren werk uns nah und weit", "tokens": ["de\u00b7ren", "werk", "uns", "nah", "und", "weit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPER", "ADJD", "KON", "ADJD"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.12": {"text": "billich von dem hof abmahnen.", "tokens": ["bil\u00b7lich", "von", "dem", "hof", "ab\u00b7mah\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Flemming, du bist so erfahren,", "tokens": ["Flem\u00b7ming", ",", "du", "bist", "so", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "ADV", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "so verst\u00e4ndig, weis und klug,", "tokens": ["so", "ver\u00b7st\u00e4n\u00b7dig", ",", "weis", "und", "klug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PTKVZ", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df ich mehr mit gutem fug", "tokens": ["da\u00df", "ich", "mehr", "mit", "gu\u00b7tem", "fug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "dir zu sagen, wol mag sparen:", "tokens": ["dir", "zu", "sa\u00b7gen", ",", "wol", "mag", "spa\u00b7ren", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "alle h\u00f6f, ja alle welt", "tokens": ["al\u00b7le", "h\u00f6f", ",", "ja", "al\u00b7le", "welt"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "ADV", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "hast du flei\u00dfig durchgezogen,", "tokens": ["hast", "du", "flei\u00b7\u00dfig", "durch\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und w\u00fcrd der Ithakisch held", "tokens": ["und", "w\u00fcrd", "der", "It\u00b7ha\u00b7kisch", "held"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "VVFIN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "leichtlicher, dan du, betrogen.", "tokens": ["leicht\u00b7li\u00b7cher", ",", "dan", "du", ",", "be\u00b7tro\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "PPER", "$,", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.9": {"text": "was vil nationen dich", "tokens": ["was", "vil", "na\u00b7ti\u00b7o\u00b7nen", "dich"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "h\u00f6ren ihre sprachen reden,", "tokens": ["h\u00f6\u00b7ren", "ih\u00b7re", "spra\u00b7chen", "re\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "will bald ihrer jede sich,", "tokens": ["will", "bald", "ih\u00b7rer", "je\u00b7de", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "PIAT", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "da\u00df du ihr landkind, bereden.", "tokens": ["da\u00df", "du", "ihr", "land\u00b7kind", ",", "be\u00b7re\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Daher hast du auch befunden,", "tokens": ["Da\u00b7her", "hast", "du", "auch", "be\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df dir deine h\u00f6flichkeit,", "tokens": ["da\u00df", "dir", "dei\u00b7ne", "h\u00f6f\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "sprachen und erfahrenheit", "tokens": ["spra\u00b7chen", "und", "er\u00b7fah\u00b7ren\u00b7heit"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "deinen k\u00f6nig selbs verbunden,", "tokens": ["dei\u00b7nen", "k\u00f6\u00b7nig", "selbs", "ver\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "welcher dich dan hin und her", "tokens": ["wel\u00b7cher", "dich", "dan", "hin", "und", "her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "PTKVZ", "KON", "ADV"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "als gesandten ausgeschicket,", "tokens": ["als", "ge\u00b7sand\u00b7ten", "aus\u00b7ge\u00b7schi\u00b7cket", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "doch zu seiner schlechten ehr", "tokens": ["doch", "zu", "sei\u00b7ner", "schlech\u00b7ten", "ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "mehr entgl\u00fccket, dan begl\u00fccket;", "tokens": ["mehr", "ent\u00b7gl\u00fc\u00b7cket", ",", "dan", "be\u00b7gl\u00fc\u00b7cket", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "zwar mag er zu seiner zeit", "tokens": ["zwar", "mag", "er", "zu", "sei\u00b7ner", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "alles wider zurecht bringen;", "tokens": ["al\u00b7les", "wi\u00b7der", "zu\u00b7recht", "brin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "auch kan mit der tugend beut,", "tokens": ["auch", "kan", "mit", "der", "tu\u00b7gend", "beut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "welche dein, dir nicht mislingen.", "tokens": ["wel\u00b7che", "dein", ",", "dir", "nicht", "mis\u00b7lin\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAT", "PPOSAT", "$,", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Der, wie du weis, kan ihm schmiden", "tokens": ["Der", ",", "wie", "du", "weis", ",", "kan", "ihm", "schmi\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "$,", "PWAV", "PPER", "PTKVZ", "$,", "VMFIN", "PPER", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "allenthalb sein eigen gl\u00fcck;", "tokens": ["al\u00b7len\u00b7thalb", "sein", "ei\u00b7gen", "gl\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "keines f\u00fcrsten saurer blick", "tokens": ["kei\u00b7nes", "f\u00fcrs\u00b7ten", "sau\u00b7rer", "blick"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "hindert seines herzens friden:", "tokens": ["hin\u00b7dert", "sei\u00b7nes", "her\u00b7zens", "fri\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "ja dein redliches gesicht,", "tokens": ["ja", "dein", "red\u00b7li\u00b7ches", "ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "welches deinen mut bezeuget,", "tokens": ["wel\u00b7ches", "dei\u00b7nen", "mut", "be\u00b7zeu\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "da\u00df von dir wahr mein bericht", "tokens": ["da\u00df", "von", "dir", "wahr", "mein", "be\u00b7richt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPER", "ADJD", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "keinem weisen man verschweiget;", "tokens": ["kei\u00b7nem", "wei\u00b7sen", "man", "ver\u00b7schwei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "und weil du der tugend hold,", "tokens": ["und", "weil", "du", "der", "tu\u00b7gend", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "m\u00e4nniglich dich billich liebet;", "tokens": ["m\u00e4n\u00b7nig\u00b7lich", "dich", "bil\u00b7lich", "lie\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "dan die lieb ist dessen sold,", "tokens": ["dan", "die", "lieb", "ist", "des\u00b7sen", "sold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "VAFIN", "PDS", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "der stets wol zu thun sich \u00fcbet.", "tokens": ["der", "stets", "wol", "zu", "thun", "sich", "\u00fc\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PTKZU", "VVINF", "PRF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Was ich schreib von dem hofleben,", "tokens": ["Was", "ich", "schreib", "von", "dem", "hof\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "APPR", "ART", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ist dir mehr, dan mir, bewust:", "tokens": ["ist", "dir", "mehr", ",", "dan", "mir", ",", "be\u00b7wust", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "ADV", "PPER", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "du wei\u00dft, ob es mehr unlust", "tokens": ["du", "wei\u00dft", ",", "ob", "es", "mehr", "un\u00b7lust"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "oder wollust uns kan geben:", "tokens": ["o\u00b7der", "wol\u00b7lust", "uns", "kan", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "jedoch welcher weis, wie du,", "tokens": ["je\u00b7doch", "wel\u00b7cher", "weis", ",", "wie", "du", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PWAT", "PTKVZ", "$,", "PWAV", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "kan aus b\u00f6sem gutes ziehen", "tokens": ["kan", "aus", "b\u00f6\u00b7sem", "gu\u00b7tes", "zie\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ADJA", "ADJA", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und, o wunder! der unruh,", "tokens": ["und", ",", "o", "wun\u00b7der", "!", "der", "un\u00b7ruh", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "FM", "NN", "$.", "ART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.8": {"text": "ruhig innerlich, entfliehen;", "tokens": ["ru\u00b7hig", "in\u00b7ner\u00b7lich", ",", "ent\u00b7flie\u00b7hen", ";"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "aber durch der lastern heer", "tokens": ["a\u00b7ber", "durch", "der", "las\u00b7tern", "heer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "wie vil sehen wir hinsterben!", "tokens": ["wie", "vil", "se\u00b7hen", "wir", "hins\u00b7ter\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.11": {"text": "und in des hofs wildem meer", "tokens": ["und", "in", "des", "hofs", "wil\u00b7dem", "meer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.12": {"text": "wie vil sehen wir verderben!", "tokens": ["wie", "vil", "se\u00b7hen", "wir", "ver\u00b7der\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Zwar ist dem meer, wan es tobet", "tokens": ["Zwar", "ist", "dem", "meer", ",", "wan", "es", "to\u00b7bet"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "oder ruhet, der hof gleich,", "tokens": ["o\u00b7der", "ru\u00b7het", ",", "der", "hof", "gleich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "NN", "ADV", "$,"], "meter": "+-+-+++", "measure": "unknown.measure.penta"}, "line.3": {"text": "darauf fahret arm und reich,", "tokens": ["da\u00b7rauf", "fah\u00b7ret", "arm", "und", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "der uns sch\u00e4ndet, der uns lobet;", "tokens": ["der", "uns", "sch\u00e4n\u00b7det", ",", "der", "uns", "lo\u00b7bet", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wie das meer ganz ungest\u00fcm,", "tokens": ["wie", "das", "meer", "ganz", "un\u00b7ge\u00b7st\u00fcm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df die schif oft untergehen:", "tokens": ["da\u00df", "die", "schif", "oft", "un\u00b7ter\u00b7ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "VVFIN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "also kan zu hof der grim", "tokens": ["al\u00b7so", "kan", "zu", "hof", "der", "grim"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "APPR", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "eines f\u00fcrsten \u00e4rger wehen;", "tokens": ["ei\u00b7nes", "f\u00fcrs\u00b7ten", "\u00e4r\u00b7ger", "we\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "auf dem meer man seine fahrt", "tokens": ["auf", "dem", "meer", "man", "sei\u00b7ne", "fahrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIS", "PPOSAT", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "nach der sternen lauf regieret,", "tokens": ["nach", "der", "ster\u00b7nen", "lauf", "re\u00b7gie\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "zu hof der Sirenen art", "tokens": ["zu", "hof", "der", "Si\u00b7re\u00b7nen", "art"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "auf die felsen uns verf\u00fchret.", "tokens": ["auf", "die", "fel\u00b7sen", "uns", "ver\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Doch der felsen, der Sirenen", "tokens": ["Doch", "der", "fel\u00b7sen", ",", "der", "Si\u00b7re\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und der wellen pracht und macht,", "tokens": ["und", "der", "wel\u00b7len", "pracht", "und", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "auch der nebeln dicke nacht", "tokens": ["auch", "der", "ne\u00b7beln", "di\u00b7cke", "nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "APPR", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "(die gemeinglich allen denen,", "tokens": ["(", "die", "ge\u00b7mein\u00b7glich", "al\u00b7len", "de\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJD", "PIAT", "PDS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "welche nicht f\u00fcrsichtig seind,", "tokens": ["wel\u00b7che", "nicht", "f\u00fcr\u00b7sich\u00b7tig", "seind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRELS", "PTKNEG", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "den weg weisen zu dem leiden)", "tokens": ["den", "weg", "wei\u00b7sen", "zu", "dem", "lei\u00b7den", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "APPR", "ART", "VVINF", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "weil sie dein und du ihr feind,", "tokens": ["weil", "sie", "dein", "und", "du", "ihr", "feind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "KON", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "kanst du, Tiphis gleich, vermeiden;", "tokens": ["kanst", "du", ",", "Ti\u00b7phis", "gleich", ",", "ver\u00b7mei\u00b7den", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "NE", "ADV", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "dan du wei\u00dft, wie sich sehr schnell", "tokens": ["dan", "du", "wei\u00dft", ",", "wie", "sich", "sehr", "schnell"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "$,", "PWAV", "PRF", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "gl\u00fcck und lieb zu hof verkehret,", "tokens": ["gl\u00fcck", "und", "lieb", "zu", "hof", "ver\u00b7keh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "da\u00df der tag, sch\u00f6n, heiter, hell,", "tokens": ["da\u00df", "der", "tag", ",", "sch\u00f6n", ",", "hei\u00b7ter", ",", "hell", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "kaum ohn sturm bis abend wehret.", "tokens": ["kaum", "ohn", "sturm", "bis", "a\u00b7bend", "weh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Dises lied nun zu beschlie\u00dfen", "tokens": ["Di\u00b7ses", "lied", "nun", "zu", "be\u00b7schlie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "von des hofs f\u00fc\u00dfbittern speis,", "tokens": ["von", "des", "hofs", "f\u00fc\u00df\u00b7bit\u00b7tern", "speis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "so la\u00df, ich bit, dise weis", "tokens": ["so", "la\u00df", ",", "ich", "bit", ",", "di\u00b7se", "weis"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "PPER", "ADJD", "$,", "PDS", "PTKVZ"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "dich, herr Flemming, nicht verdrie\u00dfen.", "tokens": ["dich", ",", "herr", "Flem\u00b7ming", ",", "nicht", "ver\u00b7drie\u00b7\u00dfen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "NE", "$,", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df mit deines namens ehr", "tokens": ["da\u00df", "mit", "dei\u00b7nes", "na\u00b7mens", "ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "meinen namen zu besch\u00f6nen", "tokens": ["mei\u00b7nen", "na\u00b7men", "zu", "be\u00b7sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "ich (hofvogel) auch begehr,", "tokens": ["ich", "(", "hof\u00b7vo\u00b7gel", ")", "auch", "be\u00b7gehr", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$(", "NE", "$(", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "federn von dir zu entlehnen;", "tokens": ["fe\u00b7dern", "von", "dir", "zu", "ent\u00b7leh\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "weil wir beed von got die gnad,", "tokens": ["weil", "wir", "beed", "von", "got", "die", "gnad", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "NE", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "da\u00df der hof uns nicht umtreibet.", "tokens": ["da\u00df", "der", "hof", "uns", "nicht", "um\u00b7trei\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "selig, der bei dem hofrad", "tokens": ["se\u00b7lig", ",", "der", "bei", "dem", "hof\u00b7rad"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "aufrecht und best\u00e4ndig bleibet!", "tokens": ["auf\u00b7recht", "und", "be\u00b7st\u00e4n\u00b7dig", "blei\u00b7bet", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}