{"textgrid.poem.47130": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "7.", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Fr\u00fchling f\u00e4hrt hernieder", "tokens": ["Der", "Fr\u00fch\u00b7ling", "f\u00e4hrt", "her\u00b7nie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Vom Himmel, um auf Triften", "tokens": ["Vom", "Him\u00b7mel", ",", "um", "auf", "Trif\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "KOUI", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Neu aufzuschlagen wieder", "tokens": ["Neu", "auf\u00b7zu\u00b7schla\u00b7gen", "wie\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "VVFIN", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Des Korans heil'ge Schriften.", "tokens": ["Des", "Ko\u00b7rans", "heil'\u00b7ge", "Schrif\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "O kommet anzubeten,", "tokens": ["O", "kom\u00b7met", "an\u00b7zu\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ihr frommen Muselmanen,", "tokens": ["Ihr", "from\u00b7men", "Mu\u00b7sel\u00b7ma\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und la\u00dft von dem Propheten", "tokens": ["Und", "la\u00dft", "von", "dem", "Pro\u00b7phe\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zum rechten Dienst euch mahnen.", "tokens": ["Zum", "rech\u00b7ten", "Dienst", "euch", "mah\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "O sehet, wie er leise", "tokens": ["O", "se\u00b7het", ",", "wie", "er", "lei\u00b7se"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "PWAV", "PPER", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Thut Wunder unbem\u00fchet,", "tokens": ["Thut", "Wun\u00b7der", "un\u00b7be\u00b7m\u00fc\u00b7het", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er spricht zum d\u00fcrren Reise:", "tokens": ["Er", "spricht", "zum", "d\u00fcr\u00b7ren", "Rei\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Erbl\u00fch'! und es erbl\u00fchet.", "tokens": ["Er\u00b7bl\u00fch'", "!", "und", "es", "er\u00b7bl\u00fc\u00b7het", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "And\u00e4chtiges Gem\u00fcte,", "tokens": ["An\u00b7d\u00e4ch\u00b7ti\u00b7ges", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "O komm und lies die Suren", "tokens": ["O", "komm", "und", "lies", "die", "Su\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von Gottes Mild' und G\u00fcte", "tokens": ["Von", "Got\u00b7tes", "Mild'", "und", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Im gr\u00fcnen Buch der Fluren.", "tokens": ["Im", "gr\u00fc\u00b7nen", "Buch", "der", "Flu\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Da ist kein Blatt so kleines,", "tokens": ["Da", "ist", "kein", "Blatt", "so", "klei\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es spricht ein Wort vom Lichte.", "tokens": ["Es", "spricht", "ein", "Wort", "vom", "Lich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Komm, Herz, und lies hier eines", "tokens": ["Komm", ",", "Herz", ",", "und", "lies", "hier", "ei\u00b7nes"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "KON", "VVFIN", "ADV", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Von Liebchens Angesichte.", "tokens": ["Von", "Lieb\u00b7chens", "An\u00b7ge\u00b7sich\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Im Wangenmorgenrote", "tokens": ["Im", "Wan\u00b7gen\u00b7mor\u00b7gen\u00b7ro\u00b7te"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Steht das Gebot, zu lieben,", "tokens": ["Steht", "das", "Ge\u00b7bot", ",", "zu", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und von des Weins Verbote", "tokens": ["Und", "von", "des", "Weins", "Ver\u00b7bo\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Steht nichts dabei geschrieben.", "tokens": ["Steht", "nichts", "da\u00b7bei", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PAV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Der Fr\u00fchling f\u00e4hrt hernieder", "tokens": ["Der", "Fr\u00fch\u00b7ling", "f\u00e4hrt", "her\u00b7nie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Vom Himmel, um auf Triften", "tokens": ["Vom", "Him\u00b7mel", ",", "um", "auf", "Trif\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "KOUI", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Neu aufzuschlagen wieder", "tokens": ["Neu", "auf\u00b7zu\u00b7schla\u00b7gen", "wie\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "VVFIN", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Des Korans heil'ge Schriften.", "tokens": ["Des", "Ko\u00b7rans", "heil'\u00b7ge", "Schrif\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "O kommet anzubeten,", "tokens": ["O", "kom\u00b7met", "an\u00b7zu\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ihr frommen Muselmanen,", "tokens": ["Ihr", "from\u00b7men", "Mu\u00b7sel\u00b7ma\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und la\u00dft von dem Propheten", "tokens": ["Und", "la\u00dft", "von", "dem", "Pro\u00b7phe\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zum rechten Dienst euch mahnen.", "tokens": ["Zum", "rech\u00b7ten", "Dienst", "euch", "mah\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "O sehet, wie er leise", "tokens": ["O", "se\u00b7het", ",", "wie", "er", "lei\u00b7se"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "PWAV", "PPER", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Thut Wunder unbem\u00fchet,", "tokens": ["Thut", "Wun\u00b7der", "un\u00b7be\u00b7m\u00fc\u00b7het", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er spricht zum d\u00fcrren Reise:", "tokens": ["Er", "spricht", "zum", "d\u00fcr\u00b7ren", "Rei\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Erbl\u00fch'! und es erbl\u00fchet.", "tokens": ["Er\u00b7bl\u00fch'", "!", "und", "es", "er\u00b7bl\u00fc\u00b7het", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "And\u00e4chtiges Gem\u00fcte,", "tokens": ["An\u00b7d\u00e4ch\u00b7ti\u00b7ges", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "O komm und lies die Suren", "tokens": ["O", "komm", "und", "lies", "die", "Su\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von Gottes Mild' und G\u00fcte", "tokens": ["Von", "Got\u00b7tes", "Mild'", "und", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Im gr\u00fcnen Buch der Fluren.", "tokens": ["Im", "gr\u00fc\u00b7nen", "Buch", "der", "Flu\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Da ist kein Blatt so kleines,", "tokens": ["Da", "ist", "kein", "Blatt", "so", "klei\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es spricht ein Wort vom Lichte.", "tokens": ["Es", "spricht", "ein", "Wort", "vom", "Lich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Komm, Herz, und lies hier eines", "tokens": ["Komm", ",", "Herz", ",", "und", "lies", "hier", "ei\u00b7nes"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "KON", "VVFIN", "ADV", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Von Liebchens Angesichte.", "tokens": ["Von", "Lieb\u00b7chens", "An\u00b7ge\u00b7sich\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Im Wangenmorgenrote", "tokens": ["Im", "Wan\u00b7gen\u00b7mor\u00b7gen\u00b7ro\u00b7te"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Steht das Gebot, zu lieben,", "tokens": ["Steht", "das", "Ge\u00b7bot", ",", "zu", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und von des Weins Verbote", "tokens": ["Und", "von", "des", "Weins", "Ver\u00b7bo\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Steht nichts dabei geschrieben.", "tokens": ["Steht", "nichts", "da\u00b7bei", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PAV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}