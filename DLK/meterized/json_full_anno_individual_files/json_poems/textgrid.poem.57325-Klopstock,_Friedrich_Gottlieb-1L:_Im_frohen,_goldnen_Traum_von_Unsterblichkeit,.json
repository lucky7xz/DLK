{"textgrid.poem.57325": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Im frohen, goldnen Traum von Unsterblichkeit,", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Im frohen, goldnen Traum von Unsterblichkeit,", "tokens": ["Im", "fro\u00b7hen", ",", "gold\u00b7nen", "Traum", "von", "U\u00b7nsterb\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Von \u00e4ltern Maalen, als sie aus Erzte giesst", "tokens": ["Von", "\u00e4l\u00b7tern", "Maa\u00b7len", ",", "als", "sie", "aus", "Erz\u00b7te", "giesst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der K\u00fcnstler, lagen, wie durch Zauber-", "tokens": ["Der", "K\u00fcnst\u00b7ler", ",", "la\u00b7gen", ",", "wie", "durch", "Zau\u00b7ber"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "$,", "PWAV", "APPR", "TRUNC"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kelche berauschet, die Dichter Deutschlands.", "tokens": ["Kel\u00b7che", "be\u00b7rau\u00b7schet", ",", "die", "Dich\u00b7ter", "Deutschlands", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "ART", "NN", "NE", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "Wie m\u00e4chtig rufst du, redend im fremden Laut", "tokens": ["Wie", "m\u00e4ch\u00b7tig", "rufst", "du", ",", "re\u00b7dend", "im", "frem\u00b7den", "Laut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "$,", "ADJD", "APPRART", "ADJA", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Selbst hier mit Deutschen, sie aus dem Wonnetraum!", "tokens": ["Selbst", "hier", "mit", "Deut\u00b7schen", ",", "sie", "aus", "dem", "Won\u00b7ne\u00b7traum", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "$,", "PPER", "APPR", "ART", "NN", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Unsterblichkeit? die nicht; du leugnest", "tokens": ["U\u00b7nsterb\u00b7lich\u00b7keit", "?", "die", "nicht", ";", "du", "leug\u00b7nest"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$.", "ART", "PTKNEG", "$.", "PPER", "VVFIN"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Selber das Daseyn von ihren Werken.", "tokens": ["Sel\u00b7ber", "das", "Da\u00b7seyn", "von", "ih\u00b7ren", "Wer\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Bis hin zur Temse, bis zu dem Rhodan hin", "tokens": ["Bis", "hin", "zur", "Tem\u00b7se", ",", "bis", "zu", "dem", "Rho\u00b7dan", "hin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPRART", "NN", "$,", "KOUS", "APPR", "ART", "NN", "PTKVZ"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Erschallt's, und Schaaren trinken, im dichten Drang,", "tokens": ["Er\u00b7schallt's", ",", "und", "Schaa\u00b7ren", "trin\u00b7ken", ",", "im", "dich\u00b7ten", "Drang", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KON", "NN", "VVINF", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mit Horcherohr, zu neuer Einsicht,", "tokens": ["Mit", "Hor\u00b7che\u00b7rohr", ",", "zu", "neu\u00b7er", "Ein\u00b7sicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "All die Belehrung, wovon du triefest.", "tokens": ["All", "die", "Be\u00b7leh\u00b7rung", ",", "wo\u00b7von", "du", "trie\u00b7fest", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.4": {"line.1": {"text": "Durch seines hohen Spruches Entscheidungen", "tokens": ["Durch", "sei\u00b7nes", "ho\u00b7hen", "Spru\u00b7ches", "Ent\u00b7schei\u00b7dun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Geweckt, entzaubert, leugnen die Dichter nicht", "tokens": ["Ge\u00b7weckt", ",", "ent\u00b7zau\u00b7bert", ",", "leug\u00b7nen", "die", "Dich\u00b7ter", "nicht"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "VVPP", "$,", "VVFIN", "ART", "NN", "PTKNEG"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dess Maales Ewigkeit, das er sich", "tokens": ["Dess", "Maa\u00b7les", "E\u00b7wig\u00b7keit", ",", "das", "er", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "PPER", "PRF"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zu dem verdientesten Rahm gesetzt hat,", "tokens": ["Zu", "dem", "ver\u00b7dien\u00b7tes\u00b7ten", "Rahm", "ge\u00b7setzt", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Als Endurteiler! Bleibender wird es stehn,", "tokens": ["Als", "E\u00b7ndur\u00b7tei\u00b7ler", "!", "Blei\u00b7ben\u00b7der", "wird", "es", "stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$.", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Denn Memphis Gr\u00e4ber, St\u00fcrmen zerst\u00f6rbar nicht!", "tokens": ["Denn", "Mem\u00b7phis", "Gr\u00e4\u00b7ber", ",", "St\u00fcr\u00b7men", "zer\u00b7st\u00f6r\u00b7bar", "nicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "$,", "NN", "ADJD", "PTKNEG", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wird mit der Zeiten Flucht nicht schwinden,", "tokens": ["Wird", "mit", "der", "Zei\u00b7ten", "Flucht", "nicht", "schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Noch der Verg\u00e4nglichkeit Strom'! erhalten,", "tokens": ["Noch", "der", "Ver\u00b7g\u00e4ng\u00b7lich\u00b7keit", "Strom'", "!", "er\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "NN", "NE", "$.", "VVPP", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.6": {"line.1": {"text": "(t\u00f6n' andres Tones, Saite!) zur Schau gestellt", "tokens": ["(", "t\u00f6n'", "and\u00b7res", "To\u00b7nes", ",", "Sai\u00b7te", "!", ")", "zur", "Schau", "ge\u00b7stellt"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "ADJA", "NN", "$,", "NN", "$.", "$(", "APPRART", "NN", "VVPP"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durch Werke, deren Daseyn er leugnete.", "tokens": ["Durch", "Wer\u00b7ke", ",", "de\u00b7ren", "Da\u00b7seyn", "er", "leug\u00b7ne\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Denn T\u00e4uschung war's nicht! denn die weisse", "tokens": ["Denn", "T\u00e4u\u00b7schung", "wa\u00b7r's", "nicht", "!", "denn", "die", "weis\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "PTKNEG", "$.", "KON", "ART", "ADJA"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Pforte durchschwebte der Dichter Traum nicht!", "tokens": ["Pfor\u00b7te", "durch\u00b7schweb\u00b7te", "der", "Dich\u00b7ter", "Traum", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "NN", "PTKNEG", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.7": {"line.1": {"text": "Im frohen, goldnen Traum von Unsterblichkeit,", "tokens": ["Im", "fro\u00b7hen", ",", "gold\u00b7nen", "Traum", "von", "U\u00b7nsterb\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Von \u00e4ltern Maalen, als sie aus Erzte giesst", "tokens": ["Von", "\u00e4l\u00b7tern", "Maa\u00b7len", ",", "als", "sie", "aus", "Erz\u00b7te", "giesst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der K\u00fcnstler, lagen, wie durch Zauber-", "tokens": ["Der", "K\u00fcnst\u00b7ler", ",", "la\u00b7gen", ",", "wie", "durch", "Zau\u00b7ber"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "$,", "PWAV", "APPR", "TRUNC"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kelche berauschet, die Dichter Deutschlands.", "tokens": ["Kel\u00b7che", "be\u00b7rau\u00b7schet", ",", "die", "Dich\u00b7ter", "Deutschlands", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "ART", "NN", "NE", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "Wie m\u00e4chtig rufst du, redend im fremden Laut", "tokens": ["Wie", "m\u00e4ch\u00b7tig", "rufst", "du", ",", "re\u00b7dend", "im", "frem\u00b7den", "Laut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "$,", "ADJD", "APPRART", "ADJA", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Selbst hier mit Deutschen, sie aus dem Wonnetraum!", "tokens": ["Selbst", "hier", "mit", "Deut\u00b7schen", ",", "sie", "aus", "dem", "Won\u00b7ne\u00b7traum", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "$,", "PPER", "APPR", "ART", "NN", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Unsterblichkeit? die nicht; du leugnest", "tokens": ["U\u00b7nsterb\u00b7lich\u00b7keit", "?", "die", "nicht", ";", "du", "leug\u00b7nest"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$.", "ART", "PTKNEG", "$.", "PPER", "VVFIN"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Selber das Daseyn von ihren Werken.", "tokens": ["Sel\u00b7ber", "das", "Da\u00b7seyn", "von", "ih\u00b7ren", "Wer\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Bis hin zur Temse, bis zu dem Rhodan hin", "tokens": ["Bis", "hin", "zur", "Tem\u00b7se", ",", "bis", "zu", "dem", "Rho\u00b7dan", "hin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPRART", "NN", "$,", "KOUS", "APPR", "ART", "NN", "PTKVZ"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Erschallt's, und Schaaren trinken, im dichten Drang,", "tokens": ["Er\u00b7schallt's", ",", "und", "Schaa\u00b7ren", "trin\u00b7ken", ",", "im", "dich\u00b7ten", "Drang", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KON", "NN", "VVINF", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mit Horcherohr, zu neuer Einsicht,", "tokens": ["Mit", "Hor\u00b7che\u00b7rohr", ",", "zu", "neu\u00b7er", "Ein\u00b7sicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "All die Belehrung, wovon du triefest.", "tokens": ["All", "die", "Be\u00b7leh\u00b7rung", ",", "wo\u00b7von", "du", "trie\u00b7fest", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.10": {"line.1": {"text": "Durch seines hohen Spruches Entscheidungen", "tokens": ["Durch", "sei\u00b7nes", "ho\u00b7hen", "Spru\u00b7ches", "Ent\u00b7schei\u00b7dun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Geweckt, entzaubert, leugnen die Dichter nicht", "tokens": ["Ge\u00b7weckt", ",", "ent\u00b7zau\u00b7bert", ",", "leug\u00b7nen", "die", "Dich\u00b7ter", "nicht"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "VVPP", "$,", "VVFIN", "ART", "NN", "PTKNEG"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dess Maales Ewigkeit, das er sich", "tokens": ["Dess", "Maa\u00b7les", "E\u00b7wig\u00b7keit", ",", "das", "er", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "PPER", "PRF"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zu dem verdientesten Rahm gesetzt hat,", "tokens": ["Zu", "dem", "ver\u00b7dien\u00b7tes\u00b7ten", "Rahm", "ge\u00b7setzt", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Als Endurteiler! Bleibender wird es stehn,", "tokens": ["Als", "E\u00b7ndur\u00b7tei\u00b7ler", "!", "Blei\u00b7ben\u00b7der", "wird", "es", "stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$.", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Denn Memphis Gr\u00e4ber, St\u00fcrmen zerst\u00f6rbar nicht!", "tokens": ["Denn", "Mem\u00b7phis", "Gr\u00e4\u00b7ber", ",", "St\u00fcr\u00b7men", "zer\u00b7st\u00f6r\u00b7bar", "nicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "$,", "NN", "ADJD", "PTKNEG", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wird mit der Zeiten Flucht nicht schwinden,", "tokens": ["Wird", "mit", "der", "Zei\u00b7ten", "Flucht", "nicht", "schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Noch der Verg\u00e4nglichkeit Strom'! erhalten,", "tokens": ["Noch", "der", "Ver\u00b7g\u00e4ng\u00b7lich\u00b7keit", "Strom'", "!", "er\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "NN", "NE", "$.", "VVPP", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.12": {"line.1": {"text": "(t\u00f6n' andres Tones, Saite!) zur Schau gestellt", "tokens": ["(", "t\u00f6n'", "and\u00b7res", "To\u00b7nes", ",", "Sai\u00b7te", "!", ")", "zur", "Schau", "ge\u00b7stellt"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "ADJA", "NN", "$,", "NN", "$.", "$(", "APPRART", "NN", "VVPP"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durch Werke, deren Daseyn er leugnete.", "tokens": ["Durch", "Wer\u00b7ke", ",", "de\u00b7ren", "Da\u00b7seyn", "er", "leug\u00b7ne\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Denn T\u00e4uschung war's nicht! denn die weisse", "tokens": ["Denn", "T\u00e4u\u00b7schung", "wa\u00b7r's", "nicht", "!", "denn", "die", "weis\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "PTKNEG", "$.", "KON", "ART", "ADJA"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Pforte durchschwebte der Dichter Traum nicht!", "tokens": ["Pfor\u00b7te", "durch\u00b7schweb\u00b7te", "der", "Dich\u00b7ter", "Traum", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "NN", "PTKNEG", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}}}}