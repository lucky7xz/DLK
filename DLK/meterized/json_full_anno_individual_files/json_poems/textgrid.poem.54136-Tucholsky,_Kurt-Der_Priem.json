{"textgrid.poem.54136": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Der Priem", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es haben die Matrosen", "tokens": ["Es", "ha\u00b7ben", "die", "Mat\u00b7ro\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "wohl auf dem blauen Meer", "tokens": ["wohl", "auf", "dem", "blau\u00b7en", "Meer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "nicht nur die weiten Hosen \u2013", "tokens": ["nicht", "nur", "die", "wei\u00b7ten", "Ho\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "sie haben noch viel mehr.", "tokens": ["sie", "ha\u00b7ben", "noch", "viel", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn gibt es nichts zu rauchen,", "tokens": ["Denn", "gibt", "es", "nichts", "zu", "rau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "wei\u00dft du, was sie da brauchen", "tokens": ["wei\u00dft", "du", ",", "was", "sie", "da", "brau\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "bei Nacht und auch bei Tag?", "tokens": ["bei", "Nacht", "und", "auch", "bei", "Tag", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Den Kautabak \u2013 den Kautabak \u2013", "tokens": ["Den", "Kau\u00b7ta\u00b7bak", "\u2013", "den", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ein kleines St\u00fcckchen Kautabak", "tokens": ["ein", "klei\u00b7nes", "St\u00fcck\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel.", "tokens": ["aus", "Kiel", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.2": {"line.1": {"text": "Es heulen die Sirenen.", "tokens": ["Es", "heu\u00b7len", "die", "Si\u00b7re\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Braut in Tr\u00e4nen schwimmt.", "tokens": ["Die", "Braut", "in", "Tr\u00e4\u00b7nen", "schwimmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es schwimmt die Braut in Tr\u00e4nen,", "tokens": ["Es", "schwimmt", "die", "Braut", "in", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "wenn der Seemann Abschied nimmt.", "tokens": ["wenn", "der", "See\u00b7mann", "Ab\u00b7schied", "nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sie dr\u00fccken sich die H\u00e4nde;", "tokens": ["Sie", "dr\u00fc\u00b7cken", "sich", "die", "H\u00e4n\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "dann gibt sie ihm am Ende", "tokens": ["dann", "gibt", "sie", "ihm", "am", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "versch\u00e4mt ein kleines Pack", "tokens": ["ver\u00b7sch\u00e4mt", "ein", "klei\u00b7nes", "Pack"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "mit Kautabak \u2013 mit Kautabak \u2013", "tokens": ["mit", "Kau\u00b7ta\u00b7bak", "\u2013", "mit", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "mit nem halben Pf\u00fcndchen Kautabak", "tokens": ["mit", "nem", "hal\u00b7ben", "Pf\u00fcnd\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel.", "tokens": ["aus", "Kiel", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.3": {"line.1": {"text": "Da hinten liegt sein Kutter,", "tokens": ["Da", "hin\u00b7ten", "liegt", "sein", "Kut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "da hinten liegt sein Kahn.", "tokens": ["da", "hin\u00b7ten", "liegt", "sein", "Kahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie sagt, sie f\u00fchlt sich Mutter,", "tokens": ["Sie", "sagt", ",", "sie", "f\u00fchlt", "sich", "Mut\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PRF", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "er sieht sie bl\u00f6de an.", "tokens": ["er", "sieht", "sie", "bl\u00f6\u00b7de", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Er l\u00e4\u00dft sich von ihr kosen,", "tokens": ["Er", "l\u00e4\u00dft", "sich", "von", "ihr", "ko\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "die H\u00e4nde in den Hosen,", "tokens": ["die", "H\u00e4n\u00b7de", "in", "den", "Ho\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "dann nimmt er einen Schlag", "tokens": ["dann", "nimmt", "er", "ei\u00b7nen", "Schlag"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "vom Kautabak \u2013 vom Kautabak \u2013", "tokens": ["vom", "Kau\u00b7ta\u00b7bak", "\u2013", "vom", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ein kleines St\u00fcckchen Kautabak", "tokens": ["ein", "klei\u00b7nes", "St\u00fcck\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel.", "tokens": ["aus", "Kiel", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.4": {"line.1": {"text": "Das Schiff f\u00e4hrt in den Hafen", "tokens": ["Das", "Schiff", "f\u00e4hrt", "in", "den", "Ha\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "wohl in Batavia.", "tokens": ["wohl", "in", "Ba\u00b7ta\u00b7via", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Mit den M\u00e4dchen mu\u00df man schlafen,", "tokens": ["Mit", "den", "M\u00e4d\u00b7chen", "mu\u00df", "man", "schla\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wozu sind sie sonst da!", "tokens": ["wo\u00b7zu", "sind", "sie", "sonst", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die er geliebkost hatte,", "tokens": ["Die", "er", "ge\u00b7lieb\u00b7kost", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "liegt nackt auf einer Matte;", "tokens": ["liegt", "nackt", "auf", "ei\u00b7ner", "Mat\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "er holt aus seinem Pack", "tokens": ["er", "holt", "aus", "sei\u00b7nem", "Pack"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "den Kautabak \u2013 den Kautabak \u2013", "tokens": ["den", "Kau\u00b7ta\u00b7bak", "\u2013", "den", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ein kleines St\u00fcckchen Kautabak", "tokens": ["ein", "klei\u00b7nes", "St\u00fcck\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel.", "tokens": ["aus", "Kiel", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.5": {"line.1": {"text": "Das Schiff t\u00e4t nicht versaufen,", "tokens": ["Das", "Schiff", "t\u00e4t", "nicht", "ver\u00b7sau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "in Hamburg legt es an.", "tokens": ["in", "Ham\u00b7burg", "legt", "es", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Marie mu\u00dft sich verkaufen", "tokens": ["Ma\u00b7rie", "mu\u00dft", "sich", "ver\u00b7kau\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PRF", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "nachts auf der Reeperbahn.", "tokens": ["nachts", "auf", "der", "Ree\u00b7per\u00b7bahn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nun sp\u00fcrt der arme Junge", "tokens": ["Nun", "sp\u00fcrt", "der", "ar\u00b7me", "Jun\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "grad unter seiner Zunge", "tokens": ["grad", "un\u00b7ter", "sei\u00b7ner", "Zun\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "den bitteren Geschmack", "tokens": ["den", "bit\u00b7te\u00b7ren", "Ge\u00b7schmack"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "vom Kautabak \u2013 vom Kautabak \u2013", "tokens": ["vom", "Kau\u00b7ta\u00b7bak", "\u2013", "vom", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "vom kleinen St\u00fcckchen Kautabak", "tokens": ["vom", "klei\u00b7nen", "St\u00fcck\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel.", "tokens": ["aus", "Kiel", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.6": {"line.1": {"text": "Wie dem Seemann mit den Frauen,", "tokens": ["Wie", "dem", "See\u00b7mann", "mit", "den", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "uns gehts genau wie ihm.", "tokens": ["uns", "gehts", "ge\u00b7nau", "wie", "ihm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Leben mu\u00df man kauen,", "tokens": ["Das", "Le\u00b7ben", "mu\u00df", "man", "kau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "das Dasein ist ein Priem.", "tokens": ["das", "Da\u00b7sein", "ist", "ein", "Priem", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Es schmeckt dem Knecht und Ritter", "tokens": ["Es", "schmeckt", "dem", "Knecht", "und", "Rit\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "mal s\u00fc\u00df und auch mal bitter . . .", "tokens": ["mal", "s\u00fc\u00df", "und", "auch", "mal", "bit\u00b7ter", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADV", "ADJD", "$.", "$.", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Spuck ihn aus, wer ihn nicht mag!", "tokens": ["Spuck", "ihn", "aus", ",", "wer", "ihn", "nicht", "mag", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "$,", "PWS", "PPER", "PTKNEG", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Den Kautabak \u2013 den Kautabak \u2013", "tokens": ["Den", "Kau\u00b7ta\u00b7bak", "\u2013", "den", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "das kleine St\u00fcckchen Kautabak", "tokens": ["das", "klei\u00b7ne", "St\u00fcck\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel!", "tokens": ["aus", "Kiel", "!"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.7": {"line.1": {"text": "Es haben die Matrosen", "tokens": ["Es", "ha\u00b7ben", "die", "Mat\u00b7ro\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "wohl auf dem blauen Meer", "tokens": ["wohl", "auf", "dem", "blau\u00b7en", "Meer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "nicht nur die weiten Hosen \u2013", "tokens": ["nicht", "nur", "die", "wei\u00b7ten", "Ho\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "sie haben noch viel mehr.", "tokens": ["sie", "ha\u00b7ben", "noch", "viel", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn gibt es nichts zu rauchen,", "tokens": ["Denn", "gibt", "es", "nichts", "zu", "rau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "wei\u00dft du, was sie da brauchen", "tokens": ["wei\u00dft", "du", ",", "was", "sie", "da", "brau\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "bei Nacht und auch bei Tag?", "tokens": ["bei", "Nacht", "und", "auch", "bei", "Tag", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Den Kautabak \u2013 den Kautabak \u2013", "tokens": ["Den", "Kau\u00b7ta\u00b7bak", "\u2013", "den", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ein kleines St\u00fcckchen Kautabak", "tokens": ["ein", "klei\u00b7nes", "St\u00fcck\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel.", "tokens": ["aus", "Kiel", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.8": {"line.1": {"text": "Es heulen die Sirenen.", "tokens": ["Es", "heu\u00b7len", "die", "Si\u00b7re\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Braut in Tr\u00e4nen schwimmt.", "tokens": ["Die", "Braut", "in", "Tr\u00e4\u00b7nen", "schwimmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es schwimmt die Braut in Tr\u00e4nen,", "tokens": ["Es", "schwimmt", "die", "Braut", "in", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "wenn der Seemann Abschied nimmt.", "tokens": ["wenn", "der", "See\u00b7mann", "Ab\u00b7schied", "nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sie dr\u00fccken sich die H\u00e4nde;", "tokens": ["Sie", "dr\u00fc\u00b7cken", "sich", "die", "H\u00e4n\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "dann gibt sie ihm am Ende", "tokens": ["dann", "gibt", "sie", "ihm", "am", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "versch\u00e4mt ein kleines Pack", "tokens": ["ver\u00b7sch\u00e4mt", "ein", "klei\u00b7nes", "Pack"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "mit Kautabak \u2013 mit Kautabak \u2013", "tokens": ["mit", "Kau\u00b7ta\u00b7bak", "\u2013", "mit", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "mit nem halben Pf\u00fcndchen Kautabak", "tokens": ["mit", "nem", "hal\u00b7ben", "Pf\u00fcnd\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel.", "tokens": ["aus", "Kiel", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.9": {"line.1": {"text": "Da hinten liegt sein Kutter,", "tokens": ["Da", "hin\u00b7ten", "liegt", "sein", "Kut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "da hinten liegt sein Kahn.", "tokens": ["da", "hin\u00b7ten", "liegt", "sein", "Kahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie sagt, sie f\u00fchlt sich Mutter,", "tokens": ["Sie", "sagt", ",", "sie", "f\u00fchlt", "sich", "Mut\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PRF", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "er sieht sie bl\u00f6de an.", "tokens": ["er", "sieht", "sie", "bl\u00f6\u00b7de", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Er l\u00e4\u00dft sich von ihr kosen,", "tokens": ["Er", "l\u00e4\u00dft", "sich", "von", "ihr", "ko\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "die H\u00e4nde in den Hosen,", "tokens": ["die", "H\u00e4n\u00b7de", "in", "den", "Ho\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "dann nimmt er einen Schlag", "tokens": ["dann", "nimmt", "er", "ei\u00b7nen", "Schlag"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "vom Kautabak \u2013 vom Kautabak \u2013", "tokens": ["vom", "Kau\u00b7ta\u00b7bak", "\u2013", "vom", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ein kleines St\u00fcckchen Kautabak", "tokens": ["ein", "klei\u00b7nes", "St\u00fcck\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel.", "tokens": ["aus", "Kiel", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.10": {"line.1": {"text": "Das Schiff f\u00e4hrt in den Hafen", "tokens": ["Das", "Schiff", "f\u00e4hrt", "in", "den", "Ha\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "wohl in Batavia.", "tokens": ["wohl", "in", "Ba\u00b7ta\u00b7via", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Mit den M\u00e4dchen mu\u00df man schlafen,", "tokens": ["Mit", "den", "M\u00e4d\u00b7chen", "mu\u00df", "man", "schla\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wozu sind sie sonst da!", "tokens": ["wo\u00b7zu", "sind", "sie", "sonst", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die er geliebkost hatte,", "tokens": ["Die", "er", "ge\u00b7lieb\u00b7kost", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "liegt nackt auf einer Matte;", "tokens": ["liegt", "nackt", "auf", "ei\u00b7ner", "Mat\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "er holt aus seinem Pack", "tokens": ["er", "holt", "aus", "sei\u00b7nem", "Pack"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "den Kautabak \u2013 den Kautabak \u2013", "tokens": ["den", "Kau\u00b7ta\u00b7bak", "\u2013", "den", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ein kleines St\u00fcckchen Kautabak", "tokens": ["ein", "klei\u00b7nes", "St\u00fcck\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel.", "tokens": ["aus", "Kiel", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.11": {"line.1": {"text": "Das Schiff t\u00e4t nicht versaufen,", "tokens": ["Das", "Schiff", "t\u00e4t", "nicht", "ver\u00b7sau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "in Hamburg legt es an.", "tokens": ["in", "Ham\u00b7burg", "legt", "es", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Marie mu\u00dft sich verkaufen", "tokens": ["Ma\u00b7rie", "mu\u00dft", "sich", "ver\u00b7kau\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PRF", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "nachts auf der Reeperbahn.", "tokens": ["nachts", "auf", "der", "Ree\u00b7per\u00b7bahn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nun sp\u00fcrt der arme Junge", "tokens": ["Nun", "sp\u00fcrt", "der", "ar\u00b7me", "Jun\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "grad unter seiner Zunge", "tokens": ["grad", "un\u00b7ter", "sei\u00b7ner", "Zun\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "den bitteren Geschmack", "tokens": ["den", "bit\u00b7te\u00b7ren", "Ge\u00b7schmack"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "vom Kautabak \u2013 vom Kautabak \u2013", "tokens": ["vom", "Kau\u00b7ta\u00b7bak", "\u2013", "vom", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "vom kleinen St\u00fcckchen Kautabak", "tokens": ["vom", "klei\u00b7nen", "St\u00fcck\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel.", "tokens": ["aus", "Kiel", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.12": {"line.1": {"text": "Wie dem Seemann mit den Frauen,", "tokens": ["Wie", "dem", "See\u00b7mann", "mit", "den", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "uns gehts genau wie ihm.", "tokens": ["uns", "gehts", "ge\u00b7nau", "wie", "ihm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Leben mu\u00df man kauen,", "tokens": ["Das", "Le\u00b7ben", "mu\u00df", "man", "kau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "das Dasein ist ein Priem.", "tokens": ["das", "Da\u00b7sein", "ist", "ein", "Priem", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Es schmeckt dem Knecht und Ritter", "tokens": ["Es", "schmeckt", "dem", "Knecht", "und", "Rit\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "mal s\u00fc\u00df und auch mal bitter . . .", "tokens": ["mal", "s\u00fc\u00df", "und", "auch", "mal", "bit\u00b7ter", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADV", "ADJD", "$.", "$.", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Spuck ihn aus, wer ihn nicht mag!", "tokens": ["Spuck", "ihn", "aus", ",", "wer", "ihn", "nicht", "mag", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "$,", "PWS", "PPER", "PTKNEG", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Den Kautabak \u2013 den Kautabak \u2013", "tokens": ["Den", "Kau\u00b7ta\u00b7bak", "\u2013", "den", "Kau\u00b7ta\u00b7bak", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "das kleine St\u00fcckchen Kautabak", "tokens": ["das", "klei\u00b7ne", "St\u00fcck\u00b7chen", "Kau\u00b7ta\u00b7bak"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "von der Firma Eckenbrecht", "tokens": ["von", "der", "Fir\u00b7ma", "E\u00b7cken\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "aus Kiel!", "tokens": ["aus", "Kiel", "!"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}}}}