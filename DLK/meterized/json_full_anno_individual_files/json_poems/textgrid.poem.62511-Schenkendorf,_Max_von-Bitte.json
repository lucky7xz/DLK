{"textgrid.poem.62511": {"metadata": {"author": {"name": "Schenkendorf, Max von", "birth": "N.A.", "death": "N.A."}, "title": "Bitte", "genre": "verse", "period": "N.A.", "pub_year": 1800, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun bitten wir den heiligen Geist", "tokens": ["Nun", "bit\u00b7ten", "wir", "den", "hei\u00b7li\u00b7gen", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Um die rechte Weisheit allermeist,", "tokens": ["Um", "die", "rech\u00b7te", "Weis\u00b7heit", "al\u00b7ler\u00b7meist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df wir unterscheiden und hell erkennen,", "tokens": ["Da\u00df", "wir", "un\u00b7ter\u00b7schei\u00b7den", "und", "hell", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "KON", "ADJD", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Wie sich nun Gutes vom B\u00f6sen mu\u00df trennen.", "tokens": ["Wie", "sich", "nun", "Gu\u00b7tes", "vom", "B\u00f6\u00b7sen", "mu\u00df", "tren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ADV", "NN", "APPRART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Kyrie Eleison!", "tokens": ["Ky\u00b7rie", "E\u00b7lei\u00b7son", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Dann bitten wir den heiligen Geist", "tokens": ["Dann", "bit\u00b7ten", "wir", "den", "hei\u00b7li\u00b7gen", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Um die rechte Feindschaft allermeist.", "tokens": ["Um", "die", "rech\u00b7te", "Feind\u00b7schaft", "al\u00b7ler\u00b7meist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df wir von dem Teufel und seinem Wesen", "tokens": ["Da\u00df", "wir", "von", "dem", "Teu\u00b7fel", "und", "sei\u00b7nem", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nach tapferm Ringen f\u00fcr ewig genesen.", "tokens": ["Nach", "tap\u00b7ferm", "Rin\u00b7gen", "f\u00fcr", "e\u00b7wig", "ge\u00b7ne\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJD", "VVPP", "$."], "meter": "+--+--+-+--", "measure": "dactylic.di.plus"}, "line.5": {"text": "Kyrie Eleison!", "tokens": ["Ky\u00b7rie", "E\u00b7lei\u00b7son", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Dann bitten wir dich, heilige Brunst,", "tokens": ["Dann", "bit\u00b7ten", "wir", "dich", ",", "hei\u00b7li\u00b7ge", "Brunst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Um der s\u00fc\u00dfen Liebe rechte Kunst,", "tokens": ["Um", "der", "s\u00fc\u00b7\u00dfen", "Lie\u00b7be", "rech\u00b7te", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df wir in Eintracht und Einfalt beharren,", "tokens": ["Da\u00df", "wir", "in", "Ein\u00b7tracht", "und", "Ein\u00b7falt", "be\u00b7har\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Alle nach Einem nur trachten und harren.", "tokens": ["Al\u00b7le", "nach", "Ei\u00b7nem", "nur", "trach\u00b7ten", "und", "har\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PIS", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.5": {"text": "Kyrie Eleison!", "tokens": ["Ky\u00b7rie", "E\u00b7lei\u00b7son", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Dann bitten wir um Glauben zun\u00e4chst,", "tokens": ["Dann", "bit\u00b7ten", "wir", "um", "Glau\u00b7ben", "zu\u00b7n\u00e4chst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Der gen Himmel aus dem Herzen w\u00e4chst,", "tokens": ["Der", "gen", "Him\u00b7mel", "aus", "dem", "Her\u00b7zen", "w\u00e4chst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df wir in K\u00e4mpfen und harten N\u00f6then", "tokens": ["Da\u00df", "wir", "in", "K\u00e4mp\u00b7fen", "und", "har\u00b7ten", "N\u00f6\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Fr\u00f6hlich uns weisen und kr\u00e4ftiglich beten.", "tokens": ["Fr\u00f6h\u00b7lich", "uns", "wei\u00b7sen", "und", "kr\u00e4f\u00b7tig\u00b7lich", "be\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVINF", "KON", "ADJD", "VVINF", "$."], "meter": "+--+--+-+--", "measure": "dactylic.di.plus"}, "line.5": {"text": "Kyrie Eleison!", "tokens": ["Ky\u00b7rie", "E\u00b7lei\u00b7son", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Nun bitten wir den heiligen Geist", "tokens": ["Nun", "bit\u00b7ten", "wir", "den", "hei\u00b7li\u00b7gen", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Um die rechte Weisheit allermeist,", "tokens": ["Um", "die", "rech\u00b7te", "Weis\u00b7heit", "al\u00b7ler\u00b7meist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df wir unterscheiden und hell erkennen,", "tokens": ["Da\u00df", "wir", "un\u00b7ter\u00b7schei\u00b7den", "und", "hell", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "KON", "ADJD", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Wie sich nun Gutes vom B\u00f6sen mu\u00df trennen.", "tokens": ["Wie", "sich", "nun", "Gu\u00b7tes", "vom", "B\u00f6\u00b7sen", "mu\u00df", "tren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ADV", "NN", "APPRART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Kyrie Eleison!", "tokens": ["Ky\u00b7rie", "E\u00b7lei\u00b7son", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Dann bitten wir den heiligen Geist", "tokens": ["Dann", "bit\u00b7ten", "wir", "den", "hei\u00b7li\u00b7gen", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Um die rechte Feindschaft allermeist.", "tokens": ["Um", "die", "rech\u00b7te", "Feind\u00b7schaft", "al\u00b7ler\u00b7meist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df wir von dem Teufel und seinem Wesen", "tokens": ["Da\u00df", "wir", "von", "dem", "Teu\u00b7fel", "und", "sei\u00b7nem", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nach tapferm Ringen f\u00fcr ewig genesen.", "tokens": ["Nach", "tap\u00b7ferm", "Rin\u00b7gen", "f\u00fcr", "e\u00b7wig", "ge\u00b7ne\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJD", "VVPP", "$."], "meter": "+--+--+-+--", "measure": "dactylic.di.plus"}, "line.5": {"text": "Kyrie Eleison!", "tokens": ["Ky\u00b7rie", "E\u00b7lei\u00b7son", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Dann bitten wir dich, heilige Brunst,", "tokens": ["Dann", "bit\u00b7ten", "wir", "dich", ",", "hei\u00b7li\u00b7ge", "Brunst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Um der s\u00fc\u00dfen Liebe rechte Kunst,", "tokens": ["Um", "der", "s\u00fc\u00b7\u00dfen", "Lie\u00b7be", "rech\u00b7te", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df wir in Eintracht und Einfalt beharren,", "tokens": ["Da\u00df", "wir", "in", "Ein\u00b7tracht", "und", "Ein\u00b7falt", "be\u00b7har\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Alle nach Einem nur trachten und harren.", "tokens": ["Al\u00b7le", "nach", "Ei\u00b7nem", "nur", "trach\u00b7ten", "und", "har\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PIS", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.5": {"text": "Kyrie Eleison!", "tokens": ["Ky\u00b7rie", "E\u00b7lei\u00b7son", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Dann bitten wir um Glauben zun\u00e4chst,", "tokens": ["Dann", "bit\u00b7ten", "wir", "um", "Glau\u00b7ben", "zu\u00b7n\u00e4chst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Der gen Himmel aus dem Herzen w\u00e4chst,", "tokens": ["Der", "gen", "Him\u00b7mel", "aus", "dem", "Her\u00b7zen", "w\u00e4chst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df wir in K\u00e4mpfen und harten N\u00f6then", "tokens": ["Da\u00df", "wir", "in", "K\u00e4mp\u00b7fen", "und", "har\u00b7ten", "N\u00f6\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Fr\u00f6hlich uns weisen und kr\u00e4ftiglich beten.", "tokens": ["Fr\u00f6h\u00b7lich", "uns", "wei\u00b7sen", "und", "kr\u00e4f\u00b7tig\u00b7lich", "be\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVINF", "KON", "ADJD", "VVINF", "$."], "meter": "+--+--+-+--", "measure": "dactylic.di.plus"}, "line.5": {"text": "Kyrie Eleison!", "tokens": ["Ky\u00b7rie", "E\u00b7lei\u00b7son", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}