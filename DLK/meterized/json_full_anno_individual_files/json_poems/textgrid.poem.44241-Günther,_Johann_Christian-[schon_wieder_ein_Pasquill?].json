{"textgrid.poem.44241": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "[schon wieder ein Pasquill?]", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schon wieder ein Pasquill? so, deucht mich, werther Freund,", "tokens": ["Schon", "wie\u00b7der", "ein", "Pas\u00b7quill", "?", "so", ",", "deucht", "mich", ",", "wert\u00b7her", "Freund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$.", "ADV", "$,", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Schreit Misgunst und Crispin, da dies mein Blat erscheint,", "tokens": ["Schreit", "Mis\u00b7gunst", "und", "Cris\u00b7pin", ",", "da", "dies", "mein", "Blat", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NE", "$,", "KOUS", "PDS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Nachdem mein Scherz und Ernst, die beide Warheit lieben,", "tokens": ["Nach\u00b7dem", "mein", "Scherz", "und", "Ernst", ",", "die", "bei\u00b7de", "War\u00b7heit", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "NE", "$,", "PRELS", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Narren dann und wann die Ohren wund gerieben.", "tokens": ["Den", "Nar\u00b7ren", "dann", "und", "wann", "die", "Oh\u00b7ren", "wund", "ge\u00b7rie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "KON", "PWAV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was Rath? Was hier zu thun? Err\u00f6thet mein Gesicht?", "tokens": ["Was", "Rath", "?", "Was", "hier", "zu", "thun", "?", "Er\u00b7r\u00f6t\u00b7het", "mein", "Ge\u00b7sicht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "PWS", "ADV", "PTKZU", "VVINF", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Freude mach ich wohl den frechen Sp\u00f6ttern nicht.", "tokens": ["Die", "Freu\u00b7de", "mach", "ich", "wohl", "den", "fre\u00b7chen", "Sp\u00f6t\u00b7tern", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie? oder soll ich mir mit sechzig Klagezetteln", "tokens": ["Wie", "?", "o\u00b7der", "soll", "ich", "mir", "mit", "sech\u00b7zig", "Kla\u00b7ge\u00b7zet\u00b7teln"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "KON", "VMFIN", "PPER", "PRF", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Papiernen Wiederruf und faules Recht erbetteln?", "tokens": ["Pa\u00b7pier\u00b7nen", "Wie\u00b7der\u00b7ruf", "und", "fau\u00b7les", "Recht", "er\u00b7bet\u00b7teln", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es lohnt sich nicht der M\u00fch. Die Misgunst ist zu toll,", "tokens": ["Es", "lohnt", "sich", "nicht", "der", "M\u00fch", ".", "Die", "Mis\u00b7gunst", "ist", "zu", "toll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKNEG", "ART", "NN", "$.", "ART", "NN", "VAFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als da\u00df man ihren Hohn so theuer ahnden soll.", "tokens": ["Als", "da\u00df", "man", "ih\u00b7ren", "Hohn", "so", "theu\u00b7er", "ahn\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "PPOSAT", "NN", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Es w\u00e4r ihr um den Schwur, so m\u00fcst ich mich bequemen,", "tokens": ["Es", "w\u00e4r", "ihr", "um", "den", "Schwur", ",", "so", "m\u00fcst", "ich", "mich", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ART", "VVFIN", "$,", "ADV", "VMFIN", "PPER", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den wohlerdachten Schimpf vor Scherzen anzunehmen.", "tokens": ["Den", "woh\u00b7ler\u00b7dach\u00b7ten", "Schimpf", "vor", "Scher\u00b7zen", "an\u00b7zu\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wie aber r\u00e4ch ich mich? Mit Schweigen. Schlechter Tort.", "tokens": ["Wie", "a\u00b7ber", "r\u00e4ch", "ich", "mich", "?", "Mit", "Schwei\u00b7gen", ".", "Schlech\u00b7ter", "Tort", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "PRF", "$.", "APPR", "NN", "$.", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So red ihr christlich zu. Die Grobheit h\u00f6rt kein Wort.", "tokens": ["So", "red", "ihr", "christ\u00b7lich", "zu", ".", "Die", "Grob\u00b7heit", "h\u00f6rt", "kein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "ART", "NN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Je mehr man Bauren fleht, je mehr die Stiefeln schwellen.", "tokens": ["Je", "mehr", "man", "Bau\u00b7ren", "fleht", ",", "je", "mehr", "die", "Stie\u00b7feln", "schwel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "NN", "VVFIN", "$,", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So seze gleich auf gleich und greif ihr an die Schellen", "tokens": ["So", "se\u00b7ze", "gleich", "auf", "gleich", "und", "greif", "ihr", "an", "die", "Schel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ADV", "KON", "ADJD", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und rei\u00df ihr b\u00f6ses Herz mit Peitsch- und Striegeln auf.", "tokens": ["Und", "rei\u00df", "ihr", "b\u00f6\u00b7ses", "Herz", "mit", "Peit\u00b7sch", "und", "Strie\u00b7geln", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "TRUNC", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Du siehst ja in der Welt den umgekehrten Lauf,", "tokens": ["Du", "siehst", "ja", "in", "der", "Welt", "den", "um\u00b7ge\u00b7kehr\u00b7ten", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wer Fried und Ruh begehrt, der mu\u00df sich st\u00fcndlich schlagen", "tokens": ["Wer", "Fried", "und", "Ruh", "be\u00b7gehrt", ",", "der", "mu\u00df", "sich", "st\u00fcnd\u00b7lich", "schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "KON", "NN", "VVPP", "$,", "ART", "VMFIN", "PRF", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und mit der Tadelsucht viel schwere G\u00e4nge wagen.", "tokens": ["Und", "mit", "der", "Ta\u00b7del\u00b7sucht", "viel", "schwe\u00b7re", "G\u00e4n\u00b7ge", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Gar recht, mein Freund, gar recht. Ein jeder Mensch ein Thor.", "tokens": ["Gar", "recht", ",", "mein", "Freund", ",", "gar", "recht", ".", "Ein", "je\u00b7der", "Mensch", "ein", "Thor", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PPOSAT", "NN", "$,", "ADV", "ADJD", "$.", "ART", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Der gr\u00f6ste nennt sich klug und zieht sich andern vor,", "tokens": ["Der", "gr\u00f6s\u00b7te", "nennt", "sich", "klug", "und", "zieht", "sich", "an\u00b7dern", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "ADJD", "KON", "VVFIN", "PRF", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Verr\u00e4th den Hasenkopf so n\u00fcchtern als im Schmause", "tokens": ["Ver\u00b7r\u00e4\u00b7th", "den", "Ha\u00b7sen\u00b7kopf", "so", "n\u00fcch\u00b7tern", "als", "im", "Schmau\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "ADV", "ADJD", "KOKOM", "APPRART", "NN"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Und weist doch allemahl den Nechsten in die Clause.", "tokens": ["Und", "weist", "doch", "al\u00b7le\u00b7mahl", "den", "Nechs\u00b7ten", "in", "die", "Clau\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Da seht ihr, schreyt Vannin, die neue Stachelschrift,", "tokens": ["Da", "seht", "ihr", ",", "schreyt", "Van\u00b7nin", ",", "die", "neu\u00b7e", "Sta\u00b7chel\u00b7schrift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VVFIN", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Die, da sie andern gilt, ihn selbst zugleich mit trift.", "tokens": ["Die", ",", "da", "sie", "an\u00b7dern", "gilt", ",", "ihn", "selbst", "zu\u00b7gleich", "mit", "trift", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,", "PPER", "ADV", "ADV", "APPR", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Vannin, halt etwas ein und las dich be\u00dfer lehren,", "tokens": ["Van\u00b7nin", ",", "halt", "et\u00b7was", "ein", "und", "las", "dich", "be\u00b7\u00dfer", "leh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PIS", "PTKVZ", "KON", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ich strafe nicht mit Grimm, ... selbst [?] zu ehren.", "tokens": ["Ich", "stra\u00b7fe", "nicht", "mit", "Grimm", ",", "...", "selbst", "?", "zu", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "NE", "$,", "$(", "ADV", "$(", "$.", "$(", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Ich weis, ich bin ein Mensch und wohl so schwach als du,", "tokens": ["Ich", "weis", ",", "ich", "bin", "ein", "Mensch", "und", "wohl", "so", "schwach", "als", "du", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "PPER", "VAFIN", "ART", "NN", "KON", "ADV", "ADV", "ADJD", "KOKOM", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Dies, was ich haben will, das las ich andern zu,", "tokens": ["Dies", ",", "was", "ich", "ha\u00b7ben", "will", ",", "das", "las", "ich", "an\u00b7dern", "zu", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "VAINF", "VMFIN", "$,", "PDS", "VVFIN", "PPER", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Dies schenck ich allen gern; nur das verwirft mein Dichten,", "tokens": ["Dies", "schenck", "ich", "al\u00b7len", "gern", ";", "nur", "das", "ver\u00b7wirft", "mein", "Dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PIAT", "ADV", "$.", "ADV", "PDS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Da\u00df S\u00fcnder gleicher Art so grob und giftig richten.", "tokens": ["Da\u00df", "S\u00fcn\u00b7der", "glei\u00b7cher", "Art", "so", "grob", "und", "gif\u00b7tig", "rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJA", "NN", "ADV", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Warum vertr\u00e4gt man nicht einander mit Gedult?", "tokens": ["Wa\u00b7rum", "ver\u00b7tr\u00e4gt", "man", "nicht", "ein\u00b7an\u00b7der", "mit", "Ge\u00b7dult", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "PTKNEG", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Wir haben allerseits den [Fluch] von Adams Schuld.", "tokens": ["Wir", "ha\u00b7ben", "al\u00b7ler\u00b7seits", "den", "Fluch", "von", "A\u00b7dams", "Schuld", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "$(", "NN", "$(", "APPR", "NE", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.35": {"text": "Der fehlt auf diesen Zug und der auf jener Seite,", "tokens": ["Der", "fehlt", "auf", "die\u00b7sen", "Zug", "und", "der", "auf", "je\u00b7ner", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PDAT", "NN", "KON", "ART", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und beide sind dabey verf\u00fchrte Wandersleute.", "tokens": ["Und", "bei\u00b7de", "sind", "da\u00b7bey", "ver\u00b7f\u00fchr\u00b7te", "Wan\u00b7ders\u00b7leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PAV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Den treibt der Ehrsuchtswind, den macht die Sch\u00f6nheit kranck.", "tokens": ["Den", "treibt", "der", "Ehr\u00b7suchts\u00b7wind", ",", "den", "macht", "die", "Sch\u00f6n\u00b7heit", "kranck", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,", "ART", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Wie, wenn im Lazareth und auf der Ruderbanck", "tokens": ["Wie", ",", "wenn", "im", "La\u00b7za\u00b7reth", "und", "auf", "der", "Ru\u00b7der\u00b7banck"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KOUS", "APPRART", "NN", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Ein Sclav und Kr\u00fcpel noch den andern spotten wollte,", "tokens": ["Ein", "Sclav", "und", "Kr\u00fc\u00b7pel", "noch", "den", "an\u00b7dern", "spot\u00b7ten", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "ART", "ADJA", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Was meinstu, was der Narr vor Schmach verdienen sollte?", "tokens": ["Was", "meins\u00b7tu", ",", "was", "der", "Narr", "vor", "Schmach", "ver\u00b7die\u00b7nen", "soll\u00b7te", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PRELS", "ART", "NN", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Und lachstu? Lache nicht; das Gleichn\u00fc\u00df zielt auf dich.", "tokens": ["Und", "lachs\u00b7tu", "?", "La\u00b7che", "nicht", ";", "das", "Gleich\u00b7n\u00fc\u00df", "zielt", "auf", "dich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "NN", "PTKNEG", "$.", "ART", "NN", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Dein Balcken ragt hervor und gleichwohl k\u00fcmmert sich", "tokens": ["Dein", "Bal\u00b7cken", "ragt", "her\u00b7vor", "und", "gleich\u00b7wohl", "k\u00fcm\u00b7mert", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "KON", "ADV", "VVFIN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Dein unversch\u00e4mter Mund um jedes Nechsten Splitter", "tokens": ["Dein", "un\u00b7ver\u00b7sch\u00e4m\u00b7ter", "Mund", "um", "je\u00b7des", "Nechs\u00b7ten", "Split\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Und macht, so bald er f\u00e4llt, ein donnernd Ungewitter.", "tokens": ["Und", "macht", ",", "so", "bald", "er", "f\u00e4llt", ",", "ein", "don\u00b7nernd", "Un\u00b7ge\u00b7wit\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "ADV", "PPER", "VVFIN", "$,", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Und wirf mir ja nicht vor, als schenckt ich dir allein", "tokens": ["Und", "wirf", "mir", "ja", "nicht", "vor", ",", "als", "schenckt", "ich", "dir", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "ADV", "PTKNEG", "PTKVZ", "$,", "KOUS", "VVFIN", "PPER", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Aus Wahn und Eigennuz dergleichen Wermuth ein.", "tokens": ["Aus", "Wahn", "und", "Ei\u00b7gen\u00b7nuz", "derg\u00b7lei\u00b7chen", "Wer\u00b7muth", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PIS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Geh, zieh, wohin du wilt, du wirst nebst gro\u00dfen S\u00fcnden", "tokens": ["Geh", ",", "zieh", ",", "wo\u00b7hin", "du", "wilt", ",", "du", "wirst", "nebst", "gro\u00b7\u00dfen", "S\u00fcn\u00b7den"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "VVFIN", "$,", "PWAV", "PPER", "VMFIN", "$,", "PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Noch manchen Heuchler sehn und viel Tartufen finden.", "tokens": ["Noch", "man\u00b7chen", "Heuch\u00b7ler", "sehn", "und", "viel", "Tar\u00b7tu\u00b7fen", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVINF", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Dort sizt das Murmelthier, der falsche Pietist,", "tokens": ["Dort", "sizt", "das", "Mur\u00b7melt\u00b7hier", ",", "der", "fal\u00b7sche", "Pie\u00b7tist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.50": {"text": "Der fast vor Heiligkeit die ganze Biebel fri\u00dft;", "tokens": ["Der", "fast", "vor", "Hei\u00b7lig\u00b7keit", "die", "gan\u00b7ze", "Bie\u00b7bel", "fri\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Schau, wie er sich allein gerecht zu seyn gedencket", "tokens": ["Schau", ",", "wie", "er", "sich", "al\u00b7lein", "ge\u00b7recht", "zu", "seyn", "ge\u00b7den\u00b7cket"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "PPER", "PRF", "ADV", "ADJD", "PTKZU", "VAINF", "VVFIN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.52": {"text": "Und jeden, der ihm steht, mit Fluch und Predigt kr\u00e4ncket.", "tokens": ["Und", "je\u00b7den", ",", "der", "ihm", "steht", ",", "mit", "Fluch", "und", "Pre\u00b7digt", "kr\u00e4n\u00b7cket", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Der Mucker ist so stolz und schleicht so fromm einher,", "tokens": ["Der", "Mu\u00b7cker", "ist", "so", "stolz", "und", "schleicht", "so", "fromm", "ein\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "KON", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Als wenn das Pflaster kaum des Engels w\u00fcrdig w\u00e4r.", "tokens": ["Als", "wenn", "das", "Pflas\u00b7ter", "kaum", "des", "En\u00b7gels", "w\u00fcr\u00b7dig", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "ADV", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Erlaubt ihm Gott einmahl die Rache seiner Flammen,", "tokens": ["Er\u00b7laubt", "ihm", "Gott", "ein\u00b7mahl", "die", "Ra\u00b7che", "sei\u00b7ner", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "So g\u00f6\u00df er wohl die Welt auf einen Klump zusammen.", "tokens": ["So", "g\u00f6\u00df", "er", "wohl", "die", "Welt", "auf", "ei\u00b7nen", "Klump", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Ein ungerathner Sohn des weisen Epicur", "tokens": ["Ein", "un\u00b7ge\u00b7rath\u00b7ner", "Sohn", "des", "wei\u00b7sen", "E\u00b7pi\u00b7cur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Glaubt das nur, was er w\u00fcntscht, beschweret die Natur,", "tokens": ["Glaubt", "das", "nur", ",", "was", "er", "w\u00fcnt\u00b7scht", ",", "be\u00b7schwe\u00b7ret", "die", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "$,", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.59": {"text": "H\u00e4lt Bauch und Gott vor eins und lacht der albern Christen,", "tokens": ["H\u00e4lt", "Bauch", "und", "Gott", "vor", "eins", "und", "lacht", "der", "al\u00b7bern", "Chris\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "APPR", "PIS", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Als die wie Kinder noch den Teufel f\u00fcrchten m\u00fcsten.", "tokens": ["Als", "die", "wie", "Kin\u00b7der", "noch", "den", "Teu\u00b7fel", "f\u00fcrch\u00b7ten", "m\u00fcs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "KOKOM", "NN", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Ein Schulfuchs, der den Kopf voll griechscher L\u00e4use tr\u00e4gt,", "tokens": ["Ein", "Schul\u00b7fuchs", ",", "der", "den", "Kopf", "voll", "griech\u00b7scher", "L\u00e4u\u00b7se", "tr\u00e4gt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "ADJD", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Fleisch, K\u00e4se, Kiel und Buch in eine Schachtel legt,", "tokens": ["Fleisch", ",", "K\u00e4\u00b7se", ",", "Kiel", "und", "Buch", "in", "ei\u00b7ne", "Schach\u00b7tel", "legt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NE", "KON", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Nach Alterth\u00fcmern stinckt, die Kinder r\u00f6misch nennet", "tokens": ["Nach", "Al\u00b7tert\u00b7h\u00fc\u00b7mern", "stinckt", ",", "die", "Kin\u00b7der", "r\u00f6\u00b7misch", "nen\u00b7net"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "$,", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Und, glaub ich, gar die Frau nach j\u00fcdscher Art erkennet,", "tokens": ["Und", ",", "glaub", "ich", ",", "gar", "die", "Frau", "nach", "j\u00fcd\u00b7scher", "Art", "er\u00b7ken\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "$,", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Schilt jeglichen vor tumm, der nicht so gleich beweist,", "tokens": ["Schilt", "jeg\u00b7li\u00b7chen", "vor", "tumm", ",", "der", "nicht", "so", "gleich", "be\u00b7weist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "APPR", "ADJD", "$,", "PRELS", "PTKNEG", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.67": {"text": "Und meint, wer nicht mit ihm die Eselsbr\u00fccke steiget,", "tokens": ["Und", "meint", ",", "wer", "nicht", "mit", "ihm", "die", "E\u00b7sels\u00b7br\u00fc\u00b7cke", "stei\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "PTKNEG", "APPR", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Den habe Titans Faust aus grobem Leim erzeuget.", "tokens": ["Den", "ha\u00b7be", "Ti\u00b7tans", "Faust", "aus", "gro\u00b7bem", "Leim", "er\u00b7zeu\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NE", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Ein netter Jungfernknecht, der rare B\u00e4nder kauft,", "tokens": ["Ein", "net\u00b7ter", "Jung\u00b7fern\u00b7knecht", ",", "der", "ra\u00b7re", "B\u00e4n\u00b7der", "kauft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Mit Latten und Confect in Ball und Opern lauft,", "tokens": ["Mit", "Lat\u00b7ten", "und", "Con\u00b7fect", "in", "Ball", "und", "O\u00b7pern", "lauft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Die Luft mit Puder f\u00fcllt, das Schuhwachs bey sich tr\u00e4get", "tokens": ["Die", "Luft", "mit", "Pu\u00b7der", "f\u00fcllt", ",", "das", "Schuh\u00b7wachs", "bey", "sich", "tr\u00e4\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$,", "ART", "NN", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Und Haarzopf, Arm und Fu\u00df bald hier-, bald dorthin schl\u00e4get,", "tokens": ["Und", "Haar\u00b7zopf", ",", "Arm", "und", "Fu\u00df", "bald", "hier", ",", "bald", "dor\u00b7thin", "schl\u00e4\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "ADV", "TRUNC", "$,", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Sieht Kunst und Wi\u00dfenschaft mit spr\u00f6den Blicken an,", "tokens": ["Sieht", "Kunst", "und", "Wi\u00b7\u00dfen\u00b7schaft", "mit", "spr\u00f6\u00b7den", "Bli\u00b7cken", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Und sch\u00e4zt er ja ein Buch, so ist es ein Roman,", "tokens": ["Und", "sch\u00e4zt", "er", "ja", "ein", "Buch", ",", "so", "ist", "es", "ein", "Ro\u00b7man", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ADV", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.75": {"text": "Und soll er einem ja des Weisen Tittel g\u00f6nnen,", "tokens": ["Und", "soll", "er", "ei\u00b7nem", "ja", "des", "Wei\u00b7sen", "Tit\u00b7tel", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "So mu\u00df derselbe Wind und Schmincke machen k\u00f6nnen.", "tokens": ["So", "mu\u00df", "der\u00b7sel\u00b7be", "Wind", "und", "Schmin\u00b7cke", "ma\u00b7chen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PDAT", "NN", "KON", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Wer ist wohl so ge\u00fcbt und bringt mir gl\u00fccklich bey,", "tokens": ["Wer", "ist", "wohl", "so", "ge\u00b7\u00fcbt", "und", "bringt", "mir", "gl\u00fcck\u00b7lich", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "VVPP", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Wie gro\u00df der Unterscheid von dieser Thorheit sey?", "tokens": ["Wie", "gro\u00df", "der", "Un\u00b7ter\u00b7scheid", "von", "die\u00b7ser", "Thor\u00b7heit", "sey", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "APPR", "PDAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Ich trau mir eher zu, die Allgebram zu fa\u00dfen", "tokens": ["Ich", "trau", "mir", "e\u00b7her", "zu", ",", "die", "All\u00b7ge\u00b7bram", "zu", "fa\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "PRELS", "PIS", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Und mit geschwinder M\u00fch die Rechnung sehn zu la\u00dfen,", "tokens": ["Und", "mit", "ge\u00b7schwin\u00b7der", "M\u00fch", "die", "Rech\u00b7nung", "sehn", "zu", "la\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Wie manchen . . . . . . Corvinus . . . . . . . zersprengt,", "tokens": ["Wie", "man\u00b7chen", ".", ".", ".", ".", ".", ".", "Cor\u00b7vi\u00b7nus", ".", ".", ".", ".", ".", ".", ".", "zer\u00b7sprengt", ","], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["PWAV", "PIS", "$.", "$.", "$.", "$.", "$.", "$.", "NE", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.82": {"text": "Wie mancher Wittwenfluch auf Cryphons Hofreit h\u00e4ngt,", "tokens": ["Wie", "man\u00b7cher", "Witt\u00b7wen\u00b7fluch", "auf", "Cry\u00b7phons", "Hof\u00b7reit", "h\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Wie viel seit kurzer Zeit vom Polychrest verblichen", "tokens": ["Wie", "viel", "seit", "kur\u00b7zer", "Zeit", "vom", "Po\u00b7ly\u00b7chrest", "ver\u00b7bli\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "APPR", "ADJA", "NN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Und wie viel Mondwurf sich in Schulen eingeschlichen.", "tokens": ["Und", "wie", "viel", "Mond\u00b7wurf", "sich", "in", "Schu\u00b7len", "ein\u00b7ge\u00b7schli\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIAT", "NN", "PRF", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Damit ich aber kurz in Ziel und Ordnung geh,", "tokens": ["Da\u00b7mit", "ich", "a\u00b7ber", "kurz", "in", "Ziel", "und", "Ord\u00b7nung", "geh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "So seht nur, wie es erst um derer Wandel steh,", "tokens": ["So", "seht", "nur", ",", "wie", "es", "erst", "um", "de\u00b7rer", "Wan\u00b7del", "steh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "PWAV", "PPER", "ADV", "APPR", "PDS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Die an Gela\u00dfenheit dem Meister folgen sollen", "tokens": ["Die", "an", "Ge\u00b7la\u00b7\u00dfen\u00b7heit", "dem", "Meis\u00b7ter", "fol\u00b7gen", "sol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "ART", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Und allemahl den Ruhm des Friedens haben wollen.", "tokens": ["Und", "al\u00b7le\u00b7mahl", "den", "Ruhm", "des", "Frie\u00b7dens", "ha\u00b7ben", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ART", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Wie viel von solcher Zunft sind Sp\u00f6tter voller Schein,", "tokens": ["Wie", "viel", "von", "sol\u00b7cher", "Zunft", "sind", "Sp\u00f6t\u00b7ter", "vol\u00b7ler", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "PIAT", "NN", "VAFIN", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Die Kleidung, Amt und Mund durch Wort und That entweihn", "tokens": ["Die", "Klei\u00b7dung", ",", "Amt", "und", "Mund", "durch", "Wort", "und", "That", "ent\u00b7weihn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "APPR", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Und oft ihr Priesterhaus mit Tadeln, Schimpf und Lachen", "tokens": ["Und", "oft", "ihr", "Pries\u00b7ter\u00b7haus", "mit", "Ta\u00b7deln", ",", "Schimpf", "und", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "PPOSAT", "NN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Aus Neubegierigkeit zum Musterplaze machen.", "tokens": ["Aus", "Neu\u00b7be\u00b7gie\u00b7rig\u00b7keit", "zum", "Mus\u00b7ter\u00b7pla\u00b7ze", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Allhier versammlen sich die Fabeln aus der Stadt,", "tokens": ["All\u00b7hier", "ver\u00b7samm\u00b7len", "sich", "die", "Fa\u00b7beln", "aus", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Weil jedes Plauderweib erlaubten Zutritt hat;", "tokens": ["Weil", "je\u00b7des", "Plau\u00b7der\u00b7weib", "er\u00b7laub\u00b7ten", "Zu\u00b7tritt", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Draus brennt der Eifer an, drauf mu\u00df die Canzel schm\u00e4hlen", "tokens": ["Draus", "brennt", "der", "Ei\u00b7fer", "an", ",", "drauf", "mu\u00df", "die", "Can\u00b7zel", "schm\u00e4h\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PAV", "VMFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Und, was ein Schaaf versehn, der ganzen Heerd erzehlen.", "tokens": ["Und", ",", "was", "ein", "Schaaf", "ver\u00b7sehn", ",", "der", "gan\u00b7zen", "Heerd", "er\u00b7zeh\u00b7len", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "ART", "NN", "VVINF", "$,", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Ach, sind denn sie auch rein? Ja, ja. Wer ist Murar,", "tokens": ["Ach", ",", "sind", "denn", "sie", "auch", "rein", "?", "Ja", ",", "ja", ".", "Wer", "ist", "Mu\u00b7rar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VAFIN", "KON", "PPER", "ADV", "ADJD", "$.", "PTKANT", "$,", "ADV", "$.", "PWS", "VAFIN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Vor de\u00dfen Seegensthau kein Ehstand sicher war?", "tokens": ["Vor", "de\u00b7\u00dfen", "See\u00b7genst\u00b7hau", "kein", "Eh\u00b7stand", "si\u00b7cher", "war", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIAT", "NN", "ADJD", "VAFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.99": {"text": "Er baut auf fremden Grund, bestahl sein eignes Lager", "tokens": ["Er", "baut", "auf", "frem\u00b7den", "Grund", ",", "be\u00b7stahl", "sein", "eig\u00b7nes", "La\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Und hat, man weis es wohl, manch Kirchspiel ganz zum Schwager", "tokens": ["Und", "hat", ",", "man", "weis", "es", "wohl", ",", "manch", "Kirch\u00b7spiel", "ganz", "zum", "Schwa\u00b7ger"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "$,", "PIS", "PTKVZ", "PPER", "ADV", "$,", "PIAT", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Was Wunder, schmi\u00df er oft mit H\u00f6lle, Fluch und Tod,", "tokens": ["Was", "Wun\u00b7der", ",", "schmi\u00df", "er", "oft", "mit", "H\u00f6l\u00b7le", ",", "Fluch", "und", "Tod", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "VVFIN", "PPER", "ADV", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Nahm Larv und Masquen vor und ward gleichwohl nicht roth,", "tokens": ["Nahm", "Larv", "und", "Mas\u00b7quen", "vor", "und", "ward", "gleich\u00b7wohl", "nicht", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "NN", "PTKVZ", "KON", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Wenn Flora, der er oft den Abendseegen brachte,", "tokens": ["Wenn", "Flo\u00b7ra", ",", "der", "er", "oft", "den", "A\u00b7ben\u00b7dsee\u00b7gen", "brach\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PRELS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Ihm gegen\u00fcber sa\u00df und durch den F\u00e4cher lachte.", "tokens": ["Ihm", "ge\u00b7gen\u00b7\u00fc\u00b7ber", "sa\u00df", "und", "durch", "den", "F\u00e4\u00b7cher", "lach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Halt ein! Es blizt der Bann. Er blizt nur; immer fort!", "tokens": ["Halt", "ein", "!", "Es", "blizt", "der", "Bann", ".", "Er", "blizt", "nur", ";", "im\u00b7mer", "fort", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "ADV", "$.", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Man kennt wohl noch den Lerm, man weis auch noch den Ort,", "tokens": ["Man", "kennt", "wohl", "noch", "den", "Lerm", ",", "man", "weis", "auch", "noch", "den", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ART", "NN", "$,", "PIS", "PTKVZ", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Wo so ein Kirchenlicht, das jezt vor Eifer lodert,", "tokens": ["Wo", "so", "ein", "Kir\u00b7chen\u00b7licht", ",", "das", "jezt", "vor", "Ei\u00b7fer", "lo\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Das Werck der Finstern\u00fc\u00df von Bathseban gefodert.", "tokens": ["Das", "Werck", "der", "Fins\u00b7ter\u00b7n\u00fc\u00df", "von", "Bath\u00b7se\u00b7ban", "ge\u00b7fo\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Wie machts der P\u00f6bel denn? Nun kommt, besucht das Haus,", "tokens": ["Wie", "machts", "der", "P\u00f6\u00b7bel", "denn", "?", "Nun", "kommt", ",", "be\u00b7sucht", "das", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "KON", "$.", "ADV", "VVFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Wo Flora Wochen h\u00e4lt, und r\u00e4umt die Ohren aus!", "tokens": ["Wo", "Flo\u00b7ra", "Wo\u00b7chen", "h\u00e4lt", ",", "und", "r\u00e4umt", "die", "Oh\u00b7ren", "aus", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NN", "VVFIN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Da sizt die kluge Frau mit viel verschwornen Schwestern,", "tokens": ["Da", "sizt", "die", "klu\u00b7ge", "Frau", "mit", "viel", "ver\u00b7schwor\u00b7nen", "Schwes\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Und diese raisoniert, der Deutsche nennt es l\u00e4stern,", "tokens": ["Und", "die\u00b7se", "rai\u00b7so\u00b7niert", ",", "der", "Deut\u00b7sche", "nennt", "es", "l\u00e4s\u00b7tern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "$,", "ART", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Die greift der Mann zu scharf und die zu wenig an,", "tokens": ["Die", "greift", "der", "Mann", "zu", "scharf", "und", "die", "zu", "we\u00b7nig", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "PTKA", "ADJD", "KON", "ART", "PTKA", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Da wird das Heimlichste des Ehbetts aufgethan;", "tokens": ["Da", "wird", "das", "Heim\u00b7lichs\u00b7te", "des", "Eh\u00b7betts", "auf\u00b7ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Die schilt den Prediger und spricht: Er kan nichts sagen,", "tokens": ["Die", "schilt", "den", "Pre\u00b7di\u00b7ger", "und", "spricht", ":", "Er", "kan", "nichts", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "KON", "VVFIN", "$.", "PPER", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Als was der Unterricht ihm t\u00e4glich eingeschlagen;", "tokens": ["Als", "was", "der", "Un\u00b7ter\u00b7richt", "ihm", "t\u00e4g\u00b7lich", "ein\u00b7ge\u00b7schla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "ART", "NN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Die nimmt den Schulmann durch und rechnet mit viel List,", "tokens": ["Die", "nimmt", "den", "Schul\u00b7mann", "durch", "und", "rech\u00b7net", "mit", "viel", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPR", "KON", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Wem alles . . . . . . . . . . . . . . . . er schuldig ist;", "tokens": ["Wem", "al\u00b7les", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "er", "schul\u00b7dig", "ist", ";"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.119": {"text": "Er kostet, wie mir selbst die Mutter zugeschworen,", "tokens": ["Er", "kos\u00b7tet", ",", "wie", "mir", "selbst", "die", "Mut\u00b7ter", "zu\u00b7ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "So viel als nechst Veron durch einen Saz verloren.", "tokens": ["So", "viel", "als", "nechst", "Ve\u00b7ron", "durch", "ei\u00b7nen", "Saz", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "KOKOM", "ADV", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Die andre nimmt das Wort: Ach, Frau Gevatterin,", "tokens": ["Die", "and\u00b7re", "nimmt", "das", "Wort", ":", "Ach", ",", "Frau", "Ge\u00b7vat\u00b7te\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ART", "NN", "$.", "ITJ", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Wo denckt doch wohl ihr Arzt mit diesem Pulver hin?", "tokens": ["Wo", "denckt", "doch", "wohl", "ihr", "Arzt", "mit", "die\u00b7sem", "Pul\u00b7ver", "hin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Der Kerl ist viel zu jung, denn wenn er was verst\u00fcnde,", "tokens": ["Der", "Kerl", "ist", "viel", "zu", "jung", ",", "denn", "wenn", "er", "was", "ver\u00b7st\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$,", "KON", "KOUS", "PPER", "PIS", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "So h\u00fclf er auf mein Flehn mir schon vorl\u00e4ngst zum Kinde.", "tokens": ["So", "h\u00fclf", "er", "auf", "mein", "Flehn", "mir", "schon", "vor\u00b7l\u00e4ngst", "zum", "Kin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PPER", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "So geht die Reih herum. Da kommt denn aufs Tapet,", "tokens": ["So", "geht", "die", "Reih", "he\u00b7rum", ".", "Da", "kommt", "denn", "aufs", "Ta\u00b7pet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$.", "ADV", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.126": {"text": "Warum die Alte bunt, die Junge bucklicht geht,", "tokens": ["Wa\u00b7rum", "die", "Al\u00b7te", "bunt", ",", "die", "Jun\u00b7ge", "buck\u00b7licht", "geht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJD", "$,", "ART", "NN", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Der steht der Aufsaz schlimm, den schimpft die kleine Nase,", "tokens": ["Der", "steht", "der", "Auf\u00b7saz", "schlimm", ",", "den", "schimpft", "die", "klei\u00b7ne", "Na\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADJD", "$,", "ART", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Rinaldo riecht nach Brodt und Marx nach geilem Grase,", "tokens": ["Ri\u00b7nal\u00b7do", "riecht", "nach", "Brodt", "und", "Marx", "nach", "gei\u00b7lem", "Gra\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "KON", "NE", "APPR", "ADJA", "NN", "$,"], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.129": {"text": "Marindo scherzt zu grob, Ro\u00dfalva lacht zu laut,", "tokens": ["Ma\u00b7rin\u00b7do", "scherzt", "zu", "grob", ",", "Ro\u00df\u00b7al\u00b7va", "lacht", "zu", "laut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKA", "ADJD", "$,", "NE", "VVFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Selintes henckt den Kopf, Valvata schminckt die Haut,", "tokens": ["Se\u00b7lin\u00b7tes", "henckt", "den", "Kopf", ",", "Val\u00b7va\u00b7ta", "schminckt", "die", "Haut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Gerintho raucht zu starck, Germana tanzt zu fl\u00fcchtig,", "tokens": ["Ge\u00b7rin\u00b7tho", "raucht", "zu", "starck", ",", "Ger\u00b7ma\u00b7na", "tanzt", "zu", "fl\u00fcch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKA", "ADJD", "$,", "NE", "VVFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Und wo Brasitte steht, da ist die Luft nicht richtig.", "tokens": ["Und", "wo", "Bra\u00b7sit\u00b7te", "steht", ",", "da", "ist", "die", "Luft", "nicht", "rich\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "VVFIN", "$,", "ADV", "VAFIN", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Dies w\u00e4hrt den halben Tag, und da mu\u00df alles her", "tokens": ["Dies", "w\u00e4hrt", "den", "hal\u00b7ben", "Tag", ",", "und", "da", "mu\u00df", "al\u00b7les", "her"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$,", "KON", "ADV", "VMFIN", "PIS", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Und wenn es auch nur . . . . . . . Strumpfband w\u00e4r,", "tokens": ["Und", "wenn", "es", "auch", "nur", ".", ".", ".", ".", ".", ".", ".", "Strumpf\u00b7band", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.135": {"text": "Worum sich Herr und Knecht im Finstern rumgeschmi\u00dfen,", "tokens": ["Wo\u00b7rum", "sich", "Herr", "und", "Knecht", "im", "Fins\u00b7tern", "rum\u00b7ge\u00b7schmi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "NN", "KON", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Da\u00df Beicht- und Richterstuhl zulezt noch mitteln m\u00fc\u00dfen,", "tokens": ["Da\u00df", "Beicht", "und", "Rich\u00b7ter\u00b7stuhl", "zu\u00b7lezt", "noch", "mit\u00b7teln", "m\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "TRUNC", "KON", "NN", "ADV", "ADV", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.138": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.139": {"text": "Wo ... und Einfalt sizt und solche gern besch\u00fczen.", "tokens": ["Wo", "...", "und", "Ein\u00b7falt", "sizt", "und", "sol\u00b7che", "gern", "be\u00b7sch\u00fc\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$(", "KON", "NN", "VVFIN", "KON", "PIAT", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.140": {"text": "Doch wie die Weiber sind, die schon die Zunge spizen", "tokens": ["Doch", "wie", "die", "Wei\u00b7ber", "sind", ",", "die", "schon", "die", "Zun\u00b7ge", "spi\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "VAFIN", "$,", "PRELS", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.142": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.143": {"text": "Allein, da\u00df mancher Grei\u00df . . . . . . . . . . . . . . . . . . .", "tokens": ["Al\u00b7lein", ",", "da\u00df", "man\u00b7cher", "Grei\u00df", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["ADV", "$,", "KOUS", "PIAT", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.144": {"text": ". . . . . . . . . . . Bart von . . . und Ansehn . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "Bart", "von", ".", ".", ".", "und", "An\u00b7sehn", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "APPR", "$.", "$.", "$.", "KON", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.145": {"text": "Das ist der Striegel werth. Es tritt kein Buch ans Licht,", "tokens": ["Das", "ist", "der", "Strie\u00b7gel", "werth", ".", "Es", "tritt", "kein", "Buch", "ans", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADJD", "$.", "PPER", "VVFIN", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Es sey auch noch so nett, der Tadler kommt und sticht,", "tokens": ["Es", "sey", "auch", "noch", "so", "nett", ",", "der", "Tad\u00b7ler", "kommt", "und", "sticht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$,", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Verdirbt viel Weltgeschmack, indem er . . . richtet,", "tokens": ["Ver\u00b7dirbt", "viel", "Welt\u00b7ge\u00b7schmack", ",", "in\u00b7dem", "er", ".", ".", ".", "rich\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "KOUS", "PPER", "$.", "$.", "$.", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.148": {"text": "Und n\u00e4hrt oft sein Journal mit Fehlern, die er dichtet.", "tokens": ["Und", "n\u00e4hrt", "oft", "sein", "Jour\u00b7nal", "mit", "Feh\u00b7lern", ",", "die", "er", "dich\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPOSAT", "NN", "APPR", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Es bleibt auch nicht dabey; die Einfalt neuer Zeit", "tokens": ["Es", "bleibt", "auch", "nicht", "da\u00b7bey", ";", "die", "Ein\u00b7falt", "neu\u00b7er", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "PAV", "$.", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Vergi\u00dft [?] mit Pelletier der Alten Gr\u00fcndligkeit.", "tokens": ["Ver\u00b7gi\u00dft", "?", "mit", "Pel\u00b7le\u00b7tier", "der", "Al\u00b7ten", "Gr\u00fcnd\u00b7lig\u00b7keit", "."], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "$.", "$(", "APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.151": {"text": "Der . . . . . . den Tullius, in dem er nicht gelesen,", "tokens": ["Der", ".", ".", ".", ".", ".", ".", "den", "Tul\u00b7li\u00b7us", ",", "in", "dem", "er", "nicht", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$.", "$.", "$.", "$.", "$.", "$.", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.152": {"text": "Und jenem ist Virgil . . . . . Cicero . . . . . . Beesen.", "tokens": ["Und", "je\u00b7nem", "ist", "Vir\u00b7gil", ".", ".", ".", ".", ".", "Ci\u00b7ce\u00b7ro", ".", ".", ".", ".", ".", ".", "Bee\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "NE", "$.", "$.", "$.", "$.", "$.", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.153": {"text": "Ein Meister neuer Kunst, der sonst noch ziemlich reimt,", "tokens": ["Ein", "Meis\u00b7ter", "neu\u00b7er", "Kunst", ",", "der", "sonst", "noch", "ziem\u00b7lich", "reimt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "PRELS", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": ". . . . . . . . Schimpf [?] . . . . . . . getr\u00e4umt", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", "Schimpf", "?", ".", ".", ".", ".", ".", ".", ".", "ge\u00b7tr\u00e4umt"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "$(", "$.", "$(", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVPP"], "meter": "+", "measure": "single.up"}, "line.155": {"text": "Und da [er] den Homer. . . . . . . . . . . . . . . . . . . achtet", "tokens": ["Und", "da", "er", "den", "Ho\u00b7mer", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "ach\u00b7tet"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["KON", "KOUS", "$(", "PPER", "$(", "ART", "NE", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "XY"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.156": {"text": ". . . . . . . ., Gehirn, ich weis nicht wo, verpachtet.", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ",", "Ge\u00b7hirn", ",", "ich", "weis", "nicht", "wo", ",", "ver\u00b7pach\u00b7tet", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$,", "NN", "$,", "PPER", "PTKVZ", "PTKNEG", "PWAV", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.157": {"text": "Crispin theilt Sparren aus, und dies ist auch ein Wurm,", "tokens": ["Cris\u00b7pin", "theilt", "Spar\u00b7ren", "aus", ",", "und", "dies", "ist", "auch", "ein", "Wurm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "PTKVZ", "$,", "KON", "PDS", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Sein k\u00fchner M\u00fc\u00dfiggang lauft allenthalben Sturm", "tokens": ["Sein", "k\u00fch\u00b7ner", "M\u00fc\u00b7\u00dfig\u00b7gang", "lauft", "al\u00b7len\u00b7thal\u00b7ben", "Sturm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Und sucht sich wie ein Har\u00df an jeden Stein zu reiben;", "tokens": ["Und", "sucht", "sich", "wie", "ein", "Har\u00df", "an", "je\u00b7den", "Stein", "zu", "rei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "KOKOM", "ART", "NN", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Das Best' ist, da\u00df oft Haut und Borsten kleben bleiben.", "tokens": ["Das", "Best'", "ist", ",", "da\u00df", "oft", "Haut", "und", "Bors\u00b7ten", "kle\u00b7ben", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "KOUS", "ADV", "NN", "KON", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Sein Maul verschont sogar gelehrter Unschuld nicht,", "tokens": ["Sein", "Maul", "ver\u00b7schont", "so\u00b7gar", "ge\u00b7lehr\u00b7ter", "Un\u00b7schuld", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADJA", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Und obgleich jeder Stand [?] von seiner Einfalt spricht,", "tokens": ["Und", "ob\u00b7gleich", "je\u00b7der", "Stand", "?", "von", "sei\u00b7ner", "Ein\u00b7falt", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIAT", "NN", "$(", "$.", "$(", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.163": {"text": "So h\u00e4lt er doch vor Ruhm, durch fremde Bl\u00f6\u00df und Fluchen", "tokens": ["So", "h\u00e4lt", "er", "doch", "vor", "Ruhm", ",", "durch", "frem\u00b7de", "Bl\u00f6\u00df", "und", "Flu\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "$,", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Dem Schein [?], so ihn verstellt, ein Feigenblat zu suchen.", "tokens": ["Dem", "Schein", "?", ",", "so", "ihn", "ver\u00b7stellt", ",", "ein", "Fei\u00b7gen\u00b7blat", "zu", "su\u00b7chen", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "$.", "$(", "$,", "ADV", "PPER", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.165": {"text": "Amando hielt nur nechst ein pr\u00e4chtiges Pancket,", "tokens": ["A\u00b7man\u00b7do", "hielt", "nur", "nechst", "ein", "pr\u00e4ch\u00b7ti\u00b7ges", "Pan\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.166": {"text": "Und wie es insgeheim bey solchen . . . . . . . geht,", "tokens": ["Und", "wie", "es", "ins\u00b7ge\u00b7heim", "bey", "sol\u00b7chen", ".", ".", ".", ".", ".", ".", ".", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "APPR", "PIAT", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.167": {"text": "So fangen sie auch an mit . . . . . . Schwestern [?]", "tokens": ["So", "fan\u00b7gen", "sie", "auch", "an", "mit", ".", ".", ".", ".", ".", ".", "Schwes\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "$(", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.168": {"text": "Fast jeden Stand durch . . . . . . durchzul\u00e4stern [?].", "tokens": ["Fast", "je\u00b7den", "Stand", "durch", ".", ".", ".", ".", ".", ".", "durch\u00b7zu\u00b7l\u00e4s\u00b7tern", "?", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["ADV", "PIAT", "NN", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "VVIZU", "$(", "$.", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.169": {"text": "H\u00f6rt, was Farillo sprach: Ja, w\u00e4r ich wie Eugen,", "tokens": ["H\u00f6rt", ",", "was", "Fa\u00b7ril\u00b7lo", "sprach", ":", "Ja", ",", "w\u00e4r", "ich", "wie", "Eu\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "NN", "VVFIN", "$.", "PTKANT", "$,", "VAFIN", "PPER", "KOKOM", "NE", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.170": {"text": "Ich wollte noch den Tag in Ungern weiter gehn", "tokens": ["Ich", "woll\u00b7te", "noch", "den", "Tag", "in", "Un\u00b7gern", "wei\u00b7ter", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "APPR", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Und mit der ganzen Macht, ich schw\u00f6r auf meinen Kragen,", "tokens": ["Und", "mit", "der", "gan\u00b7zen", "Macht", ",", "ich", "schw\u00f6r", "auf", "mei\u00b7nen", "Kra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "Den Achmet durch den Belt und ganz Europa jagen.", "tokens": ["Den", "Ach\u00b7met", "durch", "den", "Belt", "und", "ganz", "Eu\u00b7ro\u00b7pa", "ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "KON", "ADV", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Calander l\u00f6st ihn ab, und weil das Contrebant", "tokens": ["Ca\u00b7lan\u00b7der", "l\u00f6st", "ihn", "ab", ",", "und", "weil", "das", "Cont\u00b7re\u00b7bant"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Ihm gestern Abend erst ein Viertel Bier entwand,", "tokens": ["Ihm", "ge\u00b7stern", "A\u00b7bend", "erst", "ein", "Vier\u00b7tel", "Bier", "ent\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "NN", "ADV", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "So flucht er dem Accis und weist des F\u00fcrsten Z\u00f6lle", "tokens": ["So", "flucht", "er", "dem", "Ac\u00b7cis", "und", "weist", "des", "F\u00fcrs\u00b7ten", "Z\u00f6l\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "KON", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Mitsamt dem R \u2013 \u2013 \u2013 von Stund an in die H\u00f6lle.", "tokens": ["Mit\u00b7samt", "dem", "R", "\u2013", "\u2013", "\u2013", "von", "Stund", "an", "in", "die", "H\u00f6l\u00b7le", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "$(", "$(", "$(", "APPR", "NN", "APPR", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.177": {"text": "Sempron, der tiefer sa\u00df und halb besofen schlief,", "tokens": ["Semp\u00b7ron", ",", "der", "tie\u00b7fer", "sa\u00df", "und", "halb", "be\u00b7so\u00b7fen", "schlief", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADJD", "VVFIN", "KON", "ADJD", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Erwachte, weil man gleich von weiten Feuer rief,", "tokens": ["Er\u00b7wach\u00b7te", ",", "weil", "man", "gleich", "von", "wei\u00b7ten", "Feu\u00b7er", "rief", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PIS", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Und da die G\u00e4ste gehn und christlich l\u00f6schen wollten,", "tokens": ["Und", "da", "die", "G\u00e4s\u00b7te", "gehn", "und", "christ\u00b7lich", "l\u00f6\u00b7schen", "woll\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVINF", "KON", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "So schrie er, da\u00df sie doch nur sehn und lachen sollten.", "tokens": ["So", "schrie", "er", ",", "da\u00df", "sie", "doch", "nur", "sehn", "und", "la\u00b7chen", "soll\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ADV", "VVINF", "KON", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Das liederliche Volck, so sprach der B\u00f6sewicht,", "tokens": ["Das", "lie\u00b7der\u00b7li\u00b7che", "Volck", ",", "so", "sprach", "der", "B\u00f6\u00b7se\u00b7wicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Verdient bey seiner Noth dergleichen H\u00fclfe nicht,", "tokens": ["Ver\u00b7di\u00b7ent", "bey", "sei\u00b7ner", "Noth", "derg\u00b7lei\u00b7chen", "H\u00fcl\u00b7fe", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PPOSAT", "NN", "PIS", "NN", "PTKNEG", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.183": {"text": "Denn mich beredt niemand, da\u00df den die Flammen schlagen,", "tokens": ["Denn", "mich", "be\u00b7redt", "nie\u00b7mand", ",", "da\u00df", "den", "die", "Flam\u00b7men", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "$,", "KOUS", "ART", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.184": {"text": "Der nicht vorher das Stroh mit S\u00fcnden zugetragen.", "tokens": ["Der", "nicht", "vor\u00b7her", "das", "Stroh", "mit", "S\u00fcn\u00b7den", "zu\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "ART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Gar recht, sprach Selimon, der gleich am Braten schnidt,", "tokens": ["Gar", "recht", ",", "sprach", "Se\u00b7li\u00b7mon", ",", "der", "gleich", "am", "Bra\u00b7ten", "schnidt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "VVFIN", "NE", "$,", "PRELS", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Es ist ein jeder Mensch sein eigner Ungl\u00fccksschmied,", "tokens": ["Es", "ist", "ein", "je\u00b7der", "Mensch", "sein", "eig\u00b7ner", "Un\u00b7gl\u00fccks\u00b7schmied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PIAT", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Und darum . . . . . ich auch kein . . . . Erbarmen,", "tokens": ["Und", "da\u00b7rum", ".", ".", ".", ".", ".", "ich", "auch", "kein", ".", ".", ".", ".", "Er\u00b7bar\u00b7men", ","], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "PAV", "$.", "$.", "$.", "$.", "$.", "PPER", "ADV", "PIAT", "$.", "$.", "$.", "$.", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.188": {"text": "Wenn tausend kl\u00e4glich thun und noch so viel verarmen.", "tokens": ["Wenn", "tau\u00b7send", "kl\u00e4g\u00b7lich", "thun", "und", "noch", "so", "viel", "ver\u00b7ar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ADJD", "VVINF", "KON", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "Ein Bettler nimmt von mir nicht einen Halmen Stroh;", "tokens": ["Ein", "Bett\u00b7ler", "nimmt", "von", "mir", "nicht", "ei\u00b7nen", "Hal\u00b7men", "Stroh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "Die Faulheit darbt mit Recht, vermeint [?] doch Salomo.", "tokens": ["Die", "Faul\u00b7heit", "darbt", "mit", "Recht", ",", "ver\u00b7meint", "?", "doch", "Sa\u00b7lo\u00b7mo", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,", "VVFIN", "$(", "$.", "$(", "ADV", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.191": {"text": "Es mag der nackte Hund sich so wie wir uns placken,", "tokens": ["Es", "mag", "der", "nack\u00b7te", "Hund", "sich", "so", "wie", "wir", "uns", "pla\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "PRF", "ADV", "KOKOM", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.192": {"text": "So kriegt er auch vor Brodt Ducaten einzupacken.", "tokens": ["So", "kriegt", "er", "auch", "vor", "Brodt", "Du\u00b7ca\u00b7ten", "ein\u00b7zu\u00b7pa\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "So schliest der b\u00f6se Mann, als wenn das gro\u00dfe Meer", "tokens": ["So", "schliest", "der", "b\u00f6\u00b7se", "Mann", ",", "als", "wenn", "das", "gro\u00b7\u00dfe", "Meer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "KOKOM", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.194": {"text": "Der Vorsicht, die uns lenckt, so leicht ergr\u00fcndlich w\u00e4r", "tokens": ["Der", "Vor\u00b7sicht", ",", "die", "uns", "lenckt", ",", "so", "leicht", "er\u00b7gr\u00fcnd\u00b7lich", "w\u00e4r"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "ADJD", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Und nicht auch dann und wann viel unschuldsvolle Christen", "tokens": ["Und", "nicht", "auch", "dann", "und", "wann", "viel", "un\u00b7schulds\u00b7vol\u00b7le", "Chris\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "ADV", "ADV", "KON", "PWAV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Aus Pr\u00fcfung h\u00f6hrer Huld [?] die Geifrer [?] f\u00fchlen m\u00fcsten.", "tokens": ["Aus", "Pr\u00fc\u00b7fung", "h\u00f6h\u00b7rer", "Huld", "?", "die", "Geif\u00b7rer", "?", "f\u00fch\u00b7len", "m\u00fcs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$(", "$.", "$(", "ART", "NN", "$(", "$.", "$(", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.197": {"text": "Ach arm- und blinder Mensch, greif deinen Busen an!", "tokens": ["Ach", "ar\u00b7m", "und", "blin\u00b7der", "Mensch", ",", "greif", "dei\u00b7nen", "Bu\u00b7sen", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "TRUNC", "KON", "ADJA", "NN", "$,", "ADJD", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.198": {"text": "Du weist, wie viel Natur und was Gewohnheit kan;", "tokens": ["Du", "weist", ",", "wie", "viel", "Na\u00b7tur", "und", "was", "Ge\u00b7wohn\u00b7heit", "kan", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PIAT", "NN", "KON", "PWS", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.199": {"text": "Von dieser hast auch du vielleicht noch manch Gebrechen,", "tokens": ["Von", "die\u00b7ser", "hast", "auch", "du", "viel\u00b7leicht", "noch", "manch", "Ge\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "ADV", "PPER", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Bey welchem andre dir den Gecken r\u00fccklings stechen.", "tokens": ["Bey", "wel\u00b7chem", "and\u00b7re", "dir", "den", "Ge\u00b7cken", "r\u00fcck\u00b7lings", "ste\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "ADJA", "PPER", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "Hilf, wenn du kanst und weist, und gieb vor dich nur Acht;", "tokens": ["Hilf", ",", "wenn", "du", "kanst", "und", "weist", ",", "und", "gieb", "vor", "dich", "nur", "Acht", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "PPER", "VMFIN", "KON", "VVFIN", "$,", "KON", "VVIMP", "APPR", "PPER", "ADV", "CARD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Der, so die Herzen pr\u00fcft und \u00fcber alles wacht,", "tokens": ["Der", ",", "so", "die", "Her\u00b7zen", "pr\u00fcft", "und", "\u00fc\u00b7ber", "al\u00b7les", "wacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "ART", "NN", "VVFIN", "KON", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.203": {"text": "Will schon zu rechter Zeit die Bo\u00dfheit ofenbahren", "tokens": ["Will", "schon", "zu", "rech\u00b7ter", "Zeit", "die", "Bo\u00df\u00b7heit", "o\u00b7fen\u00b7bah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "APPR", "ADJA", "NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.204": {"text": "Und jedes Straf und Lohn auf jenen Tag versparen.", "tokens": ["Und", "je\u00b7des", "Straf", "und", "Lohn", "auf", "je\u00b7nen", "Tag", "ver\u00b7spa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.205": {"text": "Wir wandern [?] in der Welt als Pilger, deren Fu\u00df", "tokens": ["Wir", "wan\u00b7dern", "?", "in", "der", "Welt", "als", "Pil\u00b7ger", ",", "de\u00b7ren", "Fu\u00df"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "$.", "$(", "APPR", "ART", "NN", "KOUS", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.206": {"text": "Durch viel Gefahr und Angst zur Ruhstatt wandeln mu\u00df.", "tokens": ["Durch", "viel", "Ge\u00b7fahr", "und", "Angst", "zur", "Ruh\u00b7statt", "wan\u00b7deln", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "APPRART", "NN", "VVFIN", "VMFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.207": {"text": "Wie will ein Reisender durch Spotten, Schimpf und Lachen", "tokens": ["Wie", "will", "ein", "Rei\u00b7sen\u00b7der", "durch", "Spot\u00b7ten", ",", "Schimpf", "und", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "ART", "NN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.208": {"text": "Dem andern neben sich den Weg noch saurer machen?", "tokens": ["Dem", "an\u00b7dern", "ne\u00b7ben", "sich", "den", "Weg", "noch", "sau\u00b7rer", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "PRF", "ART", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "Man weis, die Lieb ist blind und lobt oft, was verstellt.", "tokens": ["Man", "weis", ",", "die", "Lieb", "ist", "blind", "und", "lobt", "oft", ",", "was", "ver\u00b7stellt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "PTKVZ", "$,", "ART", "NN", "VAFIN", "ADJD", "KON", "VVFIN", "ADV", "$,", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.210": {"text": "Wie Floro Lenchens Mahl vor sch\u00f6n und artig h\u00e4lt,", "tokens": ["Wie", "Flo\u00b7ro", "Len\u00b7chens", "Mahl", "vor", "sch\u00f6n", "und", "ar\u00b7tig", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "NN", "APPR", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.211": {"text": "So achtet Damon nicht, da\u00df Lorchens Schenckel hauchet,", "tokens": ["So", "ach\u00b7tet", "Da\u00b7mon", "nicht", ",", "da\u00df", "Lor\u00b7chens", "Schen\u00b7ckel", "hau\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "PTKNEG", "$,", "KOUS", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.212": {"text": "Noch Philor, da\u00df sein Schaz zwey fremde Z\u00e4hne brauchet.", "tokens": ["Noch", "Phi\u00b7lor", ",", "da\u00df", "sein", "Schaz", "zwey", "frem\u00b7de", "Z\u00e4h\u00b7ne", "brau\u00b7chet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "KOUS", "PPOSAT", "NN", "CARD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.213": {"text": "Der Irrthum hat sein Lob; o w\u00e4r er allgemein,", "tokens": ["Der", "Irr\u00b7thum", "hat", "sein", "Lob", ";", "o", "w\u00e4r", "er", "all\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$.", "FM", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.214": {"text": "Wie gl\u00fccklich sollte nicht der Menschen Freundschaft seyn,", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "soll\u00b7te", "nicht", "der", "Men\u00b7schen", "Freund\u00b7schaft", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PTKNEG", "ART", "NN", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.215": {"text": "Wir . . . . . . . jederzeit, mit andern aufzuheben,", "tokens": ["Wir", ".", ".", ".", ".", ".", ".", ".", "je\u00b7der\u00b7zeit", ",", "mit", "an\u00b7dern", "auf\u00b7zu\u00b7he\u00b7ben", ","], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADV", "$,", "APPR", "PIS", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.216": {"text": "So wohl ohn \u00c4rgern\u00fc\u00df als sonder Vorwurf leben.", "tokens": ["So", "wohl", "ohn", "\u00c4r\u00b7ger\u00b7n\u00fc\u00df", "als", "son\u00b7der", "Vor\u00b7wurf", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "KOKOM", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Wer aber ist denn wohl ein klug- und weiser Mann?", "tokens": ["Wer", "a\u00b7ber", "ist", "denn", "wohl", "ein", "klug", "und", "wei\u00b7ser", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "ADV", "ART", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.218": {"text": "Der, so sich selbst nichts schenckt und Strafen [?] tragen kan,", "tokens": ["Der", ",", "so", "sich", "selbst", "nichts", "schenckt", "und", "Stra\u00b7fen", "?", "tra\u00b7gen", "kan", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "PRF", "ADV", "PIS", "VVFIN", "KON", "NN", "$(", "$.", "$(", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.219": {"text": "Des Nechsten schwachen Fu\u00df mit Lieb und Gunst regieret", "tokens": ["Des", "Nechs\u00b7ten", "schwa\u00b7chen", "Fu\u00df", "mit", "Lieb", "und", "Gunst", "re\u00b7gie\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.220": {"text": "Und, wenn er ausw\u00e4rts geht, mit Lust . . . . vorw\u00e4rts f\u00fchret.", "tokens": ["Und", ",", "wenn", "er", "aus\u00b7w\u00e4rts", "geht", ",", "mit", "Lust", ".", ".", ".", ".", "vor\u00b7w\u00e4rts", "f\u00fch\u00b7ret", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,", "APPR", "NN", "$.", "$.", "$.", "$.", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.221": {"text": "Ein solcher thut, was Gott, Natur und Zeit begehrt,", "tokens": ["Ein", "sol\u00b7cher", "thut", ",", "was", "Gott", ",", "Na\u00b7tur", "und", "Zeit", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "VVFIN", "$,", "PRELS", "NN", "$,", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "Und ist, wo nur nicht mehr, des h\u00f6chsten Thrones werth,", "tokens": ["Und", "ist", ",", "wo", "nur", "nicht", "mehr", ",", "des", "h\u00f6chs\u00b7ten", "Thro\u00b7nes", "werth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "PWAV", "ADV", "PTKNEG", "ADV", "$,", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.223": {"text": "Allein auch unter uns so selten aufzutreiben", "tokens": ["Al\u00b7lein", "auch", "un\u00b7ter", "uns", "so", "sel\u00b7ten", "auf\u00b7zu\u00b7trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "PPER", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Als Dichter, welche rein und nett und gr\u00fcndlich schreiben.", "tokens": ["Als", "Dich\u00b7ter", ",", "wel\u00b7che", "rein", "und", "nett", "und", "gr\u00fcnd\u00b7lich", "schrei\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PRELS", "ADJD", "KON", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.225": {"text": "Ein jeder schmeichelt sich aus Wahn und Selbstbetrug", "tokens": ["Ein", "je\u00b7der", "schmei\u00b7chelt", "sich", "aus", "Wahn", "und", "Selbst\u00b7be\u00b7trug"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "PRF", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "Und meint, er sey vor sich gut, heilig, fromm und klug,", "tokens": ["Und", "meint", ",", "er", "sey", "vor", "sich", "gut", ",", "hei\u00b7lig", ",", "fromm", "und", "klug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "APPR", "PRF", "ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Und sagt Gott st\u00fcndlich Danck wie jener Pharis\u00e4er.", "tokens": ["Und", "sagt", "Gott", "st\u00fcnd\u00b7lich", "Danck", "wie", "je\u00b7ner", "Pha\u00b7ri\u00b7s\u00e4\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ADJD", "NN", "KOKOM", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "Der Geiz verdorrt bey Gold und henckt und bringt sich eher", "tokens": ["Der", "Geiz", "ver\u00b7dorrt", "bey", "Gold", "und", "henckt", "und", "bringt", "sich", "e\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "KON", "VVFIN", "KON", "VVFIN", "PRF", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.229": {"text": "Um Hals und Seeligkeit, als da\u00df sein Herz der Reu", "tokens": ["Um", "Hals", "und", "See\u00b7lig\u00b7keit", ",", "als", "da\u00df", "sein", "Herz", "der", "Reu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "NN", "KON", "NN", "$,", "KOKOM", "KOUS", "PPOSAT", "NN", "ART", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.230": {"text": "Des halb verlornen Sohns verthanes Geld verzeih.", "tokens": ["Des", "halb", "ver\u00b7lor\u00b7nen", "Sohns", "ver\u00b7tha\u00b7nes", "Geld", "ver\u00b7zeih", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.231": {"text": "Der, welchen die Natur bald von Geburth verschneidet,", "tokens": ["Der", ",", "wel\u00b7chen", "die", "Na\u00b7tur", "bald", "von", "Ge\u00b7burth", "ver\u00b7schnei\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAT", "ART", "NN", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.232": {"text": "Hast alle Z\u00e4rtligkeit, an der er Mangel leidet,", "tokens": ["Hast", "al\u00b7le", "Z\u00e4rt\u00b7lig\u00b7keit", ",", "an", "der", "er", "Man\u00b7gel", "lei\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$,", "APPR", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+++-+-+-", "measure": "unknown.measure.septa"}, "line.233": {"text": "Da gegentheils Solan, der voller Geilheit tobt", "tokens": ["Da", "ge\u00b7gen\u00b7theils", "So\u00b7lan", ",", "der", "vol\u00b7ler", "Geil\u00b7heit", "tobt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "$,", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.234": {"text": "Und mit den Hengsten springt, fast keinen Dichter lobt,", "tokens": ["Und", "mit", "den", "Hengs\u00b7ten", "springt", ",", "fast", "kei\u00b7nen", "Dich\u00b7ter", "lobt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Der nicht wie er sein Maul in jeder Pf\u00fcze sp\u00fclet", "tokens": ["Der", "nicht", "wie", "er", "sein", "Maul", "in", "je\u00b7der", "Pf\u00fc\u00b7ze", "sp\u00fc\u00b7let"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "PWAV", "PPER", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.236": {"text": "Noch Adams Raserey mit Evens \u00c4pfeln k\u00fchlet.", "tokens": ["Noch", "A\u00b7dams", "Ra\u00b7se\u00b7rey", "mit", "E\u00b7vens", "\u00c4p\u00b7feln", "k\u00fch\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Die bla\u00dfe Caelia, die Ruhm in Schande sucht,", "tokens": ["Die", "bla\u00b7\u00dfe", "Cae\u00b7lia", ",", "die", "Ruhm", "in", "Schan\u00b7de", "sucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.238": {"text": "Ersticket durch viel Thee selbst ungebohrne Frucht,", "tokens": ["Er\u00b7sti\u00b7cket", "durch", "viel", "Thee", "selbst", "un\u00b7ge\u00b7bohr\u00b7ne", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.239": {"text": "Beschimpft den braven Mann und macht wie Messaline", "tokens": ["Be\u00b7schimpft", "den", "bra\u00b7ven", "Mann", "und", "macht", "wie", "Mes\u00b7sa\u00b7li\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "KON", "VVFIN", "KOKOM", "NE"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.240": {"text": "Korn, Kirchstuhl, Sommerhaus, Stall, Heu und Opernb\u00fchne", "tokens": ["Korn", ",", "Kirch\u00b7stuhl", ",", "Som\u00b7mer\u00b7haus", ",", "Stall", ",", "Heu", "und", "O\u00b7pern\u00b7b\u00fch\u00b7ne"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.241": {"text": "Zum Schauplaz ihrer Brunst und untersteht sich doch,", "tokens": ["Zum", "Schau\u00b7plaz", "ih\u00b7rer", "Brunst", "und", "un\u00b7ter\u00b7steht", "sich", "doch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "KON", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.242": {"text": "Der armen Kammermagd, die endlich . . . . . das Joch", "tokens": ["Der", "ar\u00b7men", "Kam\u00b7mer\u00b7magd", ",", "die", "end\u00b7lich", ".", ".", ".", ".", ".", "das", "Joch"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "$.", "$.", "$.", "$.", "$.", "ART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.243": {"text": "Des schweren Kranzes bricht, den Himmel zu verschlie\u00dfen,", "tokens": ["Des", "schwe\u00b7ren", "Kran\u00b7zes", "bricht", ",", "den", "Him\u00b7mel", "zu", "ver\u00b7schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.244": {"text": "Da sie doch selbst verdient, in Oel und Pech zu flie\u00dfen.", "tokens": ["Da", "sie", "doch", "selbst", "ver\u00b7dient", ",", "in", "O\u00b7el", "und", "Pech", "zu", "flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "$,", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Schon wieder ein Pasquill? so, deucht mich, werther Freund,", "tokens": ["Schon", "wie\u00b7der", "ein", "Pas\u00b7quill", "?", "so", ",", "deucht", "mich", ",", "wert\u00b7her", "Freund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$.", "ADV", "$,", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Schreit Misgunst und Crispin, da dies mein Blat erscheint,", "tokens": ["Schreit", "Mis\u00b7gunst", "und", "Cris\u00b7pin", ",", "da", "dies", "mein", "Blat", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NE", "$,", "KOUS", "PDS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Nachdem mein Scherz und Ernst, die beide Warheit lieben,", "tokens": ["Nach\u00b7dem", "mein", "Scherz", "und", "Ernst", ",", "die", "bei\u00b7de", "War\u00b7heit", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "NE", "$,", "PRELS", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Narren dann und wann die Ohren wund gerieben.", "tokens": ["Den", "Nar\u00b7ren", "dann", "und", "wann", "die", "Oh\u00b7ren", "wund", "ge\u00b7rie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "KON", "PWAV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was Rath? Was hier zu thun? Err\u00f6thet mein Gesicht?", "tokens": ["Was", "Rath", "?", "Was", "hier", "zu", "thun", "?", "Er\u00b7r\u00f6t\u00b7het", "mein", "Ge\u00b7sicht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "PWS", "ADV", "PTKZU", "VVINF", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Freude mach ich wohl den frechen Sp\u00f6ttern nicht.", "tokens": ["Die", "Freu\u00b7de", "mach", "ich", "wohl", "den", "fre\u00b7chen", "Sp\u00f6t\u00b7tern", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie? oder soll ich mir mit sechzig Klagezetteln", "tokens": ["Wie", "?", "o\u00b7der", "soll", "ich", "mir", "mit", "sech\u00b7zig", "Kla\u00b7ge\u00b7zet\u00b7teln"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "KON", "VMFIN", "PPER", "PRF", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Papiernen Wiederruf und faules Recht erbetteln?", "tokens": ["Pa\u00b7pier\u00b7nen", "Wie\u00b7der\u00b7ruf", "und", "fau\u00b7les", "Recht", "er\u00b7bet\u00b7teln", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es lohnt sich nicht der M\u00fch. Die Misgunst ist zu toll,", "tokens": ["Es", "lohnt", "sich", "nicht", "der", "M\u00fch", ".", "Die", "Mis\u00b7gunst", "ist", "zu", "toll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKNEG", "ART", "NN", "$.", "ART", "NN", "VAFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als da\u00df man ihren Hohn so theuer ahnden soll.", "tokens": ["Als", "da\u00df", "man", "ih\u00b7ren", "Hohn", "so", "theu\u00b7er", "ahn\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "PPOSAT", "NN", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Es w\u00e4r ihr um den Schwur, so m\u00fcst ich mich bequemen,", "tokens": ["Es", "w\u00e4r", "ihr", "um", "den", "Schwur", ",", "so", "m\u00fcst", "ich", "mich", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ART", "VVFIN", "$,", "ADV", "VMFIN", "PPER", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den wohlerdachten Schimpf vor Scherzen anzunehmen.", "tokens": ["Den", "woh\u00b7ler\u00b7dach\u00b7ten", "Schimpf", "vor", "Scher\u00b7zen", "an\u00b7zu\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wie aber r\u00e4ch ich mich? Mit Schweigen. Schlechter Tort.", "tokens": ["Wie", "a\u00b7ber", "r\u00e4ch", "ich", "mich", "?", "Mit", "Schwei\u00b7gen", ".", "Schlech\u00b7ter", "Tort", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "PRF", "$.", "APPR", "NN", "$.", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So red ihr christlich zu. Die Grobheit h\u00f6rt kein Wort.", "tokens": ["So", "red", "ihr", "christ\u00b7lich", "zu", ".", "Die", "Grob\u00b7heit", "h\u00f6rt", "kein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "ART", "NN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Je mehr man Bauren fleht, je mehr die Stiefeln schwellen.", "tokens": ["Je", "mehr", "man", "Bau\u00b7ren", "fleht", ",", "je", "mehr", "die", "Stie\u00b7feln", "schwel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "NN", "VVFIN", "$,", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So seze gleich auf gleich und greif ihr an die Schellen", "tokens": ["So", "se\u00b7ze", "gleich", "auf", "gleich", "und", "greif", "ihr", "an", "die", "Schel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ADV", "KON", "ADJD", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und rei\u00df ihr b\u00f6ses Herz mit Peitsch- und Striegeln auf.", "tokens": ["Und", "rei\u00df", "ihr", "b\u00f6\u00b7ses", "Herz", "mit", "Peit\u00b7sch", "und", "Strie\u00b7geln", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "TRUNC", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Du siehst ja in der Welt den umgekehrten Lauf,", "tokens": ["Du", "siehst", "ja", "in", "der", "Welt", "den", "um\u00b7ge\u00b7kehr\u00b7ten", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wer Fried und Ruh begehrt, der mu\u00df sich st\u00fcndlich schlagen", "tokens": ["Wer", "Fried", "und", "Ruh", "be\u00b7gehrt", ",", "der", "mu\u00df", "sich", "st\u00fcnd\u00b7lich", "schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "KON", "NN", "VVPP", "$,", "ART", "VMFIN", "PRF", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und mit der Tadelsucht viel schwere G\u00e4nge wagen.", "tokens": ["Und", "mit", "der", "Ta\u00b7del\u00b7sucht", "viel", "schwe\u00b7re", "G\u00e4n\u00b7ge", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Gar recht, mein Freund, gar recht. Ein jeder Mensch ein Thor.", "tokens": ["Gar", "recht", ",", "mein", "Freund", ",", "gar", "recht", ".", "Ein", "je\u00b7der", "Mensch", "ein", "Thor", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PPOSAT", "NN", "$,", "ADV", "ADJD", "$.", "ART", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Der gr\u00f6ste nennt sich klug und zieht sich andern vor,", "tokens": ["Der", "gr\u00f6s\u00b7te", "nennt", "sich", "klug", "und", "zieht", "sich", "an\u00b7dern", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "ADJD", "KON", "VVFIN", "PRF", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Verr\u00e4th den Hasenkopf so n\u00fcchtern als im Schmause", "tokens": ["Ver\u00b7r\u00e4\u00b7th", "den", "Ha\u00b7sen\u00b7kopf", "so", "n\u00fcch\u00b7tern", "als", "im", "Schmau\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "ADV", "ADJD", "KOKOM", "APPRART", "NN"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Und weist doch allemahl den Nechsten in die Clause.", "tokens": ["Und", "weist", "doch", "al\u00b7le\u00b7mahl", "den", "Nechs\u00b7ten", "in", "die", "Clau\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Da seht ihr, schreyt Vannin, die neue Stachelschrift,", "tokens": ["Da", "seht", "ihr", ",", "schreyt", "Van\u00b7nin", ",", "die", "neu\u00b7e", "Sta\u00b7chel\u00b7schrift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VVFIN", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Die, da sie andern gilt, ihn selbst zugleich mit trift.", "tokens": ["Die", ",", "da", "sie", "an\u00b7dern", "gilt", ",", "ihn", "selbst", "zu\u00b7gleich", "mit", "trift", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,", "PPER", "ADV", "ADV", "APPR", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Vannin, halt etwas ein und las dich be\u00dfer lehren,", "tokens": ["Van\u00b7nin", ",", "halt", "et\u00b7was", "ein", "und", "las", "dich", "be\u00b7\u00dfer", "leh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PIS", "PTKVZ", "KON", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ich strafe nicht mit Grimm, ... selbst [?] zu ehren.", "tokens": ["Ich", "stra\u00b7fe", "nicht", "mit", "Grimm", ",", "...", "selbst", "?", "zu", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "NE", "$,", "$(", "ADV", "$(", "$.", "$(", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Ich weis, ich bin ein Mensch und wohl so schwach als du,", "tokens": ["Ich", "weis", ",", "ich", "bin", "ein", "Mensch", "und", "wohl", "so", "schwach", "als", "du", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "PPER", "VAFIN", "ART", "NN", "KON", "ADV", "ADV", "ADJD", "KOKOM", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Dies, was ich haben will, das las ich andern zu,", "tokens": ["Dies", ",", "was", "ich", "ha\u00b7ben", "will", ",", "das", "las", "ich", "an\u00b7dern", "zu", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "VAINF", "VMFIN", "$,", "PDS", "VVFIN", "PPER", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Dies schenck ich allen gern; nur das verwirft mein Dichten,", "tokens": ["Dies", "schenck", "ich", "al\u00b7len", "gern", ";", "nur", "das", "ver\u00b7wirft", "mein", "Dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PIAT", "ADV", "$.", "ADV", "PDS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Da\u00df S\u00fcnder gleicher Art so grob und giftig richten.", "tokens": ["Da\u00df", "S\u00fcn\u00b7der", "glei\u00b7cher", "Art", "so", "grob", "und", "gif\u00b7tig", "rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJA", "NN", "ADV", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Warum vertr\u00e4gt man nicht einander mit Gedult?", "tokens": ["Wa\u00b7rum", "ver\u00b7tr\u00e4gt", "man", "nicht", "ein\u00b7an\u00b7der", "mit", "Ge\u00b7dult", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "PTKNEG", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Wir haben allerseits den [Fluch] von Adams Schuld.", "tokens": ["Wir", "ha\u00b7ben", "al\u00b7ler\u00b7seits", "den", "Fluch", "von", "A\u00b7dams", "Schuld", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "$(", "NN", "$(", "APPR", "NE", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.35": {"text": "Der fehlt auf diesen Zug und der auf jener Seite,", "tokens": ["Der", "fehlt", "auf", "die\u00b7sen", "Zug", "und", "der", "auf", "je\u00b7ner", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PDAT", "NN", "KON", "ART", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und beide sind dabey verf\u00fchrte Wandersleute.", "tokens": ["Und", "bei\u00b7de", "sind", "da\u00b7bey", "ver\u00b7f\u00fchr\u00b7te", "Wan\u00b7ders\u00b7leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PAV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Den treibt der Ehrsuchtswind, den macht die Sch\u00f6nheit kranck.", "tokens": ["Den", "treibt", "der", "Ehr\u00b7suchts\u00b7wind", ",", "den", "macht", "die", "Sch\u00f6n\u00b7heit", "kranck", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,", "ART", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Wie, wenn im Lazareth und auf der Ruderbanck", "tokens": ["Wie", ",", "wenn", "im", "La\u00b7za\u00b7reth", "und", "auf", "der", "Ru\u00b7der\u00b7banck"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KOUS", "APPRART", "NN", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Ein Sclav und Kr\u00fcpel noch den andern spotten wollte,", "tokens": ["Ein", "Sclav", "und", "Kr\u00fc\u00b7pel", "noch", "den", "an\u00b7dern", "spot\u00b7ten", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "ART", "ADJA", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Was meinstu, was der Narr vor Schmach verdienen sollte?", "tokens": ["Was", "meins\u00b7tu", ",", "was", "der", "Narr", "vor", "Schmach", "ver\u00b7die\u00b7nen", "soll\u00b7te", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PRELS", "ART", "NN", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Und lachstu? Lache nicht; das Gleichn\u00fc\u00df zielt auf dich.", "tokens": ["Und", "lachs\u00b7tu", "?", "La\u00b7che", "nicht", ";", "das", "Gleich\u00b7n\u00fc\u00df", "zielt", "auf", "dich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "NN", "PTKNEG", "$.", "ART", "NN", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Dein Balcken ragt hervor und gleichwohl k\u00fcmmert sich", "tokens": ["Dein", "Bal\u00b7cken", "ragt", "her\u00b7vor", "und", "gleich\u00b7wohl", "k\u00fcm\u00b7mert", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "KON", "ADV", "VVFIN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Dein unversch\u00e4mter Mund um jedes Nechsten Splitter", "tokens": ["Dein", "un\u00b7ver\u00b7sch\u00e4m\u00b7ter", "Mund", "um", "je\u00b7des", "Nechs\u00b7ten", "Split\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Und macht, so bald er f\u00e4llt, ein donnernd Ungewitter.", "tokens": ["Und", "macht", ",", "so", "bald", "er", "f\u00e4llt", ",", "ein", "don\u00b7nernd", "Un\u00b7ge\u00b7wit\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "ADV", "PPER", "VVFIN", "$,", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Und wirf mir ja nicht vor, als schenckt ich dir allein", "tokens": ["Und", "wirf", "mir", "ja", "nicht", "vor", ",", "als", "schenckt", "ich", "dir", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "ADV", "PTKNEG", "PTKVZ", "$,", "KOUS", "VVFIN", "PPER", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Aus Wahn und Eigennuz dergleichen Wermuth ein.", "tokens": ["Aus", "Wahn", "und", "Ei\u00b7gen\u00b7nuz", "derg\u00b7lei\u00b7chen", "Wer\u00b7muth", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PIS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Geh, zieh, wohin du wilt, du wirst nebst gro\u00dfen S\u00fcnden", "tokens": ["Geh", ",", "zieh", ",", "wo\u00b7hin", "du", "wilt", ",", "du", "wirst", "nebst", "gro\u00b7\u00dfen", "S\u00fcn\u00b7den"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "VVFIN", "$,", "PWAV", "PPER", "VMFIN", "$,", "PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Noch manchen Heuchler sehn und viel Tartufen finden.", "tokens": ["Noch", "man\u00b7chen", "Heuch\u00b7ler", "sehn", "und", "viel", "Tar\u00b7tu\u00b7fen", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVINF", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Dort sizt das Murmelthier, der falsche Pietist,", "tokens": ["Dort", "sizt", "das", "Mur\u00b7melt\u00b7hier", ",", "der", "fal\u00b7sche", "Pie\u00b7tist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.50": {"text": "Der fast vor Heiligkeit die ganze Biebel fri\u00dft;", "tokens": ["Der", "fast", "vor", "Hei\u00b7lig\u00b7keit", "die", "gan\u00b7ze", "Bie\u00b7bel", "fri\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Schau, wie er sich allein gerecht zu seyn gedencket", "tokens": ["Schau", ",", "wie", "er", "sich", "al\u00b7lein", "ge\u00b7recht", "zu", "seyn", "ge\u00b7den\u00b7cket"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "PPER", "PRF", "ADV", "ADJD", "PTKZU", "VAINF", "VVFIN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.52": {"text": "Und jeden, der ihm steht, mit Fluch und Predigt kr\u00e4ncket.", "tokens": ["Und", "je\u00b7den", ",", "der", "ihm", "steht", ",", "mit", "Fluch", "und", "Pre\u00b7digt", "kr\u00e4n\u00b7cket", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Der Mucker ist so stolz und schleicht so fromm einher,", "tokens": ["Der", "Mu\u00b7cker", "ist", "so", "stolz", "und", "schleicht", "so", "fromm", "ein\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "KON", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Als wenn das Pflaster kaum des Engels w\u00fcrdig w\u00e4r.", "tokens": ["Als", "wenn", "das", "Pflas\u00b7ter", "kaum", "des", "En\u00b7gels", "w\u00fcr\u00b7dig", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "ADV", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Erlaubt ihm Gott einmahl die Rache seiner Flammen,", "tokens": ["Er\u00b7laubt", "ihm", "Gott", "ein\u00b7mahl", "die", "Ra\u00b7che", "sei\u00b7ner", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "So g\u00f6\u00df er wohl die Welt auf einen Klump zusammen.", "tokens": ["So", "g\u00f6\u00df", "er", "wohl", "die", "Welt", "auf", "ei\u00b7nen", "Klump", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Ein ungerathner Sohn des weisen Epicur", "tokens": ["Ein", "un\u00b7ge\u00b7rath\u00b7ner", "Sohn", "des", "wei\u00b7sen", "E\u00b7pi\u00b7cur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Glaubt das nur, was er w\u00fcntscht, beschweret die Natur,", "tokens": ["Glaubt", "das", "nur", ",", "was", "er", "w\u00fcnt\u00b7scht", ",", "be\u00b7schwe\u00b7ret", "die", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "$,", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.59": {"text": "H\u00e4lt Bauch und Gott vor eins und lacht der albern Christen,", "tokens": ["H\u00e4lt", "Bauch", "und", "Gott", "vor", "eins", "und", "lacht", "der", "al\u00b7bern", "Chris\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "APPR", "PIS", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Als die wie Kinder noch den Teufel f\u00fcrchten m\u00fcsten.", "tokens": ["Als", "die", "wie", "Kin\u00b7der", "noch", "den", "Teu\u00b7fel", "f\u00fcrch\u00b7ten", "m\u00fcs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "KOKOM", "NN", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Ein Schulfuchs, der den Kopf voll griechscher L\u00e4use tr\u00e4gt,", "tokens": ["Ein", "Schul\u00b7fuchs", ",", "der", "den", "Kopf", "voll", "griech\u00b7scher", "L\u00e4u\u00b7se", "tr\u00e4gt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "ADJD", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Fleisch, K\u00e4se, Kiel und Buch in eine Schachtel legt,", "tokens": ["Fleisch", ",", "K\u00e4\u00b7se", ",", "Kiel", "und", "Buch", "in", "ei\u00b7ne", "Schach\u00b7tel", "legt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NE", "KON", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Nach Alterth\u00fcmern stinckt, die Kinder r\u00f6misch nennet", "tokens": ["Nach", "Al\u00b7tert\u00b7h\u00fc\u00b7mern", "stinckt", ",", "die", "Kin\u00b7der", "r\u00f6\u00b7misch", "nen\u00b7net"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "$,", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Und, glaub ich, gar die Frau nach j\u00fcdscher Art erkennet,", "tokens": ["Und", ",", "glaub", "ich", ",", "gar", "die", "Frau", "nach", "j\u00fcd\u00b7scher", "Art", "er\u00b7ken\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "$,", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Schilt jeglichen vor tumm, der nicht so gleich beweist,", "tokens": ["Schilt", "jeg\u00b7li\u00b7chen", "vor", "tumm", ",", "der", "nicht", "so", "gleich", "be\u00b7weist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "APPR", "ADJD", "$,", "PRELS", "PTKNEG", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.67": {"text": "Und meint, wer nicht mit ihm die Eselsbr\u00fccke steiget,", "tokens": ["Und", "meint", ",", "wer", "nicht", "mit", "ihm", "die", "E\u00b7sels\u00b7br\u00fc\u00b7cke", "stei\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "PTKNEG", "APPR", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Den habe Titans Faust aus grobem Leim erzeuget.", "tokens": ["Den", "ha\u00b7be", "Ti\u00b7tans", "Faust", "aus", "gro\u00b7bem", "Leim", "er\u00b7zeu\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NE", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Ein netter Jungfernknecht, der rare B\u00e4nder kauft,", "tokens": ["Ein", "net\u00b7ter", "Jung\u00b7fern\u00b7knecht", ",", "der", "ra\u00b7re", "B\u00e4n\u00b7der", "kauft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Mit Latten und Confect in Ball und Opern lauft,", "tokens": ["Mit", "Lat\u00b7ten", "und", "Con\u00b7fect", "in", "Ball", "und", "O\u00b7pern", "lauft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Die Luft mit Puder f\u00fcllt, das Schuhwachs bey sich tr\u00e4get", "tokens": ["Die", "Luft", "mit", "Pu\u00b7der", "f\u00fcllt", ",", "das", "Schuh\u00b7wachs", "bey", "sich", "tr\u00e4\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$,", "ART", "NN", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Und Haarzopf, Arm und Fu\u00df bald hier-, bald dorthin schl\u00e4get,", "tokens": ["Und", "Haar\u00b7zopf", ",", "Arm", "und", "Fu\u00df", "bald", "hier", ",", "bald", "dor\u00b7thin", "schl\u00e4\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "ADV", "TRUNC", "$,", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Sieht Kunst und Wi\u00dfenschaft mit spr\u00f6den Blicken an,", "tokens": ["Sieht", "Kunst", "und", "Wi\u00b7\u00dfen\u00b7schaft", "mit", "spr\u00f6\u00b7den", "Bli\u00b7cken", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Und sch\u00e4zt er ja ein Buch, so ist es ein Roman,", "tokens": ["Und", "sch\u00e4zt", "er", "ja", "ein", "Buch", ",", "so", "ist", "es", "ein", "Ro\u00b7man", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ADV", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.75": {"text": "Und soll er einem ja des Weisen Tittel g\u00f6nnen,", "tokens": ["Und", "soll", "er", "ei\u00b7nem", "ja", "des", "Wei\u00b7sen", "Tit\u00b7tel", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "So mu\u00df derselbe Wind und Schmincke machen k\u00f6nnen.", "tokens": ["So", "mu\u00df", "der\u00b7sel\u00b7be", "Wind", "und", "Schmin\u00b7cke", "ma\u00b7chen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PDAT", "NN", "KON", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Wer ist wohl so ge\u00fcbt und bringt mir gl\u00fccklich bey,", "tokens": ["Wer", "ist", "wohl", "so", "ge\u00b7\u00fcbt", "und", "bringt", "mir", "gl\u00fcck\u00b7lich", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "VVPP", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Wie gro\u00df der Unterscheid von dieser Thorheit sey?", "tokens": ["Wie", "gro\u00df", "der", "Un\u00b7ter\u00b7scheid", "von", "die\u00b7ser", "Thor\u00b7heit", "sey", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "APPR", "PDAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Ich trau mir eher zu, die Allgebram zu fa\u00dfen", "tokens": ["Ich", "trau", "mir", "e\u00b7her", "zu", ",", "die", "All\u00b7ge\u00b7bram", "zu", "fa\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "PRELS", "PIS", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Und mit geschwinder M\u00fch die Rechnung sehn zu la\u00dfen,", "tokens": ["Und", "mit", "ge\u00b7schwin\u00b7der", "M\u00fch", "die", "Rech\u00b7nung", "sehn", "zu", "la\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Wie manchen . . . . . . Corvinus . . . . . . . zersprengt,", "tokens": ["Wie", "man\u00b7chen", ".", ".", ".", ".", ".", ".", "Cor\u00b7vi\u00b7nus", ".", ".", ".", ".", ".", ".", ".", "zer\u00b7sprengt", ","], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["PWAV", "PIS", "$.", "$.", "$.", "$.", "$.", "$.", "NE", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.82": {"text": "Wie mancher Wittwenfluch auf Cryphons Hofreit h\u00e4ngt,", "tokens": ["Wie", "man\u00b7cher", "Witt\u00b7wen\u00b7fluch", "auf", "Cry\u00b7phons", "Hof\u00b7reit", "h\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Wie viel seit kurzer Zeit vom Polychrest verblichen", "tokens": ["Wie", "viel", "seit", "kur\u00b7zer", "Zeit", "vom", "Po\u00b7ly\u00b7chrest", "ver\u00b7bli\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "APPR", "ADJA", "NN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Und wie viel Mondwurf sich in Schulen eingeschlichen.", "tokens": ["Und", "wie", "viel", "Mond\u00b7wurf", "sich", "in", "Schu\u00b7len", "ein\u00b7ge\u00b7schli\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIAT", "NN", "PRF", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Damit ich aber kurz in Ziel und Ordnung geh,", "tokens": ["Da\u00b7mit", "ich", "a\u00b7ber", "kurz", "in", "Ziel", "und", "Ord\u00b7nung", "geh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "So seht nur, wie es erst um derer Wandel steh,", "tokens": ["So", "seht", "nur", ",", "wie", "es", "erst", "um", "de\u00b7rer", "Wan\u00b7del", "steh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "PWAV", "PPER", "ADV", "APPR", "PDS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Die an Gela\u00dfenheit dem Meister folgen sollen", "tokens": ["Die", "an", "Ge\u00b7la\u00b7\u00dfen\u00b7heit", "dem", "Meis\u00b7ter", "fol\u00b7gen", "sol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "ART", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Und allemahl den Ruhm des Friedens haben wollen.", "tokens": ["Und", "al\u00b7le\u00b7mahl", "den", "Ruhm", "des", "Frie\u00b7dens", "ha\u00b7ben", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ART", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Wie viel von solcher Zunft sind Sp\u00f6tter voller Schein,", "tokens": ["Wie", "viel", "von", "sol\u00b7cher", "Zunft", "sind", "Sp\u00f6t\u00b7ter", "vol\u00b7ler", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "PIAT", "NN", "VAFIN", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Die Kleidung, Amt und Mund durch Wort und That entweihn", "tokens": ["Die", "Klei\u00b7dung", ",", "Amt", "und", "Mund", "durch", "Wort", "und", "That", "ent\u00b7weihn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "APPR", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Und oft ihr Priesterhaus mit Tadeln, Schimpf und Lachen", "tokens": ["Und", "oft", "ihr", "Pries\u00b7ter\u00b7haus", "mit", "Ta\u00b7deln", ",", "Schimpf", "und", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "PPOSAT", "NN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Aus Neubegierigkeit zum Musterplaze machen.", "tokens": ["Aus", "Neu\u00b7be\u00b7gie\u00b7rig\u00b7keit", "zum", "Mus\u00b7ter\u00b7pla\u00b7ze", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Allhier versammlen sich die Fabeln aus der Stadt,", "tokens": ["All\u00b7hier", "ver\u00b7samm\u00b7len", "sich", "die", "Fa\u00b7beln", "aus", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Weil jedes Plauderweib erlaubten Zutritt hat;", "tokens": ["Weil", "je\u00b7des", "Plau\u00b7der\u00b7weib", "er\u00b7laub\u00b7ten", "Zu\u00b7tritt", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Draus brennt der Eifer an, drauf mu\u00df die Canzel schm\u00e4hlen", "tokens": ["Draus", "brennt", "der", "Ei\u00b7fer", "an", ",", "drauf", "mu\u00df", "die", "Can\u00b7zel", "schm\u00e4h\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PAV", "VMFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Und, was ein Schaaf versehn, der ganzen Heerd erzehlen.", "tokens": ["Und", ",", "was", "ein", "Schaaf", "ver\u00b7sehn", ",", "der", "gan\u00b7zen", "Heerd", "er\u00b7zeh\u00b7len", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "ART", "NN", "VVINF", "$,", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Ach, sind denn sie auch rein? Ja, ja. Wer ist Murar,", "tokens": ["Ach", ",", "sind", "denn", "sie", "auch", "rein", "?", "Ja", ",", "ja", ".", "Wer", "ist", "Mu\u00b7rar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VAFIN", "KON", "PPER", "ADV", "ADJD", "$.", "PTKANT", "$,", "ADV", "$.", "PWS", "VAFIN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Vor de\u00dfen Seegensthau kein Ehstand sicher war?", "tokens": ["Vor", "de\u00b7\u00dfen", "See\u00b7genst\u00b7hau", "kein", "Eh\u00b7stand", "si\u00b7cher", "war", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIAT", "NN", "ADJD", "VAFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.99": {"text": "Er baut auf fremden Grund, bestahl sein eignes Lager", "tokens": ["Er", "baut", "auf", "frem\u00b7den", "Grund", ",", "be\u00b7stahl", "sein", "eig\u00b7nes", "La\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Und hat, man weis es wohl, manch Kirchspiel ganz zum Schwager", "tokens": ["Und", "hat", ",", "man", "weis", "es", "wohl", ",", "manch", "Kirch\u00b7spiel", "ganz", "zum", "Schwa\u00b7ger"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "$,", "PIS", "PTKVZ", "PPER", "ADV", "$,", "PIAT", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Was Wunder, schmi\u00df er oft mit H\u00f6lle, Fluch und Tod,", "tokens": ["Was", "Wun\u00b7der", ",", "schmi\u00df", "er", "oft", "mit", "H\u00f6l\u00b7le", ",", "Fluch", "und", "Tod", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "VVFIN", "PPER", "ADV", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Nahm Larv und Masquen vor und ward gleichwohl nicht roth,", "tokens": ["Nahm", "Larv", "und", "Mas\u00b7quen", "vor", "und", "ward", "gleich\u00b7wohl", "nicht", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "NN", "PTKVZ", "KON", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Wenn Flora, der er oft den Abendseegen brachte,", "tokens": ["Wenn", "Flo\u00b7ra", ",", "der", "er", "oft", "den", "A\u00b7ben\u00b7dsee\u00b7gen", "brach\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PRELS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Ihm gegen\u00fcber sa\u00df und durch den F\u00e4cher lachte.", "tokens": ["Ihm", "ge\u00b7gen\u00b7\u00fc\u00b7ber", "sa\u00df", "und", "durch", "den", "F\u00e4\u00b7cher", "lach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Halt ein! Es blizt der Bann. Er blizt nur; immer fort!", "tokens": ["Halt", "ein", "!", "Es", "blizt", "der", "Bann", ".", "Er", "blizt", "nur", ";", "im\u00b7mer", "fort", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "ADV", "$.", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Man kennt wohl noch den Lerm, man weis auch noch den Ort,", "tokens": ["Man", "kennt", "wohl", "noch", "den", "Lerm", ",", "man", "weis", "auch", "noch", "den", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ART", "NN", "$,", "PIS", "PTKVZ", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Wo so ein Kirchenlicht, das jezt vor Eifer lodert,", "tokens": ["Wo", "so", "ein", "Kir\u00b7chen\u00b7licht", ",", "das", "jezt", "vor", "Ei\u00b7fer", "lo\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Das Werck der Finstern\u00fc\u00df von Bathseban gefodert.", "tokens": ["Das", "Werck", "der", "Fins\u00b7ter\u00b7n\u00fc\u00df", "von", "Bath\u00b7se\u00b7ban", "ge\u00b7fo\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Wie machts der P\u00f6bel denn? Nun kommt, besucht das Haus,", "tokens": ["Wie", "machts", "der", "P\u00f6\u00b7bel", "denn", "?", "Nun", "kommt", ",", "be\u00b7sucht", "das", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "KON", "$.", "ADV", "VVFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Wo Flora Wochen h\u00e4lt, und r\u00e4umt die Ohren aus!", "tokens": ["Wo", "Flo\u00b7ra", "Wo\u00b7chen", "h\u00e4lt", ",", "und", "r\u00e4umt", "die", "Oh\u00b7ren", "aus", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NN", "VVFIN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Da sizt die kluge Frau mit viel verschwornen Schwestern,", "tokens": ["Da", "sizt", "die", "klu\u00b7ge", "Frau", "mit", "viel", "ver\u00b7schwor\u00b7nen", "Schwes\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Und diese raisoniert, der Deutsche nennt es l\u00e4stern,", "tokens": ["Und", "die\u00b7se", "rai\u00b7so\u00b7niert", ",", "der", "Deut\u00b7sche", "nennt", "es", "l\u00e4s\u00b7tern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "$,", "ART", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Die greift der Mann zu scharf und die zu wenig an,", "tokens": ["Die", "greift", "der", "Mann", "zu", "scharf", "und", "die", "zu", "we\u00b7nig", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "PTKA", "ADJD", "KON", "ART", "PTKA", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Da wird das Heimlichste des Ehbetts aufgethan;", "tokens": ["Da", "wird", "das", "Heim\u00b7lichs\u00b7te", "des", "Eh\u00b7betts", "auf\u00b7ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Die schilt den Prediger und spricht: Er kan nichts sagen,", "tokens": ["Die", "schilt", "den", "Pre\u00b7di\u00b7ger", "und", "spricht", ":", "Er", "kan", "nichts", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "KON", "VVFIN", "$.", "PPER", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Als was der Unterricht ihm t\u00e4glich eingeschlagen;", "tokens": ["Als", "was", "der", "Un\u00b7ter\u00b7richt", "ihm", "t\u00e4g\u00b7lich", "ein\u00b7ge\u00b7schla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "ART", "NN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Die nimmt den Schulmann durch und rechnet mit viel List,", "tokens": ["Die", "nimmt", "den", "Schul\u00b7mann", "durch", "und", "rech\u00b7net", "mit", "viel", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPR", "KON", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Wem alles . . . . . . . . . . . . . . . . er schuldig ist;", "tokens": ["Wem", "al\u00b7les", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "er", "schul\u00b7dig", "ist", ";"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.119": {"text": "Er kostet, wie mir selbst die Mutter zugeschworen,", "tokens": ["Er", "kos\u00b7tet", ",", "wie", "mir", "selbst", "die", "Mut\u00b7ter", "zu\u00b7ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "So viel als nechst Veron durch einen Saz verloren.", "tokens": ["So", "viel", "als", "nechst", "Ve\u00b7ron", "durch", "ei\u00b7nen", "Saz", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "KOKOM", "ADV", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Die andre nimmt das Wort: Ach, Frau Gevatterin,", "tokens": ["Die", "and\u00b7re", "nimmt", "das", "Wort", ":", "Ach", ",", "Frau", "Ge\u00b7vat\u00b7te\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ART", "NN", "$.", "ITJ", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Wo denckt doch wohl ihr Arzt mit diesem Pulver hin?", "tokens": ["Wo", "denckt", "doch", "wohl", "ihr", "Arzt", "mit", "die\u00b7sem", "Pul\u00b7ver", "hin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Der Kerl ist viel zu jung, denn wenn er was verst\u00fcnde,", "tokens": ["Der", "Kerl", "ist", "viel", "zu", "jung", ",", "denn", "wenn", "er", "was", "ver\u00b7st\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$,", "KON", "KOUS", "PPER", "PIS", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "So h\u00fclf er auf mein Flehn mir schon vorl\u00e4ngst zum Kinde.", "tokens": ["So", "h\u00fclf", "er", "auf", "mein", "Flehn", "mir", "schon", "vor\u00b7l\u00e4ngst", "zum", "Kin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PPER", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "So geht die Reih herum. Da kommt denn aufs Tapet,", "tokens": ["So", "geht", "die", "Reih", "he\u00b7rum", ".", "Da", "kommt", "denn", "aufs", "Ta\u00b7pet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$.", "ADV", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.126": {"text": "Warum die Alte bunt, die Junge bucklicht geht,", "tokens": ["Wa\u00b7rum", "die", "Al\u00b7te", "bunt", ",", "die", "Jun\u00b7ge", "buck\u00b7licht", "geht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJD", "$,", "ART", "NN", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Der steht der Aufsaz schlimm, den schimpft die kleine Nase,", "tokens": ["Der", "steht", "der", "Auf\u00b7saz", "schlimm", ",", "den", "schimpft", "die", "klei\u00b7ne", "Na\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADJD", "$,", "ART", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Rinaldo riecht nach Brodt und Marx nach geilem Grase,", "tokens": ["Ri\u00b7nal\u00b7do", "riecht", "nach", "Brodt", "und", "Marx", "nach", "gei\u00b7lem", "Gra\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "KON", "NE", "APPR", "ADJA", "NN", "$,"], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.129": {"text": "Marindo scherzt zu grob, Ro\u00dfalva lacht zu laut,", "tokens": ["Ma\u00b7rin\u00b7do", "scherzt", "zu", "grob", ",", "Ro\u00df\u00b7al\u00b7va", "lacht", "zu", "laut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKA", "ADJD", "$,", "NE", "VVFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Selintes henckt den Kopf, Valvata schminckt die Haut,", "tokens": ["Se\u00b7lin\u00b7tes", "henckt", "den", "Kopf", ",", "Val\u00b7va\u00b7ta", "schminckt", "die", "Haut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Gerintho raucht zu starck, Germana tanzt zu fl\u00fcchtig,", "tokens": ["Ge\u00b7rin\u00b7tho", "raucht", "zu", "starck", ",", "Ger\u00b7ma\u00b7na", "tanzt", "zu", "fl\u00fcch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKA", "ADJD", "$,", "NE", "VVFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Und wo Brasitte steht, da ist die Luft nicht richtig.", "tokens": ["Und", "wo", "Bra\u00b7sit\u00b7te", "steht", ",", "da", "ist", "die", "Luft", "nicht", "rich\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "VVFIN", "$,", "ADV", "VAFIN", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Dies w\u00e4hrt den halben Tag, und da mu\u00df alles her", "tokens": ["Dies", "w\u00e4hrt", "den", "hal\u00b7ben", "Tag", ",", "und", "da", "mu\u00df", "al\u00b7les", "her"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$,", "KON", "ADV", "VMFIN", "PIS", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Und wenn es auch nur . . . . . . . Strumpfband w\u00e4r,", "tokens": ["Und", "wenn", "es", "auch", "nur", ".", ".", ".", ".", ".", ".", ".", "Strumpf\u00b7band", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.135": {"text": "Worum sich Herr und Knecht im Finstern rumgeschmi\u00dfen,", "tokens": ["Wo\u00b7rum", "sich", "Herr", "und", "Knecht", "im", "Fins\u00b7tern", "rum\u00b7ge\u00b7schmi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "NN", "KON", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Da\u00df Beicht- und Richterstuhl zulezt noch mitteln m\u00fc\u00dfen,", "tokens": ["Da\u00df", "Beicht", "und", "Rich\u00b7ter\u00b7stuhl", "zu\u00b7lezt", "noch", "mit\u00b7teln", "m\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "TRUNC", "KON", "NN", "ADV", "ADV", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.138": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.139": {"text": "Wo ... und Einfalt sizt und solche gern besch\u00fczen.", "tokens": ["Wo", "...", "und", "Ein\u00b7falt", "sizt", "und", "sol\u00b7che", "gern", "be\u00b7sch\u00fc\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$(", "KON", "NN", "VVFIN", "KON", "PIAT", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.140": {"text": "Doch wie die Weiber sind, die schon die Zunge spizen", "tokens": ["Doch", "wie", "die", "Wei\u00b7ber", "sind", ",", "die", "schon", "die", "Zun\u00b7ge", "spi\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "VAFIN", "$,", "PRELS", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.142": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.143": {"text": "Allein, da\u00df mancher Grei\u00df . . . . . . . . . . . . . . . . . . .", "tokens": ["Al\u00b7lein", ",", "da\u00df", "man\u00b7cher", "Grei\u00df", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["ADV", "$,", "KOUS", "PIAT", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.144": {"text": ". . . . . . . . . . . Bart von . . . und Ansehn . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "Bart", "von", ".", ".", ".", "und", "An\u00b7sehn", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "APPR", "$.", "$.", "$.", "KON", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.145": {"text": "Das ist der Striegel werth. Es tritt kein Buch ans Licht,", "tokens": ["Das", "ist", "der", "Strie\u00b7gel", "werth", ".", "Es", "tritt", "kein", "Buch", "ans", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADJD", "$.", "PPER", "VVFIN", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Es sey auch noch so nett, der Tadler kommt und sticht,", "tokens": ["Es", "sey", "auch", "noch", "so", "nett", ",", "der", "Tad\u00b7ler", "kommt", "und", "sticht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$,", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Verdirbt viel Weltgeschmack, indem er . . . richtet,", "tokens": ["Ver\u00b7dirbt", "viel", "Welt\u00b7ge\u00b7schmack", ",", "in\u00b7dem", "er", ".", ".", ".", "rich\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "KOUS", "PPER", "$.", "$.", "$.", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.148": {"text": "Und n\u00e4hrt oft sein Journal mit Fehlern, die er dichtet.", "tokens": ["Und", "n\u00e4hrt", "oft", "sein", "Jour\u00b7nal", "mit", "Feh\u00b7lern", ",", "die", "er", "dich\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPOSAT", "NN", "APPR", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Es bleibt auch nicht dabey; die Einfalt neuer Zeit", "tokens": ["Es", "bleibt", "auch", "nicht", "da\u00b7bey", ";", "die", "Ein\u00b7falt", "neu\u00b7er", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "PAV", "$.", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Vergi\u00dft [?] mit Pelletier der Alten Gr\u00fcndligkeit.", "tokens": ["Ver\u00b7gi\u00dft", "?", "mit", "Pel\u00b7le\u00b7tier", "der", "Al\u00b7ten", "Gr\u00fcnd\u00b7lig\u00b7keit", "."], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "$.", "$(", "APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.151": {"text": "Der . . . . . . den Tullius, in dem er nicht gelesen,", "tokens": ["Der", ".", ".", ".", ".", ".", ".", "den", "Tul\u00b7li\u00b7us", ",", "in", "dem", "er", "nicht", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$.", "$.", "$.", "$.", "$.", "$.", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.152": {"text": "Und jenem ist Virgil . . . . . Cicero . . . . . . Beesen.", "tokens": ["Und", "je\u00b7nem", "ist", "Vir\u00b7gil", ".", ".", ".", ".", ".", "Ci\u00b7ce\u00b7ro", ".", ".", ".", ".", ".", ".", "Bee\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "NE", "$.", "$.", "$.", "$.", "$.", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.153": {"text": "Ein Meister neuer Kunst, der sonst noch ziemlich reimt,", "tokens": ["Ein", "Meis\u00b7ter", "neu\u00b7er", "Kunst", ",", "der", "sonst", "noch", "ziem\u00b7lich", "reimt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "PRELS", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": ". . . . . . . . Schimpf [?] . . . . . . . getr\u00e4umt", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", "Schimpf", "?", ".", ".", ".", ".", ".", ".", ".", "ge\u00b7tr\u00e4umt"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "$(", "$.", "$(", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVPP"], "meter": "+", "measure": "single.up"}, "line.155": {"text": "Und da [er] den Homer. . . . . . . . . . . . . . . . . . . achtet", "tokens": ["Und", "da", "er", "den", "Ho\u00b7mer", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "ach\u00b7tet"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["KON", "KOUS", "$(", "PPER", "$(", "ART", "NE", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "XY"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.156": {"text": ". . . . . . . ., Gehirn, ich weis nicht wo, verpachtet.", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ",", "Ge\u00b7hirn", ",", "ich", "weis", "nicht", "wo", ",", "ver\u00b7pach\u00b7tet", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$,", "NN", "$,", "PPER", "PTKVZ", "PTKNEG", "PWAV", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.157": {"text": "Crispin theilt Sparren aus, und dies ist auch ein Wurm,", "tokens": ["Cris\u00b7pin", "theilt", "Spar\u00b7ren", "aus", ",", "und", "dies", "ist", "auch", "ein", "Wurm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "PTKVZ", "$,", "KON", "PDS", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Sein k\u00fchner M\u00fc\u00dfiggang lauft allenthalben Sturm", "tokens": ["Sein", "k\u00fch\u00b7ner", "M\u00fc\u00b7\u00dfig\u00b7gang", "lauft", "al\u00b7len\u00b7thal\u00b7ben", "Sturm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Und sucht sich wie ein Har\u00df an jeden Stein zu reiben;", "tokens": ["Und", "sucht", "sich", "wie", "ein", "Har\u00df", "an", "je\u00b7den", "Stein", "zu", "rei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "KOKOM", "ART", "NN", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Das Best' ist, da\u00df oft Haut und Borsten kleben bleiben.", "tokens": ["Das", "Best'", "ist", ",", "da\u00df", "oft", "Haut", "und", "Bors\u00b7ten", "kle\u00b7ben", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "KOUS", "ADV", "NN", "KON", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Sein Maul verschont sogar gelehrter Unschuld nicht,", "tokens": ["Sein", "Maul", "ver\u00b7schont", "so\u00b7gar", "ge\u00b7lehr\u00b7ter", "Un\u00b7schuld", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADJA", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Und obgleich jeder Stand [?] von seiner Einfalt spricht,", "tokens": ["Und", "ob\u00b7gleich", "je\u00b7der", "Stand", "?", "von", "sei\u00b7ner", "Ein\u00b7falt", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIAT", "NN", "$(", "$.", "$(", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.163": {"text": "So h\u00e4lt er doch vor Ruhm, durch fremde Bl\u00f6\u00df und Fluchen", "tokens": ["So", "h\u00e4lt", "er", "doch", "vor", "Ruhm", ",", "durch", "frem\u00b7de", "Bl\u00f6\u00df", "und", "Flu\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "$,", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Dem Schein [?], so ihn verstellt, ein Feigenblat zu suchen.", "tokens": ["Dem", "Schein", "?", ",", "so", "ihn", "ver\u00b7stellt", ",", "ein", "Fei\u00b7gen\u00b7blat", "zu", "su\u00b7chen", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "$.", "$(", "$,", "ADV", "PPER", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.165": {"text": "Amando hielt nur nechst ein pr\u00e4chtiges Pancket,", "tokens": ["A\u00b7man\u00b7do", "hielt", "nur", "nechst", "ein", "pr\u00e4ch\u00b7ti\u00b7ges", "Pan\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.166": {"text": "Und wie es insgeheim bey solchen . . . . . . . geht,", "tokens": ["Und", "wie", "es", "ins\u00b7ge\u00b7heim", "bey", "sol\u00b7chen", ".", ".", ".", ".", ".", ".", ".", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "APPR", "PIAT", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.167": {"text": "So fangen sie auch an mit . . . . . . Schwestern [?]", "tokens": ["So", "fan\u00b7gen", "sie", "auch", "an", "mit", ".", ".", ".", ".", ".", ".", "Schwes\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "$(", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.168": {"text": "Fast jeden Stand durch . . . . . . durchzul\u00e4stern [?].", "tokens": ["Fast", "je\u00b7den", "Stand", "durch", ".", ".", ".", ".", ".", ".", "durch\u00b7zu\u00b7l\u00e4s\u00b7tern", "?", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["ADV", "PIAT", "NN", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "VVIZU", "$(", "$.", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.169": {"text": "H\u00f6rt, was Farillo sprach: Ja, w\u00e4r ich wie Eugen,", "tokens": ["H\u00f6rt", ",", "was", "Fa\u00b7ril\u00b7lo", "sprach", ":", "Ja", ",", "w\u00e4r", "ich", "wie", "Eu\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "NN", "VVFIN", "$.", "PTKANT", "$,", "VAFIN", "PPER", "KOKOM", "NE", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.170": {"text": "Ich wollte noch den Tag in Ungern weiter gehn", "tokens": ["Ich", "woll\u00b7te", "noch", "den", "Tag", "in", "Un\u00b7gern", "wei\u00b7ter", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "APPR", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Und mit der ganzen Macht, ich schw\u00f6r auf meinen Kragen,", "tokens": ["Und", "mit", "der", "gan\u00b7zen", "Macht", ",", "ich", "schw\u00f6r", "auf", "mei\u00b7nen", "Kra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "Den Achmet durch den Belt und ganz Europa jagen.", "tokens": ["Den", "Ach\u00b7met", "durch", "den", "Belt", "und", "ganz", "Eu\u00b7ro\u00b7pa", "ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "KON", "ADV", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Calander l\u00f6st ihn ab, und weil das Contrebant", "tokens": ["Ca\u00b7lan\u00b7der", "l\u00f6st", "ihn", "ab", ",", "und", "weil", "das", "Cont\u00b7re\u00b7bant"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Ihm gestern Abend erst ein Viertel Bier entwand,", "tokens": ["Ihm", "ge\u00b7stern", "A\u00b7bend", "erst", "ein", "Vier\u00b7tel", "Bier", "ent\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "NN", "ADV", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "So flucht er dem Accis und weist des F\u00fcrsten Z\u00f6lle", "tokens": ["So", "flucht", "er", "dem", "Ac\u00b7cis", "und", "weist", "des", "F\u00fcrs\u00b7ten", "Z\u00f6l\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "KON", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Mitsamt dem R \u2013 \u2013 \u2013 von Stund an in die H\u00f6lle.", "tokens": ["Mit\u00b7samt", "dem", "R", "\u2013", "\u2013", "\u2013", "von", "Stund", "an", "in", "die", "H\u00f6l\u00b7le", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "$(", "$(", "$(", "APPR", "NN", "APPR", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.177": {"text": "Sempron, der tiefer sa\u00df und halb besofen schlief,", "tokens": ["Semp\u00b7ron", ",", "der", "tie\u00b7fer", "sa\u00df", "und", "halb", "be\u00b7so\u00b7fen", "schlief", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADJD", "VVFIN", "KON", "ADJD", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Erwachte, weil man gleich von weiten Feuer rief,", "tokens": ["Er\u00b7wach\u00b7te", ",", "weil", "man", "gleich", "von", "wei\u00b7ten", "Feu\u00b7er", "rief", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PIS", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Und da die G\u00e4ste gehn und christlich l\u00f6schen wollten,", "tokens": ["Und", "da", "die", "G\u00e4s\u00b7te", "gehn", "und", "christ\u00b7lich", "l\u00f6\u00b7schen", "woll\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVINF", "KON", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "So schrie er, da\u00df sie doch nur sehn und lachen sollten.", "tokens": ["So", "schrie", "er", ",", "da\u00df", "sie", "doch", "nur", "sehn", "und", "la\u00b7chen", "soll\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ADV", "VVINF", "KON", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Das liederliche Volck, so sprach der B\u00f6sewicht,", "tokens": ["Das", "lie\u00b7der\u00b7li\u00b7che", "Volck", ",", "so", "sprach", "der", "B\u00f6\u00b7se\u00b7wicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Verdient bey seiner Noth dergleichen H\u00fclfe nicht,", "tokens": ["Ver\u00b7di\u00b7ent", "bey", "sei\u00b7ner", "Noth", "derg\u00b7lei\u00b7chen", "H\u00fcl\u00b7fe", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PPOSAT", "NN", "PIS", "NN", "PTKNEG", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.183": {"text": "Denn mich beredt niemand, da\u00df den die Flammen schlagen,", "tokens": ["Denn", "mich", "be\u00b7redt", "nie\u00b7mand", ",", "da\u00df", "den", "die", "Flam\u00b7men", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "$,", "KOUS", "ART", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.184": {"text": "Der nicht vorher das Stroh mit S\u00fcnden zugetragen.", "tokens": ["Der", "nicht", "vor\u00b7her", "das", "Stroh", "mit", "S\u00fcn\u00b7den", "zu\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "ART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Gar recht, sprach Selimon, der gleich am Braten schnidt,", "tokens": ["Gar", "recht", ",", "sprach", "Se\u00b7li\u00b7mon", ",", "der", "gleich", "am", "Bra\u00b7ten", "schnidt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "VVFIN", "NE", "$,", "PRELS", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Es ist ein jeder Mensch sein eigner Ungl\u00fccksschmied,", "tokens": ["Es", "ist", "ein", "je\u00b7der", "Mensch", "sein", "eig\u00b7ner", "Un\u00b7gl\u00fccks\u00b7schmied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PIAT", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Und darum . . . . . ich auch kein . . . . Erbarmen,", "tokens": ["Und", "da\u00b7rum", ".", ".", ".", ".", ".", "ich", "auch", "kein", ".", ".", ".", ".", "Er\u00b7bar\u00b7men", ","], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "PAV", "$.", "$.", "$.", "$.", "$.", "PPER", "ADV", "PIAT", "$.", "$.", "$.", "$.", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.188": {"text": "Wenn tausend kl\u00e4glich thun und noch so viel verarmen.", "tokens": ["Wenn", "tau\u00b7send", "kl\u00e4g\u00b7lich", "thun", "und", "noch", "so", "viel", "ver\u00b7ar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ADJD", "VVINF", "KON", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "Ein Bettler nimmt von mir nicht einen Halmen Stroh;", "tokens": ["Ein", "Bett\u00b7ler", "nimmt", "von", "mir", "nicht", "ei\u00b7nen", "Hal\u00b7men", "Stroh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "Die Faulheit darbt mit Recht, vermeint [?] doch Salomo.", "tokens": ["Die", "Faul\u00b7heit", "darbt", "mit", "Recht", ",", "ver\u00b7meint", "?", "doch", "Sa\u00b7lo\u00b7mo", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,", "VVFIN", "$(", "$.", "$(", "ADV", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.191": {"text": "Es mag der nackte Hund sich so wie wir uns placken,", "tokens": ["Es", "mag", "der", "nack\u00b7te", "Hund", "sich", "so", "wie", "wir", "uns", "pla\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "PRF", "ADV", "KOKOM", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.192": {"text": "So kriegt er auch vor Brodt Ducaten einzupacken.", "tokens": ["So", "kriegt", "er", "auch", "vor", "Brodt", "Du\u00b7ca\u00b7ten", "ein\u00b7zu\u00b7pa\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "So schliest der b\u00f6se Mann, als wenn das gro\u00dfe Meer", "tokens": ["So", "schliest", "der", "b\u00f6\u00b7se", "Mann", ",", "als", "wenn", "das", "gro\u00b7\u00dfe", "Meer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "KOKOM", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.194": {"text": "Der Vorsicht, die uns lenckt, so leicht ergr\u00fcndlich w\u00e4r", "tokens": ["Der", "Vor\u00b7sicht", ",", "die", "uns", "lenckt", ",", "so", "leicht", "er\u00b7gr\u00fcnd\u00b7lich", "w\u00e4r"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "ADJD", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Und nicht auch dann und wann viel unschuldsvolle Christen", "tokens": ["Und", "nicht", "auch", "dann", "und", "wann", "viel", "un\u00b7schulds\u00b7vol\u00b7le", "Chris\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "ADV", "ADV", "KON", "PWAV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Aus Pr\u00fcfung h\u00f6hrer Huld [?] die Geifrer [?] f\u00fchlen m\u00fcsten.", "tokens": ["Aus", "Pr\u00fc\u00b7fung", "h\u00f6h\u00b7rer", "Huld", "?", "die", "Geif\u00b7rer", "?", "f\u00fch\u00b7len", "m\u00fcs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$(", "$.", "$(", "ART", "NN", "$(", "$.", "$(", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.197": {"text": "Ach arm- und blinder Mensch, greif deinen Busen an!", "tokens": ["Ach", "ar\u00b7m", "und", "blin\u00b7der", "Mensch", ",", "greif", "dei\u00b7nen", "Bu\u00b7sen", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "TRUNC", "KON", "ADJA", "NN", "$,", "ADJD", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.198": {"text": "Du weist, wie viel Natur und was Gewohnheit kan;", "tokens": ["Du", "weist", ",", "wie", "viel", "Na\u00b7tur", "und", "was", "Ge\u00b7wohn\u00b7heit", "kan", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PIAT", "NN", "KON", "PWS", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.199": {"text": "Von dieser hast auch du vielleicht noch manch Gebrechen,", "tokens": ["Von", "die\u00b7ser", "hast", "auch", "du", "viel\u00b7leicht", "noch", "manch", "Ge\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "ADV", "PPER", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Bey welchem andre dir den Gecken r\u00fccklings stechen.", "tokens": ["Bey", "wel\u00b7chem", "and\u00b7re", "dir", "den", "Ge\u00b7cken", "r\u00fcck\u00b7lings", "ste\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "ADJA", "PPER", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "Hilf, wenn du kanst und weist, und gieb vor dich nur Acht;", "tokens": ["Hilf", ",", "wenn", "du", "kanst", "und", "weist", ",", "und", "gieb", "vor", "dich", "nur", "Acht", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "PPER", "VMFIN", "KON", "VVFIN", "$,", "KON", "VVIMP", "APPR", "PPER", "ADV", "CARD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Der, so die Herzen pr\u00fcft und \u00fcber alles wacht,", "tokens": ["Der", ",", "so", "die", "Her\u00b7zen", "pr\u00fcft", "und", "\u00fc\u00b7ber", "al\u00b7les", "wacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "ART", "NN", "VVFIN", "KON", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.203": {"text": "Will schon zu rechter Zeit die Bo\u00dfheit ofenbahren", "tokens": ["Will", "schon", "zu", "rech\u00b7ter", "Zeit", "die", "Bo\u00df\u00b7heit", "o\u00b7fen\u00b7bah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "APPR", "ADJA", "NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.204": {"text": "Und jedes Straf und Lohn auf jenen Tag versparen.", "tokens": ["Und", "je\u00b7des", "Straf", "und", "Lohn", "auf", "je\u00b7nen", "Tag", "ver\u00b7spa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.205": {"text": "Wir wandern [?] in der Welt als Pilger, deren Fu\u00df", "tokens": ["Wir", "wan\u00b7dern", "?", "in", "der", "Welt", "als", "Pil\u00b7ger", ",", "de\u00b7ren", "Fu\u00df"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "$.", "$(", "APPR", "ART", "NN", "KOUS", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.206": {"text": "Durch viel Gefahr und Angst zur Ruhstatt wandeln mu\u00df.", "tokens": ["Durch", "viel", "Ge\u00b7fahr", "und", "Angst", "zur", "Ruh\u00b7statt", "wan\u00b7deln", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "APPRART", "NN", "VVFIN", "VMFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.207": {"text": "Wie will ein Reisender durch Spotten, Schimpf und Lachen", "tokens": ["Wie", "will", "ein", "Rei\u00b7sen\u00b7der", "durch", "Spot\u00b7ten", ",", "Schimpf", "und", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "ART", "NN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.208": {"text": "Dem andern neben sich den Weg noch saurer machen?", "tokens": ["Dem", "an\u00b7dern", "ne\u00b7ben", "sich", "den", "Weg", "noch", "sau\u00b7rer", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "PRF", "ART", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "Man weis, die Lieb ist blind und lobt oft, was verstellt.", "tokens": ["Man", "weis", ",", "die", "Lieb", "ist", "blind", "und", "lobt", "oft", ",", "was", "ver\u00b7stellt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "PTKVZ", "$,", "ART", "NN", "VAFIN", "ADJD", "KON", "VVFIN", "ADV", "$,", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.210": {"text": "Wie Floro Lenchens Mahl vor sch\u00f6n und artig h\u00e4lt,", "tokens": ["Wie", "Flo\u00b7ro", "Len\u00b7chens", "Mahl", "vor", "sch\u00f6n", "und", "ar\u00b7tig", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "NN", "APPR", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.211": {"text": "So achtet Damon nicht, da\u00df Lorchens Schenckel hauchet,", "tokens": ["So", "ach\u00b7tet", "Da\u00b7mon", "nicht", ",", "da\u00df", "Lor\u00b7chens", "Schen\u00b7ckel", "hau\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "PTKNEG", "$,", "KOUS", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.212": {"text": "Noch Philor, da\u00df sein Schaz zwey fremde Z\u00e4hne brauchet.", "tokens": ["Noch", "Phi\u00b7lor", ",", "da\u00df", "sein", "Schaz", "zwey", "frem\u00b7de", "Z\u00e4h\u00b7ne", "brau\u00b7chet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "KOUS", "PPOSAT", "NN", "CARD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.213": {"text": "Der Irrthum hat sein Lob; o w\u00e4r er allgemein,", "tokens": ["Der", "Irr\u00b7thum", "hat", "sein", "Lob", ";", "o", "w\u00e4r", "er", "all\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$.", "FM", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.214": {"text": "Wie gl\u00fccklich sollte nicht der Menschen Freundschaft seyn,", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "soll\u00b7te", "nicht", "der", "Men\u00b7schen", "Freund\u00b7schaft", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PTKNEG", "ART", "NN", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.215": {"text": "Wir . . . . . . . jederzeit, mit andern aufzuheben,", "tokens": ["Wir", ".", ".", ".", ".", ".", ".", ".", "je\u00b7der\u00b7zeit", ",", "mit", "an\u00b7dern", "auf\u00b7zu\u00b7he\u00b7ben", ","], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADV", "$,", "APPR", "PIS", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.216": {"text": "So wohl ohn \u00c4rgern\u00fc\u00df als sonder Vorwurf leben.", "tokens": ["So", "wohl", "ohn", "\u00c4r\u00b7ger\u00b7n\u00fc\u00df", "als", "son\u00b7der", "Vor\u00b7wurf", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "KOKOM", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Wer aber ist denn wohl ein klug- und weiser Mann?", "tokens": ["Wer", "a\u00b7ber", "ist", "denn", "wohl", "ein", "klug", "und", "wei\u00b7ser", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "ADV", "ART", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.218": {"text": "Der, so sich selbst nichts schenckt und Strafen [?] tragen kan,", "tokens": ["Der", ",", "so", "sich", "selbst", "nichts", "schenckt", "und", "Stra\u00b7fen", "?", "tra\u00b7gen", "kan", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "PRF", "ADV", "PIS", "VVFIN", "KON", "NN", "$(", "$.", "$(", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.219": {"text": "Des Nechsten schwachen Fu\u00df mit Lieb und Gunst regieret", "tokens": ["Des", "Nechs\u00b7ten", "schwa\u00b7chen", "Fu\u00df", "mit", "Lieb", "und", "Gunst", "re\u00b7gie\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.220": {"text": "Und, wenn er ausw\u00e4rts geht, mit Lust . . . . vorw\u00e4rts f\u00fchret.", "tokens": ["Und", ",", "wenn", "er", "aus\u00b7w\u00e4rts", "geht", ",", "mit", "Lust", ".", ".", ".", ".", "vor\u00b7w\u00e4rts", "f\u00fch\u00b7ret", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,", "APPR", "NN", "$.", "$.", "$.", "$.", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.221": {"text": "Ein solcher thut, was Gott, Natur und Zeit begehrt,", "tokens": ["Ein", "sol\u00b7cher", "thut", ",", "was", "Gott", ",", "Na\u00b7tur", "und", "Zeit", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "VVFIN", "$,", "PRELS", "NN", "$,", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "Und ist, wo nur nicht mehr, des h\u00f6chsten Thrones werth,", "tokens": ["Und", "ist", ",", "wo", "nur", "nicht", "mehr", ",", "des", "h\u00f6chs\u00b7ten", "Thro\u00b7nes", "werth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "PWAV", "ADV", "PTKNEG", "ADV", "$,", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.223": {"text": "Allein auch unter uns so selten aufzutreiben", "tokens": ["Al\u00b7lein", "auch", "un\u00b7ter", "uns", "so", "sel\u00b7ten", "auf\u00b7zu\u00b7trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "PPER", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Als Dichter, welche rein und nett und gr\u00fcndlich schreiben.", "tokens": ["Als", "Dich\u00b7ter", ",", "wel\u00b7che", "rein", "und", "nett", "und", "gr\u00fcnd\u00b7lich", "schrei\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PRELS", "ADJD", "KON", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.225": {"text": "Ein jeder schmeichelt sich aus Wahn und Selbstbetrug", "tokens": ["Ein", "je\u00b7der", "schmei\u00b7chelt", "sich", "aus", "Wahn", "und", "Selbst\u00b7be\u00b7trug"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "PRF", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "Und meint, er sey vor sich gut, heilig, fromm und klug,", "tokens": ["Und", "meint", ",", "er", "sey", "vor", "sich", "gut", ",", "hei\u00b7lig", ",", "fromm", "und", "klug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "APPR", "PRF", "ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Und sagt Gott st\u00fcndlich Danck wie jener Pharis\u00e4er.", "tokens": ["Und", "sagt", "Gott", "st\u00fcnd\u00b7lich", "Danck", "wie", "je\u00b7ner", "Pha\u00b7ri\u00b7s\u00e4\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ADJD", "NN", "KOKOM", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "Der Geiz verdorrt bey Gold und henckt und bringt sich eher", "tokens": ["Der", "Geiz", "ver\u00b7dorrt", "bey", "Gold", "und", "henckt", "und", "bringt", "sich", "e\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "KON", "VVFIN", "KON", "VVFIN", "PRF", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.229": {"text": "Um Hals und Seeligkeit, als da\u00df sein Herz der Reu", "tokens": ["Um", "Hals", "und", "See\u00b7lig\u00b7keit", ",", "als", "da\u00df", "sein", "Herz", "der", "Reu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "NN", "KON", "NN", "$,", "KOKOM", "KOUS", "PPOSAT", "NN", "ART", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.230": {"text": "Des halb verlornen Sohns verthanes Geld verzeih.", "tokens": ["Des", "halb", "ver\u00b7lor\u00b7nen", "Sohns", "ver\u00b7tha\u00b7nes", "Geld", "ver\u00b7zeih", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.231": {"text": "Der, welchen die Natur bald von Geburth verschneidet,", "tokens": ["Der", ",", "wel\u00b7chen", "die", "Na\u00b7tur", "bald", "von", "Ge\u00b7burth", "ver\u00b7schnei\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAT", "ART", "NN", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.232": {"text": "Hast alle Z\u00e4rtligkeit, an der er Mangel leidet,", "tokens": ["Hast", "al\u00b7le", "Z\u00e4rt\u00b7lig\u00b7keit", ",", "an", "der", "er", "Man\u00b7gel", "lei\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$,", "APPR", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+++-+-+-", "measure": "unknown.measure.septa"}, "line.233": {"text": "Da gegentheils Solan, der voller Geilheit tobt", "tokens": ["Da", "ge\u00b7gen\u00b7theils", "So\u00b7lan", ",", "der", "vol\u00b7ler", "Geil\u00b7heit", "tobt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "$,", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.234": {"text": "Und mit den Hengsten springt, fast keinen Dichter lobt,", "tokens": ["Und", "mit", "den", "Hengs\u00b7ten", "springt", ",", "fast", "kei\u00b7nen", "Dich\u00b7ter", "lobt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Der nicht wie er sein Maul in jeder Pf\u00fcze sp\u00fclet", "tokens": ["Der", "nicht", "wie", "er", "sein", "Maul", "in", "je\u00b7der", "Pf\u00fc\u00b7ze", "sp\u00fc\u00b7let"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "PWAV", "PPER", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.236": {"text": "Noch Adams Raserey mit Evens \u00c4pfeln k\u00fchlet.", "tokens": ["Noch", "A\u00b7dams", "Ra\u00b7se\u00b7rey", "mit", "E\u00b7vens", "\u00c4p\u00b7feln", "k\u00fch\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Die bla\u00dfe Caelia, die Ruhm in Schande sucht,", "tokens": ["Die", "bla\u00b7\u00dfe", "Cae\u00b7lia", ",", "die", "Ruhm", "in", "Schan\u00b7de", "sucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.238": {"text": "Ersticket durch viel Thee selbst ungebohrne Frucht,", "tokens": ["Er\u00b7sti\u00b7cket", "durch", "viel", "Thee", "selbst", "un\u00b7ge\u00b7bohr\u00b7ne", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.239": {"text": "Beschimpft den braven Mann und macht wie Messaline", "tokens": ["Be\u00b7schimpft", "den", "bra\u00b7ven", "Mann", "und", "macht", "wie", "Mes\u00b7sa\u00b7li\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "KON", "VVFIN", "KOKOM", "NE"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.240": {"text": "Korn, Kirchstuhl, Sommerhaus, Stall, Heu und Opernb\u00fchne", "tokens": ["Korn", ",", "Kirch\u00b7stuhl", ",", "Som\u00b7mer\u00b7haus", ",", "Stall", ",", "Heu", "und", "O\u00b7pern\u00b7b\u00fch\u00b7ne"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.241": {"text": "Zum Schauplaz ihrer Brunst und untersteht sich doch,", "tokens": ["Zum", "Schau\u00b7plaz", "ih\u00b7rer", "Brunst", "und", "un\u00b7ter\u00b7steht", "sich", "doch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "KON", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.242": {"text": "Der armen Kammermagd, die endlich . . . . . das Joch", "tokens": ["Der", "ar\u00b7men", "Kam\u00b7mer\u00b7magd", ",", "die", "end\u00b7lich", ".", ".", ".", ".", ".", "das", "Joch"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "$.", "$.", "$.", "$.", "$.", "ART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.243": {"text": "Des schweren Kranzes bricht, den Himmel zu verschlie\u00dfen,", "tokens": ["Des", "schwe\u00b7ren", "Kran\u00b7zes", "bricht", ",", "den", "Him\u00b7mel", "zu", "ver\u00b7schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.244": {"text": "Da sie doch selbst verdient, in Oel und Pech zu flie\u00dfen.", "tokens": ["Da", "sie", "doch", "selbst", "ver\u00b7dient", ",", "in", "O\u00b7el", "und", "Pech", "zu", "flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "$,", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}}}}