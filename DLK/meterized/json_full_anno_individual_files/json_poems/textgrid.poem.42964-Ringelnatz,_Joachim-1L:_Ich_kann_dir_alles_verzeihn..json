{"textgrid.poem.42964": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich kann dir alles verzeihn.", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich kann dir alles verzeihn.", "tokens": ["Ich", "kann", "dir", "al\u00b7les", "ver\u00b7zeihn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Aber du mu\u00dft mir die Freiheit lassen,", "tokens": ["A\u00b7ber", "du", "mu\u00dft", "mir", "die", "Frei\u00b7heit", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Mich nicht mehr mit dir zu befassen.", "tokens": ["Mich", "nicht", "mehr", "mit", "dir", "zu", "be\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "S\u00e4chsische Quengelein,", "tokens": ["S\u00e4ch\u00b7si\u00b7sche", "Quen\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Auch wenn man ihrer nur tr\u00e4umt,", "tokens": ["Auch", "wenn", "man", "ih\u00b7rer", "nur", "tr\u00e4umt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "PPOSAT", "ADV", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Sind etwas, womit man die Zeit vers\u00e4umt.", "tokens": ["Sind", "et\u00b7was", ",", "wo\u00b7mit", "man", "die", "Zeit", "ver\u00b7s\u00e4umt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "PWAV", "PIS", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.2": {"line.1": {"text": "Du hast viel warmes Gem\u00fct", "tokens": ["Du", "hast", "viel", "war\u00b7mes", "Ge\u00b7m\u00fct"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Und l\u00fcgst oft aus H\u00f6flichkeit.", "tokens": ["Und", "l\u00fcgst", "oft", "aus", "H\u00f6f\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Und auf diesem Boden bl\u00fcht", "tokens": ["Und", "auf", "die\u00b7sem", "Bo\u00b7den", "bl\u00fcht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und gedeiht die Geschmacklosigkeit.", "tokens": ["Und", "ge\u00b7deiht", "die", "Ge\u00b7schmack\u00b7lo\u00b7sig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.3": {"line.1": {"text": "Ich wei\u00df das genau. Denn ich bin", "tokens": ["Ich", "wei\u00df", "das", "ge\u00b7nau", ".", "Denn", "ich", "bin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJD", "$.", "KON", "PPER", "VAFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "In Sachsen erwachsen. Das zu verschweigen", "tokens": ["In", "Sach\u00b7sen", "er\u00b7wach\u00b7sen", ".", "Das", "zu", "ver\u00b7schwei\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "VVPP", "$.", "PDS", "PTKZU", "VVINF"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Oder deswegen mokant sich zu zeigen,", "tokens": ["O\u00b7der", "des\u00b7we\u00b7gen", "mo\u00b7kant", "sich", "zu", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VMFIN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "H\u00e4tte nicht \u2013 \u2013 oder nur s\u00e4chsischen Sinn.", "tokens": ["H\u00e4t\u00b7te", "nicht", "\u2013", "\u2013", "o\u00b7der", "nur", "s\u00e4ch\u00b7si\u00b7schen", "Sinn", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$(", "$(", "KON", "ADV", "ADJA", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich kann deiner Falschheit nicht trauen.", "tokens": ["Ich", "kann", "dei\u00b7ner", "Falschheit", "nicht", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Geh jetzt zur Ruh!", "tokens": ["Geh", "jetzt", "zur", "Ruh", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPRART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Blondhaarig mit schwarzen Brauen,", "tokens": ["Blond\u00b7haa\u00b7rig", "mit", "schwar\u00b7zen", "Brau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "So sch\u00f6nes M\u00e4dchen du!", "tokens": ["So", "sch\u00f6\u00b7nes", "M\u00e4d\u00b7chen", "du", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Aussichten sind unendlich weit.", "tokens": ["Aus\u00b7sich\u00b7ten", "sind", "un\u00b7end\u00b7lich", "weit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aber S\u00e4chsisch in dieser Zeit,", "tokens": ["A\u00b7ber", "S\u00e4ch\u00b7sisch", "in", "die\u00b7ser", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Eins, Neun, Zwo, Acht \u2013 \u2013 \u2013", "tokens": ["Eins", ",", "Neun", ",", "Zwo", ",", "Acht", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["NN", "$,", "CARD", "$,", "CARD", "$,", "CARD", "$(", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Gute Nacht.", "tokens": ["Gu\u00b7te", "Nacht", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Als sie dann traurig ging,", "tokens": ["Als", "sie", "dann", "trau\u00b7rig", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ward mir so bang und kalt.", "tokens": ["Ward", "mir", "so", "bang", "und", "kalt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Gab ich ihr keinen Halt.", "tokens": ["Gab", "ich", "ihr", "kei\u00b7nen", "Halt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Armes Ding!", "tokens": ["Ar\u00b7mes", "Ding", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Ich kann dir alles verzeihn.", "tokens": ["Ich", "kann", "dir", "al\u00b7les", "ver\u00b7zeihn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Aber du mu\u00dft mir die Freiheit lassen,", "tokens": ["A\u00b7ber", "du", "mu\u00dft", "mir", "die", "Frei\u00b7heit", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Mich nicht mehr mit dir zu befassen.", "tokens": ["Mich", "nicht", "mehr", "mit", "dir", "zu", "be\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "S\u00e4chsische Quengelein,", "tokens": ["S\u00e4ch\u00b7si\u00b7sche", "Quen\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Auch wenn man ihrer nur tr\u00e4umt,", "tokens": ["Auch", "wenn", "man", "ih\u00b7rer", "nur", "tr\u00e4umt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "PPOSAT", "ADV", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Sind etwas, womit man die Zeit vers\u00e4umt.", "tokens": ["Sind", "et\u00b7was", ",", "wo\u00b7mit", "man", "die", "Zeit", "ver\u00b7s\u00e4umt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "PWAV", "PIS", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.8": {"line.1": {"text": "Du hast viel warmes Gem\u00fct", "tokens": ["Du", "hast", "viel", "war\u00b7mes", "Ge\u00b7m\u00fct"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Und l\u00fcgst oft aus H\u00f6flichkeit.", "tokens": ["Und", "l\u00fcgst", "oft", "aus", "H\u00f6f\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Und auf diesem Boden bl\u00fcht", "tokens": ["Und", "auf", "die\u00b7sem", "Bo\u00b7den", "bl\u00fcht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und gedeiht die Geschmacklosigkeit.", "tokens": ["Und", "ge\u00b7deiht", "die", "Ge\u00b7schmack\u00b7lo\u00b7sig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.9": {"line.1": {"text": "Ich wei\u00df das genau. Denn ich bin", "tokens": ["Ich", "wei\u00df", "das", "ge\u00b7nau", ".", "Denn", "ich", "bin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJD", "$.", "KON", "PPER", "VAFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "In Sachsen erwachsen. Das zu verschweigen", "tokens": ["In", "Sach\u00b7sen", "er\u00b7wach\u00b7sen", ".", "Das", "zu", "ver\u00b7schwei\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "VVPP", "$.", "PDS", "PTKZU", "VVINF"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Oder deswegen mokant sich zu zeigen,", "tokens": ["O\u00b7der", "des\u00b7we\u00b7gen", "mo\u00b7kant", "sich", "zu", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VMFIN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "H\u00e4tte nicht \u2013 \u2013 oder nur s\u00e4chsischen Sinn.", "tokens": ["H\u00e4t\u00b7te", "nicht", "\u2013", "\u2013", "o\u00b7der", "nur", "s\u00e4ch\u00b7si\u00b7schen", "Sinn", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$(", "$(", "KON", "ADV", "ADJA", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.10": {"line.1": {"text": "Ich kann deiner Falschheit nicht trauen.", "tokens": ["Ich", "kann", "dei\u00b7ner", "Falschheit", "nicht", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Geh jetzt zur Ruh!", "tokens": ["Geh", "jetzt", "zur", "Ruh", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPRART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Blondhaarig mit schwarzen Brauen,", "tokens": ["Blond\u00b7haa\u00b7rig", "mit", "schwar\u00b7zen", "Brau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "So sch\u00f6nes M\u00e4dchen du!", "tokens": ["So", "sch\u00f6\u00b7nes", "M\u00e4d\u00b7chen", "du", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Aussichten sind unendlich weit.", "tokens": ["Aus\u00b7sich\u00b7ten", "sind", "un\u00b7end\u00b7lich", "weit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aber S\u00e4chsisch in dieser Zeit,", "tokens": ["A\u00b7ber", "S\u00e4ch\u00b7sisch", "in", "die\u00b7ser", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Eins, Neun, Zwo, Acht \u2013 \u2013 \u2013", "tokens": ["Eins", ",", "Neun", ",", "Zwo", ",", "Acht", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["NN", "$,", "CARD", "$,", "CARD", "$,", "CARD", "$(", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Gute Nacht.", "tokens": ["Gu\u00b7te", "Nacht", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.12": {"line.1": {"text": "Als sie dann traurig ging,", "tokens": ["Als", "sie", "dann", "trau\u00b7rig", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ward mir so bang und kalt.", "tokens": ["Ward", "mir", "so", "bang", "und", "kalt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Gab ich ihr keinen Halt.", "tokens": ["Gab", "ich", "ihr", "kei\u00b7nen", "Halt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Armes Ding!", "tokens": ["Ar\u00b7mes", "Ding", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}