{"textgrid.poem.24022": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "Hoher Besuch", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Brandrot das Haar, ein violetter Hut", "tokens": ["Brand\u00b7rot", "das", "Haar", ",", "ein", "vi\u00b7o\u00b7let\u00b7ter", "Hut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit schwarzem Schleier und orangenen R\u00fcschen,", "tokens": ["Mit", "schwar\u00b7zem", "Schlei\u00b7er", "und", "o\u00b7ran\u00b7ge\u00b7nen", "R\u00fc\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Braun das Jackett, die Boa: gelber Fuchs,", "tokens": ["Braun", "das", "Ja\u00b7ckett", ",", "die", "Boa", ":", "gel\u00b7ber", "Fuchs", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "ART", "NN", "$.", "APPR", "NE", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Der Rock marineblaues Tuch mit Schwarz.", "tokens": ["Der", "Rock", "ma\u00b7ri\u00b7ne\u00b7blau\u00b7es", "Tuch", "mit", "Schwarz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ich sinke in die Kniee: \u00bbHerzogin!", "tokens": ["Ich", "sin\u00b7ke", "in", "die", "Kni\u00b7ee", ":", "\u00bb", "Her\u00b7zo\u00b7gin", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$.", "$(", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Tritt \u00fcber meinen Nacken in mein Haus!", "tokens": ["Tritt", "\u00fc\u00b7ber", "mei\u00b7nen", "Na\u00b7cken", "in", "mein", "Haus", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "All meine Vers-D\u00e4monen blasen Tusch,", "tokens": ["All", "mei\u00b7ne", "Ver\u00b7sD\u00e4\u00b7mo\u00b7nen", "bla\u00b7sen", "Tusch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und auf dem Tisch von Palisanderholz", "tokens": ["Und", "auf", "dem", "Tisch", "von", "Pa\u00b7li\u00b7san\u00b7der\u00b7holz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Harrt seiner Herrin ein Carton \u203aMarquis\u2039", "tokens": ["Harrt", "sei\u00b7ner", "Her\u00b7rin", "ein", "Car\u00b7ton", "\u203a", "Mar\u00b7quis", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "NE", "$(", "NE", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Der besten parf\u00fcmierten Pralin\u00e9s.\u00ab", "tokens": ["Der", "bes\u00b7ten", "par\u00b7f\u00fc\u00b7mier\u00b7ten", "Pra\u00b7lin\u00e9s", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.3": {"line.1": {"text": "\u2013 Schnabunkel! sagt sie, zieht das Ohr mir lang,", "tokens": ["\u2013", "Schna\u00b7bun\u00b7kel", "!", "sagt", "sie", ",", "zieht", "das", "Ohr", "mir", "lang", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$.", "VVFIN", "PPER", "$,", "VVFIN", "ART", "NN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "K\u00fc\u00dft mich (wie riecht sie frisch!) hastig und schnell", "tokens": ["K\u00fc\u00dft", "mich", "(", "wie", "riecht", "sie", "frisch", "!", ")", "has\u00b7tig", "und", "schnell"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$(", "PWAV", "VVFIN", "PPER", "ADJD", "$.", "$(", "ADJD", "KON", "ADJD"], "meter": "+--+-++--+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und setzt sich in das gelbe Kanapee.", "tokens": ["Und", "setzt", "sich", "in", "das", "gel\u00b7be", "Ka\u00b7na\u00b7pee", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "\u2013 Bonbons! befiehlt sie. \u00bbHier!\u00ab Den Schleier hoch,", "tokens": ["\u2013", "Bon\u00b7bons", "!", "be\u00b7fiehlt", "sie", ".", "\u00bb", "Hier", "!", "\u00ab", "Den", "Schlei\u00b7er", "hoch", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$.", "VVFIN", "PPER", "$.", "$(", "ADV", "$.", "$(", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und in die braune Schokolade senkt", "tokens": ["Und", "in", "die", "brau\u00b7ne", "Scho\u00b7ko\u00b7la\u00b7de", "senkt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sich wei\u00df das allerschneeigste Gebi\u00df.", "tokens": ["Sich", "wei\u00df", "das", "al\u00b7ler\u00b7schne\u00b7e\u00b7igs\u00b7te", "Ge\u00b7bi\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.4": {"line.1": {"text": "\u00bbund was befiehlt die rote Herzogin!\u00ab", "tokens": ["\u00bb", "und", "was", "be\u00b7fiehlt", "die", "ro\u00b7te", "Her\u00b7zo\u00b7gin", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PWS", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u2013 Sie w\u00fcnscht geliebt zu sein.", "tokens": ["\u2013", "Sie", "w\u00fcnscht", "ge\u00b7liebt", "zu", "sein", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbsofort Madam?\u00ab", "tokens": ["\u00bb", "so\u00b7fort", "Ma\u00b7dam", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "NN", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "\u2013 Sofort und sehr. Man k\u00fcsse mich enorm!", "tokens": ["\u2013", "So\u00b7fort", "und", "sehr", ".", "Man", "k\u00fcs\u00b7se", "mich", "en\u00b7orm", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "KON", "ADV", "$.", "PIS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbbelieben Eure Hoheit nicht erst das Jackett ...?\u00ab", "tokens": ["\u00bb", "be\u00b7lie\u00b7ben", "Eu\u00b7re", "Ho\u00b7heit", "nicht", "erst", "das", "Ja\u00b7ckett", "...", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "VVFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "ART", "NN", "$(", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich w\u00fcnsche im Jackett geliebt zu sein.", "tokens": ["Ich", "w\u00fcn\u00b7sche", "im", "Ja\u00b7ckett", "ge\u00b7liebt", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbdoch wenigstens den Schleier ab, Madam ...?\u00ab", "tokens": ["\u00bb", "doch", "we\u00b7nigs\u00b7tens", "den", "Schlei\u00b7er", "ab", ",", "Ma\u00b7dam", "...", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "ART", "NN", "PTKVZ", "$,", "NN", "$(", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u2013 Genehmigt!", "tokens": ["\u2013", "Ge\u00b7neh\u00b7migt", "!"], "token_info": ["punct", "word", "punct"], "pos": ["$(", "VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Das Gegitter auf den Tisch.", "tokens": ["Das", "Ge\u00b7git\u00b7ter", "auf", "den", "Tisch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wir k\u00fcssen uns. Sie dr\u00fcckt mich fest an sich,", "tokens": ["Wir", "k\u00fcs\u00b7sen", "uns", ".", "Sie", "dr\u00fcckt", "mich", "fest", "an", "sich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "PPER", "ADJD", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der gelbe Fuchs umkitzelt meinen Hals.", "tokens": ["Der", "gel\u00b7be", "Fuchs", "um\u00b7kit\u00b7zelt", "mei\u00b7nen", "Hals", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "\u2013 Ich bin sehr gn\u00e4dig heute, findst du nicht?", "tokens": ["\u2013", "Ich", "bin", "sehr", "gn\u00e4\u00b7dig", "heu\u00b7te", ",", "findst", "du", "nicht", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "ADV", "$,", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbich finde, da\u00df Ihr immer huldreich seid.\u00ab", "tokens": ["\u00bb", "ich", "fin\u00b7de", ",", "da\u00df", "Ihr", "im\u00b7mer", "huld\u00b7reich", "seid", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u2013 Ich bin zu gut f\u00fcr diese Welt. Sag mal:", "tokens": ["\u2013", "Ich", "bin", "zu", "gut", "f\u00fcr", "die\u00b7se", "Welt", ".", "Sag", "mal", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PTKA", "ADJD", "APPR", "PDAT", "NN", "$.", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wei\u00dft du denn, wer ich bin? \u00bbI, keine Spur!\u00ab", "tokens": ["Wei\u00dft", "du", "denn", ",", "wer", "ich", "bin", "?", "\u00bb", "I", ",", "kei\u00b7ne", "Spur", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWS", "PPER", "VAFIN", "$.", "$(", "XY", "$,", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u2013 Und willst es auch nicht wissen? \u2013 \u00bbPfui, wer wird,", "tokens": ["\u2013", "Und", "willst", "es", "auch", "nicht", "wis\u00b7sen", "?", "\u2013", "\u00bb", "Pfui", ",", "wer", "wird", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KON", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$.", "$(", "$(", "NN", "$,", "PWS", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Neugierig sein, wenn er im Gl\u00fccke sitzt!?", "tokens": ["Neu\u00b7gie\u00b7rig", "sein", ",", "wenn", "er", "im", "Gl\u00fc\u00b7cke", "sitzt", "!?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "$,", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Du bist mir meine rote Herzogin,", "tokens": ["Du", "bist", "mir", "mei\u00b7ne", "ro\u00b7te", "Her\u00b7zo\u00b7gin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Denn deine Grazie, dein Wuchs, dein Gang,", "tokens": ["Denn", "dei\u00b7ne", "Gra\u00b7zie", ",", "dein", "Wuchs", ",", "dein", "Gang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Die Art, wie du die Handschuh von den Fingern streifst,", "tokens": ["Die", "Art", ",", "wie", "du", "die", "Hand\u00b7schuh", "von", "den", "Fin\u00b7gern", "streifst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie du den Kopf zur\u00fcckbeugst, k\u00fc\u00df ich dich,", "tokens": ["Wie", "du", "den", "Kopf", "zu\u00b7r\u00fcck\u00b7beugst", ",", "k\u00fc\u00df", "ich", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "PRF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Wie du Bonbons i\u00dfst, l\u00e4chelst, dir den Schleier steckst,", "tokens": ["Wie", "du", "Bon\u00b7bons", "i\u00df\u00b7st", ",", "l\u00e4\u00b7chelst", ",", "dir", "den", "Schlei\u00b7er", "steckst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVFIN", "$,", "VVFIN", "$,", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.12": {"text": "Und, ach, die Art, wie du mich k\u00fc\u00dfst, Madam,", "tokens": ["Und", ",", "ach", ",", "die", "Art", ",", "wie", "du", "mich", "k\u00fc\u00df\u00b7st", ",", "Ma\u00b7dam", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "ITJ", "$,", "ART", "NN", "$,", "PWAV", "PPER", "PRF", "VVFIN", "$,", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.13": {"text": "Ist herzoglich, \u2013 ich sagte k\u00f6niglich,", "tokens": ["Ist", "her\u00b7zog\u00b7lich", ",", "\u2013", "ich", "sag\u00b7te", "k\u00f6\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "$(", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "W\u00e4r mir dies Wort f\u00fcr dich nicht zu verbraucht.", "tokens": ["W\u00e4r", "mir", "dies", "Wort", "f\u00fcr", "dich", "nicht", "zu", "ver\u00b7braucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "NN", "APPR", "PPER", "PTKNEG", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Und nun zu denken, da\u00df dein Mann vielleicht", "tokens": ["Und", "nun", "zu", "den\u00b7ken", ",", "da\u00df", "dein", "Mann", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "$,", "KOUS", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Banquier ist, Rechtsanwalt, Professor, Arzt,", "tokens": ["Ban\u00b7qui\u00b7er", "ist", ",", "Rechts\u00b7an\u00b7walt", ",", "Pro\u00b7fes\u00b7sor", ",", "Arzt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Major, Regierungsrat, Gro\u00dfbrauer, Maler,", "tokens": ["Ma\u00b7jor", ",", "Re\u00b7gie\u00b7rungs\u00b7rat", ",", "Gro\u00df\u00b7brau\u00b7er", ",", "Ma\u00b7ler", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+--+--++-+-", "measure": "dactylic.di.plus"}, "line.18": {"text": "Kurz irgend was, dem man begegnen kann,", "tokens": ["Kurz", "ir\u00b7gend", "was", ",", "dem", "man", "be\u00b7geg\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "PIS", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Im Trambahnwagen, auf der Stra\u00dfe, im Caf\u00e9 \u2013", "tokens": ["Im", "Tram\u00b7bahn\u00b7wa\u00b7gen", ",", "auf", "der", "Stra\u00b7\u00dfe", ",", "im", "Ca\u00b7f\u00e9", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ART", "NN", "$,", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Entsetzlich! Nein, du bist die Herzogin.", "tokens": ["Ent\u00b7setz\u00b7lich", "!", "Nein", ",", "du", "bist", "die", "Her\u00b7zo\u00b7gin", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "PTKANT", "$,", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Dein Mann (sie l\u00e4chelt seltsam) wohnt im Schlo\u00df,", "tokens": ["Dein", "Mann", "(", "sie", "l\u00e4\u00b7chelt", "selt\u00b7sam", ")", "wohnt", "im", "Schlo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPER", "VVFIN", "ADJD", "$(", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Ist alt und gn\u00e4dig, geistreich, tolerant,", "tokens": ["Ist", "alt", "und", "gn\u00e4\u00b7dig", ",", "geist\u00b7reich", ",", "to\u00b7le\u00b7rant", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Tr\u00e4gt Escarpins, Jabots, sagt ma ch\u00e9rie,", "tokens": ["Tr\u00e4gt", "E\u00b7scar\u00b7pins", ",", "Ja\u00b7bots", ",", "sagt", "ma", "ch\u00e9rie", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "NE", "$,", "VVFIN", "NE", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.24": {"text": "Regiert ein Volk, das sehr zufrieden ist,", "tokens": ["Re\u00b7giert", "ein", "Volk", ",", "das", "sehr", "zu\u00b7frie\u00b7den", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "PRELS", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Pflegt das Ballet, liebt altes Porzellan,", "tokens": ["Pflegt", "das", "Bal\u00b7let", ",", "liebt", "al\u00b7tes", "Por\u00b7zel\u00b7lan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.26": {"text": "Bl\u00e4st etwas Fl\u00f6te, h\u00fcstelt in die Hand,", "tokens": ["Bl\u00e4st", "et\u00b7was", "Fl\u00f6\u00b7te", ",", "h\u00fcs\u00b7telt", "in", "die", "Hand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Hat hie und da ein bischen Podagra", "tokens": ["Hat", "hie", "und", "da", "ein", "bi\u00b7schen", "Po\u00b7da\u00b7gra"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.28": {"text": "Und l\u00e4chelt etwas schmerzlich, wenn er h\u00f6rt,", "tokens": ["Und", "l\u00e4\u00b7chelt", "et\u00b7was", "schmerz\u00b7lich", ",", "wenn", "er", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Die Liebe sei ein g\u00f6ttliches Pl\u00e4sier,", "tokens": ["Die", "Lie\u00b7be", "sei", "ein", "g\u00f6tt\u00b7li\u00b7ches", "Pl\u00e4\u00b7sier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Kurz, Serenissimus ist comme il faut", "tokens": ["Kurz", ",", "Se\u00b7re\u00b7nis\u00b7si\u00b7mus", "ist", "com\u00b7me", "il", "faut"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.31": {"text": "Und hat nicht viel dagegen einzuwenden,", "tokens": ["Und", "hat", "nicht", "viel", "da\u00b7ge\u00b7gen", "ein\u00b7zu\u00b7wen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "PAV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Da\u00df Serenissima den Dichter k\u00fc\u00dft,", "tokens": ["Da\u00df", "Se\u00b7re\u00b7nis\u00b7si\u00b7ma", "den", "Dich\u00b7ter", "k\u00fc\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "Der schon manch Carmen ihm zu Ehren sang", "tokens": ["Der", "schon", "manch", "Car\u00b7men", "ihm", "zu", "Eh\u00b7ren", "sang"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PIAT", "NN", "PPER", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Und am orange-gr\u00fcnen Band das Kreuz", "tokens": ["Und", "am", "o\u00b7ran\u00b7ge\u00b7gr\u00fc\u00b7nen", "Band", "das", "Kreuz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Vom wei\u00dfen Papageienorden tr\u00e4gt.\u00ab", "tokens": ["Vom", "wei\u00b7\u00dfen", "Pa\u00b7pa\u00b7gei\u00b7en\u00b7or\u00b7den", "tr\u00e4gt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "\u2013 Oh mein Schnabunkel, welch ein Narr du bist!", "tokens": ["\u2013", "Oh", "mein", "Schna\u00b7bun\u00b7kel", ",", "welch", "ein", "Narr", "du", "bist", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "XY", "PPOSAT", "NN", "$,", "PWAT", "ART", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In deinem gelben Kanapee verge\u00df ich", "tokens": ["In", "dei\u00b7nem", "gel\u00b7ben", "Ka\u00b7na\u00b7pee", "ver\u00b7ge\u00df", "ich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sehr viel, \u2013 verge\u00df ich mich und bin ein Kind,", "tokens": ["Sehr", "viel", ",", "\u2013", "ver\u00b7ge\u00df", "ich", "mich", "und", "bin", "ein", "Kind", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "$(", "VVFIN", "PPER", "PRF", "KON", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Leichtsinnig, treulos, hingegeben, \u2013 gut.", "tokens": ["Leicht\u00b7sin\u00b7nig", ",", "treu\u00b7los", ",", "hin\u00b7ge\u00b7ge\u00b7ben", ",", "\u2013", "gut", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "VVPP", "$,", "$(", "ADJD", "$."], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.5": {"text": "Nein, du sollst nie erfahren, wer ich bin.", "tokens": ["Nein", ",", "du", "sollst", "nie", "er\u00b7fah\u00b7ren", ",", "wer", "ich", "bin", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "ADV", "VVINF", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wir wollen hier in diesem kleinen Haus", "tokens": ["Wir", "wol\u00b7len", "hier", "in", "die\u00b7sem", "klei\u00b7nen", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Verstecken spielen vor uns selbst, nicht wahr,", "tokens": ["Ver\u00b7ste\u00b7cken", "spie\u00b7len", "vor", "uns", "selbst", ",", "nicht", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPER", "ADV", "$,", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und gl\u00fccklich sein, weil wir blo\u00df Menschen sind,", "tokens": ["Und", "gl\u00fcck\u00b7lich", "sein", ",", "weil", "wir", "blo\u00df", "Men\u00b7schen", "sind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAINF", "$,", "KOUS", "PPER", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Nicht der und der und die und die \u2013 blo\u00df ich und du.", "tokens": ["Nicht", "der", "und", "der", "und", "die", "und", "die", "\u2013", "blo\u00df", "ich", "und", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "KON", "ART", "KON", "ART", "KON", "ART", "$(", "ADV", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Auch sei nicht Treue hier geschworen, und", "tokens": ["Auch", "sei", "nicht", "Treu\u00b7e", "hier", "ge\u00b7schwo\u00b7ren", ",", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "PTKNEG", "NN", "ADV", "VVPP", "$,", "KON"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Kein Band gekn\u00fcpft; das Heute ist uns hold,", "tokens": ["Kein", "Band", "ge\u00b7kn\u00fcpft", ";", "das", "Heu\u00b7te", "ist", "uns", "hold", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$.", "ART", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Das Morgen m\u00f6g es sein; was sp\u00e4ter kommt,", "tokens": ["Das", "Mor\u00b7gen", "m\u00f6g", "es", "sein", ";", "was", "sp\u00e4\u00b7ter", "kommt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VAINF", "$.", "PWS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Das mag die G\u00f6tter k\u00fcmmern, die es walten;", "tokens": ["Das", "mag", "die", "G\u00f6t\u00b7ter", "k\u00fcm\u00b7mern", ",", "die", "es", "wal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "VVINF", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Uns w\u00e4chst kein graues Haar um dies Vielleicht.", "tokens": ["Uns", "w\u00e4chst", "kein", "grau\u00b7es", "Haar", "um", "dies", "Viel\u00b7leicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "APPR", "PDS", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "K\u00fc\u00df mich, Schnabunkel! Serenissima", "tokens": ["K\u00fc\u00df", "mich", ",", "Schna\u00b7bun\u00b7kel", "!", "Se\u00b7re\u00b7nis\u00b7si\u00b7ma"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["VVIMP", "PPER", "$,", "NN", "$.", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Ist k\u00fcssedurstig und so sehr verliebt", "tokens": ["Ist", "k\u00fcs\u00b7se\u00b7durs\u00b7tig", "und", "so", "sehr", "ver\u00b7liebt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "KON", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "In diesen Herrn vom gelben Kanapee,", "tokens": ["In", "die\u00b7sen", "Herrn", "vom", "gel\u00b7ben", "Ka\u00b7na\u00b7pee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Da\u00df sie nichts hat, was nicht auch ihm geh\u00f6rte.", "tokens": ["Da\u00df", "sie", "nichts", "hat", ",", "was", "nicht", "auch", "ihm", "ge\u00b7h\u00f6r\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VAFIN", "$,", "PRELS", "PTKNEG", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Sie lebt nur hier; was drau\u00dfen ist, ist Tod;", "tokens": ["Sie", "lebt", "nur", "hier", ";", "was", "drau\u00b7\u00dfen", "ist", ",", "ist", "Tod", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "PWS", "ADV", "VAFIN", "$,", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Ein Vers von dir, ihr in das Herz gehaucht,", "tokens": ["Ein", "Vers", "von", "dir", ",", "ihr", "in", "das", "Herz", "ge\u00b7haucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$,", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Ist Lebens mehr, als alle ihre Welt.", "tokens": ["Ist", "Le\u00b7bens", "mehr", ",", "als", "al\u00b7le", "ih\u00b7re", "Welt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "$,", "KOUS", "PIS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Hier ist ihr Traum, und sie genie\u00dft ihn ganz,", "tokens": ["Hier", "ist", "ihr", "Traum", ",", "und", "sie", "ge\u00b7nie\u00dft", "ihn", "ganz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Sieht alles gl\u00e4nzend, wies im Traumland ist,", "tokens": ["Sieht", "al\u00b7les", "gl\u00e4n\u00b7zend", ",", "wies", "im", "Traum\u00b7land", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "$,", "VVFIN", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "F\u00fchlt alles hundertfach, weil sie es tr\u00e4umt.", "tokens": ["F\u00fchlt", "al\u00b7les", "hun\u00b7dert\u00b7fach", ",", "weil", "sie", "es", "tr\u00e4umt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Du bist mein Page, reizend und verrucht,", "tokens": ["Du", "bist", "mein", "Pa\u00b7ge", ",", "rei\u00b7zend", "und", "ver\u00b7rucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Ich schlich zu dir, die Nacht war warm und feucht,", "tokens": ["Ich", "schlich", "zu", "dir", ",", "die", "Nacht", "war", "warm", "und", "feucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "PPER", "$,", "ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Aus meinem Bette in den Pavillon,", "tokens": ["Aus", "mei\u00b7nem", "Bet\u00b7te", "in", "den", "Pa\u00b7vil\u00b7lon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Die Sterne blinzeln, und die Nachtigall", "tokens": ["Die", "Ster\u00b7ne", "blin\u00b7zeln", ",", "und", "die", "Nach\u00b7ti\u00b7gall"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Schluchzt Liebe aus der Laube von Jasmin.", "tokens": ["Schluchzt", "Lie\u00b7be", "aus", "der", "Lau\u00b7be", "von", "Jas\u00b7min", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.30": {"text": "Das Leben ist ein Abenteurerspiel,", "tokens": ["Das", "Le\u00b7ben", "ist", "ein", "A\u00b7bent\u00b7eu\u00b7rer\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Gefahr giebt hei\u00dfe S\u00fc\u00dfe dem Genu\u00df,", "tokens": ["Ge\u00b7fahr", "giebt", "hei\u00b7\u00dfe", "S\u00fc\u00b7\u00dfe", "dem", "Ge\u00b7nu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Die S\u00fcnde ist ein wunderbarer Trost", "tokens": ["Die", "S\u00fcn\u00b7de", "ist", "ein", "wun\u00b7der\u00b7ba\u00b7rer", "Trost"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "Im Leben, das so trostlos grade geht.", "tokens": ["Im", "Le\u00b7ben", ",", "das", "so", "trost\u00b7los", "gra\u00b7de", "geht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "ADV", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Ich habe keine Kunst: was S\u00fcnde hei\u00dft,", "tokens": ["Ich", "ha\u00b7be", "kei\u00b7ne", "Kunst", ":", "was", "S\u00fcn\u00b7de", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$.", "PWS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "\u00bbich sehe, da\u00df dein Mund ein Leuchten hat", "tokens": ["\u00bb", "ich", "se\u00b7he", ",", "da\u00df", "dein", "Mund", "ein", "Leuch\u00b7ten", "hat"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie Rosenbl\u00e4tter, und dein Auge schwimmt", "tokens": ["Wie", "Ro\u00b7sen\u00b7bl\u00e4t\u00b7ter", ",", "und", "dein", "Au\u00b7ge", "schwimmt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "$,", "KON", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "In Wollust; alles ist so sch\u00f6n erregt,", "tokens": ["In", "Wol\u00b7lust", ";", "al\u00b7les", "ist", "so", "sch\u00f6n", "er\u00b7regt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "PIS", "VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df ich empfinde, wie du gl\u00fccklich bist.", "tokens": ["Da\u00df", "ich", "emp\u00b7fin\u00b7de", ",", "wie", "du", "gl\u00fcck\u00b7lich", "bist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und sieh, mir ist, du w\u00e4rst von mir ein Lied,", "tokens": ["Und", "sieh", ",", "mir", "ist", ",", "du", "w\u00e4rst", "von", "mir", "ein", "Lied", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "$,", "PPER", "VAFIN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das mir in heitrer Unbewu\u00dftheit kam,", "tokens": ["Das", "mir", "in", "hei\u00b7trer", "Un\u00b7be\u00b7wu\u00df\u00b7theit", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich sag mirs immer, immer wieder vor", "tokens": ["Ich", "sag", "mirs", "im\u00b7mer", ",", "im\u00b7mer", "wie\u00b7der", "vor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "ADV", "$,", "ADV", "ADV", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und wundre mich begl\u00fcckt: Das kam von mir?", "tokens": ["Und", "wund\u00b7re", "mich", "be\u00b7gl\u00fcckt", ":", "Das", "kam", "von", "mir", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "$.", "PDS", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Oh du mein sch\u00f6nes Lied, geschenktes Gl\u00fcck,", "tokens": ["Oh", "du", "mein", "sch\u00f6\u00b7nes", "Lied", ",", "ge\u00b7schenk\u00b7tes", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "PPER", "PPOSAT", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Du Leben, Traum, Gleichklang und Wiederklang:", "tokens": ["Du", "Le\u00b7ben", ",", "Traum", ",", "Gleich\u00b7klang", "und", "Wie\u00b7der\u00b7klang", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Da\u00df du mir kamst, zeigt mir, da\u00df G\u00f6tter sind,", "tokens": ["Da\u00df", "du", "mir", "kamst", ",", "zeigt", "mir", ",", "da\u00df", "G\u00f6t\u00b7ter", "sind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "$,", "KOUS", "NN", "VAFIN", "$,"], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Die Gnaden f\u00fcr mich haben und mich f\u00fchren.", "tokens": ["Die", "Gna\u00b7den", "f\u00fcr", "mich", "ha\u00b7ben", "und", "mich", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VAFIN", "KON", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Aus Ketten haben sie mich frei gemacht,", "tokens": ["Aus", "Ket\u00b7ten", "ha\u00b7ben", "sie", "mich", "frei", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Wie einen Vogel machten sie mich leicht", "tokens": ["Wie", "ei\u00b7nen", "Vo\u00b7gel", "mach\u00b7ten", "sie", "mich", "leicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NE", "VVFIN", "PPER", "PRF", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Und gaben auch den leichten Sinn ins Herz,", "tokens": ["Und", "ga\u00b7ben", "auch", "den", "leich\u00b7ten", "Sinn", "ins", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Der nicht bedenkt und fr\u00e4gt, nur nimmt und singt.\u00ab", "tokens": ["Der", "nicht", "be\u00b7denkt", "und", "fr\u00e4gt", ",", "nur", "nimmt", "und", "singt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PTKNEG", "VVFIN", "KON", "VVFIN", "$,", "ADV", "VVFIN", "KON", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Die rote Herzogin lacht wie ein Kind", "tokens": ["Die", "ro\u00b7te", "Her\u00b7zo\u00b7gin", "lacht", "wie", "ein", "Kind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und nimmt den Hut ab: \u2013 \u00bbHilf mir aus der Jacke!\u00ab", "tokens": ["Und", "nimmt", "den", "Hut", "ab", ":", "\u2013", "\u00bb", "Hilf", "mir", "aus", "der", "Ja\u00b7cke", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$.", "$(", "$(", "VVIMP", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Aus allem helf ich ihr, was sie beengt.", "tokens": ["Aus", "al\u00b7lem", "helf", "ich", "ihr", ",", "was", "sie", "be\u00b7engt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PPER", "PPER", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ihr rotes Haar ist nun ihr einzig Kleid.", "tokens": ["Ihr", "ro\u00b7tes", "Haar", "ist", "nun", "ihr", "ein\u00b7zig", "Kleid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und ich erhebe sie zur Kaiserin.", "tokens": ["Und", "ich", "er\u00b7he\u00b7be", "sie", "zur", "Kai\u00b7se\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Brandrot das Haar, ein violetter Hut", "tokens": ["Brand\u00b7rot", "das", "Haar", ",", "ein", "vi\u00b7o\u00b7let\u00b7ter", "Hut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit schwarzem Schleier und orangenen R\u00fcschen,", "tokens": ["Mit", "schwar\u00b7zem", "Schlei\u00b7er", "und", "o\u00b7ran\u00b7ge\u00b7nen", "R\u00fc\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Braun das Jackett, die Boa: gelber Fuchs,", "tokens": ["Braun", "das", "Ja\u00b7ckett", ",", "die", "Boa", ":", "gel\u00b7ber", "Fuchs", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "ART", "NN", "$.", "APPR", "NE", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Der Rock marineblaues Tuch mit Schwarz.", "tokens": ["Der", "Rock", "ma\u00b7ri\u00b7ne\u00b7blau\u00b7es", "Tuch", "mit", "Schwarz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Ich sinke in die Kniee: \u00bbHerzogin!", "tokens": ["Ich", "sin\u00b7ke", "in", "die", "Kni\u00b7ee", ":", "\u00bb", "Her\u00b7zo\u00b7gin", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$.", "$(", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Tritt \u00fcber meinen Nacken in mein Haus!", "tokens": ["Tritt", "\u00fc\u00b7ber", "mei\u00b7nen", "Na\u00b7cken", "in", "mein", "Haus", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "All meine Vers-D\u00e4monen blasen Tusch,", "tokens": ["All", "mei\u00b7ne", "Ver\u00b7sD\u00e4\u00b7mo\u00b7nen", "bla\u00b7sen", "Tusch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und auf dem Tisch von Palisanderholz", "tokens": ["Und", "auf", "dem", "Tisch", "von", "Pa\u00b7li\u00b7san\u00b7der\u00b7holz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Harrt seiner Herrin ein Carton \u203aMarquis\u2039", "tokens": ["Harrt", "sei\u00b7ner", "Her\u00b7rin", "ein", "Car\u00b7ton", "\u203a", "Mar\u00b7quis", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "NE", "$(", "NE", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Der besten parf\u00fcmierten Pralin\u00e9s.\u00ab", "tokens": ["Der", "bes\u00b7ten", "par\u00b7f\u00fc\u00b7mier\u00b7ten", "Pra\u00b7lin\u00e9s", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.14": {"line.1": {"text": "\u2013 Schnabunkel! sagt sie, zieht das Ohr mir lang,", "tokens": ["\u2013", "Schna\u00b7bun\u00b7kel", "!", "sagt", "sie", ",", "zieht", "das", "Ohr", "mir", "lang", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$.", "VVFIN", "PPER", "$,", "VVFIN", "ART", "NN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "K\u00fc\u00dft mich (wie riecht sie frisch!) hastig und schnell", "tokens": ["K\u00fc\u00dft", "mich", "(", "wie", "riecht", "sie", "frisch", "!", ")", "has\u00b7tig", "und", "schnell"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$(", "PWAV", "VVFIN", "PPER", "ADJD", "$.", "$(", "ADJD", "KON", "ADJD"], "meter": "+--+-++--+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und setzt sich in das gelbe Kanapee.", "tokens": ["Und", "setzt", "sich", "in", "das", "gel\u00b7be", "Ka\u00b7na\u00b7pee", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "\u2013 Bonbons! befiehlt sie. \u00bbHier!\u00ab Den Schleier hoch,", "tokens": ["\u2013", "Bon\u00b7bons", "!", "be\u00b7fiehlt", "sie", ".", "\u00bb", "Hier", "!", "\u00ab", "Den", "Schlei\u00b7er", "hoch", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$.", "VVFIN", "PPER", "$.", "$(", "ADV", "$.", "$(", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und in die braune Schokolade senkt", "tokens": ["Und", "in", "die", "brau\u00b7ne", "Scho\u00b7ko\u00b7la\u00b7de", "senkt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sich wei\u00df das allerschneeigste Gebi\u00df.", "tokens": ["Sich", "wei\u00df", "das", "al\u00b7ler\u00b7schne\u00b7e\u00b7igs\u00b7te", "Ge\u00b7bi\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.15": {"line.1": {"text": "\u00bbund was befiehlt die rote Herzogin!\u00ab", "tokens": ["\u00bb", "und", "was", "be\u00b7fiehlt", "die", "ro\u00b7te", "Her\u00b7zo\u00b7gin", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PWS", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u2013 Sie w\u00fcnscht geliebt zu sein.", "tokens": ["\u2013", "Sie", "w\u00fcnscht", "ge\u00b7liebt", "zu", "sein", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbsofort Madam?\u00ab", "tokens": ["\u00bb", "so\u00b7fort", "Ma\u00b7dam", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "NN", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "\u2013 Sofort und sehr. Man k\u00fcsse mich enorm!", "tokens": ["\u2013", "So\u00b7fort", "und", "sehr", ".", "Man", "k\u00fcs\u00b7se", "mich", "en\u00b7orm", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "KON", "ADV", "$.", "PIS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbbelieben Eure Hoheit nicht erst das Jackett ...?\u00ab", "tokens": ["\u00bb", "be\u00b7lie\u00b7ben", "Eu\u00b7re", "Ho\u00b7heit", "nicht", "erst", "das", "Ja\u00b7ckett", "...", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "VVFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "ART", "NN", "$(", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich w\u00fcnsche im Jackett geliebt zu sein.", "tokens": ["Ich", "w\u00fcn\u00b7sche", "im", "Ja\u00b7ckett", "ge\u00b7liebt", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbdoch wenigstens den Schleier ab, Madam ...?\u00ab", "tokens": ["\u00bb", "doch", "we\u00b7nigs\u00b7tens", "den", "Schlei\u00b7er", "ab", ",", "Ma\u00b7dam", "...", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "ART", "NN", "PTKVZ", "$,", "NN", "$(", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u2013 Genehmigt!", "tokens": ["\u2013", "Ge\u00b7neh\u00b7migt", "!"], "token_info": ["punct", "word", "punct"], "pos": ["$(", "VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Das Gegitter auf den Tisch.", "tokens": ["Das", "Ge\u00b7git\u00b7ter", "auf", "den", "Tisch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Wir k\u00fcssen uns. Sie dr\u00fcckt mich fest an sich,", "tokens": ["Wir", "k\u00fcs\u00b7sen", "uns", ".", "Sie", "dr\u00fcckt", "mich", "fest", "an", "sich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "PPER", "ADJD", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der gelbe Fuchs umkitzelt meinen Hals.", "tokens": ["Der", "gel\u00b7be", "Fuchs", "um\u00b7kit\u00b7zelt", "mei\u00b7nen", "Hals", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "\u2013 Ich bin sehr gn\u00e4dig heute, findst du nicht?", "tokens": ["\u2013", "Ich", "bin", "sehr", "gn\u00e4\u00b7dig", "heu\u00b7te", ",", "findst", "du", "nicht", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "ADV", "$,", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbich finde, da\u00df Ihr immer huldreich seid.\u00ab", "tokens": ["\u00bb", "ich", "fin\u00b7de", ",", "da\u00df", "Ihr", "im\u00b7mer", "huld\u00b7reich", "seid", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u2013 Ich bin zu gut f\u00fcr diese Welt. Sag mal:", "tokens": ["\u2013", "Ich", "bin", "zu", "gut", "f\u00fcr", "die\u00b7se", "Welt", ".", "Sag", "mal", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PTKA", "ADJD", "APPR", "PDAT", "NN", "$.", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wei\u00dft du denn, wer ich bin? \u00bbI, keine Spur!\u00ab", "tokens": ["Wei\u00dft", "du", "denn", ",", "wer", "ich", "bin", "?", "\u00bb", "I", ",", "kei\u00b7ne", "Spur", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWS", "PPER", "VAFIN", "$.", "$(", "XY", "$,", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u2013 Und willst es auch nicht wissen? \u2013 \u00bbPfui, wer wird,", "tokens": ["\u2013", "Und", "willst", "es", "auch", "nicht", "wis\u00b7sen", "?", "\u2013", "\u00bb", "Pfui", ",", "wer", "wird", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KON", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$.", "$(", "$(", "NN", "$,", "PWS", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Neugierig sein, wenn er im Gl\u00fccke sitzt!?", "tokens": ["Neu\u00b7gie\u00b7rig", "sein", ",", "wenn", "er", "im", "Gl\u00fc\u00b7cke", "sitzt", "!?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "$,", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Du bist mir meine rote Herzogin,", "tokens": ["Du", "bist", "mir", "mei\u00b7ne", "ro\u00b7te", "Her\u00b7zo\u00b7gin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Denn deine Grazie, dein Wuchs, dein Gang,", "tokens": ["Denn", "dei\u00b7ne", "Gra\u00b7zie", ",", "dein", "Wuchs", ",", "dein", "Gang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Die Art, wie du die Handschuh von den Fingern streifst,", "tokens": ["Die", "Art", ",", "wie", "du", "die", "Hand\u00b7schuh", "von", "den", "Fin\u00b7gern", "streifst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie du den Kopf zur\u00fcckbeugst, k\u00fc\u00df ich dich,", "tokens": ["Wie", "du", "den", "Kopf", "zu\u00b7r\u00fcck\u00b7beugst", ",", "k\u00fc\u00df", "ich", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "PRF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Wie du Bonbons i\u00dfst, l\u00e4chelst, dir den Schleier steckst,", "tokens": ["Wie", "du", "Bon\u00b7bons", "i\u00df\u00b7st", ",", "l\u00e4\u00b7chelst", ",", "dir", "den", "Schlei\u00b7er", "steckst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVFIN", "$,", "VVFIN", "$,", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.12": {"text": "Und, ach, die Art, wie du mich k\u00fc\u00dfst, Madam,", "tokens": ["Und", ",", "ach", ",", "die", "Art", ",", "wie", "du", "mich", "k\u00fc\u00df\u00b7st", ",", "Ma\u00b7dam", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "ITJ", "$,", "ART", "NN", "$,", "PWAV", "PPER", "PRF", "VVFIN", "$,", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.13": {"text": "Ist herzoglich, \u2013 ich sagte k\u00f6niglich,", "tokens": ["Ist", "her\u00b7zog\u00b7lich", ",", "\u2013", "ich", "sag\u00b7te", "k\u00f6\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "$(", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "W\u00e4r mir dies Wort f\u00fcr dich nicht zu verbraucht.", "tokens": ["W\u00e4r", "mir", "dies", "Wort", "f\u00fcr", "dich", "nicht", "zu", "ver\u00b7braucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "NN", "APPR", "PPER", "PTKNEG", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Und nun zu denken, da\u00df dein Mann vielleicht", "tokens": ["Und", "nun", "zu", "den\u00b7ken", ",", "da\u00df", "dein", "Mann", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "$,", "KOUS", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Banquier ist, Rechtsanwalt, Professor, Arzt,", "tokens": ["Ban\u00b7qui\u00b7er", "ist", ",", "Rechts\u00b7an\u00b7walt", ",", "Pro\u00b7fes\u00b7sor", ",", "Arzt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Major, Regierungsrat, Gro\u00dfbrauer, Maler,", "tokens": ["Ma\u00b7jor", ",", "Re\u00b7gie\u00b7rungs\u00b7rat", ",", "Gro\u00df\u00b7brau\u00b7er", ",", "Ma\u00b7ler", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+--+--++-+-", "measure": "dactylic.di.plus"}, "line.18": {"text": "Kurz irgend was, dem man begegnen kann,", "tokens": ["Kurz", "ir\u00b7gend", "was", ",", "dem", "man", "be\u00b7geg\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "PIS", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Im Trambahnwagen, auf der Stra\u00dfe, im Caf\u00e9 \u2013", "tokens": ["Im", "Tram\u00b7bahn\u00b7wa\u00b7gen", ",", "auf", "der", "Stra\u00b7\u00dfe", ",", "im", "Ca\u00b7f\u00e9", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ART", "NN", "$,", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Entsetzlich! Nein, du bist die Herzogin.", "tokens": ["Ent\u00b7setz\u00b7lich", "!", "Nein", ",", "du", "bist", "die", "Her\u00b7zo\u00b7gin", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "PTKANT", "$,", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Dein Mann (sie l\u00e4chelt seltsam) wohnt im Schlo\u00df,", "tokens": ["Dein", "Mann", "(", "sie", "l\u00e4\u00b7chelt", "selt\u00b7sam", ")", "wohnt", "im", "Schlo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPER", "VVFIN", "ADJD", "$(", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Ist alt und gn\u00e4dig, geistreich, tolerant,", "tokens": ["Ist", "alt", "und", "gn\u00e4\u00b7dig", ",", "geist\u00b7reich", ",", "to\u00b7le\u00b7rant", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Tr\u00e4gt Escarpins, Jabots, sagt ma ch\u00e9rie,", "tokens": ["Tr\u00e4gt", "E\u00b7scar\u00b7pins", ",", "Ja\u00b7bots", ",", "sagt", "ma", "ch\u00e9rie", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "NE", "$,", "VVFIN", "NE", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.24": {"text": "Regiert ein Volk, das sehr zufrieden ist,", "tokens": ["Re\u00b7giert", "ein", "Volk", ",", "das", "sehr", "zu\u00b7frie\u00b7den", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "PRELS", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Pflegt das Ballet, liebt altes Porzellan,", "tokens": ["Pflegt", "das", "Bal\u00b7let", ",", "liebt", "al\u00b7tes", "Por\u00b7zel\u00b7lan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.26": {"text": "Bl\u00e4st etwas Fl\u00f6te, h\u00fcstelt in die Hand,", "tokens": ["Bl\u00e4st", "et\u00b7was", "Fl\u00f6\u00b7te", ",", "h\u00fcs\u00b7telt", "in", "die", "Hand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Hat hie und da ein bischen Podagra", "tokens": ["Hat", "hie", "und", "da", "ein", "bi\u00b7schen", "Po\u00b7da\u00b7gra"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.28": {"text": "Und l\u00e4chelt etwas schmerzlich, wenn er h\u00f6rt,", "tokens": ["Und", "l\u00e4\u00b7chelt", "et\u00b7was", "schmerz\u00b7lich", ",", "wenn", "er", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Die Liebe sei ein g\u00f6ttliches Pl\u00e4sier,", "tokens": ["Die", "Lie\u00b7be", "sei", "ein", "g\u00f6tt\u00b7li\u00b7ches", "Pl\u00e4\u00b7sier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Kurz, Serenissimus ist comme il faut", "tokens": ["Kurz", ",", "Se\u00b7re\u00b7nis\u00b7si\u00b7mus", "ist", "com\u00b7me", "il", "faut"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.31": {"text": "Und hat nicht viel dagegen einzuwenden,", "tokens": ["Und", "hat", "nicht", "viel", "da\u00b7ge\u00b7gen", "ein\u00b7zu\u00b7wen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "PAV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Da\u00df Serenissima den Dichter k\u00fc\u00dft,", "tokens": ["Da\u00df", "Se\u00b7re\u00b7nis\u00b7si\u00b7ma", "den", "Dich\u00b7ter", "k\u00fc\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "Der schon manch Carmen ihm zu Ehren sang", "tokens": ["Der", "schon", "manch", "Car\u00b7men", "ihm", "zu", "Eh\u00b7ren", "sang"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PIAT", "NN", "PPER", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Und am orange-gr\u00fcnen Band das Kreuz", "tokens": ["Und", "am", "o\u00b7ran\u00b7ge\u00b7gr\u00fc\u00b7nen", "Band", "das", "Kreuz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Vom wei\u00dfen Papageienorden tr\u00e4gt.\u00ab", "tokens": ["Vom", "wei\u00b7\u00dfen", "Pa\u00b7pa\u00b7gei\u00b7en\u00b7or\u00b7den", "tr\u00e4gt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "\u2013 Oh mein Schnabunkel, welch ein Narr du bist!", "tokens": ["\u2013", "Oh", "mein", "Schna\u00b7bun\u00b7kel", ",", "welch", "ein", "Narr", "du", "bist", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "XY", "PPOSAT", "NN", "$,", "PWAT", "ART", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In deinem gelben Kanapee verge\u00df ich", "tokens": ["In", "dei\u00b7nem", "gel\u00b7ben", "Ka\u00b7na\u00b7pee", "ver\u00b7ge\u00df", "ich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sehr viel, \u2013 verge\u00df ich mich und bin ein Kind,", "tokens": ["Sehr", "viel", ",", "\u2013", "ver\u00b7ge\u00df", "ich", "mich", "und", "bin", "ein", "Kind", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "$(", "VVFIN", "PPER", "PRF", "KON", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Leichtsinnig, treulos, hingegeben, \u2013 gut.", "tokens": ["Leicht\u00b7sin\u00b7nig", ",", "treu\u00b7los", ",", "hin\u00b7ge\u00b7ge\u00b7ben", ",", "\u2013", "gut", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "VVPP", "$,", "$(", "ADJD", "$."], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.5": {"text": "Nein, du sollst nie erfahren, wer ich bin.", "tokens": ["Nein", ",", "du", "sollst", "nie", "er\u00b7fah\u00b7ren", ",", "wer", "ich", "bin", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "ADV", "VVINF", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wir wollen hier in diesem kleinen Haus", "tokens": ["Wir", "wol\u00b7len", "hier", "in", "die\u00b7sem", "klei\u00b7nen", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Verstecken spielen vor uns selbst, nicht wahr,", "tokens": ["Ver\u00b7ste\u00b7cken", "spie\u00b7len", "vor", "uns", "selbst", ",", "nicht", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPER", "ADV", "$,", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und gl\u00fccklich sein, weil wir blo\u00df Menschen sind,", "tokens": ["Und", "gl\u00fcck\u00b7lich", "sein", ",", "weil", "wir", "blo\u00df", "Men\u00b7schen", "sind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAINF", "$,", "KOUS", "PPER", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Nicht der und der und die und die \u2013 blo\u00df ich und du.", "tokens": ["Nicht", "der", "und", "der", "und", "die", "und", "die", "\u2013", "blo\u00df", "ich", "und", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "KON", "ART", "KON", "ART", "KON", "ART", "$(", "ADV", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Auch sei nicht Treue hier geschworen, und", "tokens": ["Auch", "sei", "nicht", "Treu\u00b7e", "hier", "ge\u00b7schwo\u00b7ren", ",", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "PTKNEG", "NN", "ADV", "VVPP", "$,", "KON"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Kein Band gekn\u00fcpft; das Heute ist uns hold,", "tokens": ["Kein", "Band", "ge\u00b7kn\u00fcpft", ";", "das", "Heu\u00b7te", "ist", "uns", "hold", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$.", "ART", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Das Morgen m\u00f6g es sein; was sp\u00e4ter kommt,", "tokens": ["Das", "Mor\u00b7gen", "m\u00f6g", "es", "sein", ";", "was", "sp\u00e4\u00b7ter", "kommt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VAINF", "$.", "PWS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Das mag die G\u00f6tter k\u00fcmmern, die es walten;", "tokens": ["Das", "mag", "die", "G\u00f6t\u00b7ter", "k\u00fcm\u00b7mern", ",", "die", "es", "wal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "VVINF", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Uns w\u00e4chst kein graues Haar um dies Vielleicht.", "tokens": ["Uns", "w\u00e4chst", "kein", "grau\u00b7es", "Haar", "um", "dies", "Viel\u00b7leicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "APPR", "PDS", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "K\u00fc\u00df mich, Schnabunkel! Serenissima", "tokens": ["K\u00fc\u00df", "mich", ",", "Schna\u00b7bun\u00b7kel", "!", "Se\u00b7re\u00b7nis\u00b7si\u00b7ma"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["VVIMP", "PPER", "$,", "NN", "$.", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Ist k\u00fcssedurstig und so sehr verliebt", "tokens": ["Ist", "k\u00fcs\u00b7se\u00b7durs\u00b7tig", "und", "so", "sehr", "ver\u00b7liebt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "KON", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "In diesen Herrn vom gelben Kanapee,", "tokens": ["In", "die\u00b7sen", "Herrn", "vom", "gel\u00b7ben", "Ka\u00b7na\u00b7pee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Da\u00df sie nichts hat, was nicht auch ihm geh\u00f6rte.", "tokens": ["Da\u00df", "sie", "nichts", "hat", ",", "was", "nicht", "auch", "ihm", "ge\u00b7h\u00f6r\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VAFIN", "$,", "PRELS", "PTKNEG", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Sie lebt nur hier; was drau\u00dfen ist, ist Tod;", "tokens": ["Sie", "lebt", "nur", "hier", ";", "was", "drau\u00b7\u00dfen", "ist", ",", "ist", "Tod", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "PWS", "ADV", "VAFIN", "$,", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Ein Vers von dir, ihr in das Herz gehaucht,", "tokens": ["Ein", "Vers", "von", "dir", ",", "ihr", "in", "das", "Herz", "ge\u00b7haucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$,", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Ist Lebens mehr, als alle ihre Welt.", "tokens": ["Ist", "Le\u00b7bens", "mehr", ",", "als", "al\u00b7le", "ih\u00b7re", "Welt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "$,", "KOUS", "PIS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Hier ist ihr Traum, und sie genie\u00dft ihn ganz,", "tokens": ["Hier", "ist", "ihr", "Traum", ",", "und", "sie", "ge\u00b7nie\u00dft", "ihn", "ganz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Sieht alles gl\u00e4nzend, wies im Traumland ist,", "tokens": ["Sieht", "al\u00b7les", "gl\u00e4n\u00b7zend", ",", "wies", "im", "Traum\u00b7land", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "$,", "VVFIN", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "F\u00fchlt alles hundertfach, weil sie es tr\u00e4umt.", "tokens": ["F\u00fchlt", "al\u00b7les", "hun\u00b7dert\u00b7fach", ",", "weil", "sie", "es", "tr\u00e4umt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Du bist mein Page, reizend und verrucht,", "tokens": ["Du", "bist", "mein", "Pa\u00b7ge", ",", "rei\u00b7zend", "und", "ver\u00b7rucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Ich schlich zu dir, die Nacht war warm und feucht,", "tokens": ["Ich", "schlich", "zu", "dir", ",", "die", "Nacht", "war", "warm", "und", "feucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "PPER", "$,", "ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Aus meinem Bette in den Pavillon,", "tokens": ["Aus", "mei\u00b7nem", "Bet\u00b7te", "in", "den", "Pa\u00b7vil\u00b7lon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Die Sterne blinzeln, und die Nachtigall", "tokens": ["Die", "Ster\u00b7ne", "blin\u00b7zeln", ",", "und", "die", "Nach\u00b7ti\u00b7gall"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Schluchzt Liebe aus der Laube von Jasmin.", "tokens": ["Schluchzt", "Lie\u00b7be", "aus", "der", "Lau\u00b7be", "von", "Jas\u00b7min", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.30": {"text": "Das Leben ist ein Abenteurerspiel,", "tokens": ["Das", "Le\u00b7ben", "ist", "ein", "A\u00b7bent\u00b7eu\u00b7rer\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Gefahr giebt hei\u00dfe S\u00fc\u00dfe dem Genu\u00df,", "tokens": ["Ge\u00b7fahr", "giebt", "hei\u00b7\u00dfe", "S\u00fc\u00b7\u00dfe", "dem", "Ge\u00b7nu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Die S\u00fcnde ist ein wunderbarer Trost", "tokens": ["Die", "S\u00fcn\u00b7de", "ist", "ein", "wun\u00b7der\u00b7ba\u00b7rer", "Trost"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "Im Leben, das so trostlos grade geht.", "tokens": ["Im", "Le\u00b7ben", ",", "das", "so", "trost\u00b7los", "gra\u00b7de", "geht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "ADV", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Ich habe keine Kunst: was S\u00fcnde hei\u00dft,", "tokens": ["Ich", "ha\u00b7be", "kei\u00b7ne", "Kunst", ":", "was", "S\u00fcn\u00b7de", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$.", "PWS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "\u00bbich sehe, da\u00df dein Mund ein Leuchten hat", "tokens": ["\u00bb", "ich", "se\u00b7he", ",", "da\u00df", "dein", "Mund", "ein", "Leuch\u00b7ten", "hat"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie Rosenbl\u00e4tter, und dein Auge schwimmt", "tokens": ["Wie", "Ro\u00b7sen\u00b7bl\u00e4t\u00b7ter", ",", "und", "dein", "Au\u00b7ge", "schwimmt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "$,", "KON", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "In Wollust; alles ist so sch\u00f6n erregt,", "tokens": ["In", "Wol\u00b7lust", ";", "al\u00b7les", "ist", "so", "sch\u00f6n", "er\u00b7regt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "PIS", "VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df ich empfinde, wie du gl\u00fccklich bist.", "tokens": ["Da\u00df", "ich", "emp\u00b7fin\u00b7de", ",", "wie", "du", "gl\u00fcck\u00b7lich", "bist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und sieh, mir ist, du w\u00e4rst von mir ein Lied,", "tokens": ["Und", "sieh", ",", "mir", "ist", ",", "du", "w\u00e4rst", "von", "mir", "ein", "Lied", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "$,", "PPER", "VAFIN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das mir in heitrer Unbewu\u00dftheit kam,", "tokens": ["Das", "mir", "in", "hei\u00b7trer", "Un\u00b7be\u00b7wu\u00df\u00b7theit", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich sag mirs immer, immer wieder vor", "tokens": ["Ich", "sag", "mirs", "im\u00b7mer", ",", "im\u00b7mer", "wie\u00b7der", "vor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "ADV", "$,", "ADV", "ADV", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und wundre mich begl\u00fcckt: Das kam von mir?", "tokens": ["Und", "wund\u00b7re", "mich", "be\u00b7gl\u00fcckt", ":", "Das", "kam", "von", "mir", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "$.", "PDS", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Oh du mein sch\u00f6nes Lied, geschenktes Gl\u00fcck,", "tokens": ["Oh", "du", "mein", "sch\u00f6\u00b7nes", "Lied", ",", "ge\u00b7schenk\u00b7tes", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "PPER", "PPOSAT", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Du Leben, Traum, Gleichklang und Wiederklang:", "tokens": ["Du", "Le\u00b7ben", ",", "Traum", ",", "Gleich\u00b7klang", "und", "Wie\u00b7der\u00b7klang", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Da\u00df du mir kamst, zeigt mir, da\u00df G\u00f6tter sind,", "tokens": ["Da\u00df", "du", "mir", "kamst", ",", "zeigt", "mir", ",", "da\u00df", "G\u00f6t\u00b7ter", "sind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "$,", "KOUS", "NN", "VAFIN", "$,"], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Die Gnaden f\u00fcr mich haben und mich f\u00fchren.", "tokens": ["Die", "Gna\u00b7den", "f\u00fcr", "mich", "ha\u00b7ben", "und", "mich", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VAFIN", "KON", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Aus Ketten haben sie mich frei gemacht,", "tokens": ["Aus", "Ket\u00b7ten", "ha\u00b7ben", "sie", "mich", "frei", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Wie einen Vogel machten sie mich leicht", "tokens": ["Wie", "ei\u00b7nen", "Vo\u00b7gel", "mach\u00b7ten", "sie", "mich", "leicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NE", "VVFIN", "PPER", "PRF", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Und gaben auch den leichten Sinn ins Herz,", "tokens": ["Und", "ga\u00b7ben", "auch", "den", "leich\u00b7ten", "Sinn", "ins", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Der nicht bedenkt und fr\u00e4gt, nur nimmt und singt.\u00ab", "tokens": ["Der", "nicht", "be\u00b7denkt", "und", "fr\u00e4gt", ",", "nur", "nimmt", "und", "singt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PTKNEG", "VVFIN", "KON", "VVFIN", "$,", "ADV", "VVFIN", "KON", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Die rote Herzogin lacht wie ein Kind", "tokens": ["Die", "ro\u00b7te", "Her\u00b7zo\u00b7gin", "lacht", "wie", "ein", "Kind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und nimmt den Hut ab: \u2013 \u00bbHilf mir aus der Jacke!\u00ab", "tokens": ["Und", "nimmt", "den", "Hut", "ab", ":", "\u2013", "\u00bb", "Hilf", "mir", "aus", "der", "Ja\u00b7cke", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$.", "$(", "$(", "VVIMP", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Aus allem helf ich ihr, was sie beengt.", "tokens": ["Aus", "al\u00b7lem", "helf", "ich", "ihr", ",", "was", "sie", "be\u00b7engt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PPER", "PPER", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ihr rotes Haar ist nun ihr einzig Kleid.", "tokens": ["Ihr", "ro\u00b7tes", "Haar", "ist", "nun", "ihr", "ein\u00b7zig", "Kleid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und ich erhebe sie zur Kaiserin.", "tokens": ["Und", "ich", "er\u00b7he\u00b7be", "sie", "zur", "Kai\u00b7se\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}