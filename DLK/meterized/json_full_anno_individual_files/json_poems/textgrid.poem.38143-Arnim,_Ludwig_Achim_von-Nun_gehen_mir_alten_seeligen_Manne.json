{"textgrid.poem.38143": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Nun gehen mir alten seeligen Manne", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als Jupiter gedacht,", "tokens": ["Als", "Ju\u00b7pi\u00b7ter", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Er h\u00e4tte Himmel und Erd,", "tokens": ["Er", "h\u00e4t\u00b7te", "Him\u00b7mel", "und", "Erd", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ganz fertig ausgemacht,", "tokens": ["Ganz", "fer\u00b7tig", "aus\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und was darin geh\u00f6rt,", "tokens": ["Und", "was", "da\u00b7rin", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PAV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da sah er hin und her,", "tokens": ["Da", "sah", "er", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Besinnt sich endlich fein,", "tokens": ["Be\u00b7sinnt", "sich", "end\u00b7lich", "fein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Es m\u00fc\u00dft seyn etwas mehr,", "tokens": ["Es", "m\u00fc\u00dft", "seyn", "et\u00b7was", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VAINF", "PIS", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "So da geh\u00f6rt darein.", "tokens": ["So", "da", "ge\u00b7h\u00f6rt", "da\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Der Sachen ha ha Cupido lacht,", "tokens": ["Der", "Sa\u00b7chen", "ha", "ha", "Cu\u00b7pi\u00b7do", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Sprach: Alter du hast nicht alles gemacht,", "tokens": ["Sprach", ":", "Al\u00b7ter", "du", "hast", "nicht", "al\u00b7les", "ge\u00b7macht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "PPER", "VAFIN", "PTKNEG", "PIS", "VVPP", "$,"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.11": {"text": "Besinn dich fein wohl, besinn dich fein wohl,", "tokens": ["Be\u00b7sinn", "dich", "fein", "wohl", ",", "be\u00b7sinn", "dich", "fein", "wohl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "ADV", "$,", "VVFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Das Beste fehlt hier, das billig seyn soll!", "tokens": ["Das", "Bes\u00b7te", "fehlt", "hier", ",", "das", "bil\u00b7lig", "seyn", "soll", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "PRELS", "ADJD", "VAINF", "VMFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Solches Jovem verdro\u00df hart,", "tokens": ["Sol\u00b7ches", "Jo\u00b7vem", "ver\u00b7dro\u00df", "hart", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "+----+-", "measure": "dactylic.init"}, "line.2": {"text": "Da\u00df er von diesem Kind,", "tokens": ["Da\u00df", "er", "von", "die\u00b7sem", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sp\u00f6ttlich verlachet ward,", "tokens": ["Sp\u00f6tt\u00b7lich", "ver\u00b7la\u00b7chet", "ward", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VAFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Da nahm er in sein Sinn,", "tokens": ["Da", "nahm", "er", "in", "sein", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Erschafft ein Kreatur", "tokens": ["Er\u00b7schafft", "ein", "Kre\u00b7a\u00b7tur"], "token_info": ["word", "word", "word"], "pos": ["NN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Ein sch\u00f6n jungfr\u00e4ulich Bild,", "tokens": ["Ein", "sch\u00f6n", "jung\u00b7fr\u00e4u\u00b7lich", "Bild", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Welche sch\u00f6ne Figur", "tokens": ["Wel\u00b7che", "sch\u00f6\u00b7ne", "Fi\u00b7gur"], "token_info": ["word", "word", "word"], "pos": ["PWAT", "ADJA", "NN"], "meter": "+-+---", "measure": "unknown.measure.di"}, "line.8": {"text": "Er f\u00fcr sein Kunstwerk hielt.", "tokens": ["Er", "f\u00fcr", "sein", "Kunst\u00b7werk", "hielt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Der Sachen ha ha Cupido lacht:", "tokens": ["Der", "Sa\u00b7chen", "ha", "ha", "Cu\u00b7pi\u00b7do", "lacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "NE", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Du hast alles recht wohl gemacht,", "tokens": ["Du", "hast", "al\u00b7les", "recht", "wohl", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADV", "ADV", "VVPP", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.11": {"text": "Des freu ich mich sehr, des freu ich mich sehr;", "tokens": ["Des", "freu", "ich", "mich", "sehr", ",", "des", "freu", "ich", "mich", "sehr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPER", "PRF", "ADV", "$,", "ART", "ADJD", "PPER", "PRF", "ADV", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Ach Lieber mach doch der Dinge noch mehr.", "tokens": ["Ach", "Lie\u00b7ber", "mach", "doch", "der", "Din\u00b7ge", "noch", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJD", "VVFIN", "ADV", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Welches Jovi Freuden bracht,", "tokens": ["Wel\u00b7ches", "Jo\u00b7vi", "Freu\u00b7den", "bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df dieses Kind nackend und blo\u00df,", "tokens": ["Da\u00df", "die\u00b7ses", "Kind", "na\u00b7ckend", "und", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "VVPP", "KON", "ADV", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Ihn sehr freundlich anlacht,", "tokens": ["Ihn", "sehr", "freund\u00b7lich", "an\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Drum setzt ers in sein Schoo\u00df,", "tokens": ["Drum", "setzt", "ers", "in", "sein", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das Bild entschlief so bald,", "tokens": ["Das", "Bild", "ent\u00b7schlief", "so", "bald", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Er h\u00e4tts gek\u00fc\u00dft so gern,", "tokens": ["Er", "h\u00e4tts", "ge\u00b7k\u00fc\u00dft", "so", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Wolts aber mit Gewalt,", "tokens": ["Wolts", "a\u00b7ber", "mit", "Ge\u00b7walt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Nicht aus dem Schlaf verst\u00f6rn.", "tokens": ["Nicht", "aus", "dem", "Schlaf", "ver\u00b7st\u00f6rn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "Der Sachen ha ha Cupido lacht,", "tokens": ["Der", "Sa\u00b7chen", "ha", "ha", "Cu\u00b7pi\u00b7do", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Sprach: Alter k\u00fc\u00df fort, bis sie erwacht,", "tokens": ["Sprach", ":", "Al\u00b7ter", "k\u00fc\u00df", "fort", ",", "bis", "sie", "er\u00b7wacht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "VVFIN", "PTKVZ", "$,", "KOUS", "PPER", "VVPP", "$,"], "meter": "-+--+---+", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "La\u00df also nicht ruhn, la\u00df also nicht ruhn,", "tokens": ["La\u00df", "al\u00b7so", "nicht", "ruhn", ",", "la\u00df", "al\u00b7so", "nicht", "ruhn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PTKNEG", "VVINF", "$,", "VVIMP", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Es ist ihr nicht um den Schlaf zu thun.", "tokens": ["Es", "ist", "ihr", "nicht", "um", "den", "Schlaf", "zu", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Dein Liebelein schlaf oder wach,", "tokens": ["Dein", "Lie\u00b7be\u00b7lein", "schlaf", "o\u00b7der", "wach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "So k\u00fc\u00df sie immerfort,", "tokens": ["So", "k\u00fc\u00df", "sie", "im\u00b7mer\u00b7fort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dir kein Gedanken mach,", "tokens": ["Dir", "kein", "Ge\u00b7dan\u00b7ken", "mach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Sondern glaub meinem Wort,", "tokens": ["Son\u00b7dern", "glaub", "mei\u00b7nem", "Wort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "K\u00fc\u00df sie so oft und wohl,", "tokens": ["K\u00fc\u00df", "sie", "so", "oft", "und", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Ich will verwetten was,", "tokens": ["Ich", "will", "ver\u00b7wet\u00b7ten", "was", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "PWS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Ob sie dich schelten soll,", "tokens": ["Ob", "sie", "dich", "schel\u00b7ten", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Sondern sprechen, k\u00fc\u00df nur bas!", "tokens": ["Son\u00b7dern", "spre\u00b7chen", ",", "k\u00fc\u00df", "nur", "bas", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "VVFIN", "ADV", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Der Sachen, ha ha, Cupido lacht,", "tokens": ["Der", "Sa\u00b7chen", ",", "ha", "ha", ",", "Cu\u00b7pi\u00b7do", "lacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ITJ", "ITJ", "$,", "NE", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Zwey Lieblein scherzen die ganze Nacht,", "tokens": ["Zwey", "Lieb\u00b7lein", "scher\u00b7zen", "die", "gan\u00b7ze", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "La\u00df also frey gehn, la\u00df also frey gehn,", "tokens": ["La\u00df", "al\u00b7so", "frey", "gehn", ",", "la\u00df", "al\u00b7so", "frey", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADJD", "VVINF", "$,", "VVIMP", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Ach Kinder was wird noch draus entstehn.", "tokens": ["Ach", "Kin\u00b7der", "was", "wird", "noch", "draus", "ent\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "PWS", "VAFIN", "ADV", "PAV", "VVINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Darum sch\u00f6nes Liebelein,", "tokens": ["Da\u00b7rum", "sch\u00f6\u00b7nes", "Lie\u00b7be\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df mich dir nun k\u00fcssen auch", "tokens": ["La\u00df", "mich", "dir", "nun", "k\u00fcs\u00b7sen", "auch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPER", "ADV", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dein werthes M\u00fcndelein,", "tokens": ["Dein", "wert\u00b7hes", "M\u00fcn\u00b7del\u00b7ein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Weils ist ein alter Brauch,", "tokens": ["Weils", "ist", "ein", "al\u00b7ter", "Brauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der mu\u00df abkommen nicht,", "tokens": ["Der", "mu\u00df", "ab\u00b7kom\u00b7men", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "VVINF", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Weils ist ein ehlich Pflicht,", "tokens": ["Weils", "ist", "ein", "eh\u00b7lich", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Und wenns in Ehren geschieht,", "tokens": ["Und", "wenns", "in", "Eh\u00b7ren", "ge\u00b7schieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "So kanns ja schaden nicht.", "tokens": ["So", "kanns", "ja", "scha\u00b7den", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "So haben die Alten einander gek\u00fc\u00dft,", "tokens": ["So", "ha\u00b7ben", "die", "Al\u00b7ten", "ein\u00b7an\u00b7der", "ge\u00b7k\u00fc\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.10": {"text": "Bis aus Zwey ein Drey worden ist.", "tokens": ["Bis", "aus", "Zwey", "ein", "Drey", "wor\u00b7den", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "CARD", "ART", "NN", "VAPP", "VAFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.11": {"text": "So la\u00dft uns nun auch halten den Gebrauch,", "tokens": ["So", "la\u00dft", "uns", "nun", "auch", "hal\u00b7ten", "den", "Ge\u00b7brauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "So lang wir leben auf dieser Erd.", "tokens": ["So", "lang", "wir", "le\u00b7ben", "auf", "die\u00b7ser", "Erd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Als Jupiter gedacht,", "tokens": ["Als", "Ju\u00b7pi\u00b7ter", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Er h\u00e4tte Himmel und Erd,", "tokens": ["Er", "h\u00e4t\u00b7te", "Him\u00b7mel", "und", "Erd", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ganz fertig ausgemacht,", "tokens": ["Ganz", "fer\u00b7tig", "aus\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und was darin geh\u00f6rt,", "tokens": ["Und", "was", "da\u00b7rin", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PAV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da sah er hin und her,", "tokens": ["Da", "sah", "er", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Besinnt sich endlich fein,", "tokens": ["Be\u00b7sinnt", "sich", "end\u00b7lich", "fein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Es m\u00fc\u00dft seyn etwas mehr,", "tokens": ["Es", "m\u00fc\u00dft", "seyn", "et\u00b7was", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VAINF", "PIS", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "So da geh\u00f6rt darein.", "tokens": ["So", "da", "ge\u00b7h\u00f6rt", "da\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Der Sachen ha ha Cupido lacht,", "tokens": ["Der", "Sa\u00b7chen", "ha", "ha", "Cu\u00b7pi\u00b7do", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Sprach: Alter du hast nicht alles gemacht,", "tokens": ["Sprach", ":", "Al\u00b7ter", "du", "hast", "nicht", "al\u00b7les", "ge\u00b7macht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "PPER", "VAFIN", "PTKNEG", "PIS", "VVPP", "$,"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.11": {"text": "Besinn dich fein wohl, besinn dich fein wohl,", "tokens": ["Be\u00b7sinn", "dich", "fein", "wohl", ",", "be\u00b7sinn", "dich", "fein", "wohl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "ADV", "$,", "VVFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Das Beste fehlt hier, das billig seyn soll!", "tokens": ["Das", "Bes\u00b7te", "fehlt", "hier", ",", "das", "bil\u00b7lig", "seyn", "soll", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "PRELS", "ADJD", "VAINF", "VMFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Solches Jovem verdro\u00df hart,", "tokens": ["Sol\u00b7ches", "Jo\u00b7vem", "ver\u00b7dro\u00df", "hart", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "+----+-", "measure": "dactylic.init"}, "line.2": {"text": "Da\u00df er von diesem Kind,", "tokens": ["Da\u00df", "er", "von", "die\u00b7sem", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sp\u00f6ttlich verlachet ward,", "tokens": ["Sp\u00f6tt\u00b7lich", "ver\u00b7la\u00b7chet", "ward", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VAFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Da nahm er in sein Sinn,", "tokens": ["Da", "nahm", "er", "in", "sein", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Erschafft ein Kreatur", "tokens": ["Er\u00b7schafft", "ein", "Kre\u00b7a\u00b7tur"], "token_info": ["word", "word", "word"], "pos": ["NN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Ein sch\u00f6n jungfr\u00e4ulich Bild,", "tokens": ["Ein", "sch\u00f6n", "jung\u00b7fr\u00e4u\u00b7lich", "Bild", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Welche sch\u00f6ne Figur", "tokens": ["Wel\u00b7che", "sch\u00f6\u00b7ne", "Fi\u00b7gur"], "token_info": ["word", "word", "word"], "pos": ["PWAT", "ADJA", "NN"], "meter": "+-+---", "measure": "unknown.measure.di"}, "line.8": {"text": "Er f\u00fcr sein Kunstwerk hielt.", "tokens": ["Er", "f\u00fcr", "sein", "Kunst\u00b7werk", "hielt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Der Sachen ha ha Cupido lacht:", "tokens": ["Der", "Sa\u00b7chen", "ha", "ha", "Cu\u00b7pi\u00b7do", "lacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "NE", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Du hast alles recht wohl gemacht,", "tokens": ["Du", "hast", "al\u00b7les", "recht", "wohl", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADV", "ADV", "VVPP", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.11": {"text": "Des freu ich mich sehr, des freu ich mich sehr;", "tokens": ["Des", "freu", "ich", "mich", "sehr", ",", "des", "freu", "ich", "mich", "sehr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPER", "PRF", "ADV", "$,", "ART", "ADJD", "PPER", "PRF", "ADV", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Ach Lieber mach doch der Dinge noch mehr.", "tokens": ["Ach", "Lie\u00b7ber", "mach", "doch", "der", "Din\u00b7ge", "noch", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJD", "VVFIN", "ADV", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Welches Jovi Freuden bracht,", "tokens": ["Wel\u00b7ches", "Jo\u00b7vi", "Freu\u00b7den", "bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df dieses Kind nackend und blo\u00df,", "tokens": ["Da\u00df", "die\u00b7ses", "Kind", "na\u00b7ckend", "und", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "VVPP", "KON", "ADV", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Ihn sehr freundlich anlacht,", "tokens": ["Ihn", "sehr", "freund\u00b7lich", "an\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Drum setzt ers in sein Schoo\u00df,", "tokens": ["Drum", "setzt", "ers", "in", "sein", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das Bild entschlief so bald,", "tokens": ["Das", "Bild", "ent\u00b7schlief", "so", "bald", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Er h\u00e4tts gek\u00fc\u00dft so gern,", "tokens": ["Er", "h\u00e4tts", "ge\u00b7k\u00fc\u00dft", "so", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Wolts aber mit Gewalt,", "tokens": ["Wolts", "a\u00b7ber", "mit", "Ge\u00b7walt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Nicht aus dem Schlaf verst\u00f6rn.", "tokens": ["Nicht", "aus", "dem", "Schlaf", "ver\u00b7st\u00f6rn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "Der Sachen ha ha Cupido lacht,", "tokens": ["Der", "Sa\u00b7chen", "ha", "ha", "Cu\u00b7pi\u00b7do", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Sprach: Alter k\u00fc\u00df fort, bis sie erwacht,", "tokens": ["Sprach", ":", "Al\u00b7ter", "k\u00fc\u00df", "fort", ",", "bis", "sie", "er\u00b7wacht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "VVFIN", "PTKVZ", "$,", "KOUS", "PPER", "VVPP", "$,"], "meter": "-+--+---+", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "La\u00df also nicht ruhn, la\u00df also nicht ruhn,", "tokens": ["La\u00df", "al\u00b7so", "nicht", "ruhn", ",", "la\u00df", "al\u00b7so", "nicht", "ruhn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PTKNEG", "VVINF", "$,", "VVIMP", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Es ist ihr nicht um den Schlaf zu thun.", "tokens": ["Es", "ist", "ihr", "nicht", "um", "den", "Schlaf", "zu", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Dein Liebelein schlaf oder wach,", "tokens": ["Dein", "Lie\u00b7be\u00b7lein", "schlaf", "o\u00b7der", "wach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "So k\u00fc\u00df sie immerfort,", "tokens": ["So", "k\u00fc\u00df", "sie", "im\u00b7mer\u00b7fort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dir kein Gedanken mach,", "tokens": ["Dir", "kein", "Ge\u00b7dan\u00b7ken", "mach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Sondern glaub meinem Wort,", "tokens": ["Son\u00b7dern", "glaub", "mei\u00b7nem", "Wort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "K\u00fc\u00df sie so oft und wohl,", "tokens": ["K\u00fc\u00df", "sie", "so", "oft", "und", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Ich will verwetten was,", "tokens": ["Ich", "will", "ver\u00b7wet\u00b7ten", "was", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "PWS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Ob sie dich schelten soll,", "tokens": ["Ob", "sie", "dich", "schel\u00b7ten", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Sondern sprechen, k\u00fc\u00df nur bas!", "tokens": ["Son\u00b7dern", "spre\u00b7chen", ",", "k\u00fc\u00df", "nur", "bas", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "VVFIN", "ADV", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Der Sachen, ha ha, Cupido lacht,", "tokens": ["Der", "Sa\u00b7chen", ",", "ha", "ha", ",", "Cu\u00b7pi\u00b7do", "lacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ITJ", "ITJ", "$,", "NE", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Zwey Lieblein scherzen die ganze Nacht,", "tokens": ["Zwey", "Lieb\u00b7lein", "scher\u00b7zen", "die", "gan\u00b7ze", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "La\u00df also frey gehn, la\u00df also frey gehn,", "tokens": ["La\u00df", "al\u00b7so", "frey", "gehn", ",", "la\u00df", "al\u00b7so", "frey", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADJD", "VVINF", "$,", "VVIMP", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Ach Kinder was wird noch draus entstehn.", "tokens": ["Ach", "Kin\u00b7der", "was", "wird", "noch", "draus", "ent\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "PWS", "VAFIN", "ADV", "PAV", "VVINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Darum sch\u00f6nes Liebelein,", "tokens": ["Da\u00b7rum", "sch\u00f6\u00b7nes", "Lie\u00b7be\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df mich dir nun k\u00fcssen auch", "tokens": ["La\u00df", "mich", "dir", "nun", "k\u00fcs\u00b7sen", "auch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPER", "ADV", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dein werthes M\u00fcndelein,", "tokens": ["Dein", "wert\u00b7hes", "M\u00fcn\u00b7del\u00b7ein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Weils ist ein alter Brauch,", "tokens": ["Weils", "ist", "ein", "al\u00b7ter", "Brauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der mu\u00df abkommen nicht,", "tokens": ["Der", "mu\u00df", "ab\u00b7kom\u00b7men", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "VVINF", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Weils ist ein ehlich Pflicht,", "tokens": ["Weils", "ist", "ein", "eh\u00b7lich", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Und wenns in Ehren geschieht,", "tokens": ["Und", "wenns", "in", "Eh\u00b7ren", "ge\u00b7schieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "So kanns ja schaden nicht.", "tokens": ["So", "kanns", "ja", "scha\u00b7den", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "So haben die Alten einander gek\u00fc\u00dft,", "tokens": ["So", "ha\u00b7ben", "die", "Al\u00b7ten", "ein\u00b7an\u00b7der", "ge\u00b7k\u00fc\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.10": {"text": "Bis aus Zwey ein Drey worden ist.", "tokens": ["Bis", "aus", "Zwey", "ein", "Drey", "wor\u00b7den", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "CARD", "ART", "NN", "VAPP", "VAFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.11": {"text": "So la\u00dft uns nun auch halten den Gebrauch,", "tokens": ["So", "la\u00dft", "uns", "nun", "auch", "hal\u00b7ten", "den", "Ge\u00b7brauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "So lang wir leben auf dieser Erd.", "tokens": ["So", "lang", "wir", "le\u00b7ben", "auf", "die\u00b7ser", "Erd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}