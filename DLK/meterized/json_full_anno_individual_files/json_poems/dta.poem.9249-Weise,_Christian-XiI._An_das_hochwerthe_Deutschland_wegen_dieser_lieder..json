{"dta.poem.9249": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "XiI.  \n An das hochwerthe Deutschland wegen  \n dieser lieder.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Du liebstes vaterland! verg\u00f6nne deinem sohne/", "tokens": ["Du", "liebs\u00b7tes", "va\u00b7ter\u00b7land", "!", "ver\u00b7g\u00f6n\u00b7ne", "dei\u00b7nem", "soh\u00b7ne", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$.", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df er sein eitles thun der welt zu schauen giebt/", "tokens": ["Da\u00df", "er", "sein", "eit\u00b7les", "thun", "der", "welt", "zu", "schau\u00b7en", "giebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich sehne mich darbey nach keinem andern lohne/", "tokens": ["Ich", "seh\u00b7ne", "mich", "dar\u00b7bey", "nach", "kei\u00b7nem", "an\u00b7dern", "loh\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PAV", "APPR", "PIAT", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als wann die hohe gunst den guten willen liebt.", "tokens": ["Als", "wann", "die", "ho\u00b7he", "gunst", "den", "gu\u00b7ten", "wil\u00b7len", "liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich mu\u00df es zwar gestehn/ es sind geringe sachen/", "tokens": ["Ich", "mu\u00df", "es", "zwar", "ge\u00b7stehn", "/", "es", "sind", "ge\u00b7rin\u00b7ge", "sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVPP", "$(", "PPER", "VAFIN", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Daraus ein blosser schertz/ und sonsten nichts entspringt/", "tokens": ["Da\u00b7raus", "ein", "blos\u00b7ser", "schertz", "/", "und", "sons\u00b7ten", "nichts", "ent\u00b7springt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "$(", "KON", "VVFIN", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Jedoch/ ein kurtzes lied kan sich belieblich machen/", "tokens": ["Je\u00b7doch", "/", "ein", "kurt\u00b7zes", "lied", "kan", "sich", "be\u00b7lieb\u00b7lich", "ma\u00b7chen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ART", "ADJA", "NN", "VMFIN", "PRF", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wann nur die rechte zeit es auf die bahne bringt:", "tokens": ["Wann", "nur", "die", "rech\u00b7te", "zeit", "es", "auf", "die", "bah\u00b7ne", "bringt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich bin kein Opitz nicht/ der bleibt noch unser Meister/", "tokens": ["Ich", "bin", "kein", "O\u00b7pitz", "nicht", "/", "der", "bleibt", "noch", "un\u00b7ser", "Meis\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "PTKNEG", "$(", "ART", "VVFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und sein ber\u00fchmter thon reist durch das sternen-dach/", "tokens": ["Und", "sein", "be\u00b7r\u00fchm\u00b7ter", "thon", "reist", "durch", "das", "ster\u00b7nen\u00b7dach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Hingegen fliegen sonst die lobens-werthen geister", "tokens": ["Hin\u00b7ge\u00b7gen", "flie\u00b7gen", "sonst", "die", "lo\u00b7bens\u00b7wert\u00b7hen", "geis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.12": {"text": "Kaum auf den halben weg mit schwachen federn nach.", "tokens": ["Kaum", "auf", "den", "hal\u00b7ben", "weg", "mit", "schwa\u00b7chen", "fe\u00b7dern", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "ADV", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wiewohl ich darff mich nicht in die gesellschafft mengen/", "tokens": ["Wie\u00b7wohl", "ich", "darff", "mich", "nicht", "in", "die", "ge\u00b7sell\u00b7schafft", "men\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "PPER", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die durch den lorber-zweig das haar um sich verbindt/", "tokens": ["Die", "durch", "den", "lor\u00b7ber\u00b7zweig", "das", "haar", "um", "sich", "ver\u00b7bindt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ART", "NN", "APPR", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Mein gl\u00fccke f\u00fchrt mich sonst auf kunst-beliebten g\u00e4ngen/", "tokens": ["Mein", "gl\u00fc\u00b7cke", "f\u00fchrt", "mich", "sonst", "auf", "kunst\u00b7be\u00b7lieb\u00b7ten", "g\u00e4n\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da dieses neben-werck gar wenig stunden findt.", "tokens": ["Da", "die\u00b7ses", "ne\u00b7ben\u00b7\u00b7werck", "gar", "we\u00b7nig", "stun\u00b7den", "findt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ADV", "PIAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Doch liebstes Vaterland/ ich werde dir gefallen/", "tokens": ["Doch", "liebs\u00b7tes", "Va\u00b7ter\u00b7land", "/", "ich", "wer\u00b7de", "dir", "ge\u00b7fal\u00b7len", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$(", "PPER", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df ich im schreiben nicht ein sprach-tyranne bin/", "tokens": ["Da\u00df", "ich", "im", "schrei\u00b7ben", "nicht", "ein", "sprach\u00b7ty\u00b7ran\u00b7ne", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "VVFIN", "PTKNEG", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ich folge deiner zier/ und richte mich in allen", "tokens": ["Ich", "fol\u00b7ge", "dei\u00b7ner", "zier", "/", "und", "rich\u00b7te", "mich", "in", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$(", "KON", "VVFIN", "PRF", "APPR", "PIAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Auff alte reinigkeit und neue kurtzweil hin/", "tokens": ["Auff", "al\u00b7te", "rei\u00b7nig\u00b7keit", "und", "neu\u00b7e", "kurt\u00b7zweil", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ich bin so eckel nicht/ ich lasse mir belieben/", "tokens": ["Ich", "bin", "so", "ec\u00b7kel", "nicht", "/", "ich", "las\u00b7se", "mir", "be\u00b7lie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "PTKNEG", "$(", "PPER", "VVFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Was die gewohnheit itzt in langen brauch gebracht/", "tokens": ["Was", "die", "ge\u00b7wohn\u00b7heit", "itzt", "in", "lan\u00b7gen", "brauch", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "H\u00e4tt unser alterthum nicht so und so geschrieben/", "tokens": ["H\u00e4tt", "un\u00b7ser", "al\u00b7ter\u00b7thum", "nicht", "so", "und", "so", "ge\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "KON", "ADV", "VVPP", "$("], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "So h\u00e4tt es dieser kiel auch anders nachgemacht.", "tokens": ["So", "h\u00e4tt", "es", "die\u00b7ser", "kiel", "auch", "an\u00b7ders", "nach\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "VVFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und weil die Teutschen viel aus andern sprachen borgen/", "tokens": ["Und", "weil", "die", "Teut\u00b7schen", "viel", "aus", "an\u00b7dern", "spra\u00b7chen", "bor\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "APPR", "PIS", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "So mu\u00df ich ebenfalls mich auch darzu verstehn:", "tokens": ["So", "mu\u00df", "ich", "e\u00b7ben\u00b7falls", "mich", "auch", "dar\u00b7zu", "ver\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPER", "ADV", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ein ander/ dens verdreust/ mag sich zu tode sorgen/", "tokens": ["Ein", "an\u00b7der", "/", "dens", "ver\u00b7dreust", "/", "mag", "sich", "zu", "to\u00b7de", "sor\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$(", "ADV", "VVFIN", "$(", "VMFIN", "PRF", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Gnug/ da\u00df die Verse gut/ die Lieder lieblich gehn/", "tokens": ["Gnug", "/", "da\u00df", "die", "Ver\u00b7se", "gut", "/", "die", "Lie\u00b7der", "lieb\u00b7lich", "gehn", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "ART", "NN", "ADJD", "$(", "ART", "NN", "ADJD", "VVINF", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.29": {"text": "Ist di\u00df nicht puppenwerck/ wer etwas grosses heissen/", "tokens": ["Ist", "di\u00df", "nicht", "pup\u00b7pen\u00b7werck", "/", "wer", "et\u00b7was", "gros\u00b7ses", "heis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "PTKNEG", "NN", "$(", "PWS", "ADV", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und seinen lorbeer-krantz mit golde zieren will/", "tokens": ["Und", "sei\u00b7nen", "lor\u00b7beer\u00b7krantz", "mit", "gol\u00b7de", "zie\u00b7ren", "will", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Der mu\u00df das ABC aus seiner ordnung schmeissen/", "tokens": ["Der", "mu\u00df", "das", "AbC", "aus", "sei\u00b7ner", "ord\u00b7nung", "schmeis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Bald hat er nicht genug/ bald hat er gar zu viel/", "tokens": ["Bald", "hat", "er", "nicht", "ge\u00b7nug", "/", "bald", "hat", "er", "gar", "zu", "viel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADV", "$(", "ADV", "VAFIN", "PPER", "ADV", "PTKA", "PIS", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Da ist ein wort nicht recht/ das haben die Lateiner/", "tokens": ["Da", "ist", "ein", "wort", "nicht", "recht", "/", "das", "ha\u00b7ben", "die", "La\u00b7tei\u00b7ner", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKNEG", "ADJD", "$(", "PDS", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Gelehnt u. nicht geschenckt; das kom\u0303t aus Griechenland/", "tokens": ["Ge\u00b7lehnt", "u.", "nicht", "ge\u00b7schenckt", ";", "das", "kom\u0303t", "aus", "Grie\u00b7chen\u00b7land", "/"], "token_info": ["word", "abbreviation", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PTKNEG", "VVPP", "$.", "PDS", "VVFIN", "APPR", "NE", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "Da wird der thon zu lang/ da wird die sylbe kleiner/", "tokens": ["Da", "wird", "der", "thon", "zu", "lang", "/", "da", "wird", "die", "syl\u00b7be", "klei\u00b7ner", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKA", "ADJD", "$(", "ADV", "VAFIN", "ART", "ADJA", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Die sprache die wird nur nicht g\u00e4ntzlich umbgewandt.", "tokens": ["Die", "spra\u00b7che", "die", "wird", "nur", "nicht", "g\u00e4ntz\u00b7lich", "umb\u00b7ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PDS", "VAFIN", "ADV", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Der arme Zizero ist auch ins Z\u2019 gerathen/", "tokens": ["Der", "ar\u00b7me", "Zi\u00b7ze\u00b7ro", "ist", "auch", "ins", "Z'", "ge\u00b7ra\u00b7then", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VAFIN", "ADV", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Der sonst fast oben an/ in seiner reihe steht/", "tokens": ["Der", "sonst", "fast", "o\u00b7ben", "an", "/", "in", "sei\u00b7ner", "rei\u00b7he", "steht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "PTKVZ", "$(", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Vielleicht weil ein gem\u00fcth/ in diesen helden-thaten/", "tokens": ["Viel\u00b7leicht", "weil", "ein", "ge\u00b7m\u00fcth", "/", "in", "die\u00b7sen", "hel\u00b7den\u00b7tha\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "$(", "APPR", "PDAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Gar langsam auf den glantz der redens-k\u00fcnstler geht", "tokens": ["Gar", "lang\u00b7sam", "auf", "den", "glantz", "der", "re\u00b7den\u00b7sk\u00fcnst\u00b7ler", "geht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "ART", "ADJA", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Sanct Felten ist hinauff bi\u00df an das F gestiegen/", "tokens": ["Sanct", "Fel\u00b7ten", "ist", "hin\u00b7auff", "bi\u00df", "an", "das", "F", "ge\u00b7stie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Und er verdient f\u00fcrwahr die ehr-bezeugung nicht:", "tokens": ["Und", "er", "ver\u00b7dient", "f\u00fcr\u00b7wahr", "die", "ehr\u00b7be\u00b7zeu\u00b7gung", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Der Kwarck mu\u00df in das K aus seinem neste fliegen/", "tokens": ["Der", "Kwarck", "mu\u00df", "in", "das", "K", "aus", "sei\u00b7nem", "nes\u00b7te", "flie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "ART", "NN", "APPR", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Ob gleich die gantze welt den h\u00e4ndeln widerspricht/", "tokens": ["Ob", "gleich", "die", "gant\u00b7ze", "welt", "den", "h\u00e4n\u00b7deln", "wi\u00b7der\u00b7spricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Der K\u00e4yser soll bey uns nicht weiter K\u00e4yser heissen/", "tokens": ["Der", "K\u00e4y\u00b7ser", "soll", "bey", "uns", "nicht", "wei\u00b7ter", "K\u00e4y\u00b7ser", "heis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "PPER", "PTKNEG", "ADV", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Er soll daf\u00fcr ein Ertz- und grosser K\u00f6nig seyn/", "tokens": ["Er", "soll", "da\u00b7f\u00fcr", "ein", "Ertz", "und", "gros\u00b7ser", "K\u00f6\u00b7nig", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "ART", "TRUNC", "KON", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Wer uns di\u00df tapffre wort will aus der zunge reissen/", "tokens": ["Wer", "uns", "di\u00df", "tapf\u00b7fre", "wort", "will", "aus", "der", "zun\u00b7ge", "reis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PDS", "ADJA", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.48": {"text": "Raubt uns der v\u00f6lcker ruhm/ mit unsers landes schein/", "tokens": ["Raubt", "uns", "der", "v\u00f6l\u00b7cker", "ruhm", "/", "mit", "un\u00b7sers", "lan\u00b7des", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$(", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Ein solcher kl\u00fcgling hat gewi\u00df nicht viel gelesen/", "tokens": ["Ein", "sol\u00b7cher", "kl\u00fcg\u00b7ling", "hat", "ge\u00b7wi\u00df", "nicht", "viel", "ge\u00b7le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "ADV", "PTKNEG", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Und hat ers ja gethan/ so m\u00f6cht er in sich gehn/", "tokens": ["Und", "hat", "ers", "ja", "ge\u00b7than", "/", "so", "m\u00f6cht", "er", "in", "sich", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "ADV", "VVPP", "$(", "ADV", "VMFIN", "PPER", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Da\u00df unsre Deutschen auch nicht narren sind gewesen/", "tokens": ["Da\u00df", "uns\u00b7re", "Deut\u00b7schen", "auch", "nicht", "nar\u00b7ren", "sind", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "PTKNEG", "VVINF", "VAFIN", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Und da\u00df man alles kan ohn diesen tand verstehn.", "tokens": ["Und", "da\u00df", "man", "al\u00b7les", "kan", "ohn", "die\u00b7sen", "tand", "ver\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PIS", "VMFIN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ein ander mag sich mehr mit diesen leuten zancken/", "tokens": ["Ein", "an\u00b7der", "mag", "sich", "mehr", "mit", "die\u00b7sen", "leu\u00b7ten", "zan\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VMFIN", "PRF", "ADV", "APPR", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Mein ungebundner fu\u00df geht in der einfalt fort/", "tokens": ["Mein", "un\u00b7ge\u00b7bund\u00b7ner", "fu\u00df", "geht", "in", "der", "ein\u00b7falt", "fort", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "PTKVZ", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Und mein erregter sinn verwickelt die gedancken/", "tokens": ["Und", "mein", "er\u00b7reg\u00b7ter", "sinn", "ver\u00b7wi\u00b7ckelt", "die", "ge\u00b7dan\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Mehr in der sachen selbst/ als in ein kahles wort.", "tokens": ["Mehr", "in", "der", "sa\u00b7chen", "selbst", "/", "als", "in", "ein", "kah\u00b7les", "wort", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "ADV", "$(", "KOKOM", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Hier hab ich nur geschertzt/ doch wird man leicht gedencken/", "tokens": ["Hier", "hab", "ich", "nur", "ge\u00b7schertzt", "/", "doch", "wird", "man", "leicht", "ge\u00b7den\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$(", "ADV", "VAFIN", "PIS", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Da\u00df/ wie ich meiner lust allhier genug gethan/", "tokens": ["Da\u00df", "/", "wie", "ich", "mei\u00b7ner", "lust", "all\u00b7hier", "ge\u00b7nug", "ge\u00b7than", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "PWAV", "PPER", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Ich/ wann ich k\u00fcnfftig will die augen h\u00f6her lencken/", "tokens": ["Ich", "/", "wann", "ich", "k\u00fcnff\u00b7tig", "will", "die", "au\u00b7gen", "h\u00f6\u00b7her", "len\u00b7cken", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PWAV", "PPER", "ADJD", "VMFIN", "ART", "NN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Mit gleicher fertigkeit die feder richten kan.", "tokens": ["Mit", "glei\u00b7cher", "fer\u00b7tig\u00b7keit", "die", "fe\u00b7der", "rich\u00b7ten", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Ich bin auch nicht so k\u00fchn/ den ", "tokens": ["Ich", "bin", "auch", "nicht", "so", "k\u00fchn", "/", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "$(", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.62": {"text": "Weil er den h\u00f6hnschen mund nur an die G\u00f6tter setzt.", "tokens": ["Weil", "er", "den", "h\u00f6hn\u00b7schen", "mund", "nur", "an", "die", "G\u00f6t\u00b7ter", "setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Solt er di\u00df schlechte werck zu seiner rache suchen?", "tokens": ["Solt", "er", "di\u00df", "schlech\u00b7te", "werck", "zu", "sei\u00b7ner", "ra\u00b7che", "su\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PDS", "VVFIN", "NN", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Nein/ er ist viel zu stoltz/ wann er die z\u00e4hne wetzt.", "tokens": ["Nein", "/", "er", "ist", "viel", "zu", "stoltz", "/", "wann", "er", "die", "z\u00e4h\u00b7ne", "wetzt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "PPER", "VAFIN", "ADV", "PTKA", "ADJD", "$(", "PWAV", "PPER", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Drum bin ich auch vergn\u00fcgt/ und lege diese lieder/", "tokens": ["Drum", "bin", "ich", "auch", "ver\u00b7gn\u00fcgt", "/", "und", "le\u00b7ge", "die\u00b7se", "lie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "VVPP", "$(", "KON", "VVFIN", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Halb furchtsam und darbey halb trotzig vor die welt/", "tokens": ["Halb", "furcht\u00b7sam", "und", "dar\u00b7bey", "halb", "trot\u00b7zig", "vor", "die", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "KON", "PAV", "ADJD", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Es falle wie es will/ so komm ich doch nicht wieder/", "tokens": ["Es", "fal\u00b7le", "wie", "es", "will", "/", "so", "komm", "ich", "doch", "nicht", "wie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "PPER", "VMFIN", "$(", "ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Der himmel hat den flei\u00df mir sonst wohin bestellt.", "tokens": ["Der", "him\u00b7mel", "hat", "den", "flei\u00df", "mir", "sonst", "wo\u00b7hin", "be\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "PPER", "ADV", "PWAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}