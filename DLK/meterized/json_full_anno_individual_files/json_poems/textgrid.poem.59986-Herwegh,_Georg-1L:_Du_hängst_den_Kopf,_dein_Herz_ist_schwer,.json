{"textgrid.poem.59986": {"metadata": {"author": {"name": "Herwegh, Georg", "birth": "N.A.", "death": "N.A."}, "title": "1L: Du h\u00e4ngst den Kopf, dein Herz ist schwer,", "genre": "verse", "period": "N.A.", "pub_year": 1846, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du h\u00e4ngst den Kopf, dein Herz ist schwer,", "tokens": ["Du", "h\u00e4ngst", "den", "Kopf", ",", "dein", "Herz", "ist", "schwer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Kummer dr\u00fcckt und Sorg es;", "tokens": ["Und", "Kum\u00b7mer", "dr\u00fcckt", "und", "Sorg", "es", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "KON", "NN", "PPER", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mein deutscher Michel, du lachst nicht mehr,", "tokens": ["Mein", "deut\u00b7scher", "Mi\u00b7chel", ",", "du", "lachst", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NE", "$,", "PPER", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Selbst nicht \u00fcber Hermann Orges.", "tokens": ["Selbst", "nicht", "\u00fc\u00b7ber", "Her\u00b7mann", "Or\u00b7ges", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "NE", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "O tr\u00f6ste dich, dich hat das Gl\u00fcck", "tokens": ["O", "tr\u00f6s\u00b7te", "dich", ",", "dich", "hat", "das", "Gl\u00fcck"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bewahrt zu h\u00f6heren Zielen:", "tokens": ["Be\u00b7wahrt", "zu", "h\u00f6\u00b7he\u00b7ren", "Zie\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Es ist ja ein erb\u00e4rmlich St\u00fcck,", "tokens": ["Es", "ist", "ja", "ein", "er\u00b7b\u00e4rm\u00b7lich", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das sie erb\u00e4rmlich spielen.", "tokens": ["Das", "sie", "er\u00b7b\u00e4rm\u00b7lich", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Der gestern mit dem Dolch auf Pump", "tokens": ["Der", "ge\u00b7stern", "mit", "dem", "Dolch", "auf", "Pump"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "APPR", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Ein Brutus wollte werden \u2013", "tokens": ["Ein", "Bru\u00b7tus", "woll\u00b7te", "wer\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VMFIN", "VAINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Du hast's erlebt, wie weit ein Lump", "tokens": ["Du", "hast's", "er\u00b7lebt", ",", "wie", "weit", "ein", "Lump"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PWAV", "ADJD", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es jetzo bringt auf Erden!", "tokens": ["Es", "jet\u00b7zo", "bringt", "auf", "Er\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Du hast's erlebt, das Ruder nimmt", "tokens": ["Du", "hast's", "er\u00b7lebt", ",", "das", "Ru\u00b7der", "nimmt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Staates Robert Macaire,", "tokens": ["Des", "Staa\u00b7tes", "Ro\u00b7bert", "Ma\u00b7cai\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dem einst die Sterne hatten bestimmt", "tokens": ["Dem", "einst", "die", "Ster\u00b7ne", "hat\u00b7ten", "be\u00b7stimmt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Das Ruder \u2013 einer Galeere.", "tokens": ["Das", "Ru\u00b7der", "\u2013", "ei\u00b7ner", "Ga\u00b7lee\u00b7re", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Du hast's erlebt \u2013 du wei\u00dft, wie faul", "tokens": ["Du", "hast's", "er\u00b7lebt", "\u2013", "du", "wei\u00dft", ",", "wie", "faul"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "PPER", "VVFIN", "$,", "PWAV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es aussieht in der Kulisse:", "tokens": ["Es", "aus\u00b7sieht", "in", "der", "Ku\u00b7lis\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Sie protestieren mit dem Maul,", "tokens": ["Sie", "pro\u00b7tes\u00b7tie\u00b7ren", "mit", "dem", "Maul", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und hinten kriegen sie Schmisse.", "tokens": ["Und", "hin\u00b7ten", "krie\u00b7gen", "sie", "Schmis\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Du gro\u00dfe Denkernation,", "tokens": ["Du", "gro\u00b7\u00dfe", "Den\u00b7ker\u00b7na\u00b7ti\u00b7on", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O trockne die Augen, die feuchten;", "tokens": ["O", "trock\u00b7ne", "die", "Au\u00b7gen", ",", "die", "feuch\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADJA", "ART", "NN", "$,", "ART", "ADJA", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Dir bleibt die h\u00f6here Mission,", "tokens": ["Dir", "bleibt", "die", "h\u00f6\u00b7he\u00b7re", "Mis\u00b7si\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die B\u00fchne zu \u2013 erleuchten.", "tokens": ["Die", "B\u00fch\u00b7ne", "zu", "\u2013", "er\u00b7leuch\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "$(", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Die Juden ausgenommen, ist", "tokens": ["Die", "Ju\u00b7den", "aus\u00b7ge\u00b7nom\u00b7men", ",", "ist"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVPP", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht jeder geboren zum Handeln;", "tokens": ["Nicht", "je\u00b7der", "ge\u00b7bo\u00b7ren", "zum", "Han\u00b7deln", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "VVPP", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Die Szene kann der Maschinist", "tokens": ["Die", "Sze\u00b7ne", "kann", "der", "Ma\u00b7schi\u00b7nist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch ohne dich verwandeln.", "tokens": ["Auch", "oh\u00b7ne", "dich", "ver\u00b7wan\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und was er tut, ist wohlgetan,", "tokens": ["Und", "was", "er", "tut", ",", "ist", "wohl\u00b7ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Singt Gellert oder Lavater:", "tokens": ["Singt", "Gel\u00b7lert", "o\u00b7der", "La\u00b7va\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVPP", "KON", "NE", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du, Michel, z\u00fcnde die Lichter an", "tokens": ["Du", ",", "Mi\u00b7chel", ",", "z\u00fcn\u00b7de", "die", "Lich\u00b7ter", "an"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NE", "$,", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Im gro\u00dfen Welttheater.", "tokens": ["Im", "gro\u00b7\u00dfen", "Welt\u00b7the\u00b7a\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Der Schiller und Goethe, der Lessing und Kant,", "tokens": ["Der", "Schil\u00b7ler", "und", "Goe\u00b7the", ",", "der", "Les\u00b7sing", "und", "Kant", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "-+--+---+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das sind gewaltige Kerzen;", "tokens": ["Das", "sind", "ge\u00b7wal\u00b7ti\u00b7ge", "Ker\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie sind noch nicht heruntergebrannt", "tokens": ["Sie", "sind", "noch", "nicht", "her\u00b7un\u00b7ter\u00b7ge\u00b7brannt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wie andere deutsche Herzen.", "tokens": ["Wie", "an\u00b7de\u00b7re", "deut\u00b7sche", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Sie haben geleuchtet, sie leuchten hell,", "tokens": ["Sie", "ha\u00b7ben", "ge\u00b7leuch\u00b7tet", ",", "sie", "leuch\u00b7ten", "hell", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sie blitzen gleich Gewittern", "tokens": ["Sie", "blit\u00b7zen", "gleich", "Ge\u00b7wit\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und werden manchem Policinell", "tokens": ["Und", "wer\u00b7den", "man\u00b7chem", "Po\u00b7li\u00b7ci\u00b7nell"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Die Sp\u00e4\u00dfe noch verbittern.", "tokens": ["Die", "Sp\u00e4\u00b7\u00dfe", "noch", "ver\u00b7bit\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Sie sind gef\u00e4hrlicher, als du meinst:", "tokens": ["Sie", "sind", "ge\u00b7f\u00e4hr\u00b7li\u00b7cher", ",", "als", "du", "meinst", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von diesen Lichtern wird stammen", "tokens": ["Von", "die\u00b7sen", "Lich\u00b7tern", "wird", "stam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der hochverr\u00e4trische Funke, der einst", "tokens": ["Der", "hoch\u00b7ver\u00b7r\u00e4t\u00b7ri\u00b7sche", "Fun\u00b7ke", ",", "der", "einst"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Bude steckt in Flammen. \u2013", "tokens": ["Die", "Bu\u00b7de", "steckt", "in", "Flam\u00b7men", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Die Bude der Bretter, welche die Welt,", "tokens": ["Die", "Bu\u00b7de", "der", "Bret\u00b7ter", ",", "wel\u00b7che", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die heutige Welt bedeuten:", "tokens": ["Die", "heu\u00b7ti\u00b7ge", "Welt", "be\u00b7deu\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "F\u00fcr Buben ein gro\u00dfes Tatenfeld,", "tokens": ["F\u00fcr", "Bu\u00b7ben", "ein", "gro\u00b7\u00dfes", "Ta\u00b7ten\u00b7feld", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zu enge den ehrlichen Leuten.", "tokens": ["Zu", "en\u00b7ge", "den", "ehr\u00b7li\u00b7chen", "Leu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.13": {"line.1": {"text": "Und brennt er ab, der Kom\u00f6dien-Staat", "tokens": ["Und", "brennt", "er", "ab", ",", "der", "Ko\u00b7m\u00f6\u00b7di\u00b7en\u00b7Staat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Zepter, Kronen und Ketten,", "tokens": ["Mit", "Zep\u00b7ter", ",", "Kro\u00b7nen", "und", "Ket\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Es wird den Theaterapparat", "tokens": ["Es", "wird", "den", "The\u00b7a\u00b7te\u00b7rap\u00b7pa\u00b7rat"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Kein Branddirektor retten.", "tokens": ["Kein", "Brand\u00b7di\u00b7rek\u00b7tor", "ret\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Wir bauen auf des Hauses St\u00e4tt", "tokens": ["Wir", "bau\u00b7en", "auf", "des", "Hau\u00b7ses", "St\u00e4tt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein neues im gro\u00dfen Stile;", "tokens": ["Ein", "neu\u00b7es", "im", "gro\u00b7\u00dfen", "Sti\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da wollen wir sitzen im ersten Parkett,", "tokens": ["Da", "wol\u00b7len", "wir", "sit\u00b7zen", "im", "ers\u00b7ten", "Par\u00b7kett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Um \u2013 zuzuschauen dem Spiele.", "tokens": ["Um", "\u2013", "zu\u00b7zu\u00b7schau\u00b7en", "dem", "Spie\u00b7le", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "$(", "VVIZU", "ART", "NN", "$."], "meter": "---+--+-", "measure": "iambic.di.relaxed"}}, "stanza.15": {"line.1": {"text": "Du h\u00e4ngst den Kopf, dein Herz ist schwer,", "tokens": ["Du", "h\u00e4ngst", "den", "Kopf", ",", "dein", "Herz", "ist", "schwer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Kummer dr\u00fcckt und Sorg es;", "tokens": ["Und", "Kum\u00b7mer", "dr\u00fcckt", "und", "Sorg", "es", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "KON", "NN", "PPER", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mein deutscher Michel, du lachst nicht mehr,", "tokens": ["Mein", "deut\u00b7scher", "Mi\u00b7chel", ",", "du", "lachst", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NE", "$,", "PPER", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Selbst nicht \u00fcber Hermann Orges.", "tokens": ["Selbst", "nicht", "\u00fc\u00b7ber", "Her\u00b7mann", "Or\u00b7ges", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "NE", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "O tr\u00f6ste dich, dich hat das Gl\u00fcck", "tokens": ["O", "tr\u00f6s\u00b7te", "dich", ",", "dich", "hat", "das", "Gl\u00fcck"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bewahrt zu h\u00f6heren Zielen:", "tokens": ["Be\u00b7wahrt", "zu", "h\u00f6\u00b7he\u00b7ren", "Zie\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Es ist ja ein erb\u00e4rmlich St\u00fcck,", "tokens": ["Es", "ist", "ja", "ein", "er\u00b7b\u00e4rm\u00b7lich", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das sie erb\u00e4rmlich spielen.", "tokens": ["Das", "sie", "er\u00b7b\u00e4rm\u00b7lich", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Der gestern mit dem Dolch auf Pump", "tokens": ["Der", "ge\u00b7stern", "mit", "dem", "Dolch", "auf", "Pump"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "APPR", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Ein Brutus wollte werden \u2013", "tokens": ["Ein", "Bru\u00b7tus", "woll\u00b7te", "wer\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VMFIN", "VAINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Du hast's erlebt, wie weit ein Lump", "tokens": ["Du", "hast's", "er\u00b7lebt", ",", "wie", "weit", "ein", "Lump"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PWAV", "ADJD", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es jetzo bringt auf Erden!", "tokens": ["Es", "jet\u00b7zo", "bringt", "auf", "Er\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Du hast's erlebt, das Ruder nimmt", "tokens": ["Du", "hast's", "er\u00b7lebt", ",", "das", "Ru\u00b7der", "nimmt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Staates Robert Macaire,", "tokens": ["Des", "Staa\u00b7tes", "Ro\u00b7bert", "Ma\u00b7cai\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dem einst die Sterne hatten bestimmt", "tokens": ["Dem", "einst", "die", "Ster\u00b7ne", "hat\u00b7ten", "be\u00b7stimmt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Das Ruder \u2013 einer Galeere.", "tokens": ["Das", "Ru\u00b7der", "\u2013", "ei\u00b7ner", "Ga\u00b7lee\u00b7re", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Du hast's erlebt \u2013 du wei\u00dft, wie faul", "tokens": ["Du", "hast's", "er\u00b7lebt", "\u2013", "du", "wei\u00dft", ",", "wie", "faul"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "PPER", "VVFIN", "$,", "PWAV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es aussieht in der Kulisse:", "tokens": ["Es", "aus\u00b7sieht", "in", "der", "Ku\u00b7lis\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Sie protestieren mit dem Maul,", "tokens": ["Sie", "pro\u00b7tes\u00b7tie\u00b7ren", "mit", "dem", "Maul", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und hinten kriegen sie Schmisse.", "tokens": ["Und", "hin\u00b7ten", "krie\u00b7gen", "sie", "Schmis\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "Du gro\u00dfe Denkernation,", "tokens": ["Du", "gro\u00b7\u00dfe", "Den\u00b7ker\u00b7na\u00b7ti\u00b7on", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O trockne die Augen, die feuchten;", "tokens": ["O", "trock\u00b7ne", "die", "Au\u00b7gen", ",", "die", "feuch\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADJA", "ART", "NN", "$,", "ART", "ADJA", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Dir bleibt die h\u00f6here Mission,", "tokens": ["Dir", "bleibt", "die", "h\u00f6\u00b7he\u00b7re", "Mis\u00b7si\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die B\u00fchne zu \u2013 erleuchten.", "tokens": ["Die", "B\u00fch\u00b7ne", "zu", "\u2013", "er\u00b7leuch\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "$(", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Die Juden ausgenommen, ist", "tokens": ["Die", "Ju\u00b7den", "aus\u00b7ge\u00b7nom\u00b7men", ",", "ist"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVPP", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht jeder geboren zum Handeln;", "tokens": ["Nicht", "je\u00b7der", "ge\u00b7bo\u00b7ren", "zum", "Han\u00b7deln", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "VVPP", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Die Szene kann der Maschinist", "tokens": ["Die", "Sze\u00b7ne", "kann", "der", "Ma\u00b7schi\u00b7nist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch ohne dich verwandeln.", "tokens": ["Auch", "oh\u00b7ne", "dich", "ver\u00b7wan\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Und was er tut, ist wohlgetan,", "tokens": ["Und", "was", "er", "tut", ",", "ist", "wohl\u00b7ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Singt Gellert oder Lavater:", "tokens": ["Singt", "Gel\u00b7lert", "o\u00b7der", "La\u00b7va\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVPP", "KON", "NE", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du, Michel, z\u00fcnde die Lichter an", "tokens": ["Du", ",", "Mi\u00b7chel", ",", "z\u00fcn\u00b7de", "die", "Lich\u00b7ter", "an"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NE", "$,", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Im gro\u00dfen Welttheater.", "tokens": ["Im", "gro\u00b7\u00dfen", "Welt\u00b7the\u00b7a\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Der Schiller und Goethe, der Lessing und Kant,", "tokens": ["Der", "Schil\u00b7ler", "und", "Goe\u00b7the", ",", "der", "Les\u00b7sing", "und", "Kant", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "-+--+---+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das sind gewaltige Kerzen;", "tokens": ["Das", "sind", "ge\u00b7wal\u00b7ti\u00b7ge", "Ker\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie sind noch nicht heruntergebrannt", "tokens": ["Sie", "sind", "noch", "nicht", "her\u00b7un\u00b7ter\u00b7ge\u00b7brannt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wie andere deutsche Herzen.", "tokens": ["Wie", "an\u00b7de\u00b7re", "deut\u00b7sche", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.24": {"line.1": {"text": "Sie haben geleuchtet, sie leuchten hell,", "tokens": ["Sie", "ha\u00b7ben", "ge\u00b7leuch\u00b7tet", ",", "sie", "leuch\u00b7ten", "hell", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sie blitzen gleich Gewittern", "tokens": ["Sie", "blit\u00b7zen", "gleich", "Ge\u00b7wit\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und werden manchem Policinell", "tokens": ["Und", "wer\u00b7den", "man\u00b7chem", "Po\u00b7li\u00b7ci\u00b7nell"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Die Sp\u00e4\u00dfe noch verbittern.", "tokens": ["Die", "Sp\u00e4\u00b7\u00dfe", "noch", "ver\u00b7bit\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Sie sind gef\u00e4hrlicher, als du meinst:", "tokens": ["Sie", "sind", "ge\u00b7f\u00e4hr\u00b7li\u00b7cher", ",", "als", "du", "meinst", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von diesen Lichtern wird stammen", "tokens": ["Von", "die\u00b7sen", "Lich\u00b7tern", "wird", "stam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der hochverr\u00e4trische Funke, der einst", "tokens": ["Der", "hoch\u00b7ver\u00b7r\u00e4t\u00b7ri\u00b7sche", "Fun\u00b7ke", ",", "der", "einst"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Bude steckt in Flammen. \u2013", "tokens": ["Die", "Bu\u00b7de", "steckt", "in", "Flam\u00b7men", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Die Bude der Bretter, welche die Welt,", "tokens": ["Die", "Bu\u00b7de", "der", "Bret\u00b7ter", ",", "wel\u00b7che", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die heutige Welt bedeuten:", "tokens": ["Die", "heu\u00b7ti\u00b7ge", "Welt", "be\u00b7deu\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "F\u00fcr Buben ein gro\u00dfes Tatenfeld,", "tokens": ["F\u00fcr", "Bu\u00b7ben", "ein", "gro\u00b7\u00dfes", "Ta\u00b7ten\u00b7feld", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zu enge den ehrlichen Leuten.", "tokens": ["Zu", "en\u00b7ge", "den", "ehr\u00b7li\u00b7chen", "Leu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.27": {"line.1": {"text": "Und brennt er ab, der Kom\u00f6dien-Staat", "tokens": ["Und", "brennt", "er", "ab", ",", "der", "Ko\u00b7m\u00f6\u00b7di\u00b7en\u00b7Staat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Zepter, Kronen und Ketten,", "tokens": ["Mit", "Zep\u00b7ter", ",", "Kro\u00b7nen", "und", "Ket\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Es wird den Theaterapparat", "tokens": ["Es", "wird", "den", "The\u00b7a\u00b7te\u00b7rap\u00b7pa\u00b7rat"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Kein Branddirektor retten.", "tokens": ["Kein", "Brand\u00b7di\u00b7rek\u00b7tor", "ret\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Wir bauen auf des Hauses St\u00e4tt", "tokens": ["Wir", "bau\u00b7en", "auf", "des", "Hau\u00b7ses", "St\u00e4tt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein neues im gro\u00dfen Stile;", "tokens": ["Ein", "neu\u00b7es", "im", "gro\u00b7\u00dfen", "Sti\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da wollen wir sitzen im ersten Parkett,", "tokens": ["Da", "wol\u00b7len", "wir", "sit\u00b7zen", "im", "ers\u00b7ten", "Par\u00b7kett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Um \u2013 zuzuschauen dem Spiele.", "tokens": ["Um", "\u2013", "zu\u00b7zu\u00b7schau\u00b7en", "dem", "Spie\u00b7le", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "$(", "VVIZU", "ART", "NN", "$."], "meter": "---+--+-", "measure": "iambic.di.relaxed"}}}}}