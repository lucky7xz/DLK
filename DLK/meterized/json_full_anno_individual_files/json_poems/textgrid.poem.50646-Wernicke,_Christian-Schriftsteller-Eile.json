{"textgrid.poem.50646": {"metadata": {"author": {"name": "Wernicke, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Schriftsteller-Eile", "genre": "verse", "period": "N.A.", "pub_year": 1693, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was Marcus schreibt, das ist geschrieben,", "tokens": ["Was", "Mar\u00b7cus", "schreibt", ",", "das", "ist", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "VVFIN", "$,", "PDS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und was ihm aus der Feder f\u00e4llt,", "tokens": ["Und", "was", "ihm", "aus", "der", "Fe\u00b7der", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist, wie es f\u00e4llt, auch liegen", "tokens": ["Ist", ",", "wie", "es", "f\u00e4llt", ",", "auch", "lie\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und fragst du, was die Ursach sei?", "tokens": ["Und", "fragst", "du", ",", "was", "die", "Ur\u00b7sach", "sei", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PRELS", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Weil er Nachdenklichkeit f\u00fcr Beutelschneiderei,", "tokens": ["Weil", "er", "Nach\u00b7denk\u00b7lich\u00b7keit", "f\u00fcr", "Beu\u00b7tel\u00b7schnei\u00b7de\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und ein durchstrichen Wort f\u00fcr Mord und Todtschlag h\u00e4lt.", "tokens": ["Und", "ein", "durch\u00b7stri\u00b7chen", "Wort", "f\u00fcr", "Mord", "und", "Todt\u00b7schlag", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was Marcus schreibt, das ist geschrieben,", "tokens": ["Was", "Mar\u00b7cus", "schreibt", ",", "das", "ist", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "VVFIN", "$,", "PDS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und was ihm aus der Feder f\u00e4llt,", "tokens": ["Und", "was", "ihm", "aus", "der", "Fe\u00b7der", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist, wie es f\u00e4llt, auch liegen", "tokens": ["Ist", ",", "wie", "es", "f\u00e4llt", ",", "auch", "lie\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und fragst du, was die Ursach sei?", "tokens": ["Und", "fragst", "du", ",", "was", "die", "Ur\u00b7sach", "sei", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PRELS", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Weil er Nachdenklichkeit f\u00fcr Beutelschneiderei,", "tokens": ["Weil", "er", "Nach\u00b7denk\u00b7lich\u00b7keit", "f\u00fcr", "Beu\u00b7tel\u00b7schnei\u00b7de\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und ein durchstrichen Wort f\u00fcr Mord und Todtschlag h\u00e4lt.", "tokens": ["Und", "ein", "durch\u00b7stri\u00b7chen", "Wort", "f\u00fcr", "Mord", "und", "Todt\u00b7schlag", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}