{"textgrid.poem.44250": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "[corvin, der vor der Zeit der Biebel Blumen stahl]", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Corvin, der vor der Zeit der Biebel Blumen stahl", "tokens": ["Cor\u00b7vin", ",", "der", "vor", "der", "Zeit", "der", "Bie\u00b7bel", "Blu\u00b7men", "stahl"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "APPR", "ART", "NN", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und . . . . . . das Haupt der Geilheit mit zu schm\u00fccken,", "tokens": ["Und", ".", ".", ".", ".", ".", ".", "das", "Haupt", "der", "Geil\u00b7heit", "mit", "zu", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$.", "$.", "$.", "$.", "$.", "$.", "ART", "NN", "ART", "NN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Erschien jezt am Parna\u00df und in des Phoebus Saal", "tokens": ["Er\u00b7schien", "jezt", "am", "Par\u00b7na\u00df", "und", "in", "des", "Phoe\u00b7bus", "Saal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPRART", "NN", "KON", "APPR", "ART", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und lies den Korbvoll Obst von reifen Fr\u00fcchten blicken.", "tokens": ["Und", "lies", "den", "Korb\u00b7voll", "Obst", "von", "rei\u00b7fen", "Fr\u00fcch\u00b7ten", "bli\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie nun die M\u00e4gdgen stets am ersten l\u00fcstern sind,", "tokens": ["Wie", "nun", "die", "M\u00e4gd\u00b7gen", "stets", "am", "ers\u00b7ten", "l\u00fcs\u00b7tern", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "APPRART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So kam die Musenschaar mit Vorwiz hergelaufen,", "tokens": ["So", "kam", "die", "Mu\u00b7sen\u00b7schaar", "mit", "Vor\u00b7wiz", "her\u00b7ge\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Um was . . . . . . . . . . . . . . . . . . . . . . . zu kaufen.", "tokens": ["Um", "was", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "zu", "kau\u00b7fen", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["KOUI", "PWS", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "PTKZU", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Jedoch ihr Appetit lies hier . . . . . ziemlich blind;", "tokens": ["Je\u00b7doch", "ihr", "Ap\u00b7pe\u00b7tit", "lies", "hier", ".", ".", ".", ".", ".", "ziem\u00b7lich", "blind", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "ADV", "ADJD", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.9": {"text": "Denn als sich nach und nach . . . . . . . . . . bi\u00dfen,", "tokens": ["Denn", "als", "sich", "nach", "und", "nach", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "bi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "KOUS", "PRF", "APPR", "KON", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADV", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.10": {"text": "Verlor sich der Geschmack, und keine konte wi\u00dfen,", "tokens": ["Ver\u00b7lor", "sich", "der", "Ge\u00b7schmack", ",", "und", "kei\u00b7ne", "kon\u00b7te", "wi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$,", "KON", "PIAT", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Von was vor Land und Art . . . . . . . . . . . w\u00e4r.", "tokens": ["Von", "was", "vor", "Land", "und", "Art", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "NN", "KON", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Die eine rieth . . . . . . . und sprach von ohngefehr,", "tokens": ["Die", "ei\u00b7ne", "rieth", ".", ".", ".", ".", ".", ".", ".", "und", "sprach", "von", "ohn\u00b7ge\u00b7fehr", ","], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "KON", "VVFIN", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Es m\u00fc\u00dfen Mispeln seyn, und zwar aus diesem Grunde,", "tokens": ["Es", "m\u00fc\u00b7\u00dfen", "Mis\u00b7peln", "seyn", ",", "und", "zwar", "aus", "die\u00b7sem", "Grun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "VAINF", "$,", "KON", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Dieweil sie au\u00dfen Stroh und innen Steine fand.", "tokens": ["Die\u00b7weil", "sie", "au\u00b7\u00dfen", "Stroh", "und", "in\u00b7nen", "Stei\u00b7ne", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Thalia ist schon l\u00e4ngst durch ihren Hohn bekand,", "tokens": ["Tha\u00b7lia", "ist", "schon", "l\u00e4ngst", "durch", "ih\u00b7ren", "Hohn", "be\u00b7kand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.16": {"text": "Und darum sprach sie gleich mit . . . . . . Munde:", "tokens": ["Und", "da\u00b7rum", "sprach", "sie", "gleich", "mit", ".", ".", ".", ".", ".", ".", "Mun\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Was braucht es denn hierf\u00fcr der Gr\u00fcnde viel und fein?", "tokens": ["Was", "braucht", "es", "denn", "hier\u00b7f\u00fcr", "der", "Gr\u00fcn\u00b7de", "viel", "und", "fein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PAV", "ART", "NN", "ADV", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ich f\u00fchl, es werden nichts als Plapperbeeren seyn.", "tokens": ["Ich", "f\u00fchl", ",", "es", "wer\u00b7den", "nichts", "als", "Plap\u00b7per\u00b7bee\u00b7ren", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PIS", "KOKOM", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Corvin, der vor der Zeit der Biebel Blumen stahl", "tokens": ["Cor\u00b7vin", ",", "der", "vor", "der", "Zeit", "der", "Bie\u00b7bel", "Blu\u00b7men", "stahl"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "APPR", "ART", "NN", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und . . . . . . das Haupt der Geilheit mit zu schm\u00fccken,", "tokens": ["Und", ".", ".", ".", ".", ".", ".", "das", "Haupt", "der", "Geil\u00b7heit", "mit", "zu", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$.", "$.", "$.", "$.", "$.", "$.", "ART", "NN", "ART", "NN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Erschien jezt am Parna\u00df und in des Phoebus Saal", "tokens": ["Er\u00b7schien", "jezt", "am", "Par\u00b7na\u00df", "und", "in", "des", "Phoe\u00b7bus", "Saal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPRART", "NN", "KON", "APPR", "ART", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und lies den Korbvoll Obst von reifen Fr\u00fcchten blicken.", "tokens": ["Und", "lies", "den", "Korb\u00b7voll", "Obst", "von", "rei\u00b7fen", "Fr\u00fcch\u00b7ten", "bli\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie nun die M\u00e4gdgen stets am ersten l\u00fcstern sind,", "tokens": ["Wie", "nun", "die", "M\u00e4gd\u00b7gen", "stets", "am", "ers\u00b7ten", "l\u00fcs\u00b7tern", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "APPRART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So kam die Musenschaar mit Vorwiz hergelaufen,", "tokens": ["So", "kam", "die", "Mu\u00b7sen\u00b7schaar", "mit", "Vor\u00b7wiz", "her\u00b7ge\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Um was . . . . . . . . . . . . . . . . . . . . . . . zu kaufen.", "tokens": ["Um", "was", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "zu", "kau\u00b7fen", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["KOUI", "PWS", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "PTKZU", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Jedoch ihr Appetit lies hier . . . . . ziemlich blind;", "tokens": ["Je\u00b7doch", "ihr", "Ap\u00b7pe\u00b7tit", "lies", "hier", ".", ".", ".", ".", ".", "ziem\u00b7lich", "blind", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "ADV", "$.", "$.", "$.", "$.", "$.", "ADV", "ADJD", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.9": {"text": "Denn als sich nach und nach . . . . . . . . . . bi\u00dfen,", "tokens": ["Denn", "als", "sich", "nach", "und", "nach", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "bi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "KOUS", "PRF", "APPR", "KON", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADV", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.10": {"text": "Verlor sich der Geschmack, und keine konte wi\u00dfen,", "tokens": ["Ver\u00b7lor", "sich", "der", "Ge\u00b7schmack", ",", "und", "kei\u00b7ne", "kon\u00b7te", "wi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$,", "KON", "PIAT", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Von was vor Land und Art . . . . . . . . . . . w\u00e4r.", "tokens": ["Von", "was", "vor", "Land", "und", "Art", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "NN", "KON", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Die eine rieth . . . . . . . und sprach von ohngefehr,", "tokens": ["Die", "ei\u00b7ne", "rieth", ".", ".", ".", ".", ".", ".", ".", "und", "sprach", "von", "ohn\u00b7ge\u00b7fehr", ","], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "KON", "VVFIN", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Es m\u00fc\u00dfen Mispeln seyn, und zwar aus diesem Grunde,", "tokens": ["Es", "m\u00fc\u00b7\u00dfen", "Mis\u00b7peln", "seyn", ",", "und", "zwar", "aus", "die\u00b7sem", "Grun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "VAINF", "$,", "KON", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Dieweil sie au\u00dfen Stroh und innen Steine fand.", "tokens": ["Die\u00b7weil", "sie", "au\u00b7\u00dfen", "Stroh", "und", "in\u00b7nen", "Stei\u00b7ne", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Thalia ist schon l\u00e4ngst durch ihren Hohn bekand,", "tokens": ["Tha\u00b7lia", "ist", "schon", "l\u00e4ngst", "durch", "ih\u00b7ren", "Hohn", "be\u00b7kand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.16": {"text": "Und darum sprach sie gleich mit . . . . . . Munde:", "tokens": ["Und", "da\u00b7rum", "sprach", "sie", "gleich", "mit", ".", ".", ".", ".", ".", ".", "Mun\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Was braucht es denn hierf\u00fcr der Gr\u00fcnde viel und fein?", "tokens": ["Was", "braucht", "es", "denn", "hier\u00b7f\u00fcr", "der", "Gr\u00fcn\u00b7de", "viel", "und", "fein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PAV", "ART", "NN", "ADV", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ich f\u00fchl, es werden nichts als Plapperbeeren seyn.", "tokens": ["Ich", "f\u00fchl", ",", "es", "wer\u00b7den", "nichts", "als", "Plap\u00b7per\u00b7bee\u00b7ren", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PIS", "KOKOM", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}