{"textgrid.poem.23951": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "Rosen", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als ich im kurzen R\u00f6ckchen ging,", "tokens": ["Als", "ich", "im", "kur\u00b7zen", "R\u00f6ck\u00b7chen", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da wu\u00dft ich gerne jedes Ding", "tokens": ["Da", "wu\u00dft", "ich", "ger\u00b7ne", "je\u00b7des", "Ding"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und lie\u00df der Mutter keine Ruh:", "tokens": ["Und", "lie\u00df", "der", "Mut\u00b7ter", "kei\u00b7ne", "Ruh", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Warum? Weshalb? Wieso? Wozu?", "tokens": ["Wa\u00b7rum", "?", "We\u00b7shalb", "?", "Wie\u00b7so", "?", "Wo\u00b7zu", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "$.", "PWAV", "$.", "PWAV", "$.", "PWAV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schwer war es, Antwort sagen", "tokens": ["Schwer", "war", "es", ",", "Ant\u00b7wort", "sa\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Auf soviel schwere Fragen:", "tokens": ["Auf", "so\u00b7viel", "schwe\u00b7re", "Fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.7": {"text": "Du Mama, sag, Mama,", "tokens": ["Du", "Ma\u00b7ma", ",", "sag", ",", "Ma\u00b7ma", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "NN", "$,", "VVFIN", "$,", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Wozu sind denn die Rosen da?", "tokens": ["Wo\u00b7zu", "sind", "denn", "die", "Ro\u00b7sen", "da", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sprach Mama:", "tokens": ["Sprach", "Ma\u00b7ma", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Eisasa!", "tokens": ["Ei\u00b7sa\u00b7sa", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.11": {"text": "Rosen sind zum Brechen da.", "tokens": ["Ro\u00b7sen", "sind", "zum", "Bre\u00b7chen", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Nun trag ich schon ein langes Kleid", "tokens": ["Nun", "trag", "ich", "schon", "ein", "lan\u00b7ges", "Kleid"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bin selbst f\u00fcrchterlich gescheidt", "tokens": ["Und", "bin", "selbst", "f\u00fcrch\u00b7ter\u00b7lich", "ge\u00b7scheidt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und darf nicht jeden stellen: Du,", "tokens": ["Und", "darf", "nicht", "je\u00b7den", "stel\u00b7len", ":", "Du", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "PIS", "VVINF", "$.", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Warum? Weshalb? Wieso? Wozu?", "tokens": ["Wa\u00b7rum", "?", "We\u00b7shalb", "?", "Wie\u00b7so", "?", "Wo\u00b7zu", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "$.", "PWAV", "$.", "PWAV", "$.", "PWAV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und hab doch viel zu fragen.", "tokens": ["Und", "hab", "doch", "viel", "zu", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Was w\u00fcrde die wohl sagen,", "tokens": ["Was", "w\u00fcr\u00b7de", "die", "wohl", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Fr\u00fcg ich: Du, sag, Mama:", "tokens": ["Fr\u00fcg", "ich", ":", "Du", ",", "sag", ",", "Ma\u00b7ma", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "$.", "PPER", "$,", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Wozu sind denn wir M\u00e4dchen da?", "tokens": ["Wo\u00b7zu", "sind", "denn", "wir", "M\u00e4d\u00b7chen", "da", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "KON", "PPER", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Spr\u00e4ch Mama:", "tokens": ["Spr\u00e4ch", "Ma\u00b7ma", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Eisasa!", "tokens": ["Ei\u00b7sa\u00b7sa", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.11": {"text": "M\u00e4dchen sind zum K\u00fcssen da.", "tokens": ["M\u00e4d\u00b7chen", "sind", "zum", "K\u00fcs\u00b7sen", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Als ich im kurzen R\u00f6ckchen ging,", "tokens": ["Als", "ich", "im", "kur\u00b7zen", "R\u00f6ck\u00b7chen", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da wu\u00dft ich gerne jedes Ding", "tokens": ["Da", "wu\u00dft", "ich", "ger\u00b7ne", "je\u00b7des", "Ding"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und lie\u00df der Mutter keine Ruh:", "tokens": ["Und", "lie\u00df", "der", "Mut\u00b7ter", "kei\u00b7ne", "Ruh", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Warum? Weshalb? Wieso? Wozu?", "tokens": ["Wa\u00b7rum", "?", "We\u00b7shalb", "?", "Wie\u00b7so", "?", "Wo\u00b7zu", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "$.", "PWAV", "$.", "PWAV", "$.", "PWAV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schwer war es, Antwort sagen", "tokens": ["Schwer", "war", "es", ",", "Ant\u00b7wort", "sa\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Auf soviel schwere Fragen:", "tokens": ["Auf", "so\u00b7viel", "schwe\u00b7re", "Fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.7": {"text": "Du Mama, sag, Mama,", "tokens": ["Du", "Ma\u00b7ma", ",", "sag", ",", "Ma\u00b7ma", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "NN", "$,", "VVFIN", "$,", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Wozu sind denn die Rosen da?", "tokens": ["Wo\u00b7zu", "sind", "denn", "die", "Ro\u00b7sen", "da", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sprach Mama:", "tokens": ["Sprach", "Ma\u00b7ma", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Eisasa!", "tokens": ["Ei\u00b7sa\u00b7sa", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.11": {"text": "Rosen sind zum Brechen da.", "tokens": ["Ro\u00b7sen", "sind", "zum", "Bre\u00b7chen", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Nun trag ich schon ein langes Kleid", "tokens": ["Nun", "trag", "ich", "schon", "ein", "lan\u00b7ges", "Kleid"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bin selbst f\u00fcrchterlich gescheidt", "tokens": ["Und", "bin", "selbst", "f\u00fcrch\u00b7ter\u00b7lich", "ge\u00b7scheidt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und darf nicht jeden stellen: Du,", "tokens": ["Und", "darf", "nicht", "je\u00b7den", "stel\u00b7len", ":", "Du", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "PIS", "VVINF", "$.", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Warum? Weshalb? Wieso? Wozu?", "tokens": ["Wa\u00b7rum", "?", "We\u00b7shalb", "?", "Wie\u00b7so", "?", "Wo\u00b7zu", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "$.", "PWAV", "$.", "PWAV", "$.", "PWAV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und hab doch viel zu fragen.", "tokens": ["Und", "hab", "doch", "viel", "zu", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Was w\u00fcrde die wohl sagen,", "tokens": ["Was", "w\u00fcr\u00b7de", "die", "wohl", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Fr\u00fcg ich: Du, sag, Mama:", "tokens": ["Fr\u00fcg", "ich", ":", "Du", ",", "sag", ",", "Ma\u00b7ma", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "$.", "PPER", "$,", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Wozu sind denn wir M\u00e4dchen da?", "tokens": ["Wo\u00b7zu", "sind", "denn", "wir", "M\u00e4d\u00b7chen", "da", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "KON", "PPER", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Spr\u00e4ch Mama:", "tokens": ["Spr\u00e4ch", "Ma\u00b7ma", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Eisasa!", "tokens": ["Ei\u00b7sa\u00b7sa", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.11": {"text": "M\u00e4dchen sind zum K\u00fcssen da.", "tokens": ["M\u00e4d\u00b7chen", "sind", "zum", "K\u00fcs\u00b7sen", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}