{"textgrid.poem.46997": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Morgentau verstreut im Thale", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Morgentau verstreut im Thale", "tokens": ["Der", "Mor\u00b7gen\u00b7tau", "ver\u00b7streut", "im", "Tha\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sein blitzendes Geschmeide;", "tokens": ["Sein", "blit\u00b7zen\u00b7des", "Ge\u00b7schmei\u00b7de", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da richtet sich im ersten Strahle", "tokens": ["Da", "rich\u00b7tet", "sich", "im", "ers\u00b7ten", "Strah\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Empor am Bach die Weide.", "tokens": ["Em\u00b7por", "am", "Bach", "die", "Wei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Im Nachttau lie\u00df sie niederhangen", "tokens": ["Im", "Nacht\u00b7tau", "lie\u00df", "sie", "nie\u00b7der\u00b7han\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr gr\u00fcnendes Gefieder", "tokens": ["Ihr", "gr\u00fc\u00b7nen\u00b7des", "Ge\u00b7fie\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und hebt mit Hoffnung und Verlangen", "tokens": ["Und", "hebt", "mit", "Hoff\u00b7nung", "und", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es nun im Fr\u00fchrot wieder.", "tokens": ["Es", "nun", "im", "Fr\u00fch\u00b7rot", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Die Weide hat seit alten Tagen", "tokens": ["Die", "Wei\u00b7de", "hat", "seit", "al\u00b7ten", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So manchem Sturm getrutzet,", "tokens": ["So", "man\u00b7chem", "Sturm", "ge\u00b7trut\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ist immer wieder ausgeschlagen,", "tokens": ["Ist", "im\u00b7mer", "wie\u00b7der", "aus\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So oft man sie gestutzet.", "tokens": ["So", "oft", "man", "sie", "ge\u00b7stut\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Es hat sich in getrennte Glieder", "tokens": ["Es", "hat", "sich", "in", "ge\u00b7trenn\u00b7te", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr hohler Stamm zerkl\u00fcftet,", "tokens": ["Ihr", "hoh\u00b7ler", "Stamm", "zer\u00b7kl\u00fcf\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und jedes St\u00e4mmchen hat sich wieder", "tokens": ["Und", "je\u00b7des", "St\u00e4mm\u00b7chen", "hat", "sich", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VAFIN", "PRF", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit eigner Bork' umr\u00fcftet.", "tokens": ["Mit", "eig\u00b7ner", "Bork'", "um\u00b7r\u00fcf\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Sie weichen auseinander immer,", "tokens": ["Sie", "wei\u00b7chen", "aus\u00b7ein\u00b7an\u00b7der", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und wer sie sieht, der schw\u00f6ret,", "tokens": ["Und", "wer", "sie", "sieht", ",", "der", "schw\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es haben diese St\u00e4mme nimmer", "tokens": ["Es", "ha\u00b7ben", "die\u00b7se", "St\u00e4m\u00b7me", "nim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu einem Stamm geh\u00f6ret.", "tokens": ["Zu", "ei\u00b7nem", "Stamm", "ge\u00b7h\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Doch wie die L\u00fcfte dr\u00fcber rauschen,", "tokens": ["Doch", "wie", "die", "L\u00fcf\u00b7te", "dr\u00fc\u00b7ber", "rau\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So neigen mit Gefl\u00fcster", "tokens": ["So", "nei\u00b7gen", "mit", "Ge\u00b7fl\u00fcs\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Zweig' einander zu, und tauschen", "tokens": ["Die", "Zweig'", "ein\u00b7an\u00b7der", "zu", ",", "und", "tau\u00b7schen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$,", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Noch Gr\u00fc\u00dfe wie Geschwister;", "tokens": ["Noch", "Gr\u00fc\u00b7\u00dfe", "wie", "Ge\u00b7schwis\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOKOM", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und w\u00f6lben \u00fcberm hohlen Kerne", "tokens": ["Und", "w\u00f6l\u00b7ben", "\u00fc\u00b7berm", "hoh\u00b7len", "Ker\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl gegen Sturmes W\u00fcten", "tokens": ["Wohl", "ge\u00b7gen", "Stur\u00b7mes", "W\u00fc\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Ein Obdach, unter welchem gerne", "tokens": ["Ein", "Ob\u00b7dach", ",", "un\u00b7ter", "wel\u00b7chem", "ger\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Des Liedes Tauben br\u00fcten.", "tokens": ["Des", "Lie\u00b7des", "Tau\u00b7ben", "br\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Soll ich, o Weide, dich beklagen,", "tokens": ["Soll", "ich", ",", "o", "Wei\u00b7de", ",", "dich", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "FM", "NN", "$,", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df du den Kern vermissest,", "tokens": ["Da\u00df", "du", "den", "Kern", "ver\u00b7mis\u00b7sest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da jeden Fr\u00fchling auszuschlagen", "tokens": ["Da", "je\u00b7den", "Fr\u00fch\u00b7ling", "aus\u00b7zu\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du dennoch nie vergissest?", "tokens": ["Du", "den\u00b7noch", "nie", "ver\u00b7gis\u00b7sest", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Du gleichest meinem Vaterlande,", "tokens": ["Du", "glei\u00b7chest", "mei\u00b7nem", "Va\u00b7ter\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dem tief in sich gespaltnen,", "tokens": ["Dem", "tief", "in", "sich", "ge\u00b7spalt\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von einem tiefern Lebensbande", "tokens": ["Von", "ei\u00b7nem", "tie\u00b7fern", "Le\u00b7bens\u00b7ban\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zusammen doch gehaltnen.", "tokens": ["Zu\u00b7sam\u00b7men", "doch", "ge\u00b7halt\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Der Morgentau verstreut im Thale", "tokens": ["Der", "Mor\u00b7gen\u00b7tau", "ver\u00b7streut", "im", "Tha\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sein blitzendes Geschmeide;", "tokens": ["Sein", "blit\u00b7zen\u00b7des", "Ge\u00b7schmei\u00b7de", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da richtet sich im ersten Strahle", "tokens": ["Da", "rich\u00b7tet", "sich", "im", "ers\u00b7ten", "Strah\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Empor am Bach die Weide.", "tokens": ["Em\u00b7por", "am", "Bach", "die", "Wei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Im Nachttau lie\u00df sie niederhangen", "tokens": ["Im", "Nacht\u00b7tau", "lie\u00df", "sie", "nie\u00b7der\u00b7han\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr gr\u00fcnendes Gefieder", "tokens": ["Ihr", "gr\u00fc\u00b7nen\u00b7des", "Ge\u00b7fie\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und hebt mit Hoffnung und Verlangen", "tokens": ["Und", "hebt", "mit", "Hoff\u00b7nung", "und", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es nun im Fr\u00fchrot wieder.", "tokens": ["Es", "nun", "im", "Fr\u00fch\u00b7rot", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Die Weide hat seit alten Tagen", "tokens": ["Die", "Wei\u00b7de", "hat", "seit", "al\u00b7ten", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So manchem Sturm getrutzet,", "tokens": ["So", "man\u00b7chem", "Sturm", "ge\u00b7trut\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ist immer wieder ausgeschlagen,", "tokens": ["Ist", "im\u00b7mer", "wie\u00b7der", "aus\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So oft man sie gestutzet.", "tokens": ["So", "oft", "man", "sie", "ge\u00b7stut\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Es hat sich in getrennte Glieder", "tokens": ["Es", "hat", "sich", "in", "ge\u00b7trenn\u00b7te", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr hohler Stamm zerkl\u00fcftet,", "tokens": ["Ihr", "hoh\u00b7ler", "Stamm", "zer\u00b7kl\u00fcf\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und jedes St\u00e4mmchen hat sich wieder", "tokens": ["Und", "je\u00b7des", "St\u00e4mm\u00b7chen", "hat", "sich", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VAFIN", "PRF", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit eigner Bork' umr\u00fcftet.", "tokens": ["Mit", "eig\u00b7ner", "Bork'", "um\u00b7r\u00fcf\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Sie weichen auseinander immer,", "tokens": ["Sie", "wei\u00b7chen", "aus\u00b7ein\u00b7an\u00b7der", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und wer sie sieht, der schw\u00f6ret,", "tokens": ["Und", "wer", "sie", "sieht", ",", "der", "schw\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es haben diese St\u00e4mme nimmer", "tokens": ["Es", "ha\u00b7ben", "die\u00b7se", "St\u00e4m\u00b7me", "nim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu einem Stamm geh\u00f6ret.", "tokens": ["Zu", "ei\u00b7nem", "Stamm", "ge\u00b7h\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Doch wie die L\u00fcfte dr\u00fcber rauschen,", "tokens": ["Doch", "wie", "die", "L\u00fcf\u00b7te", "dr\u00fc\u00b7ber", "rau\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So neigen mit Gefl\u00fcster", "tokens": ["So", "nei\u00b7gen", "mit", "Ge\u00b7fl\u00fcs\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Zweig' einander zu, und tauschen", "tokens": ["Die", "Zweig'", "ein\u00b7an\u00b7der", "zu", ",", "und", "tau\u00b7schen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$,", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Noch Gr\u00fc\u00dfe wie Geschwister;", "tokens": ["Noch", "Gr\u00fc\u00b7\u00dfe", "wie", "Ge\u00b7schwis\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOKOM", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Und w\u00f6lben \u00fcberm hohlen Kerne", "tokens": ["Und", "w\u00f6l\u00b7ben", "\u00fc\u00b7berm", "hoh\u00b7len", "Ker\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl gegen Sturmes W\u00fcten", "tokens": ["Wohl", "ge\u00b7gen", "Stur\u00b7mes", "W\u00fc\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Ein Obdach, unter welchem gerne", "tokens": ["Ein", "Ob\u00b7dach", ",", "un\u00b7ter", "wel\u00b7chem", "ger\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Des Liedes Tauben br\u00fcten.", "tokens": ["Des", "Lie\u00b7des", "Tau\u00b7ben", "br\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Soll ich, o Weide, dich beklagen,", "tokens": ["Soll", "ich", ",", "o", "Wei\u00b7de", ",", "dich", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "FM", "NN", "$,", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df du den Kern vermissest,", "tokens": ["Da\u00df", "du", "den", "Kern", "ver\u00b7mis\u00b7sest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da jeden Fr\u00fchling auszuschlagen", "tokens": ["Da", "je\u00b7den", "Fr\u00fch\u00b7ling", "aus\u00b7zu\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du dennoch nie vergissest?", "tokens": ["Du", "den\u00b7noch", "nie", "ver\u00b7gis\u00b7sest", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Du gleichest meinem Vaterlande,", "tokens": ["Du", "glei\u00b7chest", "mei\u00b7nem", "Va\u00b7ter\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dem tief in sich gespaltnen,", "tokens": ["Dem", "tief", "in", "sich", "ge\u00b7spalt\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von einem tiefern Lebensbande", "tokens": ["Von", "ei\u00b7nem", "tie\u00b7fern", "Le\u00b7bens\u00b7ban\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zusammen doch gehaltnen.", "tokens": ["Zu\u00b7sam\u00b7men", "doch", "ge\u00b7halt\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}