{"textgrid.poem.62610": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Trauer-Ode auf das Absterben", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "EuGEN ist todt! was h\u00f6rt mein Ohr?", "tokens": ["Eu\u00b7GEN", "ist", "todt", "!", "was", "h\u00f6rt", "mein", "Ohr", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "$.", "PWS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie? sucht mich Fama zu betr\u00fcgen?", "tokens": ["Wie", "?", "sucht", "mich", "Fa\u00b7ma", "zu", "be\u00b7tr\u00fc\u00b7gen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "PPER", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "EuGEN, der keine Schlacht verlohr,", "tokens": ["Eu\u00b7GEN", ",", "der", "kei\u00b7ne", "Schlacht", "ver\u00b7lohr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Soll durch Morbonens Faust so pl\u00f6tzlich unterliegen?", "tokens": ["Soll", "durch", "Mor\u00b7bo\u00b7nens", "Faust", "so", "pl\u00f6tz\u00b7lich", "un\u00b7ter\u00b7lie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "O eitler Ruf! o falsch Geschrey!", "tokens": ["O", "eit\u00b7ler", "Ruf", "!", "o", "falsch", "Ge\u00b7schrey", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "FM", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wodurch in Ost, S\u00fcd, West und Norden", "tokens": ["Wo\u00b7durch", "in", "Ost", ",", "S\u00fcd", ",", "West", "und", "Nor\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPR", "NE", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Welt so oft get\u00e4uschet worden;", "tokens": ["Die", "Welt", "so", "oft", "ge\u00b7t\u00e4u\u00b7schet", "wor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich glaube nimmermehr, da\u00df dieses m\u00f6glich sey?", "tokens": ["Ich", "glau\u00b7be", "nim\u00b7mer\u00b7mehr", ",", "da\u00df", "die\u00b7ses", "m\u00f6g\u00b7lich", "sey", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "PDAT", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Das Schicksal l\u00e4st es nicht geschehen;", "tokens": ["Das", "Schick\u00b7sal", "l\u00e4st", "es", "nicht", "ge\u00b7sche\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So bald darf Unser Held noch nicht von hinnen gehen.", "tokens": ["So", "bald", "darf", "Un\u00b7ser", "Held", "noch", "nicht", "von", "hin\u00b7nen", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPOSAT", "NN", "ADV", "PTKNEG", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "EuGEN ist todt! ja! ja! sein Sarg", "tokens": ["Eu\u00b7GEN", "ist", "todt", "!", "ja", "!", "ja", "!", "sein", "Sarg"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "VAFIN", "ADJD", "$.", "PTKANT", "$.", "PTKANT", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00f6mmt mir von weiten ins Gesichte.", "tokens": ["K\u00f6mmt", "mir", "von", "wei\u00b7ten", "ins", "Ge\u00b7sich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Uberzeugung ist zu stark;", "tokens": ["Die", "Ub\u00b7er\u00b7zeu\u00b7gung", "ist", "zu", "stark", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun seh, nun merk ich wohl, es ist kein blos Gedichte.", "tokens": ["Nun", "seh", ",", "nun", "merk", "ich", "wohl", ",", "es", "ist", "kein", "blos", "Ge\u00b7dich\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV", "$,", "PPER", "VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sein Geist schwebt in der Ewigkeit,", "tokens": ["Sein", "Geist", "schwebt", "in", "der", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und hat den Erden-Krei\u00df verlassen.", "tokens": ["Und", "hat", "den", "Er\u00b7den\u00b7Krei\u00df", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man klaget jetzt auf unsern Gassen:", "tokens": ["Man", "kla\u00b7get", "jetzt", "auf", "un\u00b7sern", "Gas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dort liegt der tapfre F\u00fcrst; der gr\u00f6ste Held im Streit!", "tokens": ["Dort", "liegt", "der", "tapf\u00b7re", "F\u00fcrst", ";", "der", "gr\u00f6s\u00b7te", "Held", "im", "Streit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der kl\u00fcgste Feld-Herr unter allen", "tokens": ["Der", "kl\u00fcgs\u00b7te", "Feld\u00b7Herr", "un\u00b7ter", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ist, welch ein Schreckens-Wort! entseelt, erbla\u00dft, gefallen!", "tokens": ["Ist", ",", "welch", "ein", "Schre\u00b7ckens\u00b7Wort", "!", "ent\u00b7seelt", ",", "er\u00b7bla\u00dft", ",", "ge\u00b7fal\u00b7len", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "$,", "PWAT", "ART", "NN", "$.", "VVFIN", "$,", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wer wei\u00df, ob auch ein Donner-Strahl,", "tokens": ["Wer", "wei\u00df", ",", "ob", "auch", "ein", "Don\u00b7ner\u00b7Strahl", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der \u00f6fters Mensch und Vieh erschrecket,", "tokens": ["Der", "\u00f6f\u00b7ters", "Mensch", "und", "Vieh", "er\u00b7schre\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So bittres Leid, so grosse Quaal,", "tokens": ["So", "bitt\u00b7res", "Leid", ",", "so", "gros\u00b7se", "Qua\u00b7al", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als diese Trauer-Post in mancher Brust erwecket?", "tokens": ["Als", "die\u00b7se", "Trau\u00b7e\u00b7rPost", "in", "man\u00b7cher", "Brust", "er\u00b7we\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auch CARL wird von dem Fall ger\u00fchrt,", "tokens": ["Auch", "CaRL", "wird", "von", "dem", "Fall", "ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sucht den Kummer anzudeuten;", "tokens": ["Und", "sucht", "den", "Kum\u00b7mer", "an\u00b7zu\u00b7deu\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bey allen Helden unsrer Zeiten", "tokens": ["Bey", "al\u00b7len", "Hel\u00b7den", "uns\u00b7rer", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wird nichts als Traurigkeit und herber Schmerz versp\u00fchrt.", "tokens": ["Wird", "nichts", "als", "Trau\u00b7rig\u00b7keit", "und", "her\u00b7ber", "Schmerz", "ver\u00b7sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "KOKOM", "NN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Europa wird dadurch ersch\u00fcttert;", "tokens": ["Eu\u00b7ro\u00b7pa", "wird", "da\u00b7durch", "er\u00b7sch\u00fct\u00b7tert", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "EuGENENS schneller Tod macht, da\u00df es bebt und zittert.", "tokens": ["Eu\u00b7GEN\u00b7ENS", "schnel\u00b7ler", "Tod", "macht", ",", "da\u00df", "es", "bebt", "und", "zit\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Nicht nur die Gr\u00f6\u00dften dieser Welt", "tokens": ["Nicht", "nur", "die", "Gr\u00f6\u00df\u00b7ten", "die\u00b7ser", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Betrauren Ihn mit scharfen Klagen;", "tokens": ["Be\u00b7trau\u00b7ren", "Ihn", "mit", "schar\u00b7fen", "Kla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sinds nicht blos, die um den Held,", "tokens": ["Sie", "sinds", "nicht", "blos", ",", "die", "um", "den", "Held", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "$,", "PRELS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und diesen ", "tokens": ["Und", "die\u00b7sen"], "token_info": ["word", "word"], "pos": ["KON", "PDAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Auch die, so schlechter Staub bedeckt;", "tokens": ["Auch", "die", ",", "so", "schlech\u00b7ter", "Staub", "be\u00b7deckt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die allerniedrigsten im Reiche", "tokens": ["Die", "al\u00b7ler\u00b7nied\u00b7rigs\u00b7ten", "im", "Rei\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "APPRART", "NE"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Beweinen diese F\u00fcrsten-Leiche;", "tokens": ["Be\u00b7wei\u00b7nen", "die\u00b7se", "F\u00fcrs\u00b7ten\u00b7Lei\u00b7che", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ihr Herz wird von dem Ri\u00df aufs heftigste erschreckt.", "tokens": ["Ihr", "Herz", "wird", "von", "dem", "Ri\u00df", "aufs", "hef\u00b7tigs\u00b7te", "er\u00b7schreckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die, welche Seine Thaten wissen,", "tokens": ["Die", ",", "wel\u00b7che", "Sei\u00b7ne", "Tha\u00b7ten", "wis\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Hat Sein geschwinder Tod in Ohnmacht hingerissen.", "tokens": ["Hat", "Sein", "ge\u00b7schwin\u00b7der", "Tod", "in", "Ohn\u00b7macht", "hin\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ich wei\u00df, wie mich Sein Fall bet\u00e4ubt;", "tokens": ["Ich", "wei\u00df", ",", "wie", "mich", "Sein", "Fall", "be\u00b7t\u00e4ubt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich weine, wenn ich dran gedenke.", "tokens": ["Ich", "wei\u00b7ne", ",", "wenn", "ich", "dran", "ge\u00b7den\u00b7ke", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O Schmerz! der mich zum Seufzen treibt,", "tokens": ["O", "Schmerz", "!", "der", "mich", "zum", "Seuf\u00b7zen", "treibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ART", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So oft ich mich im Geist zu Seiner Bahre lenke.", "tokens": ["So", "oft", "ich", "mich", "im", "Geist", "zu", "Sei\u00b7ner", "Bah\u00b7re", "len\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "APPRART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "EuGEN, der meiner Niedrigkeit", "tokens": ["Eu\u00b7GEN", ",", "der", "mei\u00b7ner", "Nied\u00b7rig\u00b7keit"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So viele Gnad und Huld erwiesen;", "tokens": ["So", "vie\u00b7le", "Gnad", "und", "Huld", "er\u00b7wie\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "EuGEN, der meinen Flei\u00df gepriesen,", "tokens": ["Eu\u00b7GEN", ",", "der", "mei\u00b7nen", "Flei\u00df", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Setzt jetzo meine Brust in ungemeines Leid.", "tokens": ["Setzt", "jet\u00b7zo", "mei\u00b7ne", "Brust", "in", "un\u00b7ge\u00b7mei\u00b7nes", "Leid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "O soll ich Deinen Tod besingen!", "tokens": ["O", "soll", "ich", "Dei\u00b7nen", "Tod", "be\u00b7sin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "O darf ich Dir nicht mehr ein Freuden-Opfer bringe!", "tokens": ["O", "darf", "ich", "Dir", "nicht", "mehr", "ein", "Freu\u00b7den\u00b7Op\u00b7fer", "brin\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PPER", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Die Ehrfurcht, so mein Dichter-Rohr", "tokens": ["Die", "Ehr\u00b7furcht", ",", "so", "mein", "Dich\u00b7ter\u00b7Rohr"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey jener holden Zeit gef\u00fchret,", "tokens": ["Bey", "je\u00b7ner", "hol\u00b7den", "Zeit", "ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Stellt mir auch jetzt die Pflichten vor,", "tokens": ["Stellt", "mir", "auch", "jetzt", "die", "Pflich\u00b7ten", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da Oesterreich an Dir ein ", "tokens": ["Da", "O\u00b7es\u00b7ter\u00b7reich", "an", "Dir", "ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "APPR", "PPER", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich werde, ", "tokens": ["Ich", "wer\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "So lange mich die Musen lieben,", "tokens": ["So", "lan\u00b7ge", "mich", "die", "Mu\u00b7sen", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Mein Spiel in Deinem Ruhme \u00fcben,", "tokens": ["Mein", "Spiel", "in", "Dei\u00b7nem", "Ruh\u00b7me", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ob mancher Midas gleich ein h\u00f6hnisch Urtheil f\u00e4llt.", "tokens": ["Ob", "man\u00b7cher", "Mi\u00b7das", "gleich", "ein", "h\u00f6h\u00b7nisch", "Ur\u00b7theil", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADV", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Thorheit soll mir nicht verwehren,", "tokens": ["Die", "Thor\u00b7heit", "soll", "mir", "nicht", "ver\u00b7weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Dich, ", "tokens": ["Dich", ","], "token_info": ["word", "punct"], "pos": ["PPER", "$,"], "meter": "-", "measure": "single.down"}}, "stanza.7": {"line.1": {"text": "O d\u00fcrft ich nur zu dieser Zeit", "tokens": ["O", "d\u00fcrft", "ich", "nur", "zu", "die\u00b7ser", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Laub auf Deine Bahre streuen,", "tokens": ["Kein", "Laub", "auf", "Dei\u00b7ne", "Bah\u00b7re", "streu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und Dir in banger Traurigkeit", "tokens": ["Und", "Dir", "in", "ban\u00b7ger", "Trau\u00b7rig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor einen Lorbeer-Strau\u00df Cypressen-Str\u00e4uche weyhen!", "tokens": ["Vor", "ei\u00b7nen", "Lor\u00b7beer\u00b7Strau\u00df", "Cy\u00b7pres\u00b7sen\u00b7Str\u00e4u\u00b7che", "wey\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr Musen! wenn euch nicht EUGEN", "tokens": ["Ihr", "Mu\u00b7sen", "!", "wenn", "euch", "nicht", "Eu\u00b7GEN"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "KOUS", "PPER", "PTKNEG", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die F\u00e4higkeit, wie mir, geraubet;", "tokens": ["Die", "F\u00e4\u00b7hig\u00b7keit", ",", "wie", "mir", ",", "ge\u00b7rau\u00b7bet", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn euch der harte Schmerz erlaubet,", "tokens": ["Wenn", "euch", "der", "har\u00b7te", "Schmerz", "er\u00b7lau\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So f\u00fchrt mir jetzt den Kiel, Sein Grabmaal zu erh\u00f6hn.", "tokens": ["So", "f\u00fchrt", "mir", "jetzt", "den", "Kiel", ",", "Sein", "Grab\u00b7maal", "zu", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NE", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich bin zu schwach bey so viel Gr\u00e4men", "tokens": ["Ich", "bin", "zu", "schwach", "bey", "so", "viel", "Gr\u00e4\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "APPR", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die Feder ohne Furcht in meine Hand zu nehmen.", "tokens": ["Die", "Fe\u00b7der", "oh\u00b7ne", "Furcht", "in", "mei\u00b7ne", "Hand", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Da\u00df ich dich in der Gruft verst\u00f6hre,", "tokens": ["Da\u00df", "ich", "dich", "in", "der", "Gruft", "ver\u00b7st\u00f6h\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und mich zu Deines Grabes Th\u00fcr", "tokens": ["Und", "mich", "zu", "Dei\u00b7nes", "Gra\u00b7bes", "Th\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit meinem heischern Rohr u. matten Sayten kehre.", "tokens": ["Mit", "mei\u00b7nem", "hei\u00b7schern", "Rohr", "u.", "mat\u00b7ten", "Say\u00b7ten", "keh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Du l\u00e4\u00dft es, ", "tokens": ["Du", "l\u00e4\u00dft", "es", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ich wei\u00df, Du wirst es mir vergeben;", "tokens": ["Ich", "wei\u00df", ",", "Du", "wirst", "es", "mir", "ver\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Du hast ja sonst in Deinem Leben", "tokens": ["Du", "hast", "ja", "sonst", "in", "Dei\u00b7nem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Mein schwaches Lauten-Spiel so gn\u00e4dig angesehn:", "tokens": ["Mein", "schwa\u00b7ches", "Lau\u00b7ten\u00b7Spiel", "so", "gn\u00e4\u00b7dig", "an\u00b7ge\u00b7sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Du wirst auf mein geringes Dichten,", "tokens": ["Du", "wirst", "auf", "mein", "ge\u00b7rin\u00b7ges", "Dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Auch aus dem Grabe noch ein holdes Auge richten.", "tokens": ["Auch", "aus", "dem", "Gra\u00b7be", "noch", "ein", "hol\u00b7des", "Au\u00b7ge", "rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ich kan Dich, Herr! nach W\u00fcrdigkeit", "tokens": ["Ich", "kan", "Dich", ",", "Herr", "!", "nach", "W\u00fcr\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "$,", "NN", "$.", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und nach Verdienst zwar nicht besingen,", "tokens": ["Und", "nach", "Ver\u00b7dienst", "zwar", "nicht", "be\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Noch Deiner Thaten Seltenheit,", "tokens": ["Noch", "Dei\u00b7ner", "Tha\u00b7ten", "Sel\u00b7ten\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch Deine Tugenden in meine Reime zwingen.", "tokens": ["Noch", "Dei\u00b7ne", "Tu\u00b7gen\u00b7den", "in", "mei\u00b7ne", "Rei\u00b7me", "zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es stehet nicht in meiner Kraft", "tokens": ["Es", "ste\u00b7het", "nicht", "in", "mei\u00b7ner", "Kraft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von einem so beherzten Helden", "tokens": ["Von", "ei\u00b7nem", "so", "be\u00b7herz\u00b7ten", "Hel\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Auch nur das wenigste zu melden;", "tokens": ["Auch", "nur", "das", "we\u00b7nigs\u00b7te", "zu", "mel\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich lalle blos etwas von Deiner Eigenschaft.", "tokens": ["Ich", "lal\u00b7le", "blos", "et\u00b7was", "von", "Dei\u00b7ner", "Ei\u00b7gen\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der gr\u00f6\u00dfte Dichter m\u00fc\u00dfte schweigen,", "tokens": ["Der", "gr\u00f6\u00df\u00b7te", "Dich\u00b7ter", "m\u00fc\u00df\u00b7te", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wofern er willens w\u00e4r, von Deinem Ruhm zu zeugen.", "tokens": ["Wo\u00b7fern", "er", "wil\u00b7lens", "w\u00e4r", ",", "von", "Dei\u00b7nem", "Ruhm", "zu", "zeu\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAFIN", "$,", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Die\u00df ist kein Werk vor einen Mann;", "tokens": ["Die\u00df", "ist", "kein", "Werk", "vor", "ei\u00b7nen", "Mann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein einzig Jahr von Deinem Leben;", "tokens": ["Ein", "ein\u00b7zig", "Jahr", "von", "Dei\u00b7nem", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur eine That, die Du gethan,", "tokens": ["Nur", "ei\u00b7ne", "That", ",", "die", "Du", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kan dem, der sie beschreibt, gnug Stoff und Nachdruck geben.", "tokens": ["Kan", "dem", ",", "der", "sie", "be\u00b7schreibt", ",", "gnug", "Stoff", "und", "Nach\u00b7druck", "ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hat nun ein Dichter fast allein", "tokens": ["Hat", "nun", "ein", "Dich\u00b7ter", "fast", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von einem Jahre gnug zu sagen,", "tokens": ["Von", "ei\u00b7nem", "Jah\u00b7re", "gnug", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wer will sich an die andern wagen?", "tokens": ["Wer", "will", "sich", "an", "die", "an\u00b7dern", "wa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Hier mu\u00df gewi\u00df ein Chor von drey und siebnzig seyn.", "tokens": ["Hier", "mu\u00df", "ge\u00b7wi\u00df", "ein", "Chor", "von", "drey", "und", "siebn\u00b7zig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "ART", "NN", "APPR", "CARD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Thaten sind nicht zu ergr\u00fcnden,", "tokens": ["Die", "Tha\u00b7ten", "sind", "nicht", "zu", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wo wird man wohl bey uns so viele Dichter finden?", "tokens": ["Wo", "wird", "man", "wohl", "bey", "uns", "so", "vie\u00b7le", "Dich\u00b7ter", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PIS", "ADV", "APPR", "PPER", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Der Vorzug, den die Allmachts-Hand", "tokens": ["Der", "Vor\u00b7zug", ",", "den", "die", "All\u00b7machts\u00b7Hand"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den F\u00fcrsten in der Welt geschenket,", "tokens": ["Den", "F\u00fcrs\u00b7ten", "in", "der", "Welt", "ge\u00b7schen\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ist gro\u00df, so fern man ihren Stand,", "tokens": ["Ist", "gro\u00df", ",", "so", "fern", "man", "ih\u00b7ren", "Stand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "ADV", "ADJD", "PIS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Ansehn, Ehr und Ruhm u. hohe Macht bedenket.", "tokens": ["Ihr", "An\u00b7sehn", ",", "Ehr", "und", "Ruhm", "u.", "ho\u00b7he", "Macht", "be\u00b7den\u00b7ket", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Sie sind begl\u00fcckt: Der Tod allein,", "tokens": ["Sie", "sind", "be\u00b7gl\u00fcckt", ":", "Der", "Tod", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der auch in g\u00fcldnen H\u00e4usern wohnet,", "tokens": ["Der", "auch", "in", "g\u00fcld\u00b7nen", "H\u00e4u\u00b7sern", "woh\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und keines Purpurs Glanz verschonet,", "tokens": ["Und", "kei\u00b7nes", "Pur\u00b7purs", "Glanz", "ver\u00b7scho\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zeigt, da\u00df sie ebenfalls, wie andre sterblich seyn.", "tokens": ["Zeigt", ",", "da\u00df", "sie", "e\u00b7ben\u00b7falls", ",", "wie", "and\u00b7re", "sterb\u00b7lich", "seyn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADV", "$,", "PWAV", "PIS", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Kein Ansehn kan den Tod besiegen;", "tokens": ["Kein", "An\u00b7sehn", "kan", "den", "Tod", "be\u00b7sie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ein Cr\u00f6sus mu\u00df so wohl als Irus unterliegen.", "tokens": ["Ein", "Cr\u00f6\u00b7sus", "mu\u00df", "so", "wohl", "als", "I\u00b7rus", "un\u00b7ter\u00b7lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADV", "KOUS", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "O! wenn des Himmels G\u00fctigkeit", "tokens": ["O", "!", "wenn", "des", "Him\u00b7mels", "G\u00fc\u00b7tig\u00b7keit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur dies dem Tod gebiethen wolte,", "tokens": ["Nur", "dies", "dem", "Tod", "ge\u00b7bie\u00b7then", "wol\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df er der Helden Lebens-Zeit", "tokens": ["Da\u00df", "er", "der", "Hel\u00b7den", "Le\u00b7bens\u00b7Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht so geschwind, so fr\u00fch, so bald verk\u00fcrzen solte!", "tokens": ["Nicht", "so", "ge\u00b7schwind", ",", "so", "fr\u00fch", ",", "so", "bald", "ver\u00b7k\u00fcr\u00b7zen", "sol\u00b7te", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "O gieng doch ihrer Jahre Lauf", "tokens": ["O", "gieng", "doch", "ih\u00b7rer", "Jah\u00b7re", "Lauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So weit, als in den ersten Tagen,", "tokens": ["So", "weit", ",", "als", "in", "den", "ers\u00b7ten", "Ta\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wovon uns die Geschichte sagen;", "tokens": ["Wo\u00b7von", "uns", "die", "Ge\u00b7schich\u00b7te", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "O stieg ihr Alter nur auf mehr als hundert nauf!", "tokens": ["O", "stieg", "ihr", "Al\u00b7ter", "nur", "auf", "mehr", "als", "hun\u00b7dert", "nauf", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "PIAT", "KOKOM", "CARD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So w\u00e4r noch jetzt EUGEN auf Erden,", "tokens": ["So", "w\u00e4r", "noch", "jetzt", "Eu\u00b7GEN", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und k\u00f6nte wie vor dem die Lust besungen werden.", "tokens": ["Und", "k\u00f6n\u00b7te", "wie", "vor", "dem", "die", "Lust", "be\u00b7sun\u00b7gen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "KOKOM", "APPR", "ART", "ART", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Der Donner br\u00fcllt und ra\u00dft vielmehr", "tokens": ["Der", "Don\u00b7ner", "br\u00fcllt", "und", "ra\u00dft", "viel\u00b7mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf hohen Bergen als in Gr\u00fcnden.", "tokens": ["Auf", "ho\u00b7hen", "Ber\u00b7gen", "als", "in", "Gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sein blitzend Feuer pflegt weit eh'r", "tokens": ["Sein", "blit\u00b7zend", "Feu\u00b7er", "pflegt", "weit", "eh'r"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Eichen stolzes Haupt als Hecken zu entz\u00fcnden.", "tokens": ["Der", "Ei\u00b7chen", "stol\u00b7zes", "Haupt", "als", "He\u00b7cken", "zu", "ent\u00b7z\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KOUS", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So macht es auch der Parcen Hand;", "tokens": ["So", "macht", "es", "auch", "der", "Par\u00b7cen", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie t\u00f6dtet K\u00f6nige und Kayser,", "tokens": ["Sie", "t\u00f6d\u00b7tet", "K\u00f6\u00b7ni\u00b7ge", "und", "Kay\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Verheert die allergr\u00f6\u00dften H\u00e4user,", "tokens": ["Ver\u00b7heert", "die", "al\u00b7ler\u00b7gr\u00f6\u00df\u00b7ten", "H\u00e4u\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und scheut am wenigsten den hohen F\u00fcrsten-Stand.", "tokens": ["Und", "scheut", "am", "we\u00b7nigs\u00b7ten", "den", "ho\u00b7hen", "F\u00fcrs\u00b7ten\u00b7Stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.9": {"text": "Hingegen schont sie schlechter H\u00fctten,", "tokens": ["Hin\u00b7ge\u00b7gen", "schont", "sie", "schlech\u00b7ter", "H\u00fct\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Die doch wohl oftermahls um ihre Ankunft bitten.", "tokens": ["Die", "doch", "wohl", "of\u00b7ter\u00b7mahls", "um", "ih\u00b7re", "An\u00b7kunft", "bit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Dort auf dem Deutschen Libanon,", "tokens": ["Dort", "auf", "dem", "Deut\u00b7schen", "Li\u00b7ba\u00b7non", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den lauter tapfre Helden zieren,", "tokens": ["Den", "lau\u00b7ter", "tapf\u00b7re", "Hel\u00b7den", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vernimmt man einen Klage-Thon;", "tokens": ["Ver\u00b7nimmt", "man", "ei\u00b7nen", "Kla\u00b7ge\u00b7Thon", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man kan den strengen Schmerz an allen Orten sp\u00fchren.", "tokens": ["Man", "kan", "den", "stren\u00b7gen", "Schmerz", "an", "al\u00b7len", "Or\u00b7ten", "sp\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Warum? die gr\u00f6\u00dfte Ceder ist", "tokens": ["Wa\u00b7rum", "?", "die", "gr\u00f6\u00df\u00b7te", "Ce\u00b7der", "ist"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "ART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch Prinz EUGENENS Tod gefallen.", "tokens": ["Durch", "Prinz", "Eu\u00b7GEN\u00b7ENS", "Tod", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "O, da\u00df ein solches Donner-Knallen,", "tokens": ["O", ",", "da\u00df", "ein", "sol\u00b7ches", "Don\u00b7ner\u00b7Knal\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den angenehmen Hayn so j\u00e4mmerlich verw\u00fcst!", "tokens": ["Den", "an\u00b7ge\u00b7neh\u00b7men", "Hayn", "so", "j\u00e4m\u00b7mer\u00b7lich", "ver\u00b7w\u00fcst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ihr Cedern! wie wirds euch ergehen!", "tokens": ["Ihr", "Ce\u00b7dern", "!", "wie", "wirds", "euch", "er\u00b7ge\u00b7hen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PWAV", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.10": {"text": "F\u00e4llt euer sch\u00f6nster Stamm, wie wolt denn ihr bestehen?", "tokens": ["F\u00e4llt", "eu\u00b7er", "sch\u00f6ns\u00b7ter", "Stamm", ",", "wie", "wolt", "denn", "ihr", "be\u00b7ste\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$,", "PWAV", "VMFIN", "KON", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Wie, wenn das Auge dieser Welt", "tokens": ["Wie", ",", "wenn", "das", "Au\u00b7ge", "die\u00b7ser", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KOUS", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Licht dem Horizont entziehet,", "tokens": ["Sein", "Licht", "dem", "Ho\u00b7ri\u00b7zont", "ent\u00b7zie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Schatten auf die Wiesen f\u00e4llt,", "tokens": ["Der", "Schat\u00b7ten", "auf", "die", "Wie\u00b7sen", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jemehr der helle Schein von ihrer Gegend fliehet.", "tokens": ["Je\u00b7mehr", "der", "hel\u00b7le", "Schein", "von", "ih\u00b7rer", "Ge\u00b7gend", "flie\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So wird durch grosser F\u00fcrsten Tod", "tokens": ["So", "wird", "durch", "gros\u00b7ser", "F\u00fcrs\u00b7ten", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Land, das ihre Thaten sch\u00e4tzet,", "tokens": ["Ein", "Land", ",", "das", "ih\u00b7re", "Tha\u00b7ten", "sch\u00e4t\u00b7zet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "In tr\u00fcbe Finsterni\u00df gesetzet,", "tokens": ["In", "tr\u00fc\u00b7be", "Fins\u00b7ter\u00b7ni\u00df", "ge\u00b7set\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Weil so ein harter Streich nicht wenig Ungl\u00fcck droht.", "tokens": ["Weil", "so", "ein", "har\u00b7ter", "Streich", "nicht", "we\u00b7nig", "Un\u00b7gl\u00fcck", "droht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "PTKNEG", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "EuGENENS d\u00fcstre Gruft und Bogen", "tokens": ["Eu\u00b7GEN\u00b7ENS", "d\u00fcst\u00b7re", "Gruft", "und", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Hat gleiche Dunkelheit dem Reiche zugezogen.", "tokens": ["Hat", "glei\u00b7che", "Dun\u00b7kel\u00b7heit", "dem", "Rei\u00b7che", "zu\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "ART", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Man hat, Unsterblicher EUGEN!", "tokens": ["Man", "hat", ",", "U\u00b7nsterb\u00b7li\u00b7cher", "Eu\u00b7GEN", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "$,", "ADJA", "NN", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "Dich als Philippens Sohn betrachtet;", "tokens": ["Dich", "als", "Phil\u00b7ip\u00b7pens", "Sohn", "be\u00b7trach\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "NE", "NN", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Wer Deinen L\u00f6wen-Muth gesehn,", "tokens": ["Wer", "Dei\u00b7nen", "L\u00f6\u00b7wen\u00b7Muth", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat Dich weit h\u00f6her noch als Scanderbeck geachtet.", "tokens": ["Hat", "Dich", "weit", "h\u00f6\u00b7her", "noch", "als", "Scan\u00b7der\u00b7beck", "ge\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADJD", "ADV", "KOUS", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du bist von Deiner Jugend an", "tokens": ["Du", "bist", "von", "Dei\u00b7ner", "Ju\u00b7gend", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem Helden-Ruhme nachgegangen:", "tokens": ["Dem", "Hel\u00b7den\u00b7Ruh\u00b7me", "nach\u00b7ge\u00b7gan\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du hast ihn auch gar bald empfangen,", "tokens": ["Du", "hast", "ihn", "auch", "gar", "bald", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Weil deine Faust weit mehr als C\u00e4sars Arm gethan.", "tokens": ["Weil", "dei\u00b7ne", "Faust", "weit", "mehr", "als", "C\u00e4\u00b7sars", "Arm", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "PIAT", "KOKOM", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du wustest jeden Feind zu zwingen,", "tokens": ["Du", "wus\u00b7test", "je\u00b7den", "Feind", "zu", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ja alles muste Dir, was Du versucht, gelingen.", "tokens": ["Ja", "al\u00b7les", "mus\u00b7te", "Dir", ",", "was", "Du", "ver\u00b7sucht", ",", "ge\u00b7lin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "PIS", "VMFIN", "PPER", "$,", "PWS", "PPER", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Dich hat zwar Dein Durchlauchtger Stand,", "tokens": ["Dich", "hat", "zwar", "Dein", "Durch\u00b7laucht\u00b7ger", "Stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Doch mehr die Tapferkeit erhoben.", "tokens": ["Doch", "mehr", "die", "Tap\u00b7fer\u00b7keit", "er\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wem ist Dein Streiten unbekannt?", "tokens": ["Wem", "ist", "Dein", "Strei\u00b7ten", "un\u00b7be\u00b7kannt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer sucht nicht Deinen Muth und Helden-Geist zu loben?", "tokens": ["Wer", "sucht", "nicht", "Dei\u00b7nen", "Muth", "und", "Hel\u00b7den\u00b7Geist", "zu", "lo\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "PPOSAT", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein Sebel ward vom Blute warm,", "tokens": ["Dein", "Se\u00b7bel", "ward", "vom", "Blu\u00b7te", "warm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn er der Feinde Hal\u00df zerbrochen,", "tokens": ["Wenn", "er", "der", "Fein\u00b7de", "Hal\u00df", "zer\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die sich vor deinem Zorn verkrochen:", "tokens": ["Die", "sich", "vor", "dei\u00b7nem", "Zorn", "ver\u00b7kro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Denn wo du hingeriethst, da tre\u00f1te sich ihr Schwarm:", "tokens": ["Denn", "wo", "du", "hin\u00b7ge\u00b7riethst", ",", "da", "tre\u00f1te", "sich", "ihr", "Schwarm", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PRF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Dein Schwerdt kam stets mit Heyl und Gl\u00fccke,", "tokens": ["Dein", "Schwerdt", "kam", "stets", "mit", "Heyl", "und", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mit Beute, Ehr und Ruhm, mit Blut und Sieg zur\u00fccke.", "tokens": ["Mit", "Beu\u00b7te", ",", "Ehr", "und", "Ruhm", ",", "mit", "Blut", "und", "Sieg", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Auch nur das Losungs-Wort zum Streit", "tokens": ["Auch", "nur", "das", "Lo\u00b7sungs\u00b7Wort", "zum", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erweckte bey dem Feind ein Lermen.", "tokens": ["Er\u00b7weck\u00b7te", "bey", "dem", "Feind", "ein", "Ler\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du suchtest Dich bey rauher Zeit", "tokens": ["Du", "such\u00b7test", "Dich", "bey", "rau\u00b7her", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am feurigen Gesch\u00fctz und Bomben zu erw\u00e4rmen.", "tokens": ["Am", "feu\u00b7ri\u00b7gen", "Ge\u00b7sch\u00fctz", "und", "Bom\u00b7ben", "zu", "er\u00b7w\u00e4r\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Strom, der sonst wie Silber war,", "tokens": ["Ein", "Strom", ",", "der", "sonst", "wie", "Sil\u00b7ber", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "KOKOM", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ward oft zu einem rothen Meere.", "tokens": ["Ward", "oft", "zu", "ei\u00b7nem", "ro\u00b7then", "Mee\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wo Du o Held! mit Deinem Heere", "tokens": ["Wo", "Du", "o", "Held", "!", "mit", "Dei\u00b7nem", "Hee\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "FM", "NN", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dem Feind entgege gienst, da wich die ganze Schaar.", "tokens": ["Dem", "Feind", "ent\u00b7ge\u00b7ge", "gienst", ",", "da", "wich", "die", "gan\u00b7ze", "Schaar", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVFIN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "An jedem Ort wo Du gestanden,", "tokens": ["An", "je\u00b7dem", "Ort", "wo", "Du", "ge\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PWAV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ist noch von Deinem Ruhm ein Ehrenmaal vorhanden.", "tokens": ["Ist", "noch", "von", "Dei\u00b7nem", "Ruhm", "ein", "Eh\u00b7ren\u00b7maal", "vor\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPOSAT", "NN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Dein Auge war ein schneller Blitz,", "tokens": ["Dein", "Au\u00b7ge", "war", "ein", "schnel\u00b7ler", "Blitz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Arm ein Donnerschlag zu nennen.", "tokens": ["Dein", "Arm", "ein", "Don\u00b7ner\u00b7schlag", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dies mu\u00df noch Achmeths stolzer Sitz,", "tokens": ["Dies", "mu\u00df", "noch", "Ach\u00b7meths", "stol\u00b7zer", "Sitz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das freche Monden-Volk zu seinem Schimpf bekennen.", "tokens": ["Das", "fre\u00b7che", "Mon\u00b7den\u00b7Volk", "zu", "sei\u00b7nem", "Schimpf", "be\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du hast mit Lust, wenn Du gekriegt,", "tokens": ["Du", "hast", "mit", "Lust", ",", "wenn", "Du", "ge\u00b7kriegt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "$,", "KOUS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein tapfres Helden-Blut verspritzet,", "tokens": ["Dein", "tapf\u00b7res", "Hel\u00b7den\u00b7Blut", "ver\u00b7sprit\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und Deinen Purpur-Schwei\u00df verschwitzet,", "tokens": ["Und", "Dei\u00b7nen", "Pur\u00b7pur\u00b7Schwei\u00df", "ver\u00b7schwit\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ward nur der k\u00fchne Feind auf solche Art besiegt.", "tokens": ["Ward", "nur", "der", "k\u00fch\u00b7ne", "Feind", "auf", "sol\u00b7che", "Art", "be\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du wustest Dir zu allen Zeiten", "tokens": ["Du", "wus\u00b7test", "Dir", "zu", "al\u00b7len", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Den Weg zur Sternenburg durch k\u00e4mpfen zu bereiten.", "tokens": ["Den", "Weg", "zur", "Ster\u00b7nen\u00b7burg", "durch", "k\u00e4mp\u00b7fen", "zu", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Doch hast Du nie nach Parther Art", "tokens": ["Doch", "hast", "Du", "nie", "nach", "Par\u00b7ther", "Art"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Blut der Deinigen verschwendet.", "tokens": ["Das", "Blut", "der", "Dei\u00b7ni\u00b7gen", "ver\u00b7schwen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du hast Dein Heer wie Dich verwahrt,", "tokens": ["Du", "hast", "Dein", "Heer", "wie", "Dich", "ver\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "KOKOM", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und mancherley Gefahr durch Klugheit abgewendet.", "tokens": ["Und", "man\u00b7cher\u00b7ley", "Ge\u00b7fahr", "durch", "Klug\u00b7heit", "ab\u00b7ge\u00b7wen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Ehrsucht nahm zu keiner Zeit", "tokens": ["Die", "Ehr\u00b7sucht", "nahm", "zu", "kei\u00b7ner", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Herrschaft \u00fcber Dein Gewissen;", "tokens": ["Die", "Herr\u00b7schaft", "\u00fc\u00b7ber", "Dein", "Ge\u00b7wis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dies wird Dein Volk bezeugen m\u00fcssen,", "tokens": ["Dies", "wird", "Dein", "Volk", "be\u00b7zeu\u00b7gen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das Du zum Kampf gef\u00fchrt. O kluge Tapferkeit!", "tokens": ["Das", "Du", "zum", "Kampf", "ge\u00b7f\u00fchrt", ".", "O", "klu\u00b7ge", "Tap\u00b7fer\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPRART", "NN", "VVPP", "$.", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie mancher, der nach Ruhm getrachtet,", "tokens": ["Wie", "man\u00b7cher", ",", "der", "nach", "Ruhm", "ge\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "$,", "PRELS", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Hat \u00f6fters ohne Noth viel tausend Mann geschlachtet.", "tokens": ["Hat", "\u00f6f\u00b7ters", "oh\u00b7ne", "Noth", "viel", "tau\u00b7send", "Mann", "ge\u00b7schlach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "ADV", "CARD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Ein k\u00fchner Streiter weicht nicht ehr,", "tokens": ["Ein", "k\u00fch\u00b7ner", "Strei\u00b7ter", "weicht", "nicht", "ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis seine tapfre Faust gesieget,", "tokens": ["Bis", "sei\u00b7ne", "tapf\u00b7re", "Faust", "ge\u00b7sie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und, wenn er nicht so gl\u00fccklich w\u00e4r,", "tokens": ["Und", ",", "wenn", "er", "nicht", "so", "gl\u00fcck\u00b7lich", "w\u00e4r", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So k\u00e4mpft er bis er stirbt und auf der Wahlst\u00e4tt lieget.", "tokens": ["So", "k\u00e4mpft", "er", "bis", "er", "stirbt", "und", "auf", "der", "Wahl\u00b7st\u00e4tt", "lie\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "PPER", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dies hat an Dir o Held EUGEN!", "tokens": ["Dies", "hat", "an", "Dir", "o", "Held", "Eu\u00b7GEN", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "FM", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Welt erstaunend wahrgenommen;", "tokens": ["Die", "Welt", "er\u00b7stau\u00b7nend", "wahr\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du bist fast nie zur\u00fccke kommen,", "tokens": ["Du", "bist", "fast", "nie", "zu\u00b7r\u00fc\u00b7cke", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Du h\u00e4ttest denn den Fall des Feindes angesehn.", "tokens": ["Du", "h\u00e4t\u00b7test", "denn", "den", "Fall", "des", "Fein\u00b7des", "an\u00b7ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dir m\u00fcste jeder Streich gelingen,", "tokens": ["Dir", "m\u00fcs\u00b7te", "je\u00b7der", "Streich", "ge\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Du kuntest wenigstens den Feind zum Frieden zwingen.", "tokens": ["Du", "kun\u00b7test", "we\u00b7nigs\u00b7tens", "den", "Feind", "zum", "Frie\u00b7den", "zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "An einem L\u00f6wen findet man", "tokens": ["An", "ei\u00b7nem", "L\u00f6\u00b7wen", "fin\u00b7det", "man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Gro\u00dfmuth \u00e4chtes Meisterst\u00fccke.", "tokens": ["Der", "Gro\u00df\u00b7muth", "\u00e4ch\u00b7tes", "Meis\u00b7ter\u00b7st\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Schaut ihn sein Gegner sterbend an,", "tokens": ["Schaut", "ihn", "sein", "Geg\u00b7ner", "ster\u00b7bend", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So h\u00f6rt die Rache auf; er geht vergn\u00fcgt zur\u00fccke.", "tokens": ["So", "h\u00f6rt", "die", "Ra\u00b7che", "auf", ";", "er", "geht", "ver\u00b7gn\u00fcgt", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durchlauchtger Held! wo hat ein F\u00fcrst", "tokens": ["Durch\u00b7laucht\u00b7ger", "Held", "!", "wo", "hat", "ein", "F\u00fcrst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "PWAV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mehr Gro\u00dfmuth als wie Du gewiesen?", "tokens": ["Mehr", "Gro\u00df\u00b7muth", "als", "wie", "Du", "ge\u00b7wie\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KOUS", "KOKOM", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Herr! lag der Feind zu Deinen F\u00fcssen,", "tokens": ["Herr", "!", "lag", "der", "Feind", "zu", "Dei\u00b7nen", "F\u00fcs\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "So hast Du weiter nicht nach seinem Fall ged\u00fcrst.", "tokens": ["So", "hast", "Du", "wei\u00b7ter", "nicht", "nach", "sei\u00b7nem", "Fall", "ge\u00b7d\u00fcrst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du warst vergn\u00fcgt, wenn er sich beugte,", "tokens": ["Du", "warst", "ver\u00b7gn\u00fcgt", ",", "wenn", "er", "sich", "beug\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und sich vor Deiner Faust und blutgen Sebel neigte.", "tokens": ["Und", "sich", "vor", "Dei\u00b7ner", "Faust", "und", "blut\u00b7gen", "Se\u00b7bel", "neig\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PPOSAT", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Des L\u00f6wens br\u00fcllendes Geschrey", "tokens": ["Des", "L\u00f6\u00b7wens", "br\u00fcl\u00b7len\u00b7des", "Ge\u00b7schrey"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Macht, da\u00df ein ganzer Wald ersch\u00fcttert.", "tokens": ["Macht", ",", "da\u00df", "ein", "gan\u00b7zer", "Wald", "er\u00b7sch\u00fct\u00b7tert", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vor Dir o Held! ich rede frey,", "tokens": ["Vor", "Dir", "o", "Held", "!", "ich", "re\u00b7de", "frey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "FM", "NN", "$.", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist fast die halbe Welt erschrocken und erzittert.", "tokens": ["Ist", "fast", "die", "hal\u00b7be", "Welt", "er\u00b7schro\u00b7cken", "und", "er\u00b7zit\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein tapfres Ansehn nur allein;", "tokens": ["Dein", "tapf\u00b7res", "An\u00b7sehn", "nur", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein Heldenm\u00fcthiges Gesichte", "tokens": ["Dein", "Hel\u00b7den\u00b7m\u00fct\u00b7hi\u00b7ges", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.7": {"text": "Schlug oft ein ganzes Heer zu nichte;", "tokens": ["Schlug", "oft", "ein", "gan\u00b7zes", "Heer", "zu", "nich\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "APPR", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dein Name jagte gleich dem Feind ein Schrecken ein.", "tokens": ["Dein", "Na\u00b7me", "jag\u00b7te", "gleich", "dem", "Feind", "ein", "Schre\u00b7cken", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Nachwelt wird dies Zeugni\u00df lesen:", "tokens": ["Die", "Nach\u00b7welt", "wird", "dies", "Zeug\u00b7ni\u00df", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PDS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Du seyst ein Hannibal zu unsrer Zeit gewesen.", "tokens": ["Du", "seyst", "ein", "Han\u00b7ni\u00b7bal", "zu", "uns\u00b7rer", "Zeit", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Dort lie\u00df ein F\u00fcrst zu Gibeon", "tokens": ["Dort", "lie\u00df", "ein", "F\u00fcrst", "zu", "Gi\u00b7be\u00b7on"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sonn im Streite stille stehen,", "tokens": ["Die", "Sonn", "im", "Strei\u00b7te", "stil\u00b7le", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und in dem Thale Ajalon", "tokens": ["Und", "in", "dem", "Tha\u00b7le", "A\u00b7jal\u00b7on"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Mond in seinem Lauf nicht weiter abw\u00e4rts gehen", "tokens": ["Den", "Mond", "in", "sei\u00b7nem", "Lauf", "nicht", "wei\u00b7ter", "ab\u00b7w\u00e4rts", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "PTKNEG", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du kontest auch o Held EUGEN!", "tokens": ["Du", "kon\u00b7test", "auch", "o", "Held", "Eu\u00b7GEN", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "FM", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Sonne allzeit Stand gebiethen,", "tokens": ["Der", "Son\u00b7ne", "all\u00b7zeit", "Stand", "ge\u00b7bie\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und ihren schnellen Lauf verh\u00fcten:", "tokens": ["Und", "ih\u00b7ren", "schnel\u00b7len", "Lauf", "ver\u00b7h\u00fc\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Es muste auf Dein Wort das Mond-Licht stille stehn.", "tokens": ["Es", "mus\u00b7te", "auf", "Dein", "Wort", "das", "Mon\u00b7dLicht", "stil\u00b7le", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du warst ein Weltber\u00fchmter Streiter;", "tokens": ["Du", "warst", "ein", "Welt\u00b7be\u00b7r\u00fchm\u00b7ter", "Strei\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Dein Wahlspruch stunde fest; es hie\u00df: Nur immer weiter.", "tokens": ["Dein", "Wahl\u00b7spruch", "stun\u00b7de", "fest", ";", "es", "hie\u00df", ":", "Nur", "im\u00b7mer", "wei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$.", "PPER", "VVFIN", "$.", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Du hast bey Deiner grossen Macht,", "tokens": ["Du", "hast", "bey", "Dei\u00b7ner", "gros\u00b7sen", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey Deinem Muth und hohen Wesen", "tokens": ["Bey", "Dei\u00b7nem", "Muth", "und", "ho\u00b7hen", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auch an die Freundlichkeit gedacht", "tokens": ["Auch", "an", "die", "Freund\u00b7lich\u00b7keit", "ge\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und die Gerechtigkeit zur F\u00fchrerin erlesen.", "tokens": ["Und", "die", "Ge\u00b7rech\u00b7tig\u00b7keit", "zur", "F\u00fch\u00b7re\u00b7rin", "er\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja, Deiner Tugend Seltenheit", "tokens": ["Ja", ",", "Dei\u00b7ner", "Tu\u00b7gend", "Sel\u00b7ten\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bewiese sich in Werk und Worten;", "tokens": ["Be\u00b7wie\u00b7se", "sich", "in", "Werk", "und", "Wor\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man f\u00fcrchtete an allen Orten,", "tokens": ["Man", "f\u00fcrch\u00b7te\u00b7te", "an", "al\u00b7len", "Or\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und liebte Dich zugleich mit gr\u00f6ster Z\u00e4rtlichkeit.", "tokens": ["Und", "lieb\u00b7te", "Dich", "zu\u00b7gleich", "mit", "gr\u00f6s\u00b7ter", "Z\u00e4rt\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Kein Mensch ist je mit na\u00dfen Wangen,", "tokens": ["Kein", "Mensch", "ist", "je", "mit", "na\u00b7\u00dfen", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und mit betr\u00fcbtem Geist von Deinem Antlitz gangen.", "tokens": ["Und", "mit", "be\u00b7tr\u00fcb\u00b7tem", "Geist", "von", "Dei\u00b7nem", "Ant\u00b7litz", "gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Wo denk ich hin? mein ganzer Flei\u00df", "tokens": ["Wo", "denk", "ich", "hin", "?", "mein", "gan\u00b7zer", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "PTKVZ", "$.", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kan deinen Ruhm doch nicht ergr\u00fcnden.", "tokens": ["Kan", "dei\u00b7nen", "Ruhm", "doch", "nicht", "er\u00b7gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So wenig man den Anfang wei\u00df,", "tokens": ["So", "we\u00b7nig", "man", "den", "An\u00b7fang", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So wenig kan ich auch desselben Ende finden.", "tokens": ["So", "we\u00b7nig", "kan", "ich", "auch", "des\u00b7sel\u00b7ben", "En\u00b7de", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "PPER", "ADV", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Sonne w\u00fcrde noch viel ehr", "tokens": ["Die", "Son\u00b7ne", "w\u00fcr\u00b7de", "noch", "viel", "ehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch ihre zw\u00f6lf bekannte Zeichen", "tokens": ["Durch", "ih\u00b7re", "zw\u00f6lf", "be\u00b7kann\u00b7te", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Des rundgew\u00f6lbten Himmels streichen,", "tokens": ["Des", "rund\u00b7ge\u00b7w\u00f6lb\u00b7ten", "Him\u00b7mels", "strei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bevor ich Herr! Dein Lob zu schildern f\u00e4hig w\u00e4r.", "tokens": ["Be\u00b7vor", "ich", "Herr", "!", "Dein", "Lob", "zu", "schil\u00b7dern", "f\u00e4\u00b7hig", "w\u00e4r", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "$.", "PPOSAT", "NN", "PTKZU", "VVINF", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich mu\u00df von deinen Werken schweigen,", "tokens": ["Ich", "mu\u00df", "von", "dei\u00b7nen", "Wer\u00b7ken", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und nur mit stillem Geist die tiefste Ehrfurcht zeigen.", "tokens": ["Und", "nur", "mit", "stil\u00b7lem", "Geist", "die", "tiefs\u00b7te", "Ehr\u00b7furcht", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Die Weisheit kehrt mit ihrem Schein", "tokens": ["Die", "Weis\u00b7heit", "kehrt", "mit", "ih\u00b7rem", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und mehr als K\u00f6niglichen Gaben", "tokens": ["Und", "mehr", "als", "K\u00f6\u00b7nig\u00b7li\u00b7chen", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "KOKOM", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Viel lieber in Pal\u00e4sten ein,", "tokens": ["Viel", "lie\u00b7ber", "in", "Pa\u00b7l\u00e4s\u00b7ten", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als bey den Niedrigen die bl\u00f6de Sinne haben.", "tokens": ["Als", "bey", "den", "Nied\u00b7ri\u00b7gen", "die", "bl\u00f6\u00b7de", "Sin\u00b7ne", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein F\u00fcrst mu\u00df selbst ein Pharus seyn!", "tokens": ["Ein", "F\u00fcrst", "mu\u00df", "selbst", "ein", "Pha\u00b7rus", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Herzog mu\u00df zu allen Zeiten", "tokens": ["Ein", "Her\u00b7zog", "mu\u00df", "zu", "al\u00b7len", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sein Volk zum Weg der Tugend leiten,", "tokens": ["Sein", "Volk", "zum", "Weg", "der", "Tu\u00b7gend", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sonst wird er nimmermehr, sein Land mit Gl\u00fcck erfreun.", "tokens": ["Sonst", "wird", "er", "nim\u00b7mer\u00b7mehr", ",", "sein", "Land", "mit", "Gl\u00fcck", "er\u00b7freun", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$,", "PPOSAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die, so zugleich das Ruder f\u00fchren.", "tokens": ["Die", ",", "so", "zu\u00b7gleich", "das", "Ru\u00b7der", "f\u00fch\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mu\u00df gleichfals, wie EUGEN, der Schmuck der Weisheit zieren.", "tokens": ["Mu\u00df", "gleich\u00b7fals", ",", "wie", "Eu\u00b7GEN", ",", "der", "Schmuck", "der", "Weis\u00b7heit", "zie\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "$,", "PWAV", "NN", "$,", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Der L\u00f6we schl\u00e4ft; doch wacht er auch,", "tokens": ["Der", "L\u00f6\u00b7we", "schl\u00e4ft", ";", "doch", "wacht", "er", "auch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und h\u00e4lt die Augen schlummernd offen.", "tokens": ["Und", "h\u00e4lt", "die", "Au\u00b7gen", "schlum\u00b7mernd", "of\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dies ist gesalbter F\u00fcrsten Brauch;", "tokens": ["Dies", "ist", "ge\u00b7salb\u00b7ter", "F\u00fcrs\u00b7ten", "Brauch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dies kan man ebenfals von ihrer Weisheit hoffen.", "tokens": ["Dies", "kan", "man", "e\u00b7ben\u00b7fals", "von", "ih\u00b7rer", "Weis\u00b7heit", "hof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PIS", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des Reiches Wohlfahrt, Gl\u00fcck und Ruh", "tokens": ["Des", "Rei\u00b7ches", "Wohl\u00b7fahrt", ",", "Gl\u00fcck", "und", "Ruh"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hat oft EUGEN den Schlaf entzogen,", "tokens": ["Hat", "oft", "Eu\u00b7GEN", "den", "Schlaf", "ent\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und Ihn zur Wachsamkeit bewogen,", "tokens": ["Und", "Ihn", "zur", "Wach\u00b7sam\u00b7keit", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sein Auge schlosse sich nicht ohne Sorgen zu.", "tokens": ["Sein", "Au\u00b7ge", "schlos\u00b7se", "sich", "nicht", "oh\u00b7ne", "Sor\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "PTKNEG", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Kein R\u00e4zel war so schwer zu finden,", "tokens": ["Kein", "R\u00e4\u00b7zel", "war", "so", "schwer", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "EuGEN vermocht es doch durch Klugheit zu ergr\u00fcnden.", "tokens": ["Eu\u00b7GEN", "ver\u00b7mocht", "es", "doch", "durch", "Klug\u00b7heit", "zu", "er\u00b7gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Ein Staats-Mann \u00fcberlegt mit Flei\u00df", "tokens": ["Ein", "Staats\u00b7Mann", "\u00fc\u00b7ber\u00b7legt", "mit", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was seinem F\u00fcrsten Vortheil bringet;", "tokens": ["Was", "sei\u00b7nem", "F\u00fcrs\u00b7ten", "Vor\u00b7theil", "brin\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er achtet weder M\u00fch noch Schwei\u00df", "tokens": ["Er", "ach\u00b7tet", "we\u00b7der", "M\u00fch", "noch", "Schwei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "NN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wofern ihm nur sein Thun und kluger Rath gelinget.", "tokens": ["Wo\u00b7fern", "ihm", "nur", "sein", "Thun", "und", "klu\u00b7ger", "Rath", "ge\u00b7lin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Weltber\u00fchmte Prinz EUGEN,", "tokens": ["Der", "Welt\u00b7be\u00b7r\u00fchm\u00b7te", "Prinz", "Eu\u00b7GEN", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist diesem eifrig nachgekommen;", "tokens": ["Ist", "die\u00b7sem", "eif\u00b7rig", "nach\u00b7ge\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man hat best\u00e4ndig wahrgenommen,", "tokens": ["Man", "hat", "be\u00b7st\u00e4n\u00b7dig", "wahr\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df Er nur auf den Flor Germaniens gesehn.", "tokens": ["Da\u00df", "Er", "nur", "auf", "den", "Flor", "Ger\u00b7ma\u00b7ni\u00b7ens", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sein Vorsatz war, Sein tapfres Leben,", "tokens": ["Sein", "Vor\u00b7satz", "war", ",", "Sein", "tapf\u00b7res", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Vor unser h\u00f6chstes Haupt, den Kayser aufzugeben.", "tokens": ["Vor", "un\u00b7ser", "h\u00f6chs\u00b7tes", "Haupt", ",", "den", "Kay\u00b7ser", "auf\u00b7zu\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Wo hat solch ein gelehrter Held", "tokens": ["Wo", "hat", "solch", "ein", "ge\u00b7lehr\u00b7ter", "Held"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Erden-Krey\u00df, wie Du, geschm\u00fccket?", "tokens": ["Den", "Er\u00b7den\u00b7Krey\u00df", ",", "wie", "Du", ",", "ge\u00b7schm\u00fc\u00b7cket", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn hat wohl je die weite Welt", "tokens": ["Wenn", "hat", "wohl", "je", "die", "wei\u00b7te", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein solch ", "tokens": ["Ein", "solch"], "token_info": ["word", "word"], "pos": ["ART", "PIAT"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Minerva fand Geh\u00f6r bey Dir;", "tokens": ["Mi\u00b7ner\u00b7va", "fand", "Ge\u00b7h\u00f6r", "bey", "Dir", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "APPR", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Wenn andre sie vertrieben hatten,", "tokens": ["Wenn", "and\u00b7re", "sie", "ver\u00b7trie\u00b7ben", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So kam ihr Deine Huld zu statten;", "tokens": ["So", "kam", "ihr", "Dei\u00b7ne", "Huld", "zu", "stat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sie stellte sich Dein Bild als ihren Schutz-Gott f\u00fcr.", "tokens": ["Sie", "stell\u00b7te", "sich", "Dein", "Bild", "als", "ih\u00b7ren", "Schutz\u00b7Gott", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPOSAT", "NN", "KOUS", "PPOSAT", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nun aber mu\u00df sie trostlo\u00df stehen,", "tokens": ["Nun", "a\u00b7ber", "mu\u00df", "sie", "trost\u00b7lo\u00df", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und mit betr\u00fcbtem Geist von Deinem Grabe gehen.", "tokens": ["Und", "mit", "be\u00b7tr\u00fcb\u00b7tem", "Geist", "von", "Dei\u00b7nem", "Gra\u00b7be", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "EuGEN ist tod! ihr Musen weint!", "tokens": ["Eu\u00b7GEN", "ist", "tod", "!", "ihr", "Mu\u00b7sen", "weint", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NN", "$.", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn eure St\u00fctze ist gefallen.", "tokens": ["Denn", "eu\u00b7re", "St\u00fct\u00b7ze", "ist", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kommt, la\u00dft um euren besten Freund", "tokens": ["Kommt", ",", "la\u00dft", "um", "eu\u00b7ren", "bes\u00b7ten", "Freund"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dort auf dem Helicon ein Trauer-Lied erschallen.", "tokens": ["Dort", "auf", "dem", "He\u00b7li\u00b7con", "ein", "Trau\u00b7e\u00b7rLied", "er\u00b7schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Beklagt den sch\u00f6nen-B\u00fccher-Saal,", "tokens": ["Be\u00b7klagt", "den", "sch\u00f6\u00b7nen\u00b7B\u00fc\u00b7cher\u00b7Saal", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den so viel auserlesne Sachen.", "tokens": ["Den", "so", "viel", "au\u00b7ser\u00b7les\u00b7ne", "Sa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ber\u00fchmt und fast unsch\u00e4tzbar machen.", "tokens": ["Be\u00b7r\u00fchmt", "und", "fast", "un\u00b7sch\u00e4tz\u00b7bar", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bezeugt durch matten Thon des Herzens bange Quaal.", "tokens": ["Be\u00b7zeugt", "durch", "mat\u00b7ten", "Thon", "des", "Her\u00b7zens", "ban\u00b7ge", "Qua\u00b7al", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "ART", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "EuGENENS Tugend hat verdienet,", "tokens": ["Eu\u00b7GEN\u00b7ENS", "Tu\u00b7gend", "hat", "ver\u00b7die\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Da\u00df auch auf eurem Hayn Sein Angedenken gr\u00fcnet.", "tokens": ["Da\u00df", "auch", "auf", "eu\u00b7rem", "Hayn", "Sein", "An\u00b7ge\u00b7den\u00b7ken", "gr\u00fc\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Wenn Salomon den Tempel baut,", "tokens": ["Wenn", "Sa\u00b7lo\u00b7mon", "den", "Tem\u00b7pel", "baut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So wird dadurch sein Ruhm erhoben.", "tokens": ["So", "wird", "da\u00b7durch", "sein", "Ruhm", "er\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PAV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wer Unsers Herzogs Tempel schaut,", "tokens": ["Wer", "Un\u00b7sers", "Her\u00b7zogs", "Tem\u00b7pel", "schaut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mu\u00df diesen grossen Prinz und Seine Anstalt loben.", "tokens": ["Mu\u00df", "die\u00b7sen", "gros\u00b7sen", "Prinz", "und", "Sei\u00b7ne", "An\u00b7stalt", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDAT", "ADJA", "NN", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Garten, den Semiramis", "tokens": ["Der", "Gar\u00b7ten", ",", "den", "Se\u00b7mi\u00b7ra\u00b7mis"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Welt zum Wunder hinterlassen,", "tokens": ["Der", "Welt", "zum", "Wun\u00b7der", "hin\u00b7ter\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Kan kaum so viele Sch\u00f6nheit fassen,", "tokens": ["Kan", "kaum", "so", "vie\u00b7le", "Sch\u00f6n\u00b7heit", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Als uns der kluge Held an Seinem Garten wie\u00df.", "tokens": ["Als", "uns", "der", "klu\u00b7ge", "Held", "an", "Sei\u00b7nem", "Gar\u00b7ten", "wie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "EuGEN lie\u00df wie August in Pohlen,", "tokens": ["Eu\u00b7GEN", "lie\u00df", "wie", "Au\u00b7gust", "in", "Poh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KOKOM", "NN", "APPR", "NE", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.10": {"text": "Die Wunder der Natur von weiten Orten hohlen.", "tokens": ["Die", "Wun\u00b7der", "der", "Na\u00b7tur", "von", "wei\u00b7ten", "Or\u00b7ten", "hoh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Der Grosse Kayser kan zwar nun", "tokens": ["Der", "Gros\u00b7se", "Kay\u00b7ser", "kan", "zwar", "nun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VMFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Janus offnen Tempel schliessen;", "tokens": ["Des", "Ja\u00b7nus", "off\u00b7nen", "Tem\u00b7pel", "schlies\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allein, Er kans nicht freudig thun;", "tokens": ["Al\u00b7lein", ",", "Er", "kans", "nicht", "freu\u00b7dig", "thun", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Augen werden Ihm darbey beweglich fliessen.", "tokens": ["Die", "Au\u00b7gen", "wer\u00b7den", "Ihm", "dar\u00b7bey", "be\u00b7weg\u00b7lich", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PAV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie k\u00f6mmts? ", "tokens": ["Wie", "k\u00f6mmts", "?"], "token_info": ["word", "word", "punct"], "pos": ["PWAV", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Sein gr\u00f6\u00dfter Staats-Minister fliehet,", "tokens": ["Sein", "gr\u00f6\u00df\u00b7ter", "Staats\u00b7Mi\u00b7nis\u00b7ter", "flie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Indem er sich der Welt entziehet.", "tokens": ["In\u00b7dem", "er", "sich", "der", "Welt", "ent\u00b7zie\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dergleichen harter Fall mu\u00df Ihm zu Herzen gehn.", "tokens": ["Derg\u00b7lei\u00b7chen", "har\u00b7ter", "Fall", "mu\u00df", "Ihm", "zu", "Her\u00b7zen", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJA", "NN", "VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Hier sieht man, wie das Gl\u00fccke spielet,", "tokens": ["Hier", "sieht", "man", ",", "wie", "das", "Gl\u00fc\u00b7cke", "spie\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wie oft es bey der Lust zugleich auf Unlust zielet.", "tokens": ["Wie", "oft", "es", "bey", "der", "Lust", "zu\u00b7gleich", "auf", "Un\u00b7lust", "zie\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Das Alterthum war sonst bem\u00fcht,", "tokens": ["Das", "Al\u00b7ter\u00b7thum", "war", "sonst", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Colossen in die H\u00f6h zu bauen.", "tokens": ["Co\u00b7los\u00b7sen", "in", "die", "H\u00f6h", "zu", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O Tapfrer Prinz EUGEN! man sieht", "tokens": ["O", "Tapf\u00b7rer", "Prinz", "Eu\u00b7GEN", "!", "man", "sieht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADJA", "NN", "NE", "$.", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dein Bildni\u00df nicht in Stein; nein in was sch\u00f6nres hauen.", "tokens": ["Dein", "Bild\u00b7ni\u00df", "nicht", "in", "Stein", ";", "nein", "in", "was", "sch\u00f6n\u00b7res", "hau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "APPR", "NN", "$.", "PTKANT", "APPR", "PRELS", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Herzen werden Dir zur Gruft,", "tokens": ["Die", "Her\u00b7zen", "wer\u00b7den", "Dir", "zur", "Gruft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In diese wird man Dich versenken:", "tokens": ["In", "die\u00b7se", "wird", "man", "Dich", "ver\u00b7sen\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "PIS", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hier ruht Dein ewig Angedenken:", "tokens": ["Hier", "ruht", "Dein", "e\u00b7wig", "An\u00b7ge\u00b7den\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dies Grabmaal trotzt der Zeit, dem Feuer und der Lust.", "tokens": ["Dies", "Grab\u00b7maal", "trotzt", "der", "Zeit", ",", "dem", "Feu\u00b7er", "und", "der", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was sucht ihr Lampen anzuz\u00fcnden?", "tokens": ["Was", "sucht", "ihr", "Lam\u00b7pen", "an\u00b7zu\u00b7z\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ihr werdet Glanz genug in Seinem Namen finden.", "tokens": ["Ihr", "wer\u00b7det", "Glanz", "ge\u00b7nug", "in", "Sei\u00b7nem", "Na\u00b7men", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Herr! w\u00e4r Dein Tod in vorger Zeit", "tokens": ["Herr", "!", "w\u00e4r", "Dein", "Tod", "in", "vor\u00b7ger", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "VAFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und in dem Heydenthum geschehen,", "tokens": ["Und", "in", "dem", "Hey\u00b7den\u00b7thum", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wir w\u00fcrden auch mit Traurigkeit,", "tokens": ["Wir", "w\u00fcr\u00b7den", "auch", "mit", "Trau\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor jener tiefen Gruft nach Art des Orpheus stehen.", "tokens": ["Vor", "je\u00b7ner", "tie\u00b7fen", "Gruft", "nach", "Art", "des", "Or\u00b7pheus", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "APPR", "NN", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir w\u00fcrden wahrlich nicht mit Flehn", "tokens": ["Wir", "w\u00fcr\u00b7den", "wahr\u00b7lich", "nicht", "mit", "Flehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Klage-Liedern m\u00fcde werden,", "tokens": ["Und", "Kla\u00b7ge\u00b7Lie\u00b7dern", "m\u00fc\u00b7de", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bis wir Dich wieder auf der Erden", "tokens": ["Bis", "wir", "Dich", "wie\u00b7der", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Gleich der Euridice aufs neue k\u00f6nten sehn.", "tokens": ["Gleich", "der", "Eu\u00b7ri\u00b7di\u00b7ce", "aufs", "neu\u00b7e", "k\u00f6n\u00b7ten", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "APPRART", "ADJA", "VMFIN", "VVINF", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Doch nein! umsonst! ist unser Weinen,", "tokens": ["Doch", "nein", "!", "um\u00b7sonst", "!", "ist", "un\u00b7ser", "Wei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$.", "ADV", "$.", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "EuGEN wird nun nicht mehr auf dieser Welt erscheinen.", "tokens": ["Eu\u00b7GEN", "wird", "nun", "nicht", "mehr", "auf", "die\u00b7ser", "Welt", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "PTKNEG", "ADV", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "EuGEN ist todt! was h\u00f6rt mein Ohr?", "tokens": ["Eu\u00b7GEN", "ist", "todt", "!", "was", "h\u00f6rt", "mein", "Ohr", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "$.", "PWS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie? sucht mich Fama zu betr\u00fcgen?", "tokens": ["Wie", "?", "sucht", "mich", "Fa\u00b7ma", "zu", "be\u00b7tr\u00fc\u00b7gen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "PPER", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "EuGEN, der keine Schlacht verlohr,", "tokens": ["Eu\u00b7GEN", ",", "der", "kei\u00b7ne", "Schlacht", "ver\u00b7lohr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Soll durch Morbonens Faust so pl\u00f6tzlich unterliegen?", "tokens": ["Soll", "durch", "Mor\u00b7bo\u00b7nens", "Faust", "so", "pl\u00f6tz\u00b7lich", "un\u00b7ter\u00b7lie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "O eitler Ruf! o falsch Geschrey!", "tokens": ["O", "eit\u00b7ler", "Ruf", "!", "o", "falsch", "Ge\u00b7schrey", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "FM", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wodurch in Ost, S\u00fcd, West und Norden", "tokens": ["Wo\u00b7durch", "in", "Ost", ",", "S\u00fcd", ",", "West", "und", "Nor\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPR", "NE", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Welt so oft get\u00e4uschet worden;", "tokens": ["Die", "Welt", "so", "oft", "ge\u00b7t\u00e4u\u00b7schet", "wor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich glaube nimmermehr, da\u00df dieses m\u00f6glich sey?", "tokens": ["Ich", "glau\u00b7be", "nim\u00b7mer\u00b7mehr", ",", "da\u00df", "die\u00b7ses", "m\u00f6g\u00b7lich", "sey", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "PDAT", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Das Schicksal l\u00e4st es nicht geschehen;", "tokens": ["Das", "Schick\u00b7sal", "l\u00e4st", "es", "nicht", "ge\u00b7sche\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So bald darf Unser Held noch nicht von hinnen gehen.", "tokens": ["So", "bald", "darf", "Un\u00b7ser", "Held", "noch", "nicht", "von", "hin\u00b7nen", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPOSAT", "NN", "ADV", "PTKNEG", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "EuGEN ist todt! ja! ja! sein Sarg", "tokens": ["Eu\u00b7GEN", "ist", "todt", "!", "ja", "!", "ja", "!", "sein", "Sarg"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "VAFIN", "ADJD", "$.", "PTKANT", "$.", "PTKANT", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00f6mmt mir von weiten ins Gesichte.", "tokens": ["K\u00f6mmt", "mir", "von", "wei\u00b7ten", "ins", "Ge\u00b7sich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Uberzeugung ist zu stark;", "tokens": ["Die", "Ub\u00b7er\u00b7zeu\u00b7gung", "ist", "zu", "stark", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun seh, nun merk ich wohl, es ist kein blos Gedichte.", "tokens": ["Nun", "seh", ",", "nun", "merk", "ich", "wohl", ",", "es", "ist", "kein", "blos", "Ge\u00b7dich\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV", "$,", "PPER", "VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sein Geist schwebt in der Ewigkeit,", "tokens": ["Sein", "Geist", "schwebt", "in", "der", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und hat den Erden-Krei\u00df verlassen.", "tokens": ["Und", "hat", "den", "Er\u00b7den\u00b7Krei\u00df", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man klaget jetzt auf unsern Gassen:", "tokens": ["Man", "kla\u00b7get", "jetzt", "auf", "un\u00b7sern", "Gas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dort liegt der tapfre F\u00fcrst; der gr\u00f6ste Held im Streit!", "tokens": ["Dort", "liegt", "der", "tapf\u00b7re", "F\u00fcrst", ";", "der", "gr\u00f6s\u00b7te", "Held", "im", "Streit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der kl\u00fcgste Feld-Herr unter allen", "tokens": ["Der", "kl\u00fcgs\u00b7te", "Feld\u00b7Herr", "un\u00b7ter", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ist, welch ein Schreckens-Wort! entseelt, erbla\u00dft, gefallen!", "tokens": ["Ist", ",", "welch", "ein", "Schre\u00b7ckens\u00b7Wort", "!", "ent\u00b7seelt", ",", "er\u00b7bla\u00dft", ",", "ge\u00b7fal\u00b7len", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "$,", "PWAT", "ART", "NN", "$.", "VVFIN", "$,", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Wer wei\u00df, ob auch ein Donner-Strahl,", "tokens": ["Wer", "wei\u00df", ",", "ob", "auch", "ein", "Don\u00b7ner\u00b7Strahl", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der \u00f6fters Mensch und Vieh erschrecket,", "tokens": ["Der", "\u00f6f\u00b7ters", "Mensch", "und", "Vieh", "er\u00b7schre\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So bittres Leid, so grosse Quaal,", "tokens": ["So", "bitt\u00b7res", "Leid", ",", "so", "gros\u00b7se", "Qua\u00b7al", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als diese Trauer-Post in mancher Brust erwecket?", "tokens": ["Als", "die\u00b7se", "Trau\u00b7e\u00b7rPost", "in", "man\u00b7cher", "Brust", "er\u00b7we\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auch CARL wird von dem Fall ger\u00fchrt,", "tokens": ["Auch", "CaRL", "wird", "von", "dem", "Fall", "ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sucht den Kummer anzudeuten;", "tokens": ["Und", "sucht", "den", "Kum\u00b7mer", "an\u00b7zu\u00b7deu\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bey allen Helden unsrer Zeiten", "tokens": ["Bey", "al\u00b7len", "Hel\u00b7den", "uns\u00b7rer", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wird nichts als Traurigkeit und herber Schmerz versp\u00fchrt.", "tokens": ["Wird", "nichts", "als", "Trau\u00b7rig\u00b7keit", "und", "her\u00b7ber", "Schmerz", "ver\u00b7sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "KOKOM", "NN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Europa wird dadurch ersch\u00fcttert;", "tokens": ["Eu\u00b7ro\u00b7pa", "wird", "da\u00b7durch", "er\u00b7sch\u00fct\u00b7tert", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "EuGENENS schneller Tod macht, da\u00df es bebt und zittert.", "tokens": ["Eu\u00b7GEN\u00b7ENS", "schnel\u00b7ler", "Tod", "macht", ",", "da\u00df", "es", "bebt", "und", "zit\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.39": {"line.1": {"text": "Nicht nur die Gr\u00f6\u00dften dieser Welt", "tokens": ["Nicht", "nur", "die", "Gr\u00f6\u00df\u00b7ten", "die\u00b7ser", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Betrauren Ihn mit scharfen Klagen;", "tokens": ["Be\u00b7trau\u00b7ren", "Ihn", "mit", "schar\u00b7fen", "Kla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sinds nicht blos, die um den Held,", "tokens": ["Sie", "sinds", "nicht", "blos", ",", "die", "um", "den", "Held", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "$,", "PRELS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und diesen ", "tokens": ["Und", "die\u00b7sen"], "token_info": ["word", "word"], "pos": ["KON", "PDAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Auch die, so schlechter Staub bedeckt;", "tokens": ["Auch", "die", ",", "so", "schlech\u00b7ter", "Staub", "be\u00b7deckt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die allerniedrigsten im Reiche", "tokens": ["Die", "al\u00b7ler\u00b7nied\u00b7rigs\u00b7ten", "im", "Rei\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "APPRART", "NE"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Beweinen diese F\u00fcrsten-Leiche;", "tokens": ["Be\u00b7wei\u00b7nen", "die\u00b7se", "F\u00fcrs\u00b7ten\u00b7Lei\u00b7che", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ihr Herz wird von dem Ri\u00df aufs heftigste erschreckt.", "tokens": ["Ihr", "Herz", "wird", "von", "dem", "Ri\u00df", "aufs", "hef\u00b7tigs\u00b7te", "er\u00b7schreckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die, welche Seine Thaten wissen,", "tokens": ["Die", ",", "wel\u00b7che", "Sei\u00b7ne", "Tha\u00b7ten", "wis\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Hat Sein geschwinder Tod in Ohnmacht hingerissen.", "tokens": ["Hat", "Sein", "ge\u00b7schwin\u00b7der", "Tod", "in", "Ohn\u00b7macht", "hin\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Ich wei\u00df, wie mich Sein Fall bet\u00e4ubt;", "tokens": ["Ich", "wei\u00df", ",", "wie", "mich", "Sein", "Fall", "be\u00b7t\u00e4ubt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich weine, wenn ich dran gedenke.", "tokens": ["Ich", "wei\u00b7ne", ",", "wenn", "ich", "dran", "ge\u00b7den\u00b7ke", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O Schmerz! der mich zum Seufzen treibt,", "tokens": ["O", "Schmerz", "!", "der", "mich", "zum", "Seuf\u00b7zen", "treibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ART", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So oft ich mich im Geist zu Seiner Bahre lenke.", "tokens": ["So", "oft", "ich", "mich", "im", "Geist", "zu", "Sei\u00b7ner", "Bah\u00b7re", "len\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "APPRART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "EuGEN, der meiner Niedrigkeit", "tokens": ["Eu\u00b7GEN", ",", "der", "mei\u00b7ner", "Nied\u00b7rig\u00b7keit"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So viele Gnad und Huld erwiesen;", "tokens": ["So", "vie\u00b7le", "Gnad", "und", "Huld", "er\u00b7wie\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "EuGEN, der meinen Flei\u00df gepriesen,", "tokens": ["Eu\u00b7GEN", ",", "der", "mei\u00b7nen", "Flei\u00df", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Setzt jetzo meine Brust in ungemeines Leid.", "tokens": ["Setzt", "jet\u00b7zo", "mei\u00b7ne", "Brust", "in", "un\u00b7ge\u00b7mei\u00b7nes", "Leid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "O soll ich Deinen Tod besingen!", "tokens": ["O", "soll", "ich", "Dei\u00b7nen", "Tod", "be\u00b7sin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "O darf ich Dir nicht mehr ein Freuden-Opfer bringe!", "tokens": ["O", "darf", "ich", "Dir", "nicht", "mehr", "ein", "Freu\u00b7den\u00b7Op\u00b7fer", "brin\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PPER", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "Die Ehrfurcht, so mein Dichter-Rohr", "tokens": ["Die", "Ehr\u00b7furcht", ",", "so", "mein", "Dich\u00b7ter\u00b7Rohr"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey jener holden Zeit gef\u00fchret,", "tokens": ["Bey", "je\u00b7ner", "hol\u00b7den", "Zeit", "ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Stellt mir auch jetzt die Pflichten vor,", "tokens": ["Stellt", "mir", "auch", "jetzt", "die", "Pflich\u00b7ten", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da Oesterreich an Dir ein ", "tokens": ["Da", "O\u00b7es\u00b7ter\u00b7reich", "an", "Dir", "ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "APPR", "PPER", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich werde, ", "tokens": ["Ich", "wer\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "So lange mich die Musen lieben,", "tokens": ["So", "lan\u00b7ge", "mich", "die", "Mu\u00b7sen", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Mein Spiel in Deinem Ruhme \u00fcben,", "tokens": ["Mein", "Spiel", "in", "Dei\u00b7nem", "Ruh\u00b7me", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ob mancher Midas gleich ein h\u00f6hnisch Urtheil f\u00e4llt.", "tokens": ["Ob", "man\u00b7cher", "Mi\u00b7das", "gleich", "ein", "h\u00f6h\u00b7nisch", "Ur\u00b7theil", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADV", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Thorheit soll mir nicht verwehren,", "tokens": ["Die", "Thor\u00b7heit", "soll", "mir", "nicht", "ver\u00b7weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Dich, ", "tokens": ["Dich", ","], "token_info": ["word", "punct"], "pos": ["PPER", "$,"], "meter": "-", "measure": "single.down"}}, "stanza.42": {"line.1": {"text": "O d\u00fcrft ich nur zu dieser Zeit", "tokens": ["O", "d\u00fcrft", "ich", "nur", "zu", "die\u00b7ser", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Laub auf Deine Bahre streuen,", "tokens": ["Kein", "Laub", "auf", "Dei\u00b7ne", "Bah\u00b7re", "streu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und Dir in banger Traurigkeit", "tokens": ["Und", "Dir", "in", "ban\u00b7ger", "Trau\u00b7rig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor einen Lorbeer-Strau\u00df Cypressen-Str\u00e4uche weyhen!", "tokens": ["Vor", "ei\u00b7nen", "Lor\u00b7beer\u00b7Strau\u00df", "Cy\u00b7pres\u00b7sen\u00b7Str\u00e4u\u00b7che", "wey\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr Musen! wenn euch nicht EUGEN", "tokens": ["Ihr", "Mu\u00b7sen", "!", "wenn", "euch", "nicht", "Eu\u00b7GEN"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "KOUS", "PPER", "PTKNEG", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die F\u00e4higkeit, wie mir, geraubet;", "tokens": ["Die", "F\u00e4\u00b7hig\u00b7keit", ",", "wie", "mir", ",", "ge\u00b7rau\u00b7bet", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn euch der harte Schmerz erlaubet,", "tokens": ["Wenn", "euch", "der", "har\u00b7te", "Schmerz", "er\u00b7lau\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So f\u00fchrt mir jetzt den Kiel, Sein Grabmaal zu erh\u00f6hn.", "tokens": ["So", "f\u00fchrt", "mir", "jetzt", "den", "Kiel", ",", "Sein", "Grab\u00b7maal", "zu", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NE", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich bin zu schwach bey so viel Gr\u00e4men", "tokens": ["Ich", "bin", "zu", "schwach", "bey", "so", "viel", "Gr\u00e4\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "APPR", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die Feder ohne Furcht in meine Hand zu nehmen.", "tokens": ["Die", "Fe\u00b7der", "oh\u00b7ne", "Furcht", "in", "mei\u00b7ne", "Hand", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.43": {"line.1": {"text": "Da\u00df ich dich in der Gruft verst\u00f6hre,", "tokens": ["Da\u00df", "ich", "dich", "in", "der", "Gruft", "ver\u00b7st\u00f6h\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und mich zu Deines Grabes Th\u00fcr", "tokens": ["Und", "mich", "zu", "Dei\u00b7nes", "Gra\u00b7bes", "Th\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit meinem heischern Rohr u. matten Sayten kehre.", "tokens": ["Mit", "mei\u00b7nem", "hei\u00b7schern", "Rohr", "u.", "mat\u00b7ten", "Say\u00b7ten", "keh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Du l\u00e4\u00dft es, ", "tokens": ["Du", "l\u00e4\u00dft", "es", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ich wei\u00df, Du wirst es mir vergeben;", "tokens": ["Ich", "wei\u00df", ",", "Du", "wirst", "es", "mir", "ver\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Du hast ja sonst in Deinem Leben", "tokens": ["Du", "hast", "ja", "sonst", "in", "Dei\u00b7nem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Mein schwaches Lauten-Spiel so gn\u00e4dig angesehn:", "tokens": ["Mein", "schwa\u00b7ches", "Lau\u00b7ten\u00b7Spiel", "so", "gn\u00e4\u00b7dig", "an\u00b7ge\u00b7sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Du wirst auf mein geringes Dichten,", "tokens": ["Du", "wirst", "auf", "mein", "ge\u00b7rin\u00b7ges", "Dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Auch aus dem Grabe noch ein holdes Auge richten.", "tokens": ["Auch", "aus", "dem", "Gra\u00b7be", "noch", "ein", "hol\u00b7des", "Au\u00b7ge", "rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "Ich kan Dich, Herr! nach W\u00fcrdigkeit", "tokens": ["Ich", "kan", "Dich", ",", "Herr", "!", "nach", "W\u00fcr\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "$,", "NN", "$.", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und nach Verdienst zwar nicht besingen,", "tokens": ["Und", "nach", "Ver\u00b7dienst", "zwar", "nicht", "be\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Noch Deiner Thaten Seltenheit,", "tokens": ["Noch", "Dei\u00b7ner", "Tha\u00b7ten", "Sel\u00b7ten\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch Deine Tugenden in meine Reime zwingen.", "tokens": ["Noch", "Dei\u00b7ne", "Tu\u00b7gen\u00b7den", "in", "mei\u00b7ne", "Rei\u00b7me", "zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es stehet nicht in meiner Kraft", "tokens": ["Es", "ste\u00b7het", "nicht", "in", "mei\u00b7ner", "Kraft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von einem so beherzten Helden", "tokens": ["Von", "ei\u00b7nem", "so", "be\u00b7herz\u00b7ten", "Hel\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Auch nur das wenigste zu melden;", "tokens": ["Auch", "nur", "das", "we\u00b7nigs\u00b7te", "zu", "mel\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich lalle blos etwas von Deiner Eigenschaft.", "tokens": ["Ich", "lal\u00b7le", "blos", "et\u00b7was", "von", "Dei\u00b7ner", "Ei\u00b7gen\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der gr\u00f6\u00dfte Dichter m\u00fc\u00dfte schweigen,", "tokens": ["Der", "gr\u00f6\u00df\u00b7te", "Dich\u00b7ter", "m\u00fc\u00df\u00b7te", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wofern er willens w\u00e4r, von Deinem Ruhm zu zeugen.", "tokens": ["Wo\u00b7fern", "er", "wil\u00b7lens", "w\u00e4r", ",", "von", "Dei\u00b7nem", "Ruhm", "zu", "zeu\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAFIN", "$,", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Die\u00df ist kein Werk vor einen Mann;", "tokens": ["Die\u00df", "ist", "kein", "Werk", "vor", "ei\u00b7nen", "Mann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein einzig Jahr von Deinem Leben;", "tokens": ["Ein", "ein\u00b7zig", "Jahr", "von", "Dei\u00b7nem", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur eine That, die Du gethan,", "tokens": ["Nur", "ei\u00b7ne", "That", ",", "die", "Du", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kan dem, der sie beschreibt, gnug Stoff und Nachdruck geben.", "tokens": ["Kan", "dem", ",", "der", "sie", "be\u00b7schreibt", ",", "gnug", "Stoff", "und", "Nach\u00b7druck", "ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hat nun ein Dichter fast allein", "tokens": ["Hat", "nun", "ein", "Dich\u00b7ter", "fast", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von einem Jahre gnug zu sagen,", "tokens": ["Von", "ei\u00b7nem", "Jah\u00b7re", "gnug", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wer will sich an die andern wagen?", "tokens": ["Wer", "will", "sich", "an", "die", "an\u00b7dern", "wa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Hier mu\u00df gewi\u00df ein Chor von drey und siebnzig seyn.", "tokens": ["Hier", "mu\u00df", "ge\u00b7wi\u00df", "ein", "Chor", "von", "drey", "und", "siebn\u00b7zig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "ART", "NN", "APPR", "CARD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Thaten sind nicht zu ergr\u00fcnden,", "tokens": ["Die", "Tha\u00b7ten", "sind", "nicht", "zu", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wo wird man wohl bey uns so viele Dichter finden?", "tokens": ["Wo", "wird", "man", "wohl", "bey", "uns", "so", "vie\u00b7le", "Dich\u00b7ter", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PIS", "ADV", "APPR", "PPER", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Der Vorzug, den die Allmachts-Hand", "tokens": ["Der", "Vor\u00b7zug", ",", "den", "die", "All\u00b7machts\u00b7Hand"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den F\u00fcrsten in der Welt geschenket,", "tokens": ["Den", "F\u00fcrs\u00b7ten", "in", "der", "Welt", "ge\u00b7schen\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ist gro\u00df, so fern man ihren Stand,", "tokens": ["Ist", "gro\u00df", ",", "so", "fern", "man", "ih\u00b7ren", "Stand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "ADV", "ADJD", "PIS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Ansehn, Ehr und Ruhm u. hohe Macht bedenket.", "tokens": ["Ihr", "An\u00b7sehn", ",", "Ehr", "und", "Ruhm", "u.", "ho\u00b7he", "Macht", "be\u00b7den\u00b7ket", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Sie sind begl\u00fcckt: Der Tod allein,", "tokens": ["Sie", "sind", "be\u00b7gl\u00fcckt", ":", "Der", "Tod", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der auch in g\u00fcldnen H\u00e4usern wohnet,", "tokens": ["Der", "auch", "in", "g\u00fcld\u00b7nen", "H\u00e4u\u00b7sern", "woh\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und keines Purpurs Glanz verschonet,", "tokens": ["Und", "kei\u00b7nes", "Pur\u00b7purs", "Glanz", "ver\u00b7scho\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zeigt, da\u00df sie ebenfalls, wie andre sterblich seyn.", "tokens": ["Zeigt", ",", "da\u00df", "sie", "e\u00b7ben\u00b7falls", ",", "wie", "and\u00b7re", "sterb\u00b7lich", "seyn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADV", "$,", "PWAV", "PIS", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Kein Ansehn kan den Tod besiegen;", "tokens": ["Kein", "An\u00b7sehn", "kan", "den", "Tod", "be\u00b7sie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ein Cr\u00f6sus mu\u00df so wohl als Irus unterliegen.", "tokens": ["Ein", "Cr\u00f6\u00b7sus", "mu\u00df", "so", "wohl", "als", "I\u00b7rus", "un\u00b7ter\u00b7lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADV", "KOUS", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.47": {"line.1": {"text": "O! wenn des Himmels G\u00fctigkeit", "tokens": ["O", "!", "wenn", "des", "Him\u00b7mels", "G\u00fc\u00b7tig\u00b7keit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur dies dem Tod gebiethen wolte,", "tokens": ["Nur", "dies", "dem", "Tod", "ge\u00b7bie\u00b7then", "wol\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df er der Helden Lebens-Zeit", "tokens": ["Da\u00df", "er", "der", "Hel\u00b7den", "Le\u00b7bens\u00b7Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht so geschwind, so fr\u00fch, so bald verk\u00fcrzen solte!", "tokens": ["Nicht", "so", "ge\u00b7schwind", ",", "so", "fr\u00fch", ",", "so", "bald", "ver\u00b7k\u00fcr\u00b7zen", "sol\u00b7te", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "O gieng doch ihrer Jahre Lauf", "tokens": ["O", "gieng", "doch", "ih\u00b7rer", "Jah\u00b7re", "Lauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So weit, als in den ersten Tagen,", "tokens": ["So", "weit", ",", "als", "in", "den", "ers\u00b7ten", "Ta\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wovon uns die Geschichte sagen;", "tokens": ["Wo\u00b7von", "uns", "die", "Ge\u00b7schich\u00b7te", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "O stieg ihr Alter nur auf mehr als hundert nauf!", "tokens": ["O", "stieg", "ihr", "Al\u00b7ter", "nur", "auf", "mehr", "als", "hun\u00b7dert", "nauf", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "PIAT", "KOKOM", "CARD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So w\u00e4r noch jetzt EUGEN auf Erden,", "tokens": ["So", "w\u00e4r", "noch", "jetzt", "Eu\u00b7GEN", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und k\u00f6nte wie vor dem die Lust besungen werden.", "tokens": ["Und", "k\u00f6n\u00b7te", "wie", "vor", "dem", "die", "Lust", "be\u00b7sun\u00b7gen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "KOKOM", "APPR", "ART", "ART", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Der Donner br\u00fcllt und ra\u00dft vielmehr", "tokens": ["Der", "Don\u00b7ner", "br\u00fcllt", "und", "ra\u00dft", "viel\u00b7mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf hohen Bergen als in Gr\u00fcnden.", "tokens": ["Auf", "ho\u00b7hen", "Ber\u00b7gen", "als", "in", "Gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sein blitzend Feuer pflegt weit eh'r", "tokens": ["Sein", "blit\u00b7zend", "Feu\u00b7er", "pflegt", "weit", "eh'r"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Eichen stolzes Haupt als Hecken zu entz\u00fcnden.", "tokens": ["Der", "Ei\u00b7chen", "stol\u00b7zes", "Haupt", "als", "He\u00b7cken", "zu", "ent\u00b7z\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KOUS", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So macht es auch der Parcen Hand;", "tokens": ["So", "macht", "es", "auch", "der", "Par\u00b7cen", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie t\u00f6dtet K\u00f6nige und Kayser,", "tokens": ["Sie", "t\u00f6d\u00b7tet", "K\u00f6\u00b7ni\u00b7ge", "und", "Kay\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Verheert die allergr\u00f6\u00dften H\u00e4user,", "tokens": ["Ver\u00b7heert", "die", "al\u00b7ler\u00b7gr\u00f6\u00df\u00b7ten", "H\u00e4u\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und scheut am wenigsten den hohen F\u00fcrsten-Stand.", "tokens": ["Und", "scheut", "am", "we\u00b7nigs\u00b7ten", "den", "ho\u00b7hen", "F\u00fcrs\u00b7ten\u00b7Stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.9": {"text": "Hingegen schont sie schlechter H\u00fctten,", "tokens": ["Hin\u00b7ge\u00b7gen", "schont", "sie", "schlech\u00b7ter", "H\u00fct\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Die doch wohl oftermahls um ihre Ankunft bitten.", "tokens": ["Die", "doch", "wohl", "of\u00b7ter\u00b7mahls", "um", "ih\u00b7re", "An\u00b7kunft", "bit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "Dort auf dem Deutschen Libanon,", "tokens": ["Dort", "auf", "dem", "Deut\u00b7schen", "Li\u00b7ba\u00b7non", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den lauter tapfre Helden zieren,", "tokens": ["Den", "lau\u00b7ter", "tapf\u00b7re", "Hel\u00b7den", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vernimmt man einen Klage-Thon;", "tokens": ["Ver\u00b7nimmt", "man", "ei\u00b7nen", "Kla\u00b7ge\u00b7Thon", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man kan den strengen Schmerz an allen Orten sp\u00fchren.", "tokens": ["Man", "kan", "den", "stren\u00b7gen", "Schmerz", "an", "al\u00b7len", "Or\u00b7ten", "sp\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Warum? die gr\u00f6\u00dfte Ceder ist", "tokens": ["Wa\u00b7rum", "?", "die", "gr\u00f6\u00df\u00b7te", "Ce\u00b7der", "ist"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "ART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch Prinz EUGENENS Tod gefallen.", "tokens": ["Durch", "Prinz", "Eu\u00b7GEN\u00b7ENS", "Tod", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "O, da\u00df ein solches Donner-Knallen,", "tokens": ["O", ",", "da\u00df", "ein", "sol\u00b7ches", "Don\u00b7ner\u00b7Knal\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den angenehmen Hayn so j\u00e4mmerlich verw\u00fcst!", "tokens": ["Den", "an\u00b7ge\u00b7neh\u00b7men", "Hayn", "so", "j\u00e4m\u00b7mer\u00b7lich", "ver\u00b7w\u00fcst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ihr Cedern! wie wirds euch ergehen!", "tokens": ["Ihr", "Ce\u00b7dern", "!", "wie", "wirds", "euch", "er\u00b7ge\u00b7hen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PWAV", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.10": {"text": "F\u00e4llt euer sch\u00f6nster Stamm, wie wolt denn ihr bestehen?", "tokens": ["F\u00e4llt", "eu\u00b7er", "sch\u00f6ns\u00b7ter", "Stamm", ",", "wie", "wolt", "denn", "ihr", "be\u00b7ste\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$,", "PWAV", "VMFIN", "KON", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.50": {"line.1": {"text": "Wie, wenn das Auge dieser Welt", "tokens": ["Wie", ",", "wenn", "das", "Au\u00b7ge", "die\u00b7ser", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KOUS", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Licht dem Horizont entziehet,", "tokens": ["Sein", "Licht", "dem", "Ho\u00b7ri\u00b7zont", "ent\u00b7zie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Schatten auf die Wiesen f\u00e4llt,", "tokens": ["Der", "Schat\u00b7ten", "auf", "die", "Wie\u00b7sen", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jemehr der helle Schein von ihrer Gegend fliehet.", "tokens": ["Je\u00b7mehr", "der", "hel\u00b7le", "Schein", "von", "ih\u00b7rer", "Ge\u00b7gend", "flie\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So wird durch grosser F\u00fcrsten Tod", "tokens": ["So", "wird", "durch", "gros\u00b7ser", "F\u00fcrs\u00b7ten", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Land, das ihre Thaten sch\u00e4tzet,", "tokens": ["Ein", "Land", ",", "das", "ih\u00b7re", "Tha\u00b7ten", "sch\u00e4t\u00b7zet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "In tr\u00fcbe Finsterni\u00df gesetzet,", "tokens": ["In", "tr\u00fc\u00b7be", "Fins\u00b7ter\u00b7ni\u00df", "ge\u00b7set\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Weil so ein harter Streich nicht wenig Ungl\u00fcck droht.", "tokens": ["Weil", "so", "ein", "har\u00b7ter", "Streich", "nicht", "we\u00b7nig", "Un\u00b7gl\u00fcck", "droht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "PTKNEG", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "EuGENENS d\u00fcstre Gruft und Bogen", "tokens": ["Eu\u00b7GEN\u00b7ENS", "d\u00fcst\u00b7re", "Gruft", "und", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Hat gleiche Dunkelheit dem Reiche zugezogen.", "tokens": ["Hat", "glei\u00b7che", "Dun\u00b7kel\u00b7heit", "dem", "Rei\u00b7che", "zu\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "ART", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Man hat, Unsterblicher EUGEN!", "tokens": ["Man", "hat", ",", "U\u00b7nsterb\u00b7li\u00b7cher", "Eu\u00b7GEN", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "$,", "ADJA", "NN", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "Dich als Philippens Sohn betrachtet;", "tokens": ["Dich", "als", "Phil\u00b7ip\u00b7pens", "Sohn", "be\u00b7trach\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "NE", "NN", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Wer Deinen L\u00f6wen-Muth gesehn,", "tokens": ["Wer", "Dei\u00b7nen", "L\u00f6\u00b7wen\u00b7Muth", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat Dich weit h\u00f6her noch als Scanderbeck geachtet.", "tokens": ["Hat", "Dich", "weit", "h\u00f6\u00b7her", "noch", "als", "Scan\u00b7der\u00b7beck", "ge\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADJD", "ADV", "KOUS", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du bist von Deiner Jugend an", "tokens": ["Du", "bist", "von", "Dei\u00b7ner", "Ju\u00b7gend", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem Helden-Ruhme nachgegangen:", "tokens": ["Dem", "Hel\u00b7den\u00b7Ruh\u00b7me", "nach\u00b7ge\u00b7gan\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du hast ihn auch gar bald empfangen,", "tokens": ["Du", "hast", "ihn", "auch", "gar", "bald", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Weil deine Faust weit mehr als C\u00e4sars Arm gethan.", "tokens": ["Weil", "dei\u00b7ne", "Faust", "weit", "mehr", "als", "C\u00e4\u00b7sars", "Arm", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "PIAT", "KOKOM", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du wustest jeden Feind zu zwingen,", "tokens": ["Du", "wus\u00b7test", "je\u00b7den", "Feind", "zu", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ja alles muste Dir, was Du versucht, gelingen.", "tokens": ["Ja", "al\u00b7les", "mus\u00b7te", "Dir", ",", "was", "Du", "ver\u00b7sucht", ",", "ge\u00b7lin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "PIS", "VMFIN", "PPER", "$,", "PWS", "PPER", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.52": {"line.1": {"text": "Dich hat zwar Dein Durchlauchtger Stand,", "tokens": ["Dich", "hat", "zwar", "Dein", "Durch\u00b7laucht\u00b7ger", "Stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Doch mehr die Tapferkeit erhoben.", "tokens": ["Doch", "mehr", "die", "Tap\u00b7fer\u00b7keit", "er\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wem ist Dein Streiten unbekannt?", "tokens": ["Wem", "ist", "Dein", "Strei\u00b7ten", "un\u00b7be\u00b7kannt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer sucht nicht Deinen Muth und Helden-Geist zu loben?", "tokens": ["Wer", "sucht", "nicht", "Dei\u00b7nen", "Muth", "und", "Hel\u00b7den\u00b7Geist", "zu", "lo\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "PPOSAT", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein Sebel ward vom Blute warm,", "tokens": ["Dein", "Se\u00b7bel", "ward", "vom", "Blu\u00b7te", "warm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn er der Feinde Hal\u00df zerbrochen,", "tokens": ["Wenn", "er", "der", "Fein\u00b7de", "Hal\u00df", "zer\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die sich vor deinem Zorn verkrochen:", "tokens": ["Die", "sich", "vor", "dei\u00b7nem", "Zorn", "ver\u00b7kro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Denn wo du hingeriethst, da tre\u00f1te sich ihr Schwarm:", "tokens": ["Denn", "wo", "du", "hin\u00b7ge\u00b7riethst", ",", "da", "tre\u00f1te", "sich", "ihr", "Schwarm", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PRF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Dein Schwerdt kam stets mit Heyl und Gl\u00fccke,", "tokens": ["Dein", "Schwerdt", "kam", "stets", "mit", "Heyl", "und", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mit Beute, Ehr und Ruhm, mit Blut und Sieg zur\u00fccke.", "tokens": ["Mit", "Beu\u00b7te", ",", "Ehr", "und", "Ruhm", ",", "mit", "Blut", "und", "Sieg", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.53": {"line.1": {"text": "Auch nur das Losungs-Wort zum Streit", "tokens": ["Auch", "nur", "das", "Lo\u00b7sungs\u00b7Wort", "zum", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erweckte bey dem Feind ein Lermen.", "tokens": ["Er\u00b7weck\u00b7te", "bey", "dem", "Feind", "ein", "Ler\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du suchtest Dich bey rauher Zeit", "tokens": ["Du", "such\u00b7test", "Dich", "bey", "rau\u00b7her", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am feurigen Gesch\u00fctz und Bomben zu erw\u00e4rmen.", "tokens": ["Am", "feu\u00b7ri\u00b7gen", "Ge\u00b7sch\u00fctz", "und", "Bom\u00b7ben", "zu", "er\u00b7w\u00e4r\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Strom, der sonst wie Silber war,", "tokens": ["Ein", "Strom", ",", "der", "sonst", "wie", "Sil\u00b7ber", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "KOKOM", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ward oft zu einem rothen Meere.", "tokens": ["Ward", "oft", "zu", "ei\u00b7nem", "ro\u00b7then", "Mee\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wo Du o Held! mit Deinem Heere", "tokens": ["Wo", "Du", "o", "Held", "!", "mit", "Dei\u00b7nem", "Hee\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "FM", "NN", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dem Feind entgege gienst, da wich die ganze Schaar.", "tokens": ["Dem", "Feind", "ent\u00b7ge\u00b7ge", "gienst", ",", "da", "wich", "die", "gan\u00b7ze", "Schaar", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVFIN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "An jedem Ort wo Du gestanden,", "tokens": ["An", "je\u00b7dem", "Ort", "wo", "Du", "ge\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PWAV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ist noch von Deinem Ruhm ein Ehrenmaal vorhanden.", "tokens": ["Ist", "noch", "von", "Dei\u00b7nem", "Ruhm", "ein", "Eh\u00b7ren\u00b7maal", "vor\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPOSAT", "NN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.54": {"line.1": {"text": "Dein Auge war ein schneller Blitz,", "tokens": ["Dein", "Au\u00b7ge", "war", "ein", "schnel\u00b7ler", "Blitz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Arm ein Donnerschlag zu nennen.", "tokens": ["Dein", "Arm", "ein", "Don\u00b7ner\u00b7schlag", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dies mu\u00df noch Achmeths stolzer Sitz,", "tokens": ["Dies", "mu\u00df", "noch", "Ach\u00b7meths", "stol\u00b7zer", "Sitz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das freche Monden-Volk zu seinem Schimpf bekennen.", "tokens": ["Das", "fre\u00b7che", "Mon\u00b7den\u00b7Volk", "zu", "sei\u00b7nem", "Schimpf", "be\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du hast mit Lust, wenn Du gekriegt,", "tokens": ["Du", "hast", "mit", "Lust", ",", "wenn", "Du", "ge\u00b7kriegt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "$,", "KOUS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein tapfres Helden-Blut verspritzet,", "tokens": ["Dein", "tapf\u00b7res", "Hel\u00b7den\u00b7Blut", "ver\u00b7sprit\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und Deinen Purpur-Schwei\u00df verschwitzet,", "tokens": ["Und", "Dei\u00b7nen", "Pur\u00b7pur\u00b7Schwei\u00df", "ver\u00b7schwit\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ward nur der k\u00fchne Feind auf solche Art besiegt.", "tokens": ["Ward", "nur", "der", "k\u00fch\u00b7ne", "Feind", "auf", "sol\u00b7che", "Art", "be\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du wustest Dir zu allen Zeiten", "tokens": ["Du", "wus\u00b7test", "Dir", "zu", "al\u00b7len", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Den Weg zur Sternenburg durch k\u00e4mpfen zu bereiten.", "tokens": ["Den", "Weg", "zur", "Ster\u00b7nen\u00b7burg", "durch", "k\u00e4mp\u00b7fen", "zu", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.55": {"line.1": {"text": "Doch hast Du nie nach Parther Art", "tokens": ["Doch", "hast", "Du", "nie", "nach", "Par\u00b7ther", "Art"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Blut der Deinigen verschwendet.", "tokens": ["Das", "Blut", "der", "Dei\u00b7ni\u00b7gen", "ver\u00b7schwen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du hast Dein Heer wie Dich verwahrt,", "tokens": ["Du", "hast", "Dein", "Heer", "wie", "Dich", "ver\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "KOKOM", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und mancherley Gefahr durch Klugheit abgewendet.", "tokens": ["Und", "man\u00b7cher\u00b7ley", "Ge\u00b7fahr", "durch", "Klug\u00b7heit", "ab\u00b7ge\u00b7wen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Ehrsucht nahm zu keiner Zeit", "tokens": ["Die", "Ehr\u00b7sucht", "nahm", "zu", "kei\u00b7ner", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Herrschaft \u00fcber Dein Gewissen;", "tokens": ["Die", "Herr\u00b7schaft", "\u00fc\u00b7ber", "Dein", "Ge\u00b7wis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dies wird Dein Volk bezeugen m\u00fcssen,", "tokens": ["Dies", "wird", "Dein", "Volk", "be\u00b7zeu\u00b7gen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das Du zum Kampf gef\u00fchrt. O kluge Tapferkeit!", "tokens": ["Das", "Du", "zum", "Kampf", "ge\u00b7f\u00fchrt", ".", "O", "klu\u00b7ge", "Tap\u00b7fer\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPRART", "NN", "VVPP", "$.", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie mancher, der nach Ruhm getrachtet,", "tokens": ["Wie", "man\u00b7cher", ",", "der", "nach", "Ruhm", "ge\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "$,", "PRELS", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Hat \u00f6fters ohne Noth viel tausend Mann geschlachtet.", "tokens": ["Hat", "\u00f6f\u00b7ters", "oh\u00b7ne", "Noth", "viel", "tau\u00b7send", "Mann", "ge\u00b7schlach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "ADV", "CARD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.56": {"line.1": {"text": "Ein k\u00fchner Streiter weicht nicht ehr,", "tokens": ["Ein", "k\u00fch\u00b7ner", "Strei\u00b7ter", "weicht", "nicht", "ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis seine tapfre Faust gesieget,", "tokens": ["Bis", "sei\u00b7ne", "tapf\u00b7re", "Faust", "ge\u00b7sie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und, wenn er nicht so gl\u00fccklich w\u00e4r,", "tokens": ["Und", ",", "wenn", "er", "nicht", "so", "gl\u00fcck\u00b7lich", "w\u00e4r", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So k\u00e4mpft er bis er stirbt und auf der Wahlst\u00e4tt lieget.", "tokens": ["So", "k\u00e4mpft", "er", "bis", "er", "stirbt", "und", "auf", "der", "Wahl\u00b7st\u00e4tt", "lie\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "PPER", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dies hat an Dir o Held EUGEN!", "tokens": ["Dies", "hat", "an", "Dir", "o", "Held", "Eu\u00b7GEN", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "FM", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Welt erstaunend wahrgenommen;", "tokens": ["Die", "Welt", "er\u00b7stau\u00b7nend", "wahr\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du bist fast nie zur\u00fccke kommen,", "tokens": ["Du", "bist", "fast", "nie", "zu\u00b7r\u00fc\u00b7cke", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Du h\u00e4ttest denn den Fall des Feindes angesehn.", "tokens": ["Du", "h\u00e4t\u00b7test", "denn", "den", "Fall", "des", "Fein\u00b7des", "an\u00b7ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dir m\u00fcste jeder Streich gelingen,", "tokens": ["Dir", "m\u00fcs\u00b7te", "je\u00b7der", "Streich", "ge\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Du kuntest wenigstens den Feind zum Frieden zwingen.", "tokens": ["Du", "kun\u00b7test", "we\u00b7nigs\u00b7tens", "den", "Feind", "zum", "Frie\u00b7den", "zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.57": {"line.1": {"text": "An einem L\u00f6wen findet man", "tokens": ["An", "ei\u00b7nem", "L\u00f6\u00b7wen", "fin\u00b7det", "man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Gro\u00dfmuth \u00e4chtes Meisterst\u00fccke.", "tokens": ["Der", "Gro\u00df\u00b7muth", "\u00e4ch\u00b7tes", "Meis\u00b7ter\u00b7st\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Schaut ihn sein Gegner sterbend an,", "tokens": ["Schaut", "ihn", "sein", "Geg\u00b7ner", "ster\u00b7bend", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So h\u00f6rt die Rache auf; er geht vergn\u00fcgt zur\u00fccke.", "tokens": ["So", "h\u00f6rt", "die", "Ra\u00b7che", "auf", ";", "er", "geht", "ver\u00b7gn\u00fcgt", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durchlauchtger Held! wo hat ein F\u00fcrst", "tokens": ["Durch\u00b7laucht\u00b7ger", "Held", "!", "wo", "hat", "ein", "F\u00fcrst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "PWAV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mehr Gro\u00dfmuth als wie Du gewiesen?", "tokens": ["Mehr", "Gro\u00df\u00b7muth", "als", "wie", "Du", "ge\u00b7wie\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KOUS", "KOKOM", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Herr! lag der Feind zu Deinen F\u00fcssen,", "tokens": ["Herr", "!", "lag", "der", "Feind", "zu", "Dei\u00b7nen", "F\u00fcs\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "So hast Du weiter nicht nach seinem Fall ged\u00fcrst.", "tokens": ["So", "hast", "Du", "wei\u00b7ter", "nicht", "nach", "sei\u00b7nem", "Fall", "ge\u00b7d\u00fcrst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du warst vergn\u00fcgt, wenn er sich beugte,", "tokens": ["Du", "warst", "ver\u00b7gn\u00fcgt", ",", "wenn", "er", "sich", "beug\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und sich vor Deiner Faust und blutgen Sebel neigte.", "tokens": ["Und", "sich", "vor", "Dei\u00b7ner", "Faust", "und", "blut\u00b7gen", "Se\u00b7bel", "neig\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PPOSAT", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.58": {"line.1": {"text": "Des L\u00f6wens br\u00fcllendes Geschrey", "tokens": ["Des", "L\u00f6\u00b7wens", "br\u00fcl\u00b7len\u00b7des", "Ge\u00b7schrey"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Macht, da\u00df ein ganzer Wald ersch\u00fcttert.", "tokens": ["Macht", ",", "da\u00df", "ein", "gan\u00b7zer", "Wald", "er\u00b7sch\u00fct\u00b7tert", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vor Dir o Held! ich rede frey,", "tokens": ["Vor", "Dir", "o", "Held", "!", "ich", "re\u00b7de", "frey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "FM", "NN", "$.", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist fast die halbe Welt erschrocken und erzittert.", "tokens": ["Ist", "fast", "die", "hal\u00b7be", "Welt", "er\u00b7schro\u00b7cken", "und", "er\u00b7zit\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein tapfres Ansehn nur allein;", "tokens": ["Dein", "tapf\u00b7res", "An\u00b7sehn", "nur", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein Heldenm\u00fcthiges Gesichte", "tokens": ["Dein", "Hel\u00b7den\u00b7m\u00fct\u00b7hi\u00b7ges", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.7": {"text": "Schlug oft ein ganzes Heer zu nichte;", "tokens": ["Schlug", "oft", "ein", "gan\u00b7zes", "Heer", "zu", "nich\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "APPR", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dein Name jagte gleich dem Feind ein Schrecken ein.", "tokens": ["Dein", "Na\u00b7me", "jag\u00b7te", "gleich", "dem", "Feind", "ein", "Schre\u00b7cken", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Nachwelt wird dies Zeugni\u00df lesen:", "tokens": ["Die", "Nach\u00b7welt", "wird", "dies", "Zeug\u00b7ni\u00df", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PDS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Du seyst ein Hannibal zu unsrer Zeit gewesen.", "tokens": ["Du", "seyst", "ein", "Han\u00b7ni\u00b7bal", "zu", "uns\u00b7rer", "Zeit", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.59": {"line.1": {"text": "Dort lie\u00df ein F\u00fcrst zu Gibeon", "tokens": ["Dort", "lie\u00df", "ein", "F\u00fcrst", "zu", "Gi\u00b7be\u00b7on"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sonn im Streite stille stehen,", "tokens": ["Die", "Sonn", "im", "Strei\u00b7te", "stil\u00b7le", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und in dem Thale Ajalon", "tokens": ["Und", "in", "dem", "Tha\u00b7le", "A\u00b7jal\u00b7on"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Mond in seinem Lauf nicht weiter abw\u00e4rts gehen", "tokens": ["Den", "Mond", "in", "sei\u00b7nem", "Lauf", "nicht", "wei\u00b7ter", "ab\u00b7w\u00e4rts", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "PTKNEG", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du kontest auch o Held EUGEN!", "tokens": ["Du", "kon\u00b7test", "auch", "o", "Held", "Eu\u00b7GEN", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "FM", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Sonne allzeit Stand gebiethen,", "tokens": ["Der", "Son\u00b7ne", "all\u00b7zeit", "Stand", "ge\u00b7bie\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und ihren schnellen Lauf verh\u00fcten:", "tokens": ["Und", "ih\u00b7ren", "schnel\u00b7len", "Lauf", "ver\u00b7h\u00fc\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Es muste auf Dein Wort das Mond-Licht stille stehn.", "tokens": ["Es", "mus\u00b7te", "auf", "Dein", "Wort", "das", "Mon\u00b7dLicht", "stil\u00b7le", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du warst ein Weltber\u00fchmter Streiter;", "tokens": ["Du", "warst", "ein", "Welt\u00b7be\u00b7r\u00fchm\u00b7ter", "Strei\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Dein Wahlspruch stunde fest; es hie\u00df: Nur immer weiter.", "tokens": ["Dein", "Wahl\u00b7spruch", "stun\u00b7de", "fest", ";", "es", "hie\u00df", ":", "Nur", "im\u00b7mer", "wei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$.", "PPER", "VVFIN", "$.", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.60": {"line.1": {"text": "Du hast bey Deiner grossen Macht,", "tokens": ["Du", "hast", "bey", "Dei\u00b7ner", "gros\u00b7sen", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey Deinem Muth und hohen Wesen", "tokens": ["Bey", "Dei\u00b7nem", "Muth", "und", "ho\u00b7hen", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auch an die Freundlichkeit gedacht", "tokens": ["Auch", "an", "die", "Freund\u00b7lich\u00b7keit", "ge\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und die Gerechtigkeit zur F\u00fchrerin erlesen.", "tokens": ["Und", "die", "Ge\u00b7rech\u00b7tig\u00b7keit", "zur", "F\u00fch\u00b7re\u00b7rin", "er\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja, Deiner Tugend Seltenheit", "tokens": ["Ja", ",", "Dei\u00b7ner", "Tu\u00b7gend", "Sel\u00b7ten\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bewiese sich in Werk und Worten;", "tokens": ["Be\u00b7wie\u00b7se", "sich", "in", "Werk", "und", "Wor\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man f\u00fcrchtete an allen Orten,", "tokens": ["Man", "f\u00fcrch\u00b7te\u00b7te", "an", "al\u00b7len", "Or\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und liebte Dich zugleich mit gr\u00f6ster Z\u00e4rtlichkeit.", "tokens": ["Und", "lieb\u00b7te", "Dich", "zu\u00b7gleich", "mit", "gr\u00f6s\u00b7ter", "Z\u00e4rt\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Kein Mensch ist je mit na\u00dfen Wangen,", "tokens": ["Kein", "Mensch", "ist", "je", "mit", "na\u00b7\u00dfen", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und mit betr\u00fcbtem Geist von Deinem Antlitz gangen.", "tokens": ["Und", "mit", "be\u00b7tr\u00fcb\u00b7tem", "Geist", "von", "Dei\u00b7nem", "Ant\u00b7litz", "gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.61": {"line.1": {"text": "Wo denk ich hin? mein ganzer Flei\u00df", "tokens": ["Wo", "denk", "ich", "hin", "?", "mein", "gan\u00b7zer", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "PTKVZ", "$.", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kan deinen Ruhm doch nicht ergr\u00fcnden.", "tokens": ["Kan", "dei\u00b7nen", "Ruhm", "doch", "nicht", "er\u00b7gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So wenig man den Anfang wei\u00df,", "tokens": ["So", "we\u00b7nig", "man", "den", "An\u00b7fang", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So wenig kan ich auch desselben Ende finden.", "tokens": ["So", "we\u00b7nig", "kan", "ich", "auch", "des\u00b7sel\u00b7ben", "En\u00b7de", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "PPER", "ADV", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Sonne w\u00fcrde noch viel ehr", "tokens": ["Die", "Son\u00b7ne", "w\u00fcr\u00b7de", "noch", "viel", "ehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch ihre zw\u00f6lf bekannte Zeichen", "tokens": ["Durch", "ih\u00b7re", "zw\u00f6lf", "be\u00b7kann\u00b7te", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Des rundgew\u00f6lbten Himmels streichen,", "tokens": ["Des", "rund\u00b7ge\u00b7w\u00f6lb\u00b7ten", "Him\u00b7mels", "strei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bevor ich Herr! Dein Lob zu schildern f\u00e4hig w\u00e4r.", "tokens": ["Be\u00b7vor", "ich", "Herr", "!", "Dein", "Lob", "zu", "schil\u00b7dern", "f\u00e4\u00b7hig", "w\u00e4r", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "$.", "PPOSAT", "NN", "PTKZU", "VVINF", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich mu\u00df von deinen Werken schweigen,", "tokens": ["Ich", "mu\u00df", "von", "dei\u00b7nen", "Wer\u00b7ken", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und nur mit stillem Geist die tiefste Ehrfurcht zeigen.", "tokens": ["Und", "nur", "mit", "stil\u00b7lem", "Geist", "die", "tiefs\u00b7te", "Ehr\u00b7furcht", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.62": {"line.1": {"text": "Die Weisheit kehrt mit ihrem Schein", "tokens": ["Die", "Weis\u00b7heit", "kehrt", "mit", "ih\u00b7rem", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und mehr als K\u00f6niglichen Gaben", "tokens": ["Und", "mehr", "als", "K\u00f6\u00b7nig\u00b7li\u00b7chen", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "KOKOM", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Viel lieber in Pal\u00e4sten ein,", "tokens": ["Viel", "lie\u00b7ber", "in", "Pa\u00b7l\u00e4s\u00b7ten", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als bey den Niedrigen die bl\u00f6de Sinne haben.", "tokens": ["Als", "bey", "den", "Nied\u00b7ri\u00b7gen", "die", "bl\u00f6\u00b7de", "Sin\u00b7ne", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein F\u00fcrst mu\u00df selbst ein Pharus seyn!", "tokens": ["Ein", "F\u00fcrst", "mu\u00df", "selbst", "ein", "Pha\u00b7rus", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Herzog mu\u00df zu allen Zeiten", "tokens": ["Ein", "Her\u00b7zog", "mu\u00df", "zu", "al\u00b7len", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sein Volk zum Weg der Tugend leiten,", "tokens": ["Sein", "Volk", "zum", "Weg", "der", "Tu\u00b7gend", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sonst wird er nimmermehr, sein Land mit Gl\u00fcck erfreun.", "tokens": ["Sonst", "wird", "er", "nim\u00b7mer\u00b7mehr", ",", "sein", "Land", "mit", "Gl\u00fcck", "er\u00b7freun", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$,", "PPOSAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die, so zugleich das Ruder f\u00fchren.", "tokens": ["Die", ",", "so", "zu\u00b7gleich", "das", "Ru\u00b7der", "f\u00fch\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mu\u00df gleichfals, wie EUGEN, der Schmuck der Weisheit zieren.", "tokens": ["Mu\u00df", "gleich\u00b7fals", ",", "wie", "Eu\u00b7GEN", ",", "der", "Schmuck", "der", "Weis\u00b7heit", "zie\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "$,", "PWAV", "NN", "$,", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.63": {"line.1": {"text": "Der L\u00f6we schl\u00e4ft; doch wacht er auch,", "tokens": ["Der", "L\u00f6\u00b7we", "schl\u00e4ft", ";", "doch", "wacht", "er", "auch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und h\u00e4lt die Augen schlummernd offen.", "tokens": ["Und", "h\u00e4lt", "die", "Au\u00b7gen", "schlum\u00b7mernd", "of\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dies ist gesalbter F\u00fcrsten Brauch;", "tokens": ["Dies", "ist", "ge\u00b7salb\u00b7ter", "F\u00fcrs\u00b7ten", "Brauch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dies kan man ebenfals von ihrer Weisheit hoffen.", "tokens": ["Dies", "kan", "man", "e\u00b7ben\u00b7fals", "von", "ih\u00b7rer", "Weis\u00b7heit", "hof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PIS", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des Reiches Wohlfahrt, Gl\u00fcck und Ruh", "tokens": ["Des", "Rei\u00b7ches", "Wohl\u00b7fahrt", ",", "Gl\u00fcck", "und", "Ruh"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hat oft EUGEN den Schlaf entzogen,", "tokens": ["Hat", "oft", "Eu\u00b7GEN", "den", "Schlaf", "ent\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und Ihn zur Wachsamkeit bewogen,", "tokens": ["Und", "Ihn", "zur", "Wach\u00b7sam\u00b7keit", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sein Auge schlosse sich nicht ohne Sorgen zu.", "tokens": ["Sein", "Au\u00b7ge", "schlos\u00b7se", "sich", "nicht", "oh\u00b7ne", "Sor\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "PTKNEG", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Kein R\u00e4zel war so schwer zu finden,", "tokens": ["Kein", "R\u00e4\u00b7zel", "war", "so", "schwer", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "EuGEN vermocht es doch durch Klugheit zu ergr\u00fcnden.", "tokens": ["Eu\u00b7GEN", "ver\u00b7mocht", "es", "doch", "durch", "Klug\u00b7heit", "zu", "er\u00b7gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.64": {"line.1": {"text": "Ein Staats-Mann \u00fcberlegt mit Flei\u00df", "tokens": ["Ein", "Staats\u00b7Mann", "\u00fc\u00b7ber\u00b7legt", "mit", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was seinem F\u00fcrsten Vortheil bringet;", "tokens": ["Was", "sei\u00b7nem", "F\u00fcrs\u00b7ten", "Vor\u00b7theil", "brin\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er achtet weder M\u00fch noch Schwei\u00df", "tokens": ["Er", "ach\u00b7tet", "we\u00b7der", "M\u00fch", "noch", "Schwei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "NN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wofern ihm nur sein Thun und kluger Rath gelinget.", "tokens": ["Wo\u00b7fern", "ihm", "nur", "sein", "Thun", "und", "klu\u00b7ger", "Rath", "ge\u00b7lin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Weltber\u00fchmte Prinz EUGEN,", "tokens": ["Der", "Welt\u00b7be\u00b7r\u00fchm\u00b7te", "Prinz", "Eu\u00b7GEN", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist diesem eifrig nachgekommen;", "tokens": ["Ist", "die\u00b7sem", "eif\u00b7rig", "nach\u00b7ge\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man hat best\u00e4ndig wahrgenommen,", "tokens": ["Man", "hat", "be\u00b7st\u00e4n\u00b7dig", "wahr\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df Er nur auf den Flor Germaniens gesehn.", "tokens": ["Da\u00df", "Er", "nur", "auf", "den", "Flor", "Ger\u00b7ma\u00b7ni\u00b7ens", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sein Vorsatz war, Sein tapfres Leben,", "tokens": ["Sein", "Vor\u00b7satz", "war", ",", "Sein", "tapf\u00b7res", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Vor unser h\u00f6chstes Haupt, den Kayser aufzugeben.", "tokens": ["Vor", "un\u00b7ser", "h\u00f6chs\u00b7tes", "Haupt", ",", "den", "Kay\u00b7ser", "auf\u00b7zu\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.65": {"line.1": {"text": "Wo hat solch ein gelehrter Held", "tokens": ["Wo", "hat", "solch", "ein", "ge\u00b7lehr\u00b7ter", "Held"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Erden-Krey\u00df, wie Du, geschm\u00fccket?", "tokens": ["Den", "Er\u00b7den\u00b7Krey\u00df", ",", "wie", "Du", ",", "ge\u00b7schm\u00fc\u00b7cket", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn hat wohl je die weite Welt", "tokens": ["Wenn", "hat", "wohl", "je", "die", "wei\u00b7te", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein solch ", "tokens": ["Ein", "solch"], "token_info": ["word", "word"], "pos": ["ART", "PIAT"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Minerva fand Geh\u00f6r bey Dir;", "tokens": ["Mi\u00b7ner\u00b7va", "fand", "Ge\u00b7h\u00f6r", "bey", "Dir", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "APPR", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Wenn andre sie vertrieben hatten,", "tokens": ["Wenn", "and\u00b7re", "sie", "ver\u00b7trie\u00b7ben", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So kam ihr Deine Huld zu statten;", "tokens": ["So", "kam", "ihr", "Dei\u00b7ne", "Huld", "zu", "stat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sie stellte sich Dein Bild als ihren Schutz-Gott f\u00fcr.", "tokens": ["Sie", "stell\u00b7te", "sich", "Dein", "Bild", "als", "ih\u00b7ren", "Schutz\u00b7Gott", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPOSAT", "NN", "KOUS", "PPOSAT", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nun aber mu\u00df sie trostlo\u00df stehen,", "tokens": ["Nun", "a\u00b7ber", "mu\u00df", "sie", "trost\u00b7lo\u00df", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und mit betr\u00fcbtem Geist von Deinem Grabe gehen.", "tokens": ["Und", "mit", "be\u00b7tr\u00fcb\u00b7tem", "Geist", "von", "Dei\u00b7nem", "Gra\u00b7be", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.66": {"line.1": {"text": "EuGEN ist tod! ihr Musen weint!", "tokens": ["Eu\u00b7GEN", "ist", "tod", "!", "ihr", "Mu\u00b7sen", "weint", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NN", "$.", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn eure St\u00fctze ist gefallen.", "tokens": ["Denn", "eu\u00b7re", "St\u00fct\u00b7ze", "ist", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kommt, la\u00dft um euren besten Freund", "tokens": ["Kommt", ",", "la\u00dft", "um", "eu\u00b7ren", "bes\u00b7ten", "Freund"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dort auf dem Helicon ein Trauer-Lied erschallen.", "tokens": ["Dort", "auf", "dem", "He\u00b7li\u00b7con", "ein", "Trau\u00b7e\u00b7rLied", "er\u00b7schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Beklagt den sch\u00f6nen-B\u00fccher-Saal,", "tokens": ["Be\u00b7klagt", "den", "sch\u00f6\u00b7nen\u00b7B\u00fc\u00b7cher\u00b7Saal", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den so viel auserlesne Sachen.", "tokens": ["Den", "so", "viel", "au\u00b7ser\u00b7les\u00b7ne", "Sa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ber\u00fchmt und fast unsch\u00e4tzbar machen.", "tokens": ["Be\u00b7r\u00fchmt", "und", "fast", "un\u00b7sch\u00e4tz\u00b7bar", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bezeugt durch matten Thon des Herzens bange Quaal.", "tokens": ["Be\u00b7zeugt", "durch", "mat\u00b7ten", "Thon", "des", "Her\u00b7zens", "ban\u00b7ge", "Qua\u00b7al", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "ART", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "EuGENENS Tugend hat verdienet,", "tokens": ["Eu\u00b7GEN\u00b7ENS", "Tu\u00b7gend", "hat", "ver\u00b7die\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Da\u00df auch auf eurem Hayn Sein Angedenken gr\u00fcnet.", "tokens": ["Da\u00df", "auch", "auf", "eu\u00b7rem", "Hayn", "Sein", "An\u00b7ge\u00b7den\u00b7ken", "gr\u00fc\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.67": {"line.1": {"text": "Wenn Salomon den Tempel baut,", "tokens": ["Wenn", "Sa\u00b7lo\u00b7mon", "den", "Tem\u00b7pel", "baut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So wird dadurch sein Ruhm erhoben.", "tokens": ["So", "wird", "da\u00b7durch", "sein", "Ruhm", "er\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PAV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wer Unsers Herzogs Tempel schaut,", "tokens": ["Wer", "Un\u00b7sers", "Her\u00b7zogs", "Tem\u00b7pel", "schaut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mu\u00df diesen grossen Prinz und Seine Anstalt loben.", "tokens": ["Mu\u00df", "die\u00b7sen", "gros\u00b7sen", "Prinz", "und", "Sei\u00b7ne", "An\u00b7stalt", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDAT", "ADJA", "NN", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Garten, den Semiramis", "tokens": ["Der", "Gar\u00b7ten", ",", "den", "Se\u00b7mi\u00b7ra\u00b7mis"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Welt zum Wunder hinterlassen,", "tokens": ["Der", "Welt", "zum", "Wun\u00b7der", "hin\u00b7ter\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Kan kaum so viele Sch\u00f6nheit fassen,", "tokens": ["Kan", "kaum", "so", "vie\u00b7le", "Sch\u00f6n\u00b7heit", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Als uns der kluge Held an Seinem Garten wie\u00df.", "tokens": ["Als", "uns", "der", "klu\u00b7ge", "Held", "an", "Sei\u00b7nem", "Gar\u00b7ten", "wie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "EuGEN lie\u00df wie August in Pohlen,", "tokens": ["Eu\u00b7GEN", "lie\u00df", "wie", "Au\u00b7gust", "in", "Poh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KOKOM", "NN", "APPR", "NE", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.10": {"text": "Die Wunder der Natur von weiten Orten hohlen.", "tokens": ["Die", "Wun\u00b7der", "der", "Na\u00b7tur", "von", "wei\u00b7ten", "Or\u00b7ten", "hoh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.68": {"line.1": {"text": "Der Grosse Kayser kan zwar nun", "tokens": ["Der", "Gros\u00b7se", "Kay\u00b7ser", "kan", "zwar", "nun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VMFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Janus offnen Tempel schliessen;", "tokens": ["Des", "Ja\u00b7nus", "off\u00b7nen", "Tem\u00b7pel", "schlies\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allein, Er kans nicht freudig thun;", "tokens": ["Al\u00b7lein", ",", "Er", "kans", "nicht", "freu\u00b7dig", "thun", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Augen werden Ihm darbey beweglich fliessen.", "tokens": ["Die", "Au\u00b7gen", "wer\u00b7den", "Ihm", "dar\u00b7bey", "be\u00b7weg\u00b7lich", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PAV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie k\u00f6mmts? ", "tokens": ["Wie", "k\u00f6mmts", "?"], "token_info": ["word", "word", "punct"], "pos": ["PWAV", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Sein gr\u00f6\u00dfter Staats-Minister fliehet,", "tokens": ["Sein", "gr\u00f6\u00df\u00b7ter", "Staats\u00b7Mi\u00b7nis\u00b7ter", "flie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Indem er sich der Welt entziehet.", "tokens": ["In\u00b7dem", "er", "sich", "der", "Welt", "ent\u00b7zie\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dergleichen harter Fall mu\u00df Ihm zu Herzen gehn.", "tokens": ["Derg\u00b7lei\u00b7chen", "har\u00b7ter", "Fall", "mu\u00df", "Ihm", "zu", "Her\u00b7zen", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJA", "NN", "VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Hier sieht man, wie das Gl\u00fccke spielet,", "tokens": ["Hier", "sieht", "man", ",", "wie", "das", "Gl\u00fc\u00b7cke", "spie\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wie oft es bey der Lust zugleich auf Unlust zielet.", "tokens": ["Wie", "oft", "es", "bey", "der", "Lust", "zu\u00b7gleich", "auf", "Un\u00b7lust", "zie\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.69": {"line.1": {"text": "Das Alterthum war sonst bem\u00fcht,", "tokens": ["Das", "Al\u00b7ter\u00b7thum", "war", "sonst", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Colossen in die H\u00f6h zu bauen.", "tokens": ["Co\u00b7los\u00b7sen", "in", "die", "H\u00f6h", "zu", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O Tapfrer Prinz EUGEN! man sieht", "tokens": ["O", "Tapf\u00b7rer", "Prinz", "Eu\u00b7GEN", "!", "man", "sieht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADJA", "NN", "NE", "$.", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dein Bildni\u00df nicht in Stein; nein in was sch\u00f6nres hauen.", "tokens": ["Dein", "Bild\u00b7ni\u00df", "nicht", "in", "Stein", ";", "nein", "in", "was", "sch\u00f6n\u00b7res", "hau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "APPR", "NN", "$.", "PTKANT", "APPR", "PRELS", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Herzen werden Dir zur Gruft,", "tokens": ["Die", "Her\u00b7zen", "wer\u00b7den", "Dir", "zur", "Gruft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In diese wird man Dich versenken:", "tokens": ["In", "die\u00b7se", "wird", "man", "Dich", "ver\u00b7sen\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "PIS", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hier ruht Dein ewig Angedenken:", "tokens": ["Hier", "ruht", "Dein", "e\u00b7wig", "An\u00b7ge\u00b7den\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dies Grabmaal trotzt der Zeit, dem Feuer und der Lust.", "tokens": ["Dies", "Grab\u00b7maal", "trotzt", "der", "Zeit", ",", "dem", "Feu\u00b7er", "und", "der", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was sucht ihr Lampen anzuz\u00fcnden?", "tokens": ["Was", "sucht", "ihr", "Lam\u00b7pen", "an\u00b7zu\u00b7z\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ihr werdet Glanz genug in Seinem Namen finden.", "tokens": ["Ihr", "wer\u00b7det", "Glanz", "ge\u00b7nug", "in", "Sei\u00b7nem", "Na\u00b7men", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.70": {"line.1": {"text": "Herr! w\u00e4r Dein Tod in vorger Zeit", "tokens": ["Herr", "!", "w\u00e4r", "Dein", "Tod", "in", "vor\u00b7ger", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "VAFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und in dem Heydenthum geschehen,", "tokens": ["Und", "in", "dem", "Hey\u00b7den\u00b7thum", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wir w\u00fcrden auch mit Traurigkeit,", "tokens": ["Wir", "w\u00fcr\u00b7den", "auch", "mit", "Trau\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor jener tiefen Gruft nach Art des Orpheus stehen.", "tokens": ["Vor", "je\u00b7ner", "tie\u00b7fen", "Gruft", "nach", "Art", "des", "Or\u00b7pheus", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "APPR", "NN", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir w\u00fcrden wahrlich nicht mit Flehn", "tokens": ["Wir", "w\u00fcr\u00b7den", "wahr\u00b7lich", "nicht", "mit", "Flehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Klage-Liedern m\u00fcde werden,", "tokens": ["Und", "Kla\u00b7ge\u00b7Lie\u00b7dern", "m\u00fc\u00b7de", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bis wir Dich wieder auf der Erden", "tokens": ["Bis", "wir", "Dich", "wie\u00b7der", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Gleich der Euridice aufs neue k\u00f6nten sehn.", "tokens": ["Gleich", "der", "Eu\u00b7ri\u00b7di\u00b7ce", "aufs", "neu\u00b7e", "k\u00f6n\u00b7ten", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "APPRART", "ADJA", "VMFIN", "VVINF", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Doch nein! umsonst! ist unser Weinen,", "tokens": ["Doch", "nein", "!", "um\u00b7sonst", "!", "ist", "un\u00b7ser", "Wei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$.", "ADV", "$.", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "EuGEN wird nun nicht mehr auf dieser Welt erscheinen.", "tokens": ["Eu\u00b7GEN", "wird", "nun", "nicht", "mehr", "auf", "die\u00b7ser", "Welt", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "PTKNEG", "ADV", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}