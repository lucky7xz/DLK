{"textgrid.poem.54290": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Was ist wohl auf dem Rund? das \u00e4chte Dauer h\u00e4lt,", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was ist wohl auf dem Rund? das \u00e4chte Dauer h\u00e4lt,", "tokens": ["Was", "ist", "wohl", "auf", "dem", "Rund", "?", "das", "\u00e4ch\u00b7te", "Dau\u00b7er", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "APPR", "ART", "NN", "$.", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und nicht durch Unbestand in kurtzer Zeit verf\u00e4llt?", "tokens": ["Und", "nicht", "durch", "Un\u00b7be\u00b7stand", "in", "kurt\u00b7zer", "Zeit", "ver\u00b7f\u00e4llt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was offtermahls zur Welt am Morgen wird gebohren,", "tokens": ["Was", "off\u00b7ter\u00b7mahls", "zur", "Welt", "am", "Mor\u00b7gen", "wird", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPRART", "NN", "APPRART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das geht zur Abends-Zeit schon wiederum verlohren.", "tokens": ["Das", "geht", "zur", "A\u00b7bends\u00b7Zeit", "schon", "wie\u00b7de\u00b7rum", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPRART", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das Gl\u00fcck ist wandelbahr, wie leicht ist es geschehn,", "tokens": ["Das", "Gl\u00fcck", "ist", "wan\u00b7del\u00b7bahr", ",", "wie", "leicht", "ist", "es", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "PWAV", "ADJD", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df sich ein Schoo\u00df-Kind mu\u00df gest\u00fcrtzet wieder sehn;", "tokens": ["Da\u00df", "sich", "ein", "Schoo\u00df\u00b7Kind", "mu\u00df", "ge\u00b7st\u00fcrt\u00b7zet", "wie\u00b7der", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VMFIN", "VVPP", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So hoch es \u00f6ffters den und jenen hiesse steigen,", "tokens": ["So", "hoch", "es", "\u00f6ff\u00b7ters", "den", "und", "je\u00b7nen", "hies\u00b7se", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "ART", "KON", "PDS", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So tief hie\u00df ihn sein Fall wiederum auch neigen.", "tokens": ["So", "tief", "hie\u00df", "ihn", "sein", "Fall", "wie\u00b7de\u00b7rum", "auch", "nei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PPOSAT", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Ein Reicher baue nicht auf Sch\u00e4tze, Gut und Geld", "tokens": ["Ein", "Rei\u00b7cher", "bau\u00b7e", "nicht", "auf", "Sch\u00e4t\u00b7ze", ",", "Gut", "und", "Geld"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "APPR", "NN", "$,", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dieweil der Unbestand auch hier nicht Dauer h\u00e4lt.", "tokens": ["Die\u00b7weil", "der", "Un\u00b7be\u00b7stand", "auch", "hier", "nicht", "Dau\u00b7er", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ADV", "PTKNEG", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie bald kan Cr\u00f6sus nicht, das Wunder unsrer Erden,", "tokens": ["Wie", "bald", "kan", "Cr\u00f6\u00b7sus", "nicht", ",", "das", "Wun\u00b7der", "uns\u00b7rer", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "NE", "PTKNEG", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenn ihn das Gl\u00fcck verl\u00e4st, zum armen Iro werden.", "tokens": ["Wenn", "ihn", "das", "Gl\u00fcck", "ver\u00b7l\u00e4st", ",", "zum", "ar\u00b7men", "I\u00b7ro", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "APPRART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Sch\u00f6nheit dauret nicht, sie welckt den Blumen gleich;", "tokens": ["Die", "Sch\u00f6n\u00b7heit", "dau\u00b7ret", "nicht", ",", "sie", "welckt", "den", "Blu\u00b7men", "gleich", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "$,", "PPER", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was heute Purpur wei\u00dft, sieht morgen tod und bleich.", "tokens": ["Was", "heu\u00b7te", "Pur\u00b7pur", "wei\u00dft", ",", "sieht", "mor\u00b7gen", "tod", "und", "bleich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "VVFIN", "$,", "VVFIN", "ADV", "NN", "KON", "ADJD", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Der Wechsel und die Zeit wei\u00df durch gar leichte Sachen,", "tokens": ["Der", "Wech\u00b7sel", "und", "die", "Zeit", "wei\u00df", "durch", "gar", "leich\u00b7te", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Aus einer Helena die Hecubam zu machen.", "tokens": ["Aus", "ei\u00b7ner", "He\u00b7le\u00b7na", "die", "He\u00b7cu\u00b7bam", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die Wei\u00dfheit z\u00e4hmet nicht des Schicksals Tyraney,", "tokens": ["Die", "Wei\u00df\u00b7heit", "z\u00e4h\u00b7met", "nicht", "des", "Schick\u00b7sals", "Ty\u00b7ra\u00b7ney", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Denn auch ein Salomon ist nicht vom Tode frey,", "tokens": ["Denn", "auch", "ein", "Sa\u00b7lo\u00b7mon", "ist", "nicht", "vom", "To\u00b7de", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "PTKNEG", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und die Gelehrsamkeit kan, wenn wir es bedencken,", "tokens": ["Und", "die", "Ge\u00b7lehr\u00b7sam\u00b7keit", "kan", ",", "wenn", "wir", "es", "be\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "$,", "KOUS", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "So hoch auch selbge stieg, uns keinen Frey-Brief schencken.", "tokens": ["So", "hoch", "auch", "selb\u00b7ge", "stieg", ",", "uns", "kei\u00b7nen", "Frey\u00b7Brief", "schen\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ADV", "VVFIN", "$,", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+++-", "measure": "unknown.measure.septa"}, "line.21": {"text": "Und eben dieses flammt den Socrates dort an,", "tokens": ["Und", "e\u00b7ben", "die\u00b7ses", "flammt", "den", "So\u00b7cra\u00b7tes", "dort", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PDS", "VVFIN", "ART", "NE", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Da\u00df selbiger behertzt, und als ein weiser Mann,", "tokens": ["Da\u00df", "sel\u00b7bi\u00b7ger", "be\u00b7hertzt", ",", "und", "als", "ein", "wei\u00b7ser", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "VVPP", "$,", "KON", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Den Becher voller Gifft an Mund und Lippen dr\u00fcckte,", "tokens": ["Den", "Be\u00b7cher", "vol\u00b7ler", "Gifft", "an", "Mund", "und", "Lip\u00b7pen", "dr\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Er sahe, da\u00df er nichts best\u00e4ndiges erblickte.", "tokens": ["Er", "sa\u00b7he", ",", "da\u00df", "er", "nichts", "be\u00b7st\u00e4n\u00b7di\u00b7ges", "er\u00b7blick\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PIS", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was ist wohl auf dem Rund? das \u00e4chte Dauer h\u00e4lt,", "tokens": ["Was", "ist", "wohl", "auf", "dem", "Rund", "?", "das", "\u00e4ch\u00b7te", "Dau\u00b7er", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "APPR", "ART", "NN", "$.", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und nicht durch Unbestand in kurtzer Zeit verf\u00e4llt?", "tokens": ["Und", "nicht", "durch", "Un\u00b7be\u00b7stand", "in", "kurt\u00b7zer", "Zeit", "ver\u00b7f\u00e4llt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was offtermahls zur Welt am Morgen wird gebohren,", "tokens": ["Was", "off\u00b7ter\u00b7mahls", "zur", "Welt", "am", "Mor\u00b7gen", "wird", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPRART", "NN", "APPRART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das geht zur Abends-Zeit schon wiederum verlohren.", "tokens": ["Das", "geht", "zur", "A\u00b7bends\u00b7Zeit", "schon", "wie\u00b7de\u00b7rum", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPRART", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das Gl\u00fcck ist wandelbahr, wie leicht ist es geschehn,", "tokens": ["Das", "Gl\u00fcck", "ist", "wan\u00b7del\u00b7bahr", ",", "wie", "leicht", "ist", "es", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "PWAV", "ADJD", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df sich ein Schoo\u00df-Kind mu\u00df gest\u00fcrtzet wieder sehn;", "tokens": ["Da\u00df", "sich", "ein", "Schoo\u00df\u00b7Kind", "mu\u00df", "ge\u00b7st\u00fcrt\u00b7zet", "wie\u00b7der", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VMFIN", "VVPP", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So hoch es \u00f6ffters den und jenen hiesse steigen,", "tokens": ["So", "hoch", "es", "\u00f6ff\u00b7ters", "den", "und", "je\u00b7nen", "hies\u00b7se", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "ART", "KON", "PDS", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So tief hie\u00df ihn sein Fall wiederum auch neigen.", "tokens": ["So", "tief", "hie\u00df", "ihn", "sein", "Fall", "wie\u00b7de\u00b7rum", "auch", "nei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PPOSAT", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Ein Reicher baue nicht auf Sch\u00e4tze, Gut und Geld", "tokens": ["Ein", "Rei\u00b7cher", "bau\u00b7e", "nicht", "auf", "Sch\u00e4t\u00b7ze", ",", "Gut", "und", "Geld"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "APPR", "NN", "$,", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dieweil der Unbestand auch hier nicht Dauer h\u00e4lt.", "tokens": ["Die\u00b7weil", "der", "Un\u00b7be\u00b7stand", "auch", "hier", "nicht", "Dau\u00b7er", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ADV", "PTKNEG", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie bald kan Cr\u00f6sus nicht, das Wunder unsrer Erden,", "tokens": ["Wie", "bald", "kan", "Cr\u00f6\u00b7sus", "nicht", ",", "das", "Wun\u00b7der", "uns\u00b7rer", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "NE", "PTKNEG", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenn ihn das Gl\u00fcck verl\u00e4st, zum armen Iro werden.", "tokens": ["Wenn", "ihn", "das", "Gl\u00fcck", "ver\u00b7l\u00e4st", ",", "zum", "ar\u00b7men", "I\u00b7ro", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "APPRART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Sch\u00f6nheit dauret nicht, sie welckt den Blumen gleich;", "tokens": ["Die", "Sch\u00f6n\u00b7heit", "dau\u00b7ret", "nicht", ",", "sie", "welckt", "den", "Blu\u00b7men", "gleich", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "$,", "PPER", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was heute Purpur wei\u00dft, sieht morgen tod und bleich.", "tokens": ["Was", "heu\u00b7te", "Pur\u00b7pur", "wei\u00dft", ",", "sieht", "mor\u00b7gen", "tod", "und", "bleich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "VVFIN", "$,", "VVFIN", "ADV", "NN", "KON", "ADJD", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Der Wechsel und die Zeit wei\u00df durch gar leichte Sachen,", "tokens": ["Der", "Wech\u00b7sel", "und", "die", "Zeit", "wei\u00df", "durch", "gar", "leich\u00b7te", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Aus einer Helena die Hecubam zu machen.", "tokens": ["Aus", "ei\u00b7ner", "He\u00b7le\u00b7na", "die", "He\u00b7cu\u00b7bam", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die Wei\u00dfheit z\u00e4hmet nicht des Schicksals Tyraney,", "tokens": ["Die", "Wei\u00df\u00b7heit", "z\u00e4h\u00b7met", "nicht", "des", "Schick\u00b7sals", "Ty\u00b7ra\u00b7ney", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Denn auch ein Salomon ist nicht vom Tode frey,", "tokens": ["Denn", "auch", "ein", "Sa\u00b7lo\u00b7mon", "ist", "nicht", "vom", "To\u00b7de", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "PTKNEG", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und die Gelehrsamkeit kan, wenn wir es bedencken,", "tokens": ["Und", "die", "Ge\u00b7lehr\u00b7sam\u00b7keit", "kan", ",", "wenn", "wir", "es", "be\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "$,", "KOUS", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "So hoch auch selbge stieg, uns keinen Frey-Brief schencken.", "tokens": ["So", "hoch", "auch", "selb\u00b7ge", "stieg", ",", "uns", "kei\u00b7nen", "Frey\u00b7Brief", "schen\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ADV", "VVFIN", "$,", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+++-", "measure": "unknown.measure.septa"}, "line.21": {"text": "Und eben dieses flammt den Socrates dort an,", "tokens": ["Und", "e\u00b7ben", "die\u00b7ses", "flammt", "den", "So\u00b7cra\u00b7tes", "dort", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PDS", "VVFIN", "ART", "NE", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Da\u00df selbiger behertzt, und als ein weiser Mann,", "tokens": ["Da\u00df", "sel\u00b7bi\u00b7ger", "be\u00b7hertzt", ",", "und", "als", "ein", "wei\u00b7ser", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "VVPP", "$,", "KON", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Den Becher voller Gifft an Mund und Lippen dr\u00fcckte,", "tokens": ["Den", "Be\u00b7cher", "vol\u00b7ler", "Gifft", "an", "Mund", "und", "Lip\u00b7pen", "dr\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Er sahe, da\u00df er nichts best\u00e4ndiges erblickte.", "tokens": ["Er", "sa\u00b7he", ",", "da\u00df", "er", "nichts", "be\u00b7st\u00e4n\u00b7di\u00b7ges", "er\u00b7blick\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PIS", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}