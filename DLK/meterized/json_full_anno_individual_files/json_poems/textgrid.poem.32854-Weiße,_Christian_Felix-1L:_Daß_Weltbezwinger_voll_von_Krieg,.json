{"textgrid.poem.32854": {"metadata": {"author": {"name": "Wei\u00dfe, Christian Felix", "birth": "N.A.", "death": "N.A."}, "title": "1L: Da\u00df Weltbezwinger voll von Krieg,", "genre": "verse", "period": "N.A.", "pub_year": 1765, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df Weltbezwinger voll von Krieg,", "tokens": ["Da\u00df", "Welt\u00b7be\u00b7zwin\u00b7ger", "voll", "von", "Krieg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Schlacht, Eroberung und Sieg,", "tokens": ["Durch", "Schlacht", ",", "Er\u00b7o\u00b7be\u00b7rung", "und", "Sieg", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die B\u00fcrger gro\u00df und gl\u00fccklich machen:", "tokens": ["Die", "B\u00fcr\u00b7ger", "gro\u00df", "und", "gl\u00fcck\u00b7lich", "ma\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr:", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch da\u00df die Staaten reizend bl\u00fchn,", "tokens": ["Doch", "da\u00df", "die", "Staa\u00b7ten", "rei\u00b7zend", "bl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo F\u00fcrsten weise B\u00fcrger ziehn,", "tokens": ["Wo", "F\u00fcrs\u00b7ten", "wei\u00b7se", "B\u00fcr\u00b7ger", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und \u00fcber die Gesetze wachen:", "tokens": ["Und", "\u00fc\u00b7ber", "die", "Ge\u00b7set\u00b7ze", "wa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Da\u00df das Verdienst am Hofe steigt,", "tokens": ["Da\u00df", "das", "Ver\u00b7dienst", "am", "Ho\u00b7fe", "steigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Laster vor der Tugend schweigt,", "tokens": ["Das", "Las\u00b7ter", "vor", "der", "Tu\u00b7gend", "schweigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vom Thron besch\u00e4mt die Schmeichler eilen,", "tokens": ["Vom", "Thron", "be\u00b7sch\u00e4mt", "die", "Schmeich\u00b7ler", "ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr:", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df Narrheit, Bosheit, Trug und List", "tokens": ["Da\u00df", "Nar\u00b7rheit", ",", "Bos\u00b7heit", ",", "Trug", "und", "List"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zur Hoheit oft die Leiter ist,", "tokens": ["Zur", "Ho\u00b7heit", "oft", "die", "Lei\u00b7ter", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Laquayen Huld und Gnad ertheilen,", "tokens": ["La\u00b7qua\u00b7yen", "Huld", "und", "Gnad", "er\u00b7thei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Da\u00df jeder Priester heilig lebt,", "tokens": ["Da\u00df", "je\u00b7der", "Pries\u00b7ter", "hei\u00b7lig", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Philosoph nach Weisheit strebt,", "tokens": ["Der", "Phi\u00b7lo\u00b7soph", "nach", "Weis\u00b7heit", "strebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Unschuld vor Gerichte sieget;", "tokens": ["Die", "Un\u00b7schuld", "vor", "Ge\u00b7rich\u00b7te", "sie\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr.", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df oft der Fromme menschlich irrt,", "tokens": ["Da\u00df", "oft", "der", "From\u00b7me", "menschlich", "irrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Der Philosoph zum Thier oft wird,", "tokens": ["Der", "Phi\u00b7lo\u00b7soph", "zum", "Thier", "oft", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das Recht dem Gold oft unterlieget;", "tokens": ["Das", "Recht", "dem", "Gold", "oft", "un\u00b7ter\u00b7lie\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Da\u00df, wer aus goldnen Sch\u00fcsseln speist,", "tokens": ["Da\u00df", ",", "wer", "aus", "gold\u00b7nen", "Sch\u00fcs\u00b7seln", "speist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den laut der P\u00f6bel gl\u00fccklich preist,", "tokens": ["Den", "laut", "der", "P\u00f6\u00b7bel", "gl\u00fcck\u00b7lich", "preist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Lebens wahres Gl\u00fcck empfindet;", "tokens": ["Des", "Le\u00b7bens", "wah\u00b7res", "Gl\u00fcck", "emp\u00b7fin\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr:", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch da\u00df der Mann sein Leben n\u00fctzt,", "tokens": ["Doch", "da\u00df", "der", "Mann", "sein", "Le\u00b7ben", "n\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der nicht mehr w\u00fcnscht, als er besitzt,", "tokens": ["Der", "nicht", "mehr", "w\u00fcnscht", ",", "als", "er", "be\u00b7sitzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sich nicht am Wahn des P\u00f6bels bindet;", "tokens": ["Sich", "nicht", "am", "Wahn", "des", "P\u00f6\u00b7bels", "bin\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Mein Vetter sch\u00fcttet Geld in Hut,", "tokens": ["Mein", "Vet\u00b7ter", "sch\u00fct\u00b7tet", "Geld", "in", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ruft: die\u00df ist das h\u00f6chste Gut!", "tokens": ["Und", "ruft", ":", "die\u00df", "ist", "das", "h\u00f6chs\u00b7te", "Gut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sieh Kind, die\u00df mu\u00dft du dir erwerben;", "tokens": ["Sieh", "Kind", ",", "die\u00df", "mu\u00dft", "du", "dir", "er\u00b7wer\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PDS", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr.", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch wenn man nicht sein Geld vergr\u00e4bt,", "tokens": ["Doch", "wenn", "man", "nicht", "sein", "Geld", "ver\u00b7gr\u00e4bt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Freunden davon freudig lebt,", "tokens": ["Mit", "Freun\u00b7den", "da\u00b7von", "freu\u00b7dig", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PAV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df es denn sch\u00f6n ist, Geld zu erben:", "tokens": ["Da\u00df", "es", "denn", "sch\u00f6n", "ist", ",", "Geld", "zu", "er\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wenn sich Beatrix schminkt und schm\u00fcckt,", "tokens": ["Wenn", "sich", "Be\u00b7at\u00b7rix", "schminkt", "und", "schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lieb\u00e4ugelt, buhlt, die H\u00e4nde dr\u00fcckt,", "tokens": ["Lie\u00b7b\u00e4u\u00b7gelt", ",", "buhlt", ",", "die", "H\u00e4n\u00b7de", "dr\u00fcckt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Da\u00df sie dadurch ein Herz entrissen.", "tokens": ["Da\u00df", "sie", "da\u00b7durch", "ein", "Herz", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr:", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch da\u00df, wenn auch kein Putz sie ziert,", "tokens": ["Doch", "da\u00df", ",", "wenn", "auch", "kein", "Putz", "sie", "ziert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "KOUS", "ADV", "PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die g\u00f6ttliche Selinde r\u00fchrt,", "tokens": ["Die", "g\u00f6tt\u00b7li\u00b7che", "Se\u00b7lin\u00b7de", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und jeder Mund sie w\u00fcnscht zu k\u00fcssen,", "tokens": ["Und", "je\u00b7der", "Mund", "sie", "w\u00fcnscht", "zu", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Da\u00df, um geehrt und reich zu seyn,", "tokens": ["Da\u00df", ",", "um", "ge\u00b7ehrt", "und", "reich", "zu", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUI", "VVPP", "KON", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich mich dem\u00fcthig, kriechend, klein,", "tokens": ["Ich", "mich", "de\u00b7m\u00fct\u00b7hig", ",", "krie\u00b7chend", ",", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "PRF", "ADJD", "$,", "VVPP", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn mich das Gl\u00fccke flieht, geberde;", "tokens": ["Wenn", "mich", "das", "Gl\u00fc\u00b7cke", "flieht", ",", "ge\u00b7ber\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja daran zweifl' ich sehr.", "tokens": ["Ja", "da\u00b7ran", "zweifl'", "ich", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df ich entfernt vom Sklaverey,", "tokens": ["Da\u00df", "ich", "ent\u00b7fernt", "vom", "Skla\u00b7ve\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Freund, Vaterland und M\u00e4dchen treu,", "tokens": ["Freund", ",", "Va\u00b7ter\u00b7land", "und", "M\u00e4d\u00b7chen", "treu", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Frey leben und frey sterben werde:", "tokens": ["Frey", "le\u00b7ben", "und", "frey", "ster\u00b7ben", "wer\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "ADJD", "VVINF", "VAFIN", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Da\u00df Weltbezwinger voll von Krieg,", "tokens": ["Da\u00df", "Welt\u00b7be\u00b7zwin\u00b7ger", "voll", "von", "Krieg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Schlacht, Eroberung und Sieg,", "tokens": ["Durch", "Schlacht", ",", "Er\u00b7o\u00b7be\u00b7rung", "und", "Sieg", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die B\u00fcrger gro\u00df und gl\u00fccklich machen:", "tokens": ["Die", "B\u00fcr\u00b7ger", "gro\u00df", "und", "gl\u00fcck\u00b7lich", "ma\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr:", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch da\u00df die Staaten reizend bl\u00fchn,", "tokens": ["Doch", "da\u00df", "die", "Staa\u00b7ten", "rei\u00b7zend", "bl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo F\u00fcrsten weise B\u00fcrger ziehn,", "tokens": ["Wo", "F\u00fcrs\u00b7ten", "wei\u00b7se", "B\u00fcr\u00b7ger", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und \u00fcber die Gesetze wachen:", "tokens": ["Und", "\u00fc\u00b7ber", "die", "Ge\u00b7set\u00b7ze", "wa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Da\u00df das Verdienst am Hofe steigt,", "tokens": ["Da\u00df", "das", "Ver\u00b7dienst", "am", "Ho\u00b7fe", "steigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Laster vor der Tugend schweigt,", "tokens": ["Das", "Las\u00b7ter", "vor", "der", "Tu\u00b7gend", "schweigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vom Thron besch\u00e4mt die Schmeichler eilen,", "tokens": ["Vom", "Thron", "be\u00b7sch\u00e4mt", "die", "Schmeich\u00b7ler", "ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr:", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df Narrheit, Bosheit, Trug und List", "tokens": ["Da\u00df", "Nar\u00b7rheit", ",", "Bos\u00b7heit", ",", "Trug", "und", "List"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zur Hoheit oft die Leiter ist,", "tokens": ["Zur", "Ho\u00b7heit", "oft", "die", "Lei\u00b7ter", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Laquayen Huld und Gnad ertheilen,", "tokens": ["La\u00b7qua\u00b7yen", "Huld", "und", "Gnad", "er\u00b7thei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Da\u00df jeder Priester heilig lebt,", "tokens": ["Da\u00df", "je\u00b7der", "Pries\u00b7ter", "hei\u00b7lig", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Philosoph nach Weisheit strebt,", "tokens": ["Der", "Phi\u00b7lo\u00b7soph", "nach", "Weis\u00b7heit", "strebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Unschuld vor Gerichte sieget;", "tokens": ["Die", "Un\u00b7schuld", "vor", "Ge\u00b7rich\u00b7te", "sie\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr.", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df oft der Fromme menschlich irrt,", "tokens": ["Da\u00df", "oft", "der", "From\u00b7me", "menschlich", "irrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Der Philosoph zum Thier oft wird,", "tokens": ["Der", "Phi\u00b7lo\u00b7soph", "zum", "Thier", "oft", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das Recht dem Gold oft unterlieget;", "tokens": ["Das", "Recht", "dem", "Gold", "oft", "un\u00b7ter\u00b7lie\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Da\u00df, wer aus goldnen Sch\u00fcsseln speist,", "tokens": ["Da\u00df", ",", "wer", "aus", "gold\u00b7nen", "Sch\u00fcs\u00b7seln", "speist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den laut der P\u00f6bel gl\u00fccklich preist,", "tokens": ["Den", "laut", "der", "P\u00f6\u00b7bel", "gl\u00fcck\u00b7lich", "preist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Lebens wahres Gl\u00fcck empfindet;", "tokens": ["Des", "Le\u00b7bens", "wah\u00b7res", "Gl\u00fcck", "emp\u00b7fin\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr:", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch da\u00df der Mann sein Leben n\u00fctzt,", "tokens": ["Doch", "da\u00df", "der", "Mann", "sein", "Le\u00b7ben", "n\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der nicht mehr w\u00fcnscht, als er besitzt,", "tokens": ["Der", "nicht", "mehr", "w\u00fcnscht", ",", "als", "er", "be\u00b7sitzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sich nicht am Wahn des P\u00f6bels bindet;", "tokens": ["Sich", "nicht", "am", "Wahn", "des", "P\u00f6\u00b7bels", "bin\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Mein Vetter sch\u00fcttet Geld in Hut,", "tokens": ["Mein", "Vet\u00b7ter", "sch\u00fct\u00b7tet", "Geld", "in", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ruft: die\u00df ist das h\u00f6chste Gut!", "tokens": ["Und", "ruft", ":", "die\u00df", "ist", "das", "h\u00f6chs\u00b7te", "Gut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sieh Kind, die\u00df mu\u00dft du dir erwerben;", "tokens": ["Sieh", "Kind", ",", "die\u00df", "mu\u00dft", "du", "dir", "er\u00b7wer\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PDS", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr.", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch wenn man nicht sein Geld vergr\u00e4bt,", "tokens": ["Doch", "wenn", "man", "nicht", "sein", "Geld", "ver\u00b7gr\u00e4bt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Freunden davon freudig lebt,", "tokens": ["Mit", "Freun\u00b7den", "da\u00b7von", "freu\u00b7dig", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PAV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df es denn sch\u00f6n ist, Geld zu erben:", "tokens": ["Da\u00df", "es", "denn", "sch\u00f6n", "ist", ",", "Geld", "zu", "er\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Wenn sich Beatrix schminkt und schm\u00fcckt,", "tokens": ["Wenn", "sich", "Be\u00b7at\u00b7rix", "schminkt", "und", "schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lieb\u00e4ugelt, buhlt, die H\u00e4nde dr\u00fcckt,", "tokens": ["Lie\u00b7b\u00e4u\u00b7gelt", ",", "buhlt", ",", "die", "H\u00e4n\u00b7de", "dr\u00fcckt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Da\u00df sie dadurch ein Herz entrissen.", "tokens": ["Da\u00df", "sie", "da\u00b7durch", "ein", "Herz", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, daran zweifl' ich sehr:", "tokens": ["Ja", ",", "da\u00b7ran", "zweifl'", "ich", "sehr", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch da\u00df, wenn auch kein Putz sie ziert,", "tokens": ["Doch", "da\u00df", ",", "wenn", "auch", "kein", "Putz", "sie", "ziert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "KOUS", "ADV", "PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die g\u00f6ttliche Selinde r\u00fchrt,", "tokens": ["Die", "g\u00f6tt\u00b7li\u00b7che", "Se\u00b7lin\u00b7de", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und jeder Mund sie w\u00fcnscht zu k\u00fcssen,", "tokens": ["Und", "je\u00b7der", "Mund", "sie", "w\u00fcnscht", "zu", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Da\u00df, um geehrt und reich zu seyn,", "tokens": ["Da\u00df", ",", "um", "ge\u00b7ehrt", "und", "reich", "zu", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUI", "VVPP", "KON", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich mich dem\u00fcthig, kriechend, klein,", "tokens": ["Ich", "mich", "de\u00b7m\u00fct\u00b7hig", ",", "krie\u00b7chend", ",", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "PRF", "ADJD", "$,", "VVPP", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn mich das Gl\u00fccke flieht, geberde;", "tokens": ["Wenn", "mich", "das", "Gl\u00fc\u00b7cke", "flieht", ",", "ge\u00b7ber\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja daran zweifl' ich sehr.", "tokens": ["Ja", "da\u00b7ran", "zweifl'", "ich", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df ich entfernt vom Sklaverey,", "tokens": ["Da\u00df", "ich", "ent\u00b7fernt", "vom", "Skla\u00b7ve\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Freund, Vaterland und M\u00e4dchen treu,", "tokens": ["Freund", ",", "Va\u00b7ter\u00b7land", "und", "M\u00e4d\u00b7chen", "treu", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Frey leben und frey sterben werde:", "tokens": ["Frey", "le\u00b7ben", "und", "frey", "ster\u00b7ben", "wer\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "ADJD", "VVINF", "VAFIN", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Nein, daran zweifl' ich nicht mehr.", "tokens": ["Nein", ",", "da\u00b7ran", "zweifl'", "ich", "nicht", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}