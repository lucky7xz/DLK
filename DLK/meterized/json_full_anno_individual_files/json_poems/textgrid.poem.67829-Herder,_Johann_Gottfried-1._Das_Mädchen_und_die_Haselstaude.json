{"textgrid.poem.67829": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "1. Das M\u00e4dchen und die Haselstaude", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es wollt ein M\u00e4dchen Rosenbrechen gehn", "tokens": ["Es", "wollt", "ein", "M\u00e4d\u00b7chen", "Ro\u00b7sen\u00b7bre\u00b7chen", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wohl in die gr\u00fcne Heide.", "tokens": ["Wohl", "in", "die", "gr\u00fc\u00b7ne", "Hei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was fand sie da am Wege stehn?", "tokens": ["Was", "fand", "sie", "da", "am", "We\u00b7ge", "stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Eine Hasel, die war gr\u00fcne.", "tokens": ["Ei\u00b7ne", "Ha\u00b7sel", ",", "die", "war", "gr\u00fc\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "\u00bbguten Tag, guten Tag, liebe Hasel mein,", "tokens": ["\u00bb", "gu\u00b7ten", "Tag", ",", "gu\u00b7ten", "Tag", ",", "lie\u00b7be", "Ha\u00b7sel", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "ADJA", "NN", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Warum bist du so gr\u00fcne?\u00ab", "tokens": ["Wa\u00b7rum", "bist", "du", "so", "gr\u00fc\u00b7ne", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbhab Dank, hab Dank, wackres M\u00e4gdelein,", "tokens": ["\u00bb", "hab", "Dank", ",", "hab", "Dank", ",", "wack\u00b7res", "M\u00e4g\u00b7del\u00b7ein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "$,", "VAFIN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Warum bist du so sch\u00f6ne?\u00ab", "tokens": ["Wa\u00b7rum", "bist", "du", "so", "sch\u00f6\u00b7ne", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "\u00bbwarum da\u00df ich so sch\u00f6ne bin,", "tokens": ["\u00bb", "wa\u00b7rum", "da\u00df", "ich", "so", "sch\u00f6\u00b7ne", "bin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "KOUS", "PPER", "ADV", "ADJA", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das will ich dir wohl sagen:", "tokens": ["Das", "will", "ich", "dir", "wohl", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich e\u00df wei\u00df Brod, trink k\u00fchlen Wein,", "tokens": ["Ich", "e\u00df", "wei\u00df", "Brod", ",", "trink", "k\u00fch\u00b7len", "Wein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVFIN", "NN", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Davon bin ich so sch\u00f6ne.\u00ab", "tokens": ["Da\u00b7von", "bin", "ich", "so", "sch\u00f6\u00b7ne", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u00bbi\u00dft du wei\u00df Brod, trinkst k\u00fchlen Wein,", "tokens": ["\u00bb", "i\u00dft", "du", "wei\u00df", "Brod", ",", "trinkst", "k\u00fch\u00b7len", "Wein", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "VVFIN", "NN", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bist davon so sch\u00f6ne:", "tokens": ["Und", "bist", "da\u00b7von", "so", "sch\u00f6\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "ADV", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So f\u00e4llt alle Morgen k\u00fchler Thau auf mich,", "tokens": ["So", "f\u00e4llt", "al\u00b7le", "Mor\u00b7gen", "k\u00fch\u00b7ler", "Thau", "auf", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Davon bin ich so gr\u00fcne.\u00ab", "tokens": ["Da\u00b7von", "bin", "ich", "so", "gr\u00fc\u00b7ne", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbso f\u00e4llt alle Morgen k\u00fchler Thau auf dich,", "tokens": ["\u00bb", "so", "f\u00e4llt", "al\u00b7le", "Mor\u00b7gen", "k\u00fch\u00b7ler", "Thau", "auf", "dich", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PIAT", "NN", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und bist davon so gr\u00fcne?", "tokens": ["Und", "bist", "da\u00b7von", "so", "gr\u00fc\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "ADV", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn aber ein M\u00e4dchen ihren Kranz verliert,", "tokens": ["Wenn", "a\u00b7ber", "ein", "M\u00e4d\u00b7chen", "ih\u00b7ren", "Kranz", "ver\u00b7liert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Nimmer kriegt sie ihn wieder.\u00ab", "tokens": ["Nim\u00b7mer", "kriegt", "sie", "ihn", "wie\u00b7der", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "$.", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.6": {"line.1": {"text": "\u00bbwenn aber ein M\u00e4dchen ihren Kranz will behalten,", "tokens": ["\u00bb", "wenn", "a\u00b7ber", "ein", "M\u00e4d\u00b7chen", "ih\u00b7ren", "Kranz", "will", "be\u00b7hal\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADV", "ART", "NN", "PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Zu Hause mu\u00df sie bleiben,", "tokens": ["Zu", "Hau\u00b7se", "mu\u00df", "sie", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Darf nicht auf alle Narrent\u00e4nz' gehn;", "tokens": ["Darf", "nicht", "auf", "al\u00b7le", "Nar\u00b7ren\u00b7t\u00e4nz'", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Die Narrent\u00e4nz' mu\u00df sie meiden.\u00ab", "tokens": ["Die", "Nar\u00b7ren\u00b7t\u00e4nz'", "mu\u00df", "sie", "mei\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "\u00bbhab Dank, hab Dank, liebe Hasel mein,", "tokens": ["\u00bb", "hab", "Dank", ",", "hab", "Dank", ",", "lie\u00b7be", "Ha\u00b7sel", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "$,", "VAFIN", "NN", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Da\u00df du mir das gesaget,", "tokens": ["Da\u00df", "du", "mir", "das", "ge\u00b7sa\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PDS", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "H\u00e4tt' mich sonst heut auf'n Narrentanz bereit,", "tokens": ["H\u00e4tt'", "mich", "sonst", "heut", "auf'n", "Nar\u00b7ren\u00b7tanz", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Zu Hause will ich bleiben.\u00ab", "tokens": ["Zu", "Hau\u00b7se", "will", "ich", "blei\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Es wollt ein M\u00e4dchen Rosenbrechen gehn", "tokens": ["Es", "wollt", "ein", "M\u00e4d\u00b7chen", "Ro\u00b7sen\u00b7bre\u00b7chen", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wohl in die gr\u00fcne Heide.", "tokens": ["Wohl", "in", "die", "gr\u00fc\u00b7ne", "Hei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was fand sie da am Wege stehn?", "tokens": ["Was", "fand", "sie", "da", "am", "We\u00b7ge", "stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Eine Hasel, die war gr\u00fcne.", "tokens": ["Ei\u00b7ne", "Ha\u00b7sel", ",", "die", "war", "gr\u00fc\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "\u00bbguten Tag, guten Tag, liebe Hasel mein,", "tokens": ["\u00bb", "gu\u00b7ten", "Tag", ",", "gu\u00b7ten", "Tag", ",", "lie\u00b7be", "Ha\u00b7sel", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "ADJA", "NN", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Warum bist du so gr\u00fcne?\u00ab", "tokens": ["Wa\u00b7rum", "bist", "du", "so", "gr\u00fc\u00b7ne", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbhab Dank, hab Dank, wackres M\u00e4gdelein,", "tokens": ["\u00bb", "hab", "Dank", ",", "hab", "Dank", ",", "wack\u00b7res", "M\u00e4g\u00b7del\u00b7ein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "$,", "VAFIN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Warum bist du so sch\u00f6ne?\u00ab", "tokens": ["Wa\u00b7rum", "bist", "du", "so", "sch\u00f6\u00b7ne", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "\u00bbwarum da\u00df ich so sch\u00f6ne bin,", "tokens": ["\u00bb", "wa\u00b7rum", "da\u00df", "ich", "so", "sch\u00f6\u00b7ne", "bin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "KOUS", "PPER", "ADV", "ADJA", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das will ich dir wohl sagen:", "tokens": ["Das", "will", "ich", "dir", "wohl", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich e\u00df wei\u00df Brod, trink k\u00fchlen Wein,", "tokens": ["Ich", "e\u00df", "wei\u00df", "Brod", ",", "trink", "k\u00fch\u00b7len", "Wein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVFIN", "NN", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Davon bin ich so sch\u00f6ne.\u00ab", "tokens": ["Da\u00b7von", "bin", "ich", "so", "sch\u00f6\u00b7ne", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "\u00bbi\u00dft du wei\u00df Brod, trinkst k\u00fchlen Wein,", "tokens": ["\u00bb", "i\u00dft", "du", "wei\u00df", "Brod", ",", "trinkst", "k\u00fch\u00b7len", "Wein", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "VVFIN", "NN", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bist davon so sch\u00f6ne:", "tokens": ["Und", "bist", "da\u00b7von", "so", "sch\u00f6\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "ADV", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So f\u00e4llt alle Morgen k\u00fchler Thau auf mich,", "tokens": ["So", "f\u00e4llt", "al\u00b7le", "Mor\u00b7gen", "k\u00fch\u00b7ler", "Thau", "auf", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Davon bin ich so gr\u00fcne.\u00ab", "tokens": ["Da\u00b7von", "bin", "ich", "so", "gr\u00fc\u00b7ne", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "\u00bbso f\u00e4llt alle Morgen k\u00fchler Thau auf dich,", "tokens": ["\u00bb", "so", "f\u00e4llt", "al\u00b7le", "Mor\u00b7gen", "k\u00fch\u00b7ler", "Thau", "auf", "dich", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PIAT", "NN", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und bist davon so gr\u00fcne?", "tokens": ["Und", "bist", "da\u00b7von", "so", "gr\u00fc\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "ADV", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn aber ein M\u00e4dchen ihren Kranz verliert,", "tokens": ["Wenn", "a\u00b7ber", "ein", "M\u00e4d\u00b7chen", "ih\u00b7ren", "Kranz", "ver\u00b7liert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Nimmer kriegt sie ihn wieder.\u00ab", "tokens": ["Nim\u00b7mer", "kriegt", "sie", "ihn", "wie\u00b7der", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "$.", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.13": {"line.1": {"text": "\u00bbwenn aber ein M\u00e4dchen ihren Kranz will behalten,", "tokens": ["\u00bb", "wenn", "a\u00b7ber", "ein", "M\u00e4d\u00b7chen", "ih\u00b7ren", "Kranz", "will", "be\u00b7hal\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADV", "ART", "NN", "PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Zu Hause mu\u00df sie bleiben,", "tokens": ["Zu", "Hau\u00b7se", "mu\u00df", "sie", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Darf nicht auf alle Narrent\u00e4nz' gehn;", "tokens": ["Darf", "nicht", "auf", "al\u00b7le", "Nar\u00b7ren\u00b7t\u00e4nz'", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Die Narrent\u00e4nz' mu\u00df sie meiden.\u00ab", "tokens": ["Die", "Nar\u00b7ren\u00b7t\u00e4nz'", "mu\u00df", "sie", "mei\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "\u00bbhab Dank, hab Dank, liebe Hasel mein,", "tokens": ["\u00bb", "hab", "Dank", ",", "hab", "Dank", ",", "lie\u00b7be", "Ha\u00b7sel", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "$,", "VAFIN", "NN", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Da\u00df du mir das gesaget,", "tokens": ["Da\u00df", "du", "mir", "das", "ge\u00b7sa\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PDS", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "H\u00e4tt' mich sonst heut auf'n Narrentanz bereit,", "tokens": ["H\u00e4tt'", "mich", "sonst", "heut", "auf'n", "Nar\u00b7ren\u00b7tanz", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Zu Hause will ich bleiben.\u00ab", "tokens": ["Zu", "Hau\u00b7se", "will", "ich", "blei\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}