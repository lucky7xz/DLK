{"dta.poem.20566": {"metadata": {"author": {"name": "N. N., ", "birth": "N.A.", "death": "N.A."}, "title": "Zweiter Tag der Schlacht von Bautzen,  \n  am  21.  Mai  1813.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1848", "urn": "urn:nbn:de:kobv:b4-25129-1", "language": ["de:0.99"], "booktitle": "[N. N.]: Erinnerungen eines freiwilligen reitenden J\u00e4gers aus den Kriegsjahren 1813\u20131815. Berlin, 1848."}, "poem": {"stanza.1": {"line.1": {"text": "Der Truppen Stellung, des Schlachtfeldes Lage", "tokens": ["Der", "Trup\u00b7pen", "Stel\u00b7lung", ",", "des", "Schlacht\u00b7fel\u00b7des", "La\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "War dieselbe fast, wie am vor\u2019gen Tage. \u2014", "tokens": ["War", "die\u00b7sel\u00b7be", "fast", ",", "wie", "am", "vor'\u00b7gen", "Ta\u00b7ge", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PDAT", "ADV", "$,", "PWAV", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Auf dem linken Fl\u00fcgel blieb stehn als erste Linie ", "tokens": ["Auf", "dem", "lin\u00b7ken", "Fl\u00fc\u00b7gel", "blieb", "stehn", "als", "ers\u00b7te", "Li\u00b7nie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "VVINF", "KOKOM", "ADJA", "NN"], "meter": "--+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "radowitsch,", "tokens": ["ra\u00b7do\u00b7witsch", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+--", "measure": "dactylic.init"}, "line.5": {"text": "Sich ausdehnend von Mehltheuer bis Jenkowitz und Ziesch\u00fctz,", "tokens": ["Sich", "aus\u00b7deh\u00b7nend", "von", "Mehl\u00b7theu\u00b7er", "bis", "Jen\u00b7ko\u00b7witz", "und", "Zie\u00b7sch\u00fctz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVPP", "APPR", "NN", "APPR", "NE", "KON", "NN", "$,"], "meter": "--+--+---+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Auf der \u00e4u\u00dfersten Linken stand ", "tokens": ["Auf", "der", "\u00e4u\u00b7\u00dfers\u00b7ten", "Lin\u00b7ken", "stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Lissanewitsch und Uwaroff. &#8212;", "tokens": ["Lis\u00b7sa\u00b7ne\u00b7witsch", "und", "U\u00b7wa\u00b7roff", ".", "&#8212;"], "token_info": ["word", "word", "word", "punct", "XML_entity"], "pos": ["ADJD", "KON", "NN", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "F\u00fcrst ", "tokens": ["F\u00fcrst"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "stehn,", "tokens": ["stehn", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.10": {"text": "Rechts neben ihm den ", "tokens": ["Rechts", "ne\u00b7ben", "ihm", "den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPER", "ART"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.11": {"text": "Saint Priest folgte nach,", "tokens": ["Saint", "Priest", "folg\u00b7te", "nach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.12": {"text": "Stand von Rischen bis zum Bl\u00f6saer Bach. \u2014", "tokens": ["Stand", "von", "Ri\u00b7schen", "bis", "zum", "Bl\u00f6\u00b7saer", "Bach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "NN", "APPR", "APPRART", "NN", "NE", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.13": {"text": "York stand in der Mitten", "tokens": ["Y\u00b7ork", "stand", "in", "der", "Mit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.14": {"text": "Bei Litten,", "tokens": ["Bei", "Lit\u00b7ten", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "Rechts ", "tokens": ["Rechts"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.16": {"text": "Um zu verhindern Retirade,", "tokens": ["Um", "zu", "ver\u00b7hin\u00b7dern", "Re\u00b7ti\u00b7ra\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PTKZU", "VVINF", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Stand als Reserve ", "tokens": ["Stand", "als", "Re\u00b7ser\u00b7ve"], "token_info": ["word", "word", "word"], "pos": ["NN", "KOUS", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.18": {"text": "Bei einem Ort, der P\u00fcrschwitz hei\u00dft. \u2014", "tokens": ["Bei", "ei\u00b7nem", "Ort", ",", "der", "P\u00fcr\u00b7schwitz", "hei\u00dft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Bl&#252;cher stand wie gestern, links Kl&#252;x, rechts Ziethen,", "tokens": ["Bl", "&#252;", "cher", "stand", "wie", "ge\u00b7stern", ",", "links", "Kl", "&#252;", "x", ",", "rechts", "Ziet\u00b7hen", ","], "token_info": ["word", "XML_entity", "word", "word", "word", "word", "punct", "word", "word", "XML_entity", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "VVFIN", "KOKOM", "ADV", "$,", "ADV", "NE", "$(", "FM.la", "$,", "ADV", "VVFIN", "$,"], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.20": {"text": "Roeder hatte die Reserve zu h&#252;ten.", "tokens": ["Roe\u00b7der", "hat\u00b7te", "die", "Re\u00b7ser\u00b7ve", "zu", "h", "&#252;", "ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "XML_entity", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "APPR", "FM", "FM", "FM", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.21": {"text": "Hinter linkem Fl\u00fcgel hielt ", "tokens": ["Hin\u00b7ter", "lin\u00b7kem", "Fl\u00fc\u00b7gel", "hielt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.22": {"text": "In Bezug auf F\u00fchrung der Cavall\u2019rie. \u2014", "tokens": ["In", "Be\u00b7zug", "auf", "F\u00fch\u00b7rung", "der", "Ca\u00b7vall'\u00b7rie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "ART", "NN", "$.", "$("], "meter": "--+-+--+--", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "Stark besetzt war Dobersch\u00fctz", "tokens": ["Stark", "be\u00b7setzt", "war", "Do\u00b7ber\u00b7sch\u00fctz"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVPP", "VAFIN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.24": {"text": "Und Plieskowitz. \u2014", "tokens": ["Und", "Plies\u00b7ko\u00b7witz", "."], "token_info": ["word", "word", "punct", "punct"], "pos": ["KON", "NE", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.25": {"text": "Von Gleina bis zum Malschwitzer See", "tokens": ["Von", "Glei\u00b7na", "bis", "zum", "Mal\u00b7schwit\u00b7zer", "See"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "APPRART", "NN", "NN"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.26": {"text": "Stand ", "tokens": ["Stand"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.27": {"text": "Seine Avantgarde stand bei Salga", "tokens": ["Sei\u00b7ne", "A\u00b7vant\u00b7gar\u00b7de", "stand", "bei", "Sal\u00b7ga"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "NE"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.28": {"text": "Und dehnte sich aus bis Gottamelda. \u2014", "tokens": ["Und", "dehn\u00b7te", "sich", "aus", "bis", "Got\u00b7ta\u00b7mel\u00b7da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "APPR", "NE", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Von edler Kampflust sah man gl\u00fchn", "tokens": ["Von", "ed\u00b7ler", "Kampf\u00b7lust", "sah", "man", "gl\u00fchn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PIS", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Den Gardenchef, F\u00fcrst ", "tokens": ["Den", "Gar\u00b7den\u00b7chef", ",", "F\u00fcrst"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "Der Feinde Heer", "tokens": ["Der", "Fein\u00b7de", "Heer"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Stand wie gestern. Er,", "tokens": ["Stand", "wie", "ge\u00b7stern", ".", "Er", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "KOKOM", "ADV", "$.", "PPER", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Oudinot drang vor bis Gro\u00df-Kunitz", "tokens": ["Ou\u00b7di\u00b7not", "drang", "vor", "bis", "Gro\u00df\u00b7Ku\u00b7nitz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "APPR", "NE"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Und stand noch bis Binnewitz. \u2014", "tokens": ["Und", "stand", "noch", "bis", "Bin\u00b7ne\u00b7witz", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NE", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Macdonald stand im R&#252;cken von Strehla,", "tokens": ["Mac\u00b7do\u00b7nald", "stand", "im", "R", "&#252;", "cken", "von", "Streh\u00b7la", ","], "token_info": ["word", "word", "word", "word", "XML_entity", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NE", "$(", "NN", "APPR", "NE", "$,"], "meter": "+--+-+-+++", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Marmont im Centrum bei Burka. &#8212;", "tokens": ["Mar\u00b7mont", "im", "Cen\u00b7trum", "bei", "Bur\u00b7ka", ".", "&#8212;"], "token_info": ["word", "word", "word", "word", "word", "punct", "XML_entity"], "pos": ["NE", "APPRART", "NN", "APPR", "NE", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Links ihm zur Seite stand ", "tokens": ["Links", "ihm", "zur", "Sei\u00b7te", "stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "PPER", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Beim Ort, Nieder-Gurkau genannt. \u2014", "tokens": ["Beim", "Ort", ",", "Nie\u00b7der\u00b7Gur\u00b7kau", "ge\u00b7nannt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "$,", "NE", "VVPP", "$.", "$("], "meter": "-++-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Bei und hinter Klix stand ", "tokens": ["Bei", "und", "hin\u00b7ter", "Klix", "stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KON", "APPR", "NE", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Als Reserve die Garden und Reiterei", "tokens": ["Als", "Re\u00b7ser\u00b7ve", "die", "Gar\u00b7den", "und", "Rei\u00b7te\u00b7rei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ART", "NN", "KON", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Von ", "tokens": ["Von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.12": {"text": "Maubourg. &#8212;", "tokens": ["Mau\u00b7bourg", ".", "&#8212;"], "token_info": ["word", "punct", "XML_entity"], "pos": ["NE", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "Wir hatten neunzig, der Feind hundert siebenzig tausend", "tokens": ["Wir", "hat\u00b7ten", "neun\u00b7zig", ",", "der", "Feind", "hun\u00b7dert", "sie\u00b7ben\u00b7zig", "tau\u00b7send"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "CARD", "$,", "ART", "NN", "CARD", "CARD", "CARD"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Mann. &#8212;", "tokens": ["Mann", ".", "&#8212;"], "token_info": ["word", "punct", "XML_entity"], "pos": ["NN", "$.", "$("], "meter": "+", "measure": "single.up"}, "line.15": {"text": "Man kann", "tokens": ["Man", "kann"], "token_info": ["word", "word"], "pos": ["PIS", "VMFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.16": {"text": "Zahl der Todten, Verwundeten, Gefangenen schwer z\u00e4hlen.", "tokens": ["Zahl", "der", "Tod\u00b7ten", ",", "Ver\u00b7wun\u00b7de\u00b7ten", ",", "Ge\u00b7fan\u00b7ge\u00b7nen", "schwer", "z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "NN", "$,", "NN", "ADJD", "VVINF", "$."], "meter": "+-+--+-+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.17": {"text": "Zehntausend Mann sollten, so sagt man, den Welschen", "tokens": ["Zehn\u00b7tau\u00b7send", "Mann", "soll\u00b7ten", ",", "so", "sagt", "man", ",", "den", "Wel\u00b7schen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["CARD", "NN", "VMFIN", "$,", "ADV", "VVFIN", "PIS", "$,", "ART", "NN"], "meter": "-+-+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "fehlen. &#8212;", "tokens": ["feh\u00b7len", ".", "&#8212;"], "token_info": ["word", "punct", "XML_entity"], "pos": ["VVFIN", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.19": {"text": "In aller Fr\u00fch,", "tokens": ["In", "al\u00b7ler", "Fr\u00fch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.20": {"text": "Morgens drei Uhr, stellten die", "tokens": ["Mor\u00b7gens", "drei", "Uhr", ",", "stell\u00b7ten", "die"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "CARD", "NN", "$,", "VVFIN", "ART"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "Heersf\u00fcrsten des Bundes im Schlachtfeld sich ein. \u2014", "tokens": ["Heers\u00b7f\u00fcrs\u00b7ten", "des", "Bun\u00b7des", "im", "Schlacht\u00b7feld", "sich", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ART", "NN", "APPRART", "NN", "PRF", "PTKVZ", "$.", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.22": {"text": "Bei der Morgenr\u00f6the erstem Schein", "tokens": ["Bei", "der", "Mor\u00b7gen\u00b7r\u00f6\u00b7the", "ers\u00b7tem", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.23": {"text": "Sah auch ", "tokens": ["Sah", "auch"], "token_info": ["word", "word"], "pos": ["VVFIN", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.24": {"text": "Quadrat", "tokens": ["Quad\u00b7rat"], "token_info": ["word"], "pos": ["NN"], "meter": "--", "measure": "unknown.measure.zero"}, "line.25": {"text": "Eine Rede halten, wie oft er that. \u2014", "tokens": ["Ei\u00b7ne", "Re\u00b7de", "hal\u00b7ten", ",", "wie", "oft", "er", "that", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "PWAV", "ADV", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.26": {"text": "Bei Jenkowitz sp\u00e4ter, auf der Erde liegend, Er dejeunirte,", "tokens": ["Bei", "Jen\u00b7ko\u00b7witz", "sp\u00e4\u00b7ter", ",", "auf", "der", "Er\u00b7de", "lie\u00b7gend", ",", "Er", "de\u00b7jeun\u00b7ir\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJD", "$,", "APPR", "ART", "NN", "VVPP", "$,", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+--", "measure": "trochaic.octa.plus"}, "line.27": {"text": "W\u00e4hrend eine Granate \u00fcber Jhm parabolirte", "tokens": ["W\u00e4h\u00b7rend", "ei\u00b7ne", "Gra\u00b7na\u00b7te", "\u00fc\u00b7ber", "Jhm", "pa\u00b7ra\u00b7bo\u00b7lir\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "PPER", "VVFIN"], "meter": "+-+-+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.28": {"text": "Und rumpirte. \u2014", "tokens": ["Und", "rum\u00b7pir\u00b7te", "."], "token_info": ["word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.29": {"text": "Dann verweilte Er ganz nah", "tokens": ["Dann", "ver\u00b7weil\u00b7te", "Er", "ganz", "nah"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.30": {"text": "Bei Nieder-Kaina,", "tokens": ["Bei", "Nie\u00b7der\u00b7Kai\u00b7na", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.31": {"text": "Um zu beobachten die Bewegung des ", "tokens": ["Um", "zu", "be\u00b7ob\u00b7ach\u00b7ten", "die", "Be\u00b7we\u00b7gung", "des"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PTKZU", "VVINF", "ART", "NN", "ART"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "Er sprach dabei", "tokens": ["Er", "sprach", "da\u00b7bei"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV"], "meter": "-+-+", "measure": "iambic.di"}, "line.33": {"text": "Mit F\u00fcrst ", "tokens": ["Mit", "F\u00fcrst"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.34": {"text": "Der trug Neufschateller Heerkleidung heut. \u2014", "tokens": ["Der", "trug", "Neuf\u00b7scha\u00b7tel\u00b7ler", "Heer\u00b7klei\u00b7dung", "heut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "ADJA", "NN", "ADV", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.35": {"text": "Die Krieger des Bundes und der Franzosen", "tokens": ["Die", "Krie\u00b7ger", "des", "Bun\u00b7des", "und", "der", "Fran\u00b7zo\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "KON", "ART", "NN"], "meter": "-+--+-++-+-", "measure": "iambic.penta.relaxed"}, "line.36": {"text": "Sahn den ganzen Morgen sich an. \u2014 Es kosen", "tokens": ["Sahn", "den", "gan\u00b7zen", "Mor\u00b7gen", "sich", "an", ".", "Es", "ko\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PRF", "PTKVZ", "$.", "$(", "PPER", "VVINF"], "meter": "+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.37": {"text": "Beide mit einander, indem sie begr\u00fc\u00dfen", "tokens": ["Bei\u00b7de", "mit", "ein\u00b7an\u00b7der", ",", "in\u00b7dem", "sie", "be\u00b7gr\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "APPR", "PRF", "$,", "KOUS", "PPER", "VVINF"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.38": {"text": "Sich mit verschied\u2019nen Kanonensch\u00fcssen. \u2014", "tokens": ["Sich", "mit", "ver\u00b7schie\u00b7d'\u00b7nen", "Ka\u00b7no\u00b7nen\u00b7sch\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.39": {"text": "Nicht auf ", "tokens": ["Nicht", "auf"], "token_info": ["word", "word"], "pos": ["PTKNEG", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.40": {"text": "Sondern der Schlachtordnung \u2014 spielte Gesch\u00fctz. \u2014 Fest z\u00fcgeln", "tokens": ["Son\u00b7dern", "der", "Schlach\u00b7tord\u00b7nung", "spiel\u00b7te", "Ge\u00b7sch\u00fctz", ".", "Fest", "z\u00fc\u00b7geln"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "$(", "VVFIN", "NN", "$.", "$(", "NN", "VVINF"], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.41": {"text": "Sah man das Centrum durch ", "tokens": ["Sah", "man", "das", "Cen\u00b7trum", "durch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ART", "NN", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.42": {"text": "Weil der Angriff zu m\u00f6rderischer Art", "tokens": ["Weil", "der", "An\u00b7griff", "zu", "m\u00f6r\u00b7de\u00b7ri\u00b7scher", "Art"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.43": {"text": "W\u00e4re gewesen,", "tokens": ["W\u00e4\u00b7re", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "VAPP", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.44": {"text": "So lange ", "tokens": ["So", "lan\u00b7ge"], "token_info": ["word", "word"], "pos": ["ADV", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.45": {"text": "Die Umgehung zu vollf\u00fchren, \u2014", "tokens": ["Die", "Um\u00b7ge\u00b7hung", "zu", "voll\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.46": {"text": "Dieselbe nicht schon im Stande war zu effektuiren. \u2014", "tokens": ["Die\u00b7sel\u00b7be", "nicht", "schon", "im", "Stan\u00b7de", "war", "zu", "ef\u00b7fek\u00b7tu\u00b7i\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDAT", "PTKNEG", "ADV", "APPRART", "NN", "VAFIN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.47": {"text": "Saint Priest und Eugen", "tokens": ["Saint", "Priest", "und", "Eu\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "NN", "KON", "NE"], "meter": "-+-+-", "measure": "iambic.di"}, "line.48": {"text": "Griffen sich an auf Daranitz H\u00f6hn.", "tokens": ["Grif\u00b7fen", "sich", "an", "auf", "Da\u00b7ra\u00b7nitz", "H\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "APPR", "NE", "NE", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.49": {"text": "Kart\u00e4tschen flogen. \u2014 Oft mu\u00dfte man wischen", "tokens": ["Kar\u00b7t\u00e4t\u00b7schen", "flo\u00b7gen", ".", "Oft", "mu\u00df\u00b7te", "man", "wi\u00b7schen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "$.", "$(", "ADV", "VMFIN", "PIS", "VVINF"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.50": {"text": "Rein der Kanonen ", "tokens": ["Rein", "der", "Ka\u00b7no\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["NN", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.51": {"text": "Sah man eine Partei nach der andern", "tokens": ["Sah", "man", "ei\u00b7ne", "Par\u00b7tei", "nach", "der", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ART", "NN", "APPR", "ART", "ADJA"], "meter": "+-+-++--+-", "measure": "trochaic.penta.relaxed"}, "line.52": {"text": "Wandern. \u2014", "tokens": ["Wan\u00b7dern", "."], "token_info": ["word", "punct", "punct"], "pos": ["NN", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.53": {"text": "Mit achter Russischer Division wu\u00dfte brav sich zu wehren", "tokens": ["Mit", "ach\u00b7ter", "Rus\u00b7si\u00b7scher", "Di\u00b7vi\u00b7si\u00b7on", "wu\u00df\u00b7te", "brav", "sich", "zu", "weh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN", "VVFIN", "ADJD", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+--+-+--+-", "measure": "iambic.septa.relaxed"}, "line.54": {"text": "Oberst ", "tokens": ["O\u00b7berst"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.55": {"text": "Jm gefahrvollsten Moment", "tokens": ["Jm", "ge\u00b7fahr\u00b7volls\u00b7ten", "Mo\u00b7ment"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.56": {"text": "Sandte Prinz ", "tokens": ["Sand\u00b7te", "Prinz"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.57": {"text": "Er selbst folgte als Convoi", "tokens": ["Er", "selbst", "folg\u00b7te", "als", "Con\u00b7voi"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "KOKOM", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.58": {"text": "Mit der Division ", "tokens": ["Mit", "der", "Di\u00b7vi\u00b7si\u00b7on"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.59": {"text": "Zum Vortheil der Russen entschied sich hier Kampf \u2014", "tokens": ["Zum", "Vor\u00b7theil", "der", "Rus\u00b7sen", "ent\u00b7schied", "sich", "hier", "Kampf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "PRF", "ADV", "NN", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.60": {"text": "Da pl\u00f6tzlich im dichten Pulverdampf", "tokens": ["Da", "pl\u00f6tz\u00b7lich", "im", "dich\u00b7ten", "Pul\u00b7ver\u00b7dampf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPRART", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.61": {"text": "Kam von F\u00fcrst ", "tokens": ["Kam", "von", "F\u00fcrst"], "token_info": ["word", "word", "word"], "pos": ["NE", "APPR", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.62": {"text": "Der brachte ", "tokens": ["Der", "brach\u00b7te"], "token_info": ["word", "word"], "pos": ["PDS", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.63": {"text": "Des Inhalts: er wolle senden einen Theil", "tokens": ["Des", "In\u00b7halts", ":", "er", "wol\u00b7le", "sen\u00b7den", "ei\u00b7nen", "Theil"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "PPER", "VMFIN", "PIS", "ART", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.64": {"text": "Seiner Truppen ihm, dem bedr\u00e4ngten Gef\u00e4hrten zum Heil. \u2014", "tokens": ["Sei\u00b7ner", "Trup\u00b7pen", "ihm", ",", "dem", "be\u00b7dr\u00e4ng\u00b7ten", "Ge\u00b7f\u00e4hr\u00b7ten", "zum", "Heil", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "PPER", "$,", "ART", "ADJA", "NN", "APPRART", "NN", "$.", "$("], "meter": "--+--+-+--+--+", "measure": "anapaest.di.plus"}, "line.65": {"text": "Prinz ", "tokens": ["Prinz"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.66": {"text": "Zwei Regimenter ab, brach auf", "tokens": ["Zwei", "Re\u00b7gi\u00b7men\u00b7ter", "ab", ",", "brach", "auf"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["CARD", "NN", "PTKVZ", "$,", "VVFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Dann mit f\u00fcnf andern in eigner Person. \u2014", "tokens": ["Dann", "mit", "f\u00fcnf", "an\u00b7dern", "in", "eig\u00b7ner", "Per\u00b7son", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "CARD", "ADJA", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.68": {"text": "Unterdessen hatte ", "tokens": ["Un\u00b7ter\u00b7des\u00b7sen", "hat\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.69": {"text": "Anderweitig erhalten Soutien.", "tokens": ["An\u00b7der\u00b7wei\u00b7tig", "er\u00b7hal\u00b7ten", "Sou\u00b7ti\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.70": {"text": "Wiedererk\u00e4mpft ward das Terrain", "tokens": ["Wie\u00b7der\u00b7er\u00b7k\u00e4mpft", "ward", "das", "Ter\u00b7rain"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.71": {"text": "Von Mehltheur. \u2014 Sieger", "tokens": ["Von", "Mehl\u00b7theur", ".", "Sie\u00b7ger"], "token_info": ["word", "word", "punct", "punct", "word"], "pos": ["APPR", "NN", "$.", "$(", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.72": {"text": "Blieben auf diesem Fl\u00fcgel die Russischen Krieger.", "tokens": ["Blie\u00b7ben", "auf", "die\u00b7sem", "Fl\u00fc\u00b7gel", "die", "Rus\u00b7si\u00b7schen", "Krie\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.73": {"text": "Auf dem rechten", "tokens": ["Auf", "dem", "rech\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.74": {"text": "Fl\u00fcgel wich ab hiervon das Fechten. \u2014", "tokens": ["Fl\u00fc\u00b7gel", "wich", "ab", "hier\u00b7von", "das", "Fech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "PAV", "ART", "NN", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.75": {"text": "N\u00e4mlich auf diesem Fl\u00fcgel, hier,", "tokens": ["N\u00e4m\u00b7lich", "auf", "die\u00b7sem", "Fl\u00fc\u00b7gel", ",", "hier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$,", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.76": {"text": "Hatte ", "tokens": ["Hat\u00b7te"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.77": {"text": "Jhm selbst zugeh\u00f6renden Divisionen,", "tokens": ["Jhm", "selbst", "zu\u00b7ge\u00b7h\u00f6\u00b7ren\u00b7den", "Di\u00b7vi\u00b7si\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.78": {"text": "Unter dem heftigsten Feuer der Kanonen,", "tokens": ["Un\u00b7ter", "dem", "hef\u00b7tigs\u00b7ten", "Feu\u00b7er", "der", "Ka\u00b7no\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.79": {"text": "Den Uebergang \u00fcber Spree bei Klix erstritten. \u2014", "tokens": ["Den", "Ue\u00b7ber\u00b7gang", "\u00fc\u00b7ber", "Spree", "bei", "Klix", "er\u00b7strit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "NE", "APPR", "NE", "VVFIN", "$.", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.80": {"text": "Unterw\u00e4rts hatte die Spree \u00fcberschritten", "tokens": ["Un\u00b7ter\u00b7w\u00e4rts", "hat\u00b7te", "die", "Spree", "\u00fc\u00b7bersc\u00b7hrit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NE", "VVFIN"], "meter": "+--+--++-+-", "measure": "dactylic.di.plus"}, "line.81": {"text": "Beim Orte Leichnam: ", "tokens": ["Beim", "Or\u00b7te", "Leich\u00b7nam", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.82": {"text": "Napoleon", "tokens": ["Na\u00b7po\u00b7le\u00b7on"], "token_info": ["word"], "pos": ["NE"], "meter": "-+-+", "measure": "iambic.di"}, "line.83": {"text": "Sandte an ", "tokens": ["Sand\u00b7te", "an"], "token_info": ["word", "word"], "pos": ["VVFIN", "PTKVZ"], "meter": "+-+", "measure": "trochaic.di"}, "line.84": {"text": "Einen Zettel, geschrieben mit Stift von Blei;", "tokens": ["Ei\u00b7nen", "Zet\u00b7tel", ",", "ge\u00b7schrie\u00b7ben", "mit", "Stift", "von", "Blei", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "APPR", "NN", "APPR", "NN", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.85": {"text": "Es hie\u00df drin: ", "tokens": ["Es", "hie\u00df", "drin", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.86": {"text": "Um zehn Uhr, dahin gehe des Kaisers Verlangen. \u2014", "tokens": ["Um", "zehn", "Uhr", ",", "da\u00b7hin", "ge\u00b7he", "des", "Kai\u00b7sers", "Ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "CARD", "NN", "$,", "PAV", "VVFIN", "ART", "NN", "NN", "$.", "$("], "meter": "--+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.87": {"text": "Nun war ", "tokens": ["Nun", "war"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.88": {"text": "Nach der Richtung von Beititz in Bewegung. \u2014", "tokens": ["Nach", "der", "Rich\u00b7tung", "von", "Bei\u00b7titz", "in", "Be\u00b7we\u00b7gung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "APPR", "NN", "$.", "$("], "meter": "+-+--+++-+-", "measure": "trochaic.hexa.relaxed"}, "line.89": {"text": "Barclay setzte dem Angriff entgegen Damm,", "tokens": ["Bar\u00b7clay", "setz\u00b7te", "dem", "An\u00b7griff", "ent\u00b7ge\u00b7gen", "Damm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "APPR", "NE", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.90": {"text": "Dessen ungeachtet nahm ein Beititz Division ", "tokens": ["Des\u00b7sen", "un\u00b7ge\u00b7ach\u00b7tet", "nahm", "ein", "Bei\u00b7titz", "Di\u00b7vi\u00b7si\u00b7on"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPO", "VVFIN", "ART", "NN", "NN"], "meter": "+-+-+-+-+--+-+", "measure": "trochaic.septa.relaxed"}, "line.91": {"text": "Den Verb\u00fcndeten konnte dies bringen gro\u00dfe Gefahr,", "tokens": ["Den", "Ver\u00b7b\u00fcn\u00b7de\u00b7ten", "konn\u00b7te", "dies", "brin\u00b7gen", "gro\u00b7\u00dfe", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PDS", "VVINF", "ADJA", "NN", "$,"], "meter": "+-+--+--+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.92": {"text": "Weil hierdurch war", "tokens": ["Weil", "hier\u00b7durch", "war"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PAV", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.93": {"text": "Die Verbindung zwischen ", "tokens": ["Die", "Ver\u00b7bin\u00b7dung", "zwi\u00b7schen"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.94": {"text": "Durchschnitten.", "tokens": ["Durch\u00b7schnit\u00b7ten", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.95": {"text": "Bl&#252;cher sah sich hierdurch im R&#252;cken bedroht! &#8212;", "tokens": ["Bl", "&#252;", "cher", "sah", "sich", "hier\u00b7durch", "im", "R", "&#252;", "cken", "be\u00b7droht", "!", "&#8212;"], "token_info": ["word", "XML_entity", "word", "word", "word", "word", "word", "word", "XML_entity", "word", "word", "punct", "XML_entity"], "pos": ["NE", "$(", "NE", "VVFIN", "PRF", "PAV", "APPRART", "NE", "$(", "VVINF", "VVFIN", "$.", "$("], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.96": {"text": "Er, ", "tokens": ["Er", ","], "token_info": ["word", "punct"], "pos": ["PPER", "$,"], "meter": "-", "measure": "single.down"}, "line.97": {"text": "Eilte herbei, sp\u00e4ter auch ", "tokens": ["Eil\u00b7te", "her\u00b7bei", ",", "sp\u00e4\u00b7ter", "auch"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$,", "ADJD", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.98": {"text": "Beider H\u00fclfe sich th\u00e4tig erweist.", "tokens": ["Bei\u00b7der", "H\u00fcl\u00b7fe", "sich", "th\u00e4\u00b7tig", "er\u00b7weist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PRF", "ADJD", "VVPP", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.99": {"text": "Major ", "tokens": ["Ma\u00b7jor"], "token_info": ["word"], "pos": ["NE"], "meter": "-+", "measure": "iambic.single"}, "line.100": {"text": "Da\u00df er vom Feind schon die Augen sah.", "tokens": ["Da\u00df", "er", "vom", "Feind", "schon", "die", "Au\u00b7gen", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.101": {"text": "So konnt\u2019 Letzt\u2019rer nicht prorumpiren", "tokens": ["So", "konnt'", "Letzt'\u00b7rer", "nicht", "pro\u00b7rum\u00b7pi\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "PTKNEG", "VVINF"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.102": {"text": "Und sich auf Ebene deployiren. \u2014", "tokens": ["Und", "sich", "auf", "E\u00b7be\u00b7ne", "dep\u00b7lo\u00b7yi\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PRF", "APPR", "NN", "VVINF", "$.", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.103": {"text": "Eine ", "tokens": ["Ei\u00b7ne"], "token_info": ["word"], "pos": ["ART"], "meter": "+-", "measure": "trochaic.single"}, "line.104": {"text": "Kam ebenfalls zur Verst\u00e4rkung. \u2014", "tokens": ["Kam", "e\u00b7ben\u00b7falls", "zur", "Ver\u00b7st\u00e4r\u00b7kung", "."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "ADV", "APPRART", "NN", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.105": {"text": "Einige Zeit sp\u00e4ter", "tokens": ["Ei\u00b7ni\u00b7ge", "Zeit", "sp\u00e4\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "ADJD"], "meter": "+---+-", "measure": "dactylic.init"}, "line.106": {"text": "Folgte Gen\u2019ral ", "tokens": ["Folg\u00b7te", "Gen'\u00b7ral"], "token_info": ["word", "word"], "pos": ["VVFIN", "NN"], "meter": "+---", "measure": "dactylic.init"}, "line.107": {"text": "Der Genannten festem Zusammenbleiben", "tokens": ["Der", "Ge\u00b7nann\u00b7ten", "fes\u00b7tem", "Zu\u00b7sam\u00b7men\u00b7blei\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.108": {"text": "Gelang es ", "tokens": ["Ge\u00b7lang", "es"], "token_info": ["word", "word"], "pos": ["NN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.109": {"text": "Ney,", "tokens": ["Ney", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+", "measure": "single.up"}, "line.110": {"text": "Wie ruhmw\u00fcrdig derselbe gewi\u00df sonst sei,", "tokens": ["Wie", "ruhm\u00b7w\u00fcr\u00b7dig", "der\u00b7sel\u00b7be", "ge\u00b7wi\u00df", "sonst", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PDAT", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.111": {"text": "Beging den militairischen Schnitzer,", "tokens": ["Be\u00b7ging", "den", "mi\u00b7li\u00b7tai\u00b7ri\u00b7schen", "Schnit\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.112": {"text": "Da\u00df er dem ", "tokens": ["Da\u00df", "er", "dem"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ART"], "meter": "+--", "measure": "dactylic.init"}, "line.113": {"text": "Und, zumal als dieser aus Beititz geschlagen,", "tokens": ["Und", ",", "zu\u00b7mal", "als", "die\u00b7ser", "aus", "Bei\u00b7titz", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "KOKOM", "PDS", "APPR", "NN", "VVPP", "$,"], "meter": "----+--+--+-", "measure": "iambic.tri.relaxed"}, "line.114": {"text": "Unterlie\u00df schnell neuen Angriff zu wagen. \u2014", "tokens": ["Un\u00b7ter\u00b7lie\u00df", "schnell", "neu\u00b7en", "An\u00b7griff", "zu", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.115": {"text": "Ney verlor dadurch viertausend Wunde,", "tokens": ["Ney", "ver\u00b7lor", "da\u00b7durch", "vier\u00b7tau\u00b7send", "Wun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PAV", "CARD", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.116": {"text": "Au\u00dferdem eine kostbare Stunde,", "tokens": ["Au\u00b7\u00dfer\u00b7dem", "ei\u00b7ne", "kost\u00b7ba\u00b7re", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.117": {"text": "In der, jetzt darf man\u2019s wohl offen gestehn,", "tokens": ["In", "der", ",", "jetzt", "darf", "man's", "wohl", "of\u00b7fen", "ge\u00b7stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "ADV", "VMFIN", "PIS", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.118": {"text": "Bl&#252;cher's Umwicklung konnt' vor sich gehn. &#8212;", "tokens": ["Bl", "&#252;", "cher's", "Um\u00b7wick\u00b7lung", "konnt'", "vor", "sich", "gehn", ".", "&#8212;"], "token_info": ["word", "XML_entity", "word", "word", "word", "word", "word", "word", "punct", "XML_entity"], "pos": ["NE", "$(", "NE", "NN", "VMFIN", "APPR", "PRF", "VVINF", "$.", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.119": {"text": "Von Buchwald", "tokens": ["Von", "Buch\u00b7wald"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.120": {"text": "Kamen hierauf bald", "tokens": ["Ka\u00b7men", "hier\u00b7auf", "bald"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PAV", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.121": {"text": "Lauriston's Schaaren. &#8212;", "tokens": ["Lau\u00b7ri\u00b7ston's", "Schaa\u00b7ren", ".", "&#8212;"], "token_info": ["word", "word", "punct", "XML_entity"], "pos": ["NE", "NN", "$.", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.122": {"text": "Wie wir auch oben schon erfahren,", "tokens": ["Wie", "wir", "auch", "o\u00b7ben", "schon", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.123": {"text": "Ueberschritt ", "tokens": ["Ue\u00b7ber\u00b7schritt"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.124": {"text": "Er kam", "tokens": ["Er", "kam"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.125": {"text": "Sodann nach Br\u00f6sa. \u2014", "tokens": ["So\u00b7dann", "nach", "Br\u00f6\u00b7sa", "."], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "NE", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.126": {"text": "Br\u00f6sa und Gottesmelda", "tokens": ["Br\u00f6\u00b7sa", "und", "Got\u00b7tes\u00b7mel\u00b7da"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "NE"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.127": {"text": "Mu\u00dfte trotz Feuern von starkem Gesch\u00fctz", "tokens": ["Mu\u00df\u00b7te", "trotz", "Feu\u00b7ern", "von", "star\u00b7kem", "Ge\u00b7sch\u00fctz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "NN", "APPR", "ADJA", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.128": {"text": "Aufgeben ", "tokens": ["Auf\u00b7ge\u00b7ben"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.129": {"text": "Maison eroberte von Klix", "tokens": ["Mai\u00b7son", "er\u00b7o\u00b7ber\u00b7te", "von", "Klix"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.130": {"text": "Aus, zwischen zehn und elf Uhr, Malschwitz,", "tokens": ["Aus", ",", "zwi\u00b7schen", "zehn", "und", "elf", "Uhr", ",", "Mal\u00b7schwitz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "$,", "APPR", "CARD", "KON", "CARD", "NN", "$,", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.131": {"text": "Wandte sich sodann nach Pliskowitz", "tokens": ["Wand\u00b7te", "sich", "so\u00b7dann", "nach", "Plis\u00b7ko\u00b7witz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "APPR", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.132": {"text": "Und nahm es gleichfalls gegen 2 Uhr in Besitz. \u2014", "tokens": ["Und", "nahm", "es", "gleich\u00b7falls", "ge\u00b7gen", "2", "Uhr", "in", "Be\u00b7sitz", "."], "token_info": ["word", "word", "word", "word", "word", "number", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "CARD", "NN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.133": {"text": "In Dobersch\u00fctz", "tokens": ["In", "Do\u00b7ber\u00b7sch\u00fctz"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.134": {"text": "Behauptete sich Major ", "tokens": ["Be\u00b7haup\u00b7te\u00b7te", "sich", "Ma\u00b7jor"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PRF", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.135": {"text": "Mit Tapferkeit, das l\u00e4\u00dft ihm selbst Neid.", "tokens": ["Mit", "Tap\u00b7fer\u00b7keit", ",", "das", "l\u00e4\u00dft", "ihm", "selbst", "Neid", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PDS", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.136": {"text": "Man sah ihn fest und ritterlich stehn,", "tokens": ["Man", "sah", "ihn", "fest", "und", "rit\u00b7ter\u00b7lich", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKVZ", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.137": {"text": "Bis ihm erst Ordre ward, r\u00fcckw\u00e4rts zu gehn.", "tokens": ["Bis", "ihm", "erst", "Ord\u00b7re", "ward", ",", "r\u00fcck\u00b7w\u00e4rts", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "NN", "VAFIN", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.138": {"text": "Durch die Thaten am Vormittag", "tokens": ["Durch", "die", "Tha\u00b7ten", "am", "Vor\u00b7mit\u00b7tag"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.139": {"text": "Hatte ", "tokens": ["Hat\u00b7te"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.140": {"text": "Der vom Centrum ausgehen sollte, vorbereitet. \u2014", "tokens": ["Der", "vom", "Cen\u00b7trum", "aus\u00b7ge\u00b7hen", "soll\u00b7te", ",", "vor\u00b7be\u00b7rei\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "APPRART", "NN", "VVINF", "VMFIN", "$,", "VVPP", "$.", "$("], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.141": {"text": "Marmont und Bertrand schreitet", "tokens": ["Mar\u00b7mont", "und", "Ber\u00b7trand", "schrei\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "VVFIN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.142": {"text": "Vor. ", "tokens": ["Vor", "."], "token_info": ["word", "punct"], "pos": ["APPR", "$."], "meter": "+", "measure": "single.up"}, "line.143": {"text": "Des ", "tokens": ["Des"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.144": {"text": "Der so eben genannte Theil der Armee", "tokens": ["Der", "so", "e\u00b7ben", "ge\u00b7nann\u00b7te", "Theil", "der", "Ar\u00b7mee"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "ADJA", "NN", "ART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.145": {"text": "Geht bei Nieder-Gurkau \u00fcber die Spree.", "tokens": ["Geht", "bei", "Nie\u00b7der\u00b7Gur\u00b7kau", "\u00fc\u00b7ber", "die", "Spree", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "APPR", "ART", "NE", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.146": {"text": "Bl&#252;cher von links, rechts und vorn angegriffen war,", "tokens": ["Bl", "&#252;", "cher", "von", "links", ",", "rechts", "und", "vorn", "an\u00b7ge\u00b7grif\u00b7fen", "war", ","], "token_info": ["word", "XML_entity", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "APPR", "ADV", "$,", "ADV", "KON", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+--++-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.147": {"text": "Selbst seinem R\u00fccken droht Gefahr.", "tokens": ["Selbst", "sei\u00b7nem", "R\u00fc\u00b7cken", "droht", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.148": {"text": "Es schien", "tokens": ["Es", "schien"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.149": {"text": "Als wenn das Feuer seiner Batterien", "tokens": ["Als", "wenn", "das", "Feu\u00b7er", "sei\u00b7ner", "Bat\u00b7te\u00b7ri\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.150": {"text": "Den Feind hielte in Zaum.", "tokens": ["Den", "Feind", "hiel\u00b7te", "in", "Zaum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.151": {"text": "Doch w\u00e4hrte dies dreiviertel Stunden kaum,", "tokens": ["Doch", "w\u00e4hr\u00b7te", "dies", "drei\u00b7vier\u00b7tel", "Stun\u00b7den", "kaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.152": {"text": "Da hatten die Russen, Kampfgenossen", "tokens": ["Da", "hat\u00b7ten", "die", "Rus\u00b7sen", ",", "Kampf\u00b7ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.153": {"text": "Preu\u00dfens, ihr s\u00e4mmtliches Pulver verschossen.", "tokens": ["Preu\u00b7\u00dfens", ",", "ihr", "s\u00e4mmt\u00b7li\u00b7ches", "Pul\u00b7ver", "ver\u00b7schos\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.154": {"text": "Brigade ", "tokens": ["Bri\u00b7ga\u00b7de"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.155": {"text": "Doch auch sie wich der Kraft, die ihr \u00fcberlegen.", "tokens": ["Doch", "auch", "sie", "wich", "der", "Kraft", ",", "die", "ihr", "\u00fc\u00b7berl\u00b7e\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.156": {"text": "Schwer verwund\u2019t ward ", "tokens": ["Schwer", "ver\u00b7wund't", "ward"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "VVPP", "VAFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.157": {"text": "Getroffen ward ", "tokens": ["Ge\u00b7trof\u00b7fen", "ward"], "token_info": ["word", "word"], "pos": ["VVPP", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.158": {"text": "In immer dichtern engeren Kreisen", "tokens": ["In", "im\u00b7mer", "dich\u00b7tern", "en\u00b7ge\u00b7ren", "Krei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADJA", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.159": {"text": "Langen an mit t\u00f6dtendem Eisen", "tokens": ["Lan\u00b7gen", "an", "mit", "t\u00f6d\u00b7ten\u00b7dem", "Ei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "APPR", "ADJA", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.160": {"text": "Napoleon's Massen. &#8212;", "tokens": ["Na\u00b7po\u00b7le\u00b7on's", "Mas\u00b7sen", ".", "&#8212;"], "token_info": ["word", "word", "punct", "XML_entity"], "pos": ["NE", "NN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.161": {"text": "Morand mu\u00df Spree verlassen.", "tokens": ["Mo\u00b7rand", "mu\u00df", "Spree", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "NE", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.162": {"text": "Lauriston kommt drohend herbei von Buchwald,", "tokens": ["Lau\u00b7ris\u00b7ton", "kommt", "dro\u00b7hend", "her\u00b7bei", "von", "Buch\u00b7wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADV", "APPR", "NE", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.163": {"text": "Nach Barsankwitz ", "tokens": ["Nach", "Bar\u00b7sank\u00b7witz"], "token_info": ["word", "word"], "pos": ["APPR", "NE"], "meter": "-+-+", "measure": "iambic.di"}, "line.164": {"text": "Zu fich redet ", "tokens": ["Zu", "fich", "re\u00b7det"], "token_info": ["word", "word", "word"], "pos": ["PTKA", "ADJD", "VVFIN"], "meter": "-+--", "measure": "dactylic.init"}, "line.165": {"text": "Ich mu\u00df die bisher\u2019ge Stellung aufgeben,", "tokens": ["Ich", "mu\u00df", "die", "bis\u00b7her'\u00b7ge", "Stel\u00b7lung", "auf\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+-+-+--", "measure": "iambic.tetra.relaxed"}, "line.166": {"text": "Zur\u00fcck mu\u00df ich gehn, es schmerzt mich uns\u00e4glich.", "tokens": ["Zu\u00b7r\u00fcck", "mu\u00df", "ich", "gehn", ",", "es", "schmerzt", "mich", "un\u00b7s\u00e4g\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.167": {"text": "Zu H\u00fclf\u2019 mir zu eilen, ist, wei\u00df ich, unm\u00f6glich! \u2014", "tokens": ["Zu", "H\u00fcl\u00b7f'", "mir", "zu", "ei\u00b7len", ",", "ist", ",", "wei\u00df", "ich", ",", "un\u00b7m\u00f6g\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["APPR", "NN", "PPER", "PTKZU", "VVFIN", "$,", "VAFIN", "$,", "VVFIN", "PPER", "$,", "ADJD", "$.", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.168": {"text": "Doch ", "tokens": ["Doch"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.169": {"text": "Kommt helfend herbei. Indessen anjetzt", "tokens": ["Kommt", "hel\u00b7fend", "her\u00b7bei", ".", "In\u00b7des\u00b7sen", "an\u00b7jetzt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADJD", "PTKVZ", "$.", "NN", "VVFIN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.170": {"text": "Ist H\u00fclfe zu sp\u00e4t. Er sieht retiriren", "tokens": ["Ist", "H\u00fcl\u00b7fe", "zu", "sp\u00e4t", ".", "Er", "sieht", "re\u00b7ti\u00b7ri\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NN", "PTKA", "ADJD", "$.", "PPER", "VVFIN", "VVINF"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.171": {"text": "Bl&#252;cher, von Kreckwitz H\u00f6h'n Feind kanonieren.", "tokens": ["Bl", "&#252;", "cher", ",", "von", "Kreck\u00b7witz", "H\u00f6h'n", "Feind", "ka\u00b7no\u00b7nie\u00b7ren", "."], "token_info": ["word", "XML_entity", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "$,", "APPR", "NE", "NN", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.172": {"text": "Drei Uhr schlug\u2019s. \u2014 Man kam \u00fcberein,", "tokens": ["Drei", "Uhr", "schlug'", "s.", "Man", "kam", "\u00fc\u00b7be\u00b7re\u00b7in", ","], "token_info": ["word", "word", "word", "abbreviation", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "NE", "$(", "PIS", "VVFIN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.173": {"text": "Da\u00df R\u00fcckzug mu\u00df angetreten sein.", "tokens": ["Da\u00df", "R\u00fcck\u00b7zug", "mu\u00df", "an\u00b7ge\u00b7tre\u00b7ten", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.174": {"text": "Es geschah derselbe mit stoischer Ruh,", "tokens": ["Es", "ge\u00b7schah", "der\u00b7sel\u00b7be", "mit", "sto\u00b7i\u00b7scher", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "APPR", "ADJA", "NN", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.175": {"text": "Der Feind sah bewundernd ganz nah dabei zu.", "tokens": ["Der", "Feind", "sah", "be\u00b7wun\u00b7dernd", "ganz", "nah", "da\u00b7bei", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ADV", "ADJD", "PAV", "PTKVZ", "$."], "meter": "-+--+-+-++-", "measure": "iambic.penta.relaxed"}, "line.176": {"text": "Um den Abmarsch zu decken: Steh\u2019 fest, linker Fl\u00fcgel,", "tokens": ["Um", "den", "Ab\u00b7marsch", "zu", "de\u00b7cken", ":", "Steh'", "fest", ",", "lin\u00b7ker", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "PTKZU", "VVINF", "$.", "NN", "PTKVZ", "$,", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.177": {"text": "Zur R\u00fcckendeckung! \u2014 Verh\u00e4ngt sei der Z\u00fcgel,", "tokens": ["Zur", "R\u00fc\u00b7cken\u00b7de\u00b7ckung", "!", "Ver\u00b7h\u00e4ngt", "sei", "der", "Z\u00fc\u00b7gel", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "$(", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.178": {"text": "Spreng\u2019 vorw\u00e4rts, Du Russische Cavallerie!", "tokens": ["Spreng'", "vor\u00b7w\u00e4rts", ",", "Du", "Rus\u00b7si\u00b7sche", "Ca\u00b7val\u00b7le\u00b7rie", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.179": {"text": "Du s\u00e4mmtliche reitende Artillerie! \u2014", "tokens": ["Du", "s\u00e4mmt\u00b7li\u00b7che", "rei\u00b7ten\u00b7de", "Ar\u00b7til\u00b7le\u00b7rie", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADJA", "ADJA", "NN", "$.", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.180": {"text": "Gen\u2019ral ", "tokens": ["Gen'\u00b7ral"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.181": {"text": "H\u00e4lt ab so, da\u00df nachsetzt mit Schnelligkeit Feind.", "tokens": ["H\u00e4lt", "ab", "so", ",", "da\u00df", "nach\u00b7setzt", "mit", "Schnel\u00b7lig\u00b7keit", "Feind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "ADV", "$,", "KOUS", "ADV", "APPR", "NN", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.182": {"text": "R\u00fcckw\u00e4rts geht ", "tokens": ["R\u00fcck\u00b7w\u00e4rts", "geht"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.183": {"text": "Jhm schlie\u00dft sich an ", "tokens": ["Jhm", "schlie\u00dft", "sich", "an"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR"], "meter": "-+-+", "measure": "iambic.di"}, "line.184": {"text": "Barclay dirigirt sich &#252;ber Groditz.", "tokens": ["Bar\u00b7clay", "di\u00b7ri\u00b7girt", "sich", "&#252;", "ber", "Gro\u00b7ditz", "."], "token_info": ["word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "$(", "NE", "NE", "$."], "meter": "----+--+-", "measure": "iambic.di.relaxed"}, "line.185": {"text": "Dort stellt noch einmal auf H\u00f6h\u2019n ", "tokens": ["Dort", "stellt", "noch", "ein\u00b7mal", "auf", "H\u00f6h'n"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.186": {"text": "Hinderte so, da\u00df nicht etwa im Lauf", "tokens": ["Hin\u00b7der\u00b7te", "so", ",", "da\u00df", "nicht", "et\u00b7wa", "im", "Lauf"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PTKNEG", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.187": {"text": "Fr\u00fcher als er, in Wei\u00dfenberg sei:", "tokens": ["Fr\u00fc\u00b7her", "als", "er", ",", "in", "Wei\u00b7\u00dfen\u00b7berg", "sei", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PPER", "$,", "APPR", "NE", "VAFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.188": {"text": "Ney. &#8212;", "tokens": ["Ney", ".", "&#8212;"], "token_info": ["word", "punct", "XML_entity"], "pos": ["NE", "$.", "$("], "meter": "+", "measure": "single.up"}, "line.189": {"text": "Kleist", "tokens": ["Kleist"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.190": {"text": "F\u00fchrte ", "tokens": ["F\u00fchr\u00b7te"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.191": {"text": "Preu\u00dfens Fahnen weh\u2019n", "tokens": ["Preu\u00b7\u00dfens", "Fah\u00b7nen", "weh'n"], "token_info": ["word", "word", "word"], "pos": ["NE", "NN", "VVINF"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.192": {"text": "Auf W\u00fcrschen\u2019s H\u00f6h\u2019n. \u2014", "tokens": ["Auf", "W\u00fcr\u00b7schen's", "H\u00f6h'", "n."], "token_info": ["word", "word", "word", "abbreviation", "punct"], "pos": ["APPR", "NE", "NN", "NE", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.193": {"text": "Von ", "tokens": ["Von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.194": {"text": "Bis gegen Abend sich ", "tokens": ["Bis", "ge\u00b7gen", "A\u00b7bend", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "APPR", "NN", "PRF"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.195": {"text": "Fest stand Reg\u2019ment ", "tokens": ["Fest", "stand", "Reg'\u00b7ment"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.196": {"text": "Bei Wei\u00dfenberg nahmen die Preu\u00dfen Biwacht.", "tokens": ["Bei", "Wei\u00b7\u00dfen\u00b7berg", "nah\u00b7men", "die", "Preu\u00b7\u00dfen", "Bi\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.197": {"text": "Gefangen war Keiner, auch fehlt\u2019 kein Gesch\u00fctz,", "tokens": ["Ge\u00b7fan\u00b7gen", "war", "Kei\u00b7ner", ",", "auch", "fehlt'", "kein", "Ge\u00b7sch\u00fctz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIS", "$,", "ADV", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.198": {"text": "Gen\u00fcber von W\u00fcrschen nahm ", "tokens": ["Ge\u00b7n\u00fc\u00b7ber", "von", "W\u00fcr\u00b7schen", "nahm"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "VVFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.199": {"text": "Der Russe in Ordnung sich retirirt,", "tokens": ["Der", "Rus\u00b7se", "in", "Ord\u00b7nung", "sich", "re\u00b7ti\u00b7rirt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "PRF", "VVPP", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.200": {"text": "Von ", "tokens": ["Von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.201": {"text": "Standhaft ficht Letzt\u2019rer (Preu\u00df\u2019 zollt ihm Applaus!)", "tokens": ["Stand\u00b7haft", "ficht", "Letzt'\u00b7rer", "(", "Preu\u00df'", "zollt", "ihm", "Ap\u00b7plaus", "!", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "NE", "$(", "NE", "VVFIN", "PPER", "NN", "$.", "$("], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.202": {"text": "Und Hauptcorps aus Engpa\u00df sich wickelt heraus. \u2014", "tokens": ["Und", "Haupt\u00b7corps", "aus", "Eng\u00b7pa\u00df", "sich", "wi\u00b7ckelt", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "APPR", "NN", "PRF", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.203": {"text": "Nach Hochkirch und L\u00f6bau geht vorw\u00e4rts man jetzt,", "tokens": ["Nach", "Hoch\u00b7kirch", "und", "L\u00f6\u00b7bau", "geht", "vor\u00b7w\u00e4rts", "man", "jetzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "ADV", "PIS", "ADV", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.204": {"text": "Saint Priest als Nachhut Steind\u00f6rffel besetzt.", "tokens": ["Saint", "Priest", "als", "Nach\u00b7hut", "Stein\u00b7d\u00f6rf\u00b7fel", "be\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KOUS", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.205": {"text": "Zu Mengelsdorff ruht ", "tokens": ["Zu", "Men\u00b7gels\u00b7dorff", "ruht"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NE", "VVFIN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.206": {"text": "Friedrich Wilhelm zu Reichenbach sorgend noch", "tokens": ["Fried\u00b7rich", "Wil\u00b7helm", "zu", "Rei\u00b7chen\u00b7bach", "sor\u00b7gend", "noch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "APPR", "NN", "ADJD", "ADV"], "meter": "-----+-+--+", "measure": "iambic.tri.chol"}, "line.207": {"text": "wacht.", "tokens": ["wacht", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.208": {"text": "Zu Purschwitz mit Garden da blieb ", "tokens": ["Zu", "Pur\u00b7schwitz", "mit", "Gar\u00b7den", "da", "blieb"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "NN", "ADV", "VVFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.209": {"text": "Vorm Schlafengeh\u2019n rief er: Es ist doch sehr hart,", "tokens": ["Vorm", "Schla\u00b7fen\u00b7geh'n", "rief", "er", ":", "Es", "ist", "doch", "sehr", "hart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.210": {"text": "Nicht Erfolg, nicht Gefang\u2019ner durch Metzelei heut!", "tokens": ["Nicht", "Er\u00b7folg", ",", "nicht", "Ge\u00b7fang'\u00b7ner", "durch", "Met\u00b7ze\u00b7lei", "heut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "$,", "PTKNEG", "NN", "APPR", "NN", "ADV", "$."], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.211": {"text": "Keinen Nagel wollen mir lassen die Leut\u2019!", "tokens": ["Kei\u00b7nen", "Na\u00b7gel", "wol\u00b7len", "mir", "las\u00b7sen", "die", "Leut'", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}}}}}