{"dta.poem.21838": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "ViI.  \n  Barbillchen/ die Zukker-dokke.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.85", "af:0.14"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Du s\u00fc\u00dfbeliebtes Honig-kind/", "tokens": ["Du", "s\u00fc\u00df\u00b7be\u00b7lieb\u00b7tes", "Ho\u00b7nig\u00b7kind", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Barbillchen/ Labn\u00fc\u00df meiner Seelen\u2019/", "tokens": ["Bar\u00b7bill\u00b7chen", "/", "Lab\u00b7n\u00fc\u00df", "mei\u00b7ner", "See\u00b7len'", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der Indiens s\u00fcsse Zukker-h\u00f6len", "tokens": ["der", "In\u00b7di\u00b7ens", "s\u00fcs\u00b7se", "Zuk\u00b7ker\u00b7h\u00f6len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "an Anmuht nicht zugleichen sind.", "tokens": ["an", "An\u00b7muht", "nicht", "zu\u00b7glei\u00b7chen", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich wil es/ da\u00df es alle wissen/", "tokens": ["Ich", "wil", "es", "/", "da\u00df", "es", "al\u00b7le", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "$(", "KOUS", "PPER", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "warum ich dich so offt mu\u00df k\u00fcssen.", "tokens": ["wa\u00b7rum", "ich", "dich", "so", "offt", "mu\u00df", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Zukker-trozz/ der Nektar-Wein/", "tokens": ["Der", "Zuk\u00b7ker\u00b7trozz", "/", "der", "Nek\u00b7ta\u00b7rWein", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der in den g\u00f6ldnen Demant-schaalen", "tokens": ["der", "in", "den", "g\u00f6ld\u00b7nen", "De\u00b7mant\u00b7schaa\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "macht/ da\u00df sie ewig trunken sein/", "tokens": ["macht", "/", "da\u00df", "sie", "e\u00b7wig", "trun\u00b7ken", "sein", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOUS", "PPER", "ADJD", "ADJD", "VAINF", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "weil de\u00df Geschmakks/ des Zukker-s\u00fcssen", "tokens": ["weil", "de\u00df", "Ge\u00b7schmakks", "/", "des", "Zuk\u00b7ker\u00b7s\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ART", "NN", "$(", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dein unverglichner Labsal-Mund", "tokens": ["Dein", "un\u00b7ver\u00b7glich\u00b7ner", "Lab\u00b7sa\u00b7lMund"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ist solch\u2019 ein Nektar meinem Herzen/", "tokens": ["ist", "solch'", "ein", "Nek\u00b7tar", "mei\u00b7nem", "Her\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "f\u00fcr meiner Liebe Wermuht Schmerzen.", "tokens": ["f\u00fcr", "mei\u00b7ner", "Lie\u00b7be", "Wer\u00b7muht", "Schmer\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was au\u00df Hymettens bunten Grund\u2019", "tokens": ["Was", "au\u00df", "Hy\u00b7met\u00b7tens", "bun\u00b7ten", "Grund'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "NE", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "am Morgen die bem\u00fchte Biene", "tokens": ["am", "Mor\u00b7gen", "die", "be\u00b7m\u00fch\u00b7te", "Bie\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "S\u00fc\u00df ist der g\u00f6ldnen Haare Band/", "tokens": ["S\u00fc\u00df", "ist", "der", "g\u00f6ld\u00b7nen", "Haa\u00b7re", "Band", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Lippen-tau/ dem Zukker-reichen", "tokens": ["Dem", "Lip\u00b7pen\u00b7tau", "/", "dem", "Zuk\u00b7ker\u00b7rei\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NE", "$(", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mu\u00df s\u00fcsser Alakant auch weichen.", "tokens": ["mu\u00df", "s\u00fcs\u00b7ser", "A\u00b7la\u00b7kant", "auch", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Dein Atem s\u00fcsser/ denn Kaneel/", "tokens": ["Dein", "A\u00b7tem", "s\u00fcs\u00b7ser", "/", "denn", "Ka\u00b7ne\u00b7el", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "$(", "KON", "NN", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "S\u00fc\u00df deine Rede/ s\u00fc\u00df dein Lachen/", "tokens": ["S\u00fc\u00df", "dei\u00b7ne", "Re\u00b7de", "/", "s\u00fc\u00df", "dein", "La\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$(", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "dein Schlaffen/ s\u00fcsser/ ach! dein wachen.", "tokens": ["dein", "Schlaf\u00b7fen", "/", "s\u00fcs\u00b7ser", "/", "ach", "!", "dein", "wa\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "ADJD", "$(", "XY", "$.", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "S\u00fc\u00df deine Kleider/ s\u00fc\u00df dein Rokk", "tokens": ["S\u00fc\u00df", "dei\u00b7ne", "Klei\u00b7der", "/", "s\u00fc\u00df", "dein", "Rokk"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "$(", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "das Fuppchen drein ist s\u00fc\u00df darneben/", "tokens": ["das", "Fuppc\u00b7hen", "drein", "ist", "s\u00fc\u00df", "dar\u00b7ne\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADJD", "PAV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "du weist/ was du mir drau\u00df gegeben.", "tokens": ["du", "weist", "/", "was", "du", "mir", "drau\u00df", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWS", "PPER", "PRF", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Barillchen/ s\u00fcsse Zukker-dokk\u2019", "tokens": ["Ba\u00b7rill\u00b7chen", "/", "s\u00fcs\u00b7se", "Zuk\u00b7ker\u00b7dok\u00b7k'"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$(", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Ich schmekke d\u00fcnkt mich/ noch die Gaben/", "tokens": ["Ich", "schmek\u00b7ke", "d\u00fcnkt", "mich", "/", "noch", "die", "Ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVFIN", "PPER", "$(", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "die auch die Todten k\u00f6nnen laben.", "tokens": ["die", "auch", "die", "Tod\u00b7ten", "k\u00f6n\u00b7nen", "la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Das s\u00fcsseste/ so an dir ist/", "tokens": ["Das", "s\u00fcs\u00b7ses\u00b7te", "/", "so", "an", "dir", "ist", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "ADV", "APPR", "PPER", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mu\u00df ich/ ungerne zwar/ verschweigen/", "tokens": ["mu\u00df", "ich", "/", "un\u00b7ger\u00b7ne", "zwar", "/", "ver\u00b7schwei\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "$(", "ADV", "ADV", "$(", "VVINF", "$("], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "doch kan es \u00fcber alles steigen/", "tokens": ["doch", "kan", "es", "\u00fc\u00b7ber", "al\u00b7les", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "was je die Sterblichen vers\u00fc\u00dft.", "tokens": ["was", "je", "die", "Sterb\u00b7li\u00b7chen", "ver\u00b7s\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die S\u00fcsse/ so es von sich giebet", "tokens": ["Die", "S\u00fcs\u00b7se", "/", "so", "es", "von", "sich", "gie\u00b7bet"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ADV", "PPER", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "macht Leib und Geist zugleich verliebet.", "tokens": ["macht", "Leib", "und", "Geist", "zu\u00b7gleich", "ver\u00b7lie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Man sagt wol/ da\u00df was s\u00fcssers nicht", "tokens": ["Man", "sagt", "wol", "/", "da\u00df", "was", "s\u00fcs\u00b7sers", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "$(", "KOUS", "PIS", "ADV", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "das kan ich leicht daher entgr\u00fcnden:", "tokens": ["das", "kan", "ich", "leicht", "da\u00b7her", "ent\u00b7gr\u00fcn\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADJD", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "als neulich uns verschwandt das Licht/", "tokens": ["als", "neu\u00b7lich", "uns", "ver\u00b7schwandt", "das", "Licht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "war mir das wachen also s\u00fcsse/", "tokens": ["war", "mir", "das", "wa\u00b7chen", "al\u00b7so", "s\u00fcs\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df ich den Schlaaff drum fahren liesse.", "tokens": ["da\u00df", "ich", "den", "Schlaaff", "drum", "fah\u00b7ren", "lies\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PAV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}