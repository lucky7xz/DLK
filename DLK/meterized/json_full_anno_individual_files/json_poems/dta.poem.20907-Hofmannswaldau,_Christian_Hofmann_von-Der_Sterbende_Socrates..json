{"dta.poem.20907": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Der  \n Sterbende  \n  Socrates.", "genre": "Lyrik; Prosa; Drama", "period": "N.A.", "pub_year": "1679", "urn": "urn:nbn:de:kobv:b4-20289-1", "language": ["de:0.99"], "booktitle": "Hofmann von Hofmannswaldau, Christian: Deutsche Ubersetzungen und Gedichte. Breslau, 1679."}, "poem": {"stanza.1": {"line.1": {"text": "Solt an dem lichten Wunderreiche/", "tokens": ["Solt", "an", "dem", "lich\u00b7ten", "Wun\u00b7der\u00b7rei\u00b7che", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So stets befreit ist von der Nacht/", "tokens": ["So", "stets", "be\u00b7freit", "ist", "von", "der", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "VAFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Zirck von weitem seyn betracht/", "tokens": ["Der", "Zirck", "von", "wei\u00b7tem", "seyn", "be\u00b7tracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIS", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er schien uns einem Balle gleiche/", "tokens": ["Er", "schien", "uns", "ei\u00b7nem", "Bal\u00b7le", "glei\u00b7che", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der gantz mit Farben ist umlegt/", "tokens": ["Der", "gantz", "mit", "Far\u00b7ben", "ist", "um\u00b7legt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So gr\u00fcn und gelbes um sich tr\u00e4gt/", "tokens": ["So", "gr\u00fcn", "und", "gel\u00b7bes", "um", "sich", "tr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJA", "APPR", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und was sonst mehr des Phoebus Wagen", "tokens": ["Und", "was", "sonst", "mehr", "des", "Phoe\u00b7bus", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Vor angenehme Farben f\u00fchrt;", "tokens": ["Vor", "an\u00b7ge\u00b7neh\u00b7me", "Far\u00b7ben", "f\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Was den ber\u00fchmten Bogen ziert/", "tokens": ["Was", "den", "be\u00b7r\u00fchm\u00b7ten", "Bo\u00b7gen", "ziert", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und was die Blumen um sich tragen.", "tokens": ["Und", "was", "die", "Blu\u00b7men", "um", "sich", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Di\u00df/ was die weisen Mahler zeigen/", "tokens": ["Di\u00df", "/", "was", "die", "wei\u00b7sen", "Mah\u00b7ler", "zei\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$(", "PWS", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und derer kluger Pinsel macht/", "tokens": ["Und", "de\u00b7rer", "klu\u00b7ger", "Pin\u00b7sel", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie alles/ was sie f\u00fcrgebracht/", "tokens": ["Wie", "al\u00b7les", "/", "was", "sie", "f\u00fcr\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "$(", "PWS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bem\u00fcht sich ihnen nach zusteigen.", "tokens": ["Be\u00b7m\u00fcht", "sich", "ih\u00b7nen", "nach", "zu\u00b7stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPER", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch unsre Farben sind zu schlecht/", "tokens": ["Doch", "uns\u00b7re", "Far\u00b7ben", "sind", "zu", "schlecht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und gleichen ihnen sich nicht recht/", "tokens": ["Und", "glei\u00b7chen", "ih\u00b7nen", "sich", "nicht", "recht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "PPER", "PRF", "PTKNEG", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Es mu\u00df der Schnee und Scharlach weichen/", "tokens": ["Es", "mu\u00df", "der", "Schnee", "und", "Schar\u00b7lach", "wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Des schweren Ertzes hoher Schein", "tokens": ["Des", "schwe\u00b7ren", "Ert\u00b7zes", "ho\u00b7her", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Kan ihnen nicht verglichen seyn/", "tokens": ["Kan", "ih\u00b7nen", "nicht", "ver\u00b7gli\u00b7chen", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und ihren hohen Glantz erreichen.", "tokens": ["Und", "ih\u00b7ren", "ho\u00b7hen", "Glantz", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Viel Farben die wir kaum erkennen/", "tokens": ["Viel", "Far\u00b7ben", "die", "wir", "kaum", "er\u00b7ken\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die unsre Augen nie gesp\u00fchrt/", "tokens": ["Die", "uns\u00b7re", "Au\u00b7gen", "nie", "ge\u00b7sp\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sind hier gar reichlich aufgef\u00fchrt/", "tokens": ["Sind", "hier", "gar", "reich\u00b7lich", "auf\u00b7ge\u00b7f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und m\u00fcssen durch die Wolcken brennen/", "tokens": ["Und", "m\u00fcs\u00b7sen", "durch", "die", "Wol\u00b7cken", "bren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Tieffe so der Ort beschleust/", "tokens": ["Die", "Tief\u00b7fe", "so", "der", "Ort", "be\u00b7schleust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da Lufft durchstreicht und Wasser fleust/", "tokens": ["Da", "Lufft", "durch\u00b7streicht", "und", "Was\u00b7ser", "fleust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So von Natur hier reinlich quillet/", "tokens": ["So", "von", "Na\u00b7tur", "hier", "rein\u00b7lich", "quil\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Hat ein besonder Glantz und Licht/", "tokens": ["Hat", "ein", "be\u00b7son\u00b7der", "Glantz", "und", "Licht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So in die gr\u00f6sten H\u00f6len bricht/", "tokens": ["So", "in", "die", "gr\u00f6s\u00b7ten", "H\u00f6\u00b7len", "bricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und sie mit neuen Farben f\u00fcllet.", "tokens": ["Und", "sie", "mit", "neu\u00b7en", "Far\u00b7ben", "f\u00fcl\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Alldar ist Baum und Frucht gemahlet/", "tokens": ["A\u00b7lldar", "ist", "Baum", "und", "Frucht", "ge\u00b7mah\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Blume trotzt den Diamant/", "tokens": ["Die", "Blu\u00b7me", "trotzt", "den", "Di\u00b7a\u00b7mant", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Womit das reiche Morenland/", "tokens": ["Wo\u00b7mit", "das", "rei\u00b7che", "Mo\u00b7ren\u00b7land", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und dessen schwartzer B\u00fcrger pralet.", "tokens": ["Und", "des\u00b7sen", "schwart\u00b7zer", "B\u00fcr\u00b7ger", "pra\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Viel tausend Edlersteine Pracht/", "tokens": ["Viel", "tau\u00b7send", "Ed\u00b7lers\u00b7tei\u00b7ne", "Pracht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Womit der K\u00e4yser pr\u00e4chtig macht", "tokens": ["Wo\u00b7mit", "der", "K\u00e4y\u00b7ser", "pr\u00e4ch\u00b7tig", "macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den Purpur/ so den Leib bedecket/", "tokens": ["Den", "Pur\u00b7pur", "/", "so", "den", "Leib", "be\u00b7de\u00b7cket", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wird hier in Pusch und W\u00e4ldern seyn/", "tokens": ["Wird", "hier", "in", "Pusch", "und", "W\u00e4l\u00b7dern", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "KON", "NN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als wie der harte Kieselstein", "tokens": ["Als", "wie", "der", "har\u00b7te", "Kie\u00b7sel\u00b7stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bey uns in allen Lachen stecket.", "tokens": ["Bey", "uns", "in", "al\u00b7len", "La\u00b7chen", "ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Kein Silber kan allhier bewegen/", "tokens": ["Kein", "Sil\u00b7ber", "kan", "all\u00b7hier", "be\u00b7we\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Gold ist selbst fast wenig wehrt/", "tokens": ["Das", "Gold", "ist", "selbst", "fast", "we\u00b7nig", "wehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Perlen sind nicht mehr begehrt/", "tokens": ["Die", "Per\u00b7len", "sind", "nicht", "mehr", "be\u00b7gehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es denckt hier keiner Geld zu pregen/", "tokens": ["Es", "denckt", "hier", "kei\u00b7ner", "Geld", "zu", "pre\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Thiere haben gute Zeit/", "tokens": ["Die", "Thie\u00b7re", "ha\u00b7ben", "gu\u00b7te", "Zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sind hier aller Noth befreyt/", "tokens": ["Und", "sind", "hier", "al\u00b7ler", "Noth", "be\u00b7freyt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So unsre Erde hat umgeben;", "tokens": ["So", "uns\u00b7re", "Er\u00b7de", "hat", "um\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Man wei\u00df hier nichts was Grab und Grufft/", "tokens": ["Man", "wei\u00df", "hier", "nichts", "was", "Grab", "und", "Grufft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PIS", "PWS", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es kan in dieser reinen Lufft", "tokens": ["Es", "kan", "in", "die\u00b7ser", "rei\u00b7nen", "Lufft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das Vieh bey Menschen fr\u00f6lich leben.", "tokens": ["Das", "Vieh", "bey", "Men\u00b7schen", "fr\u00f6\u00b7lich", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Man schaut allhier viel sch\u00f6ne Str\u00e4nde/", "tokens": ["Man", "schaut", "all\u00b7hier", "viel", "sch\u00f6\u00b7ne", "Str\u00e4n\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So nicht der Unfall \u00e4ngsten kan/", "tokens": ["So", "nicht", "der", "Un\u00b7fall", "\u00e4ngs\u00b7ten", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Alldar des Todes Morde-Zahn", "tokens": ["A\u00b7lldar", "des", "To\u00b7des", "Mor\u00b7de\u00b7Zahn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Mu\u00df finden seiner Herrschafft Ende.", "tokens": ["Mu\u00df", "fin\u00b7den", "sei\u00b7ner", "Herr\u00b7schafft", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Viel Inseln sind hier f\u00fcrgestelt/", "tokens": ["Viel", "In\u00b7seln", "sind", "hier", "f\u00fcr\u00b7ge\u00b7stelt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Denn nichts bey uns die Wage h\u00e4lt;", "tokens": ["Denn", "nichts", "bey", "uns", "die", "Wa\u00b7ge", "h\u00e4lt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Man schaut das Meer nicht um sie gehen/", "tokens": ["Man", "schaut", "das", "Meer", "nicht", "um", "sie", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PTKNEG", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Hier wird kein ander Well erkiest/", "tokens": ["Hier", "wird", "kein", "an\u00b7der", "Well", "er\u00b7kiest", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "ADJD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als eine Lufft die sauber ist/", "tokens": ["Als", "ei\u00b7ne", "Lufft", "die", "sau\u00b7ber", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da Ph\u00f6bus nicht kan schlaffen gehen.", "tokens": ["Da", "Ph\u00f6\u00b7bus", "nicht", "kan", "schlaf\u00b7fen", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PTKNEG", "VMFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Die nun im Lande der Gnaden", "tokens": ["Die", "nun", "im", "Lan\u00b7de", "der", "Gna\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Erlanget haben B\u00fcrgerschchafft/", "tokens": ["Er\u00b7lan\u00b7get", "ha\u00b7ben", "B\u00fcr\u00b7ger\u00b7schchafft", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "VAFIN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die haben gr\u00f6sser St\u00e4rck und Krafft", "tokens": ["Die", "ha\u00b7ben", "gr\u00f6s\u00b7ser", "St\u00e4rck", "und", "Krafft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als wir mit Sterbligkeit beladen;", "tokens": ["Als", "wir", "mit", "Ster\u00b7blig\u00b7keit", "be\u00b7la\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Jhr Grundzeug ist vortreflich gut/", "tokens": ["Ihr", "Grund\u00b7zeug", "ist", "vor\u00b7tre\u00b7flich", "gut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jhn ist die Lufft/ was uns die Fluth/", "tokens": ["Jhn", "ist", "die", "Lufft", "/", "was", "uns", "die", "Fluth", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$(", "PWS", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und in dem Schlosse voller Wonne/", "tokens": ["Und", "in", "dem", "Schlos\u00b7se", "vol\u00b7ler", "Won\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Streicht nicht ein Dunst der Schaden bringt/", "tokens": ["Streicht", "nicht", "ein", "Dunst", "der", "Scha\u00b7den", "bringt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Was hier durch ihre Lunge dringt", "tokens": ["Was", "hier", "durch", "ih\u00b7re", "Lun\u00b7ge", "dringt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ist noch viel remer als die Sonne.", "tokens": ["Ist", "noch", "viel", "re\u00b7mer", "als", "die", "Son\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Jhr Ansehn/ Augen und Gesichte/", "tokens": ["Ihr", "An\u00b7sehn", "/", "Au\u00b7gen", "und", "Ge\u00b7sich\u00b7te", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist weit vor unsern ausgeziert/", "tokens": ["Ist", "weit", "vor", "un\u00b7sern", "aus\u00b7ge\u00b7ziert", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "PPOSAT", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was man bey uns vor K\u00fcnste sp\u00fchrt/", "tokens": ["Was", "man", "bey", "uns", "vor", "K\u00fcns\u00b7te", "sp\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PPER", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die sieht man dort mit mehrem Lichte.", "tokens": ["Die", "sieht", "man", "dort", "mit", "meh\u00b7rem", "Lich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Sinnen stehn in ihrer Krafft/", "tokens": ["Die", "Sin\u00b7nen", "stehn", "in", "ih\u00b7rer", "Krafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Leiber werden nicht behafft", "tokens": ["Die", "Lei\u00b7ber", "wer\u00b7den", "nicht", "be\u00b7hafft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit Kranckheit/ wie auf unser Erden/", "tokens": ["Mit", "Kran\u00b7ck\u00b7heit", "/", "wie", "auf", "un\u00b7ser", "Er\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "KOKOM", "APPR", "PPOSAT", "NN", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Da mancher Tag uns traurig macht/", "tokens": ["Da", "man\u00b7cher", "Tag", "uns", "trau\u00b7rig", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es wird hier nichts herf\u00fcr gebracht/", "tokens": ["Es", "wird", "hier", "nichts", "her\u00b7f\u00fcr", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dardurch die Seele blind kan werden.", "tokens": ["Dar\u00b7durch", "die", "See\u00b7le", "blind", "kan", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADJD", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Steht nun die Lufft f\u00fcr See und Fl\u00fcssen/", "tokens": ["Steht", "nun", "die", "Lufft", "f\u00fcr", "See", "und", "Fl\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ehrt man den Himmel f\u00fcr der Lufft/", "tokens": ["Ehrt", "man", "den", "Him\u00b7mel", "f\u00fcr", "der", "Lufft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wird/ was hier zum Leben rufft/", "tokens": ["So", "wird", "/", "was", "hier", "zum", "Le\u00b7ben", "rufft", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$(", "PWS", "ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Uns mit mehr Gaben ziehren m\u00fcssen/", "tokens": ["Uns", "mit", "mehr", "Ga\u00b7ben", "zieh\u00b7ren", "m\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und die/ den in der neuen Welt", "tokens": ["Und", "die", "/", "den", "in", "der", "neu\u00b7en", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "$(", "ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist Leib und Geist so wohl bestelt/", "tokens": ["Ist", "Leib", "und", "Geist", "so", "wohl", "be\u00b7stelt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und der Vollkommenheit geniessen/", "tokens": ["Und", "der", "Voll\u00b7kom\u00b7men\u00b7heit", "ge\u00b7nies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die schweben voller Wissenschafft/", "tokens": ["Die", "schwe\u00b7ben", "vol\u00b7ler", "Wis\u00b7sen\u00b7schafft", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und k\u00f6nnen des Verm\u00f6gens Krafft", "tokens": ["Und", "k\u00f6n\u00b7nen", "des", "Ver\u00b7m\u00f6\u00b7gens", "Krafft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "In der Natur rechtschaffen wissen.", "tokens": ["In", "der", "Na\u00b7tur", "recht\u00b7schaf\u00b7fen", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Da sind die grossen Wunderwercke/", "tokens": ["Da", "sind", "die", "gros\u00b7sen", "Wun\u00b7der\u00b7wer\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Damit der Himmel ist geziehrt/", "tokens": ["Da\u00b7mit", "der", "Him\u00b7mel", "ist", "ge\u00b7ziehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und was man hier vor Stimmen sp\u00fchrt/", "tokens": ["Und", "was", "man", "hier", "vor", "Stim\u00b7men", "sp\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind Zeugnisse der G\u00f6tter St\u00e4rcke/", "tokens": ["Sind", "Zeug\u00b7nis\u00b7se", "der", "G\u00f6t\u00b7ter", "St\u00e4r\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ART", "NN", "NN", "$("], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Hier ist das ware Haupt-Altar/", "tokens": ["Hier", "ist", "das", "wa\u00b7re", "Haup\u00b7tAl\u00b7tar", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es mag der Menschen reiche Schaar/", "tokens": ["Es", "mag", "der", "Men\u00b7schen", "rei\u00b7che", "Schaar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Allhier kein Opffer frey entz\u00fcnden.", "tokens": ["All\u00b7hier", "kein", "Opf\u00b7fer", "frey", "ent\u00b7z\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wer nun betritt die grosse Bahn/", "tokens": ["Wer", "nun", "be\u00b7tritt", "die", "gros\u00b7se", "Bahn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der sieht so offt die G\u00f6tter an/", "tokens": ["Der", "sieht", "so", "offt", "die", "G\u00f6t\u00b7ter", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als wir allhier der Menschen finden.", "tokens": ["Als", "wir", "all\u00b7hier", "der", "Men\u00b7schen", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Hier wei\u00df die Wolcke nicht zu decken/", "tokens": ["Hier", "wei\u00df", "die", "Wol\u00b7cke", "nicht", "zu", "de\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Man kennt hier weder Schlaff noch Nacht/", "tokens": ["Man", "kennt", "hier", "we\u00b7der", "Schlaff", "noch", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "KON", "NN", "ADV", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Monden Licht/ der Sonnen Pracht/", "tokens": ["Des", "Mon\u00b7den", "Licht", "/", "der", "Son\u00b7nen", "Pracht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Begehrt sich hier nicht zu verstecken/", "tokens": ["Be\u00b7gehrt", "sich", "hier", "nicht", "zu", "ver\u00b7ste\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das Unheil hat hier keine Stadt/", "tokens": ["Das", "Un\u00b7heil", "hat", "hier", "kei\u00b7ne", "Stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man sagt hier nichts von Missethat;", "tokens": ["Man", "sagt", "hier", "nichts", "von", "Mis\u00b7se\u00b7that", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die G\u00f6tter sind da voll Genaden.", "tokens": ["Die", "G\u00f6t\u00b7ter", "sind", "da", "voll", "Ge\u00b7na\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Hier ist kein Eisen und kein Band/", "tokens": ["Hier", "ist", "kein", "Ei\u00b7sen", "und", "kein", "Band", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "KON", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Hier ist kein Gifft/ hier ist kein Brand/", "tokens": ["Hier", "ist", "kein", "Gifft", "/", "hier", "ist", "kein", "Brand", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$(", "ADV", "VAFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die Pest wei\u00df hier nichts mehr zu schaden.", "tokens": ["Die", "Pest", "wei\u00df", "hier", "nichts", "mehr", "zu", "scha\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIS", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Gar viel Geleite/ wie man schreibet/", "tokens": ["Gar", "viel", "Ge\u00b7lei\u00b7te", "/", "wie", "man", "schrei\u00b7bet", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$(", "PWAV", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sind hier mit Wasser angef\u00fcllt/", "tokens": ["Sind", "hier", "mit", "Was\u00b7ser", "an\u00b7ge\u00b7f\u00fcllt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dadurch manch Strom mit Rauschen quillt/", "tokens": ["Da\u00b7durch", "manch", "Strom", "mit", "Rau\u00b7schen", "quillt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIAT", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und durch die krummen R\u00f6hren treibet/", "tokens": ["Und", "durch", "die", "krum\u00b7men", "R\u00f6h\u00b7ren", "trei\u00b7bet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Gr\u00e4ber sind gar mannigfalt/", "tokens": ["Die", "Gr\u00e4\u00b7ber", "sind", "gar", "man\u00b7nig\u00b7falt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bald enge zu/ bald weit gestalt/", "tokens": ["Bald", "en\u00b7ge", "zu", "/", "bald", "weit", "ge\u00b7stalt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "PTKZU", "$(", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Jhr Einfall ist gantz rund zu sp\u00fchren;", "tokens": ["Ihr", "Ein\u00b7fall", "ist", "gantz", "rund", "zu", "sp\u00fch\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit unsern treffen sie nicht ein/", "tokens": ["Mit", "un\u00b7sern", "tref\u00b7fen", "sie", "nicht", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "In dem sie allzu enge seyn/", "tokens": ["In", "dem", "sie", "all\u00b7zu", "en\u00b7ge", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PTKA", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und allzu tieff ihr Wasser f\u00fchren.", "tokens": ["Und", "all\u00b7zu", "tieff", "ihr", "Was\u00b7ser", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKA", "ADJD", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Die R\u00f6hren so beschlossen liegen/", "tokens": ["Die", "R\u00f6h\u00b7ren", "so", "be\u00b7schlos\u00b7sen", "lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die kriegen durch Gewichtes Krafft/", "tokens": ["Die", "krie\u00b7gen", "durch", "Ge\u00b7wich\u00b7tes", "Krafft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Tieff in der Erden einen Hafft/", "tokens": ["Tieff", "in", "der", "Er\u00b7den", "ei\u00b7nen", "Hafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN", "$("], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und m\u00fcssen sich zusammen f\u00fcgen;", "tokens": ["Und", "m\u00fcs\u00b7sen", "sich", "zu\u00b7sam\u00b7men", "f\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da endet vieler Fl\u00fcsse Art", "tokens": ["Da", "en\u00b7det", "vie\u00b7ler", "Fl\u00fcs\u00b7se", "Art"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die alte Bahn/ die alte Fahrt/", "tokens": ["Die", "al\u00b7te", "Bahn", "/", "die", "al\u00b7te", "Fahrt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und fl\u00f6ssen nicht wie sie geflossen.", "tokens": ["Und", "fl\u00f6s\u00b7sen", "nicht", "wie", "sie", "ge\u00b7flos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PWAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Es lenckt ein unbekanter Schlund", "tokens": ["Es", "lenckt", "ein", "un\u00b7be\u00b7kan\u00b7ter", "Schlund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Hier ieden Flu\u00df auch auf den Grund", "tokens": ["Hier", "ie\u00b7den", "Flu\u00df", "auch", "auf", "den", "Grund"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Des Quelles/ da er ist entsprossen.", "tokens": ["Des", "Quel\u00b7les", "/", "da", "er", "ist", "ent\u00b7spros\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "KOUS", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Hier ist gar bald ein Flu\u00df zu finden/", "tokens": ["Hier", "ist", "gar", "bald", "ein", "Flu\u00df", "zu", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Feuer/ Flamm und Schwefel f\u00fchrt/", "tokens": ["Der", "Feu\u00b7er", "/", "Flamm", "und", "Schwe\u00b7fel", "f\u00fchrt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "NE", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bald einer der sich kaume r\u00fchrt/", "tokens": ["Bald", "ei\u00b7ner", "der", "sich", "kau\u00b7me", "r\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PRELS", "PRF", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sich l\u00e4st Eis und Winter binden;", "tokens": ["Und", "sich", "l\u00e4st", "Eis", "und", "Win\u00b7ter", "bin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und dieses Na\u00df der Ewigkeit", "tokens": ["Und", "die\u00b7ses", "Na\u00df", "der", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist gantz erf\u00fcllt mit Ungleichheit/", "tokens": ["Ist", "gantz", "er\u00b7f\u00fcllt", "mit", "Un\u00b7gleich\u00b7heit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der fleust gantz faul/ ein ander schnelle/", "tokens": ["Der", "fleust", "gantz", "faul", "/", "ein", "an\u00b7der", "schnel\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "$(", "ART", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der ein ist tr\u00fcb/ ein ander klar/", "tokens": ["Der", "ein", "ist", "tr\u00fcb", "/", "ein", "an\u00b7der", "klar", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "VAFIN", "ADJD", "$(", "ART", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und der vergleicht sich gantz und gar", "tokens": ["Und", "der", "ver\u00b7gleicht", "sich", "gantz", "und", "gar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "VVFIN", "PRF", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mit der Sicilianer Quelle.", "tokens": ["Mit", "der", "Si\u00b7ci\u00b7li\u00b7a\u00b7ner", "Quel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Da laufft der Fl\u00fcsse Strom zu Hauffen/", "tokens": ["Da", "laufft", "der", "Fl\u00fcs\u00b7se", "Strom", "zu", "Hauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und wird gar wunderlich gemengt/", "tokens": ["Und", "wird", "gar", "wun\u00b7der\u00b7lich", "ge\u00b7mengt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In dem er im Gewichte hengt/", "tokens": ["In", "dem", "er", "im", "Ge\u00b7wich\u00b7te", "hengt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und mu\u00df in ein Gef\u00e4sse lauffen/", "tokens": ["Und", "mu\u00df", "in", "ein", "Ge\u00b7f\u00e4s\u00b7se", "lauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So stets in gleicher Wage steht/", "tokens": ["So", "stets", "in", "glei\u00b7cher", "Wa\u00b7ge", "steht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und nimmer auf die Seite geht.", "tokens": ["Und", "nim\u00b7mer", "auf", "die", "Sei\u00b7te", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Di\u00df Fa\u00df ist der Homerus Graben/", "tokens": ["Di\u00df", "Fa\u00df", "ist", "der", "Ho\u00b7me\u00b7rus", "Gra\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "ART", "NE", "NN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "So mit der Fluth bedecket bleibt/", "tokens": ["So", "mit", "der", "Fluth", "be\u00b7de\u00b7cket", "bleibt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und diesen Klo\u00df von sammen treibt/", "tokens": ["Und", "die\u00b7sen", "Klo\u00df", "von", "sam\u00b7men", "treibt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "APPR", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den sie zur Mutter scheint zu haben.", "tokens": ["Den", "sie", "zur", "Mut\u00b7ter", "scheint", "zu", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVFIN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}