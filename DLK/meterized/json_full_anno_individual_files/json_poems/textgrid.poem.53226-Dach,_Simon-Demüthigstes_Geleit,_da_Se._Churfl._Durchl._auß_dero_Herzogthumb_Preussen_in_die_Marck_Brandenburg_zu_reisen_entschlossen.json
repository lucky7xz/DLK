{"textgrid.poem.53226": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Dem\u00fcthigstes Geleit, da Se. Churfl. Durchl. au\u00df dero Herzogthumb Preussen in die Marck Brandenburg zu reisen entschlossen", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "K\u00f6nnen wir mit keinen Sachen,", "tokens": ["K\u00f6n\u00b7nen", "wir", "mit", "kei\u00b7nen", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Held, Dir l\u00e4nger Seumnis machen?", "tokens": ["Held", ",", "Dir", "l\u00e4n\u00b7ger", "Seum\u00b7nis", "ma\u00b7chen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "ADJD", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mu\u00df dein Auffbruch dann geschehn?", "tokens": ["Mu\u00df", "dein", "Auff\u00b7bruch", "dann", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ach was schaffstu uns f\u00fcr Schmertzen!", "tokens": ["Ach", "was", "schaffs\u00b7tu", "uns", "f\u00fcr", "Schmert\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und mit was betr\u00fcbtem Hertzen", "tokens": ["Und", "mit", "was", "be\u00b7tr\u00fcb\u00b7tem", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PRELS", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Zwingstu uns Dir nachzusehn!", "tokens": ["Zwings\u00b7tu", "uns", "Dir", "nach\u00b7zu\u00b7sehn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "O das Helm, Gescho\u00df und Degen", "tokens": ["O", "das", "Helm", ",", "Ge\u00b7scho\u00df", "und", "De\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ART", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und was Deutschland aller wegen", "tokens": ["Und", "was", "Deutschland", "al\u00b7ler", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "NN", "PIAT", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auff den Grund verw\u00fcstet hat,", "tokens": ["Auff", "den", "Grund", "ver\u00b7w\u00fcs\u00b7tet", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Umbgeschmoltzen wehr' in Pfl\u00fcge!", "tokens": ["U\u00b7mbge\u00b7schmolt\u00b7zen", "wehr'", "in", "Pfl\u00fc\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "O das Rhue f\u00fcr wilde Kriege", "tokens": ["O", "das", "Rhue", "f\u00fcr", "wil\u00b7de", "Krie\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hielt' umbschlossen Dorff und Stadt!", "tokens": ["Hielt'", "umbsc\u00b7hlos\u00b7sen", "Dorff", "und", "Stadt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Preussen k\u00f6nt' jetzt Dich behalten,", "tokens": ["Preus\u00b7sen", "k\u00f6nt'", "jetzt", "Dich", "be\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "D\u00f6rffte t\u00f6dtlich nicht erkalten,", "tokens": ["D\u00f6rff\u00b7te", "t\u00f6dt\u00b7lich", "nicht", "er\u00b7kal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun dein Sinn dahin gedenckt,", "tokens": ["Nun", "dein", "Sinn", "da\u00b7hin", "ge\u00b7denckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PAV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo-es-her Dich, sein Verlangen,", "tokens": ["Wo\u00b7es\u00b7her", "Dich", ",", "sein", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kurtz vor diesem hat empfangen", "tokens": ["Kurtz", "vor", "die\u00b7sem", "hat", "emp\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PDAT", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nur nicht auff den Todt gekr\u00e4nckt.", "tokens": ["Nur", "nicht", "auff", "den", "Todt", "ge\u00b7kr\u00e4nckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Deutschland wird es mir verzeihen,", "tokens": ["Deutschland", "wird", "es", "mir", "ver\u00b7zei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Fridrich Wilhelmen jhm leihen", "tokens": ["Frid\u00b7rich", "Wil\u00b7hel\u00b7men", "jhm", "lei\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "PPER", "VVINF"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Hat zu grosse Furcht und Pein.", "tokens": ["Hat", "zu", "gros\u00b7se", "Furcht", "und", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Brandenburg wird zweene melden", "tokens": ["Bran\u00b7den\u00b7burg", "wird", "zwee\u00b7ne", "mel\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VAFIN", "CARD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "So daselbst, O thewre Helden!", "tokens": ["So", "da\u00b7selbst", ",", "O", "thew\u00b7re", "Hel\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "$,", "NE", "ADJA", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Kurtz hievor verblichen seyn.", "tokens": ["Kurtz", "hie\u00b7vor", "ver\u00b7bli\u00b7chen", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PAV", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Du auch kuntest, einer Leichen", "tokens": ["Du", "auch", "kun\u00b7test", ",", "ei\u00b7ner", "Lei\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "PTKVZ", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schon gar \u00e4hnlich, kaum entweichen,", "tokens": ["Schon", "gar", "\u00e4hn\u00b7lich", ",", "kaum", "ent\u00b7wei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$,", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und man solte Furcht-loh\u00df stehn,", "tokens": ["Und", "man", "sol\u00b7te", "Furcht\u00b7loh\u00df", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun wir Dich sehn von uns scheiden?", "tokens": ["Nun", "wir", "Dich", "sehn", "von", "uns", "schei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PRF", "VVINF", "APPR", "PPER", "VVINF", "$."], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Sehn Dich Sicherheit hie meiden,", "tokens": ["Sehn", "Dich", "Si\u00b7cher\u00b7heit", "hie", "mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dort in Schwerd und Flamme gehn?", "tokens": ["Dort", "in", "Schwerd", "und", "Flam\u00b7me", "gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Nein, wir haben auff dein Leben", "tokens": ["Nein", ",", "wir", "ha\u00b7ben", "auff", "dein", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weit ein mehrers noch zu geben:", "tokens": ["Weit", "ein", "meh\u00b7rers", "noch", "zu", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Theseus war Athenen Zier,", "tokens": ["The\u00b7seus", "war", "A\u00b7the\u00b7nen", "Zier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hector noch zuletzt vorhanden,", "tokens": ["Hec\u00b7tor", "noch", "zu\u00b7letzt", "vor\u00b7han\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Worauff Trojen Reich bestanden,", "tokens": ["Wo\u00b7rauff", "Tro\u00b7jen", "Reich", "be\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "NE", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wir bestehn auff Gott und Dir.", "tokens": ["Wir", "be\u00b7stehn", "auff", "Gott", "und", "Dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Kan ich, bin ich recht bey Sinnen,", "tokens": ["Kan", "ich", ",", "bin", "ich", "recht", "bey", "Sin\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "VAFIN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch die Welt so lieb gewinnen,", "tokens": ["Auch", "die", "Welt", "so", "lieb", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich sollt' auf Deinen Todt", "tokens": ["Da\u00df", "ich", "sollt'", "auf", "Dei\u00b7nen", "Todt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "(den Gott ja nicht m\u00fcss' erleuben)", "tokens": ["(", "den", "Gott", "ja", "nicht", "m\u00fcss'", "er\u00b7leu\u00b7ben", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ADV", "PTKNEG", "VMFIN", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "L\u00e4nger wollen \u00fcbrig bleiben,", "tokens": ["L\u00e4n\u00b7ger", "wol\u00b7len", "\u00fcb\u00b7rig", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nur zu Hertzeleid' und Noht?", "tokens": ["Nur", "zu", "Hert\u00b7ze\u00b7leid'", "und", "Noht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Aber Lieb' und das Gebl\u00fcte", "tokens": ["A\u00b7ber", "Lieb'", "und", "das", "Ge\u00b7bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Reisst nur von uns Dein Gem\u00fcte,", "tokens": ["Reisst", "nur", "von", "uns", "Dein", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "PPOSAT", "NN", "$,"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.3": {"text": "Deine Marck hat Dich besiegt,", "tokens": ["Dei\u00b7ne", "Marck", "hat", "Dich", "be\u00b7siegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die von Leid' und Angst durchfahren", "tokens": ["Die", "von", "Leid'", "und", "Angst", "durch\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Blutig und mit freyen Haren", "tokens": ["Blu\u00b7tig", "und", "mit", "frey\u00b7en", "Ha\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dir zu sehr f\u00fcr Augen liegt.", "tokens": ["Dir", "zu", "sehr", "f\u00fcr", "Au\u00b7gen", "liegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKA", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Die zu Tag und Nacht mit Thr\u00e4nen", "tokens": ["Die", "zu", "Tag", "und", "Nacht", "mit", "Thr\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur nach Dir sich wei\u00df zu sehnen,", "tokens": ["Nur", "nach", "Dir", "sich", "wei\u00df", "zu", "seh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PRF", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Spricht: Wie lang doch, O mein Liecht,", "tokens": ["Spricht", ":", "Wie", "lang", "doch", ",", "O", "mein", "Liecht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PWAV", "ADJD", "ADV", "$,", "NE", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Suchstu noch mich au\u00dfzuschliessen?", "tokens": ["Suchs\u00b7tu", "noch", "mich", "au\u00df\u00b7zu\u00b7schlies\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sol ich ewig dann nicht wissen,", "tokens": ["Sol", "ich", "e\u00b7wig", "dann", "nicht", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ob ich Dein sey, oder nicht?", "tokens": ["Ob", "ich", "Dein", "sey", ",", "o\u00b7der", "nicht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "VAFIN", "$,", "KON", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Zehl die Unzahl meiner Wunden,", "tokens": ["Zehl", "die", "Un\u00b7zahl", "mei\u00b7ner", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So ich diese Jahr empfunden,", "tokens": ["So", "ich", "die\u00b7se", "Jahr", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "So wirst Du des Meeres Sand", "tokens": ["So", "wirst", "Du", "des", "Mee\u00b7res", "Sand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Leicht auch \u00fcberschlagen lernen,", "tokens": ["Leicht", "auch", "\u00fc\u00b7bersc\u00b7hla\u00b7gen", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ja die grosse Zahl der Sternen", "tokens": ["Ja", "die", "gros\u00b7se", "Zahl", "der", "Ster\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird dir nicht seyn unbekant.", "tokens": ["Wird", "dir", "nicht", "seyn", "un\u00b7be\u00b7kant", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VAINF", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Wenn hat mich nicht Glut verzehret?", "tokens": ["Wenn", "hat", "mich", "nicht", "Glut", "ver\u00b7zeh\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "PTKNEG", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wenn nicht Pest und Schwerd verheeret?", "tokens": ["Wenn", "nicht", "Pest", "und", "Schwerd", "ver\u00b7hee\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn nicht Rauben und Gefahr", "tokens": ["Wenn", "nicht", "Rau\u00b7ben", "und", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mir auff Marck und Bein getroffen?", "tokens": ["Mir", "auff", "Marck", "und", "Bein", "ge\u00b7trof\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer hat nicht mein Blut gesoffen,", "tokens": ["Wer", "hat", "nicht", "mein", "Blut", "ge\u00b7sof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PTKNEG", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Da\u00df ich nicht bin die ich war?", "tokens": ["Da\u00df", "ich", "nicht", "bin", "die", "ich", "war", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VAFIN", "ART", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Gleichwol hab' ich alle Plagen", "tokens": ["Gleich\u00b7wol", "hab'", "ich", "al\u00b7le", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Immer mit Gedult ertragen,", "tokens": ["Im\u00b7mer", "mit", "Ge\u00b7dult", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur des grimmen Todes Macht,", "tokens": ["Nur", "des", "grim\u00b7men", "To\u00b7des", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die Drey F\u00fcrsten mir genommen", "tokens": ["Die", "Drey", "F\u00fcrs\u00b7ten", "mir", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "CARD", "NN", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Eh drey Jahr herumb seyn kommen,", "tokens": ["Eh", "drey", "Jahr", "he\u00b7rumb", "seyn", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "APZR", "VAINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat mich gantz von mir gebracht.", "tokens": ["Hat", "mich", "gantz", "von", "mir", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Nun bin ich erst allermassen,", "tokens": ["Nun", "bin", "ich", "erst", "al\u00b7ler\u00b7mas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hoch betr\u00fcbt und gantz verlassen,", "tokens": ["Hoch", "be\u00b7tr\u00fcbt", "und", "gantz", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "KON", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wann ich dir auch frembde bin;", "tokens": ["Wann", "ich", "dir", "auch", "fremb\u00b7de", "bin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ADJA", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sag, was ist doch mein Gebrechen?", "tokens": ["Sag", ",", "was", "ist", "doch", "mein", "Ge\u00b7bre\u00b7chen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Warumb mu\u00df dein Zorn sich rechen", "tokens": ["Wa\u00b7rumb", "mu\u00df", "dein", "Zorn", "sich", "re\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPOSAT", "NN", "PRF", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und lenckt von mir Deinen Sinn?", "tokens": ["Und", "lenckt", "von", "mir", "Dei\u00b7nen", "Sinn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PPOSAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Bin ich nicht f\u00fcr Gott mit Behten", "tokens": ["Bin", "ich", "nicht", "f\u00fcr", "Gott", "mit", "Beh\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "APPR", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Umb Dein Wolergehn getretten,", "tokens": ["Umb", "Dein", "Wo\u00b7ler\u00b7gehn", "ge\u00b7tret\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "So k\u00f6mpt recht mir diese Pein.", "tokens": ["So", "k\u00f6mpt", "recht", "mir", "die\u00b7se", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PPER", "PDAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ja ich wil auff aller Erden", "tokens": ["Ja", "ich", "wil", "auff", "al\u00b7ler", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PPER", "VMFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ein Gel\u00e4ch' und Schawspiel werden,", "tokens": ["Ein", "Ge\u00b7l\u00e4ch'", "und", "Schaw\u00b7spiel", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und der V\u00f6lcker M\u00e4hrlein seyn.", "tokens": ["Und", "der", "V\u00f6l\u00b7cker", "M\u00e4hr\u00b7lein", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Merckstu aber auff mein Flehen,", "tokens": ["Mercks\u00b7tu", "a\u00b7ber", "auff", "mein", "Fle\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Warumb mu\u00df ich Dich nicht sehen?", "tokens": ["Wa\u00b7rumb", "mu\u00df", "ich", "Dich", "nicht", "se\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist nur Preussen die Du liebst?", "tokens": ["Ist", "nur", "Preus\u00b7sen", "die", "Du", "liebst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "ART", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wormit hat sie Dich ber\u00fccket,", "tokens": ["Wor\u00b7mit", "hat", "sie", "Dich", "be\u00b7r\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df Du, gantz in jhr verstricket,", "tokens": ["Da\u00df", "Du", ",", "gantz", "in", "jhr", "ver\u00b7stri\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nichts auff mich, Dein Erbtheil, giebst?", "tokens": ["Nichts", "auff", "mich", ",", "Dein", "E\u00b7rbtheil", ",", "giebst", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "APPR", "PPER", "$,", "PPOSAT", "NN", "$,", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Ach vielleicht empfindstu Grawen", "tokens": ["Ach", "viel\u00b7leicht", "emp\u00b7finds\u00b7tu", "Gra\u00b7wen"], "token_info": ["word", "word", "word", "word"], "pos": ["ITJ", "ADV", "VVFIN", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mich die he\u00dflich' anzuschawen,", "tokens": ["Mich", "die", "he\u00df\u00b7lich'", "an\u00b7zu\u00b7scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVIZU", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Weil ich bin so w\u00fcst und leer?", "tokens": ["Weil", "ich", "bin", "so", "w\u00fcst", "und", "leer", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADV", "VVFIN", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Keiner weich' ich leicht an Gaben,", "tokens": ["Kei\u00b7ner", "weich'", "ich", "leicht", "an", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kan ich dich nur umb mich haben,", "tokens": ["Kan", "ich", "dich", "nur", "umb", "mich", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "APPR", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Komm, mit Dir k\u00f6mpt alles her!", "tokens": ["Komm", ",", "mit", "Dir", "k\u00f6mpt", "al\u00b7les", "her", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "PPER", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Herr, die Asche Deiner Ahnen,", "tokens": ["Herr", ",", "die", "A\u00b7sche", "Dei\u00b7ner", "Ah\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So die trewsten Unterthanen", "tokens": ["So", "die", "trew\u00b7sten", "Un\u00b7ter\u00b7tha\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bey mir fanden jederzeit,", "tokens": ["Bey", "mir", "fan\u00b7den", "je\u00b7der\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sol ein Zeugnu\u00df mir ablegen,", "tokens": ["Sol", "ein", "Zeug\u00b7nu\u00df", "mir", "ab\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ob du mich des Jammers wegen", "tokens": ["Ob", "du", "mich", "des", "Jam\u00b7mers", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Billich setzest an die Seit'.", "tokens": ["Bil\u00b7lich", "set\u00b7zest", "an", "die", "Seit'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Hat Dich sonst wer auffgenommen,", "tokens": ["Hat", "Dich", "sonst", "wer", "auff\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PWS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als Du an die\u00df' Liecht bist kommen?", "tokens": ["Als", "Du", "an", "die\u00df'", "Liecht", "bist", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer? Hab ich es nicht gethan?", "tokens": ["Wer", "?", "Hab", "ich", "es", "nicht", "ge\u00b7than", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "NN", "PPER", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df Du nach der Zeit dein Leben", "tokens": ["Da\u00df", "Du", "nach", "der", "Zeit", "dein", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Hie schier h\u00e4ttest auffgegeben,", "tokens": ["Hie", "schier", "h\u00e4t\u00b7test", "auff\u00b7ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Bin ich da wo schuldig an?", "tokens": ["Bin", "ich", "da", "wo", "schul\u00b7dig", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PWAV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Wer warff deinen Vater nieder?", "tokens": ["Wer", "warff", "dei\u00b7nen", "Va\u00b7ter", "nie\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Preussen gebe mir Ihn wieder,", "tokens": ["Preus\u00b7sen", "ge\u00b7be", "mir", "Ihn", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPER", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mir steht auch mein Urtheil frey.", "tokens": ["Mir", "steht", "auch", "mein", "Ur\u00b7theil", "frey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Was der Schlu\u00df des Himmels schaffet,", "tokens": ["Was", "der", "Schlu\u00df", "des", "Him\u00b7mels", "schaf\u00b7fet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der uns H\u00e4upter giebt und raffet,", "tokens": ["Der", "uns", "H\u00e4up\u00b7ter", "giebt", "und", "raf\u00b7fet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Misst man uns mit Unrecht bey.", "tokens": ["Misst", "man", "uns", "mit", "Un\u00b7recht", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Ich bin nicht die ich gewesen,", "tokens": ["Ich", "bin", "nicht", "die", "ich", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "PRELS", "PPER", "VAPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Doch k\u00f6mpst Du, ich wil genesen,", "tokens": ["Doch", "k\u00f6mpst", "Du", ",", "ich", "wil", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Komm, weil noch ein Geist in mir!", "tokens": ["Komm", ",", "weil", "noch", "ein", "Geist", "in", "mir", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "ART", "NN", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6mpstu nicht, ich sterb' indessen,", "tokens": ["K\u00f6mps\u00b7tu", "nicht", ",", "ich", "sterb'", "in\u00b7des\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wem doch hastu zu-zu-m\u00e4ssen", "tokens": ["Wem", "doch", "has\u00b7tu", "zu\u00b7zu\u00b7m\u00e4s\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADV", "NE", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Meinen Untergang als Dir?", "tokens": ["Mei\u00b7nen", "Un\u00b7ter\u00b7gang", "als", "Dir", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOUS", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Herr, der ist von Stahl' und Steinen,", "tokens": ["Herr", ",", "der", "ist", "von", "Stahl'", "und", "Stei\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "VAFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welcher diese Klag' und Weinen", "tokens": ["Wel\u00b7cher", "die\u00b7se", "Klag'", "und", "Wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAT", "PDAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00f6rt mit unbewegtem Muth':", "tokens": ["H\u00f6rt", "mit", "un\u00b7be\u00b7weg\u00b7tem", "Muth'", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und Du solt Bedencken tragen,", "tokens": ["Und", "Du", "solt", "Be\u00b7den\u00b7cken", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Nach derselben Noht zu fragen,", "tokens": ["Nach", "der\u00b7sel\u00b7ben", "Noht", "zu", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die so sehnlich nach Dir thut?", "tokens": ["Die", "so", "sehn\u00b7lich", "nach", "Dir", "thut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Es ist war, die lieben Leute", "tokens": ["Es", "ist", "war", ",", "die", "lie\u00b7ben", "Leu\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VAFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sind zu lang des Krieges Beute,", "tokens": ["Sind", "zu", "lang", "des", "Krie\u00b7ges", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKA", "ADJD", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sind zu lang ohn Gl\u00fcck und Rhue,", "tokens": ["Sind", "zu", "lang", "ohn", "Gl\u00fcck", "und", "Rhue", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKA", "ADJD", "APPR", "NN", "KON", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wolten gern sich wieder bawen,", "tokens": ["Wol\u00b7ten", "gern", "sich", "wie\u00b7der", "ba\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Wo sie einig noch auff schawen,", "tokens": ["Wo", "sie", "ei\u00b7nig", "noch", "auff", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "ADV", "APPR", "VVINF", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Sind nur unser Gott und Du.", "tokens": ["Sind", "nur", "un\u00b7ser", "Gott", "und", "Du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "KON", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Darumb bistu nicht zu hindern,", "tokens": ["Da\u00b7rumb", "bis\u00b7tu", "nicht", "zu", "hin\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "Nichts mu\u00df deinen Vorsatz mindern.", "tokens": ["Nichts", "mu\u00df", "dei\u00b7nen", "Vor\u00b7satz", "min\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Du gestehst uns kaum ein Wort.", "tokens": ["Du", "ge\u00b7stehst", "uns", "kaum", "ein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Deine Wagen-Rosse schreyen,", "tokens": ["Dei\u00b7ne", "Wa\u00b7gen\u00b7Ros\u00b7se", "schre\u00b7yen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Dein Geleit, die Preussschen Freyen", "tokens": ["Dein", "Ge\u00b7leit", ",", "die", "Preuss\u00b7schen", "Frey\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sampt der Leib-Hut ist schon fort.", "tokens": ["Sampt", "der", "Leib\u00b7Hut", "ist", "schon", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "+-++--+", "measure": "iambic.tetra.chol"}}, "stanza.24": {"line.1": {"text": "Was h\u00f6r ich f\u00fcr Leid und Heulen?", "tokens": ["Was", "h\u00f6r", "ich", "f\u00fcr", "Leid", "und", "Heu\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mustu denn so von uns eilen?", "tokens": ["Mus\u00b7tu", "denn", "so", "von", "uns", "ei\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Spricht die M\u00fctterliche Trew.", "tokens": ["Spricht", "die", "M\u00fct\u00b7ter\u00b7li\u00b7che", "Trew", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und man wei\u00df f\u00fcr Weh und Klagen", "tokens": ["Und", "man", "wei\u00df", "f\u00fcr", "Weh", "und", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dir kaum gutte Nacht zu sagen,", "tokens": ["Dir", "kaum", "gut\u00b7te", "Nacht", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Alles f\u00fchret nur Geschrey.", "tokens": ["Al\u00b7les", "f\u00fch\u00b7ret", "nur", "Ge\u00b7schrey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Deine Schwestern, die G\u00f6ttinnen,", "tokens": ["Dei\u00b7ne", "Schwes\u00b7tern", ",", "die", "G\u00f6t\u00b7tin\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nnen sich nicht eins besinnen,", "tokens": ["K\u00f6n\u00b7nen", "sich", "nicht", "eins", "be\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "PTKNEG", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was mit Ihnen jetzt geschieht:", "tokens": ["Was", "mit", "Ih\u00b7nen", "jetzt", "ge\u00b7schieht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die Fraw Mutter kan bey weiten", "tokens": ["Die", "Fraw", "Mut\u00b7ter", "kan", "bey", "wei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VMFIN", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dich f\u00fcr Wehmut nicht geleiten,", "tokens": ["Dich", "f\u00fcr", "Weh\u00b7mut", "nicht", "ge\u00b7lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So man umb und an Ihr sieht.", "tokens": ["So", "man", "umb", "und", "an", "Ihr", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "APPR", "KON", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Aber alles Ach und Flehen", "tokens": ["A\u00b7ber", "al\u00b7les", "Ach", "und", "Fle\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ungeh\u00f6rt, unangesehen,", "tokens": ["Un\u00b7ge\u00b7h\u00f6rt", ",", "un\u00b7an\u00b7ge\u00b7se\u00b7hen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Thustu was Dein Schlu\u00df bestimmt,", "tokens": ["Thu\u00b7stu", "was", "Dein", "Schlu\u00df", "be\u00b7stimmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie, wann Mast und Ruder krachen,", "tokens": ["Wie", ",", "wann", "Mast", "und", "Ru\u00b7der", "kra\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aeolus f\u00fcr Sturm-erwachen", "tokens": ["A\u00b7e\u00b7o\u00b7lus", "f\u00fcr", "Stur\u00b7mer\u00b7wa\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["NE", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "G\u00e4ntzlich kein Gebeht vernimmt.", "tokens": ["G\u00e4ntz\u00b7lich", "kein", "Ge\u00b7beht", "ver\u00b7nimmt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Also wer in frembden Landen", "tokens": ["Al\u00b7so", "wer", "in", "fremb\u00b7den", "Lan\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PWS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist verkn\u00fcpfft in Liebes Banden,", "tokens": ["Ist", "ver\u00b7kn\u00fcpfft", "in", "Lie\u00b7bes", "Ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn die Braut Ihn kommen heisst,", "tokens": ["Wenn", "die", "Braut", "Ihn", "kom\u00b7men", "heisst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird Ihn nichts zu halten wissen,", "tokens": ["Wird", "Ihn", "nichts", "zu", "hal\u00b7ten", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIS", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bi\u00df Er sich der Freunde K\u00fcssen", "tokens": ["Bi\u00df", "Er", "sich", "der", "Freun\u00b7de", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "PRF", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Endlich mit Gewalt entreisst.", "tokens": ["End\u00b7lich", "mit", "Ge\u00b7walt", "en\u00b7treisst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Nun wir lassen Dich schon fahren,", "tokens": ["Nun", "wir", "las\u00b7sen", "Dich", "schon", "fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber alle Himmels-Scharen", "tokens": ["A\u00b7ber", "al\u00b7le", "Him\u00b7mels\u00b7Scha\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nehmen Dich in trewe Hut,", "tokens": ["Neh\u00b7men", "Dich", "in", "tre\u00b7we", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00fcssen au\u00df und ein Dich f\u00fchren!", "tokens": ["M\u00fcs\u00b7sen", "au\u00df", "und", "ein", "Dich", "f\u00fch\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "KON", "ART", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dessen nichts kan G\u00f6tter r\u00fchren,", "tokens": ["Des\u00b7sen", "nichts", "kan", "G\u00f6t\u00b7ter", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Was uns Menschen Schaden thut.", "tokens": ["Was", "uns", "Men\u00b7schen", "Scha\u00b7den", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Mars m\u00fcss' allen Grimm und Waffen,", "tokens": ["Mars", "m\u00fcss'", "al\u00b7len", "Grimm", "und", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn Du k\u00f6mpst, bey Seite schaffen,", "tokens": ["Wenn", "Du", "k\u00f6mpst", ",", "bey", "Sei\u00b7te", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "M\u00fcss', in deine Huld verliebt,", "tokens": ["M\u00fcss'", ",", "in", "dei\u00b7ne", "Huld", "ver\u00b7liebt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In ein Lachen stracks verkehren", "tokens": ["In", "ein", "La\u00b7chen", "stracks", "ver\u00b7keh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aller L\u00e4nder M\u00fch und Zehren,", "tokens": ["Al\u00b7ler", "L\u00e4n\u00b7der", "M\u00fch", "und", "Zeh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die Er jetzt noch sehr betr\u00fcbt!", "tokens": ["Die", "Er", "jetzt", "noch", "sehr", "be\u00b7tr\u00fcbt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Bring auff Aller Leid und Klagen,", "tokens": ["Bring", "auff", "Al\u00b7ler", "Leid", "und", "Kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Held, mit Dir hinau\u00df getragen", "tokens": ["Held", ",", "mit", "Dir", "hin\u00b7au\u00df", "ge\u00b7tra\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "PPER", "APZR", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wolstand, Gn\u00fcg und g\u00fcldne Rast!", "tokens": ["Wol\u00b7stand", ",", "Gn\u00fcg", "und", "g\u00fcld\u00b7ne", "Rast", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "KON", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Thue, was Dich die Sterne heissen,", "tokens": ["Thue", ",", "was", "Dich", "die", "Ster\u00b7ne", "heis\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wiss' nur, da\u00df Du auch in Preussen", "tokens": ["Wiss'", "nur", ",", "da\u00df", "Du", "auch", "in", "Preus\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "$,", "KOUS", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Viel von Deinem Hertzen hast!", "tokens": ["Viel", "von", "Dei\u00b7nem", "Hert\u00b7zen", "hast", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "K\u00f6nnen wir mit keinen Sachen,", "tokens": ["K\u00f6n\u00b7nen", "wir", "mit", "kei\u00b7nen", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Held, Dir l\u00e4nger Seumnis machen?", "tokens": ["Held", ",", "Dir", "l\u00e4n\u00b7ger", "Seum\u00b7nis", "ma\u00b7chen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "ADJD", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mu\u00df dein Auffbruch dann geschehn?", "tokens": ["Mu\u00df", "dein", "Auff\u00b7bruch", "dann", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ach was schaffstu uns f\u00fcr Schmertzen!", "tokens": ["Ach", "was", "schaffs\u00b7tu", "uns", "f\u00fcr", "Schmert\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und mit was betr\u00fcbtem Hertzen", "tokens": ["Und", "mit", "was", "be\u00b7tr\u00fcb\u00b7tem", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PRELS", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Zwingstu uns Dir nachzusehn!", "tokens": ["Zwings\u00b7tu", "uns", "Dir", "nach\u00b7zu\u00b7sehn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "O das Helm, Gescho\u00df und Degen", "tokens": ["O", "das", "Helm", ",", "Ge\u00b7scho\u00df", "und", "De\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ART", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und was Deutschland aller wegen", "tokens": ["Und", "was", "Deutschland", "al\u00b7ler", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "NN", "PIAT", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auff den Grund verw\u00fcstet hat,", "tokens": ["Auff", "den", "Grund", "ver\u00b7w\u00fcs\u00b7tet", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Umbgeschmoltzen wehr' in Pfl\u00fcge!", "tokens": ["U\u00b7mbge\u00b7schmolt\u00b7zen", "wehr'", "in", "Pfl\u00fc\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "O das Rhue f\u00fcr wilde Kriege", "tokens": ["O", "das", "Rhue", "f\u00fcr", "wil\u00b7de", "Krie\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hielt' umbschlossen Dorff und Stadt!", "tokens": ["Hielt'", "umbsc\u00b7hlos\u00b7sen", "Dorff", "und", "Stadt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Preussen k\u00f6nt' jetzt Dich behalten,", "tokens": ["Preus\u00b7sen", "k\u00f6nt'", "jetzt", "Dich", "be\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "D\u00f6rffte t\u00f6dtlich nicht erkalten,", "tokens": ["D\u00f6rff\u00b7te", "t\u00f6dt\u00b7lich", "nicht", "er\u00b7kal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun dein Sinn dahin gedenckt,", "tokens": ["Nun", "dein", "Sinn", "da\u00b7hin", "ge\u00b7denckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PAV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo-es-her Dich, sein Verlangen,", "tokens": ["Wo\u00b7es\u00b7her", "Dich", ",", "sein", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kurtz vor diesem hat empfangen", "tokens": ["Kurtz", "vor", "die\u00b7sem", "hat", "emp\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PDAT", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nur nicht auff den Todt gekr\u00e4nckt.", "tokens": ["Nur", "nicht", "auff", "den", "Todt", "ge\u00b7kr\u00e4nckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Deutschland wird es mir verzeihen,", "tokens": ["Deutschland", "wird", "es", "mir", "ver\u00b7zei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Fridrich Wilhelmen jhm leihen", "tokens": ["Frid\u00b7rich", "Wil\u00b7hel\u00b7men", "jhm", "lei\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "PPER", "VVINF"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Hat zu grosse Furcht und Pein.", "tokens": ["Hat", "zu", "gros\u00b7se", "Furcht", "und", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Brandenburg wird zweene melden", "tokens": ["Bran\u00b7den\u00b7burg", "wird", "zwee\u00b7ne", "mel\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VAFIN", "CARD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "So daselbst, O thewre Helden!", "tokens": ["So", "da\u00b7selbst", ",", "O", "thew\u00b7re", "Hel\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "$,", "NE", "ADJA", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Kurtz hievor verblichen seyn.", "tokens": ["Kurtz", "hie\u00b7vor", "ver\u00b7bli\u00b7chen", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PAV", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Du auch kuntest, einer Leichen", "tokens": ["Du", "auch", "kun\u00b7test", ",", "ei\u00b7ner", "Lei\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "PTKVZ", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schon gar \u00e4hnlich, kaum entweichen,", "tokens": ["Schon", "gar", "\u00e4hn\u00b7lich", ",", "kaum", "ent\u00b7wei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$,", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und man solte Furcht-loh\u00df stehn,", "tokens": ["Und", "man", "sol\u00b7te", "Furcht\u00b7loh\u00df", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun wir Dich sehn von uns scheiden?", "tokens": ["Nun", "wir", "Dich", "sehn", "von", "uns", "schei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PRF", "VVINF", "APPR", "PPER", "VVINF", "$."], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Sehn Dich Sicherheit hie meiden,", "tokens": ["Sehn", "Dich", "Si\u00b7cher\u00b7heit", "hie", "mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dort in Schwerd und Flamme gehn?", "tokens": ["Dort", "in", "Schwerd", "und", "Flam\u00b7me", "gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Nein, wir haben auff dein Leben", "tokens": ["Nein", ",", "wir", "ha\u00b7ben", "auff", "dein", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weit ein mehrers noch zu geben:", "tokens": ["Weit", "ein", "meh\u00b7rers", "noch", "zu", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Theseus war Athenen Zier,", "tokens": ["The\u00b7seus", "war", "A\u00b7the\u00b7nen", "Zier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hector noch zuletzt vorhanden,", "tokens": ["Hec\u00b7tor", "noch", "zu\u00b7letzt", "vor\u00b7han\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Worauff Trojen Reich bestanden,", "tokens": ["Wo\u00b7rauff", "Tro\u00b7jen", "Reich", "be\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "NE", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wir bestehn auff Gott und Dir.", "tokens": ["Wir", "be\u00b7stehn", "auff", "Gott", "und", "Dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Kan ich, bin ich recht bey Sinnen,", "tokens": ["Kan", "ich", ",", "bin", "ich", "recht", "bey", "Sin\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "VAFIN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch die Welt so lieb gewinnen,", "tokens": ["Auch", "die", "Welt", "so", "lieb", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich sollt' auf Deinen Todt", "tokens": ["Da\u00df", "ich", "sollt'", "auf", "Dei\u00b7nen", "Todt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "(den Gott ja nicht m\u00fcss' erleuben)", "tokens": ["(", "den", "Gott", "ja", "nicht", "m\u00fcss'", "er\u00b7leu\u00b7ben", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ADV", "PTKNEG", "VMFIN", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "L\u00e4nger wollen \u00fcbrig bleiben,", "tokens": ["L\u00e4n\u00b7ger", "wol\u00b7len", "\u00fcb\u00b7rig", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nur zu Hertzeleid' und Noht?", "tokens": ["Nur", "zu", "Hert\u00b7ze\u00b7leid'", "und", "Noht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Aber Lieb' und das Gebl\u00fcte", "tokens": ["A\u00b7ber", "Lieb'", "und", "das", "Ge\u00b7bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Reisst nur von uns Dein Gem\u00fcte,", "tokens": ["Reisst", "nur", "von", "uns", "Dein", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "PPOSAT", "NN", "$,"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.3": {"text": "Deine Marck hat Dich besiegt,", "tokens": ["Dei\u00b7ne", "Marck", "hat", "Dich", "be\u00b7siegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die von Leid' und Angst durchfahren", "tokens": ["Die", "von", "Leid'", "und", "Angst", "durch\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Blutig und mit freyen Haren", "tokens": ["Blu\u00b7tig", "und", "mit", "frey\u00b7en", "Ha\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dir zu sehr f\u00fcr Augen liegt.", "tokens": ["Dir", "zu", "sehr", "f\u00fcr", "Au\u00b7gen", "liegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKA", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Die zu Tag und Nacht mit Thr\u00e4nen", "tokens": ["Die", "zu", "Tag", "und", "Nacht", "mit", "Thr\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur nach Dir sich wei\u00df zu sehnen,", "tokens": ["Nur", "nach", "Dir", "sich", "wei\u00df", "zu", "seh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PRF", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Spricht: Wie lang doch, O mein Liecht,", "tokens": ["Spricht", ":", "Wie", "lang", "doch", ",", "O", "mein", "Liecht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PWAV", "ADJD", "ADV", "$,", "NE", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Suchstu noch mich au\u00dfzuschliessen?", "tokens": ["Suchs\u00b7tu", "noch", "mich", "au\u00df\u00b7zu\u00b7schlies\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sol ich ewig dann nicht wissen,", "tokens": ["Sol", "ich", "e\u00b7wig", "dann", "nicht", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ob ich Dein sey, oder nicht?", "tokens": ["Ob", "ich", "Dein", "sey", ",", "o\u00b7der", "nicht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "VAFIN", "$,", "KON", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Zehl die Unzahl meiner Wunden,", "tokens": ["Zehl", "die", "Un\u00b7zahl", "mei\u00b7ner", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So ich diese Jahr empfunden,", "tokens": ["So", "ich", "die\u00b7se", "Jahr", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "So wirst Du des Meeres Sand", "tokens": ["So", "wirst", "Du", "des", "Mee\u00b7res", "Sand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Leicht auch \u00fcberschlagen lernen,", "tokens": ["Leicht", "auch", "\u00fc\u00b7bersc\u00b7hla\u00b7gen", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ja die grosse Zahl der Sternen", "tokens": ["Ja", "die", "gros\u00b7se", "Zahl", "der", "Ster\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird dir nicht seyn unbekant.", "tokens": ["Wird", "dir", "nicht", "seyn", "un\u00b7be\u00b7kant", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VAINF", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Wenn hat mich nicht Glut verzehret?", "tokens": ["Wenn", "hat", "mich", "nicht", "Glut", "ver\u00b7zeh\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "PTKNEG", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wenn nicht Pest und Schwerd verheeret?", "tokens": ["Wenn", "nicht", "Pest", "und", "Schwerd", "ver\u00b7hee\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn nicht Rauben und Gefahr", "tokens": ["Wenn", "nicht", "Rau\u00b7ben", "und", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mir auff Marck und Bein getroffen?", "tokens": ["Mir", "auff", "Marck", "und", "Bein", "ge\u00b7trof\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer hat nicht mein Blut gesoffen,", "tokens": ["Wer", "hat", "nicht", "mein", "Blut", "ge\u00b7sof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PTKNEG", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Da\u00df ich nicht bin die ich war?", "tokens": ["Da\u00df", "ich", "nicht", "bin", "die", "ich", "war", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VAFIN", "ART", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "Gleichwol hab' ich alle Plagen", "tokens": ["Gleich\u00b7wol", "hab'", "ich", "al\u00b7le", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Immer mit Gedult ertragen,", "tokens": ["Im\u00b7mer", "mit", "Ge\u00b7dult", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur des grimmen Todes Macht,", "tokens": ["Nur", "des", "grim\u00b7men", "To\u00b7des", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die Drey F\u00fcrsten mir genommen", "tokens": ["Die", "Drey", "F\u00fcrs\u00b7ten", "mir", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "CARD", "NN", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Eh drey Jahr herumb seyn kommen,", "tokens": ["Eh", "drey", "Jahr", "he\u00b7rumb", "seyn", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "APZR", "VAINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat mich gantz von mir gebracht.", "tokens": ["Hat", "mich", "gantz", "von", "mir", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Nun bin ich erst allermassen,", "tokens": ["Nun", "bin", "ich", "erst", "al\u00b7ler\u00b7mas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hoch betr\u00fcbt und gantz verlassen,", "tokens": ["Hoch", "be\u00b7tr\u00fcbt", "und", "gantz", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "KON", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wann ich dir auch frembde bin;", "tokens": ["Wann", "ich", "dir", "auch", "fremb\u00b7de", "bin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ADJA", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sag, was ist doch mein Gebrechen?", "tokens": ["Sag", ",", "was", "ist", "doch", "mein", "Ge\u00b7bre\u00b7chen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Warumb mu\u00df dein Zorn sich rechen", "tokens": ["Wa\u00b7rumb", "mu\u00df", "dein", "Zorn", "sich", "re\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPOSAT", "NN", "PRF", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und lenckt von mir Deinen Sinn?", "tokens": ["Und", "lenckt", "von", "mir", "Dei\u00b7nen", "Sinn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PPOSAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.44": {"line.1": {"text": "Bin ich nicht f\u00fcr Gott mit Behten", "tokens": ["Bin", "ich", "nicht", "f\u00fcr", "Gott", "mit", "Beh\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "APPR", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Umb Dein Wolergehn getretten,", "tokens": ["Umb", "Dein", "Wo\u00b7ler\u00b7gehn", "ge\u00b7tret\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "So k\u00f6mpt recht mir diese Pein.", "tokens": ["So", "k\u00f6mpt", "recht", "mir", "die\u00b7se", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PPER", "PDAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ja ich wil auff aller Erden", "tokens": ["Ja", "ich", "wil", "auff", "al\u00b7ler", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PPER", "VMFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ein Gel\u00e4ch' und Schawspiel werden,", "tokens": ["Ein", "Ge\u00b7l\u00e4ch'", "und", "Schaw\u00b7spiel", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und der V\u00f6lcker M\u00e4hrlein seyn.", "tokens": ["Und", "der", "V\u00f6l\u00b7cker", "M\u00e4hr\u00b7lein", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Merckstu aber auff mein Flehen,", "tokens": ["Mercks\u00b7tu", "a\u00b7ber", "auff", "mein", "Fle\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Warumb mu\u00df ich Dich nicht sehen?", "tokens": ["Wa\u00b7rumb", "mu\u00df", "ich", "Dich", "nicht", "se\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist nur Preussen die Du liebst?", "tokens": ["Ist", "nur", "Preus\u00b7sen", "die", "Du", "liebst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "ART", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wormit hat sie Dich ber\u00fccket,", "tokens": ["Wor\u00b7mit", "hat", "sie", "Dich", "be\u00b7r\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df Du, gantz in jhr verstricket,", "tokens": ["Da\u00df", "Du", ",", "gantz", "in", "jhr", "ver\u00b7stri\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nichts auff mich, Dein Erbtheil, giebst?", "tokens": ["Nichts", "auff", "mich", ",", "Dein", "E\u00b7rbtheil", ",", "giebst", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "APPR", "PPER", "$,", "PPOSAT", "NN", "$,", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.46": {"line.1": {"text": "Ach vielleicht empfindstu Grawen", "tokens": ["Ach", "viel\u00b7leicht", "emp\u00b7finds\u00b7tu", "Gra\u00b7wen"], "token_info": ["word", "word", "word", "word"], "pos": ["ITJ", "ADV", "VVFIN", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mich die he\u00dflich' anzuschawen,", "tokens": ["Mich", "die", "he\u00df\u00b7lich'", "an\u00b7zu\u00b7scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVIZU", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Weil ich bin so w\u00fcst und leer?", "tokens": ["Weil", "ich", "bin", "so", "w\u00fcst", "und", "leer", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADV", "VVFIN", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Keiner weich' ich leicht an Gaben,", "tokens": ["Kei\u00b7ner", "weich'", "ich", "leicht", "an", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kan ich dich nur umb mich haben,", "tokens": ["Kan", "ich", "dich", "nur", "umb", "mich", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "APPR", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Komm, mit Dir k\u00f6mpt alles her!", "tokens": ["Komm", ",", "mit", "Dir", "k\u00f6mpt", "al\u00b7les", "her", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "PPER", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Herr, die Asche Deiner Ahnen,", "tokens": ["Herr", ",", "die", "A\u00b7sche", "Dei\u00b7ner", "Ah\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So die trewsten Unterthanen", "tokens": ["So", "die", "trew\u00b7sten", "Un\u00b7ter\u00b7tha\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bey mir fanden jederzeit,", "tokens": ["Bey", "mir", "fan\u00b7den", "je\u00b7der\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sol ein Zeugnu\u00df mir ablegen,", "tokens": ["Sol", "ein", "Zeug\u00b7nu\u00df", "mir", "ab\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ob du mich des Jammers wegen", "tokens": ["Ob", "du", "mich", "des", "Jam\u00b7mers", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Billich setzest an die Seit'.", "tokens": ["Bil\u00b7lich", "set\u00b7zest", "an", "die", "Seit'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Hat Dich sonst wer auffgenommen,", "tokens": ["Hat", "Dich", "sonst", "wer", "auff\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PWS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als Du an die\u00df' Liecht bist kommen?", "tokens": ["Als", "Du", "an", "die\u00df'", "Liecht", "bist", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer? Hab ich es nicht gethan?", "tokens": ["Wer", "?", "Hab", "ich", "es", "nicht", "ge\u00b7than", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "NN", "PPER", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df Du nach der Zeit dein Leben", "tokens": ["Da\u00df", "Du", "nach", "der", "Zeit", "dein", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Hie schier h\u00e4ttest auffgegeben,", "tokens": ["Hie", "schier", "h\u00e4t\u00b7test", "auff\u00b7ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Bin ich da wo schuldig an?", "tokens": ["Bin", "ich", "da", "wo", "schul\u00b7dig", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PWAV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Wer warff deinen Vater nieder?", "tokens": ["Wer", "warff", "dei\u00b7nen", "Va\u00b7ter", "nie\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Preussen gebe mir Ihn wieder,", "tokens": ["Preus\u00b7sen", "ge\u00b7be", "mir", "Ihn", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPER", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mir steht auch mein Urtheil frey.", "tokens": ["Mir", "steht", "auch", "mein", "Ur\u00b7theil", "frey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Was der Schlu\u00df des Himmels schaffet,", "tokens": ["Was", "der", "Schlu\u00df", "des", "Him\u00b7mels", "schaf\u00b7fet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der uns H\u00e4upter giebt und raffet,", "tokens": ["Der", "uns", "H\u00e4up\u00b7ter", "giebt", "und", "raf\u00b7fet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Misst man uns mit Unrecht bey.", "tokens": ["Misst", "man", "uns", "mit", "Un\u00b7recht", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "Ich bin nicht die ich gewesen,", "tokens": ["Ich", "bin", "nicht", "die", "ich", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "PRELS", "PPER", "VAPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Doch k\u00f6mpst Du, ich wil genesen,", "tokens": ["Doch", "k\u00f6mpst", "Du", ",", "ich", "wil", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Komm, weil noch ein Geist in mir!", "tokens": ["Komm", ",", "weil", "noch", "ein", "Geist", "in", "mir", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "ART", "NN", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6mpstu nicht, ich sterb' indessen,", "tokens": ["K\u00f6mps\u00b7tu", "nicht", ",", "ich", "sterb'", "in\u00b7des\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wem doch hastu zu-zu-m\u00e4ssen", "tokens": ["Wem", "doch", "has\u00b7tu", "zu\u00b7zu\u00b7m\u00e4s\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADV", "NE", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Meinen Untergang als Dir?", "tokens": ["Mei\u00b7nen", "Un\u00b7ter\u00b7gang", "als", "Dir", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOUS", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.51": {"line.1": {"text": "Herr, der ist von Stahl' und Steinen,", "tokens": ["Herr", ",", "der", "ist", "von", "Stahl'", "und", "Stei\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "VAFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welcher diese Klag' und Weinen", "tokens": ["Wel\u00b7cher", "die\u00b7se", "Klag'", "und", "Wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAT", "PDAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00f6rt mit unbewegtem Muth':", "tokens": ["H\u00f6rt", "mit", "un\u00b7be\u00b7weg\u00b7tem", "Muth'", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und Du solt Bedencken tragen,", "tokens": ["Und", "Du", "solt", "Be\u00b7den\u00b7cken", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Nach derselben Noht zu fragen,", "tokens": ["Nach", "der\u00b7sel\u00b7ben", "Noht", "zu", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die so sehnlich nach Dir thut?", "tokens": ["Die", "so", "sehn\u00b7lich", "nach", "Dir", "thut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "Es ist war, die lieben Leute", "tokens": ["Es", "ist", "war", ",", "die", "lie\u00b7ben", "Leu\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VAFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sind zu lang des Krieges Beute,", "tokens": ["Sind", "zu", "lang", "des", "Krie\u00b7ges", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKA", "ADJD", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sind zu lang ohn Gl\u00fcck und Rhue,", "tokens": ["Sind", "zu", "lang", "ohn", "Gl\u00fcck", "und", "Rhue", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKA", "ADJD", "APPR", "NN", "KON", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wolten gern sich wieder bawen,", "tokens": ["Wol\u00b7ten", "gern", "sich", "wie\u00b7der", "ba\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Wo sie einig noch auff schawen,", "tokens": ["Wo", "sie", "ei\u00b7nig", "noch", "auff", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "ADV", "APPR", "VVINF", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Sind nur unser Gott und Du.", "tokens": ["Sind", "nur", "un\u00b7ser", "Gott", "und", "Du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "KON", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.53": {"line.1": {"text": "Darumb bistu nicht zu hindern,", "tokens": ["Da\u00b7rumb", "bis\u00b7tu", "nicht", "zu", "hin\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "Nichts mu\u00df deinen Vorsatz mindern.", "tokens": ["Nichts", "mu\u00df", "dei\u00b7nen", "Vor\u00b7satz", "min\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Du gestehst uns kaum ein Wort.", "tokens": ["Du", "ge\u00b7stehst", "uns", "kaum", "ein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Deine Wagen-Rosse schreyen,", "tokens": ["Dei\u00b7ne", "Wa\u00b7gen\u00b7Ros\u00b7se", "schre\u00b7yen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Dein Geleit, die Preussschen Freyen", "tokens": ["Dein", "Ge\u00b7leit", ",", "die", "Preuss\u00b7schen", "Frey\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sampt der Leib-Hut ist schon fort.", "tokens": ["Sampt", "der", "Leib\u00b7Hut", "ist", "schon", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "+-++--+", "measure": "iambic.tetra.chol"}}, "stanza.54": {"line.1": {"text": "Was h\u00f6r ich f\u00fcr Leid und Heulen?", "tokens": ["Was", "h\u00f6r", "ich", "f\u00fcr", "Leid", "und", "Heu\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mustu denn so von uns eilen?", "tokens": ["Mus\u00b7tu", "denn", "so", "von", "uns", "ei\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Spricht die M\u00fctterliche Trew.", "tokens": ["Spricht", "die", "M\u00fct\u00b7ter\u00b7li\u00b7che", "Trew", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und man wei\u00df f\u00fcr Weh und Klagen", "tokens": ["Und", "man", "wei\u00df", "f\u00fcr", "Weh", "und", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dir kaum gutte Nacht zu sagen,", "tokens": ["Dir", "kaum", "gut\u00b7te", "Nacht", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Alles f\u00fchret nur Geschrey.", "tokens": ["Al\u00b7les", "f\u00fch\u00b7ret", "nur", "Ge\u00b7schrey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.55": {"line.1": {"text": "Deine Schwestern, die G\u00f6ttinnen,", "tokens": ["Dei\u00b7ne", "Schwes\u00b7tern", ",", "die", "G\u00f6t\u00b7tin\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nnen sich nicht eins besinnen,", "tokens": ["K\u00f6n\u00b7nen", "sich", "nicht", "eins", "be\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "PTKNEG", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was mit Ihnen jetzt geschieht:", "tokens": ["Was", "mit", "Ih\u00b7nen", "jetzt", "ge\u00b7schieht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die Fraw Mutter kan bey weiten", "tokens": ["Die", "Fraw", "Mut\u00b7ter", "kan", "bey", "wei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VMFIN", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dich f\u00fcr Wehmut nicht geleiten,", "tokens": ["Dich", "f\u00fcr", "Weh\u00b7mut", "nicht", "ge\u00b7lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So man umb und an Ihr sieht.", "tokens": ["So", "man", "umb", "und", "an", "Ihr", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "APPR", "KON", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.56": {"line.1": {"text": "Aber alles Ach und Flehen", "tokens": ["A\u00b7ber", "al\u00b7les", "Ach", "und", "Fle\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ungeh\u00f6rt, unangesehen,", "tokens": ["Un\u00b7ge\u00b7h\u00f6rt", ",", "un\u00b7an\u00b7ge\u00b7se\u00b7hen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Thustu was Dein Schlu\u00df bestimmt,", "tokens": ["Thu\u00b7stu", "was", "Dein", "Schlu\u00df", "be\u00b7stimmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie, wann Mast und Ruder krachen,", "tokens": ["Wie", ",", "wann", "Mast", "und", "Ru\u00b7der", "kra\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aeolus f\u00fcr Sturm-erwachen", "tokens": ["A\u00b7e\u00b7o\u00b7lus", "f\u00fcr", "Stur\u00b7mer\u00b7wa\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["NE", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "G\u00e4ntzlich kein Gebeht vernimmt.", "tokens": ["G\u00e4ntz\u00b7lich", "kein", "Ge\u00b7beht", "ver\u00b7nimmt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.57": {"line.1": {"text": "Also wer in frembden Landen", "tokens": ["Al\u00b7so", "wer", "in", "fremb\u00b7den", "Lan\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PWS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist verkn\u00fcpfft in Liebes Banden,", "tokens": ["Ist", "ver\u00b7kn\u00fcpfft", "in", "Lie\u00b7bes", "Ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn die Braut Ihn kommen heisst,", "tokens": ["Wenn", "die", "Braut", "Ihn", "kom\u00b7men", "heisst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird Ihn nichts zu halten wissen,", "tokens": ["Wird", "Ihn", "nichts", "zu", "hal\u00b7ten", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIS", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bi\u00df Er sich der Freunde K\u00fcssen", "tokens": ["Bi\u00df", "Er", "sich", "der", "Freun\u00b7de", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "PRF", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Endlich mit Gewalt entreisst.", "tokens": ["End\u00b7lich", "mit", "Ge\u00b7walt", "en\u00b7treisst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "Nun wir lassen Dich schon fahren,", "tokens": ["Nun", "wir", "las\u00b7sen", "Dich", "schon", "fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber alle Himmels-Scharen", "tokens": ["A\u00b7ber", "al\u00b7le", "Him\u00b7mels\u00b7Scha\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nehmen Dich in trewe Hut,", "tokens": ["Neh\u00b7men", "Dich", "in", "tre\u00b7we", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00fcssen au\u00df und ein Dich f\u00fchren!", "tokens": ["M\u00fcs\u00b7sen", "au\u00df", "und", "ein", "Dich", "f\u00fch\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "KON", "ART", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dessen nichts kan G\u00f6tter r\u00fchren,", "tokens": ["Des\u00b7sen", "nichts", "kan", "G\u00f6t\u00b7ter", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Was uns Menschen Schaden thut.", "tokens": ["Was", "uns", "Men\u00b7schen", "Scha\u00b7den", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.59": {"line.1": {"text": "Mars m\u00fcss' allen Grimm und Waffen,", "tokens": ["Mars", "m\u00fcss'", "al\u00b7len", "Grimm", "und", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn Du k\u00f6mpst, bey Seite schaffen,", "tokens": ["Wenn", "Du", "k\u00f6mpst", ",", "bey", "Sei\u00b7te", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "M\u00fcss', in deine Huld verliebt,", "tokens": ["M\u00fcss'", ",", "in", "dei\u00b7ne", "Huld", "ver\u00b7liebt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In ein Lachen stracks verkehren", "tokens": ["In", "ein", "La\u00b7chen", "stracks", "ver\u00b7keh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aller L\u00e4nder M\u00fch und Zehren,", "tokens": ["Al\u00b7ler", "L\u00e4n\u00b7der", "M\u00fch", "und", "Zeh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die Er jetzt noch sehr betr\u00fcbt!", "tokens": ["Die", "Er", "jetzt", "noch", "sehr", "be\u00b7tr\u00fcbt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.60": {"line.1": {"text": "Bring auff Aller Leid und Klagen,", "tokens": ["Bring", "auff", "Al\u00b7ler", "Leid", "und", "Kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Held, mit Dir hinau\u00df getragen", "tokens": ["Held", ",", "mit", "Dir", "hin\u00b7au\u00df", "ge\u00b7tra\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "PPER", "APZR", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wolstand, Gn\u00fcg und g\u00fcldne Rast!", "tokens": ["Wol\u00b7stand", ",", "Gn\u00fcg", "und", "g\u00fcld\u00b7ne", "Rast", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "KON", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Thue, was Dich die Sterne heissen,", "tokens": ["Thue", ",", "was", "Dich", "die", "Ster\u00b7ne", "heis\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wiss' nur, da\u00df Du auch in Preussen", "tokens": ["Wiss'", "nur", ",", "da\u00df", "Du", "auch", "in", "Preus\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "$,", "KOUS", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Viel von Deinem Hertzen hast!", "tokens": ["Viel", "von", "Dei\u00b7nem", "Hert\u00b7zen", "hast", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}