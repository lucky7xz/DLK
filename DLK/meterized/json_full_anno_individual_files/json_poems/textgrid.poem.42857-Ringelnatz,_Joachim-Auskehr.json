{"textgrid.poem.42857": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Auskehr", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schundige, verbrauchte Besen wollen,", "tokens": ["Schun\u00b7di\u00b7ge", ",", "ver\u00b7brauch\u00b7te", "Be\u00b7sen", "wol\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "VMFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Nur aus schmutzig-dunklem Hintergrund:", "tokens": ["Nur", "aus", "schmut\u00b7zig\u00b7dunk\u00b7lem", "Hin\u00b7ter\u00b7grund", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Mummgedachte dummgemachte Menschen sollen", "tokens": ["Mumm\u00b7ge\u00b7dach\u00b7te", "dumm\u00b7ge\u00b7mach\u00b7te", "Men\u00b7schen", "sol\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "VMFIN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Ihnen helfen gegen Schmutz und Schund.", "tokens": ["Ih\u00b7nen", "hel\u00b7fen", "ge\u00b7gen", "Schmutz", "und", "Schund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Wollen also scheinbar Stra\u00dfen reinigen,", "tokens": ["Wol\u00b7len", "al\u00b7so", "schein\u00b7bar", "Stra\u00b7\u00dfen", "rei\u00b7ni\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Nicht vor eigner T\u00fcre, nein! O nein!", "tokens": ["Nicht", "vor", "eig\u00b7ner", "T\u00fc\u00b7re", ",", "nein", "!", "O", "nein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "$,", "PTKANT", "$.", "NE", "PTKANT", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Herrschen wollen sie und peinigen.", "tokens": ["Herr\u00b7schen", "wol\u00b7len", "sie", "und", "pei\u00b7ni\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "KON", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Denn man sah in ihren Stiel hinein.", "tokens": ["Denn", "man", "sah", "in", "ih\u00b7ren", "Stiel", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Und da fand man in den Stielen Knuten", "tokens": ["Und", "da", "fand", "man", "in", "den", "Stie\u00b7len", "Knu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Aus der mittelalterlichsten Zeit.", "tokens": ["Aus", "der", "mit\u00b7tel\u00b7al\u00b7ter\u00b7lichs\u00b7ten", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und wir andern m\u00fcssen uns nun sputen,", "tokens": ["Und", "wir", "an\u00b7dern", "m\u00fcs\u00b7sen", "uns", "nun", "spu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIS", "VMFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Denn die Besen stehen kampfbereit.", "tokens": ["Denn", "die", "Be\u00b7sen", "ste\u00b7hen", "kampf\u00b7be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Sagen wir nur: Nein!", "tokens": ["Sa\u00b7gen", "wir", "nur", ":", "Nein", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$.", "PTKANT", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "In die Ecke, Besen, Besen!", "tokens": ["In", "die", "E\u00b7cke", ",", "Be\u00b7sen", ",", "Be\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In dem Dreck, wo ihr gewesen", "tokens": ["In", "dem", "Dreck", ",", "wo", "ihr", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PWAV", "PPER", "VAPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seid, macht euern Dreck allein!", "tokens": ["Seid", ",", "macht", "eu\u00b7ern", "Dreck", "al\u00b7lein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "$,", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nicht verhandeln.", "tokens": ["Nicht", "ver\u00b7han\u00b7deln", "."], "token_info": ["word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Denn wir wollen rein,", "tokens": ["Denn", "wir", "wol\u00b7len", "rein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Auch durch Schmutz und Schund, in Freiheit wandeln.", "tokens": ["Auch", "durch", "Schmutz", "und", "Schund", ",", "in", "Frei\u00b7heit", "wan\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Schundige, verbrauchte Besen wollen,", "tokens": ["Schun\u00b7di\u00b7ge", ",", "ver\u00b7brauch\u00b7te", "Be\u00b7sen", "wol\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "VMFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Nur aus schmutzig-dunklem Hintergrund:", "tokens": ["Nur", "aus", "schmut\u00b7zig\u00b7dunk\u00b7lem", "Hin\u00b7ter\u00b7grund", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Mummgedachte dummgemachte Menschen sollen", "tokens": ["Mumm\u00b7ge\u00b7dach\u00b7te", "dumm\u00b7ge\u00b7mach\u00b7te", "Men\u00b7schen", "sol\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "VMFIN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Ihnen helfen gegen Schmutz und Schund.", "tokens": ["Ih\u00b7nen", "hel\u00b7fen", "ge\u00b7gen", "Schmutz", "und", "Schund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Wollen also scheinbar Stra\u00dfen reinigen,", "tokens": ["Wol\u00b7len", "al\u00b7so", "schein\u00b7bar", "Stra\u00b7\u00dfen", "rei\u00b7ni\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Nicht vor eigner T\u00fcre, nein! O nein!", "tokens": ["Nicht", "vor", "eig\u00b7ner", "T\u00fc\u00b7re", ",", "nein", "!", "O", "nein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "$,", "PTKANT", "$.", "NE", "PTKANT", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Herrschen wollen sie und peinigen.", "tokens": ["Herr\u00b7schen", "wol\u00b7len", "sie", "und", "pei\u00b7ni\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "KON", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Denn man sah in ihren Stiel hinein.", "tokens": ["Denn", "man", "sah", "in", "ih\u00b7ren", "Stiel", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Und da fand man in den Stielen Knuten", "tokens": ["Und", "da", "fand", "man", "in", "den", "Stie\u00b7len", "Knu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Aus der mittelalterlichsten Zeit.", "tokens": ["Aus", "der", "mit\u00b7tel\u00b7al\u00b7ter\u00b7lichs\u00b7ten", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und wir andern m\u00fcssen uns nun sputen,", "tokens": ["Und", "wir", "an\u00b7dern", "m\u00fcs\u00b7sen", "uns", "nun", "spu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIS", "VMFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Denn die Besen stehen kampfbereit.", "tokens": ["Denn", "die", "Be\u00b7sen", "ste\u00b7hen", "kampf\u00b7be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Sagen wir nur: Nein!", "tokens": ["Sa\u00b7gen", "wir", "nur", ":", "Nein", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$.", "PTKANT", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "In die Ecke, Besen, Besen!", "tokens": ["In", "die", "E\u00b7cke", ",", "Be\u00b7sen", ",", "Be\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In dem Dreck, wo ihr gewesen", "tokens": ["In", "dem", "Dreck", ",", "wo", "ihr", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PWAV", "PPER", "VAPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seid, macht euern Dreck allein!", "tokens": ["Seid", ",", "macht", "eu\u00b7ern", "Dreck", "al\u00b7lein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "$,", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nicht verhandeln.", "tokens": ["Nicht", "ver\u00b7han\u00b7deln", "."], "token_info": ["word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Denn wir wollen rein,", "tokens": ["Denn", "wir", "wol\u00b7len", "rein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Auch durch Schmutz und Schund, in Freiheit wandeln.", "tokens": ["Auch", "durch", "Schmutz", "und", "Schund", ",", "in", "Frei\u00b7heit", "wan\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}