{"textgrid.poem.26371": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "[und Montags bin ich aufgewacht]", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und Montags bin ich aufgewacht,", "tokens": ["Und", "Mon\u00b7tags", "bin", "ich", "auf\u00b7ge\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Zimmer hat ganz laut gelacht.", "tokens": ["Mein", "Zim\u00b7mer", "hat", "ganz", "laut", "ge\u00b7lacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Sah, da\u00df ich schwarz im Gehrock steckte,", "tokens": ["Sah", ",", "da\u00df", "ich", "schwarz", "im", "Ge\u00b7hrock", "steck\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als w\u00e4r's ein Sarg, mich darin streckte,", "tokens": ["Als", "w\u00e4r's", "ein", "Sarg", ",", "mich", "da\u00b7rin", "streck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NN", "$,", "PRF", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Im Knopfloch einen Stiel der Rose,", "tokens": ["Im", "Kno\u00b7pfloch", "ei\u00b7nen", "Stiel", "der", "Ro\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Schaumweinflecken auf der Hose.", "tokens": ["Und", "Schaum\u00b7wein\u00b7fle\u00b7cken", "auf", "der", "Ho\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Verlobung war gefeiert worden,", "tokens": ["Ver\u00b7lo\u00b7bung", "war", "ge\u00b7fei\u00b7ert", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Deshalb am Leib die Schaumweinorden.", "tokens": ["Des\u00b7halb", "am", "Leib", "die", "Schaum\u00b7wein\u00b7or\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Als P.T.s bester Kamerad", "tokens": ["Als", "P.", "T.", "s", "bes\u00b7ter", "Ka\u00b7me\u00b7rad"], "token_info": ["word", "abbreviation", "abbreviation", "word", "word", "word"], "pos": ["KOUS", "NE", "NE", "NE", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00dfte ich kommen ohne Gnad',", "tokens": ["Mu\u00df\u00b7te", "ich", "kom\u00b7men", "oh\u00b7ne", "Gnad'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Die Braut sagte in aller Huld,", "tokens": ["Die", "Braut", "sag\u00b7te", "in", "al\u00b7ler", "Huld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich sei an der Verlobung schuld.", "tokens": ["Ich", "sei", "an", "der", "Ver\u00b7lo\u00b7bung", "schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADJD", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.7": {"line.1": {"text": "O Kaspar Melchior Balthasar,", "tokens": ["O", "Kas\u00b7par", "Melc\u00b7hi\u00b7or", "Balt\u00b7ha\u00b7sar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und \u00fcberlebst du tausend Jahr,", "tokens": ["Und", "\u00fc\u00b7ber\u00b7lebst", "du", "tau\u00b7send", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Den Stuhl, den wirst du nie vergessen,", "tokens": ["Den", "Stuhl", ",", "den", "wirst", "du", "nie", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf dem du heute festgegessen!", "tokens": ["Auf", "dem", "du", "heu\u00b7te", "fest\u00b7ge\u00b7ges\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Wie hast du seine Bein' gedr\u00fcckt,", "tokens": ["Wie", "hast", "du", "sei\u00b7ne", "Bein'", "ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn dich die Tr\u00e4ne tief gezwickt.", "tokens": ["Wenn", "dich", "die", "Tr\u00e4\u00b7ne", "tief", "ge\u00b7zwickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Doch l\u00e4chelnd hast du dich gehalten,", "tokens": ["Doch", "l\u00e4\u00b7chelnd", "hast", "du", "dich", "ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du machtest nur Serviettenfalten.", "tokens": ["Du", "mach\u00b7test", "nur", "Ser\u00b7viet\u00b7ten\u00b7fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Und jetzt ersah ich meine Finger:", "tokens": ["Und", "jetzt", "er\u00b7sah", "ich", "mei\u00b7ne", "Fin\u00b7ger", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer waren diese schwarzen Dinger,", "tokens": ["Wer", "wa\u00b7ren", "die\u00b7se", "schwar\u00b7zen", "Din\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Wie schwarze W\u00fcrstlein anzusehn?", "tokens": ["Wie", "schwar\u00b7ze", "W\u00fcrst\u00b7lein", "an\u00b7zu\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schon wieder war etwas geschehn:", "tokens": ["Schon", "wie\u00b7der", "war", "et\u00b7was", "ge\u00b7schehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Ein Aschenregen in den Zimmern,", "tokens": ["Ein", "A\u00b7schen\u00b7re\u00b7gen", "in", "den", "Zim\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Taschentuch verkohlt, in Tr\u00fcmmern.", "tokens": ["Ein", "Ta\u00b7schen\u00b7tuch", "ver\u00b7kohlt", ",", "in", "Tr\u00fcm\u00b7mern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Und alles um mich sprach es klar,", "tokens": ["Und", "al\u00b7les", "um", "mich", "sprach", "es", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In diesen Zimmern Feuer war.", "tokens": ["In", "die\u00b7sen", "Zim\u00b7mern", "Feu\u00b7er", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Denn gleich nach dem Verlobungsessen,", "tokens": ["Denn", "gleich", "nach", "dem", "Ver\u00b7lo\u00b7bung\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo ich im Folterstuhl gesessen,", "tokens": ["Wo", "ich", "im", "Fol\u00b7ter\u00b7stuhl", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Bin ich bei Nacht nach Haus gerannt", "tokens": ["Bin", "ich", "bei", "Nacht", "nach", "Haus", "ge\u00b7rannt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "NN", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hab' mein Zimmer angebrannt.", "tokens": ["Und", "hab'", "mein", "Zim\u00b7mer", "an\u00b7ge\u00b7brannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Denn diese Ruh', die ich erzwungen,", "tokens": ["Denn", "die\u00b7se", "Ruh'", ",", "die", "ich", "er\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hat zum Schlu\u00df darauf gedrungen,", "tokens": ["Sie", "hat", "zum", "Schlu\u00df", "da\u00b7rauf", "ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Es mu\u00dfte irgendwas geschehn,", "tokens": ["Es", "mu\u00df\u00b7te", "ir\u00b7gend\u00b7was", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Blut mu\u00dft' ich oder Feuer sehn.", "tokens": ["Blut", "mu\u00dft'", "ich", "o\u00b7der", "Feu\u00b7er", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "KON", "NN", "VVINF", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Man kann nicht immer Wasser flennen,", "tokens": ["Man", "kann", "nicht", "im\u00b7mer", "Was\u00b7ser", "flen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PTKNEG", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Manch Schmerz will durch den Schornstein rennen.", "tokens": ["Manch", "Schmerz", "will", "durch", "den", "Schorn\u00b7stein", "ren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Warf mich im Sofa in die Kissen", "tokens": ["Warf", "mich", "im", "So\u00b7fa", "in", "die", "Kis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Und hab' mit Z\u00e4hnen sie zerrissen,", "tokens": ["Und", "hab'", "mit", "Z\u00e4h\u00b7nen", "sie", "zer\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Hielt meine Finger in das Licht:", "tokens": ["Hielt", "mei\u00b7ne", "Fin\u00b7ger", "in", "das", "Licht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie wurden schwarz, ich sp\u00fcrt' es nicht;", "tokens": ["Sie", "wur\u00b7den", "schwarz", ",", "ich", "sp\u00fcrt'", "es", "nicht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Lie\u00df Taschentuch, Manschetten braten,", "tokens": ["Lie\u00df", "Ta\u00b7schen\u00b7tuch", ",", "Man\u00b7schet\u00b7ten", "bra\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weil Flammen wohl den Augen taten;", "tokens": ["Weil", "Flam\u00b7men", "wohl", "den", "Au\u00b7gen", "ta\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Fiel auf dem Fleck in tiefen Schlaf,", "tokens": ["Fiel", "auf", "dem", "Fleck", "in", "tie\u00b7fen", "Schlaf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo mich ein neues Elend traf.", "tokens": ["Wo", "mich", "ein", "neu\u00b7es", "E\u00b7lend", "traf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Wohl schlug ich mir Frau K\u00f6nigin", "tokens": ["Wohl", "schlug", "ich", "mir", "Frau", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Am hellen Tag aus meinem Sinn,", "tokens": ["Am", "hel\u00b7len", "Tag", "aus", "mei\u00b7nem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Doch nachts im s\u00fc\u00dfen Schlafgefilde", "tokens": ["Doch", "nachts", "im", "s\u00fc\u00b7\u00dfen", "Schlaf\u00b7ge\u00b7fil\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schlich sie sich ein als Traumgebilde.", "tokens": ["Schlich", "sie", "sich", "ein", "als", "Traum\u00b7ge\u00b7bil\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "PRF", "ART", "KOUS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Diesmal kam sie als kleine Katz'", "tokens": ["Dies\u00b7mal", "kam", "sie", "als", "klei\u00b7ne", "Katz'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und nahm mir meinen Sofaplatz,", "tokens": ["Und", "nahm", "mir", "mei\u00b7nen", "Sof\u00b7a\u00b7platz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Ich kraute und liebkoste sie,", "tokens": ["Ich", "krau\u00b7te", "und", "lieb\u00b7kos\u00b7te", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Indes sie Zetermordio schrie,", "tokens": ["In\u00b7des", "sie", "Ze\u00b7ter\u00b7mor\u00b7dio", "schrie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Doch ich verstand nicht ihr Geschrei;", "tokens": ["Doch", "ich", "ver\u00b7stand", "nicht", "ihr", "Ge\u00b7schrei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da h\u00f6rt' ich Stimmen nebenbei,", "tokens": ["Da", "h\u00f6rt'", "ich", "Stim\u00b7men", "ne\u00b7ben\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Die sagten: \u00bbK\u00e4tzchen ist ja krank!\u00ab", "tokens": ["Die", "sag\u00b7ten", ":", "\u00bb", "K\u00e4tz\u00b7chen", "ist", "ja", "krank", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "$.", "$(", "NE", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich ging zu einem W\u00e4scheschrank,", "tokens": ["Ich", "ging", "zu", "ei\u00b7nem", "W\u00e4\u00b7sche\u00b7schrank", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Legt' Handt\u00fccher um meine Katz',", "tokens": ["Legt'", "Hand\u00b7t\u00fc\u00b7cher", "um", "mei\u00b7ne", "Katz'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Doch sie entschl\u00fcpft mit einem Satz,", "tokens": ["Doch", "sie", "ent\u00b7schl\u00fcpft", "mit", "ei\u00b7nem", "Satz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Sie wendet ihr Gesicht mir hin:", "tokens": ["Sie", "wen\u00b7det", "ihr", "Ge\u00b7sicht", "mir", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Kopf war's der Frau K\u00f6nigin.", "tokens": ["Der", "Kopf", "wa\u00b7r's", "der", "Frau", "K\u00f6\u00b7ni\u00b7gin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.32": {"line.1": {"text": "Ein Menschenkopf am Katzenleib,", "tokens": ["Ein", "Men\u00b7schen\u00b7kopf", "am", "Kat\u00b7zen\u00b7leib", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und dieses war mein Lieblingsweib!", "tokens": ["Und", "die\u00b7ses", "war", "mein", "Lieb\u00b7lings\u00b7weib", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Drau\u00dfen mit hochgehobenen Schweifen", "tokens": ["Drau\u00b7\u00dfen", "mit", "hoch\u00b7ge\u00b7ho\u00b7be\u00b7nen", "Schwei\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Sah Kater ich ums Fenster streifen;", "tokens": ["Sah", "Ka\u00b7ter", "ich", "ums", "Fens\u00b7ter", "strei\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Schmerzlich tat sich das K\u00e4tzchen recken", "tokens": ["Schmerz\u00b7lich", "tat", "sich", "das", "K\u00e4tz\u00b7chen", "re\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PRF", "ART", "NN", "VVINF"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Und tot die viere von sich strecken.", "tokens": ["Und", "tot", "die", "vie\u00b7re", "von", "sich", "stre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "PIS", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Da ward mein Herz ein kahler Fleck,", "tokens": ["Da", "ward", "mein", "Herz", "ein", "kah\u00b7ler", "Fleck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ganze Welt lag mir im Dreck,", "tokens": ["Die", "gan\u00b7ze", "Welt", "lag", "mir", "im", "Dreck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Im dunkeln Hof auf Pflastersteinen", "tokens": ["Im", "dun\u00b7keln", "Hof", "auf", "Pflas\u00b7ter\u00b7stei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sa\u00df ich und mu\u00dfte bitter weinen.", "tokens": ["Sa\u00df", "ich", "und", "mu\u00df\u00b7te", "bit\u00b7ter", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Ich wachte auf, erkenn' den Traum;", "tokens": ["Ich", "wach\u00b7te", "auf", ",", "er\u00b7kenn'", "den", "Traum", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch dieses tr\u00f6stete mich kaum.", "tokens": ["Auch", "die\u00b7ses", "tr\u00f6s\u00b7te\u00b7te", "mich", "kaum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Ich mu\u00dfte es mir eingestehn:", "tokens": ["Ich", "mu\u00df\u00b7te", "es", "mir", "ein\u00b7ge\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Unheimliches wird noch geschehn.", "tokens": ["Un\u00b7heim\u00b7li\u00b7ches", "wird", "noch", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Jetzt, Balzer, schn\u00fcr' den Kofferriemen,", "tokens": ["Jetzt", ",", "Bal\u00b7zer", ",", "schn\u00fcr'", "den", "Kof\u00b7fer\u00b7rie\u00b7men", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sonst mu\u00dft du hier noch weitermimen.", "tokens": ["Sonst", "mu\u00dft", "du", "hier", "noch", "wei\u00b7ter\u00b7mi\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Man soll sich nicht ans Ungl\u00fcck binden,", "tokens": ["Man", "soll", "sich", "nicht", "ans", "Un\u00b7gl\u00fcck", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "PTKNEG", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du mu\u00dft dich schnell ins Reisen finden.", "tokens": ["Du", "mu\u00dft", "dich", "schnell", "ins", "Rei\u00b7sen", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Und Montags bin ich aufgewacht,", "tokens": ["Und", "Mon\u00b7tags", "bin", "ich", "auf\u00b7ge\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Zimmer hat ganz laut gelacht.", "tokens": ["Mein", "Zim\u00b7mer", "hat", "ganz", "laut", "ge\u00b7lacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Sah, da\u00df ich schwarz im Gehrock steckte,", "tokens": ["Sah", ",", "da\u00df", "ich", "schwarz", "im", "Ge\u00b7hrock", "steck\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als w\u00e4r's ein Sarg, mich darin streckte,", "tokens": ["Als", "w\u00e4r's", "ein", "Sarg", ",", "mich", "da\u00b7rin", "streck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NN", "$,", "PRF", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Im Knopfloch einen Stiel der Rose,", "tokens": ["Im", "Kno\u00b7pfloch", "ei\u00b7nen", "Stiel", "der", "Ro\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Schaumweinflecken auf der Hose.", "tokens": ["Und", "Schaum\u00b7wein\u00b7fle\u00b7cken", "auf", "der", "Ho\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Verlobung war gefeiert worden,", "tokens": ["Ver\u00b7lo\u00b7bung", "war", "ge\u00b7fei\u00b7ert", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Deshalb am Leib die Schaumweinorden.", "tokens": ["Des\u00b7halb", "am", "Leib", "die", "Schaum\u00b7wein\u00b7or\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Als P.T.s bester Kamerad", "tokens": ["Als", "P.", "T.", "s", "bes\u00b7ter", "Ka\u00b7me\u00b7rad"], "token_info": ["word", "abbreviation", "abbreviation", "word", "word", "word"], "pos": ["KOUS", "NE", "NE", "NE", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00dfte ich kommen ohne Gnad',", "tokens": ["Mu\u00df\u00b7te", "ich", "kom\u00b7men", "oh\u00b7ne", "Gnad'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.46": {"line.1": {"text": "Die Braut sagte in aller Huld,", "tokens": ["Die", "Braut", "sag\u00b7te", "in", "al\u00b7ler", "Huld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich sei an der Verlobung schuld.", "tokens": ["Ich", "sei", "an", "der", "Ver\u00b7lo\u00b7bung", "schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADJD", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.47": {"line.1": {"text": "O Kaspar Melchior Balthasar,", "tokens": ["O", "Kas\u00b7par", "Melc\u00b7hi\u00b7or", "Balt\u00b7ha\u00b7sar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und \u00fcberlebst du tausend Jahr,", "tokens": ["Und", "\u00fc\u00b7ber\u00b7lebst", "du", "tau\u00b7send", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Den Stuhl, den wirst du nie vergessen,", "tokens": ["Den", "Stuhl", ",", "den", "wirst", "du", "nie", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf dem du heute festgegessen!", "tokens": ["Auf", "dem", "du", "heu\u00b7te", "fest\u00b7ge\u00b7ges\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Wie hast du seine Bein' gedr\u00fcckt,", "tokens": ["Wie", "hast", "du", "sei\u00b7ne", "Bein'", "ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn dich die Tr\u00e4ne tief gezwickt.", "tokens": ["Wenn", "dich", "die", "Tr\u00e4\u00b7ne", "tief", "ge\u00b7zwickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Doch l\u00e4chelnd hast du dich gehalten,", "tokens": ["Doch", "l\u00e4\u00b7chelnd", "hast", "du", "dich", "ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du machtest nur Serviettenfalten.", "tokens": ["Du", "mach\u00b7test", "nur", "Ser\u00b7viet\u00b7ten\u00b7fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Und jetzt ersah ich meine Finger:", "tokens": ["Und", "jetzt", "er\u00b7sah", "ich", "mei\u00b7ne", "Fin\u00b7ger", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer waren diese schwarzen Dinger,", "tokens": ["Wer", "wa\u00b7ren", "die\u00b7se", "schwar\u00b7zen", "Din\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Wie schwarze W\u00fcrstlein anzusehn?", "tokens": ["Wie", "schwar\u00b7ze", "W\u00fcrst\u00b7lein", "an\u00b7zu\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schon wieder war etwas geschehn:", "tokens": ["Schon", "wie\u00b7der", "war", "et\u00b7was", "ge\u00b7schehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Ein Aschenregen in den Zimmern,", "tokens": ["Ein", "A\u00b7schen\u00b7re\u00b7gen", "in", "den", "Zim\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Taschentuch verkohlt, in Tr\u00fcmmern.", "tokens": ["Ein", "Ta\u00b7schen\u00b7tuch", "ver\u00b7kohlt", ",", "in", "Tr\u00fcm\u00b7mern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Und alles um mich sprach es klar,", "tokens": ["Und", "al\u00b7les", "um", "mich", "sprach", "es", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In diesen Zimmern Feuer war.", "tokens": ["In", "die\u00b7sen", "Zim\u00b7mern", "Feu\u00b7er", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Denn gleich nach dem Verlobungsessen,", "tokens": ["Denn", "gleich", "nach", "dem", "Ver\u00b7lo\u00b7bung\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo ich im Folterstuhl gesessen,", "tokens": ["Wo", "ich", "im", "Fol\u00b7ter\u00b7stuhl", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Bin ich bei Nacht nach Haus gerannt", "tokens": ["Bin", "ich", "bei", "Nacht", "nach", "Haus", "ge\u00b7rannt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "NN", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hab' mein Zimmer angebrannt.", "tokens": ["Und", "hab'", "mein", "Zim\u00b7mer", "an\u00b7ge\u00b7brannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Denn diese Ruh', die ich erzwungen,", "tokens": ["Denn", "die\u00b7se", "Ruh'", ",", "die", "ich", "er\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hat zum Schlu\u00df darauf gedrungen,", "tokens": ["Sie", "hat", "zum", "Schlu\u00df", "da\u00b7rauf", "ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Es mu\u00dfte irgendwas geschehn,", "tokens": ["Es", "mu\u00df\u00b7te", "ir\u00b7gend\u00b7was", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Blut mu\u00dft' ich oder Feuer sehn.", "tokens": ["Blut", "mu\u00dft'", "ich", "o\u00b7der", "Feu\u00b7er", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "KON", "NN", "VVINF", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Man kann nicht immer Wasser flennen,", "tokens": ["Man", "kann", "nicht", "im\u00b7mer", "Was\u00b7ser", "flen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PTKNEG", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Manch Schmerz will durch den Schornstein rennen.", "tokens": ["Manch", "Schmerz", "will", "durch", "den", "Schorn\u00b7stein", "ren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Warf mich im Sofa in die Kissen", "tokens": ["Warf", "mich", "im", "So\u00b7fa", "in", "die", "Kis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Und hab' mit Z\u00e4hnen sie zerrissen,", "tokens": ["Und", "hab'", "mit", "Z\u00e4h\u00b7nen", "sie", "zer\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.61": {"line.1": {"text": "Hielt meine Finger in das Licht:", "tokens": ["Hielt", "mei\u00b7ne", "Fin\u00b7ger", "in", "das", "Licht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie wurden schwarz, ich sp\u00fcrt' es nicht;", "tokens": ["Sie", "wur\u00b7den", "schwarz", ",", "ich", "sp\u00fcrt'", "es", "nicht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.62": {"line.1": {"text": "Lie\u00df Taschentuch, Manschetten braten,", "tokens": ["Lie\u00df", "Ta\u00b7schen\u00b7tuch", ",", "Man\u00b7schet\u00b7ten", "bra\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weil Flammen wohl den Augen taten;", "tokens": ["Weil", "Flam\u00b7men", "wohl", "den", "Au\u00b7gen", "ta\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "Fiel auf dem Fleck in tiefen Schlaf,", "tokens": ["Fiel", "auf", "dem", "Fleck", "in", "tie\u00b7fen", "Schlaf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo mich ein neues Elend traf.", "tokens": ["Wo", "mich", "ein", "neu\u00b7es", "E\u00b7lend", "traf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "Wohl schlug ich mir Frau K\u00f6nigin", "tokens": ["Wohl", "schlug", "ich", "mir", "Frau", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Am hellen Tag aus meinem Sinn,", "tokens": ["Am", "hel\u00b7len", "Tag", "aus", "mei\u00b7nem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Doch nachts im s\u00fc\u00dfen Schlafgefilde", "tokens": ["Doch", "nachts", "im", "s\u00fc\u00b7\u00dfen", "Schlaf\u00b7ge\u00b7fil\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schlich sie sich ein als Traumgebilde.", "tokens": ["Schlich", "sie", "sich", "ein", "als", "Traum\u00b7ge\u00b7bil\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "PRF", "ART", "KOUS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.66": {"line.1": {"text": "Diesmal kam sie als kleine Katz'", "tokens": ["Dies\u00b7mal", "kam", "sie", "als", "klei\u00b7ne", "Katz'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und nahm mir meinen Sofaplatz,", "tokens": ["Und", "nahm", "mir", "mei\u00b7nen", "Sof\u00b7a\u00b7platz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.67": {"line.1": {"text": "Ich kraute und liebkoste sie,", "tokens": ["Ich", "krau\u00b7te", "und", "lieb\u00b7kos\u00b7te", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Indes sie Zetermordio schrie,", "tokens": ["In\u00b7des", "sie", "Ze\u00b7ter\u00b7mor\u00b7dio", "schrie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.68": {"line.1": {"text": "Doch ich verstand nicht ihr Geschrei;", "tokens": ["Doch", "ich", "ver\u00b7stand", "nicht", "ihr", "Ge\u00b7schrei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da h\u00f6rt' ich Stimmen nebenbei,", "tokens": ["Da", "h\u00f6rt'", "ich", "Stim\u00b7men", "ne\u00b7ben\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.69": {"line.1": {"text": "Die sagten: \u00bbK\u00e4tzchen ist ja krank!\u00ab", "tokens": ["Die", "sag\u00b7ten", ":", "\u00bb", "K\u00e4tz\u00b7chen", "ist", "ja", "krank", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "$.", "$(", "NE", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich ging zu einem W\u00e4scheschrank,", "tokens": ["Ich", "ging", "zu", "ei\u00b7nem", "W\u00e4\u00b7sche\u00b7schrank", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "Legt' Handt\u00fccher um meine Katz',", "tokens": ["Legt'", "Hand\u00b7t\u00fc\u00b7cher", "um", "mei\u00b7ne", "Katz'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Doch sie entschl\u00fcpft mit einem Satz,", "tokens": ["Doch", "sie", "ent\u00b7schl\u00fcpft", "mit", "ei\u00b7nem", "Satz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.71": {"line.1": {"text": "Sie wendet ihr Gesicht mir hin:", "tokens": ["Sie", "wen\u00b7det", "ihr", "Ge\u00b7sicht", "mir", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Kopf war's der Frau K\u00f6nigin.", "tokens": ["Der", "Kopf", "wa\u00b7r's", "der", "Frau", "K\u00f6\u00b7ni\u00b7gin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.72": {"line.1": {"text": "Ein Menschenkopf am Katzenleib,", "tokens": ["Ein", "Men\u00b7schen\u00b7kopf", "am", "Kat\u00b7zen\u00b7leib", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und dieses war mein Lieblingsweib!", "tokens": ["Und", "die\u00b7ses", "war", "mein", "Lieb\u00b7lings\u00b7weib", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "Drau\u00dfen mit hochgehobenen Schweifen", "tokens": ["Drau\u00b7\u00dfen", "mit", "hoch\u00b7ge\u00b7ho\u00b7be\u00b7nen", "Schwei\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Sah Kater ich ums Fenster streifen;", "tokens": ["Sah", "Ka\u00b7ter", "ich", "ums", "Fens\u00b7ter", "strei\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.74": {"line.1": {"text": "Schmerzlich tat sich das K\u00e4tzchen recken", "tokens": ["Schmerz\u00b7lich", "tat", "sich", "das", "K\u00e4tz\u00b7chen", "re\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PRF", "ART", "NN", "VVINF"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Und tot die viere von sich strecken.", "tokens": ["Und", "tot", "die", "vie\u00b7re", "von", "sich", "stre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "PIS", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.75": {"line.1": {"text": "Da ward mein Herz ein kahler Fleck,", "tokens": ["Da", "ward", "mein", "Herz", "ein", "kah\u00b7ler", "Fleck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ganze Welt lag mir im Dreck,", "tokens": ["Die", "gan\u00b7ze", "Welt", "lag", "mir", "im", "Dreck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.76": {"line.1": {"text": "Im dunkeln Hof auf Pflastersteinen", "tokens": ["Im", "dun\u00b7keln", "Hof", "auf", "Pflas\u00b7ter\u00b7stei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sa\u00df ich und mu\u00dfte bitter weinen.", "tokens": ["Sa\u00df", "ich", "und", "mu\u00df\u00b7te", "bit\u00b7ter", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.77": {"line.1": {"text": "Ich wachte auf, erkenn' den Traum;", "tokens": ["Ich", "wach\u00b7te", "auf", ",", "er\u00b7kenn'", "den", "Traum", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch dieses tr\u00f6stete mich kaum.", "tokens": ["Auch", "die\u00b7ses", "tr\u00f6s\u00b7te\u00b7te", "mich", "kaum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.78": {"line.1": {"text": "Ich mu\u00dfte es mir eingestehn:", "tokens": ["Ich", "mu\u00df\u00b7te", "es", "mir", "ein\u00b7ge\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Unheimliches wird noch geschehn.", "tokens": ["Un\u00b7heim\u00b7li\u00b7ches", "wird", "noch", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.79": {"line.1": {"text": "Jetzt, Balzer, schn\u00fcr' den Kofferriemen,", "tokens": ["Jetzt", ",", "Bal\u00b7zer", ",", "schn\u00fcr'", "den", "Kof\u00b7fer\u00b7rie\u00b7men", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sonst mu\u00dft du hier noch weitermimen.", "tokens": ["Sonst", "mu\u00dft", "du", "hier", "noch", "wei\u00b7ter\u00b7mi\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.80": {"line.1": {"text": "Man soll sich nicht ans Ungl\u00fcck binden,", "tokens": ["Man", "soll", "sich", "nicht", "ans", "Un\u00b7gl\u00fcck", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "PTKNEG", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du mu\u00dft dich schnell ins Reisen finden.", "tokens": ["Du", "mu\u00dft", "dich", "schnell", "ins", "Rei\u00b7sen", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}