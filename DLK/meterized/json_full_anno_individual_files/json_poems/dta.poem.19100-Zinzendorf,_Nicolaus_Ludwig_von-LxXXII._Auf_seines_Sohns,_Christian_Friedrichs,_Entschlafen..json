{"dta.poem.19100": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "LxXXII.   Auf seines Sohns, Christian  \n Friedrichs, Entschlafen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Obr\u00e4utigam! der zwey verbundnen Hertzen,", "tokens": ["O\u00b7br\u00e4u\u00b7ti\u00b7gam", "!", "der", "zwey", "ver\u00b7bund\u00b7nen", "Hert\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ART", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die dir das Pfand der Eh itzt eingereicht.", "tokens": ["Die", "dir", "das", "Pfand", "der", "Eh", "itzt", "ein\u00b7ge\u00b7reicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "O du durch Angst und Schmach, und Todes Schmertzen,", "tokens": ["O", "du", "durch", "Angst", "und", "Schmach", ",", "und", "To\u00b7des", "Schmert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NN", "KON", "NN", "$,", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du forderst nichts, was man nicht hat,", "tokens": ["Du", "for\u00b7derst", "nichts", ",", "was", "man", "nicht", "hat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "PRELS", "PIS", "PTKNEG", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und giebst dich immer selbst ans eingeb\u00fc\u00dften Statt.", "tokens": ["Und", "giebst", "dich", "im\u00b7mer", "selbst", "ans", "ein\u00b7ge\u00b7b\u00fc\u00df\u00b7ten", "Statt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Eilf Monden sind bereits dahin gefahren;", "tokens": ["Eilf", "Mon\u00b7den", "sind", "be\u00b7reits", "da\u00b7hin", "ge\u00b7fah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir lebeten und unser Kind noch nicht:", "tokens": ["Wir", "le\u00b7be\u00b7ten", "und", "un\u00b7ser", "Kind", "noch", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "PPOSAT", "NN", "ADV", "PTKNEG", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Doch stunden wir schon seit geraumen Jahren,", "tokens": ["Doch", "stun\u00b7den", "wir", "schon", "seit", "ge\u00b7rau\u00b7men", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Vor vieles Heyl in deiner Schuld und Pflicht:", "tokens": ["Vor", "vie\u00b7les", "Heyl", "in", "dei\u00b7ner", "Schuld", "und", "Pflicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wir kauften Weitzen-K\u00f6rner ein,", "tokens": ["Wir", "kauf\u00b7ten", "Weit\u00b7zen\u00b7K\u00f6r\u00b7ner", "ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Um etwas dir zu Dienst auf Hofnung auszustreun.", "tokens": ["Um", "et\u00b7was", "dir", "zu", "Dienst", "auf", "Hof\u00b7nung", "aus\u00b7zu\u00b7streun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "PPER", "APPR", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Was giebt man doch dem K\u00f6nige der Hertzen,", "tokens": ["Was", "giebt", "man", "doch", "dem", "K\u00f6\u00b7ni\u00b7ge", "der", "Hert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das ihm so viel Gewinn als M\u00fche macht?", "tokens": ["Das", "ihm", "so", "viel", "Ge\u00b7winn", "als", "M\u00fc\u00b7he", "macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PIAT", "NN", "KOUS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es findet sich bey denen hellsten Kertzen,", "tokens": ["Es", "fin\u00b7det", "sich", "bey", "de\u00b7nen", "hells\u00b7ten", "Kert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PRELS", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Doch eine hie und da beschmitzte Pracht:", "tokens": ["Doch", "ei\u00b7ne", "hie", "und", "da", "be\u00b7schmitz\u00b7te", "Pracht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "KON", "ADV", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wo ist ein L\u00e4mmlein ohne Fehl?", "tokens": ["Wo", "ist", "ein", "L\u00e4mm\u00b7lein", "oh\u00b7ne", "Fehl", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es w\u00e4re denn, da\u00df sichs die Liebe selbst erwehl.", "tokens": ["Es", "w\u00e4\u00b7re", "denn", ",", "da\u00df", "sichs", "die", "Lie\u00b7be", "selbst", "er\u00b7wehl", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "KOUS", "PIS", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Das sahest du, du immer ofnes Auge,", "tokens": ["Das", "sa\u00b7hest", "du", ",", "du", "im\u00b7mer", "of\u00b7nes", "Au\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "PPER", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du dachtest wohl, die Kinder meynens gut;", "tokens": ["Du", "dach\u00b7test", "wohl", ",", "die", "Kin\u00b7der", "mey\u00b7nens", "gut", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Zum Zeichen, da\u00df ihr Hertze vor mir tauge,", "tokens": ["Zum", "Zei\u00b7chen", ",", "da\u00df", "ihr", "Hert\u00b7ze", "vor", "mir", "tau\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "VVFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil mir mein Volck mit Wollen alles thut,", "tokens": ["Weil", "mir", "mein", "Volck", "mit", "Wol\u00b7len", "al\u00b7les", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "NN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So will ich mir ein Schaf ersehn,", "tokens": ["So", "will", "ich", "mir", "ein", "Schaf", "er\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein zartes Kind! ", "tokens": ["Ein", "zar\u00b7tes", "Kind", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "O wann dich nur die Seelen recht verst\u00fcnden,", "tokens": ["O", "wann", "dich", "nur", "die", "See\u00b7len", "recht", "ver\u00b7st\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWAV", "PPER", "ADV", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie g\u00e4ben sich nicht halb so viele M\u00fch,", "tokens": ["Sie", "g\u00e4\u00b7ben", "sich", "nicht", "halb", "so", "vie\u00b7le", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKNEG", "ADJD", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mit mancherley Bedencken und Ergr\u00fcnden;", "tokens": ["Mit", "man\u00b7cher\u00b7ley", "Be\u00b7den\u00b7cken", "und", "Er\u00b7gr\u00fcn\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie merckten nur, wohin die Liebe zieh,", "tokens": ["Sie", "merck\u00b7ten", "nur", ",", "wo\u00b7hin", "die", "Lie\u00b7be", "zieh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und d\u00e4chten denn, wie jener Knecht:", "tokens": ["Und", "d\u00e4ch\u00b7ten", "denn", ",", "wie", "je\u00b7ner", "Knecht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "PWAV", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Mein Freund! du gabst auch di\u00dfmal, eh du nahmest,", "tokens": ["Mein", "Freund", "!", "du", "gabst", "auch", "di\u00df\u00b7mal", ",", "eh", "du", "nah\u00b7mest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "VVFIN", "ADV", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wohl dir, mein Kind, das du zur Ruhe bringst.", "tokens": ["Wohl", "dir", ",", "mein", "Kind", ",", "das", "du", "zur", "Ru\u00b7he", "bringst", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PPOSAT", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gesegnet sey der Sabbath, da du kamest;", "tokens": ["Ge\u00b7seg\u00b7net", "sey", "der", "Sab\u00b7ba\u00b7th", ",", "da", "du", "ka\u00b7mest", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gesegnet sey der Sabbath, da du giengst:", "tokens": ["Ge\u00b7seg\u00b7net", "sey", "der", "Sab\u00b7ba\u00b7th", ",", "da", "du", "giengst", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Dein Kampf war kurtz, die Macht war klein,", "tokens": ["Dein", "Kampf", "war", "kurtz", ",", "die", "Macht", "war", "klein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch dennoch ist der Sieg um JEsu willen dein.", "tokens": ["Noch", "den\u00b7noch", "ist", "der", "Sieg", "um", "Je\u00b7su", "wil\u00b7len", "dein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "APPR", "NE", "NN", "PPOSAT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Du! der di\u00df Kind ein Schmertzens-Sohn gewesen,", "tokens": ["Du", "!", "der", "di\u00df", "Kind", "ein", "Schmert\u00b7zens\u00b7Sohn", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "ART", "PDS", "NN", "ART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Was sag ich dir, ", "tokens": ["Was", "sag", "ich", "dir", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Du warst ja kaum des Seligen genesen,", "tokens": ["Du", "warst", "ja", "kaum", "des", "Se\u00b7li\u00b7gen", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So w\u00fctete der Schmertz in Brust und Leib:", "tokens": ["So", "w\u00fc\u00b7te\u00b7te", "der", "Schmertz", "in", "Brust", "und", "Leib", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "All ein der Geist voll Helden-Muth,", "tokens": ["All", "ein", "der", "Geist", "voll", "Hel\u00b7den\u00b7Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Fragt: wie ers machen soll? und fragt nicht: wie es thut.", "tokens": ["Fragt", ":", "wie", "ers", "ma\u00b7chen", "soll", "?", "und", "fragt", "nicht", ":", "wie", "es", "thut", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PWAV", "PIS", "VVINF", "VMFIN", "$.", "KON", "VVFIN", "PTKNEG", "$.", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Wenn dieses Kind kein Schaf gewesen w\u00e4re,", "tokens": ["Wenn", "die\u00b7ses", "Kind", "kein", "Schaf", "ge\u00b7we\u00b7sen", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "PIAT", "NN", "VAPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du m\u00fchetest dich noch, du ruhtest nicht.", "tokens": ["Du", "m\u00fc\u00b7he\u00b7test", "dich", "noch", ",", "du", "ruh\u00b7test", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "All ein, der HErr besahe die Alt\u00e4re,", "tokens": ["All", "ein", ",", "der", "Herr", "be\u00b7sa\u00b7he", "die", "Al\u00b7t\u00e4\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Darauf man ihm die Opfer zugericht:", "tokens": ["Da\u00b7rauf", "man", "ihm", "die", "Op\u00b7fer", "zu\u00b7ge\u00b7richt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Bey unserm merckt er seinen Zweck,", "tokens": ["Bey", "un\u00b7serm", "merckt", "er", "sei\u00b7nen", "Zweck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum fiel das Feur herab und fra\u00df das L\u00e4mmlein weg.", "tokens": ["Drum", "fiel", "das", "Feur", "her\u00b7ab", "und", "fra\u00df", "das", "L\u00e4mm\u00b7lein", "weg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "ADV", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Komm, Schwester! komm, wir wollen niederfallen.", "tokens": ["Komm", ",", "Schwes\u00b7ter", "!", "komm", ",", "wir", "wol\u00b7len", "nie\u00b7der\u00b7fal\u00b7len", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$.", "VVFIN", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir fragen nicht erst lang: Wie heisset er?", "tokens": ["Wir", "fra\u00b7gen", "nicht", "erst", "lang", ":", "Wie", "heis\u00b7set", "er", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ADJD", "$.", "PWAV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Jhm soll in uns ein Halleluja schallen.", "tokens": ["Jhm", "soll", "in", "uns", "ein", "Hal\u00b7le\u00b7lu\u00b7ja", "schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Drum machen wir die Augen zu,", "tokens": ["Drum", "ma\u00b7chen", "wir", "die", "Au\u00b7gen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}}}}