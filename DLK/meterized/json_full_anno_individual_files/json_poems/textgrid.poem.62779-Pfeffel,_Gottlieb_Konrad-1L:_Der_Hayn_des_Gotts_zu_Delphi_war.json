{"textgrid.poem.62779": {"metadata": {"author": {"name": "Pfeffel, Gottlieb Konrad", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Hayn des Gotts zu Delphi war", "genre": "verse", "period": "N.A.", "pub_year": 1775, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Hayn des Gotts zu Delphi war", "tokens": ["Der", "Hayn", "des", "Gotts", "zu", "Del\u00b7phi", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NE", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wohnung eines alten Raben,", "tokens": ["Die", "Woh\u00b7nung", "ei\u00b7nes", "al\u00b7ten", "Ra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dem Elster, Kauz und selbst der Staar", "tokens": ["Dem", "Els\u00b7ter", ",", "Kauz", "und", "selbst", "der", "Staar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "KON", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das stolze Lob der Weisheit gaben.", "tokens": ["Das", "stol\u00b7ze", "Lob", "der", "Weis\u00b7heit", "ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Einst fragt ihn seiner Enkel Schaar,", "tokens": ["Einst", "fragt", "ihn", "sei\u00b7ner", "En\u00b7kel", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was doch der Vogel Ph\u00f6nix w\u00e4re?", "tokens": ["Was", "doch", "der", "Vo\u00b7gel", "Ph\u00f6\u00b7nix", "w\u00e4\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NE", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Unding, Kinder, eine M\u00e4hre,", "tokens": ["Ein", "Un\u00b7ding", ",", "Kin\u00b7der", ",", "ei\u00b7ne", "M\u00e4h\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Vom Aberglauben ausgeheckt,", "tokens": ["Vom", "A\u00b7berg\u00b7lau\u00b7ben", "aus\u00b7ge\u00b7heckt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "War der Bescheid. Gerechte G\u00f6tter!", "tokens": ["War", "der", "Be\u00b7scheid", ".", "Ge\u00b7rech\u00b7te", "G\u00f6t\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$.", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Kein Ph\u00f6nix? Ha, verruchter Sp\u00f6tter,", "tokens": ["Kein", "Ph\u00f6\u00b7nix", "?", "Ha", ",", "ver\u00b7ruch\u00b7ter", "Sp\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$.", "NE", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Rief hier ein Geyer, der versteckt", "tokens": ["Rief", "hier", "ein", "Ge\u00b7yer", ",", "der", "ver\u00b7steckt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "$,", "PRELS", "VVFIN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.12": {"text": "Dem Patriarchen aufgepasset,", "tokens": ["Dem", "Pat\u00b7ri\u00b7ar\u00b7chen", "auf\u00b7ge\u00b7pas\u00b7set", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Mich nimmt nur Wunder, da\u00df Apoll,", "tokens": ["Mich", "nimmt", "nur", "Wun\u00b7der", ",", "da\u00df", "A\u00b7poll", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$,", "KOUS", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Der doch gewi\u00df die Ketzer hasset,", "tokens": ["Der", "doch", "ge\u00b7wi\u00df", "die", "Ket\u00b7zer", "has\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "In seinem Hayn sie dulden soll.", "tokens": ["In", "sei\u00b7nem", "Hayn", "sie", "dul\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Doch ich will seine Schande r\u00e4chen", "tokens": ["Doch", "ich", "will", "sei\u00b7ne", "Schan\u00b7de", "r\u00e4\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und dieser Brut die H\u00e4lse brechen.", "tokens": ["Und", "die\u00b7ser", "Brut", "die", "H\u00e4l\u00b7se", "bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Er thuts und ist der erste nicht,", "tokens": ["Er", "thuts", "und", "ist", "der", "ers\u00b7te", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VAFIN", "ART", "ADJA", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Der, eigne Leidenschaft zu stillen,", "tokens": ["Der", ",", "eig\u00b7ne", "Lei\u00b7den\u00b7schaft", "zu", "stil\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Dem Redlichen, um Gottes willen,", "tokens": ["Dem", "Red\u00b7li\u00b7chen", ",", "um", "Got\u00b7tes", "wil\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUI", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Den Mordstahl in den Busen sticht.", "tokens": ["Den", "Mord\u00b7stahl", "in", "den", "Bu\u00b7sen", "sticht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Hayn des Gotts zu Delphi war", "tokens": ["Der", "Hayn", "des", "Gotts", "zu", "Del\u00b7phi", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NE", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wohnung eines alten Raben,", "tokens": ["Die", "Woh\u00b7nung", "ei\u00b7nes", "al\u00b7ten", "Ra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dem Elster, Kauz und selbst der Staar", "tokens": ["Dem", "Els\u00b7ter", ",", "Kauz", "und", "selbst", "der", "Staar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "KON", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das stolze Lob der Weisheit gaben.", "tokens": ["Das", "stol\u00b7ze", "Lob", "der", "Weis\u00b7heit", "ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Einst fragt ihn seiner Enkel Schaar,", "tokens": ["Einst", "fragt", "ihn", "sei\u00b7ner", "En\u00b7kel", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was doch der Vogel Ph\u00f6nix w\u00e4re?", "tokens": ["Was", "doch", "der", "Vo\u00b7gel", "Ph\u00f6\u00b7nix", "w\u00e4\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NE", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Unding, Kinder, eine M\u00e4hre,", "tokens": ["Ein", "Un\u00b7ding", ",", "Kin\u00b7der", ",", "ei\u00b7ne", "M\u00e4h\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Vom Aberglauben ausgeheckt,", "tokens": ["Vom", "A\u00b7berg\u00b7lau\u00b7ben", "aus\u00b7ge\u00b7heckt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "War der Bescheid. Gerechte G\u00f6tter!", "tokens": ["War", "der", "Be\u00b7scheid", ".", "Ge\u00b7rech\u00b7te", "G\u00f6t\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$.", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Kein Ph\u00f6nix? Ha, verruchter Sp\u00f6tter,", "tokens": ["Kein", "Ph\u00f6\u00b7nix", "?", "Ha", ",", "ver\u00b7ruch\u00b7ter", "Sp\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$.", "NE", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Rief hier ein Geyer, der versteckt", "tokens": ["Rief", "hier", "ein", "Ge\u00b7yer", ",", "der", "ver\u00b7steckt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "$,", "PRELS", "VVFIN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.12": {"text": "Dem Patriarchen aufgepasset,", "tokens": ["Dem", "Pat\u00b7ri\u00b7ar\u00b7chen", "auf\u00b7ge\u00b7pas\u00b7set", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Mich nimmt nur Wunder, da\u00df Apoll,", "tokens": ["Mich", "nimmt", "nur", "Wun\u00b7der", ",", "da\u00df", "A\u00b7poll", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$,", "KOUS", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Der doch gewi\u00df die Ketzer hasset,", "tokens": ["Der", "doch", "ge\u00b7wi\u00df", "die", "Ket\u00b7zer", "has\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "In seinem Hayn sie dulden soll.", "tokens": ["In", "sei\u00b7nem", "Hayn", "sie", "dul\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Doch ich will seine Schande r\u00e4chen", "tokens": ["Doch", "ich", "will", "sei\u00b7ne", "Schan\u00b7de", "r\u00e4\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und dieser Brut die H\u00e4lse brechen.", "tokens": ["Und", "die\u00b7ser", "Brut", "die", "H\u00e4l\u00b7se", "bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Er thuts und ist der erste nicht,", "tokens": ["Er", "thuts", "und", "ist", "der", "ers\u00b7te", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VAFIN", "ART", "ADJA", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Der, eigne Leidenschaft zu stillen,", "tokens": ["Der", ",", "eig\u00b7ne", "Lei\u00b7den\u00b7schaft", "zu", "stil\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Dem Redlichen, um Gottes willen,", "tokens": ["Dem", "Red\u00b7li\u00b7chen", ",", "um", "Got\u00b7tes", "wil\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUI", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Den Mordstahl in den Busen sticht.", "tokens": ["Den", "Mord\u00b7stahl", "in", "den", "Bu\u00b7sen", "sticht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}