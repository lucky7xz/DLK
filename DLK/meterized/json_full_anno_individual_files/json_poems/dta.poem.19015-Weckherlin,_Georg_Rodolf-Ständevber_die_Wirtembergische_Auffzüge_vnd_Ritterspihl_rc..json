{"dta.poem.19015": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "St\u00e4ndevber die Wirtembergische  \n Auffz\u00fcge vnd Ritterspihl/ rc.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Nein/ es ist nicht mehr noht sich ab dem grossen", "tokens": ["Nein", "/", "es", "ist", "nicht", "mehr", "noht", "sich", "ab", "dem", "gros\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "PPER", "VAFIN", "PTKNEG", "ADV", "VVFIN", "PRF", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "pracht", "tokens": ["pracht"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Des R\u00f6mischen triumfs stehts also zu entsetzen:", "tokens": ["Des", "R\u00f6\u00b7mi\u00b7schen", "tri\u00b7umfs", "stehts", "al\u00b7so", "zu", "ent\u00b7set\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Teutschland hat wol nu mehr dergleichen f\u00fcrge-", "tokens": ["Teutschland", "hat", "wol", "nu", "mehr", "derg\u00b7lei\u00b7chen", "f\u00fcr\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ADV", "ADV", "ADV", "PIS", "TRUNC"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "bracht", "tokens": ["bracht"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Da\u00df man damit gnug kan gesicht vnd sehl erg\u00f6tzen.", "tokens": ["Da\u00df", "man", "da\u00b7mit", "gnug", "kan", "ge\u00b7sicht", "vnd", "sehl", "er\u00b7g\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "ADV", "VMFIN", "VVPP", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Nein/ es ist nicht mehr noht/ mit welsch-vermischter", "tokens": ["Nein", "/", "es", "ist", "nicht", "mehr", "noht", "/", "mit", "wel\u00b7schver\u00b7mischter"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$(", "PPER", "VAFIN", "PTKNEG", "PIAT", "NN", "$(", "APPR", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "sprach", "tokens": ["sprach"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Au\u00dfl\u00e4ndische woll\u00fcst vnd frewden zu erz\u00f6hlen;", "tokens": ["Au\u00df\u00b7l\u00e4n\u00b7di\u00b7sche", "wol\u00b7l\u00fcst", "vnd", "frew\u00b7den", "zu", "er\u00b7z\u00f6h\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Teutschland empfacht dardurch weder gesp\u00f6t noch", "tokens": ["Teutschland", "em\u00b7pfacht", "dar\u00b7durch", "we\u00b7der", "ge\u00b7sp\u00f6t", "noch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PAV", "KON", "ADJD", "ADV"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "schmach/", "tokens": ["schmach", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Sondern hat in sich selbs noch frewd gnug zu er-", "tokens": ["Son\u00b7dern", "hat", "in", "sich", "selbs", "noch", "frewd", "gnug", "zu", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "PRF", "ADV", "ADV", "ADJD", "ADV", "APPR", "TRUNC"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.7": {"text": "w\u00f6hlen.", "tokens": ["w\u00f6h\u00b7len", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.3": {"line.1": {"text": "Nein/ es ist nicht mehr noht der frembden kunst vnd", "tokens": ["Nein", "/", "es", "ist", "nicht", "mehr", "noht", "der", "fremb\u00b7den", "kunst", "vnd"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "PPER", "VAFIN", "PTKNEG", "PIAT", "NN", "ART", "ADJA", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "witz", "tokens": ["witz"], "token_info": ["word"], "pos": ["NE"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Erfindungen vnd spihl vnnachthunlich zuachten:", "tokens": ["Er\u00b7fin\u00b7dun\u00b7gen", "vnd", "spihl", "vn\u00b7nach\u00b7thun\u00b7lich", "zu\u00b7ach\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "ADJD", "VVINF", "$."], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Dan Teutschland/ welches selbs der erfindungen sitz/", "tokens": ["Dan", "Teutschland", "/", "wel\u00b7ches", "selbs", "der", "er\u00b7fin\u00b7dun\u00b7gen", "sitz", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$(", "PWS", "ADV", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Erweyset vil mehr kunst den frembden zu betrachten.", "tokens": ["Er\u00b7wey\u00b7set", "vil", "mehr", "kunst", "den", "fremb\u00b7den", "zu", "be\u00b7trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "ART", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Eben alhie sah man die Printzen mit wolstand", "tokens": ["E\u00b7ben", "al\u00b7hie", "sah", "man", "die", "Print\u00b7zen", "mit", "wol\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "ART", "NN", "APPR", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Verrichten jhre l\u00e4uff wie herrschende Planeten:", "tokens": ["Ver\u00b7rich\u00b7ten", "jhre", "l\u00e4uff", "wie", "herr\u00b7schen\u00b7de", "Pla\u00b7ne\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "KOKOM", "ADJA", "NN", "$."], "meter": "-+--+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Dazu die Nymfen dan durch jhrer angen brand", "tokens": ["Da\u00b7zu", "die", "Nym\u00b7fen", "dan", "durch", "jhrer", "an\u00b7gen", "brand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Mit s\u00fcsser Influentz leuchteten wie Cometen.", "tokens": ["Mit", "s\u00fcs\u00b7ser", "In\u00b7flu\u00b7entz", "leuch\u00b7te\u00b7ten", "wie", "Co\u00b7me\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Got/ welcher geber ist vnsers vnd alles guts/", "tokens": ["Got", "/", "wel\u00b7cher", "ge\u00b7ber", "ist", "vn\u00b7sers", "vnd", "al\u00b7les", "guts", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PWAT", "NN", "VAFIN", "ADV", "KON", "PIAT", "NN", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Geb da\u00df die Teutschen auch (folgend jhren Vor-", "tokens": ["Geb", "da\u00df", "die", "Teut\u00b7schen", "auch", "(", "fol\u00b7gend", "jhren", "Vor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "KOUS", "ART", "NN", "ADV", "$(", "ADJD", "PPOSAT", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "fahren)", "tokens": ["fah\u00b7ren", ")"], "token_info": ["word", "punct"], "pos": ["VVINF", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Wie freygebig sie seind jhrer reichthumb vnd bluts/", "tokens": ["Wie", "frey\u00b7ge\u00b7big", "sie", "seind", "jhrer", "reicht\u00b7humb", "vnd", "bluts", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VAFIN", "PPER", "VVFIN", "KON", "NN", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Begihrig bleiben sein vnd jhr ehr zubewahren!", "tokens": ["Be\u00b7gih\u00b7rig", "blei\u00b7ben", "sein", "vnd", "jhr", "ehr", "zu\u00b7be\u00b7wah\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VAINF", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}