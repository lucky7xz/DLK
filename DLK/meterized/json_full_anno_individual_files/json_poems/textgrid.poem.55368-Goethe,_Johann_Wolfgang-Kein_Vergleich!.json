{"textgrid.poem.55368": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Kein Vergleich!", "genre": "verse", "period": "N.A.", "pub_year": 1818, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Befrei uns Gott von ", "tokens": ["Be\u00b7frei", "uns", "Gott", "von"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "NN", "APPR"], "meter": "-+---", "measure": "dactylic.init"}, "line.2": {"text": "Wir k\u00f6nnen sie entbehren;", "tokens": ["Wir", "k\u00f6n\u00b7nen", "sie", "ent\u00b7beh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch wollen wir durch Musterung", "tokens": ["Doch", "wol\u00b7len", "wir", "durch", "Mus\u00b7te\u00b7rung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht uns noch andre scheren.", "tokens": ["Nicht", "uns", "noch", "and\u00b7re", "sche\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPER", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Es schreibt mir einer: \u00bbDen ", "tokens": ["Es", "schreibt", "mir", "ei\u00b7ner", ":", "\u00bb", "Den"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "$.", "$(", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Von Deutschen und Franzosen\u00ab \u2013", "tokens": ["Von", "Deut\u00b7schen", "und", "Fran\u00b7zo\u00b7sen", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und jeder Patriot sogleich", "tokens": ["Und", "je\u00b7der", "Pat\u00b7ri\u00b7ot", "sog\u00b7leich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird heftig sich erbosen.", "tokens": ["Wird", "hef\u00b7tig", "sich", "er\u00b7bo\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Kein Christenmensche h\u00f6rt ihm zu;", "tokens": ["Kein", "Chris\u00b7ten\u00b7men\u00b7sche", "h\u00f6rt", "ihm", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist denn der Kerl bei Sinnen?", "tokens": ["Ist", "denn", "der", "Kerl", "bei", "Sin\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da m\u00fcssen wir gewinnen.", "tokens": ["Da", "m\u00fcs\u00b7sen", "wir", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Befrei uns Gott von ", "tokens": ["Be\u00b7frei", "uns", "Gott", "von"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "NN", "APPR"], "meter": "-+---", "measure": "dactylic.init"}, "line.2": {"text": "Wir k\u00f6nnen sie entbehren;", "tokens": ["Wir", "k\u00f6n\u00b7nen", "sie", "ent\u00b7beh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch wollen wir durch Musterung", "tokens": ["Doch", "wol\u00b7len", "wir", "durch", "Mus\u00b7te\u00b7rung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht uns noch andre scheren.", "tokens": ["Nicht", "uns", "noch", "and\u00b7re", "sche\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPER", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Es schreibt mir einer: \u00bbDen ", "tokens": ["Es", "schreibt", "mir", "ei\u00b7ner", ":", "\u00bb", "Den"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "$.", "$(", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Von Deutschen und Franzosen\u00ab \u2013", "tokens": ["Von", "Deut\u00b7schen", "und", "Fran\u00b7zo\u00b7sen", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und jeder Patriot sogleich", "tokens": ["Und", "je\u00b7der", "Pat\u00b7ri\u00b7ot", "sog\u00b7leich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird heftig sich erbosen.", "tokens": ["Wird", "hef\u00b7tig", "sich", "er\u00b7bo\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Kein Christenmensche h\u00f6rt ihm zu;", "tokens": ["Kein", "Chris\u00b7ten\u00b7men\u00b7sche", "h\u00f6rt", "ihm", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist denn der Kerl bei Sinnen?", "tokens": ["Ist", "denn", "der", "Kerl", "bei", "Sin\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da m\u00fcssen wir gewinnen.", "tokens": ["Da", "m\u00fcs\u00b7sen", "wir", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}