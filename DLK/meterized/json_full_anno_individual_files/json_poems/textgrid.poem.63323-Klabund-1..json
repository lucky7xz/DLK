{"textgrid.poem.63323": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Noch nie hat mir der Herbst so weh getan,", "tokens": ["Noch", "nie", "hat", "mir", "der", "Herbst", "so", "weh", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df ich mich ohne Freundin bla\u00df begn\u00fcge.", "tokens": ["Da\u00df", "ich", "mich", "oh\u00b7ne", "Freun\u00b7din", "bla\u00df", "be\u00b7gn\u00fc\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Am Bahnhof steh' ich oft und seh' die Z\u00fcge", "tokens": ["Am", "Bahn\u00b7hof", "steh'", "ich", "oft", "und", "seh'", "die", "Z\u00fc\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Einlaufen nach des Kursbuch's rotem Plan.", "tokens": ["Ein\u00b7lau\u00b7fen", "nach", "des", "Kurs\u00b7buch's", "ro\u00b7tem", "Plan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Hier kommt ein Zug um f\u00fcnf und dort um sechs.", "tokens": ["Hier", "kommt", "ein", "Zug", "um", "f\u00fcnf", "und", "dort", "um", "sechs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "CARD", "KON", "ADV", "APPR", "CARD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der aus Polzin. Und der aus Samarkand.", "tokens": ["Der", "aus", "Pol\u00b7zin", ".", "Und", "der", "aus", "Sa\u00b7mar\u00b7kand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "$.", "KON", "ART", "APPR", "NE", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "So oft ich mich an eine Frau gewandt,", "tokens": ["So", "oft", "ich", "mich", "an", "ei\u00b7ne", "Frau", "ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Entfloh sie mit dem Zeichen h\u00f6chsten Schrecks.", "tokens": ["Ent\u00b7floh", "sie", "mit", "dem", "Zei\u00b7chen", "h\u00f6chs\u00b7ten", "Schrecks", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Man wundert sich, da\u00df ich so kopflos bin", "tokens": ["Man", "wun\u00b7dert", "sich", ",", "da\u00df", "ich", "so", "kopf\u00b7los", "bin"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PRF", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und da\u00df ich ohne Beine gehen kann,", "tokens": ["Und", "da\u00df", "ich", "oh\u00b7ne", "Bei\u00b7ne", "ge\u00b7hen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und da\u00df ich ohne M\u00e4nnlichkeit ein Mann,", "tokens": ["Und", "da\u00df", "ich", "oh\u00b7ne", "M\u00e4nn\u00b7lich\u00b7keit", "ein", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und da\u00df ich ohne Sinnlichkeit ein Sinn.", "tokens": ["Und", "da\u00df", "ich", "oh\u00b7ne", "Sinn\u00b7lich\u00b7keit", "ein", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Noch nie hat mir der Herbst so weh getan,", "tokens": ["Noch", "nie", "hat", "mir", "der", "Herbst", "so", "weh", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df ich mich ohne Freundin bla\u00df begn\u00fcge.", "tokens": ["Da\u00df", "ich", "mich", "oh\u00b7ne", "Freun\u00b7din", "bla\u00df", "be\u00b7gn\u00fc\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Am Bahnhof steh' ich oft und seh' die Z\u00fcge", "tokens": ["Am", "Bahn\u00b7hof", "steh'", "ich", "oft", "und", "seh'", "die", "Z\u00fc\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Einlaufen nach des Kursbuch's rotem Plan.", "tokens": ["Ein\u00b7lau\u00b7fen", "nach", "des", "Kurs\u00b7buch's", "ro\u00b7tem", "Plan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Hier kommt ein Zug um f\u00fcnf und dort um sechs.", "tokens": ["Hier", "kommt", "ein", "Zug", "um", "f\u00fcnf", "und", "dort", "um", "sechs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "CARD", "KON", "ADV", "APPR", "CARD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der aus Polzin. Und der aus Samarkand.", "tokens": ["Der", "aus", "Pol\u00b7zin", ".", "Und", "der", "aus", "Sa\u00b7mar\u00b7kand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "$.", "KON", "ART", "APPR", "NE", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "So oft ich mich an eine Frau gewandt,", "tokens": ["So", "oft", "ich", "mich", "an", "ei\u00b7ne", "Frau", "ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Entfloh sie mit dem Zeichen h\u00f6chsten Schrecks.", "tokens": ["Ent\u00b7floh", "sie", "mit", "dem", "Zei\u00b7chen", "h\u00f6chs\u00b7ten", "Schrecks", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Man wundert sich, da\u00df ich so kopflos bin", "tokens": ["Man", "wun\u00b7dert", "sich", ",", "da\u00df", "ich", "so", "kopf\u00b7los", "bin"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PRF", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und da\u00df ich ohne Beine gehen kann,", "tokens": ["Und", "da\u00df", "ich", "oh\u00b7ne", "Bei\u00b7ne", "ge\u00b7hen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und da\u00df ich ohne M\u00e4nnlichkeit ein Mann,", "tokens": ["Und", "da\u00df", "ich", "oh\u00b7ne", "M\u00e4nn\u00b7lich\u00b7keit", "ein", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und da\u00df ich ohne Sinnlichkeit ein Sinn.", "tokens": ["Und", "da\u00df", "ich", "oh\u00b7ne", "Sinn\u00b7lich\u00b7keit", "ein", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}