{"textgrid.poem.43393": {"metadata": {"author": {"name": "Hoffmann von Fallersleben, August Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Hier auf Erden", "genre": "verse", "period": "N.A.", "pub_year": 1836, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hier auf Erden", "tokens": ["Hier", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Konnte werden", "tokens": ["Konn\u00b7te", "wer\u00b7den"], "token_info": ["word", "word"], "pos": ["VMFIN", "VAINF"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Doch kein schlechter Ding erdacht,", "tokens": ["Doch", "kein", "schlech\u00b7ter", "Ding", "er\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Als da\u00df man Gedanken richtet,", "tokens": ["Als", "da\u00df", "man", "Ge\u00b7dan\u00b7ken", "rich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Geister t\u00f6dtet und vernichtet,", "tokens": ["Geis\u00b7ter", "t\u00f6d\u00b7tet", "und", "ver\u00b7nich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Oder thut in Bann und Acht.", "tokens": ["O\u00b7der", "thut", "in", "Bann", "und", "Acht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "CARD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Be\u00dfre Tage,", "tokens": ["Be\u00df\u00b7re", "Ta\u00b7ge", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Mindre Plage", "tokens": ["Mind\u00b7re", "Pla\u00b7ge"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Werden nie dem Staat zu Theil \u2013", "tokens": ["Wer\u00b7den", "nie", "dem", "Staat", "zu", "Theil", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sagen darf man nicht das Rechte,", "tokens": ["Sa\u00b7gen", "darf", "man", "nicht", "das", "Rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ohne Tadel bleibt das Schlechte", "tokens": ["Oh\u00b7ne", "Ta\u00b7del", "bleibt", "das", "Schlech\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und das Kranke wird nicht heil.", "tokens": ["Und", "das", "Kran\u00b7ke", "wird", "nicht", "heil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wer es waget", "tokens": ["Wer", "es", "wa\u00b7get"], "token_info": ["word", "word", "word"], "pos": ["PWS", "PPER", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Und es saget,", "tokens": ["Und", "es", "sa\u00b7get", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Wie es ist und k\u00f6nnte sein,", "tokens": ["Wie", "es", "ist", "und", "k\u00f6nn\u00b7te", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "KON", "VMFIN", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gilt f\u00fcr einen Staatsverbrecher", "tokens": ["Gilt", "f\u00fcr", "ei\u00b7nen", "Staats\u00b7ver\u00b7bre\u00b7cher"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und man sperrt den armen Sch\u00e4cher", "tokens": ["Und", "man", "sperrt", "den", "ar\u00b7men", "Sch\u00e4\u00b7cher"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Endlich allergn\u00e4digst ein.", "tokens": ["End\u00b7lich", "al\u00b7lerg\u00b7n\u00e4\u00b7digst", "ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Unsrer Geister", "tokens": ["Uns\u00b7rer", "Geis\u00b7ter"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Herrn und Meister", "tokens": ["Herrn", "und", "Meis\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Sind jetzt die Censoren nur,", "tokens": ["Sind", "jetzt", "die", "Cen\u00b7so\u00b7ren", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+----+", "measure": "dactylic.init"}, "line.4": {"text": "Und sie werden immer dreister,", "tokens": ["Und", "sie", "wer\u00b7den", "im\u00b7mer", "dreis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Meistern Gott den Herrn und Meister:", "tokens": ["Meis\u00b7tern", "Gott", "den", "Herrn", "und", "Meis\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00dcber Gott geht die Zensur.", "tokens": ["\u00dc\u00b7ber", "Gott", "geht", "die", "Zen\u00b7sur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+---+", "measure": "unknown.measure.tri"}}, "stanza.5": {"line.1": {"text": "Ja, und immer,", "tokens": ["Ja", ",", "und", "im\u00b7mer", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KON", "ADV", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Immer schlimmer", "tokens": ["Im\u00b7mer", "schlim\u00b7mer"], "token_info": ["word", "word"], "pos": ["ADV", "ADJD"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Geht's uns armen Teufeln nur.", "tokens": ["Geht's", "uns", "ar\u00b7men", "Teu\u00b7feln", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADJA", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Glauben wir ein k\u00fcnftig Leben,", "tokens": ["Glau\u00b7ben", "wir", "ein", "k\u00fcnf\u00b7tig", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "M\u00fcssen wir auch ", "tokens": ["M\u00fcs\u00b7sen", "wir", "auch"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPER", "ADV"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Wenn's nicht gut hei\u00dft die Censur.", "tokens": ["Wenn's", "nicht", "gut", "hei\u00dft", "die", "Cen\u00b7sur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADJD", "VVFIN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.6": {"line.1": {"text": "Giebts auf Erden", "tokens": ["Giebts", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Wol Beschwerden,", "tokens": ["Wol", "Be\u00b7schwer\u00b7den", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Gr\u00f6\u00dfre noch als unsre Noth!", "tokens": ["Gr\u00f6\u00df\u00b7re", "noch", "als", "uns\u00b7re", "Noth", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KOKOM", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das Gebot: du sollst nicht t\u00f6dten!", "tokens": ["Das", "Ge\u00b7bot", ":", "du", "sollst", "nicht", "t\u00f6d\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Ist nun weiter nicht von N\u00f6then,", "tokens": ["Ist", "nun", "wei\u00b7ter", "nicht", "von", "N\u00f6\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PTKNEG", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Denn wir sind schon alle todt.", "tokens": ["Denn", "wir", "sind", "schon", "al\u00b7le", "todt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PIS", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Hier auf Erden", "tokens": ["Hier", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Konnte werden", "tokens": ["Konn\u00b7te", "wer\u00b7den"], "token_info": ["word", "word"], "pos": ["VMFIN", "VAINF"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Doch kein schlechter Ding erdacht,", "tokens": ["Doch", "kein", "schlech\u00b7ter", "Ding", "er\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Als da\u00df man Gedanken richtet,", "tokens": ["Als", "da\u00df", "man", "Ge\u00b7dan\u00b7ken", "rich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Geister t\u00f6dtet und vernichtet,", "tokens": ["Geis\u00b7ter", "t\u00f6d\u00b7tet", "und", "ver\u00b7nich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Oder thut in Bann und Acht.", "tokens": ["O\u00b7der", "thut", "in", "Bann", "und", "Acht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "CARD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Be\u00dfre Tage,", "tokens": ["Be\u00df\u00b7re", "Ta\u00b7ge", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Mindre Plage", "tokens": ["Mind\u00b7re", "Pla\u00b7ge"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Werden nie dem Staat zu Theil \u2013", "tokens": ["Wer\u00b7den", "nie", "dem", "Staat", "zu", "Theil", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sagen darf man nicht das Rechte,", "tokens": ["Sa\u00b7gen", "darf", "man", "nicht", "das", "Rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ohne Tadel bleibt das Schlechte", "tokens": ["Oh\u00b7ne", "Ta\u00b7del", "bleibt", "das", "Schlech\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und das Kranke wird nicht heil.", "tokens": ["Und", "das", "Kran\u00b7ke", "wird", "nicht", "heil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wer es waget", "tokens": ["Wer", "es", "wa\u00b7get"], "token_info": ["word", "word", "word"], "pos": ["PWS", "PPER", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Und es saget,", "tokens": ["Und", "es", "sa\u00b7get", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Wie es ist und k\u00f6nnte sein,", "tokens": ["Wie", "es", "ist", "und", "k\u00f6nn\u00b7te", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "KON", "VMFIN", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gilt f\u00fcr einen Staatsverbrecher", "tokens": ["Gilt", "f\u00fcr", "ei\u00b7nen", "Staats\u00b7ver\u00b7bre\u00b7cher"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und man sperrt den armen Sch\u00e4cher", "tokens": ["Und", "man", "sperrt", "den", "ar\u00b7men", "Sch\u00e4\u00b7cher"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Endlich allergn\u00e4digst ein.", "tokens": ["End\u00b7lich", "al\u00b7lerg\u00b7n\u00e4\u00b7digst", "ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Unsrer Geister", "tokens": ["Uns\u00b7rer", "Geis\u00b7ter"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Herrn und Meister", "tokens": ["Herrn", "und", "Meis\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Sind jetzt die Censoren nur,", "tokens": ["Sind", "jetzt", "die", "Cen\u00b7so\u00b7ren", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+----+", "measure": "dactylic.init"}, "line.4": {"text": "Und sie werden immer dreister,", "tokens": ["Und", "sie", "wer\u00b7den", "im\u00b7mer", "dreis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Meistern Gott den Herrn und Meister:", "tokens": ["Meis\u00b7tern", "Gott", "den", "Herrn", "und", "Meis\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00dcber Gott geht die Zensur.", "tokens": ["\u00dc\u00b7ber", "Gott", "geht", "die", "Zen\u00b7sur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+---+", "measure": "unknown.measure.tri"}}, "stanza.11": {"line.1": {"text": "Ja, und immer,", "tokens": ["Ja", ",", "und", "im\u00b7mer", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KON", "ADV", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Immer schlimmer", "tokens": ["Im\u00b7mer", "schlim\u00b7mer"], "token_info": ["word", "word"], "pos": ["ADV", "ADJD"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Geht's uns armen Teufeln nur.", "tokens": ["Geht's", "uns", "ar\u00b7men", "Teu\u00b7feln", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADJA", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Glauben wir ein k\u00fcnftig Leben,", "tokens": ["Glau\u00b7ben", "wir", "ein", "k\u00fcnf\u00b7tig", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "M\u00fcssen wir auch ", "tokens": ["M\u00fcs\u00b7sen", "wir", "auch"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPER", "ADV"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Wenn's nicht gut hei\u00dft die Censur.", "tokens": ["Wenn's", "nicht", "gut", "hei\u00dft", "die", "Cen\u00b7sur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADJD", "VVFIN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.12": {"line.1": {"text": "Giebts auf Erden", "tokens": ["Giebts", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Wol Beschwerden,", "tokens": ["Wol", "Be\u00b7schwer\u00b7den", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Gr\u00f6\u00dfre noch als unsre Noth!", "tokens": ["Gr\u00f6\u00df\u00b7re", "noch", "als", "uns\u00b7re", "Noth", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KOKOM", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das Gebot: du sollst nicht t\u00f6dten!", "tokens": ["Das", "Ge\u00b7bot", ":", "du", "sollst", "nicht", "t\u00f6d\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Ist nun weiter nicht von N\u00f6then,", "tokens": ["Ist", "nun", "wei\u00b7ter", "nicht", "von", "N\u00f6\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PTKNEG", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Denn wir sind schon alle todt.", "tokens": ["Denn", "wir", "sind", "schon", "al\u00b7le", "todt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PIS", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}