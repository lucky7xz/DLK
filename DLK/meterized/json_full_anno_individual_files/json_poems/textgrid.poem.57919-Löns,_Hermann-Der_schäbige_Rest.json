{"textgrid.poem.57919": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Der sch\u00e4bige Rest", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Heil soll Hannover widerfahren,", "tokens": ["Heil", "soll", "Han\u00b7no\u00b7ver", "wi\u00b7der\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "NE", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die gro\u00dfe Sarah will hierher,", "tokens": ["Die", "gro\u00b7\u00dfe", "Sa\u00b7rah", "will", "hier\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das ist sehr freundlich, doch wir fragen:", "tokens": ["Das", "ist", "sehr", "freund\u00b7lich", ",", "doch", "wir", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$,", "KON", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "O Sarah, was kamst du nicht eh'r?", "tokens": ["O", "Sa\u00b7rah", ",", "was", "kamst", "du", "nicht", "eh'r", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PWS", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.2": {"line.1": {"text": "Als du noch j\u00fcnger warst an Jahren,", "tokens": ["Als", "du", "noch", "j\u00fcn\u00b7ger", "warst", "an", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da lie\u00dfest du dich hier nicht sehn,", "tokens": ["Da", "lie\u00b7\u00dfest", "du", "dich", "hier", "nicht", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jetzt, wo die Zugkraft von dir weg ist,", "tokens": ["Jetzt", ",", "wo", "die", "Zug\u00b7kraft", "von", "dir", "weg", "ist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "APPR", "PPER", "ADV", "VAFIN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Da willst du auf die D\u00f6rfer gehn.", "tokens": ["Da", "willst", "du", "auf", "die", "D\u00f6r\u00b7fer", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "In Frankreich re\u00fcssierst du, Sarah,", "tokens": ["In", "Fran\u00b7kreich", "re\u00b7\u00fcs\u00b7sierst", "du", ",", "Sa\u00b7rah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "$,", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Kaum noch im allerkleinsten Nest,", "tokens": ["Kaum", "noch", "im", "al\u00b7ler\u00b7kleins\u00b7ten", "Nest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nun servierst du den Barbaren", "tokens": ["Und", "nun", "ser\u00b7vierst", "du", "den", "Bar\u00b7ba\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Diesseits des Rheins den sch\u00e4b'gen Rest.", "tokens": ["Dies\u00b7seits", "des", "Rheins", "den", "sch\u00e4b'\u00b7gen", "Rest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich aber sch\u00e4tze keine Neigen", "tokens": ["Ich", "a\u00b7ber", "sch\u00e4t\u00b7ze", "kei\u00b7ne", "Nei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und laufe davor, was ich kann;", "tokens": ["Und", "lau\u00b7fe", "da\u00b7vor", ",", "was", "ich", "kann", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "$,", "PWS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schon immer warst'e reichlich mager,", "tokens": ["Schon", "im\u00b7mer", "war\u00b7st'e", "reich\u00b7lich", "ma\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und jetzt ist an dir nichts mehr dran.", "tokens": ["Und", "jetzt", "ist", "an", "dir", "nichts", "mehr", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "APPR", "PPER", "PIS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Heil soll Hannover widerfahren,", "tokens": ["Heil", "soll", "Han\u00b7no\u00b7ver", "wi\u00b7der\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "NE", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die gro\u00dfe Sarah will hierher,", "tokens": ["Die", "gro\u00b7\u00dfe", "Sa\u00b7rah", "will", "hier\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das ist sehr freundlich, doch wir fragen:", "tokens": ["Das", "ist", "sehr", "freund\u00b7lich", ",", "doch", "wir", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$,", "KON", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "O Sarah, was kamst du nicht eh'r?", "tokens": ["O", "Sa\u00b7rah", ",", "was", "kamst", "du", "nicht", "eh'r", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PWS", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.6": {"line.1": {"text": "Als du noch j\u00fcnger warst an Jahren,", "tokens": ["Als", "du", "noch", "j\u00fcn\u00b7ger", "warst", "an", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da lie\u00dfest du dich hier nicht sehn,", "tokens": ["Da", "lie\u00b7\u00dfest", "du", "dich", "hier", "nicht", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jetzt, wo die Zugkraft von dir weg ist,", "tokens": ["Jetzt", ",", "wo", "die", "Zug\u00b7kraft", "von", "dir", "weg", "ist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "APPR", "PPER", "ADV", "VAFIN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Da willst du auf die D\u00f6rfer gehn.", "tokens": ["Da", "willst", "du", "auf", "die", "D\u00f6r\u00b7fer", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "In Frankreich re\u00fcssierst du, Sarah,", "tokens": ["In", "Fran\u00b7kreich", "re\u00b7\u00fcs\u00b7sierst", "du", ",", "Sa\u00b7rah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "$,", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Kaum noch im allerkleinsten Nest,", "tokens": ["Kaum", "noch", "im", "al\u00b7ler\u00b7kleins\u00b7ten", "Nest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nun servierst du den Barbaren", "tokens": ["Und", "nun", "ser\u00b7vierst", "du", "den", "Bar\u00b7ba\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Diesseits des Rheins den sch\u00e4b'gen Rest.", "tokens": ["Dies\u00b7seits", "des", "Rheins", "den", "sch\u00e4b'\u00b7gen", "Rest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ich aber sch\u00e4tze keine Neigen", "tokens": ["Ich", "a\u00b7ber", "sch\u00e4t\u00b7ze", "kei\u00b7ne", "Nei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und laufe davor, was ich kann;", "tokens": ["Und", "lau\u00b7fe", "da\u00b7vor", ",", "was", "ich", "kann", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "$,", "PWS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schon immer warst'e reichlich mager,", "tokens": ["Schon", "im\u00b7mer", "war\u00b7st'e", "reich\u00b7lich", "ma\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und jetzt ist an dir nichts mehr dran.", "tokens": ["Und", "jetzt", "ist", "an", "dir", "nichts", "mehr", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "APPR", "PPER", "PIS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}