{"textgrid.poem.49214": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "15.", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich machte diese Ver\u00df in meiner Pierinnen", "tokens": ["Ich", "mach\u00b7te", "die\u00b7se", "Ver\u00df", "in", "mei\u00b7ner", "Pie\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Begr\u00fcnten W\u00fcsteney, wie Deutschland embsig war", "tokens": ["Be\u00b7gr\u00fcn\u00b7ten", "W\u00fcs\u00b7te\u00b7ney", ",", "wie", "Deutschland", "emb\u00b7sig", "war"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PWAV", "NE", "ADJD", "VAFIN"], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Sein M\u00f6rder selbst zu seyn, da Herdt und auch Altar", "tokens": ["Sein", "M\u00f6r\u00b7der", "selbst", "zu", "seyn", ",", "da", "Herdt", "und", "auch", "Al\u00b7tar"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VAINF", "$,", "KOUS", "NE", "KON", "ADV", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In Asche ward gelegt durch trauriges Beginnen", "tokens": ["In", "A\u00b7sche", "ward", "ge\u00b7legt", "durch", "trau\u00b7ri\u00b7ges", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "VVPP", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Der blutigen Begier, da gantzer V\u00f6lcker Sinnen", "tokens": ["Der", "blu\u00b7ti\u00b7gen", "Be\u00b7gier", ",", "da", "gant\u00b7zer", "V\u00f6l\u00b7cker", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KOUS", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und Tichten ward verkehrt, da aller Laster Schar,", "tokens": ["Und", "Tich\u00b7ten", "ward", "ver\u00b7kehrt", ",", "da", "al\u00b7ler", "Las\u00b7ter", "Schar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "VVPP", "$,", "KOUS", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mord, Unzucht, Schwelgerey und Triegen gantz und gar", "tokens": ["Mord", ",", "Un\u00b7zucht", ",", "Schwel\u00b7ge\u00b7rey", "und", "Trie\u00b7gen", "gantz", "und", "gar"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "ADV", "KON", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Platz der alten Ehr' und Tugend hielten innen.", "tokens": ["Den", "Platz", "der", "al\u00b7ten", "Ehr'", "und", "Tu\u00b7gend", "hiel\u00b7ten", "in\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "KON", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Damit die b\u00f6se Zeit nun w\u00fcrde hingebracht,", "tokens": ["Da\u00b7mit", "die", "b\u00f6\u00b7se", "Zeit", "nun", "w\u00fcr\u00b7de", "hin\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hab' ich sie wollen hier an leichte Reime wenden.", "tokens": ["Hab'", "ich", "sie", "wol\u00b7len", "hier", "an", "leich\u00b7te", "Rei\u00b7me", "wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "VMFIN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mars thuts der Liebe nach, da\u00df er der Thr\u00e4nen lacht;", "tokens": ["Mars", "thuts", "der", "Lie\u00b7be", "nach", ",", "da\u00df", "er", "der", "Thr\u00e4\u00b7nen", "lacht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Mein Krieg ist lobens werth, und seiner ist zu sch\u00e4nden;", "tokens": ["Mein", "Krieg", "ist", "lo\u00b7bens", "werth", ",", "und", "sei\u00b7ner", "ist", "zu", "sch\u00e4n\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$,", "KON", "PPOSAT", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dann meiner wird gestillt durch zweyer Leute Schlacht,", "tokens": ["Dann", "mei\u00b7ner", "wird", "ge\u00b7stillt", "durch", "zwey\u00b7er", "Leu\u00b7te", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "VAFIN", "VVPP", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den andern k\u00f6nnen auch viel tausend noch nicht enden.", "tokens": ["Den", "an\u00b7dern", "k\u00f6n\u00b7nen", "auch", "viel", "tau\u00b7send", "noch", "nicht", "en\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "ADV", "ADV", "ADJD", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ich machte diese Ver\u00df in meiner Pierinnen", "tokens": ["Ich", "mach\u00b7te", "die\u00b7se", "Ver\u00df", "in", "mei\u00b7ner", "Pie\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Begr\u00fcnten W\u00fcsteney, wie Deutschland embsig war", "tokens": ["Be\u00b7gr\u00fcn\u00b7ten", "W\u00fcs\u00b7te\u00b7ney", ",", "wie", "Deutschland", "emb\u00b7sig", "war"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PWAV", "NE", "ADJD", "VAFIN"], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Sein M\u00f6rder selbst zu seyn, da Herdt und auch Altar", "tokens": ["Sein", "M\u00f6r\u00b7der", "selbst", "zu", "seyn", ",", "da", "Herdt", "und", "auch", "Al\u00b7tar"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VAINF", "$,", "KOUS", "NE", "KON", "ADV", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In Asche ward gelegt durch trauriges Beginnen", "tokens": ["In", "A\u00b7sche", "ward", "ge\u00b7legt", "durch", "trau\u00b7ri\u00b7ges", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "VVPP", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Der blutigen Begier, da gantzer V\u00f6lcker Sinnen", "tokens": ["Der", "blu\u00b7ti\u00b7gen", "Be\u00b7gier", ",", "da", "gant\u00b7zer", "V\u00f6l\u00b7cker", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KOUS", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und Tichten ward verkehrt, da aller Laster Schar,", "tokens": ["Und", "Tich\u00b7ten", "ward", "ver\u00b7kehrt", ",", "da", "al\u00b7ler", "Las\u00b7ter", "Schar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "VVPP", "$,", "KOUS", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mord, Unzucht, Schwelgerey und Triegen gantz und gar", "tokens": ["Mord", ",", "Un\u00b7zucht", ",", "Schwel\u00b7ge\u00b7rey", "und", "Trie\u00b7gen", "gantz", "und", "gar"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "ADV", "KON", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Platz der alten Ehr' und Tugend hielten innen.", "tokens": ["Den", "Platz", "der", "al\u00b7ten", "Ehr'", "und", "Tu\u00b7gend", "hiel\u00b7ten", "in\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "KON", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Damit die b\u00f6se Zeit nun w\u00fcrde hingebracht,", "tokens": ["Da\u00b7mit", "die", "b\u00f6\u00b7se", "Zeit", "nun", "w\u00fcr\u00b7de", "hin\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hab' ich sie wollen hier an leichte Reime wenden.", "tokens": ["Hab'", "ich", "sie", "wol\u00b7len", "hier", "an", "leich\u00b7te", "Rei\u00b7me", "wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "VMFIN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mars thuts der Liebe nach, da\u00df er der Thr\u00e4nen lacht;", "tokens": ["Mars", "thuts", "der", "Lie\u00b7be", "nach", ",", "da\u00df", "er", "der", "Thr\u00e4\u00b7nen", "lacht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Mein Krieg ist lobens werth, und seiner ist zu sch\u00e4nden;", "tokens": ["Mein", "Krieg", "ist", "lo\u00b7bens", "werth", ",", "und", "sei\u00b7ner", "ist", "zu", "sch\u00e4n\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$,", "KON", "PPOSAT", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dann meiner wird gestillt durch zweyer Leute Schlacht,", "tokens": ["Dann", "mei\u00b7ner", "wird", "ge\u00b7stillt", "durch", "zwey\u00b7er", "Leu\u00b7te", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "VAFIN", "VVPP", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den andern k\u00f6nnen auch viel tausend noch nicht enden.", "tokens": ["Den", "an\u00b7dern", "k\u00f6n\u00b7nen", "auch", "viel", "tau\u00b7send", "noch", "nicht", "en\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "ADV", "ADV", "ADJD", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}