{"textgrid.poem.38315": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Dies ist das ander Land", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ist nit allewege Festabend,", "tokens": ["Es", "ist", "nit", "al\u00b7le\u00b7we\u00b7ge", "Fest\u00b7a\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Der Tod k\u00f6mmt und bringet den Abend;", "tokens": ["Der", "Tod", "k\u00f6mmt", "und", "brin\u00b7get", "den", "A\u00b7bend", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und bindt uns mit einem festen Band,", "tokens": ["Und", "bindt", "uns", "mit", "ei\u00b7nem", "fes\u00b7ten", "Band", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da\u00df er uns bringe in das ander Land.", "tokens": ["Da\u00df", "er", "uns", "brin\u00b7ge", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Auch so ist allezeit nit Maye,", "tokens": ["Auch", "so", "ist", "al\u00b7le\u00b7zeit", "nit", "Ma\u00b7ye", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ADV", "PTKNEG", "NE", "$,"], "meter": "-----+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Wir m\u00fcssen tanzen an dem Reihe;", "tokens": ["Wir", "m\u00fcs\u00b7sen", "tan\u00b7zen", "an", "dem", "Rei\u00b7he", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df uns der May wird entwandt,", "tokens": ["Da\u00df", "uns", "der", "May", "wird", "ent\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Dann singen wir fort in das ander Land.", "tokens": ["Dann", "sin\u00b7gen", "wir", "fort", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Alleweg m\u00f6gen wir nit hie bleiben,", "tokens": ["Al\u00b7le\u00b7weg", "m\u00f6\u00b7gen", "wir", "nit", "hie", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Der Tod will uns von hinnen treiben;", "tokens": ["Der", "Tod", "will", "uns", "von", "hin\u00b7nen", "trei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Noch morgen oder alle zur Hand,", "tokens": ["Noch", "mor\u00b7gen", "o\u00b7der", "al\u00b7le", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "PIS", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Gott wei\u00df, wir m\u00fcssen in das ander Land.", "tokens": ["Gott", "wei\u00df", ",", "wir", "m\u00fcs\u00b7sen", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PPER", "VMFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Wie sch\u00f6n wir uns zieren und waschen,", "tokens": ["Wie", "sch\u00f6n", "wir", "uns", "zie\u00b7ren", "und", "wa\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PPER", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir sind doch erst kommen von Aschen;", "tokens": ["Wir", "sind", "doch", "erst", "kom\u00b7men", "von", "A\u00b7schen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVFIN", "APPR", "NE", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Das erst Volk, das man fand,", "tokens": ["Das", "erst", "Volk", ",", "das", "man", "fand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Das ist auch fort in das ander Land.", "tokens": ["Das", "ist", "auch", "fort", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PTKVZ", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Ach was ist s\u00fc\u00dfer, als das Leben,", "tokens": ["Ach", "was", "ist", "s\u00fc\u00b7\u00dfer", ",", "als", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VAFIN", "ADJD", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wir m\u00fcssen doch sterbend uns de\u00df begeben;", "tokens": ["Wir", "m\u00fcs\u00b7sen", "doch", "ster\u00b7bend", "uns", "de\u00df", "be\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "PPER", "ART", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Der Tod k\u00f6mmt sonder Wiederstand,", "tokens": ["Der", "Tod", "k\u00f6mmt", "son\u00b7der", "Wie\u00b7der\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und schleift uns in das ander Land.", "tokens": ["Und", "schleift", "uns", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich wach, ich sorg, ich bebe, ich kreide,", "tokens": ["Ich", "wach", ",", "ich", "sorg", ",", "ich", "be\u00b7be", ",", "ich", "krei\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Um Gut, das ist doch andrer Leute;", "tokens": ["Um", "Gut", ",", "das", "ist", "doch", "an\u00b7drer", "Leu\u00b7te", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJD", "$,", "PDS", "VAFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es war auch hie, als ich es fand,", "tokens": ["Es", "war", "auch", "hie", ",", "als", "ich", "es", "fand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier la\u00df ich es, und fahr in das ander Land.", "tokens": ["Hier", "la\u00df", "ich", "es", ",", "und", "fahr", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PPER", "$,", "KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Ich gehe scharren und sch\u00fcrchen,", "tokens": ["Ich", "ge\u00b7he", "schar\u00b7ren", "und", "sch\u00fcr\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Um Gut, als wollt ich mich erw\u00fcrgen;", "tokens": ["Um", "Gut", ",", "als", "wollt", "ich", "mich", "er\u00b7w\u00fcr\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJD", "$,", "KOUS", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Gott hat mich nit darum hergesandt,", "tokens": ["Gott", "hat", "mich", "nit", "da\u00b7rum", "her\u00b7ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PTKNEG", "PAV", "VVPP", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Mu\u00df nacket und blo\u00df in das ander Land.", "tokens": ["Mu\u00df", "na\u00b7cket", "und", "blo\u00df", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVFIN", "KON", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.8": {"line.1": {"text": "Ich sollte Gott hie zu allen Zeiten", "tokens": ["Ich", "soll\u00b7te", "Gott", "hie", "zu", "al\u00b7len", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "ADV", "APPR", "PIAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Loben, danken und benedeien;", "tokens": ["Lo\u00b7ben", ",", "dan\u00b7ken", "und", "be\u00b7ne\u00b7dei\u00b7en", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVINF", "KON", "NE", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Das w\u00e4r mein Schutz und mein Gewand", "tokens": ["Das", "w\u00e4r", "mein", "Schutz", "und", "mein", "Ge\u00b7wand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor Satanas in dem andern Land.", "tokens": ["Vor", "Sa\u00b7ta\u00b7nas", "in", "dem", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Herr Geyer, Herr Geyer, was ihr hie m\u00f6gt erkriegen,", "tokens": ["Herr", "Ge\u00b7yer", ",", "Herr", "Ge\u00b7yer", ",", "was", "ihr", "hie", "m\u00f6gt", "er\u00b7krie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "NN", "NE", "$,", "PWS", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-++-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.2": {"text": "Es mu\u00df doch alles hie bleiben liegen;", "tokens": ["Es", "mu\u00df", "doch", "al\u00b7les", "hie", "blei\u00b7ben", "lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIS", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mit uns m\u00fc\u00dft ihr unter den Sand,", "tokens": ["Mit", "uns", "m\u00fc\u00dft", "ihr", "un\u00b7ter", "den", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VMFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Fahren hin in das ander Land.", "tokens": ["Fah\u00b7ren", "hin", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.10": {"line.1": {"text": "Keines Menschen Gut oder Ehr sollst du ihm nehmen,", "tokens": ["Kei\u00b7nes", "Men\u00b7schen", "Gut", "o\u00b7der", "Ehr", "sollst", "du", "ihm", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "KON", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Freund! de\u00df sollst du dich sch\u00e4men;", "tokens": ["Freund", "!", "de\u00df", "sollst", "du", "dich", "sch\u00e4\u00b7men", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Die das thaten, die wurden geschand't,", "tokens": ["Die", "das", "tha\u00b7ten", ",", "die", "wur\u00b7den", "ge\u00b7schand't", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "VVFIN", "$,", "PRELS", "VAFIN", "VVPP", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Hie und auch im andern Land.", "tokens": ["Hie", "und", "auch", "im", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Kein Schande oder Schaden sollst du klaffen,", "tokens": ["Kein", "Schan\u00b7de", "o\u00b7der", "Scha\u00b7den", "sollst", "du", "klaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf M\u00f6nche, Nonnen oder Pfaffen;", "tokens": ["Auf", "M\u00f6n\u00b7che", ",", "Non\u00b7nen", "o\u00b7der", "Pfaf\u00b7fen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sind Gottes Schatz und edel Persant,", "tokens": ["Sie", "sind", "Got\u00b7tes", "Schatz", "und", "e\u00b7del", "Per\u00b7sant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "NN", "KON", "ADJD", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Sie geben Rede in dem andern Land.", "tokens": ["Sie", "ge\u00b7ben", "Re\u00b7de", "in", "dem", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Wo ist Karle, Hektor und Alexander?", "tokens": ["Wo", "ist", "Kar\u00b7le", ",", "Hek\u00b7tor", "und", "A\u00b7lex\u00b7an\u00b7der", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NE", "$,", "NE", "KON", "NE", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Julius, Artus und mancher ander?", "tokens": ["Ju\u00b7lius", ",", "Ar\u00b7tus", "und", "man\u00b7cher", "an\u00b7der", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "KON", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ritter, Knecht und mancher Wigand,", "tokens": ["Rit\u00b7ter", ",", "Knecht", "und", "man\u00b7cher", "Wi\u00b7gand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo anders denn im andern Land.", "tokens": ["Wo", "an\u00b7ders", "denn", "im", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "W\u00e4r irgend ein Kaiser von Rome,", "tokens": ["W\u00e4r", "ir\u00b7gend", "ein", "Kai\u00b7ser", "von", "Ro\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Der edel w\u00e4r oder so schone;", "tokens": ["Der", "e\u00b7del", "w\u00e4r", "o\u00b7der", "so", "scho\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als ein Karfunkel oder Diamant,", "tokens": ["Als", "ein", "Kar\u00b7fun\u00b7kel", "o\u00b7der", "Di\u00b7a\u00b7mant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Er mu\u00df nacket in das ander Land.", "tokens": ["Er", "mu\u00df", "na\u00b7cket", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.14": {"line.1": {"text": "Wir gehen, als die vor uns waren,", "tokens": ["Wir", "ge\u00b7hen", ",", "als", "die", "vor", "uns", "wa\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "APPR", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Starke, weise, sch\u00f6n von Jahren;", "tokens": ["Star\u00b7ke", ",", "wei\u00b7se", ",", "sch\u00f6n", "von", "Jah\u00b7ren", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie man sie nennt, oder waren genannt,", "tokens": ["Wie", "man", "sie", "nennt", ",", "o\u00b7der", "wa\u00b7ren", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVFIN", "$,", "KON", "VAFIN", "VVPP", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Sie sind all vor uns in das ander Land.", "tokens": ["Sie", "sind", "all", "vor", "uns", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "APPR", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Der Tag mag zu Abend kommen,", "tokens": ["Der", "Tag", "mag", "zu", "A\u00b7bend", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Es sey zu Schaden oder zu Frommen;", "tokens": ["Es", "sey", "zu", "Scha\u00b7den", "o\u00b7der", "zu", "From\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nach dem Leben kommt der Tod gerannt,", "tokens": ["Nach", "dem", "Le\u00b7ben", "kommt", "der", "Tod", "ge\u00b7rannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und treibt uns in das ander Land.", "tokens": ["Und", "treibt", "uns", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Als wir sind tod, wir m\u00f6gen kriegen,", "tokens": ["Als", "wir", "sind", "tod", ",", "wir", "m\u00f6\u00b7gen", "krie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein alt Leylach, darin wir liegen;", "tokens": ["Ein", "alt", "Ley\u00b7lach", ",", "da\u00b7rin", "wir", "lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "PAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Oder ein neue Kiste bekannt,", "tokens": ["O\u00b7der", "ein", "neu\u00b7e", "Kis\u00b7te", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Also fahren wir in das ander Land.", "tokens": ["Al\u00b7so", "fah\u00b7ren", "wir", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.17": {"line.1": {"text": "Wir werden alle nackend geboren,", "tokens": ["Wir", "wer\u00b7den", "al\u00b7le", "na\u00b7ckend", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Kein eigen Gut haben wir zware;", "tokens": ["Kein", "ei\u00b7gen", "Gut", "ha\u00b7ben", "wir", "zwa\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Denn unsre Seele ist ein Unterpfand,", "tokens": ["Denn", "uns\u00b7re", "See\u00b7le", "ist", "ein", "Un\u00b7ter\u00b7pfand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ihr Werk findet sie in dem andern Land.", "tokens": ["Ihr", "Werk", "fin\u00b7det", "sie", "in", "dem", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.18": {"line.1": {"text": "O Seele, o Seele, geistliche Kreature,", "tokens": ["O", "See\u00b7le", ",", "o", "See\u00b7le", ",", "geist\u00b7li\u00b7che", "Kre\u00b7a\u00b7tu\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "FM", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Gott schuf dich selber nach seiner Figure;", "tokens": ["Gott", "schuf", "dich", "sel\u00b7ber", "nach", "sei\u00b7ner", "Fi\u00b7gu\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Was du hast ges\u00e4et oder gepflanzt,", "tokens": ["Was", "du", "hast", "ge\u00b7s\u00e4et", "o\u00b7der", "ge\u00b7pflanzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "VVPP", "KON", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Das sollst du erndten in dem andern Land.", "tokens": ["Das", "sollst", "du", "ernd\u00b7ten", "in", "dem", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Das Beste, des ich mich kann entsinnen,", "tokens": ["Das", "Bes\u00b7te", ",", "des", "ich", "mich", "kann", "ent\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Das ist Gott f\u00fcrchten und allzeit minnen;", "tokens": ["Das", "ist", "Gott", "f\u00fcrch\u00b7ten", "und", "all\u00b7zeit", "min\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "VVINF", "KON", "ADV", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das soll seyn unsrer Seele Gewand,", "tokens": ["Das", "soll", "seyn", "uns\u00b7rer", "See\u00b7le", "Ge\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "VAINF", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "So fahren wir sicher in das ander Land.", "tokens": ["So", "fah\u00b7ren", "wir", "si\u00b7cher", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.20": {"line.1": {"text": "Wenn wir werden alt, krank und krumm,", "tokens": ["Wenn", "wir", "wer\u00b7den", "alt", ",", "krank", "und", "krumm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "So w\u00e4r es Zeit, da\u00df wir uns s\u00e4hen um;", "tokens": ["So", "w\u00e4r", "es", "Zeit", ",", "da\u00df", "wir", "uns", "s\u00e4\u00b7hen", "um", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn uns entf\u00e4llt der Leckerzahn,", "tokens": ["Und", "wenn", "uns", "ent\u00b7f\u00e4llt", "der", "Le\u00b7cker\u00b7zahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "So wollen wir bald in das ander Land.", "tokens": ["So", "wol\u00b7len", "wir", "bald", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Ach Gott, wer soll unser Geleitsmann seyn?", "tokens": ["Ach", "Gott", ",", "wer", "soll", "un\u00b7ser", "Ge\u00b7leits\u00b7mann", "seyn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PWS", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wir wissen ja nichts von unsrer Pein;", "tokens": ["Wir", "wis\u00b7sen", "ja", "nichts", "von", "uns\u00b7rer", "Pein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Weg ist fern und unbekannt,", "tokens": ["Der", "Weg", "ist", "fern", "und", "un\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den wir hinfahren in das ander Land.", "tokens": ["Den", "wir", "hin\u00b7fah\u00b7ren", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Nachdem als man beschrieben findt,", "tokens": ["Nach\u00b7dem", "als", "man", "be\u00b7schrie\u00b7ben", "findt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So ist unser Leben als der Wind;", "tokens": ["So", "ist", "un\u00b7ser", "Le\u00b7ben", "als", "der", "Wind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Der da flieget \u00fcber den Sand,", "tokens": ["Der", "da", "flie\u00b7get", "\u00fc\u00b7ber", "den", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "So schnell fahren wir in das ander Land.", "tokens": ["So", "schnell", "fah\u00b7ren", "wir", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}}, "stanza.23": {"line.1": {"text": "Ach da\u00df ich je ward geboren!", "tokens": ["Ach", "da\u00df", "ich", "je", "ward", "ge\u00b7bo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KOUS", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Da\u00df ich meine Zeit also hab verloren;", "tokens": ["Da\u00df", "ich", "mei\u00b7ne", "Zeit", "al\u00b7so", "hab", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-++-+-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Ach Herre, ich setze meine Seel in deine Hand,", "tokens": ["Ach", "Her\u00b7re", ",", "ich", "set\u00b7ze", "mei\u00b7ne", "Seel", "in", "dei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wenn ich hinfahre in das ander Land.", "tokens": ["Wenn", "ich", "hin\u00b7fah\u00b7re", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Wir wollen immer das beste hoffen,", "tokens": ["Wir", "wol\u00b7len", "im\u00b7mer", "das", "bes\u00b7te", "hof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Gottesgnade steht uns allzeit offen;", "tokens": ["Die", "Got\u00b7tes\u00b7gna\u00b7de", "steht", "uns", "all\u00b7zeit", "of\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wiewohl uns Gott hat hergesandt,", "tokens": ["Wie\u00b7wohl", "uns", "Gott", "hat", "her\u00b7ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch m\u00fcssen wir in das ander Land.", "tokens": ["Doch", "m\u00fcs\u00b7sen", "wir", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.25": {"line.1": {"text": "Bitten wir Maria die Jungfrau rein,", "tokens": ["Bit\u00b7ten", "wir", "Ma\u00b7ria", "die", "Jung\u00b7frau", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NE", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Da\u00df sie unsre Tr\u00f6sterin wolle seyn;", "tokens": ["Da\u00df", "sie", "uns\u00b7re", "Tr\u00f6s\u00b7te\u00b7rin", "wol\u00b7le", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VMFIN", "VAINF", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und bleiben doch immer unser Vorstand,", "tokens": ["Und", "blei\u00b7ben", "doch", "im\u00b7mer", "un\u00b7ser", "Vor\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wenn wir fahren dahin in das ander Land.", "tokens": ["Wenn", "wir", "fah\u00b7ren", "da\u00b7hin", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PAV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.26": {"line.1": {"text": "Unser Herr Jesus hat uns gegeben", "tokens": ["Un\u00b7ser", "Herr", "Je\u00b7sus", "hat", "uns", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NE", "VAFIN", "PPER", "VVPP"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Im Himmelreich fein ewiges Leben;", "tokens": ["Im", "Him\u00b7mel\u00b7reich", "fein", "e\u00b7wi\u00b7ges", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Er beh\u00fcte uns vor dem b\u00f6sen Volant,", "tokens": ["Er", "be\u00b7h\u00fc\u00b7te", "uns", "vor", "dem", "b\u00f6\u00b7sen", "Vo\u00b7lant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Da\u00df wir nit kommen in das h\u00f6llische Land.", "tokens": ["Da\u00df", "wir", "nit", "kom\u00b7men", "in", "das", "h\u00f6l\u00b7li\u00b7sche", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVINF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.27": {"line.1": {"text": "Das ist aus: Ich kann nit mehr beschreiben,", "tokens": ["Das", "ist", "aus", ":", "Ich", "kann", "nit", "mehr", "be\u00b7schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKVZ", "$.", "PPER", "VMFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Gott! der weise uns in sein ewig Leben;", "tokens": ["Gott", "!", "der", "wei\u00b7se", "uns", "in", "sein", "e\u00b7wig", "Le\u00b7ben", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJD", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Da\u00df wir da werden m\u00f6gen bekannt", "tokens": ["Da\u00df", "wir", "da", "wer\u00b7den", "m\u00f6\u00b7gen", "be\u00b7kannt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VAINF", "VMFIN", "ADJD"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit allen Heiligen in dem himmlischen Land.", "tokens": ["Mit", "al\u00b7len", "Hei\u00b7li\u00b7gen", "in", "dem", "himm\u00b7li\u00b7schen", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.28": {"line.1": {"text": "Es ist nit allewege Festabend,", "tokens": ["Es", "ist", "nit", "al\u00b7le\u00b7we\u00b7ge", "Fest\u00b7a\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Der Tod k\u00f6mmt und bringet den Abend;", "tokens": ["Der", "Tod", "k\u00f6mmt", "und", "brin\u00b7get", "den", "A\u00b7bend", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und bindt uns mit einem festen Band,", "tokens": ["Und", "bindt", "uns", "mit", "ei\u00b7nem", "fes\u00b7ten", "Band", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da\u00df er uns bringe in das ander Land.", "tokens": ["Da\u00df", "er", "uns", "brin\u00b7ge", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Auch so ist allezeit nit Maye,", "tokens": ["Auch", "so", "ist", "al\u00b7le\u00b7zeit", "nit", "Ma\u00b7ye", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ADV", "PTKNEG", "NE", "$,"], "meter": "-----+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Wir m\u00fcssen tanzen an dem Reihe;", "tokens": ["Wir", "m\u00fcs\u00b7sen", "tan\u00b7zen", "an", "dem", "Rei\u00b7he", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df uns der May wird entwandt,", "tokens": ["Da\u00df", "uns", "der", "May", "wird", "ent\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Dann singen wir fort in das ander Land.", "tokens": ["Dann", "sin\u00b7gen", "wir", "fort", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Alleweg m\u00f6gen wir nit hie bleiben,", "tokens": ["Al\u00b7le\u00b7weg", "m\u00f6\u00b7gen", "wir", "nit", "hie", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Der Tod will uns von hinnen treiben;", "tokens": ["Der", "Tod", "will", "uns", "von", "hin\u00b7nen", "trei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Noch morgen oder alle zur Hand,", "tokens": ["Noch", "mor\u00b7gen", "o\u00b7der", "al\u00b7le", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "PIS", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Gott wei\u00df, wir m\u00fcssen in das ander Land.", "tokens": ["Gott", "wei\u00df", ",", "wir", "m\u00fcs\u00b7sen", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PPER", "VMFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "Wie sch\u00f6n wir uns zieren und waschen,", "tokens": ["Wie", "sch\u00f6n", "wir", "uns", "zie\u00b7ren", "und", "wa\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PPER", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wir sind doch erst kommen von Aschen;", "tokens": ["Wir", "sind", "doch", "erst", "kom\u00b7men", "von", "A\u00b7schen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVFIN", "APPR", "NE", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Das erst Volk, das man fand,", "tokens": ["Das", "erst", "Volk", ",", "das", "man", "fand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Das ist auch fort in das ander Land.", "tokens": ["Das", "ist", "auch", "fort", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PTKVZ", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.32": {"line.1": {"text": "Ach was ist s\u00fc\u00dfer, als das Leben,", "tokens": ["Ach", "was", "ist", "s\u00fc\u00b7\u00dfer", ",", "als", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VAFIN", "ADJD", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wir m\u00fcssen doch sterbend uns de\u00df begeben;", "tokens": ["Wir", "m\u00fcs\u00b7sen", "doch", "ster\u00b7bend", "uns", "de\u00df", "be\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "PPER", "ART", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Der Tod k\u00f6mmt sonder Wiederstand,", "tokens": ["Der", "Tod", "k\u00f6mmt", "son\u00b7der", "Wie\u00b7der\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und schleift uns in das ander Land.", "tokens": ["Und", "schleift", "uns", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Ich wach, ich sorg, ich bebe, ich kreide,", "tokens": ["Ich", "wach", ",", "ich", "sorg", ",", "ich", "be\u00b7be", ",", "ich", "krei\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Um Gut, das ist doch andrer Leute;", "tokens": ["Um", "Gut", ",", "das", "ist", "doch", "an\u00b7drer", "Leu\u00b7te", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJD", "$,", "PDS", "VAFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es war auch hie, als ich es fand,", "tokens": ["Es", "war", "auch", "hie", ",", "als", "ich", "es", "fand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier la\u00df ich es, und fahr in das ander Land.", "tokens": ["Hier", "la\u00df", "ich", "es", ",", "und", "fahr", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PPER", "$,", "KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.34": {"line.1": {"text": "Ich gehe scharren und sch\u00fcrchen,", "tokens": ["Ich", "ge\u00b7he", "schar\u00b7ren", "und", "sch\u00fcr\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Um Gut, als wollt ich mich erw\u00fcrgen;", "tokens": ["Um", "Gut", ",", "als", "wollt", "ich", "mich", "er\u00b7w\u00fcr\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJD", "$,", "KOUS", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Gott hat mich nit darum hergesandt,", "tokens": ["Gott", "hat", "mich", "nit", "da\u00b7rum", "her\u00b7ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PTKNEG", "PAV", "VVPP", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Mu\u00df nacket und blo\u00df in das ander Land.", "tokens": ["Mu\u00df", "na\u00b7cket", "und", "blo\u00df", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVFIN", "KON", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.35": {"line.1": {"text": "Ich sollte Gott hie zu allen Zeiten", "tokens": ["Ich", "soll\u00b7te", "Gott", "hie", "zu", "al\u00b7len", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "ADV", "APPR", "PIAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Loben, danken und benedeien;", "tokens": ["Lo\u00b7ben", ",", "dan\u00b7ken", "und", "be\u00b7ne\u00b7dei\u00b7en", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVINF", "KON", "NE", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Das w\u00e4r mein Schutz und mein Gewand", "tokens": ["Das", "w\u00e4r", "mein", "Schutz", "und", "mein", "Ge\u00b7wand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor Satanas in dem andern Land.", "tokens": ["Vor", "Sa\u00b7ta\u00b7nas", "in", "dem", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.36": {"line.1": {"text": "Herr Geyer, Herr Geyer, was ihr hie m\u00f6gt erkriegen,", "tokens": ["Herr", "Ge\u00b7yer", ",", "Herr", "Ge\u00b7yer", ",", "was", "ihr", "hie", "m\u00f6gt", "er\u00b7krie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "NN", "NE", "$,", "PWS", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-++-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.2": {"text": "Es mu\u00df doch alles hie bleiben liegen;", "tokens": ["Es", "mu\u00df", "doch", "al\u00b7les", "hie", "blei\u00b7ben", "lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIS", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mit uns m\u00fc\u00dft ihr unter den Sand,", "tokens": ["Mit", "uns", "m\u00fc\u00dft", "ihr", "un\u00b7ter", "den", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VMFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Fahren hin in das ander Land.", "tokens": ["Fah\u00b7ren", "hin", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.37": {"line.1": {"text": "Keines Menschen Gut oder Ehr sollst du ihm nehmen,", "tokens": ["Kei\u00b7nes", "Men\u00b7schen", "Gut", "o\u00b7der", "Ehr", "sollst", "du", "ihm", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "KON", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Freund! de\u00df sollst du dich sch\u00e4men;", "tokens": ["Freund", "!", "de\u00df", "sollst", "du", "dich", "sch\u00e4\u00b7men", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Die das thaten, die wurden geschand't,", "tokens": ["Die", "das", "tha\u00b7ten", ",", "die", "wur\u00b7den", "ge\u00b7schand't", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "VVFIN", "$,", "PRELS", "VAFIN", "VVPP", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Hie und auch im andern Land.", "tokens": ["Hie", "und", "auch", "im", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Kein Schande oder Schaden sollst du klaffen,", "tokens": ["Kein", "Schan\u00b7de", "o\u00b7der", "Scha\u00b7den", "sollst", "du", "klaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf M\u00f6nche, Nonnen oder Pfaffen;", "tokens": ["Auf", "M\u00f6n\u00b7che", ",", "Non\u00b7nen", "o\u00b7der", "Pfaf\u00b7fen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sind Gottes Schatz und edel Persant,", "tokens": ["Sie", "sind", "Got\u00b7tes", "Schatz", "und", "e\u00b7del", "Per\u00b7sant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "NN", "KON", "ADJD", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Sie geben Rede in dem andern Land.", "tokens": ["Sie", "ge\u00b7ben", "Re\u00b7de", "in", "dem", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.39": {"line.1": {"text": "Wo ist Karle, Hektor und Alexander?", "tokens": ["Wo", "ist", "Kar\u00b7le", ",", "Hek\u00b7tor", "und", "A\u00b7lex\u00b7an\u00b7der", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NE", "$,", "NE", "KON", "NE", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Julius, Artus und mancher ander?", "tokens": ["Ju\u00b7lius", ",", "Ar\u00b7tus", "und", "man\u00b7cher", "an\u00b7der", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "KON", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ritter, Knecht und mancher Wigand,", "tokens": ["Rit\u00b7ter", ",", "Knecht", "und", "man\u00b7cher", "Wi\u00b7gand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo anders denn im andern Land.", "tokens": ["Wo", "an\u00b7ders", "denn", "im", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "W\u00e4r irgend ein Kaiser von Rome,", "tokens": ["W\u00e4r", "ir\u00b7gend", "ein", "Kai\u00b7ser", "von", "Ro\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Der edel w\u00e4r oder so schone;", "tokens": ["Der", "e\u00b7del", "w\u00e4r", "o\u00b7der", "so", "scho\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als ein Karfunkel oder Diamant,", "tokens": ["Als", "ein", "Kar\u00b7fun\u00b7kel", "o\u00b7der", "Di\u00b7a\u00b7mant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Er mu\u00df nacket in das ander Land.", "tokens": ["Er", "mu\u00df", "na\u00b7cket", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.41": {"line.1": {"text": "Wir gehen, als die vor uns waren,", "tokens": ["Wir", "ge\u00b7hen", ",", "als", "die", "vor", "uns", "wa\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "APPR", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Starke, weise, sch\u00f6n von Jahren;", "tokens": ["Star\u00b7ke", ",", "wei\u00b7se", ",", "sch\u00f6n", "von", "Jah\u00b7ren", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie man sie nennt, oder waren genannt,", "tokens": ["Wie", "man", "sie", "nennt", ",", "o\u00b7der", "wa\u00b7ren", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVFIN", "$,", "KON", "VAFIN", "VVPP", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Sie sind all vor uns in das ander Land.", "tokens": ["Sie", "sind", "all", "vor", "uns", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "APPR", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.42": {"line.1": {"text": "Der Tag mag zu Abend kommen,", "tokens": ["Der", "Tag", "mag", "zu", "A\u00b7bend", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Es sey zu Schaden oder zu Frommen;", "tokens": ["Es", "sey", "zu", "Scha\u00b7den", "o\u00b7der", "zu", "From\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nach dem Leben kommt der Tod gerannt,", "tokens": ["Nach", "dem", "Le\u00b7ben", "kommt", "der", "Tod", "ge\u00b7rannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und treibt uns in das ander Land.", "tokens": ["Und", "treibt", "uns", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Als wir sind tod, wir m\u00f6gen kriegen,", "tokens": ["Als", "wir", "sind", "tod", ",", "wir", "m\u00f6\u00b7gen", "krie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein alt Leylach, darin wir liegen;", "tokens": ["Ein", "alt", "Ley\u00b7lach", ",", "da\u00b7rin", "wir", "lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "PAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Oder ein neue Kiste bekannt,", "tokens": ["O\u00b7der", "ein", "neu\u00b7e", "Kis\u00b7te", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Also fahren wir in das ander Land.", "tokens": ["Al\u00b7so", "fah\u00b7ren", "wir", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.44": {"line.1": {"text": "Wir werden alle nackend geboren,", "tokens": ["Wir", "wer\u00b7den", "al\u00b7le", "na\u00b7ckend", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Kein eigen Gut haben wir zware;", "tokens": ["Kein", "ei\u00b7gen", "Gut", "ha\u00b7ben", "wir", "zwa\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Denn unsre Seele ist ein Unterpfand,", "tokens": ["Denn", "uns\u00b7re", "See\u00b7le", "ist", "ein", "Un\u00b7ter\u00b7pfand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ihr Werk findet sie in dem andern Land.", "tokens": ["Ihr", "Werk", "fin\u00b7det", "sie", "in", "dem", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.45": {"line.1": {"text": "O Seele, o Seele, geistliche Kreature,", "tokens": ["O", "See\u00b7le", ",", "o", "See\u00b7le", ",", "geist\u00b7li\u00b7che", "Kre\u00b7a\u00b7tu\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "FM", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Gott schuf dich selber nach seiner Figure;", "tokens": ["Gott", "schuf", "dich", "sel\u00b7ber", "nach", "sei\u00b7ner", "Fi\u00b7gu\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Was du hast ges\u00e4et oder gepflanzt,", "tokens": ["Was", "du", "hast", "ge\u00b7s\u00e4et", "o\u00b7der", "ge\u00b7pflanzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "VVPP", "KON", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Das sollst du erndten in dem andern Land.", "tokens": ["Das", "sollst", "du", "ernd\u00b7ten", "in", "dem", "an\u00b7dern", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.46": {"line.1": {"text": "Das Beste, des ich mich kann entsinnen,", "tokens": ["Das", "Bes\u00b7te", ",", "des", "ich", "mich", "kann", "ent\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Das ist Gott f\u00fcrchten und allzeit minnen;", "tokens": ["Das", "ist", "Gott", "f\u00fcrch\u00b7ten", "und", "all\u00b7zeit", "min\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "VVINF", "KON", "ADV", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das soll seyn unsrer Seele Gewand,", "tokens": ["Das", "soll", "seyn", "uns\u00b7rer", "See\u00b7le", "Ge\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "VAINF", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "So fahren wir sicher in das ander Land.", "tokens": ["So", "fah\u00b7ren", "wir", "si\u00b7cher", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.47": {"line.1": {"text": "Wenn wir werden alt, krank und krumm,", "tokens": ["Wenn", "wir", "wer\u00b7den", "alt", ",", "krank", "und", "krumm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "So w\u00e4r es Zeit, da\u00df wir uns s\u00e4hen um;", "tokens": ["So", "w\u00e4r", "es", "Zeit", ",", "da\u00df", "wir", "uns", "s\u00e4\u00b7hen", "um", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn uns entf\u00e4llt der Leckerzahn,", "tokens": ["Und", "wenn", "uns", "ent\u00b7f\u00e4llt", "der", "Le\u00b7cker\u00b7zahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "So wollen wir bald in das ander Land.", "tokens": ["So", "wol\u00b7len", "wir", "bald", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.48": {"line.1": {"text": "Ach Gott, wer soll unser Geleitsmann seyn?", "tokens": ["Ach", "Gott", ",", "wer", "soll", "un\u00b7ser", "Ge\u00b7leits\u00b7mann", "seyn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PWS", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wir wissen ja nichts von unsrer Pein;", "tokens": ["Wir", "wis\u00b7sen", "ja", "nichts", "von", "uns\u00b7rer", "Pein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Weg ist fern und unbekannt,", "tokens": ["Der", "Weg", "ist", "fern", "und", "un\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den wir hinfahren in das ander Land.", "tokens": ["Den", "wir", "hin\u00b7fah\u00b7ren", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.49": {"line.1": {"text": "Nachdem als man beschrieben findt,", "tokens": ["Nach\u00b7dem", "als", "man", "be\u00b7schrie\u00b7ben", "findt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So ist unser Leben als der Wind;", "tokens": ["So", "ist", "un\u00b7ser", "Le\u00b7ben", "als", "der", "Wind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Der da flieget \u00fcber den Sand,", "tokens": ["Der", "da", "flie\u00b7get", "\u00fc\u00b7ber", "den", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "So schnell fahren wir in das ander Land.", "tokens": ["So", "schnell", "fah\u00b7ren", "wir", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}}, "stanza.50": {"line.1": {"text": "Ach da\u00df ich je ward geboren!", "tokens": ["Ach", "da\u00df", "ich", "je", "ward", "ge\u00b7bo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KOUS", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Da\u00df ich meine Zeit also hab verloren;", "tokens": ["Da\u00df", "ich", "mei\u00b7ne", "Zeit", "al\u00b7so", "hab", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-++-+-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Ach Herre, ich setze meine Seel in deine Hand,", "tokens": ["Ach", "Her\u00b7re", ",", "ich", "set\u00b7ze", "mei\u00b7ne", "Seel", "in", "dei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wenn ich hinfahre in das ander Land.", "tokens": ["Wenn", "ich", "hin\u00b7fah\u00b7re", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.51": {"line.1": {"text": "Wir wollen immer das beste hoffen,", "tokens": ["Wir", "wol\u00b7len", "im\u00b7mer", "das", "bes\u00b7te", "hof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Gottesgnade steht uns allzeit offen;", "tokens": ["Die", "Got\u00b7tes\u00b7gna\u00b7de", "steht", "uns", "all\u00b7zeit", "of\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wiewohl uns Gott hat hergesandt,", "tokens": ["Wie\u00b7wohl", "uns", "Gott", "hat", "her\u00b7ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch m\u00fcssen wir in das ander Land.", "tokens": ["Doch", "m\u00fcs\u00b7sen", "wir", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.52": {"line.1": {"text": "Bitten wir Maria die Jungfrau rein,", "tokens": ["Bit\u00b7ten", "wir", "Ma\u00b7ria", "die", "Jung\u00b7frau", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NE", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Da\u00df sie unsre Tr\u00f6sterin wolle seyn;", "tokens": ["Da\u00df", "sie", "uns\u00b7re", "Tr\u00f6s\u00b7te\u00b7rin", "wol\u00b7le", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VMFIN", "VAINF", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und bleiben doch immer unser Vorstand,", "tokens": ["Und", "blei\u00b7ben", "doch", "im\u00b7mer", "un\u00b7ser", "Vor\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wenn wir fahren dahin in das ander Land.", "tokens": ["Wenn", "wir", "fah\u00b7ren", "da\u00b7hin", "in", "das", "an\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PAV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.53": {"line.1": {"text": "Unser Herr Jesus hat uns gegeben", "tokens": ["Un\u00b7ser", "Herr", "Je\u00b7sus", "hat", "uns", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NE", "VAFIN", "PPER", "VVPP"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Im Himmelreich fein ewiges Leben;", "tokens": ["Im", "Him\u00b7mel\u00b7reich", "fein", "e\u00b7wi\u00b7ges", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Er beh\u00fcte uns vor dem b\u00f6sen Volant,", "tokens": ["Er", "be\u00b7h\u00fc\u00b7te", "uns", "vor", "dem", "b\u00f6\u00b7sen", "Vo\u00b7lant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Da\u00df wir nit kommen in das h\u00f6llische Land.", "tokens": ["Da\u00df", "wir", "nit", "kom\u00b7men", "in", "das", "h\u00f6l\u00b7li\u00b7sche", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVINF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.54": {"line.1": {"text": "Das ist aus: Ich kann nit mehr beschreiben,", "tokens": ["Das", "ist", "aus", ":", "Ich", "kann", "nit", "mehr", "be\u00b7schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKVZ", "$.", "PPER", "VMFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Gott! der weise uns in sein ewig Leben;", "tokens": ["Gott", "!", "der", "wei\u00b7se", "uns", "in", "sein", "e\u00b7wig", "Le\u00b7ben", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJD", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Da\u00df wir da werden m\u00f6gen bekannt", "tokens": ["Da\u00df", "wir", "da", "wer\u00b7den", "m\u00f6\u00b7gen", "be\u00b7kannt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VAINF", "VMFIN", "ADJD"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit allen Heiligen in dem himmlischen Land.", "tokens": ["Mit", "al\u00b7len", "Hei\u00b7li\u00b7gen", "in", "dem", "himm\u00b7li\u00b7schen", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}}}}