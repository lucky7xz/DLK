{"textgrid.poem.31228": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Himmel lacht lasuren", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Himmel lacht lasuren", "tokens": ["Der", "Him\u00b7mel", "lacht", "la\u00b7su\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "auff ", "tokens": ["auff"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "so sanfft rauscht itzt der Bach;", "tokens": ["so", "sanfft", "rauscht", "itzt", "der", "Bach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "\u00fcmb seine Gr\u00e4sgens schnellen", "tokens": ["\u00fcmb", "sei\u00b7ne", "Gr\u00e4s\u00b7gens", "schnel\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "die zittrichten Libellen/", "tokens": ["die", "zit\u00b7trich\u00b7ten", "Li\u00b7bel\u00b7len", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "der Wald w\u00f6lbt gr\u00fcn sein Dach.", "tokens": ["der", "Wald", "w\u00f6lbt", "gr\u00fcn", "sein", "Dach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Nelcken/ Scharlach/ Amaranth", "tokens": ["Nel\u00b7cken", "/", "Schar\u00b7lach", "/", "A\u00b7ma\u00b7ran\u00b7th"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NN", "$(", "NE", "$(", "NE"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "und wa\u00df sonst noch wird benannt/", "tokens": ["und", "wa\u00df", "sonst", "noch", "wird", "be\u00b7nannt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Fenchel/ Lauch und Meusedorn/", "tokens": ["Fen\u00b7chel", "/", "Lauch", "und", "Meu\u00b7se\u00b7dorn", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Hertzgespan und Rittersporn/", "tokens": ["Hertz\u00b7ge\u00b7span", "und", "Rit\u00b7ter\u00b7sporn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Kellerhaltz und Koriander/", "tokens": ["Kel\u00b7ler\u00b7haltz", "und", "Ko\u00b7ri\u00b7an\u00b7der", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "alles bl\u00fcht itzt durcheinander.", "tokens": ["al\u00b7les", "bl\u00fcht", "itzt", "durch\u00b7ein\u00b7an\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Tausendsch\u00f6n und Akkeley/", "tokens": ["Tau\u00b7send\u00b7sch\u00f6n", "und", "Ak\u00b7ke\u00b7ley", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "Augentrost ist auch darbey.", "tokens": ["Au\u00b7gen\u00b7trost", "ist", "auch", "dar\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "das Wasser-Volck selbst lauscht/", "tokens": ["das", "Was\u00b7ser\u00b7Volck", "selbst", "lauscht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "wie s\u00fc\u00df der West-Wind itzt", "tokens": ["wie", "s\u00fc\u00df", "der", "West\u00b7Wind", "itzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ART", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "durchs L\u00e4ublein rauscht.", "tokens": ["durchs", "L\u00e4ub\u00b7lein", "rauscht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.18": {"text": "voll Engels\u00fc\u00df und Wohlgemuht/", "tokens": ["voll", "En\u00b7gel\u00b7s\u00fc\u00df", "und", "Wohl\u00b7ge\u00b7muht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "den Veilgens vor.", "tokens": ["den", "Veil\u00b7gens", "vor", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.20": {"text": "schlagen rund \u00fcmb mich den Dakkt/", "tokens": ["schla\u00b7gen", "rund", "\u00fcmb", "mich", "den", "Da\u00b7kkt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "auff das Volck mit dikken Waden", "tokens": ["auff", "das", "Volck", "mit", "dik\u00b7ken", "Wa\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "b\u00fcn ich durchau\u00df wie geladen!", "tokens": ["b\u00fcn", "ich", "durch\u00b7au\u00df", "wie", "ge\u00b7la\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KOKOM", "VVPP", "$."], "meter": "+-+++-+-", "measure": "unknown.measure.penta"}}, "stanza.2": {"line.1": {"text": "In jedem Arm ein Gr\u00fcbgen/", "tokens": ["In", "je\u00b7dem", "Arm", "ein", "Gr\u00fcb\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "im Kinn gar ihrer zwey/", "tokens": ["im", "Kinn", "gar", "ih\u00b7rer", "zwey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PPOSAT", "CARD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "mahlt mir das Fl\u00fcgel-B\u00fcbgen", "tokens": ["mahlt", "mir", "das", "Fl\u00fc\u00b7gel\u00b7B\u00fcb\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "die schwartze El\u00df-Marey.", "tokens": ["die", "schwart\u00b7ze", "El\u00df\u00b7Ma\u00b7rey", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Theils an Sch\u00f6nheit/ theils an L\u00e4nge/", "tokens": ["Theils", "an", "Sch\u00f6n\u00b7heit", "/", "theils", "an", "L\u00e4n\u00b7ge", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$(", "ADV", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "gleicht ", "tokens": ["gleicht"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Lilgen stehn f\u00fcr ihre Haut", "tokens": ["Lil\u00b7gen", "stehn", "f\u00fcr", "ih\u00b7re", "Haut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "nur wie schl\u00e4chtes K\u00f6rbel-Kraut.", "tokens": ["nur", "wie", "schl\u00e4ch\u00b7tes", "K\u00f6r\u00b7bel\u00b7Kraut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Noch so ward mir nichts bewu\u00dft", "tokens": ["Noch", "so", "ward", "mir", "nichts", "be\u00b7wu\u00dft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PIS", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "R\u00fcnderes al\u00df ihre Brust/", "tokens": ["R\u00fcn\u00b7de\u00b7res", "al\u00df", "ih\u00b7re", "Brust", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "ihrer Wangen Purpur-Pracht", "tokens": ["ih\u00b7rer", "Wan\u00b7gen", "Pur\u00b7pur\u00b7Pracht"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "hat ", "tokens": ["hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+", "measure": "single.up"}, "line.13": {"text": "Zween Arme/ deren Krafft", "tokens": ["Zween", "Ar\u00b7me", "/", "de\u00b7ren", "Krafft"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$(", "PRELAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "offt Leuen hin gerafft/", "tokens": ["offt", "Leu\u00b7en", "hin", "ge\u00b7rafft", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "zween Sch\u00e4nckel au\u00df Porfir", "tokens": ["zween", "Sch\u00e4n\u00b7ckel", "au\u00df", "Por\u00b7fir"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "NN", "APPR", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "da\u00df wer so wa\u00df for mir!", "tokens": ["da\u00df", "wer", "so", "wa\u00df", "for", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "ADV", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Ach/ ich kan mich ihretwegen", "tokens": ["Ach", "/", "ich", "kan", "mich", "ih\u00b7ret\u00b7we\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$(", "PPER", "VMFIN", "PPER", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "kaum mehr schlaffen legen!", "tokens": ["kaum", "mehr", "schlaf\u00b7fen", "le\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Filorindgen/", "tokens": ["Fi\u00b7lo\u00b7rind\u00b7gen", "/"], "token_info": ["word", "punct"], "pos": ["NE", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "lihbstes Kindgen/", "tokens": ["lihbs\u00b7tes", "Kind\u00b7gen", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "dein wie Goldt gewundner Zopf", "tokens": ["dein", "wie", "Goldt", "ge\u00b7wund\u00b7ner", "Zopf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "KOKOM", "NE", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "bringt mich deto \u00fcmb den Kopff.", "tokens": ["bringt", "mich", "de\u00b7to", "\u00fcmb", "den", "Kopff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Ich schau dich/ wa\u00df ich kan/", "tokens": ["Ich", "schau", "dich", "/", "wa\u00df", "ich", "kan", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "KOUS", "PPER", "VMFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "mit steiffen Augen an:", "tokens": ["mit", "steif\u00b7fen", "Au\u00b7gen", "an", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "du bist so s\u00fc\u00df/ so klein/", "tokens": ["du", "bist", "so", "s\u00fc\u00df", "/", "so", "klein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$(", "ADV", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "du Turttel-T\u00e4ubelein!", "tokens": ["du", "Turt\u00b7tel\u00b7T\u00e4u\u00b7be\u00b7lein", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Alles ist an dir ger\u00fcndet/", "tokens": ["Al\u00b7les", "ist", "an", "dir", "ge\u00b7r\u00fcn\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPER", "VVPP", "$("], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.10": {"text": "wordrauff sich mein Vergn\u00fcgen gr\u00fcndet;", "tokens": ["word\u00b7rauff", "sich", "mein", "Ver\u00b7gn\u00fc\u00b7gen", "gr\u00fcn\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "worhin man dir auch blikkt/", "tokens": ["wor\u00b7hin", "man", "dir", "auch", "blikkt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "man ist durchau\u00df erqwikkt.", "tokens": ["man", "ist", "durch\u00b7au\u00df", "er\u00b7qwikkt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "R\u00e4cht ein Dapps ist dein Menalk/", "tokens": ["R\u00e4cht", "ein", "Dapps", "ist", "dein", "Me\u00b7nalk", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "seine Bakken sind aus Kalck/", "tokens": ["sei\u00b7ne", "Bak\u00b7ken", "sind", "aus", "Kalck", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "seine Waden/ mu\u00df man wissen/", "tokens": ["sei\u00b7ne", "Wa\u00b7den", "/", "mu\u00df", "man", "wis\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "VMFIN", "PIS", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "hat ein Draut-Hahn abgebissen!", "tokens": ["hat", "ein", "Draut\u00b7Hahn", "ab\u00b7ge\u00b7bis\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Willstu bei dem alten Pauren", "tokens": ["Will\u00b7stu", "bei", "dem", "al\u00b7ten", "Pau\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "deine sch\u00f6nste Zeit versauren?", "tokens": ["dei\u00b7ne", "sch\u00f6ns\u00b7te", "Zeit", "ver\u00b7sau\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Lengst blagt ihn das Zipperlein/", "tokens": ["Lengst", "blagt", "ihn", "das", "Zip\u00b7per\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "gihb ihm zum purgieren ein;", "tokens": ["gihb", "ihm", "zum", "pur\u00b7gie\u00b7ren", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "r\u00e4cht vermischt au\u00df Ruch und Stanck/", "tokens": ["r\u00e4cht", "ver\u00b7mischt", "au\u00df", "Ruch", "und", "Stanck", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.22": {"text": "einen Apotheker-Tranck!", "tokens": ["ei\u00b7nen", "A\u00b7po\u00b7the\u00b7ker\u00b7Tranck", "!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Brunette/ la\u00df da\u00df seyn;", "tokens": ["Bru\u00b7net\u00b7te", "/", "la\u00df", "da\u00df", "seyn", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "VVIMP", "KOUS", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "mein Hertz ist nicht von Stein/", "tokens": ["mein", "Hertz", "ist", "nicht", "von", "Stein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "mein Hertz ist gantz au\u00df Wacks/", "tokens": ["mein", "Hertz", "ist", "gantz", "au\u00df", "Wacks", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "es br\u00e4nnt wie Flacks!", "tokens": ["es", "br\u00e4nnt", "wie", "Flacks", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Deine Augen wie Violen", "tokens": ["Dei\u00b7ne", "Au\u00b7gen", "wie", "Vi\u00b7o\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KOKOM", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sind zwo au\u00df geleschte Kolen/", "tokens": ["sind", "zwo", "au\u00df", "ge\u00b7leschte", "Ko\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "APPR", "ADJA", "NN", "$("], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "dein angenehmer Mund", "tokens": ["dein", "an\u00b7ge\u00b7neh\u00b7mer", "Mund"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "steht ahrtlig Zirckel-rund.", "tokens": ["steht", "ahrt\u00b7lig", "Zir\u00b7ckel\u00b7rund", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Du l\u00e4st durch diese Dh\u00fcr", "tokens": ["Du", "l\u00e4st", "durch", "die\u00b7se", "Dh\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "bloh\u00df Purpur-Sylben f\u00fcr/", "tokens": ["bloh\u00df", "Pur\u00b7pur\u00b7Syl\u00b7ben", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "dreyn sind in jedem Falle", "tokens": ["dreyn", "sind", "in", "je\u00b7dem", "Fal\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "APPR", "PIAT", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.12": {"text": "die Z\u00e4hne Berg-Kristalle.", "tokens": ["die", "Z\u00e4h\u00b7ne", "Ber\u00b7gKris\u00b7tal\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Dein runder Haltz/", "tokens": ["Dein", "run\u00b7der", "Haltz", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.14": {"text": "dein weisses Knie", "tokens": ["dein", "weis\u00b7ses", "Knie"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "macht keines-falls/", "tokens": ["macht", "kei\u00b7nes\u00b7falls", "/"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "NE", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "da\u00df ich dich flieh.", "tokens": ["da\u00df", "ich", "dich", "flieh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.17": {"text": "Auff deinen Br\u00fcsten schwimmt dein Hahr/", "tokens": ["Auff", "dei\u00b7nen", "Br\u00fcs\u00b7ten", "schwimmt", "dein", "Hahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Frau ", "tokens": ["Frau"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}, "stanza.5": {"line.1": {"text": "Su\u00dfgen kam von ohngefehr", "tokens": ["Su\u00df\u00b7gen", "kam", "von", "ohn\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "dr\u00e4llernd dorch die Wihse her/", "tokens": ["dr\u00e4l\u00b7lernd", "dorch", "die", "Wih\u00b7se", "her", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PAV", "ART", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "al\u00df ich nechst mein L\u00e4mmer-Volck", "tokens": ["al\u00df", "ich", "nechst", "mein", "L\u00e4m\u00b7mer\u00b7Volck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "unter einer B\u00fcche molck.", "tokens": ["un\u00b7ter", "ei\u00b7ner", "B\u00fc\u00b7che", "molck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Lab-Kraut/ Gunderman und Holler", "tokens": ["Lab\u00b7Kraut", "/", "Gun\u00b7der\u00b7man", "und", "Hol\u00b7ler"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NE", "KON", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "bund sie mir \u00fcmbs Hirten-Goller/", "tokens": ["bund", "sie", "mir", "\u00fcmbs", "Hir\u00b7ten\u00b7Gol\u00b7ler", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "alles/ wa\u00df ihr H\u00e4ndgen fund/", "tokens": ["al\u00b7les", "/", "wa\u00df", "ihr", "H\u00e4nd\u00b7gen", "fund", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$(", "KOUS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Rohsen lachte mir ihr Mund.", "tokens": ["Roh\u00b7sen", "lach\u00b7te", "mir", "ihr", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Drauff so schob ich ihr mein Fl\u00e4schgen", "tokens": ["Drauff", "so", "schob", "ich", "ihr", "mein", "Fl\u00e4schgen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VVFIN", "PPER", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "freundlich in ihr Hirten-D\u00e4schgen/", "tokens": ["freund\u00b7lich", "in", "ihr", "Hir\u00b7ten\u00b7D\u00e4schgen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "sie wusste kaum/ wie ihr geschah/", "tokens": ["sie", "wuss\u00b7te", "kaum", "/", "wie", "ihr", "ge\u00b7schah", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "PWAV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "mein Gott/ wa\u00df machstu da?", "tokens": ["mein", "Gott", "/", "wa\u00df", "machs\u00b7tu", "da", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PWAV", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Itzt l\u00e4\u00dft sie von frembden Hirten", "tokens": ["Itzt", "l\u00e4\u00dft", "sie", "von", "fremb\u00b7den", "Hir\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "sich so Hertz wie Mund bewirthen!", "tokens": ["sich", "so", "Hertz", "wie", "Mund", "be\u00b7wirt\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "NN", "KOKOM", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Mechtildgen f\u00fchrt mit gro\u00dfer Eil", "tokens": ["Mech\u00b7tild\u00b7gen", "f\u00fchrt", "mit", "gro\u00b7\u00dfer", "Eil"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mich hindter sich am Narren-Seil.", "tokens": ["mich", "hind\u00b7ter", "sich", "am", "Nar\u00b7ren\u00b7Seil", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kaum klopff ich an ihre Th\u00fcr/", "tokens": ["Kaum", "klopff", "ich", "an", "ih\u00b7re", "Th\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "ziht sie gleich den F\u00fcrhang f\u00fcr.", "tokens": ["ziht", "sie", "gleich", "den", "F\u00fcr\u00b7hang", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "M\u00e4gdgen/ rukk dein Mihder/", "tokens": ["M\u00e4gd\u00b7gen", "/", "rukk", "dein", "Mih\u00b7der", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "stell dich nicht zurwihder/", "tokens": ["stell", "dich", "nicht", "zur\u00b7wih\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "PTKNEG", "PTKVZ", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "der geb\u00fchrt allein der Prei\u00df/", "tokens": ["der", "ge\u00b7b\u00fchrt", "al\u00b7lein", "der", "Prei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "die mich r\u00e4cht zu lihben wei\u00df!", "tokens": ["die", "mich", "r\u00e4cht", "zu", "lih\u00b7ben", "wei\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "La\u00df dich endlich dr\u00fcmb erbitten/", "tokens": ["La\u00df", "dich", "end\u00b7lich", "dr\u00fcmb", "er\u00b7bit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PAV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "stell dich endlich nach Geb\u00fchr/", "tokens": ["stell", "dich", "end\u00b7lich", "nach", "Ge\u00b7b\u00fchr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ADV", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Sylvius geht mir nicht an Sitten/", "tokens": ["Syl\u00b7vius", "geht", "mir", "nicht", "an", "Sit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Thyrsis nicht an Tugend f\u00fcr.", "tokens": ["Thyr\u00b7sis", "nicht", "an", "Tu\u00b7gend", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "APPR", "NN", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "L\u00e4\u00dft dein Sinn sich nicht erweichen/", "tokens": ["L\u00e4\u00dft", "dein", "Sinn", "sich", "nicht", "er\u00b7wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PRF", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "gl\u00e4ubstu dan/ ich werd verbleichen?", "tokens": ["gl\u00e4ubs\u00b7tu", "dan", "/", "ich", "werd", "ver\u00b7blei\u00b7chen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "PPER", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Dihses sag ich rund und frey:", "tokens": ["Dih\u00b7ses", "sag", "ich", "rund", "und", "frey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "solches w\u00e4re K\u00e4lberey.", "tokens": ["sol\u00b7ches", "w\u00e4\u00b7re", "K\u00e4l\u00b7be\u00b7rey", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Meine Tauer-haffte Gluht", "tokens": ["Mei\u00b7ne", "Tau\u00b7e\u00b7rhaff\u00b7te", "Gluht"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "ist for viel wa\u00df B\u00e4ssres guht!", "tokens": ["ist", "for", "viel", "wa\u00df", "B\u00e4ss\u00b7res", "guht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "FM", "FM", "FM", "FM", "FM", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Margrittgen dhut sich zu commun/", "tokens": ["Mar\u00b7gritt\u00b7gen", "dhut", "sich", "zu", "com\u00b7mun", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "PTKZU", "VVINF", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "sie dukkt gleich nihder wie ein Huhn;", "tokens": ["sie", "dukkt", "gleich", "nih\u00b7der", "wie", "ein", "Huhn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df sie nechst lag in den Wochen/", "tokens": ["da\u00df", "sie", "nechst", "lag", "in", "den", "Wo\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "kam nicht bloh\u00df vom Kl\u00f6h\u00dfe-Kochen.", "tokens": ["kam", "nicht", "bloh\u00df", "vom", "Kl\u00f6h\u00b7\u00dfe\u00b7Ko\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wars der Kaspar/ wars der Melcher?", "tokens": ["Wars", "der", "Kas\u00b7par", "/", "wars", "der", "Melc\u00b7her", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NE", "$(", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ach/ sie wei\u00df es nicht mehr/ welcher!", "tokens": ["Ach", "/", "sie", "wei\u00df", "es", "nicht", "mehr", "/", "wel\u00b7cher", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ITJ", "$(", "PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "$(", "PWAT", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "S\u00e4lbst Hann\u00df Tapps schih\u00dft nicht vorbey \u2013", "tokens": ["S\u00e4lbst", "Hann\u00df", "Tapps", "schih\u00dft", "nicht", "vor\u00b7bey", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "VVFIN", "PTKNEG", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "ja/ so kombt man ins Geschrey.", "tokens": ["ja", "/", "so", "kombt", "man", "ins", "Ge\u00b7schrey", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "ADV", "VVFIN", "PIS", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Ambrette w\u00fcntscht sich wa\u00df.", "tokens": ["Am\u00b7bret\u00b7te", "w\u00fcnt\u00b7scht", "sich", "wa\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ein Kleid au\u00df Spihgel-Gla\u00df.", "tokens": ["Ein", "Kleid", "au\u00df", "Spih\u00b7gel\u00b7Gla\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit allem/ wa\u00df ein M\u00e4gdgen zihrt/", "tokens": ["Mit", "al\u00b7lem", "/", "wa\u00df", "ein", "M\u00e4gd\u00b7gen", "zihrt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$(", "KOUS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ist sie f\u00fcrtrefflig au\u00df staffirt.", "tokens": ["ist", "sie", "f\u00fcr\u00b7treff\u00b7lig", "au\u00df", "staf\u00b7firt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ach/ so reitzend kleine Wunde;", "tokens": ["ach", "/", "so", "reit\u00b7zend", "klei\u00b7ne", "Wun\u00b7de", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["XY", "$(", "ADV", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stechwurtz und F\u00fcnff-Finger-Kraut", "tokens": ["Stech\u00b7wurtz", "und", "F\u00fcnf\u00b7fFin\u00b7ger\u00b7Kraut"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "stehen darfor auff gebaut.", "tokens": ["ste\u00b7hen", "dar\u00b7for", "auff", "ge\u00b7baut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "APPR", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Der Himmel wird es schon so f\u00fcgen/", "tokens": ["Der", "Him\u00b7mel", "wird", "es", "schon", "so", "f\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "da\u00df wir uns beyde noch vergn\u00fcgen!", "tokens": ["da\u00df", "wir", "uns", "bey\u00b7de", "noch", "ver\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mit ihr an einem Dischgen/", "tokens": ["Mit", "ihr", "an", "ei\u00b7nem", "Dischgen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "da\u00df wer so r\u00e4cht mein ", "tokens": ["da\u00df", "wer", "so", "r\u00e4cht", "mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PWS", "ADV", "VVFIN", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.12": {"text": "ein s\u00e4lbst gebakknes Fischgen", "tokens": ["ein", "s\u00e4lbst", "ge\u00b7bakk\u00b7nes", "Fischgen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "reicht sie mir kikkernd zu.", "tokens": ["reicht", "sie", "mir", "kik\u00b7kernd", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.14": {"text": "Mit einem Rever\u00e4ntzgen", "tokens": ["Mit", "ei\u00b7nem", "Re\u00b7ver\u00b7\u00e4ntz\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "schihb ichs ihr zahrt zur\u00fckk:", "tokens": ["schihb", "ichs", "ihr", "zahrt", "zu\u00b7r\u00fckk", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "for dich/ mein Kind/ das Schw\u00e4ntzgen/", "tokens": ["for", "dich", "/", "mein", "Kind", "/", "das", "Schw\u00e4ntz\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$(", "PPOSAT", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "for mich das Mittel-St\u00fckk!", "tokens": ["for", "mich", "das", "Mit\u00b7tel\u00b7St\u00fc\u00b7kk", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Panompfe ist mir zu sever/", "tokens": ["Pa\u00b7nomp\u00b7fe", "ist", "mir", "zu", "se\u00b7ver", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "APPR", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sie stellt sich w\u00fcrcklich r\u00e4cht contrair/", "tokens": ["sie", "stellt", "sich", "w\u00fcrck\u00b7lich", "r\u00e4cht", "cont\u00b7rair", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "VVFIN", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein ohnvern\u00fcnfftger Stein", "tokens": ["ein", "ohn\u00b7ver\u00b7n\u00fcnfft\u00b7ger", "Stein"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "kan nicht h\u00e4rter seyn.", "tokens": ["kan", "nicht", "h\u00e4r\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Greifft man ihr in ihre Sachen/", "tokens": ["Greifft", "man", "ihr", "in", "ih\u00b7re", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00fcmb sich mahl belihbt zu machen/", "tokens": ["\u00fcmb", "sich", "mahl", "be\u00b7lihbt", "zu", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADV", "ADJD", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "gleich so ziht das M\u00e4ntsch nicht faul", "tokens": ["gleich", "so", "ziht", "das", "M\u00e4ntsch", "nicht", "faul"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "PTKNEG", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "ein wohl-ger\u00fcmpfftes Maul/", "tokens": ["ein", "wohl\u00b7ge\u00b7r\u00fcmpff\u00b7tes", "Maul", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "au\u00df dem es manchmahl/ wie mir d\u00e4ucht/", "tokens": ["au\u00df", "dem", "es", "manch\u00b7mahl", "/", "wie", "mir", "d\u00e4ucht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "$(", "PWAV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "empf\u00fcndlich nach der K\u00fcche r\u00e4ucht.", "tokens": ["emp\u00b7f\u00fcnd\u00b7lich", "nach", "der", "K\u00fc\u00b7che", "r\u00e4ucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ich b\u00fcn bey keinem Drachen", "tokens": ["Ich", "b\u00fcn", "bey", "kei\u00b7nem", "Dra\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "for Complementgens machen/", "tokens": ["for", "Com\u00b7ple\u00b7ment\u00b7gens", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "dr\u00fcmb so sag ich unverfroren:", "tokens": ["dr\u00fcmb", "so", "sag", "ich", "un\u00b7ver\u00b7fro\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "dihse la\u00df ich ohngeschohren!", "tokens": ["dih\u00b7se", "la\u00df", "ich", "ohn\u00b7ge\u00b7schoh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "S\u00fcssre Lippen gihbts al\u00df deine/", "tokens": ["S\u00fcss\u00b7re", "Lip\u00b7pen", "gihbts", "al\u00df", "dei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "KOKOM", "PPOSAT", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "r\u00fcndre Arme/ r\u00fcndre Beine/", "tokens": ["r\u00fcnd\u00b7re", "Ar\u00b7me", "/", "r\u00fcnd\u00b7re", "Bei\u00b7ne", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Jungffern sind ein gantzes Heer/", "tokens": ["Jungf\u00b7fern", "sind", "ein", "gant\u00b7zes", "Heer", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "Jungffern sind wie Sand am Meer!", "tokens": ["Jungf\u00b7fern", "sind", "wie", "Sand", "am", "Meer", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "KOKOM", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Lihbstes Lisimindgen/ heunte", "tokens": ["Lihbs\u00b7tes", "Li\u00b7si\u00b7mind\u00b7gen", "/", "heun\u00b7te"], "token_info": ["word", "word", "punct", "word"], "pos": ["NE", "NE", "$(", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bistu bey-nah schon die Neunte/", "tokens": ["bis\u00b7tu", "bey\u00b7nah", "schon", "die", "Neun\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "die mir heymlig wohl-geneigt", "tokens": ["die", "mir", "heym\u00b7lig", "wohl\u00b7ge\u00b7neigt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "ihre Lilgen-Br\u00fcste zeigt.", "tokens": ["ih\u00b7re", "Lil\u00b7gen\u00b7Br\u00fcs\u00b7te", "zeigt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie sie dantzen! Wie sie hipffen!", "tokens": ["Wie", "sie", "dant\u00b7zen", "!", "Wie", "sie", "hipf\u00b7fen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVINF", "$.", "PWAV", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn sie ihrem Flohr entschlipffen!", "tokens": ["Wenn", "sie", "ih\u00b7rem", "Flohr", "ent\u00b7schlipf\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Kaum so f\u00fchlstu dich bekr\u00e4nckt/", "tokens": ["Kaum", "so", "f\u00fchl\u00b7stu", "dich", "be\u00b7kr\u00e4nckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "wenn man sie zusammen-m\u00e4nckt!", "tokens": ["wenn", "man", "sie", "zu\u00b7sam\u00b7men\u00b7m\u00e4nckt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Rosillgen nimbt mich offt bey Seit/", "tokens": ["Ro\u00b7sill\u00b7gen", "nimbt", "mich", "offt", "bey", "Seit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Rosillgen ist polit/", "tokens": ["Ro\u00b7sill\u00b7gen", "ist", "po\u00b7lit", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NE", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Rosillgen ist for H\u00f6ffligkeit/", "tokens": ["Ro\u00b7sill\u00b7gen", "ist", "for", "H\u00f6ff\u00b7lig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NE", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "zurmahl/ wenns nihmand siht.", "tokens": ["zur\u00b7mahl", "/", "wenns", "nih\u00b7mand", "siht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Zurweilen macht mich fast zu Stein", "tokens": ["Zur\u00b7wei\u00b7len", "macht", "mich", "fast", "zu", "Stein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "die Sch\u00f6nheit ihrer Waden/", "tokens": ["die", "Sch\u00f6n\u00b7heit", "ih\u00b7rer", "Wa\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "sorbald sie mit dem lincken Bein", "tokens": ["sor\u00b7bald", "sie", "mit", "dem", "lin\u00b7cken", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "ihr r\u00e4chtes Knie beladen!", "tokens": ["ihr", "r\u00e4ch\u00b7tes", "Knie", "be\u00b7la\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Darff ich/ darmit andre prassen/", "tokens": ["Darff", "ich", "/", "dar\u00b7mit", "and\u00b7re", "pras\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$(", "KOUS", "PIS", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "solches ohnbegriffen lassen?", "tokens": ["sol\u00b7ches", "ohn\u00b7be\u00b7grif\u00b7fen", "las\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Mein/ wa\u00df wer ich for ein Wicht/", "tokens": ["Mein", "/", "wa\u00df", "wer", "ich", "for", "ein", "Wicht", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$(", "VVFIN", "PWS", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "for solch Systema b\u00fcn ich nicht!", "tokens": ["for", "solch", "Sys\u00b7te\u00b7ma", "b\u00fcn", "ich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.21": {"text": "Falls mir Chloe dih\u00df vergunt/", "tokens": ["Falls", "mir", "Chloe", "dih\u00df", "ver\u00b7gunt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "NE", "VVPP", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.22": {"text": "k\u00fc\u00df ich ihr nicht bloh\u00df den Mund/", "tokens": ["k\u00fc\u00df", "ich", "ihr", "nicht", "bloh\u00df", "den", "Mund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKNEG", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.23": {"text": "auch die Biehtzgens/ die mich laben/", "tokens": ["auch", "die", "Biehtz\u00b7gens", "/", "die", "mich", "la\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$(", "PRELS", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.24": {"text": "wollen solch Erqwicksel haben.", "tokens": ["wol\u00b7len", "solch", "E\u00b7rqwick\u00b7sel", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.25": {"text": "S\u00e4lbst das Sch\u00f6nste/ wa\u00df sie zihrt/", "tokens": ["S\u00e4lbst", "das", "Sch\u00f6ns\u00b7te", "/", "wa\u00df", "sie", "zihrt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.26": {"text": "f\u00fchlt sich nicht dardurch aigrirt;", "tokens": ["f\u00fchlt", "sich", "nicht", "dar\u00b7durch", "ai\u00b7grirt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKNEG", "PAV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.27": {"text": "gleich so d\u00e4kk es wihder zu/", "tokens": ["gleich", "so", "d\u00e4kk", "es", "wih\u00b7der", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJD", "PTKZU", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.28": {"text": "da\u00df ich nichts Galantes dhu!", "tokens": ["da\u00df", "ich", "nichts", "Ga\u00b7lan\u00b7tes", "dhu", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.29": {"text": "Die reitzende Salinde", "tokens": ["Die", "reit\u00b7zen\u00b7de", "Sa\u00b7lin\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.30": {"text": "bleibt offt allein zu Hau\u00df;", "tokens": ["bleibt", "offt", "al\u00b7lein", "zu", "Hau\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.31": {"text": "darmit ich nicht erblinde/", "tokens": ["dar\u00b7mit", "ich", "nicht", "er\u00b7blin\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.32": {"text": "lescht sie das L\u00e4mpgen au\u00df.", "tokens": ["lescht", "sie", "das", "L\u00e4mp\u00b7gen", "au\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.33": {"text": "Insgeheim/ insgeheim", "tokens": ["Ins\u00b7ge\u00b7heim", "/", "ins\u00b7ge\u00b7heim"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$(", "APPRART"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.34": {"text": "schl\u00e4kken wir dan Honig-Seim!", "tokens": ["schl\u00e4k\u00b7ken", "wir", "dan", "Ho\u00b7nig\u00b7Seim", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.35": {"text": "Florillgen zehlt zum ", "tokens": ["Flo\u00b7rill\u00b7gen", "zehlt", "zum"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "APPRART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.36": {"text": "for so ein M\u00e4ntsch lih\u00df ich mich morden.", "tokens": ["for", "so", "ein", "M\u00e4ntsch", "lih\u00df", "ich", "mich", "mor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "PPER", "PRF", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.37": {"text": "Da\u00df macht/ es ist mir einverleibt", "tokens": ["Da\u00df", "macht", "/", "es", "ist", "mir", "ein\u00b7ver\u00b7leibt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "VVFIN", "$(", "PPER", "VAFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "die Leber/ die zum Lihben dreibt!", "tokens": ["die", "Le\u00b7ber", "/", "die", "zum", "Lih\u00b7ben", "dreibt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Berillgen lihbt noch erst im Traum/", "tokens": ["Be\u00b7rill\u00b7gen", "lihbt", "noch", "erst", "im", "Traum", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sie ist von f\u00fcnffzehn Jahren kaum/", "tokens": ["sie", "ist", "von", "f\u00fcnff\u00b7zehn", "Jah\u00b7ren", "kaum", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "CARD", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mit D\u00fctgens voll Rosinen", "tokens": ["mit", "D\u00fct\u00b7gens", "voll", "Ro\u00b7si\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "l\u00e4\u00dft sie sich noch bedihnen.", "tokens": ["l\u00e4\u00dft", "sie", "sich", "noch", "be\u00b7dih\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Ihre ", "tokens": ["Ih\u00b7re"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Rohsen-Knospen ohnerbrochen/", "tokens": ["Roh\u00b7sen\u00b7Knos\u00b7pen", "oh\u00b7ner\u00b7bro\u00b7chen", "/"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "doch scheint sie mir die letzte Zeit", "tokens": ["doch", "scheint", "sie", "mir", "die", "letz\u00b7te", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "schon voll erw\u00fcntschter Lihblichkeit.", "tokens": ["schon", "voll", "er\u00b7w\u00fcnt\u00b7schter", "Lih\u00b7blich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Offt so sieht sie manchen Mann", "tokens": ["Offt", "so", "sieht", "sie", "man\u00b7chen", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "bey-nah schon zu z\u00e4hrtlich an.", "tokens": ["bey\u00b7nah", "schon", "zu", "z\u00e4hrt\u00b7lich", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKA", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Ihr noch fast zu kleiner Mund", "tokens": ["Ihr", "noch", "fast", "zu", "klei\u00b7ner", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "spizzt sich gleichsahm ku\u00dflich/", "tokens": ["spizzt", "sich", "gleich\u00b7sahm", "ku\u00df\u00b7lich", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "VVFIN", "ADJD", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "alles ist an ihr lengst rund/", "tokens": ["al\u00b7les", "ist", "an", "ihr", "lengst", "rund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPER", "VVFIN", "ADJD", "$("], "meter": "+-++--+", "measure": "iambic.tetra.chol"}, "line.14": {"text": "alles schon genu\u00dflich!", "tokens": ["al\u00b7les", "schon", "ge\u00b7nu\u00df\u00b7lich", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.15": {"text": "Sie sagt nicht ja/ sie sagt nicht nein/", "tokens": ["Sie", "sagt", "nicht", "ja", "/", "sie", "sagt", "nicht", "nein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "$(", "PPER", "VVFIN", "PTKNEG", "PTKANT", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "sie lacht sich bloh\u00df ins F\u00e4ustgen dreyn!", "tokens": ["sie", "lacht", "sich", "bloh\u00df", "ins", "F\u00e4ust\u00b7gen", "dreyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "die bey dir nicht will/ die mu\u00df/", "tokens": ["die", "bey", "dir", "nicht", "will", "/", "die", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "PTKNEG", "VMFIN", "$(", "PDS", "VMFIN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "s\u00e4lbst die durchau\u00df Spr\u00f6de;", "tokens": ["s\u00e4lbst", "die", "durch\u00b7au\u00df", "Spr\u00f6\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "ligt sie noch so dikk \u00fcmbflaumt/", "tokens": ["ligt", "sie", "noch", "so", "dikk", "\u00fcmbf\u00b7laumt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "kaum da\u00df heymlig ihr wa\u00df traumt/", "tokens": ["kaum", "da\u00df", "heym\u00b7lig", "ihr", "wa\u00df", "traumt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ADJD", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "dhut sie nicht mehr bl\u00f6de!", "tokens": ["dhut", "sie", "nicht", "mehr", "bl\u00f6\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "H\u00e4lt sie gleich ihr H\u00e4ndgen", "tokens": ["H\u00e4lt", "sie", "gleich", "ihr", "H\u00e4nd\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "f\u00fcrs gelobte L\u00e4ndgen/", "tokens": ["f\u00fcrs", "ge\u00b7lob\u00b7te", "L\u00e4nd\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "dr\u00e4ut sie dreist zu schreyn \u2013", "tokens": ["dr\u00e4ut", "sie", "dreist", "zu", "schreyn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKZU", "VAINF", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "schon in zween Minuten/", "tokens": ["schon", "in", "zween", "Mi\u00b7nu\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "VVFIN", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "ohne dich zu sputen/", "tokens": ["oh\u00b7ne", "dich", "zu", "spu\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKZU", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.11": {"text": "wirstu Sieger seyn!", "tokens": ["wirs\u00b7tu", "Sie\u00b7ger", "seyn", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VAINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.12": {"text": "Keine Jungffer ist au\u00df Stein/", "tokens": ["Kei\u00b7ne", "Jungf\u00b7fer", "ist", "au\u00df", "Stein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "alle sind au\u00df Fleisch und Bein/", "tokens": ["al\u00b7le", "sind", "au\u00df", "Fleisch", "und", "Bein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "du br\u00e4uchst nur/ willstu sie gewinnen/", "tokens": ["du", "br\u00e4uchst", "nur", "/", "will\u00b7stu", "sie", "ge\u00b7win\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "bloh\u00df auff ihr Vergn\u00fcgen sinnen!", "tokens": ["bloh\u00df", "auff", "ihr", "Ver\u00b7gn\u00fc\u00b7gen", "sin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Drusillgen k\u00fckkt mich lachend an:", "tokens": ["Dru\u00b7sill\u00b7gen", "k\u00fckkt", "mich", "la\u00b7chend", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Na/ s\u00fcsser Schazz/ wie ist da\u00df dan?", "tokens": ["Na", "/", "s\u00fcs\u00b7ser", "Schazz", "/", "wie", "ist", "da\u00df", "dan", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$(", "ADJA", "NN", "$(", "KOKOM", "VAFIN", "KOUS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Entp\u00f6hrt so dreh ich ihr den R\u00fckken.", "tokens": ["Ent\u00b7p\u00f6hrt", "so", "dreh", "ich", "ihr", "den", "R\u00fck\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "For dihses bi\u00dfgen Jugend-Krafft", "tokens": ["For", "dih\u00b7ses", "bi\u00df\u00b7gen", "Ju\u00b7gend\u00b7Krafft"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ist sie mir vihl zu mangelhafft/", "tokens": ["ist", "sie", "mir", "vihl", "zu", "man\u00b7gel\u00b7hafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00fcmb mich nach ihr zu b\u00fckken.", "tokens": ["\u00fcmb", "mich", "nach", "ihr", "zu", "b\u00fck\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "Zum Lihben dhustu mir zu leid/", "tokens": ["Zum", "Lih\u00b7ben", "dhus\u00b7tu", "mir", "zu", "leid", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nigrette/ altes Rumpel-Scheidt!", "tokens": ["Nig\u00b7ret\u00b7te", "/", "al\u00b7tes", "Rum\u00b7pel\u00b7Scheidt", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Du r\u00e4uchst nicht nach Je\u00dfminen", "tokens": ["Du", "r\u00e4uchst", "nicht", "nach", "Je\u00df\u00b7mi\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "au\u00df deinen Mund-Rubinen.", "tokens": ["au\u00df", "dei\u00b7nen", "Mun\u00b7dRu\u00b7bi\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Zwey schauckelnde Mor\u00e4ste", "tokens": ["Zwey", "schauc\u00b7keln\u00b7de", "Mo\u00b7r\u00e4s\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["CARD", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "sind lengst an dir das B\u00e4ste;", "tokens": ["sind", "lengst", "an", "dir", "das", "B\u00e4s\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "auff ihrem Scheddel hat kein Hahr/", "tokens": ["auff", "ih\u00b7rem", "Sched\u00b7del", "hat", "kein", "Hahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "die deinen Vatter einst gebahr.", "tokens": ["die", "dei\u00b7nen", "Vat\u00b7ter", "einst", "ge\u00b7bahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Bald so d\u00e4kkt dich k\u00fchl der Sand/", "tokens": ["Bald", "so", "d\u00e4kkt", "dich", "k\u00fchl", "der", "Sand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "ach/ mir wird gantz bleumourant/", "tokens": ["ach", "/", "mir", "wird", "gantz", "bleu\u00b7mou\u00b7rant", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["XY", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "bald so ligstu pixus paxus", "tokens": ["bald", "so", "ligs\u00b7tu", "pi\u00b7xus", "pa\u00b7xus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "unterm Taxus!", "tokens": ["un\u00b7term", "Ta\u00b7xus", "!"], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.19": {"text": "Vier Bretter und sechs Brettgen", "tokens": ["Vier", "Bret\u00b7ter", "und", "sechs", "Brett\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "KON", "CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.20": {"text": "sind dan dein letztes Bettgen/", "tokens": ["sind", "dan", "dein", "letz\u00b7tes", "Bett\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "denn dihses eine bleibt gewi\u00df:", "tokens": ["denn", "dih\u00b7ses", "ei\u00b7ne", "bleibt", "ge\u00b7wi\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ART", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "zu Staub sanck s\u00e4lbst ", "tokens": ["zu", "Staub", "san\u00b7ck", "s\u00e4lbst"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "VVFIN"], "meter": "-++-+", "measure": "unknown.measure.tri"}, "line.23": {"text": "La\u00df uns f\u00fcr allen St\u00fckken", "tokens": ["La\u00df", "uns", "f\u00fcr", "al\u00b7len", "St\u00fck\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.24": {"text": "dr\u00fcmb au\u00df einander r\u00fckken/", "tokens": ["dr\u00fcmb", "au\u00df", "ein\u00b7an\u00b7der", "r\u00fck\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.25": {"text": "denn ach/ nicht \u00fcmmer hat man lihb/", "tokens": ["denn", "ach", "/", "nicht", "\u00fcm\u00b7mer", "hat", "man", "lihb", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$(", "PTKNEG", "ADV", "VAFIN", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "wa\u00df ", "tokens": ["wa\u00df"], "token_info": ["word"], "pos": ["XY"], "meter": "+", "measure": "single.up"}}, "stanza.14": {"line.1": {"text": "Lohrchen legt sich keusch zu Bett/", "tokens": ["Lohr\u00b7chen", "legt", "sich", "keusch", "zu", "Bett", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ADJD", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "pl\u00e4tter al\u00df ein Nudel-Brett.", "tokens": ["pl\u00e4t\u00b7ter", "al\u00df", "ein", "Nu\u00b7del\u00b7Brett", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wems f\u00fcr der nicht gr\u00e4hst und graut/", "tokens": ["Wems", "f\u00fcr", "der", "nicht", "gr\u00e4hst", "und", "graut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PRELS", "PTKNEG", "ADJD", "KON", "VVFIN", "$("], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "st\u00e4kkt nicht in der b\u00e4sten Haut.", "tokens": ["st\u00e4kkt", "nicht", "in", "der", "b\u00e4s\u00b7ten", "Haut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mindestens for dreyzehn Groschen", "tokens": ["Min\u00b7des\u00b7tens", "for", "drey\u00b7zehn", "Gro\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "CARD", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "kl\u00e4bt sie ihr Gesicht voll Moschen;", "tokens": ["kl\u00e4bt", "sie", "ihr", "Ge\u00b7sicht", "voll", "Mo\u00b7schen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "statt Sch\u00e4nckel hat sie ein paar Staaken/", "tokens": ["statt", "Sch\u00e4n\u00b7ckel", "hat", "sie", "ein", "paar", "Staa\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ART", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "ihr N\u00e4sgen ist ein Feuer-Haaken.", "tokens": ["ihr", "N\u00e4s\u00b7gen", "ist", "ein", "Feu\u00b7er\u00b7Haa\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Ihr Bukkel kr\u00fcmmt sich schon f\u00fcr Gicht/", "tokens": ["Ihr", "Buk\u00b7kel", "kr\u00fcmmt", "sich", "schon", "f\u00fcr", "Gicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "sie wattscht wie eine Ente;", "tokens": ["sie", "watt\u00b7scht", "wie", "ei\u00b7ne", "En\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "sie leidets nicht/ sie leidets nicht/", "tokens": ["sie", "lei\u00b7dets", "nicht", "/", "sie", "lei\u00b7dets", "nicht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "$(", "PPER", "ADV", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "es sey denn ein Studente!", "tokens": ["es", "sey", "denn", "ein", "Stu\u00b7den\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "Erst nechst besuchte sie gantz spat", "tokens": ["Erst", "nechst", "be\u00b7such\u00b7te", "sie", "gantz", "spat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "ihr Himmel-blaues M\u00fcndgen", "tokens": ["ihr", "Him\u00b7mel\u00b7blau\u00b7es", "M\u00fcnd\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "wihgt mindestens drey Pf\u00fcndgen.", "tokens": ["wihgt", "min\u00b7des\u00b7tens", "drey", "Pf\u00fcnd\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "CARD", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.16": {"text": "F\u00fcnff Bazzen bot for ihren Ku\u00df", "tokens": ["F\u00fcnff", "Baz\u00b7zen", "bot", "for", "ih\u00b7ren", "Ku\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "\u00fcmbsonst Herr ", "tokens": ["\u00fcm\u00b7bsonst", "Herr"], "token_info": ["word", "word"], "pos": ["ADV", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.18": {"text": "an seinem Kopff zerbrach schon vihl/", "tokens": ["an", "sei\u00b7nem", "Kopff", "zer\u00b7brach", "schon", "vihl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "zwo Sch\u00fcsseln und ein B\u00e4hsem-Stihl \u2013", "tokens": ["zwo", "Sch\u00fcs\u00b7seln", "und", "ein", "B\u00e4h\u00b7sem\u00b7S\u00b7tihl", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Dorilis/ du loser Sakk/", "tokens": ["Do\u00b7ri\u00b7lis", "/", "du", "lo\u00b7ser", "Sakk", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "lach dich nicht zu Schnupff-Thobakk!", "tokens": ["lach", "dich", "nicht", "zu", "Schnupf\u00b7fT\u00b7ho\u00b7bakk", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.15": {"line.1": {"text": "Doris/ kleiner Hertzens-Dihb/", "tokens": ["Do\u00b7ris", "/", "klei\u00b7ner", "Hert\u00b7zens\u00b7Dihb", "/"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$(", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "hastu mich auch w\u00fcrcklich lihb?", "tokens": ["has\u00b7tu", "mich", "auch", "w\u00fcrck\u00b7lich", "lihb", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00fcrcklich? Gantz wahrhafftig?", "tokens": ["W\u00fcrck\u00b7lich", "?", "Gantz", "wahr\u00b7haff\u00b7tig", "?"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$.", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und sie k\u00fc\u00dft mich/ da\u00df es knallt", "tokens": ["Und", "sie", "k\u00fc\u00dft", "mich", "/", "da\u00df", "es", "knallt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$(", "KOUS", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "durch den dikken-Dannen-Wald/", "tokens": ["durch", "den", "dik\u00b7ken\u00b7Dan\u00b7nen\u00b7Wald", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Himmel/ war der safftig!", "tokens": ["Him\u00b7mel", "/", "war", "der", "saff\u00b7tig", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VAFIN", "ART", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Deine auffgeblehten Br\u00fcste/", "tokens": ["Dei\u00b7ne", "auff\u00b7ge\u00b7bleh\u00b7ten", "Br\u00fcs\u00b7te", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "die ich dausendmahl bek\u00fcsste/", "tokens": ["die", "ich", "dau\u00b7send\u00b7mahl", "be\u00b7k\u00fcss\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "denen hundret Hirten", "tokens": ["de\u00b7nen", "hund\u00b7ret", "Hir\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VVFIN", "NN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.10": {"text": "Lihbes-Lider girrten/", "tokens": ["Lih\u00b7bes\u00b7Li\u00b7der", "girr\u00b7ten", "/"], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.11": {"text": "deine Br\u00fcste sind mein Prei\u00df/", "tokens": ["dei\u00b7ne", "Br\u00fcs\u00b7te", "sind", "mein", "Prei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Heute/ heute strehlt ihr Sohn", "tokens": ["Heu\u00b7te", "/", "heu\u00b7te", "strehlt", "ihr", "Sohn"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$(", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "dir noch deine Hahre/", "tokens": ["dir", "noch", "dei\u00b7ne", "Hah\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.14": {"text": "morgen/ morgen ligstu schon", "tokens": ["mor\u00b7gen", "/", "mor\u00b7gen", "ligs\u00b7tu", "schon"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$(", "ADV", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "auff der Thoden-Bahre!", "tokens": ["auff", "der", "Tho\u00b7den\u00b7Bah\u00b7re", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.16": {"text": "In das schwartze Grab", "tokens": ["In", "das", "schwart\u00b7ze", "Grab"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.17": {"text": "mu\u00dftu dan hinab!", "tokens": ["mu\u00df\u00b7tu", "dan", "hin\u00b7ab", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.18": {"text": "Wenn dich erst die W\u00fcrmer fr\u00e4ssen/", "tokens": ["Wenn", "dich", "erst", "die", "W\u00fcr\u00b7mer", "fr\u00e4s\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "wird dich keiner an sich pr\u00e4ssen;", "tokens": ["wird", "dich", "kei\u00b7ner", "an", "sich", "pr\u00e4s\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIS", "APPR", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "lihbe mich dr\u00fcmb gantz und gar", "tokens": ["lih\u00b7be", "mich", "dr\u00fcmb", "gantz", "und", "gar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "mit Haut und Hahr!", "tokens": ["mit", "Haut", "und", "Hahr", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "Itzt so ist die sch\u00f6nste Zeit/", "tokens": ["Itzt", "so", "ist", "die", "sch\u00f6ns\u00b7te", "Zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "k\u00fckk/ wie's auff uns Bl\u00fchten schneyt!", "tokens": ["k\u00fckk", "/", "wie's", "auff", "uns", "Bl\u00fch\u00b7ten", "schneyt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "VVFIN", "APPR", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie leuchten durch das Gra\u00df", "tokens": ["Sie", "leuch\u00b7ten", "durch", "das", "Gra\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "so zahrt/ so Silber-bla\u00df/", "tokens": ["so", "zahrt", "/", "so", "Sil\u00b7ber\u00b7bla\u00df", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ADV", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "ein B\u00e4chlein mit Gerisel", "tokens": ["ein", "B\u00e4ch\u00b7lein", "mit", "Ge\u00b7ri\u00b7sel"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "springt \u00fcber bundte Kisel.", "tokens": ["springt", "\u00fc\u00b7ber", "bund\u00b7te", "Ki\u00b7sel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Bl\u00fczz-blinckernd au\u00df Demant/", "tokens": ["Bl\u00fcz\u00b7zb\u00b7lin\u00b7ckernd", "au\u00df", "De\u00b7mant", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "so k\u00f6mbt es her gerannt/", "tokens": ["so", "k\u00f6mbt", "es", "her", "ge\u00b7rannt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "die kleinen Feldheuschrekken", "tokens": ["die", "klei\u00b7nen", "Feld\u00b7heu\u00b7schrek\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "begihrig au\u00df ihm lekken.", "tokens": ["be\u00b7gih\u00b7rig", "au\u00df", "ihm", "lek\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Das Qwellgen klikkt und klukkert/", "tokens": ["Das", "Qwell\u00b7gen", "klikkt", "und", "kluk\u00b7kert", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "dein Hertzgen tikkt und tukkert/", "tokens": ["dein", "Hertz\u00b7gen", "tikkt", "und", "tuk\u00b7kert", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "gantz weck reichstu mir hin", "tokens": ["gantz", "weck", "reichs\u00b7tu", "mir", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "dein Schn\u00e4blgin.", "tokens": ["dein", "Schn\u00e4bl\u00b7gin", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.15": {"text": "Nein/ wa\u00df hastu doch bloh\u00df/ Schl\u00fcnglein/", "tokens": ["Nein", "/", "wa\u00df", "has\u00b7tu", "doch", "bloh\u00df", "/", "Schl\u00fcn\u00b7glein", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "$(", "PWAV", "VAFIN", "ADV", "ADV", "$(", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "for ein s\u00fcsses Zukker-Z\u00fcnglein!", "tokens": ["for", "ein", "s\u00fcs\u00b7ses", "Zuk\u00b7ker\u00b7Z\u00fcng\u00b7lein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "mit Amber und Zibeth bestrichen!", "tokens": ["mit", "Am\u00b7ber", "und", "Zi\u00b7beth", "be\u00b7stri\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Nichts l\u00e4\u00dft sich so tieff verst\u00e4kken/", "tokens": ["Nichts", "l\u00e4\u00dft", "sich", "so", "tieff", "ver\u00b7st\u00e4k\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADV", "ADJD", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Schon so zihlt er/ hoch zu Ro\u00df/", "tokens": ["Schon", "so", "zihlt", "er", "/", "hoch", "zu", "Ro\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "$(", "ADJD", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "mitten auff dein Muschel-Schlo\u00df!", "tokens": ["mit\u00b7ten", "auff", "dein", "Mu\u00b7schel\u00b7Schlo\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "Die schlaue ", "tokens": ["Die", "schlau\u00b7e"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.22": {"text": "\u00bbba\u00df auff/ gihb Acht!", "tokens": ["\u00bb", "ba\u00df", "auff", "/", "gihb", "Acht", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "$(", "VVIMP", "CARD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.23": {"text": "Sie wird noch gantz mit ihrem R\u00fckken", "tokens": ["Sie", "wird", "noch", "gantz", "mit", "ih\u00b7rem", "R\u00fck\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "den kleinen Ehrenprei\u00df zertr\u00fckken!\u00ab \u2013", "tokens": ["den", "klei\u00b7nen", "Eh\u00b7ren\u00b7prei\u00df", "zer\u00b7tr\u00fck\u00b7ken", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Itzt so kr\u00e4nckt mich nicht mehr vihl/", "tokens": ["Itzt", "so", "kr\u00e4nckt", "mich", "nicht", "mehr", "vihl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wenn dein grohbes Dorff-Geheule", "tokens": ["wenn", "dein", "groh\u00b7bes", "Dorff\u00b7Ge\u00b7heu\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sein behahrtes Ohr verlezzt.", "tokens": ["sein", "be\u00b7hahr\u00b7tes", "Ohr", "ver\u00b7lezzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weiser b\u00fcn ich al\u00df ", "tokens": ["Wei\u00b7ser", "b\u00fcn", "ich", "al\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "der schon lengst zu Staub zerstob/", "tokens": ["der", "schon", "lengst", "zu", "Staub", "zer\u00b7stob", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "herrlicher al\u00df ", "tokens": ["herr\u00b7li\u00b7cher", "al\u00df"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "der itzt nichts mehr h\u00f6rt und siht/", "tokens": ["der", "itzt", "nichts", "mehr", "h\u00f6rt", "und", "siht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIS", "ADV", "VVFIN", "KON", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "g\u00f6ldner sa\u00df auff seinem Thron", "tokens": ["g\u00f6ld\u00b7ner", "sa\u00df", "auff", "sei\u00b7nem", "Thron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "kaum der K\u00f6nig ", "tokens": ["kaum", "der", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "Bl\u00fcht es/ ist das kleinste Gras", "tokens": ["Bl\u00fcht", "es", "/", "ist", "das", "kleins\u00b7te", "Gras"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$(", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "kl\u00fcger wie ", "tokens": ["kl\u00fc\u00b7ger", "wie"], "token_info": ["word", "word"], "pos": ["ADJD", "KOKOM"], "meter": "+-+", "measure": "trochaic.di"}, "line.12": {"text": "Noch so b\u00fcn ich frohen Sinns/", "tokens": ["Noch", "so", "b\u00fcn", "ich", "fro\u00b7hen", "Sinns", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Weiber/ Wein und W\u00fcrffelgins!", "tokens": ["Wei\u00b7ber", "/", "Wein", "und", "W\u00fcrf\u00b7fel\u00b7gins", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "Noch so melck ich stripp strapp strull", "tokens": ["Noch", "so", "melck", "ich", "stripp", "strapp", "strull"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "meine Muse wie ", "tokens": ["mei\u00b7ne", "Mu\u00b7se", "wie"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "KOKOM"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.16": {"text": "Dafnis/ andrer ", "tokens": ["Daf\u00b7nis", "/", "an\u00b7drer"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$(", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.17": {"text": "sing ich verlihbter al\u00df ", "tokens": ["sing", "ich", "ver\u00b7lihb\u00b7ter", "al\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJA", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.18": {"text": "Ich b\u00fcn ein Jungffern-J\u00e4ger/", "tokens": ["Ich", "b\u00fcn", "ein", "Jungffern\u00b7J\u00e4\u00b7ger", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.19": {"text": "ich b\u00fcn ein ", "tokens": ["ich", "b\u00fcn", "ein"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.20": {"text": "k\u00e4nnt mich seit langem schon!", "tokens": ["k\u00e4nnt", "mich", "seit", "lan\u00b7gem", "schon", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Dr\u00fcmb/ bin ich einst gestorben/", "tokens": ["Dr\u00fcmb", "/", "bin", "ich", "einst", "ge\u00b7stor\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$(", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.22": {"text": "so greifft in die Theorben", "tokens": ["so", "greifft", "in", "die", "The\u00b7or\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "und w\u00fcrgt auff meinem Grab", "tokens": ["und", "w\u00fcrgt", "auff", "mei\u00b7nem", "Grab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "drey-hundret Ocksen ab!", "tokens": ["drey\u00b7hun\u00b7dret", "Ock\u00b7sen", "ab", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.25": {"text": "Ein Bau au\u00df \u00e4delsten Porfiren", "tokens": ["Ein", "Bau", "au\u00df", "\u00e4\u00b7dels\u00b7ten", "Por\u00b7fi\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.26": {"text": "soll mich dan Zirckel-rund bezihren/", "tokens": ["soll", "mich", "dan", "Zir\u00b7ckel\u00b7rund", "be\u00b7zih\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "drauff schreibt mit Gold-Schrifft und Bedacht:", "tokens": ["drauff", "schreibt", "mit", "Gold\u00b7Schrifft", "und", "Be\u00b7dacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Der Himmel lacht lasuren", "tokens": ["Der", "Him\u00b7mel", "lacht", "la\u00b7su\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "auff ", "tokens": ["auff"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "so sanfft rauscht itzt der Bach;", "tokens": ["so", "sanfft", "rauscht", "itzt", "der", "Bach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "\u00fcmb seine Gr\u00e4sgens schnellen", "tokens": ["\u00fcmb", "sei\u00b7ne", "Gr\u00e4s\u00b7gens", "schnel\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "die zittrichten Libellen/", "tokens": ["die", "zit\u00b7trich\u00b7ten", "Li\u00b7bel\u00b7len", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "der Wald w\u00f6lbt gr\u00fcn sein Dach.", "tokens": ["der", "Wald", "w\u00f6lbt", "gr\u00fcn", "sein", "Dach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Nelcken/ Scharlach/ Amaranth", "tokens": ["Nel\u00b7cken", "/", "Schar\u00b7lach", "/", "A\u00b7ma\u00b7ran\u00b7th"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NN", "$(", "NE", "$(", "NE"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "und wa\u00df sonst noch wird benannt/", "tokens": ["und", "wa\u00df", "sonst", "noch", "wird", "be\u00b7nannt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Fenchel/ Lauch und Meusedorn/", "tokens": ["Fen\u00b7chel", "/", "Lauch", "und", "Meu\u00b7se\u00b7dorn", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Hertzgespan und Rittersporn/", "tokens": ["Hertz\u00b7ge\u00b7span", "und", "Rit\u00b7ter\u00b7sporn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Kellerhaltz und Koriander/", "tokens": ["Kel\u00b7ler\u00b7haltz", "und", "Ko\u00b7ri\u00b7an\u00b7der", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "alles bl\u00fcht itzt durcheinander.", "tokens": ["al\u00b7les", "bl\u00fcht", "itzt", "durch\u00b7ein\u00b7an\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Tausendsch\u00f6n und Akkeley/", "tokens": ["Tau\u00b7send\u00b7sch\u00f6n", "und", "Ak\u00b7ke\u00b7ley", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "Augentrost ist auch darbey.", "tokens": ["Au\u00b7gen\u00b7trost", "ist", "auch", "dar\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "das Wasser-Volck selbst lauscht/", "tokens": ["das", "Was\u00b7ser\u00b7Volck", "selbst", "lauscht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "wie s\u00fc\u00df der West-Wind itzt", "tokens": ["wie", "s\u00fc\u00df", "der", "West\u00b7Wind", "itzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ART", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "durchs L\u00e4ublein rauscht.", "tokens": ["durchs", "L\u00e4ub\u00b7lein", "rauscht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.18": {"text": "voll Engels\u00fc\u00df und Wohlgemuht/", "tokens": ["voll", "En\u00b7gel\u00b7s\u00fc\u00df", "und", "Wohl\u00b7ge\u00b7muht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "den Veilgens vor.", "tokens": ["den", "Veil\u00b7gens", "vor", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.20": {"text": "schlagen rund \u00fcmb mich den Dakkt/", "tokens": ["schla\u00b7gen", "rund", "\u00fcmb", "mich", "den", "Da\u00b7kkt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "auff das Volck mit dikken Waden", "tokens": ["auff", "das", "Volck", "mit", "dik\u00b7ken", "Wa\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "b\u00fcn ich durchau\u00df wie geladen!", "tokens": ["b\u00fcn", "ich", "durch\u00b7au\u00df", "wie", "ge\u00b7la\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KOKOM", "VVPP", "$."], "meter": "+-+++-+-", "measure": "unknown.measure.penta"}}, "stanza.19": {"line.1": {"text": "In jedem Arm ein Gr\u00fcbgen/", "tokens": ["In", "je\u00b7dem", "Arm", "ein", "Gr\u00fcb\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "im Kinn gar ihrer zwey/", "tokens": ["im", "Kinn", "gar", "ih\u00b7rer", "zwey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PPOSAT", "CARD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "mahlt mir das Fl\u00fcgel-B\u00fcbgen", "tokens": ["mahlt", "mir", "das", "Fl\u00fc\u00b7gel\u00b7B\u00fcb\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "die schwartze El\u00df-Marey.", "tokens": ["die", "schwart\u00b7ze", "El\u00df\u00b7Ma\u00b7rey", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Theils an Sch\u00f6nheit/ theils an L\u00e4nge/", "tokens": ["Theils", "an", "Sch\u00f6n\u00b7heit", "/", "theils", "an", "L\u00e4n\u00b7ge", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$(", "ADV", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "gleicht ", "tokens": ["gleicht"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Lilgen stehn f\u00fcr ihre Haut", "tokens": ["Lil\u00b7gen", "stehn", "f\u00fcr", "ih\u00b7re", "Haut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "nur wie schl\u00e4chtes K\u00f6rbel-Kraut.", "tokens": ["nur", "wie", "schl\u00e4ch\u00b7tes", "K\u00f6r\u00b7bel\u00b7Kraut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Noch so ward mir nichts bewu\u00dft", "tokens": ["Noch", "so", "ward", "mir", "nichts", "be\u00b7wu\u00dft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PIS", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "R\u00fcnderes al\u00df ihre Brust/", "tokens": ["R\u00fcn\u00b7de\u00b7res", "al\u00df", "ih\u00b7re", "Brust", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "ihrer Wangen Purpur-Pracht", "tokens": ["ih\u00b7rer", "Wan\u00b7gen", "Pur\u00b7pur\u00b7Pracht"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "hat ", "tokens": ["hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+", "measure": "single.up"}, "line.13": {"text": "Zween Arme/ deren Krafft", "tokens": ["Zween", "Ar\u00b7me", "/", "de\u00b7ren", "Krafft"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$(", "PRELAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "offt Leuen hin gerafft/", "tokens": ["offt", "Leu\u00b7en", "hin", "ge\u00b7rafft", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "zween Sch\u00e4nckel au\u00df Porfir", "tokens": ["zween", "Sch\u00e4n\u00b7ckel", "au\u00df", "Por\u00b7fir"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "NN", "APPR", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "da\u00df wer so wa\u00df for mir!", "tokens": ["da\u00df", "wer", "so", "wa\u00df", "for", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "ADV", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Ach/ ich kan mich ihretwegen", "tokens": ["Ach", "/", "ich", "kan", "mich", "ih\u00b7ret\u00b7we\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$(", "PPER", "VMFIN", "PPER", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "kaum mehr schlaffen legen!", "tokens": ["kaum", "mehr", "schlaf\u00b7fen", "le\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Filorindgen/", "tokens": ["Fi\u00b7lo\u00b7rind\u00b7gen", "/"], "token_info": ["word", "punct"], "pos": ["NE", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "lihbstes Kindgen/", "tokens": ["lihbs\u00b7tes", "Kind\u00b7gen", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "dein wie Goldt gewundner Zopf", "tokens": ["dein", "wie", "Goldt", "ge\u00b7wund\u00b7ner", "Zopf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "KOKOM", "NE", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "bringt mich deto \u00fcmb den Kopff.", "tokens": ["bringt", "mich", "de\u00b7to", "\u00fcmb", "den", "Kopff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Ich schau dich/ wa\u00df ich kan/", "tokens": ["Ich", "schau", "dich", "/", "wa\u00df", "ich", "kan", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "KOUS", "PPER", "VMFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "mit steiffen Augen an:", "tokens": ["mit", "steif\u00b7fen", "Au\u00b7gen", "an", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "du bist so s\u00fc\u00df/ so klein/", "tokens": ["du", "bist", "so", "s\u00fc\u00df", "/", "so", "klein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$(", "ADV", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "du Turttel-T\u00e4ubelein!", "tokens": ["du", "Turt\u00b7tel\u00b7T\u00e4u\u00b7be\u00b7lein", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Alles ist an dir ger\u00fcndet/", "tokens": ["Al\u00b7les", "ist", "an", "dir", "ge\u00b7r\u00fcn\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPER", "VVPP", "$("], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.10": {"text": "wordrauff sich mein Vergn\u00fcgen gr\u00fcndet;", "tokens": ["word\u00b7rauff", "sich", "mein", "Ver\u00b7gn\u00fc\u00b7gen", "gr\u00fcn\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "worhin man dir auch blikkt/", "tokens": ["wor\u00b7hin", "man", "dir", "auch", "blikkt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "man ist durchau\u00df erqwikkt.", "tokens": ["man", "ist", "durch\u00b7au\u00df", "er\u00b7qwikkt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "R\u00e4cht ein Dapps ist dein Menalk/", "tokens": ["R\u00e4cht", "ein", "Dapps", "ist", "dein", "Me\u00b7nalk", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "seine Bakken sind aus Kalck/", "tokens": ["sei\u00b7ne", "Bak\u00b7ken", "sind", "aus", "Kalck", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "seine Waden/ mu\u00df man wissen/", "tokens": ["sei\u00b7ne", "Wa\u00b7den", "/", "mu\u00df", "man", "wis\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "VMFIN", "PIS", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "hat ein Draut-Hahn abgebissen!", "tokens": ["hat", "ein", "Draut\u00b7Hahn", "ab\u00b7ge\u00b7bis\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Willstu bei dem alten Pauren", "tokens": ["Will\u00b7stu", "bei", "dem", "al\u00b7ten", "Pau\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "deine sch\u00f6nste Zeit versauren?", "tokens": ["dei\u00b7ne", "sch\u00f6ns\u00b7te", "Zeit", "ver\u00b7sau\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Lengst blagt ihn das Zipperlein/", "tokens": ["Lengst", "blagt", "ihn", "das", "Zip\u00b7per\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "gihb ihm zum purgieren ein;", "tokens": ["gihb", "ihm", "zum", "pur\u00b7gie\u00b7ren", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "r\u00e4cht vermischt au\u00df Ruch und Stanck/", "tokens": ["r\u00e4cht", "ver\u00b7mischt", "au\u00df", "Ruch", "und", "Stanck", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.22": {"text": "einen Apotheker-Tranck!", "tokens": ["ei\u00b7nen", "A\u00b7po\u00b7the\u00b7ker\u00b7Tranck", "!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Brunette/ la\u00df da\u00df seyn;", "tokens": ["Bru\u00b7net\u00b7te", "/", "la\u00df", "da\u00df", "seyn", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "VVIMP", "KOUS", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "mein Hertz ist nicht von Stein/", "tokens": ["mein", "Hertz", "ist", "nicht", "von", "Stein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "mein Hertz ist gantz au\u00df Wacks/", "tokens": ["mein", "Hertz", "ist", "gantz", "au\u00df", "Wacks", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "es br\u00e4nnt wie Flacks!", "tokens": ["es", "br\u00e4nnt", "wie", "Flacks", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Deine Augen wie Violen", "tokens": ["Dei\u00b7ne", "Au\u00b7gen", "wie", "Vi\u00b7o\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KOKOM", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sind zwo au\u00df geleschte Kolen/", "tokens": ["sind", "zwo", "au\u00df", "ge\u00b7leschte", "Ko\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "APPR", "ADJA", "NN", "$("], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "dein angenehmer Mund", "tokens": ["dein", "an\u00b7ge\u00b7neh\u00b7mer", "Mund"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "steht ahrtlig Zirckel-rund.", "tokens": ["steht", "ahrt\u00b7lig", "Zir\u00b7ckel\u00b7rund", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Du l\u00e4st durch diese Dh\u00fcr", "tokens": ["Du", "l\u00e4st", "durch", "die\u00b7se", "Dh\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "bloh\u00df Purpur-Sylben f\u00fcr/", "tokens": ["bloh\u00df", "Pur\u00b7pur\u00b7Syl\u00b7ben", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "dreyn sind in jedem Falle", "tokens": ["dreyn", "sind", "in", "je\u00b7dem", "Fal\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "APPR", "PIAT", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.12": {"text": "die Z\u00e4hne Berg-Kristalle.", "tokens": ["die", "Z\u00e4h\u00b7ne", "Ber\u00b7gKris\u00b7tal\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Dein runder Haltz/", "tokens": ["Dein", "run\u00b7der", "Haltz", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.14": {"text": "dein weisses Knie", "tokens": ["dein", "weis\u00b7ses", "Knie"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "macht keines-falls/", "tokens": ["macht", "kei\u00b7nes\u00b7falls", "/"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "NE", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "da\u00df ich dich flieh.", "tokens": ["da\u00df", "ich", "dich", "flieh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.17": {"text": "Auff deinen Br\u00fcsten schwimmt dein Hahr/", "tokens": ["Auff", "dei\u00b7nen", "Br\u00fcs\u00b7ten", "schwimmt", "dein", "Hahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Frau ", "tokens": ["Frau"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}, "stanza.22": {"line.1": {"text": "Su\u00dfgen kam von ohngefehr", "tokens": ["Su\u00df\u00b7gen", "kam", "von", "ohn\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "dr\u00e4llernd dorch die Wihse her/", "tokens": ["dr\u00e4l\u00b7lernd", "dorch", "die", "Wih\u00b7se", "her", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PAV", "ART", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "al\u00df ich nechst mein L\u00e4mmer-Volck", "tokens": ["al\u00df", "ich", "nechst", "mein", "L\u00e4m\u00b7mer\u00b7Volck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "unter einer B\u00fcche molck.", "tokens": ["un\u00b7ter", "ei\u00b7ner", "B\u00fc\u00b7che", "molck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Lab-Kraut/ Gunderman und Holler", "tokens": ["Lab\u00b7Kraut", "/", "Gun\u00b7der\u00b7man", "und", "Hol\u00b7ler"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NE", "KON", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "bund sie mir \u00fcmbs Hirten-Goller/", "tokens": ["bund", "sie", "mir", "\u00fcmbs", "Hir\u00b7ten\u00b7Gol\u00b7ler", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "alles/ wa\u00df ihr H\u00e4ndgen fund/", "tokens": ["al\u00b7les", "/", "wa\u00df", "ihr", "H\u00e4nd\u00b7gen", "fund", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$(", "KOUS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Rohsen lachte mir ihr Mund.", "tokens": ["Roh\u00b7sen", "lach\u00b7te", "mir", "ihr", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Drauff so schob ich ihr mein Fl\u00e4schgen", "tokens": ["Drauff", "so", "schob", "ich", "ihr", "mein", "Fl\u00e4schgen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VVFIN", "PPER", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "freundlich in ihr Hirten-D\u00e4schgen/", "tokens": ["freund\u00b7lich", "in", "ihr", "Hir\u00b7ten\u00b7D\u00e4schgen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "sie wusste kaum/ wie ihr geschah/", "tokens": ["sie", "wuss\u00b7te", "kaum", "/", "wie", "ihr", "ge\u00b7schah", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "PWAV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "mein Gott/ wa\u00df machstu da?", "tokens": ["mein", "Gott", "/", "wa\u00df", "machs\u00b7tu", "da", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PWAV", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Itzt l\u00e4\u00dft sie von frembden Hirten", "tokens": ["Itzt", "l\u00e4\u00dft", "sie", "von", "fremb\u00b7den", "Hir\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "sich so Hertz wie Mund bewirthen!", "tokens": ["sich", "so", "Hertz", "wie", "Mund", "be\u00b7wirt\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "NN", "KOKOM", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Mechtildgen f\u00fchrt mit gro\u00dfer Eil", "tokens": ["Mech\u00b7tild\u00b7gen", "f\u00fchrt", "mit", "gro\u00b7\u00dfer", "Eil"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mich hindter sich am Narren-Seil.", "tokens": ["mich", "hind\u00b7ter", "sich", "am", "Nar\u00b7ren\u00b7Seil", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kaum klopff ich an ihre Th\u00fcr/", "tokens": ["Kaum", "klopff", "ich", "an", "ih\u00b7re", "Th\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "ziht sie gleich den F\u00fcrhang f\u00fcr.", "tokens": ["ziht", "sie", "gleich", "den", "F\u00fcr\u00b7hang", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "M\u00e4gdgen/ rukk dein Mihder/", "tokens": ["M\u00e4gd\u00b7gen", "/", "rukk", "dein", "Mih\u00b7der", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "stell dich nicht zurwihder/", "tokens": ["stell", "dich", "nicht", "zur\u00b7wih\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "PTKNEG", "PTKVZ", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "der geb\u00fchrt allein der Prei\u00df/", "tokens": ["der", "ge\u00b7b\u00fchrt", "al\u00b7lein", "der", "Prei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "die mich r\u00e4cht zu lihben wei\u00df!", "tokens": ["die", "mich", "r\u00e4cht", "zu", "lih\u00b7ben", "wei\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "La\u00df dich endlich dr\u00fcmb erbitten/", "tokens": ["La\u00df", "dich", "end\u00b7lich", "dr\u00fcmb", "er\u00b7bit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PAV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "stell dich endlich nach Geb\u00fchr/", "tokens": ["stell", "dich", "end\u00b7lich", "nach", "Ge\u00b7b\u00fchr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ADV", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Sylvius geht mir nicht an Sitten/", "tokens": ["Syl\u00b7vius", "geht", "mir", "nicht", "an", "Sit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Thyrsis nicht an Tugend f\u00fcr.", "tokens": ["Thyr\u00b7sis", "nicht", "an", "Tu\u00b7gend", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "APPR", "NN", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "L\u00e4\u00dft dein Sinn sich nicht erweichen/", "tokens": ["L\u00e4\u00dft", "dein", "Sinn", "sich", "nicht", "er\u00b7wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PRF", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "gl\u00e4ubstu dan/ ich werd verbleichen?", "tokens": ["gl\u00e4ubs\u00b7tu", "dan", "/", "ich", "werd", "ver\u00b7blei\u00b7chen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "PPER", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Dihses sag ich rund und frey:", "tokens": ["Dih\u00b7ses", "sag", "ich", "rund", "und", "frey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "solches w\u00e4re K\u00e4lberey.", "tokens": ["sol\u00b7ches", "w\u00e4\u00b7re", "K\u00e4l\u00b7be\u00b7rey", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Meine Tauer-haffte Gluht", "tokens": ["Mei\u00b7ne", "Tau\u00b7e\u00b7rhaff\u00b7te", "Gluht"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "ist for viel wa\u00df B\u00e4ssres guht!", "tokens": ["ist", "for", "viel", "wa\u00df", "B\u00e4ss\u00b7res", "guht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "FM", "FM", "FM", "FM", "FM", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Margrittgen dhut sich zu commun/", "tokens": ["Mar\u00b7gritt\u00b7gen", "dhut", "sich", "zu", "com\u00b7mun", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "PTKZU", "VVINF", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "sie dukkt gleich nihder wie ein Huhn;", "tokens": ["sie", "dukkt", "gleich", "nih\u00b7der", "wie", "ein", "Huhn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df sie nechst lag in den Wochen/", "tokens": ["da\u00df", "sie", "nechst", "lag", "in", "den", "Wo\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "kam nicht bloh\u00df vom Kl\u00f6h\u00dfe-Kochen.", "tokens": ["kam", "nicht", "bloh\u00df", "vom", "Kl\u00f6h\u00b7\u00dfe\u00b7Ko\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wars der Kaspar/ wars der Melcher?", "tokens": ["Wars", "der", "Kas\u00b7par", "/", "wars", "der", "Melc\u00b7her", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NE", "$(", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ach/ sie wei\u00df es nicht mehr/ welcher!", "tokens": ["Ach", "/", "sie", "wei\u00df", "es", "nicht", "mehr", "/", "wel\u00b7cher", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ITJ", "$(", "PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "$(", "PWAT", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "S\u00e4lbst Hann\u00df Tapps schih\u00dft nicht vorbey \u2013", "tokens": ["S\u00e4lbst", "Hann\u00df", "Tapps", "schih\u00dft", "nicht", "vor\u00b7bey", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "VVFIN", "PTKNEG", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "ja/ so kombt man ins Geschrey.", "tokens": ["ja", "/", "so", "kombt", "man", "ins", "Ge\u00b7schrey", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "ADV", "VVFIN", "PIS", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Ambrette w\u00fcntscht sich wa\u00df.", "tokens": ["Am\u00b7bret\u00b7te", "w\u00fcnt\u00b7scht", "sich", "wa\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ein Kleid au\u00df Spihgel-Gla\u00df.", "tokens": ["Ein", "Kleid", "au\u00df", "Spih\u00b7gel\u00b7Gla\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit allem/ wa\u00df ein M\u00e4gdgen zihrt/", "tokens": ["Mit", "al\u00b7lem", "/", "wa\u00df", "ein", "M\u00e4gd\u00b7gen", "zihrt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$(", "KOUS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ist sie f\u00fcrtrefflig au\u00df staffirt.", "tokens": ["ist", "sie", "f\u00fcr\u00b7treff\u00b7lig", "au\u00df", "staf\u00b7firt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ach/ so reitzend kleine Wunde;", "tokens": ["ach", "/", "so", "reit\u00b7zend", "klei\u00b7ne", "Wun\u00b7de", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["XY", "$(", "ADV", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stechwurtz und F\u00fcnff-Finger-Kraut", "tokens": ["Stech\u00b7wurtz", "und", "F\u00fcnf\u00b7fFin\u00b7ger\u00b7Kraut"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "stehen darfor auff gebaut.", "tokens": ["ste\u00b7hen", "dar\u00b7for", "auff", "ge\u00b7baut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "APPR", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Der Himmel wird es schon so f\u00fcgen/", "tokens": ["Der", "Him\u00b7mel", "wird", "es", "schon", "so", "f\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "da\u00df wir uns beyde noch vergn\u00fcgen!", "tokens": ["da\u00df", "wir", "uns", "bey\u00b7de", "noch", "ver\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mit ihr an einem Dischgen/", "tokens": ["Mit", "ihr", "an", "ei\u00b7nem", "Dischgen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "da\u00df wer so r\u00e4cht mein ", "tokens": ["da\u00df", "wer", "so", "r\u00e4cht", "mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PWS", "ADV", "VVFIN", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.12": {"text": "ein s\u00e4lbst gebakknes Fischgen", "tokens": ["ein", "s\u00e4lbst", "ge\u00b7bakk\u00b7nes", "Fischgen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "reicht sie mir kikkernd zu.", "tokens": ["reicht", "sie", "mir", "kik\u00b7kernd", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.14": {"text": "Mit einem Rever\u00e4ntzgen", "tokens": ["Mit", "ei\u00b7nem", "Re\u00b7ver\u00b7\u00e4ntz\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "schihb ichs ihr zahrt zur\u00fckk:", "tokens": ["schihb", "ichs", "ihr", "zahrt", "zu\u00b7r\u00fckk", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "for dich/ mein Kind/ das Schw\u00e4ntzgen/", "tokens": ["for", "dich", "/", "mein", "Kind", "/", "das", "Schw\u00e4ntz\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$(", "PPOSAT", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "for mich das Mittel-St\u00fckk!", "tokens": ["for", "mich", "das", "Mit\u00b7tel\u00b7St\u00fc\u00b7kk", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Panompfe ist mir zu sever/", "tokens": ["Pa\u00b7nomp\u00b7fe", "ist", "mir", "zu", "se\u00b7ver", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "APPR", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sie stellt sich w\u00fcrcklich r\u00e4cht contrair/", "tokens": ["sie", "stellt", "sich", "w\u00fcrck\u00b7lich", "r\u00e4cht", "cont\u00b7rair", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "VVFIN", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein ohnvern\u00fcnfftger Stein", "tokens": ["ein", "ohn\u00b7ver\u00b7n\u00fcnfft\u00b7ger", "Stein"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "kan nicht h\u00e4rter seyn.", "tokens": ["kan", "nicht", "h\u00e4r\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Greifft man ihr in ihre Sachen/", "tokens": ["Greifft", "man", "ihr", "in", "ih\u00b7re", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00fcmb sich mahl belihbt zu machen/", "tokens": ["\u00fcmb", "sich", "mahl", "be\u00b7lihbt", "zu", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADV", "ADJD", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "gleich so ziht das M\u00e4ntsch nicht faul", "tokens": ["gleich", "so", "ziht", "das", "M\u00e4ntsch", "nicht", "faul"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "PTKNEG", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "ein wohl-ger\u00fcmpfftes Maul/", "tokens": ["ein", "wohl\u00b7ge\u00b7r\u00fcmpff\u00b7tes", "Maul", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "au\u00df dem es manchmahl/ wie mir d\u00e4ucht/", "tokens": ["au\u00df", "dem", "es", "manch\u00b7mahl", "/", "wie", "mir", "d\u00e4ucht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "$(", "PWAV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "empf\u00fcndlich nach der K\u00fcche r\u00e4ucht.", "tokens": ["emp\u00b7f\u00fcnd\u00b7lich", "nach", "der", "K\u00fc\u00b7che", "r\u00e4ucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ich b\u00fcn bey keinem Drachen", "tokens": ["Ich", "b\u00fcn", "bey", "kei\u00b7nem", "Dra\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "for Complementgens machen/", "tokens": ["for", "Com\u00b7ple\u00b7ment\u00b7gens", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "dr\u00fcmb so sag ich unverfroren:", "tokens": ["dr\u00fcmb", "so", "sag", "ich", "un\u00b7ver\u00b7fro\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "dihse la\u00df ich ohngeschohren!", "tokens": ["dih\u00b7se", "la\u00df", "ich", "ohn\u00b7ge\u00b7schoh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "S\u00fcssre Lippen gihbts al\u00df deine/", "tokens": ["S\u00fcss\u00b7re", "Lip\u00b7pen", "gihbts", "al\u00df", "dei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "KOKOM", "PPOSAT", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "r\u00fcndre Arme/ r\u00fcndre Beine/", "tokens": ["r\u00fcnd\u00b7re", "Ar\u00b7me", "/", "r\u00fcnd\u00b7re", "Bei\u00b7ne", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Jungffern sind ein gantzes Heer/", "tokens": ["Jungf\u00b7fern", "sind", "ein", "gant\u00b7zes", "Heer", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "Jungffern sind wie Sand am Meer!", "tokens": ["Jungf\u00b7fern", "sind", "wie", "Sand", "am", "Meer", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "KOKOM", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Lihbstes Lisimindgen/ heunte", "tokens": ["Lihbs\u00b7tes", "Li\u00b7si\u00b7mind\u00b7gen", "/", "heun\u00b7te"], "token_info": ["word", "word", "punct", "word"], "pos": ["NE", "NE", "$(", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bistu bey-nah schon die Neunte/", "tokens": ["bis\u00b7tu", "bey\u00b7nah", "schon", "die", "Neun\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "die mir heymlig wohl-geneigt", "tokens": ["die", "mir", "heym\u00b7lig", "wohl\u00b7ge\u00b7neigt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "ihre Lilgen-Br\u00fcste zeigt.", "tokens": ["ih\u00b7re", "Lil\u00b7gen\u00b7Br\u00fcs\u00b7te", "zeigt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie sie dantzen! Wie sie hipffen!", "tokens": ["Wie", "sie", "dant\u00b7zen", "!", "Wie", "sie", "hipf\u00b7fen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVINF", "$.", "PWAV", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn sie ihrem Flohr entschlipffen!", "tokens": ["Wenn", "sie", "ih\u00b7rem", "Flohr", "ent\u00b7schlipf\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Kaum so f\u00fchlstu dich bekr\u00e4nckt/", "tokens": ["Kaum", "so", "f\u00fchl\u00b7stu", "dich", "be\u00b7kr\u00e4nckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "wenn man sie zusammen-m\u00e4nckt!", "tokens": ["wenn", "man", "sie", "zu\u00b7sam\u00b7men\u00b7m\u00e4nckt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Rosillgen nimbt mich offt bey Seit/", "tokens": ["Ro\u00b7sill\u00b7gen", "nimbt", "mich", "offt", "bey", "Seit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Rosillgen ist polit/", "tokens": ["Ro\u00b7sill\u00b7gen", "ist", "po\u00b7lit", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NE", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Rosillgen ist for H\u00f6ffligkeit/", "tokens": ["Ro\u00b7sill\u00b7gen", "ist", "for", "H\u00f6ff\u00b7lig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NE", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "zurmahl/ wenns nihmand siht.", "tokens": ["zur\u00b7mahl", "/", "wenns", "nih\u00b7mand", "siht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Zurweilen macht mich fast zu Stein", "tokens": ["Zur\u00b7wei\u00b7len", "macht", "mich", "fast", "zu", "Stein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "die Sch\u00f6nheit ihrer Waden/", "tokens": ["die", "Sch\u00f6n\u00b7heit", "ih\u00b7rer", "Wa\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "sorbald sie mit dem lincken Bein", "tokens": ["sor\u00b7bald", "sie", "mit", "dem", "lin\u00b7cken", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "ihr r\u00e4chtes Knie beladen!", "tokens": ["ihr", "r\u00e4ch\u00b7tes", "Knie", "be\u00b7la\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Darff ich/ darmit andre prassen/", "tokens": ["Darff", "ich", "/", "dar\u00b7mit", "and\u00b7re", "pras\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$(", "KOUS", "PIS", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "solches ohnbegriffen lassen?", "tokens": ["sol\u00b7ches", "ohn\u00b7be\u00b7grif\u00b7fen", "las\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Mein/ wa\u00df wer ich for ein Wicht/", "tokens": ["Mein", "/", "wa\u00df", "wer", "ich", "for", "ein", "Wicht", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$(", "VVFIN", "PWS", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "for solch Systema b\u00fcn ich nicht!", "tokens": ["for", "solch", "Sys\u00b7te\u00b7ma", "b\u00fcn", "ich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.21": {"text": "Falls mir Chloe dih\u00df vergunt/", "tokens": ["Falls", "mir", "Chloe", "dih\u00df", "ver\u00b7gunt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "NE", "VVPP", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.22": {"text": "k\u00fc\u00df ich ihr nicht bloh\u00df den Mund/", "tokens": ["k\u00fc\u00df", "ich", "ihr", "nicht", "bloh\u00df", "den", "Mund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKNEG", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.23": {"text": "auch die Biehtzgens/ die mich laben/", "tokens": ["auch", "die", "Biehtz\u00b7gens", "/", "die", "mich", "la\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$(", "PRELS", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.24": {"text": "wollen solch Erqwicksel haben.", "tokens": ["wol\u00b7len", "solch", "E\u00b7rqwick\u00b7sel", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.25": {"text": "S\u00e4lbst das Sch\u00f6nste/ wa\u00df sie zihrt/", "tokens": ["S\u00e4lbst", "das", "Sch\u00f6ns\u00b7te", "/", "wa\u00df", "sie", "zihrt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.26": {"text": "f\u00fchlt sich nicht dardurch aigrirt;", "tokens": ["f\u00fchlt", "sich", "nicht", "dar\u00b7durch", "ai\u00b7grirt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKNEG", "PAV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.27": {"text": "gleich so d\u00e4kk es wihder zu/", "tokens": ["gleich", "so", "d\u00e4kk", "es", "wih\u00b7der", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJD", "PTKZU", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.28": {"text": "da\u00df ich nichts Galantes dhu!", "tokens": ["da\u00df", "ich", "nichts", "Ga\u00b7lan\u00b7tes", "dhu", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.29": {"text": "Die reitzende Salinde", "tokens": ["Die", "reit\u00b7zen\u00b7de", "Sa\u00b7lin\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.30": {"text": "bleibt offt allein zu Hau\u00df;", "tokens": ["bleibt", "offt", "al\u00b7lein", "zu", "Hau\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.31": {"text": "darmit ich nicht erblinde/", "tokens": ["dar\u00b7mit", "ich", "nicht", "er\u00b7blin\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.32": {"text": "lescht sie das L\u00e4mpgen au\u00df.", "tokens": ["lescht", "sie", "das", "L\u00e4mp\u00b7gen", "au\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.33": {"text": "Insgeheim/ insgeheim", "tokens": ["Ins\u00b7ge\u00b7heim", "/", "ins\u00b7ge\u00b7heim"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$(", "APPRART"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.34": {"text": "schl\u00e4kken wir dan Honig-Seim!", "tokens": ["schl\u00e4k\u00b7ken", "wir", "dan", "Ho\u00b7nig\u00b7Seim", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.35": {"text": "Florillgen zehlt zum ", "tokens": ["Flo\u00b7rill\u00b7gen", "zehlt", "zum"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "APPRART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.36": {"text": "for so ein M\u00e4ntsch lih\u00df ich mich morden.", "tokens": ["for", "so", "ein", "M\u00e4ntsch", "lih\u00df", "ich", "mich", "mor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "PPER", "PRF", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.37": {"text": "Da\u00df macht/ es ist mir einverleibt", "tokens": ["Da\u00df", "macht", "/", "es", "ist", "mir", "ein\u00b7ver\u00b7leibt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "VVFIN", "$(", "PPER", "VAFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "die Leber/ die zum Lihben dreibt!", "tokens": ["die", "Le\u00b7ber", "/", "die", "zum", "Lih\u00b7ben", "dreibt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Berillgen lihbt noch erst im Traum/", "tokens": ["Be\u00b7rill\u00b7gen", "lihbt", "noch", "erst", "im", "Traum", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sie ist von f\u00fcnffzehn Jahren kaum/", "tokens": ["sie", "ist", "von", "f\u00fcnff\u00b7zehn", "Jah\u00b7ren", "kaum", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "CARD", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mit D\u00fctgens voll Rosinen", "tokens": ["mit", "D\u00fct\u00b7gens", "voll", "Ro\u00b7si\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "l\u00e4\u00dft sie sich noch bedihnen.", "tokens": ["l\u00e4\u00dft", "sie", "sich", "noch", "be\u00b7dih\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Ihre ", "tokens": ["Ih\u00b7re"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Rohsen-Knospen ohnerbrochen/", "tokens": ["Roh\u00b7sen\u00b7Knos\u00b7pen", "oh\u00b7ner\u00b7bro\u00b7chen", "/"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "doch scheint sie mir die letzte Zeit", "tokens": ["doch", "scheint", "sie", "mir", "die", "letz\u00b7te", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "schon voll erw\u00fcntschter Lihblichkeit.", "tokens": ["schon", "voll", "er\u00b7w\u00fcnt\u00b7schter", "Lih\u00b7blich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Offt so sieht sie manchen Mann", "tokens": ["Offt", "so", "sieht", "sie", "man\u00b7chen", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "bey-nah schon zu z\u00e4hrtlich an.", "tokens": ["bey\u00b7nah", "schon", "zu", "z\u00e4hrt\u00b7lich", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKA", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Ihr noch fast zu kleiner Mund", "tokens": ["Ihr", "noch", "fast", "zu", "klei\u00b7ner", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "spizzt sich gleichsahm ku\u00dflich/", "tokens": ["spizzt", "sich", "gleich\u00b7sahm", "ku\u00df\u00b7lich", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "VVFIN", "ADJD", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "alles ist an ihr lengst rund/", "tokens": ["al\u00b7les", "ist", "an", "ihr", "lengst", "rund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPER", "VVFIN", "ADJD", "$("], "meter": "+-++--+", "measure": "iambic.tetra.chol"}, "line.14": {"text": "alles schon genu\u00dflich!", "tokens": ["al\u00b7les", "schon", "ge\u00b7nu\u00df\u00b7lich", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.15": {"text": "Sie sagt nicht ja/ sie sagt nicht nein/", "tokens": ["Sie", "sagt", "nicht", "ja", "/", "sie", "sagt", "nicht", "nein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "$(", "PPER", "VVFIN", "PTKNEG", "PTKANT", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "sie lacht sich bloh\u00df ins F\u00e4ustgen dreyn!", "tokens": ["sie", "lacht", "sich", "bloh\u00df", "ins", "F\u00e4ust\u00b7gen", "dreyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "die bey dir nicht will/ die mu\u00df/", "tokens": ["die", "bey", "dir", "nicht", "will", "/", "die", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "PTKNEG", "VMFIN", "$(", "PDS", "VMFIN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "s\u00e4lbst die durchau\u00df Spr\u00f6de;", "tokens": ["s\u00e4lbst", "die", "durch\u00b7au\u00df", "Spr\u00f6\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "ligt sie noch so dikk \u00fcmbflaumt/", "tokens": ["ligt", "sie", "noch", "so", "dikk", "\u00fcmbf\u00b7laumt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "kaum da\u00df heymlig ihr wa\u00df traumt/", "tokens": ["kaum", "da\u00df", "heym\u00b7lig", "ihr", "wa\u00df", "traumt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ADJD", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "dhut sie nicht mehr bl\u00f6de!", "tokens": ["dhut", "sie", "nicht", "mehr", "bl\u00f6\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "H\u00e4lt sie gleich ihr H\u00e4ndgen", "tokens": ["H\u00e4lt", "sie", "gleich", "ihr", "H\u00e4nd\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "f\u00fcrs gelobte L\u00e4ndgen/", "tokens": ["f\u00fcrs", "ge\u00b7lob\u00b7te", "L\u00e4nd\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "dr\u00e4ut sie dreist zu schreyn \u2013", "tokens": ["dr\u00e4ut", "sie", "dreist", "zu", "schreyn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKZU", "VAINF", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "schon in zween Minuten/", "tokens": ["schon", "in", "zween", "Mi\u00b7nu\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "VVFIN", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "ohne dich zu sputen/", "tokens": ["oh\u00b7ne", "dich", "zu", "spu\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKZU", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.11": {"text": "wirstu Sieger seyn!", "tokens": ["wirs\u00b7tu", "Sie\u00b7ger", "seyn", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VAINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.12": {"text": "Keine Jungffer ist au\u00df Stein/", "tokens": ["Kei\u00b7ne", "Jungf\u00b7fer", "ist", "au\u00df", "Stein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "alle sind au\u00df Fleisch und Bein/", "tokens": ["al\u00b7le", "sind", "au\u00df", "Fleisch", "und", "Bein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "du br\u00e4uchst nur/ willstu sie gewinnen/", "tokens": ["du", "br\u00e4uchst", "nur", "/", "will\u00b7stu", "sie", "ge\u00b7win\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "bloh\u00df auff ihr Vergn\u00fcgen sinnen!", "tokens": ["bloh\u00df", "auff", "ihr", "Ver\u00b7gn\u00fc\u00b7gen", "sin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Drusillgen k\u00fckkt mich lachend an:", "tokens": ["Dru\u00b7sill\u00b7gen", "k\u00fckkt", "mich", "la\u00b7chend", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Na/ s\u00fcsser Schazz/ wie ist da\u00df dan?", "tokens": ["Na", "/", "s\u00fcs\u00b7ser", "Schazz", "/", "wie", "ist", "da\u00df", "dan", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$(", "ADJA", "NN", "$(", "KOKOM", "VAFIN", "KOUS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Entp\u00f6hrt so dreh ich ihr den R\u00fckken.", "tokens": ["Ent\u00b7p\u00f6hrt", "so", "dreh", "ich", "ihr", "den", "R\u00fck\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "For dihses bi\u00dfgen Jugend-Krafft", "tokens": ["For", "dih\u00b7ses", "bi\u00df\u00b7gen", "Ju\u00b7gend\u00b7Krafft"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ist sie mir vihl zu mangelhafft/", "tokens": ["ist", "sie", "mir", "vihl", "zu", "man\u00b7gel\u00b7hafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00fcmb mich nach ihr zu b\u00fckken.", "tokens": ["\u00fcmb", "mich", "nach", "ihr", "zu", "b\u00fck\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "Zum Lihben dhustu mir zu leid/", "tokens": ["Zum", "Lih\u00b7ben", "dhus\u00b7tu", "mir", "zu", "leid", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nigrette/ altes Rumpel-Scheidt!", "tokens": ["Nig\u00b7ret\u00b7te", "/", "al\u00b7tes", "Rum\u00b7pel\u00b7Scheidt", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Du r\u00e4uchst nicht nach Je\u00dfminen", "tokens": ["Du", "r\u00e4uchst", "nicht", "nach", "Je\u00df\u00b7mi\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "au\u00df deinen Mund-Rubinen.", "tokens": ["au\u00df", "dei\u00b7nen", "Mun\u00b7dRu\u00b7bi\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Zwey schauckelnde Mor\u00e4ste", "tokens": ["Zwey", "schauc\u00b7keln\u00b7de", "Mo\u00b7r\u00e4s\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["CARD", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "sind lengst an dir das B\u00e4ste;", "tokens": ["sind", "lengst", "an", "dir", "das", "B\u00e4s\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "auff ihrem Scheddel hat kein Hahr/", "tokens": ["auff", "ih\u00b7rem", "Sched\u00b7del", "hat", "kein", "Hahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "die deinen Vatter einst gebahr.", "tokens": ["die", "dei\u00b7nen", "Vat\u00b7ter", "einst", "ge\u00b7bahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Bald so d\u00e4kkt dich k\u00fchl der Sand/", "tokens": ["Bald", "so", "d\u00e4kkt", "dich", "k\u00fchl", "der", "Sand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "ach/ mir wird gantz bleumourant/", "tokens": ["ach", "/", "mir", "wird", "gantz", "bleu\u00b7mou\u00b7rant", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["XY", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "bald so ligstu pixus paxus", "tokens": ["bald", "so", "ligs\u00b7tu", "pi\u00b7xus", "pa\u00b7xus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "unterm Taxus!", "tokens": ["un\u00b7term", "Ta\u00b7xus", "!"], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.19": {"text": "Vier Bretter und sechs Brettgen", "tokens": ["Vier", "Bret\u00b7ter", "und", "sechs", "Brett\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "KON", "CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.20": {"text": "sind dan dein letztes Bettgen/", "tokens": ["sind", "dan", "dein", "letz\u00b7tes", "Bett\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "denn dihses eine bleibt gewi\u00df:", "tokens": ["denn", "dih\u00b7ses", "ei\u00b7ne", "bleibt", "ge\u00b7wi\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ART", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "zu Staub sanck s\u00e4lbst ", "tokens": ["zu", "Staub", "san\u00b7ck", "s\u00e4lbst"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "VVFIN"], "meter": "-++-+", "measure": "unknown.measure.tri"}, "line.23": {"text": "La\u00df uns f\u00fcr allen St\u00fckken", "tokens": ["La\u00df", "uns", "f\u00fcr", "al\u00b7len", "St\u00fck\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.24": {"text": "dr\u00fcmb au\u00df einander r\u00fckken/", "tokens": ["dr\u00fcmb", "au\u00df", "ein\u00b7an\u00b7der", "r\u00fck\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.25": {"text": "denn ach/ nicht \u00fcmmer hat man lihb/", "tokens": ["denn", "ach", "/", "nicht", "\u00fcm\u00b7mer", "hat", "man", "lihb", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$(", "PTKNEG", "ADV", "VAFIN", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "wa\u00df ", "tokens": ["wa\u00df"], "token_info": ["word"], "pos": ["XY"], "meter": "+", "measure": "single.up"}}, "stanza.31": {"line.1": {"text": "Lohrchen legt sich keusch zu Bett/", "tokens": ["Lohr\u00b7chen", "legt", "sich", "keusch", "zu", "Bett", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ADJD", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "pl\u00e4tter al\u00df ein Nudel-Brett.", "tokens": ["pl\u00e4t\u00b7ter", "al\u00df", "ein", "Nu\u00b7del\u00b7Brett", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wems f\u00fcr der nicht gr\u00e4hst und graut/", "tokens": ["Wems", "f\u00fcr", "der", "nicht", "gr\u00e4hst", "und", "graut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PRELS", "PTKNEG", "ADJD", "KON", "VVFIN", "$("], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "st\u00e4kkt nicht in der b\u00e4sten Haut.", "tokens": ["st\u00e4kkt", "nicht", "in", "der", "b\u00e4s\u00b7ten", "Haut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mindestens for dreyzehn Groschen", "tokens": ["Min\u00b7des\u00b7tens", "for", "drey\u00b7zehn", "Gro\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "CARD", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "kl\u00e4bt sie ihr Gesicht voll Moschen;", "tokens": ["kl\u00e4bt", "sie", "ihr", "Ge\u00b7sicht", "voll", "Mo\u00b7schen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "statt Sch\u00e4nckel hat sie ein paar Staaken/", "tokens": ["statt", "Sch\u00e4n\u00b7ckel", "hat", "sie", "ein", "paar", "Staa\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ART", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "ihr N\u00e4sgen ist ein Feuer-Haaken.", "tokens": ["ihr", "N\u00e4s\u00b7gen", "ist", "ein", "Feu\u00b7er\u00b7Haa\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Ihr Bukkel kr\u00fcmmt sich schon f\u00fcr Gicht/", "tokens": ["Ihr", "Buk\u00b7kel", "kr\u00fcmmt", "sich", "schon", "f\u00fcr", "Gicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "sie wattscht wie eine Ente;", "tokens": ["sie", "watt\u00b7scht", "wie", "ei\u00b7ne", "En\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "sie leidets nicht/ sie leidets nicht/", "tokens": ["sie", "lei\u00b7dets", "nicht", "/", "sie", "lei\u00b7dets", "nicht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "$(", "PPER", "ADV", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "es sey denn ein Studente!", "tokens": ["es", "sey", "denn", "ein", "Stu\u00b7den\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "Erst nechst besuchte sie gantz spat", "tokens": ["Erst", "nechst", "be\u00b7such\u00b7te", "sie", "gantz", "spat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "ihr Himmel-blaues M\u00fcndgen", "tokens": ["ihr", "Him\u00b7mel\u00b7blau\u00b7es", "M\u00fcnd\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "wihgt mindestens drey Pf\u00fcndgen.", "tokens": ["wihgt", "min\u00b7des\u00b7tens", "drey", "Pf\u00fcnd\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "CARD", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.16": {"text": "F\u00fcnff Bazzen bot for ihren Ku\u00df", "tokens": ["F\u00fcnff", "Baz\u00b7zen", "bot", "for", "ih\u00b7ren", "Ku\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "\u00fcmbsonst Herr ", "tokens": ["\u00fcm\u00b7bsonst", "Herr"], "token_info": ["word", "word"], "pos": ["ADV", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.18": {"text": "an seinem Kopff zerbrach schon vihl/", "tokens": ["an", "sei\u00b7nem", "Kopff", "zer\u00b7brach", "schon", "vihl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "zwo Sch\u00fcsseln und ein B\u00e4hsem-Stihl \u2013", "tokens": ["zwo", "Sch\u00fcs\u00b7seln", "und", "ein", "B\u00e4h\u00b7sem\u00b7S\u00b7tihl", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Dorilis/ du loser Sakk/", "tokens": ["Do\u00b7ri\u00b7lis", "/", "du", "lo\u00b7ser", "Sakk", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "lach dich nicht zu Schnupff-Thobakk!", "tokens": ["lach", "dich", "nicht", "zu", "Schnupf\u00b7fT\u00b7ho\u00b7bakk", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.32": {"line.1": {"text": "Doris/ kleiner Hertzens-Dihb/", "tokens": ["Do\u00b7ris", "/", "klei\u00b7ner", "Hert\u00b7zens\u00b7Dihb", "/"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$(", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "hastu mich auch w\u00fcrcklich lihb?", "tokens": ["has\u00b7tu", "mich", "auch", "w\u00fcrck\u00b7lich", "lihb", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00fcrcklich? Gantz wahrhafftig?", "tokens": ["W\u00fcrck\u00b7lich", "?", "Gantz", "wahr\u00b7haff\u00b7tig", "?"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$.", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und sie k\u00fc\u00dft mich/ da\u00df es knallt", "tokens": ["Und", "sie", "k\u00fc\u00dft", "mich", "/", "da\u00df", "es", "knallt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$(", "KOUS", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "durch den dikken-Dannen-Wald/", "tokens": ["durch", "den", "dik\u00b7ken\u00b7Dan\u00b7nen\u00b7Wald", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Himmel/ war der safftig!", "tokens": ["Him\u00b7mel", "/", "war", "der", "saff\u00b7tig", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VAFIN", "ART", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Deine auffgeblehten Br\u00fcste/", "tokens": ["Dei\u00b7ne", "auff\u00b7ge\u00b7bleh\u00b7ten", "Br\u00fcs\u00b7te", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "die ich dausendmahl bek\u00fcsste/", "tokens": ["die", "ich", "dau\u00b7send\u00b7mahl", "be\u00b7k\u00fcss\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "denen hundret Hirten", "tokens": ["de\u00b7nen", "hund\u00b7ret", "Hir\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VVFIN", "NN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.10": {"text": "Lihbes-Lider girrten/", "tokens": ["Lih\u00b7bes\u00b7Li\u00b7der", "girr\u00b7ten", "/"], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.11": {"text": "deine Br\u00fcste sind mein Prei\u00df/", "tokens": ["dei\u00b7ne", "Br\u00fcs\u00b7te", "sind", "mein", "Prei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Heute/ heute strehlt ihr Sohn", "tokens": ["Heu\u00b7te", "/", "heu\u00b7te", "strehlt", "ihr", "Sohn"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$(", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "dir noch deine Hahre/", "tokens": ["dir", "noch", "dei\u00b7ne", "Hah\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.14": {"text": "morgen/ morgen ligstu schon", "tokens": ["mor\u00b7gen", "/", "mor\u00b7gen", "ligs\u00b7tu", "schon"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$(", "ADV", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "auff der Thoden-Bahre!", "tokens": ["auff", "der", "Tho\u00b7den\u00b7Bah\u00b7re", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.16": {"text": "In das schwartze Grab", "tokens": ["In", "das", "schwart\u00b7ze", "Grab"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.17": {"text": "mu\u00dftu dan hinab!", "tokens": ["mu\u00df\u00b7tu", "dan", "hin\u00b7ab", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.18": {"text": "Wenn dich erst die W\u00fcrmer fr\u00e4ssen/", "tokens": ["Wenn", "dich", "erst", "die", "W\u00fcr\u00b7mer", "fr\u00e4s\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "wird dich keiner an sich pr\u00e4ssen;", "tokens": ["wird", "dich", "kei\u00b7ner", "an", "sich", "pr\u00e4s\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIS", "APPR", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "lihbe mich dr\u00fcmb gantz und gar", "tokens": ["lih\u00b7be", "mich", "dr\u00fcmb", "gantz", "und", "gar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "mit Haut und Hahr!", "tokens": ["mit", "Haut", "und", "Hahr", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.33": {"line.1": {"text": "Itzt so ist die sch\u00f6nste Zeit/", "tokens": ["Itzt", "so", "ist", "die", "sch\u00f6ns\u00b7te", "Zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "k\u00fckk/ wie's auff uns Bl\u00fchten schneyt!", "tokens": ["k\u00fckk", "/", "wie's", "auff", "uns", "Bl\u00fch\u00b7ten", "schneyt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "VVFIN", "APPR", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie leuchten durch das Gra\u00df", "tokens": ["Sie", "leuch\u00b7ten", "durch", "das", "Gra\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "so zahrt/ so Silber-bla\u00df/", "tokens": ["so", "zahrt", "/", "so", "Sil\u00b7ber\u00b7bla\u00df", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ADV", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "ein B\u00e4chlein mit Gerisel", "tokens": ["ein", "B\u00e4ch\u00b7lein", "mit", "Ge\u00b7ri\u00b7sel"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "springt \u00fcber bundte Kisel.", "tokens": ["springt", "\u00fc\u00b7ber", "bund\u00b7te", "Ki\u00b7sel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Bl\u00fczz-blinckernd au\u00df Demant/", "tokens": ["Bl\u00fcz\u00b7zb\u00b7lin\u00b7ckernd", "au\u00df", "De\u00b7mant", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "so k\u00f6mbt es her gerannt/", "tokens": ["so", "k\u00f6mbt", "es", "her", "ge\u00b7rannt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "die kleinen Feldheuschrekken", "tokens": ["die", "klei\u00b7nen", "Feld\u00b7heu\u00b7schrek\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "begihrig au\u00df ihm lekken.", "tokens": ["be\u00b7gih\u00b7rig", "au\u00df", "ihm", "lek\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Das Qwellgen klikkt und klukkert/", "tokens": ["Das", "Qwell\u00b7gen", "klikkt", "und", "kluk\u00b7kert", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "dein Hertzgen tikkt und tukkert/", "tokens": ["dein", "Hertz\u00b7gen", "tikkt", "und", "tuk\u00b7kert", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "gantz weck reichstu mir hin", "tokens": ["gantz", "weck", "reichs\u00b7tu", "mir", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "dein Schn\u00e4blgin.", "tokens": ["dein", "Schn\u00e4bl\u00b7gin", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.15": {"text": "Nein/ wa\u00df hastu doch bloh\u00df/ Schl\u00fcnglein/", "tokens": ["Nein", "/", "wa\u00df", "has\u00b7tu", "doch", "bloh\u00df", "/", "Schl\u00fcn\u00b7glein", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "$(", "PWAV", "VAFIN", "ADV", "ADV", "$(", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "for ein s\u00fcsses Zukker-Z\u00fcnglein!", "tokens": ["for", "ein", "s\u00fcs\u00b7ses", "Zuk\u00b7ker\u00b7Z\u00fcng\u00b7lein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "mit Amber und Zibeth bestrichen!", "tokens": ["mit", "Am\u00b7ber", "und", "Zi\u00b7beth", "be\u00b7stri\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Nichts l\u00e4\u00dft sich so tieff verst\u00e4kken/", "tokens": ["Nichts", "l\u00e4\u00dft", "sich", "so", "tieff", "ver\u00b7st\u00e4k\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADV", "ADJD", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Schon so zihlt er/ hoch zu Ro\u00df/", "tokens": ["Schon", "so", "zihlt", "er", "/", "hoch", "zu", "Ro\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "$(", "ADJD", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "mitten auff dein Muschel-Schlo\u00df!", "tokens": ["mit\u00b7ten", "auff", "dein", "Mu\u00b7schel\u00b7Schlo\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "Die schlaue ", "tokens": ["Die", "schlau\u00b7e"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.22": {"text": "\u00bbba\u00df auff/ gihb Acht!", "tokens": ["\u00bb", "ba\u00df", "auff", "/", "gihb", "Acht", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "$(", "VVIMP", "CARD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.23": {"text": "Sie wird noch gantz mit ihrem R\u00fckken", "tokens": ["Sie", "wird", "noch", "gantz", "mit", "ih\u00b7rem", "R\u00fck\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "den kleinen Ehrenprei\u00df zertr\u00fckken!\u00ab \u2013", "tokens": ["den", "klei\u00b7nen", "Eh\u00b7ren\u00b7prei\u00df", "zer\u00b7tr\u00fck\u00b7ken", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Itzt so kr\u00e4nckt mich nicht mehr vihl/", "tokens": ["Itzt", "so", "kr\u00e4nckt", "mich", "nicht", "mehr", "vihl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wenn dein grohbes Dorff-Geheule", "tokens": ["wenn", "dein", "groh\u00b7bes", "Dorff\u00b7Ge\u00b7heu\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sein behahrtes Ohr verlezzt.", "tokens": ["sein", "be\u00b7hahr\u00b7tes", "Ohr", "ver\u00b7lezzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weiser b\u00fcn ich al\u00df ", "tokens": ["Wei\u00b7ser", "b\u00fcn", "ich", "al\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "der schon lengst zu Staub zerstob/", "tokens": ["der", "schon", "lengst", "zu", "Staub", "zer\u00b7stob", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "herrlicher al\u00df ", "tokens": ["herr\u00b7li\u00b7cher", "al\u00df"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "der itzt nichts mehr h\u00f6rt und siht/", "tokens": ["der", "itzt", "nichts", "mehr", "h\u00f6rt", "und", "siht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIS", "ADV", "VVFIN", "KON", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "g\u00f6ldner sa\u00df auff seinem Thron", "tokens": ["g\u00f6ld\u00b7ner", "sa\u00df", "auff", "sei\u00b7nem", "Thron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "kaum der K\u00f6nig ", "tokens": ["kaum", "der", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "Bl\u00fcht es/ ist das kleinste Gras", "tokens": ["Bl\u00fcht", "es", "/", "ist", "das", "kleins\u00b7te", "Gras"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$(", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "kl\u00fcger wie ", "tokens": ["kl\u00fc\u00b7ger", "wie"], "token_info": ["word", "word"], "pos": ["ADJD", "KOKOM"], "meter": "+-+", "measure": "trochaic.di"}, "line.12": {"text": "Noch so b\u00fcn ich frohen Sinns/", "tokens": ["Noch", "so", "b\u00fcn", "ich", "fro\u00b7hen", "Sinns", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Weiber/ Wein und W\u00fcrffelgins!", "tokens": ["Wei\u00b7ber", "/", "Wein", "und", "W\u00fcrf\u00b7fel\u00b7gins", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "Noch so melck ich stripp strapp strull", "tokens": ["Noch", "so", "melck", "ich", "stripp", "strapp", "strull"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "meine Muse wie ", "tokens": ["mei\u00b7ne", "Mu\u00b7se", "wie"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "KOKOM"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.16": {"text": "Dafnis/ andrer ", "tokens": ["Daf\u00b7nis", "/", "an\u00b7drer"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$(", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.17": {"text": "sing ich verlihbter al\u00df ", "tokens": ["sing", "ich", "ver\u00b7lihb\u00b7ter", "al\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJA", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.18": {"text": "Ich b\u00fcn ein Jungffern-J\u00e4ger/", "tokens": ["Ich", "b\u00fcn", "ein", "Jungffern\u00b7J\u00e4\u00b7ger", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.19": {"text": "ich b\u00fcn ein ", "tokens": ["ich", "b\u00fcn", "ein"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.20": {"text": "k\u00e4nnt mich seit langem schon!", "tokens": ["k\u00e4nnt", "mich", "seit", "lan\u00b7gem", "schon", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Dr\u00fcmb/ bin ich einst gestorben/", "tokens": ["Dr\u00fcmb", "/", "bin", "ich", "einst", "ge\u00b7stor\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$(", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.22": {"text": "so greifft in die Theorben", "tokens": ["so", "greifft", "in", "die", "The\u00b7or\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "und w\u00fcrgt auff meinem Grab", "tokens": ["und", "w\u00fcrgt", "auff", "mei\u00b7nem", "Grab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "drey-hundret Ocksen ab!", "tokens": ["drey\u00b7hun\u00b7dret", "Ock\u00b7sen", "ab", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.25": {"text": "Ein Bau au\u00df \u00e4delsten Porfiren", "tokens": ["Ein", "Bau", "au\u00df", "\u00e4\u00b7dels\u00b7ten", "Por\u00b7fi\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.26": {"text": "soll mich dan Zirckel-rund bezihren/", "tokens": ["soll", "mich", "dan", "Zir\u00b7ckel\u00b7rund", "be\u00b7zih\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "drauff schreibt mit Gold-Schrifft und Bedacht:", "tokens": ["drauff", "schreibt", "mit", "Gold\u00b7Schrifft", "und", "Be\u00b7dacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}