{"textgrid.poem.62561": {"metadata": {"author": {"name": "Schenkendorf, Max von", "birth": "N.A.", "death": "N.A."}, "title": "Am heiligen Christtag", "genre": "verse", "period": "N.A.", "pub_year": 1800, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ehre sei Gott in der H\u00f6he!", "tokens": ["Eh\u00b7re", "sei", "Gott", "in", "der", "H\u00f6\u00b7he", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Friede auf Erden,", "tokens": ["Frie\u00b7de", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und den Menschen ein Wohlgefallen!", "tokens": ["Und", "den", "Men\u00b7schen", "ein", "Wohl\u00b7ge\u00b7fal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.2": {"line.1": {"text": "Das Wort kam aus der H\u00f6he,", "tokens": ["Das", "Wort", "kam", "aus", "der", "H\u00f6\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein Mensch, wie wir, zu werden,", "tokens": ["Ein", "Mensch", ",", "wie", "wir", ",", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "$,", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zur ew'gen Rettung von uns Allen", "tokens": ["Zur", "ew'\u00b7gen", "Ret\u00b7tung", "von", "uns", "Al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPER", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Gesegnet sei die Krippe,", "tokens": ["Ge\u00b7seg\u00b7net", "sei", "die", "Krip\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die meinen Herrn umgibet,", "tokens": ["Die", "mei\u00b7nen", "Herrn", "um\u00b7gi\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Kind, das einst die Schlange wird zertreten.", "tokens": ["Ein", "Kind", ",", "das", "einst", "die", "Schlan\u00b7ge", "wird", "zer\u00b7tre\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Nach sagt es nicht die Lippe,", "tokens": ["Nach", "sagt", "es", "nicht", "die", "Lip\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie sehr er uns geliebet,", "tokens": ["Wie", "sehr", "er", "uns", "ge\u00b7lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sein Auge sagt's, und zwingt uns anzubeten.", "tokens": ["Sein", "Au\u00b7ge", "sagt's", ",", "und", "zwingt", "uns", "an\u00b7zu\u00b7be\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "KON", "VVFIN", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ehre sei Gott in der H\u00f6he!", "tokens": ["Eh\u00b7re", "sei", "Gott", "in", "der", "H\u00f6\u00b7he", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Friede auf Erden,", "tokens": ["Frie\u00b7de", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und den Menschen ein Wohlgefallen!", "tokens": ["Und", "den", "Men\u00b7schen", "ein", "Wohl\u00b7ge\u00b7fal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Das Wort kam aus der H\u00f6he,", "tokens": ["Das", "Wort", "kam", "aus", "der", "H\u00f6\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein Mensch, wie wir, zu werden,", "tokens": ["Ein", "Mensch", ",", "wie", "wir", ",", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "$,", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zur ew'gen Rettung von uns Allen", "tokens": ["Zur", "ew'\u00b7gen", "Ret\u00b7tung", "von", "uns", "Al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPER", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Gesegnet sei die Krippe,", "tokens": ["Ge\u00b7seg\u00b7net", "sei", "die", "Krip\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die meinen Herrn umgibet,", "tokens": ["Die", "mei\u00b7nen", "Herrn", "um\u00b7gi\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Kind, das einst die Schlange wird zertreten.", "tokens": ["Ein", "Kind", ",", "das", "einst", "die", "Schlan\u00b7ge", "wird", "zer\u00b7tre\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Nach sagt es nicht die Lippe,", "tokens": ["Nach", "sagt", "es", "nicht", "die", "Lip\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie sehr er uns geliebet,", "tokens": ["Wie", "sehr", "er", "uns", "ge\u00b7lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sein Auge sagt's, und zwingt uns anzubeten.", "tokens": ["Sein", "Au\u00b7ge", "sagt's", ",", "und", "zwingt", "uns", "an\u00b7zu\u00b7be\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "KON", "VVFIN", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}