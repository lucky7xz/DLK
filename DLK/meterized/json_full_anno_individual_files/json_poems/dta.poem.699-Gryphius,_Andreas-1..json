{"dta.poem.699": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Was h\u00f6r ich f\u00fcr jubiliren? ", "tokens": ["Was", "h\u00f6r", "ich", "f\u00fcr", "ju\u00b7bi\u00b7li\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wer ist der so fr\u00f6lich rufft? ", "tokens": ["Wer", "ist", "der", "so", "fr\u00f6\u00b7lich", "rufft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df Feld/ Berge/ Thal vnd Lufft", "tokens": ["Da\u00df", "Feld", "/", "Ber\u00b7ge", "/", "Thal", "vnd", "Lufft"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$(", "NN", "$(", "NN", "KON", "NN"], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Das geth\u00f6ne wider geben? ", "tokens": ["Das", "ge\u00b7th\u00f6\u00b7ne", "wi\u00b7der", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Woher kompt das triumphiren?", "tokens": ["Wo\u00b7her", "kompt", "das", "tri\u00b7um\u00b7phi\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PDS", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Mag auch jemand sich erheben", "tokens": ["Mag", "auch", "je\u00b7mand", "sich", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "PIS", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Vber mich die ich von oben", "tokens": ["Vber", "mich", "die", "ich", "von", "o\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "ART", "PPER", "APPR", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Durch der grausen Donner tober,", "tokens": ["Durch", "der", "grau\u00b7sen", "Don\u00b7ner", "to\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "In den staub gest\u00fcrtzet bin", "tokens": ["In", "den", "staub", "ge\u00b7st\u00fcrt\u00b7zet", "bin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Mag denn ein Menschen geist so gar verteufelt seyn", "tokens": ["Mag", "denn", "ein", "Men\u00b7schen", "geist", "so", "gar", "ver\u00b7teu\u00b7felt", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "NN", "VVFIN", "ADV", "ADV", "VVPP", "VAINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So grausam/ so verst\u00e4int? Klopfft \u00fcber meiner pein", "tokens": ["So", "grau\u00b7sam", "/", "so", "ver\u00b7st\u00e4\u00b7int", "?", "Klopfft", "\u00fc\u00b7ber", "mei\u00b7ner", "pein"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$(", "ADV", "VVFIN", "$.", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Klopfft man ", "tokens": ["Klopfft", "man"], "token_info": ["word", "word"], "pos": ["NN", "PIS"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Tritt man mich in Sandt?", "tokens": ["Tritt", "man", "mich", "in", "Sandt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "APPR", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Rei\u00dft man Kron vnd Zepter hin.", "tokens": ["Rei\u00dft", "man", "Kron", "vnd", "Zep\u00b7ter", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Meine Feindin! magst du prangen!", "tokens": ["Mei\u00b7ne", "Fein\u00b7din", "!", "magst", "du", "pran\u00b7gen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VMFIN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "R\u00fchrt dein stoltzer Ruhm daher/", "tokens": ["R\u00fchrt", "dein", "stolt\u00b7zer", "Ruhm", "da\u00b7her", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "PAV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df Erd/ Himmel/ Lufft vnd Meer ", "tokens": ["Da\u00df", "Erd", "/", "Him\u00b7mel", "/", "Lufft", "vnd", "Meer"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$(", "NN", "$(", "NN", "KON", "NN"], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Wider mich zur Rach auffstehen? ", "tokens": ["Wi\u00b7der", "mich", "zur", "Rach", "auffs\u00b7te\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der du lange nicht entgangen", "tokens": ["Der", "du", "lan\u00b7ge", "nicht", "ent\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mag dein Geist so lachend gehen/ ", "tokens": ["Mag", "dein", "Geist", "so", "la\u00b7chend", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADV", "ADJD", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df der H\u00f6chste sich ergrimmet ", "tokens": ["Da\u00df", "der", "H\u00f6chs\u00b7te", "sich", "er\u00b7grim\u00b7met"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "PRF", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Vnd mein Haupt zum zweck bestimmet ", "tokens": ["Vnd", "mein", "Haupt", "zum", "zweck", "be\u00b7stim\u00b7met"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Auff den aller Wetter macht", "tokens": ["Auff", "den", "al\u00b7ler", "Wet\u00b7ter", "macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Mit schwartzer wolcken zorn vnd dunckel-rotten ", "tokens": ["Mit", "schwart\u00b7zer", "wol\u00b7cken", "zorn", "vnd", "dun\u00b7ckel\u00b7rot\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN", "KON", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Mit harter schl\u00e4ge Sturm vnd Schwefel-lichter hitz", "tokens": ["Mit", "har\u00b7ter", "schl\u00e4\u00b7ge", "Sturm", "vnd", "Schwe\u00b7fel\u00b7lich\u00b7ter", "hitz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN", "KON", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mit entz\u00fcnd\u2019ter glutt/", "tokens": ["Mit", "ent\u00b7z\u00fcn\u00b7d'\u00b7ter", "glutt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJD", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.13": {"text": "Vnd der schmertzen flutt/", "tokens": ["Vnd", "der", "schmert\u00b7zen", "flutt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "Von der ", "tokens": ["Von", "der"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.4": {"line.1": {"text": "Ohn ists nicht! ich mu\u00df bekennen! ", "tokens": ["Ohn", "ists", "nicht", "!", "ich", "mu\u00df", "be\u00b7ken\u00b7nen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "$.", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df de\u00df Allerh\u00f6chsten Schwerdt", "tokens": ["Da\u00df", "de\u00df", "Al\u00b7ler\u00b7h\u00f6chs\u00b7ten", "Schwerdt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das mir Seel vnd Leib durchf\u00e4hrt/ ", "tokens": ["Das", "mir", "Seel", "vnd", "Leib", "durch\u00b7f\u00e4hrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "NN", "KON", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Geist vnd Hertze gantz zuschnitten.", "tokens": ["Geist", "vnd", "Hert\u00b7ze", "gantz", "zu\u00b7schnit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "GoTTE", "tokens": ["GoT\u00b7TE"], "token_info": ["word"], "pos": ["NE"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Vnd der scharffen Pfeyle w\u00fctten", "tokens": ["Vnd", "der", "scharf\u00b7fen", "Pfey\u00b7le", "w\u00fct\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Die er auff mich abgeschossen:", "tokens": ["Die", "er", "auff", "mich", "ab\u00b7ge\u00b7schos\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Al\u00df mein freveln jhn verdrossen/", "tokens": ["Al\u00df", "mein", "fre\u00b7veln", "jhn", "ver\u00b7dros\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "VVFIN", "PPER", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Doch ich wei\u00df mein Hertze glaubt!", "tokens": ["Doch", "ich", "wei\u00df", "mein", "Hert\u00b7ze", "glaubt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "VVFIN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Ich den jetzt jedes blatt vnd jeder wind erschreckt", "tokens": ["Ich", "den", "jetzt", "je\u00b7des", "blatt", "vnd", "je\u00b7der", "wind", "er\u00b7schreckt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "ADV", "PIAT", "NN", "KON", "PIS", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wil noch die Stunde sehn/ in welcher ich erweckt/", "tokens": ["Wil", "noch", "die", "Stun\u00b7de", "sehn", "/", "in", "wel\u00b7cher", "ich", "er\u00b7weckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "VVINF", "$(", "APPR", "PRELS", "PPER", "VVPP", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.12": {"text": "Au\u00df der Plagen grufft/", "tokens": ["Au\u00df", "der", "Pla\u00b7gen", "grufft", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.13": {"text": "In die freye Lufft", "tokens": ["In", "die", "frey\u00b7e", "Lufft"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "Werd' auffrichten Hand vnd Haupt. ", "tokens": ["Werd'", "auf\u00b7frich\u00b7ten", "Hand", "vnd", "Haupt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Ist mir alles Licht entzogen: ", "tokens": ["Ist", "mir", "al\u00b7les", "Licht", "ent\u00b7zo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df der Sonnen g\u00fcld\u2019ner Schein/", "tokens": ["Mu\u00df", "der", "Son\u00b7nen", "g\u00fcld'\u00b7ner", "Schein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Von mir au\u00dfgebannet seyn/", "tokens": ["Von", "mir", "au\u00df\u00b7ge\u00b7ban\u00b7net", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Soll de\u00df zarten Mondes kertzen", "tokens": ["Soll", "de\u00df", "zar\u00b7ten", "Mon\u00b7des", "kert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die so offt die Welt vmbflogen", "tokens": ["Die", "so", "offt", "die", "Welt", "vmb\u00b7flo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Weil ich zag' in herben Schmertzen/ ", "tokens": ["Weil", "ich", "zag'", "in", "her\u00b7ben", "Schmert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Mir zu scha", "tokens": ["Mir", "zu", "scha"], "token_info": ["word", "word", "word"], "pos": ["PPER", "APPR", "NE"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Soll der Hellbestern'te Wagen ", "tokens": ["Soll", "der", "Hell\u00b7bes\u00b7tern'\u00b7te", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Nicht mir armen mehr auffgehn:", "tokens": ["Nicht", "mir", "ar\u00b7men", "mehr", "auff\u00b7gehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPER", "ADJA", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "So wird des HErren Glantz. Das dunckel das mich deckt", "tokens": ["So", "wird", "des", "Her\u00b7ren", "Glantz", ".", "Das", "dun\u00b7ckel", "das", "mich", "deckt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "$.", "ART", "ADJA", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Nacht/ die mich verh\u00fcllt: das grawen das mich schreckt", "tokens": ["Die", "Nacht", "/", "die", "mich", "ver\u00b7h\u00fcllt", ":", "das", "gra\u00b7wen", "das", "mich", "schreckt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "VVPP", "$.", "ART", "ADJA", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenden. weil sein Strahl", "tokens": ["Wen\u00b7den", ".", "weil", "sein", "Strahl"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.13": {"text": "In dem tr\u00fcben Thal ", "tokens": ["In", "dem", "tr\u00fc\u00b7ben", "Thal"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "Mit viel glantz vmb mich wird stehn.", "tokens": ["Mit", "viel", "glantz", "vmb", "mich", "wird", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "PPER", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wol! Ich wil die last der plagen", "tokens": ["Wol", "!", "Ich", "wil", "die", "last", "der", "pla\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$.", "PPER", "VMFIN", "ART", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd den jammer-reichen spott", "tokens": ["Vnd", "den", "jam\u00b7mer\u00b7rei\u00b7chen", "spott"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Den der ", "tokens": ["Den", "der"], "token_info": ["word", "word"], "pos": ["ART", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Mir auf bende Schultern leget", "tokens": ["Mir", "auf", "ben\u00b7de", "Schul\u00b7tern", "le\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ADJA", "NN", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Mit getro\u00dftem ", "tokens": ["Mit", "ge\u00b7tro\u00df\u00b7tem"], "token_info": ["word", "word"], "pos": ["APPR", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Da\u00df Er jtzt so grimmig schl\u00e4get", "tokens": ["Da\u00df", "Er", "jtzt", "so", "grim\u00b7mig", "schl\u00e4\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Hab ich Niemand schuld zu geben/", "tokens": ["Hab", "ich", "Nie\u00b7mand", "schuld", "zu", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIS", "ADJD", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Al\u00df dem rohen tollen Leben.", "tokens": ["Al\u00df", "dem", "ro\u00b7hen", "tol\u00b7len", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Das ich tag f\u00fcr tag ver\u00fcbt ", "tokens": ["Das", "ich", "tag", "f\u00fcr", "tag", "ver\u00b7\u00fcbt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "NN", "APPR", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Schlag/ straffe/ streich/ v&#241; schmei\u00df. Ich habe mehr verschuldt ", "tokens": ["Schlag", "/", "straf\u00b7fe", "/", "streich", "/", "v", "&#241;", "schmei\u00df", ".", "Ich", "ha\u00b7be", "mehr", "ver\u00b7schuldt"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "XML_entity", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$(", "VVFIN", "$(", "ADJD", "$(", "XY", "$(", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "VVPP"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Ich wil die Kinder Rutt ertragen mit geduldt", "tokens": ["Ich", "wil", "die", "Kin\u00b7der", "Rutt", "er\u00b7tra\u00b7gen", "mit", "ge\u00b7duldt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "NE", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Schlag hier/ schone dort", "tokens": ["Schlag", "hier", "/", "scho\u00b7ne", "dort"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "ADV", "$(", "VVFIN", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.13": {"text": "Besser Rutt al\u00df Mord. ", "tokens": ["Bes\u00b7ser", "Rutt", "al\u00df", "Mord", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "Besser nun/ al\u00dfdann betr\u00fcbt.", "tokens": ["Bes\u00b7ser", "nun", "/", "al\u00df\u00b7dann", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$(", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "GoTT wird was verborgen scheinet ", "tokens": ["GoTT", "wird", "was", "ver\u00b7bor\u00b7gen", "schei\u00b7net"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PIS", "VVPP", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mehr denn ", "tokens": ["Mehr", "denn"], "token_info": ["word", "word"], "pos": ["PIAT", "KON"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "L\u00e4st er gleich mein Recht jtzt ruhn", "tokens": ["L\u00e4st", "er", "gleich", "mein", "Recht", "jtzt", "ruhn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN", "ADV", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Al\u00df obs einmal aufgehoben;", "tokens": ["Al\u00df", "obs", "ein\u00b7mal", "auf\u00b7ge\u00b7ho\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wird doch/ wenn kein ", "tokens": ["Wird", "doch", "/", "wenn", "kein"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ADV", "$(", "KOUS", "PIAT"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Jeder meine ", "tokens": ["Je\u00b7der", "mei\u00b7ne"], "token_info": ["word", "word"], "pos": ["PIS", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.8": {"line.1": {"text": "Was ihr Feinde mit viel l\u00fcgen", "tokens": ["Was", "ihr", "Fein\u00b7de", "mit", "viel", "l\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPOSAT", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schimpffen/ schmehen/ hohn vnd tr\u00fcgen ", "tokens": ["Schimpf\u00b7fen", "/", "schme\u00b7hen", "/", "hohn", "vnd", "tr\u00fc\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "VVINF", "$(", "ADJA", "KON", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jtzt verd\u00e4chtig machen wolt. ", "tokens": ["Jtzt", "ver\u00b7d\u00e4ch\u00b7tig", "ma\u00b7chen", "wolt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird al\u00df der Sonnen-glantz der Dampff vnd wolcken", "tokens": ["Wird", "al\u00df", "der", "Son\u00b7nen\u00b7glantz", "der", "Dampff", "vnd", "wol\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "KOKOM", "ART", "NN", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "trenn't ", "tokens": ["trenn't"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Vnd durch der Nebel dampff am heissen Mittag rennt", "tokens": ["Vnd", "durch", "der", "Ne\u00b7bel", "dampff", "am", "heis\u00b7sen", "Mit\u00b7tag", "rennt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "PAV", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Brechen durch die Nacht", "tokens": ["Bre\u00b7chen", "durch", "die", "Nacht"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.8": {"text": "Da\u00df/ die jhr jtzt lacht", "tokens": ["Da\u00df", "/", "die", "jhr", "jtzt", "lacht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "$(", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Heulen vnd erblinden soll\u2019t.", "tokens": ["Heu\u00b7len", "vnd", "er\u00b7blin\u00b7den", "soll'", "t."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["NN", "KON", "VVINF", "VMFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "F\u00fcr mich wird der Au\u00dfspruch fallen! ", "tokens": ["F\u00fcr", "mich", "wird", "der", "Au\u00df\u00b7spruch", "fal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Denckt! wie werdet jhr bestehen?", "tokens": ["Denckt", "!", "wie", "wer\u00b7det", "jhr", "be\u00b7ste\u00b7hen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PWAV", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit was schimpff vnd spott hingehn?", "tokens": ["Mit", "was", "schimpff", "vnd", "spott", "hin\u00b7gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "HeRR! wie wird mein Hertz dich preisen?", "tokens": ["HeRR", "!", "wie", "wird", "mein", "Hertz", "dich", "prei\u00b7sen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWAV", "VAFIN", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ach! wie wird dem Lob erschallen/", "tokens": ["Ach", "!", "wie", "wird", "dem", "Lob", "er\u00b7schal\u00b7len", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PWAV", "VAFIN", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn du wirst die harten Eysen", "tokens": ["Wenn", "du", "wirst", "die", "har\u00b7ten", "Ey\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Meiner armen schwere F\u00f6sser", "tokens": ["Mei\u00b7ner", "ar\u00b7men", "schwe\u00b7re", "F\u00f6s\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Meiner ", "tokens": ["Mei\u00b7ner"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "Brechen durch ein wort entzwey! ", "tokens": ["Bre\u00b7chen", "durch", "ein", "wort", "ent\u00b7zwey", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.10": {"text": "Wenn dieser frewden ", "tokens": ["Wenn", "die\u00b7ser", "frew\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PDAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Abwech\u00dflen/ werd ich gleich/ dem so vom traum erwacht/", "tokens": ["Ab\u00b7wech\u00df\u00b7len", "/", "werd", "ich", "gleich", "/", "dem", "so", "vom", "traum", "er\u00b7wacht", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VAFIN", "PPER", "ADV", "$(", "ART", "ADV", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Meine Frewde sehn", "tokens": ["Mei\u00b7ne", "Frew\u00b7de", "sehn"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVINF"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.13": {"text": "An dem was geschehn", "tokens": ["An", "dem", "was", "ge\u00b7schehn"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "PIS", "VVINF"], "meter": "--+-+", "measure": "anapaest.init"}, "line.14": {"text": "Lo\u00df von Angst/ der wehmutt frey.", "tokens": ["Lo\u00df", "von", "Angst", "/", "der", "weh\u00b7mutt", "frey", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$(", "ART", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}