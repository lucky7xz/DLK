{"textgrid.poem.34903": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Zwei Ritter", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Crap\u00fclinski und Waschlapski,", "tokens": ["Cra\u00b7p\u00fc\u00b7lins\u00b7ki", "und", "Wasc\u00b7hlaps\u00b7ki", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Polen aus der Polackei,", "tokens": ["Po\u00b7len", "aus", "der", "Po\u00b7lac\u00b7kei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fochten f\u00fcr die Freiheit, gegen", "tokens": ["Foch\u00b7ten", "f\u00fcr", "die", "Frei\u00b7heit", ",", "ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "APPR", "ART", "NN", "$,", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Moskowitertyrannei.", "tokens": ["Mos\u00b7ko\u00b7wi\u00b7ter\u00b7ty\u00b7ran\u00b7nei", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Fochten tapfer und entkamen", "tokens": ["Foch\u00b7ten", "tap\u00b7fer", "und", "ent\u00b7ka\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Endlich gl\u00fccklich nach Paris \u2013", "tokens": ["End\u00b7lich", "gl\u00fcck\u00b7lich", "nach", "Pa\u00b7ris", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Leben bleiben, wie das Sterben", "tokens": ["Le\u00b7ben", "blei\u00b7ben", ",", "wie", "das", "Ster\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVINF", "$,", "PWAV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr das Vaterland, ist s\u00fc\u00df.", "tokens": ["F\u00fcr", "das", "Va\u00b7ter\u00b7land", ",", "ist", "s\u00fc\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wie Achilles und Patroklus,", "tokens": ["Wie", "A\u00b7chil\u00b7les", "und", "Pat\u00b7ro\u00b7klus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "KON", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "David und sein Jonathan,", "tokens": ["Da\u00b7vid", "und", "sein", "Jo\u00b7na\u00b7than", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Liebten sich die beiden Polen,", "tokens": ["Lieb\u00b7ten", "sich", "die", "bei\u00b7den", "Po\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00fc\u00dften sich: \u00bbKochan! Kochan!\u00ab", "tokens": ["K\u00fc\u00df\u00b7ten", "sich", ":", "\u00bb", "Ko\u00b7chan", "!", "Ko\u00b7chan", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["VVFIN", "PRF", "$.", "$(", "NE", "$.", "NE", "$.", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.4": {"line.1": {"text": "Keiner je verriet den andern,", "tokens": ["Kei\u00b7ner", "je", "ver\u00b7riet", "den", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVFIN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Blieben Freunde, ehrlich, treu,", "tokens": ["Blie\u00b7ben", "Freun\u00b7de", ",", "ehr\u00b7lich", ",", "treu", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ob sie gleich zwei edle Polen,", "tokens": ["Ob", "sie", "gleich", "zwei", "ed\u00b7le", "Po\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "CARD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Polen aus der Polackei.", "tokens": ["Po\u00b7len", "aus", "der", "Po\u00b7lac\u00b7kei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wohnten in derselben Stube,", "tokens": ["Wohn\u00b7ten", "in", "der\u00b7sel\u00b7ben", "Stu\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schliefen in demselben Bette;", "tokens": ["Schlie\u00b7fen", "in", "dem\u00b7sel\u00b7ben", "Bet\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Laus und eine Seele,", "tokens": ["Ei\u00b7ne", "Laus", "und", "ei\u00b7ne", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kratzten sie sich um die Wette.", "tokens": ["Kratz\u00b7ten", "sie", "sich", "um", "die", "Wet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.6": {"line.1": {"text": "Speisten in derselben Kneipe,", "tokens": ["Speis\u00b7ten", "in", "der\u00b7sel\u00b7ben", "Knei\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und da keiner wollte leiden,", "tokens": ["Und", "da", "kei\u00b7ner", "woll\u00b7te", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df der andre f\u00fcr ihn zahle,", "tokens": ["Da\u00df", "der", "and\u00b7re", "f\u00fcr", "ihn", "zah\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zahlte keiner von den beiden.", "tokens": ["Zahl\u00b7te", "kei\u00b7ner", "von", "den", "bei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "PIAT", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Auch dieselbe Henriette", "tokens": ["Auch", "die\u00b7sel\u00b7be", "Hen\u00b7riet\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PDAT", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "W\u00e4scht f\u00fcr beide edle Polen;", "tokens": ["W\u00e4scht", "f\u00fcr", "bei\u00b7de", "ed\u00b7le", "Po\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tr\u00e4llernd kommt sie jeden Monat \u2013", "tokens": ["Tr\u00e4l\u00b7lernd", "kommt", "sie", "je\u00b7den", "Mo\u00b7nat", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PIAT", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Um die W\u00e4sche abzuholen.", "tokens": ["Um", "die", "W\u00e4\u00b7sche", "ab\u00b7zu\u00b7ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Ja, sie haben wirklich W\u00e4sche,", "tokens": ["Ja", ",", "sie", "ha\u00b7ben", "wirk\u00b7lich", "W\u00e4\u00b7sche", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jeder hat der Hemden zwei,", "tokens": ["Je\u00b7der", "hat", "der", "Hem\u00b7den", "zwei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "CARD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ob sie gleich zwei edle Polen,", "tokens": ["Ob", "sie", "gleich", "zwei", "ed\u00b7le", "Po\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "CARD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Polen aus der Polackei.", "tokens": ["Po\u00b7len", "aus", "der", "Po\u00b7lac\u00b7kei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Sitzen heute am Kamine,", "tokens": ["Sit\u00b7zen", "heu\u00b7te", "am", "Ka\u00b7mi\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo die Flammen traulich flackern;", "tokens": ["Wo", "die", "Flam\u00b7men", "trau\u00b7lich", "fla\u00b7ckern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Drau\u00dfen Nacht und Schneegest\u00f6ber", "tokens": ["Drau\u00b7\u00dfen", "Nacht", "und", "Schnee\u00b7ge\u00b7st\u00f6\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Rollen von Fiakern.", "tokens": ["Und", "das", "Rol\u00b7len", "von", "Fi\u00b7a\u00b7kern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.10": {"line.1": {"text": "Eine gro\u00dfe Bowle Punsch", "tokens": ["Ei\u00b7ne", "gro\u00b7\u00dfe", "Bow\u00b7le", "Pun\u00b7sch"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "(es versteht sich, unverz\u00fcckert,", "tokens": ["(", "es", "ver\u00b7steht", "sich", ",", "un\u00b7ver\u00b7z\u00fc\u00b7ckert", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "$,", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unvers\u00e4uert, unverw\u00e4ssert)", "tokens": ["Un\u00b7ver\u00b7s\u00e4u\u00b7ert", ",", "un\u00b7ver\u00b7w\u00e4s\u00b7sert", ")"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Haben sie bereits geschl\u00fcckert.", "tokens": ["Ha\u00b7ben", "sie", "be\u00b7reits", "ge\u00b7schl\u00fc\u00b7ckert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Und von Wehmut wird beschlichen", "tokens": ["Und", "von", "Weh\u00b7mut", "wird", "be\u00b7schli\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VAFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihr Gem\u00fcte; ihr Gesicht", "tokens": ["Ihr", "Ge\u00b7m\u00fc\u00b7te", ";", "ihr", "Ge\u00b7sicht"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird befeuchtet schon von Z\u00e4hren,", "tokens": ["Wird", "be\u00b7feuch\u00b7tet", "schon", "von", "Z\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Crap\u00fclinski spricht:", "tokens": ["Und", "der", "Cra\u00b7p\u00fc\u00b7lins\u00b7ki", "spricht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.12": {"line.1": {"text": "\u00bbh\u00e4tt ich doch hier in Paris", "tokens": ["\u00bb", "h\u00e4tt", "ich", "doch", "hier", "in", "Pa\u00b7ris"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "ADV", "ADV", "APPR", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Meinen B\u00e4renpelz, den lieben", "tokens": ["Mei\u00b7nen", "B\u00e4\u00b7ren\u00b7pelz", ",", "den", "lie\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlafrock und die Katzfellnachtm\u00fctz',", "tokens": ["Schla\u00b7frock", "und", "die", "Katz\u00b7fell\u00b7nacht\u00b7m\u00fctz'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "$,"], "meter": "-+--+-++", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die im Vaterland geblieben!\u00ab", "tokens": ["Die", "im", "Va\u00b7ter\u00b7land", "ge\u00b7blie\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "APPRART", "NN", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Ihm erwiderte Waschlapski:", "tokens": ["Ihm", "er\u00b7wi\u00b7der\u00b7te", "Wasc\u00b7hlaps\u00b7ki", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.2": {"text": "\u00bbo du bist ein treuer Schlachzitz,", "tokens": ["\u00bb", "o", "du", "bist", "ein", "treu\u00b7er", "Schlach\u00b7zitz", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Denkest immer an der Heimat", "tokens": ["Den\u00b7kest", "im\u00b7mer", "an", "der", "Hei\u00b7mat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "B\u00e4renpelz und Katzfellnachtm\u00fctz'.", "tokens": ["B\u00e4\u00b7ren\u00b7pelz", "und", "Katz\u00b7fell\u00b7nacht\u00b7m\u00fctz'", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.14": {"line.1": {"text": "Polen ist noch nicht verloren,", "tokens": ["Po\u00b7len", "ist", "noch", "nicht", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsre Weiber, sie geb\u00e4ren,", "tokens": ["Uns\u00b7re", "Wei\u00b7ber", ",", "sie", "ge\u00b7b\u00e4\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unsre Jungfraun tun dasselbe,", "tokens": ["Uns\u00b7re", "Jung\u00b7fraun", "tun", "das\u00b7sel\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "PDAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Werden Helden uns bescheren,", "tokens": ["Wer\u00b7den", "Hel\u00b7den", "uns", "be\u00b7sche\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Helden, wie der Held Sobieski,", "tokens": ["Hel\u00b7den", ",", "wie", "der", "Held", "So\u00b7bies\u00b7ki", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie Schelmuffski und Uminski,", "tokens": ["Wie", "Schel\u00b7muffs\u00b7ki", "und", "Um\u00b7ins\u00b7ki", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eskrokewitsch, Schubiakski,", "tokens": ["Es\u00b7kro\u00b7ke\u00b7witsch", ",", "Schu\u00b7bi\u00b7a\u00b7ks\u00b7ki", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Und der gro\u00dfe Eselinski.\u00ab", "tokens": ["Und", "der", "gro\u00b7\u00dfe", "E\u00b7sel\u00b7ins\u00b7ki", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$.", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.16": {"line.1": {"text": "Crap\u00fclinski und Waschlapski,", "tokens": ["Cra\u00b7p\u00fc\u00b7lins\u00b7ki", "und", "Wasc\u00b7hlaps\u00b7ki", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Polen aus der Polackei,", "tokens": ["Po\u00b7len", "aus", "der", "Po\u00b7lac\u00b7kei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fochten f\u00fcr die Freiheit, gegen", "tokens": ["Foch\u00b7ten", "f\u00fcr", "die", "Frei\u00b7heit", ",", "ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "APPR", "ART", "NN", "$,", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Moskowitertyrannei.", "tokens": ["Mos\u00b7ko\u00b7wi\u00b7ter\u00b7ty\u00b7ran\u00b7nei", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Fochten tapfer und entkamen", "tokens": ["Foch\u00b7ten", "tap\u00b7fer", "und", "ent\u00b7ka\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Endlich gl\u00fccklich nach Paris \u2013", "tokens": ["End\u00b7lich", "gl\u00fcck\u00b7lich", "nach", "Pa\u00b7ris", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Leben bleiben, wie das Sterben", "tokens": ["Le\u00b7ben", "blei\u00b7ben", ",", "wie", "das", "Ster\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVINF", "$,", "PWAV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr das Vaterland, ist s\u00fc\u00df.", "tokens": ["F\u00fcr", "das", "Va\u00b7ter\u00b7land", ",", "ist", "s\u00fc\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Wie Achilles und Patroklus,", "tokens": ["Wie", "A\u00b7chil\u00b7les", "und", "Pat\u00b7ro\u00b7klus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "KON", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "David und sein Jonathan,", "tokens": ["Da\u00b7vid", "und", "sein", "Jo\u00b7na\u00b7than", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Liebten sich die beiden Polen,", "tokens": ["Lieb\u00b7ten", "sich", "die", "bei\u00b7den", "Po\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00fc\u00dften sich: \u00bbKochan! Kochan!\u00ab", "tokens": ["K\u00fc\u00df\u00b7ten", "sich", ":", "\u00bb", "Ko\u00b7chan", "!", "Ko\u00b7chan", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["VVFIN", "PRF", "$.", "$(", "NE", "$.", "NE", "$.", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.19": {"line.1": {"text": "Keiner je verriet den andern,", "tokens": ["Kei\u00b7ner", "je", "ver\u00b7riet", "den", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVFIN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Blieben Freunde, ehrlich, treu,", "tokens": ["Blie\u00b7ben", "Freun\u00b7de", ",", "ehr\u00b7lich", ",", "treu", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ob sie gleich zwei edle Polen,", "tokens": ["Ob", "sie", "gleich", "zwei", "ed\u00b7le", "Po\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "CARD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Polen aus der Polackei.", "tokens": ["Po\u00b7len", "aus", "der", "Po\u00b7lac\u00b7kei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Wohnten in derselben Stube,", "tokens": ["Wohn\u00b7ten", "in", "der\u00b7sel\u00b7ben", "Stu\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schliefen in demselben Bette;", "tokens": ["Schlie\u00b7fen", "in", "dem\u00b7sel\u00b7ben", "Bet\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Laus und eine Seele,", "tokens": ["Ei\u00b7ne", "Laus", "und", "ei\u00b7ne", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kratzten sie sich um die Wette.", "tokens": ["Kratz\u00b7ten", "sie", "sich", "um", "die", "Wet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.21": {"line.1": {"text": "Speisten in derselben Kneipe,", "tokens": ["Speis\u00b7ten", "in", "der\u00b7sel\u00b7ben", "Knei\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und da keiner wollte leiden,", "tokens": ["Und", "da", "kei\u00b7ner", "woll\u00b7te", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df der andre f\u00fcr ihn zahle,", "tokens": ["Da\u00df", "der", "and\u00b7re", "f\u00fcr", "ihn", "zah\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zahlte keiner von den beiden.", "tokens": ["Zahl\u00b7te", "kei\u00b7ner", "von", "den", "bei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "PIAT", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Auch dieselbe Henriette", "tokens": ["Auch", "die\u00b7sel\u00b7be", "Hen\u00b7riet\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PDAT", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "W\u00e4scht f\u00fcr beide edle Polen;", "tokens": ["W\u00e4scht", "f\u00fcr", "bei\u00b7de", "ed\u00b7le", "Po\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tr\u00e4llernd kommt sie jeden Monat \u2013", "tokens": ["Tr\u00e4l\u00b7lernd", "kommt", "sie", "je\u00b7den", "Mo\u00b7nat", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PIAT", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Um die W\u00e4sche abzuholen.", "tokens": ["Um", "die", "W\u00e4\u00b7sche", "ab\u00b7zu\u00b7ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Ja, sie haben wirklich W\u00e4sche,", "tokens": ["Ja", ",", "sie", "ha\u00b7ben", "wirk\u00b7lich", "W\u00e4\u00b7sche", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jeder hat der Hemden zwei,", "tokens": ["Je\u00b7der", "hat", "der", "Hem\u00b7den", "zwei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "CARD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ob sie gleich zwei edle Polen,", "tokens": ["Ob", "sie", "gleich", "zwei", "ed\u00b7le", "Po\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "CARD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Polen aus der Polackei.", "tokens": ["Po\u00b7len", "aus", "der", "Po\u00b7lac\u00b7kei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Sitzen heute am Kamine,", "tokens": ["Sit\u00b7zen", "heu\u00b7te", "am", "Ka\u00b7mi\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo die Flammen traulich flackern;", "tokens": ["Wo", "die", "Flam\u00b7men", "trau\u00b7lich", "fla\u00b7ckern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Drau\u00dfen Nacht und Schneegest\u00f6ber", "tokens": ["Drau\u00b7\u00dfen", "Nacht", "und", "Schnee\u00b7ge\u00b7st\u00f6\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Rollen von Fiakern.", "tokens": ["Und", "das", "Rol\u00b7len", "von", "Fi\u00b7a\u00b7kern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.25": {"line.1": {"text": "Eine gro\u00dfe Bowle Punsch", "tokens": ["Ei\u00b7ne", "gro\u00b7\u00dfe", "Bow\u00b7le", "Pun\u00b7sch"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "(es versteht sich, unverz\u00fcckert,", "tokens": ["(", "es", "ver\u00b7steht", "sich", ",", "un\u00b7ver\u00b7z\u00fc\u00b7ckert", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "$,", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unvers\u00e4uert, unverw\u00e4ssert)", "tokens": ["Un\u00b7ver\u00b7s\u00e4u\u00b7ert", ",", "un\u00b7ver\u00b7w\u00e4s\u00b7sert", ")"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Haben sie bereits geschl\u00fcckert.", "tokens": ["Ha\u00b7ben", "sie", "be\u00b7reits", "ge\u00b7schl\u00fc\u00b7ckert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Und von Wehmut wird beschlichen", "tokens": ["Und", "von", "Weh\u00b7mut", "wird", "be\u00b7schli\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VAFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihr Gem\u00fcte; ihr Gesicht", "tokens": ["Ihr", "Ge\u00b7m\u00fc\u00b7te", ";", "ihr", "Ge\u00b7sicht"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird befeuchtet schon von Z\u00e4hren,", "tokens": ["Wird", "be\u00b7feuch\u00b7tet", "schon", "von", "Z\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Crap\u00fclinski spricht:", "tokens": ["Und", "der", "Cra\u00b7p\u00fc\u00b7lins\u00b7ki", "spricht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.27": {"line.1": {"text": "\u00bbh\u00e4tt ich doch hier in Paris", "tokens": ["\u00bb", "h\u00e4tt", "ich", "doch", "hier", "in", "Pa\u00b7ris"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "ADV", "ADV", "APPR", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Meinen B\u00e4renpelz, den lieben", "tokens": ["Mei\u00b7nen", "B\u00e4\u00b7ren\u00b7pelz", ",", "den", "lie\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlafrock und die Katzfellnachtm\u00fctz',", "tokens": ["Schla\u00b7frock", "und", "die", "Katz\u00b7fell\u00b7nacht\u00b7m\u00fctz'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "$,"], "meter": "-+--+-++", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die im Vaterland geblieben!\u00ab", "tokens": ["Die", "im", "Va\u00b7ter\u00b7land", "ge\u00b7blie\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "APPRART", "NN", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Ihm erwiderte Waschlapski:", "tokens": ["Ihm", "er\u00b7wi\u00b7der\u00b7te", "Wasc\u00b7hlaps\u00b7ki", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.2": {"text": "\u00bbo du bist ein treuer Schlachzitz,", "tokens": ["\u00bb", "o", "du", "bist", "ein", "treu\u00b7er", "Schlach\u00b7zitz", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Denkest immer an der Heimat", "tokens": ["Den\u00b7kest", "im\u00b7mer", "an", "der", "Hei\u00b7mat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "B\u00e4renpelz und Katzfellnachtm\u00fctz'.", "tokens": ["B\u00e4\u00b7ren\u00b7pelz", "und", "Katz\u00b7fell\u00b7nacht\u00b7m\u00fctz'", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.29": {"line.1": {"text": "Polen ist noch nicht verloren,", "tokens": ["Po\u00b7len", "ist", "noch", "nicht", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsre Weiber, sie geb\u00e4ren,", "tokens": ["Uns\u00b7re", "Wei\u00b7ber", ",", "sie", "ge\u00b7b\u00e4\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unsre Jungfraun tun dasselbe,", "tokens": ["Uns\u00b7re", "Jung\u00b7fraun", "tun", "das\u00b7sel\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "PDAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Werden Helden uns bescheren,", "tokens": ["Wer\u00b7den", "Hel\u00b7den", "uns", "be\u00b7sche\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Helden, wie der Held Sobieski,", "tokens": ["Hel\u00b7den", ",", "wie", "der", "Held", "So\u00b7bies\u00b7ki", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie Schelmuffski und Uminski,", "tokens": ["Wie", "Schel\u00b7muffs\u00b7ki", "und", "Um\u00b7ins\u00b7ki", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eskrokewitsch, Schubiakski,", "tokens": ["Es\u00b7kro\u00b7ke\u00b7witsch", ",", "Schu\u00b7bi\u00b7a\u00b7ks\u00b7ki", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Und der gro\u00dfe Eselinski.\u00ab", "tokens": ["Und", "der", "gro\u00b7\u00dfe", "E\u00b7sel\u00b7ins\u00b7ki", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$.", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}}}}