{"textgrid.poem.57470": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ihr Todten! k\u00f6nnt ihr uns erscheinen,", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr Todten! k\u00f6nnt ihr uns erscheinen,", "tokens": ["Ihr", "Tod\u00b7ten", "!", "k\u00f6nnt", "ihr", "uns", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn gleich der Leib im Grabe liegt;", "tokens": ["Wenn", "gleich", "der", "Leib", "im", "Gra\u00b7be", "liegt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo auf den modernden Gebeinen", "tokens": ["Wo", "auf", "den", "mo\u00b7dern\u00b7den", "Ge\u00b7bei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verwesung, Graus und Schimmel siegt;", "tokens": ["Ver\u00b7we\u00b7sung", ",", "Graus", "und", "Schim\u00b7mel", "siegt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schwebt euer Geist noch um die Gr\u00fcfte,", "tokens": ["Schwebt", "eu\u00b7er", "Geist", "noch", "um", "die", "Gr\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bewohnt ihr noch die tiefen L\u00fcfte:", "tokens": ["Be\u00b7wohnt", "ihr", "noch", "die", "tie\u00b7fen", "L\u00fcf\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So la\u00dft doch meinen Wunsch geschehn.", "tokens": ["So", "la\u00dft", "doch", "mei\u00b7nen", "Wunsch", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ach! wollte mir ein Ruf gelingen:", "tokens": ["Ach", "!", "woll\u00b7te", "mir", "ein", "Ruf", "ge\u00b7lin\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "So lie\u00dfe sich vor allen Dingen", "tokens": ["So", "lie\u00b7\u00dfe", "sich", "vor", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die hochber\u00fchmte ", "tokens": ["Die", "hoch\u00b7be\u00b7r\u00fchm\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Ich irre. Nein! Euch, fromme Schatten,", "tokens": ["Ich", "ir\u00b7re", ".", "Nein", "!", "Euch", ",", "from\u00b7me", "Schat\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PTKANT", "$.", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erquicket das Elyserfeld:", "tokens": ["Er\u00b7quic\u00b7ket", "das", "E\u00b7ly\u00b7ser\u00b7feld", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da k\u00f6mmt euch euer Thun zu statten,", "tokens": ["Da", "k\u00f6mmt", "euch", "eu\u00b7er", "Thun", "zu", "stat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da denkt ihr kaum der Oberwelt.", "tokens": ["Da", "denkt", "ihr", "kaum", "der", "O\u00b7ber\u00b7welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sey du einmal auch mein Vertreter,", "tokens": ["Sey", "du", "ein\u00b7mal", "auch", "mein", "Ver\u00b7tre\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Dein Ansehn ist beym ", "tokens": ["Dein", "An\u00b7sehn", "ist", "beym"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPRART"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Durch deinen F\u00fcrspruch kann mirs gl\u00fccken;", "tokens": ["Durch", "dei\u00b7nen", "F\u00fcr\u00b7spruch", "kann", "mirs", "gl\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Er giebt dir leicht mit holden Blicken", "tokens": ["Er", "giebt", "dir", "leicht", "mit", "hol\u00b7den", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die jetzt verlangte Todte los.", "tokens": ["Die", "jetzt", "ver\u00b7lang\u00b7te", "Tod\u00b7te", "los", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Du fragst mich: Soll sie wieder leben?", "tokens": ["Du", "fragst", "mich", ":", "Soll", "sie", "wie\u00b7der", "le\u00b7ben", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "O nein, ", "tokens": ["O", "nein", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "PTKANT", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Sie soll mir nur den Anschlag geben,", "tokens": ["Sie", "soll", "mir", "nur", "den", "An\u00b7schlag", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den sich mein Herz von ihr verspricht.", "tokens": ["Den", "sich", "mein", "Herz", "von", "ihr", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Augenblick wird mich belehren:", "tokens": ["Ein", "Au\u00b7gen\u00b7blick", "wird", "mich", "be\u00b7leh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Alsdann mag sie zur\u00fccke kehren,", "tokens": ["Als\u00b7dann", "mag", "sie", "zu\u00b7r\u00fc\u00b7cke", "keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "VVINF", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.7": {"text": "Wo ihre Tugend sie belohnt.", "tokens": ["Wo", "ih\u00b7re", "Tu\u00b7gend", "sie", "be\u00b7lohnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wohlan, ich seh den G\u00f6tterbothen,", "tokens": ["Wo\u00b7hlan", ",", "ich", "seh", "den", "G\u00f6t\u00b7ter\u00b7bo\u00b7then", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Er eilt, er fliegt ins Reich der Todten,", "tokens": ["Er", "eilt", ",", "er", "fliegt", "ins", "Reich", "der", "Tod\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wo Marter und Vergn\u00fcgen wohnt.", "tokens": ["Wo", "Mar\u00b7ter", "und", "Ver\u00b7gn\u00fc\u00b7gen", "wohnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich bin erh\u00f6rt. Seht! Charons Nachen,", "tokens": ["Ich", "bin", "er\u00b7h\u00f6rt", ".", "Seht", "!", "Cha\u00b7rons", "Na\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "VVFIN", "$.", "NE", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der immer leer zur\u00fccke f\u00e4hrt,", "tokens": ["Der", "im\u00b7mer", "leer", "zu\u00b7r\u00fc\u00b7cke", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mu\u00df, mir zu gut, was neues machen;", "tokens": ["Mu\u00df", ",", "mir", "zu", "gut", ",", "was", "neu\u00b7es", "ma\u00b7chen", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PPER", "PTKA", "ADJD", "$,", "PWS", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dieweil es ", "tokens": ["Die\u00b7weil", "es"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Die theure ", "tokens": ["Die", "theu\u00b7re"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Sie stellt sich anfangs meinem Blicke", "tokens": ["Sie", "stellt", "sich", "an\u00b7fangs", "mei\u00b7nem", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nach Art getrennter Geister dar:", "tokens": ["Nach", "Art", "ge\u00b7trenn\u00b7ter", "Geis\u00b7ter", "dar", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch giebt ", "tokens": ["Doch", "giebt"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Durch die beruffne Wundergabe,", "tokens": ["Durch", "die", "be\u00b7ruff\u00b7ne", "Wun\u00b7der\u00b7ga\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ihr alles, was sie lebend war.", "tokens": ["Ihr", "al\u00b7les", ",", "was", "sie", "le\u00b7bend", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Sie liest. Ich seh ihr edles Wesen,", "tokens": ["Sie", "liest", ".", "Ich", "seh", "ihr", "ed\u00b7les", "We\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das ihr aus Blick und Minen stralt;", "tokens": ["Das", "ihr", "aus", "Blick", "und", "Mi\u00b7nen", "stralt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So Tracht als Gang ist auserlesen,", "tokens": ["So", "Tracht", "als", "Gang", "ist", "au\u00b7ser\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOUS", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kein K\u00fcnstler hat sie so gemalt.", "tokens": ["Kein", "K\u00fcnst\u00b7ler", "hat", "sie", "so", "ge\u00b7malt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie kehrt die scharfen Augenlichter", "tokens": ["Sie", "kehrt", "die", "schar\u00b7fen", "Au\u00b7gen\u00b7lich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Auf dich, du Vater aller Dichter!", "tokens": ["Auf", "dich", ",", "du", "Va\u00b7ter", "al\u00b7ler", "Dich\u00b7ter", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PPER", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Als dessen Schrift sie bey sich tr\u00e4gt.", "tokens": ["Als", "des\u00b7sen", "Schrift", "sie", "bey", "sich", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "VVFIN", "PPER", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sie l\u00e4chelt fast bey jeder Zeile,", "tokens": ["Sie", "l\u00e4\u00b7chelt", "fast", "bey", "je\u00b7der", "Zei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Bis sie, nach einer kurzen Weile,", "tokens": ["Bis", "sie", ",", "nach", "ei\u00b7ner", "kur\u00b7zen", "Wei\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Entz\u00fcckt in beyde H\u00e4nde schl\u00e4gt.", "tokens": ["Ent\u00b7z\u00fcckt", "in", "bey\u00b7de", "H\u00e4n\u00b7de", "schl\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "O welch ein Gl\u00fccke, dich zu schauen,", "tokens": ["O", "welch", "ein", "Gl\u00fc\u00b7cke", ",", "dich", "zu", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du Wunder der Gelehrsamkeit!", "tokens": ["Du", "Wun\u00b7der", "der", "Ge\u00b7lehr\u00b7sam\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erlaube mir, Schmuck aller Frauen!", "tokens": ["Er\u00b7lau\u00b7be", "mir", ",", "Schmuck", "al\u00b7ler", "Frau\u00b7en", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "PIAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Zu fragen, was dich so erfreut?", "tokens": ["Zu", "fra\u00b7gen", ",", "was", "dich", "so", "er\u00b7freut", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PWS", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.5": {"text": "Kann denn ", "tokens": ["Kann", "denn"], "token_info": ["word", "word"], "pos": ["VMFIN", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Dich auch im Tode noch ergetzen,", "tokens": ["Dich", "auch", "im", "To\u00b7de", "noch", "er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der doch bey uns nicht mehr gef\u00e4llt?", "tokens": ["Der", "doch", "bey", "uns", "nicht", "mehr", "ge\u00b7f\u00e4llt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPER", "PTKNEG", "ADV", "VVPP", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Ja, spricht sie: Solche Seltenheiten", "tokens": ["Ja", ",", "spricht", "sie", ":", "Sol\u00b7che", "Sel\u00b7ten\u00b7hei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$.", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Bewundern auch die Ewigkeiten", "tokens": ["Be\u00b7wun\u00b7dern", "auch", "die", "E\u00b7wig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "In unsrer tiefen Unterwelt.", "tokens": ["In", "uns\u00b7rer", "tie\u00b7fen", "Un\u00b7ter\u00b7welt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Was ist nun ferner dein Begehren?", "tokens": ["Was", "ist", "nun", "fer\u00b7ner", "dein", "Be\u00b7geh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So f\u00e4hrt sie fort: Was foderst du?", "tokens": ["So", "f\u00e4hrt", "sie", "fort", ":", "Was", "fo\u00b7derst", "du", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Warum mu\u00df ich zur\u00fccke kehren?", "tokens": ["Wa\u00b7rum", "mu\u00df", "ich", "zu\u00b7r\u00fc\u00b7cke", "keh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was st\u00f6rt man mich in meiner Ruh?", "tokens": ["Was", "st\u00f6rt", "man", "mich", "in", "mei\u00b7ner", "Ruh", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O Heldinn! deines Geistes St\u00e4rke", "tokens": ["O", "Hel\u00b7dinn", "!", "dei\u00b7nes", "Geis\u00b7tes", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "$.", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und deines Griffels Wunderwerke,", "tokens": ["Und", "dei\u00b7nes", "Grif\u00b7fels", "Wun\u00b7der\u00b7wer\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die haben mich dazu gebracht.", "tokens": ["Die", "ha\u00b7ben", "mich", "da\u00b7zu", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "PAV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich habe dir was vorzutragen,", "tokens": ["Ich", "ha\u00b7be", "dir", "was", "vor\u00b7zu\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Es steht bey dir, ob meinen Klagen", "tokens": ["Es", "steht", "bey", "dir", ",", "ob", "mei\u00b7nen", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Dein F\u00fcrspruch bald ein Ende macht.", "tokens": ["Dein", "F\u00fcr\u00b7spruch", "bald", "ein", "En\u00b7de", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Du kennst vieleicht bereits die Sch\u00f6ne,", "tokens": ["Du", "kennst", "vie\u00b7leicht", "be\u00b7reits", "die", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die dort am Weichselufer singt;", "tokens": ["Die", "dort", "am", "Weich\u00b7se\u00b7lu\u00b7fer", "singt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indem der Wohlklang ihrer T\u00f6ne", "tokens": ["In\u00b7dem", "der", "Wohl\u00b7klang", "ih\u00b7rer", "T\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gewi\u00df bis zu den Schatten dringt.", "tokens": ["Ge\u00b7wi\u00df", "bis", "zu", "den", "Schat\u00b7ten", "dringt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du kennest ihres Geistes Gaben,", "tokens": ["Du", "ken\u00b7nest", "ih\u00b7res", "Geis\u00b7tes", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die wenig ihres gleichen haben,", "tokens": ["Die", "we\u00b7nig", "ih\u00b7res", "glei\u00b7chen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PPOSAT", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und ihren nett geschnittnen Kiel;", "tokens": ["Und", "ih\u00b7ren", "nett", "ge\u00b7schnitt\u00b7nen", "Kiel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der oft den Franzen und den Britten", "tokens": ["Der", "oft", "den", "Fran\u00b7zen", "und", "den", "Brit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Den Preis der Schreibart abgestritten,", "tokens": ["Den", "Preis", "der", "Schrei\u00b7bart", "ab\u00b7ge\u00b7strit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ja Deutschland schon im Druck gefiel.", "tokens": ["Ja", "Deutschland", "schon", "im", "Druck", "ge\u00b7fiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Du kennst, in der von ", "tokens": ["Du", "kennst", ",", "in", "der", "von"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "APPR", "ART", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Ihr Buch, vom weiblichen Geschlecht:", "tokens": ["Ihr", "Buch", ",", "vom", "weib\u00b7li\u00b7chen", "Ge\u00b7schlecht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn selbst in eures ", "tokens": ["Denn", "selbst", "in", "eu\u00b7res"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Wird solch ein Lob ihr nicht geschw\u00e4cht.", "tokens": ["Wird", "solch", "ein", "Lob", "ihr", "nicht", "ge\u00b7schw\u00e4cht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ART", "NN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die\u00df Werk, das jeden hier ergetzet,", "tokens": ["Die\u00df", "Werk", ",", "das", "je\u00b7den", "hier", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Hat meine Freundinn \u00fcbersetzet,", "tokens": ["Hat", "mei\u00b7ne", "Freun\u00b7dinn", "\u00fc\u00b7bers\u00b7et\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ja fast noch sch\u00f6ner dargestellt.", "tokens": ["Ja", "fast", "noch", "sch\u00f6\u00b7ner", "dar\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Noch mehr! Sie hat mit s\u00fc\u00dfer Zungen", "tokens": ["Noch", "mehr", "!", "Sie", "hat", "mit", "s\u00fc\u00b7\u00dfer", "Zun\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$.", "PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Auch Ru\u00dflands Kaiserinn besungen,", "tokens": ["Auch", "Ru\u00df\u00b7lands", "Kai\u00b7se\u00b7rinn", "be\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Das Wunder unsrer Oberwelt.", "tokens": ["Das", "Wun\u00b7der", "uns\u00b7rer", "O\u00b7ber\u00b7welt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Sie liebt ein kluges B\u00fccherlesen,", "tokens": ["Sie", "liebt", "ein", "klu\u00b7ges", "B\u00fc\u00b7cher\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie schreibt geschickt, und mit Verstand:", "tokens": ["Sie", "schreibt", "ge\u00b7schickt", ",", "und", "mit", "Ver\u00b7stand", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "$,", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie ha\u00dft ein abgeschmacktes Wesen,", "tokens": ["Sie", "ha\u00dft", "ein", "ab\u00b7ge\u00b7schmack\u00b7tes", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und kurz, sie ziert ihr Vaterland.", "tokens": ["Und", "kurz", ",", "sie", "ziert", "ihr", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nur eins, o Heldinn! mu\u00df ich klagen,", "tokens": ["Nur", "eins", ",", "o", "Hel\u00b7dinn", "!", "mu\u00df", "ich", "kla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "FM", "NN", "$.", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie hat mir etwas abgeschlagen,", "tokens": ["Sie", "hat", "mir", "et\u00b7was", "ab\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was ich zu ihrem Ruhme bath;", "tokens": ["Was", "ich", "zu", "ih\u00b7rem", "Ruh\u00b7me", "ba\u00b7th", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Was keine noch vor ihren Zeiten,", "tokens": ["Was", "kei\u00b7ne", "noch", "vor", "ih\u00b7ren", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Verstand und Tugend auszubreiten,", "tokens": ["Ver\u00b7stand", "und", "Tu\u00b7gend", "aus\u00b7zu\u00b7brei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Von deutschem Frauenzimmer that.", "tokens": ["Von", "deut\u00b7schem", "Frau\u00b7en\u00b7zim\u00b7mer", "that", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Es ist f\u00fcr sie nicht schwer zu nennen;", "tokens": ["Es", "ist", "f\u00fcr", "sie", "nicht", "schwer", "zu", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr Kiel vermag weit mehr, denn das:", "tokens": ["Ihr", "Kiel", "ver\u00b7mag", "weit", "mehr", ",", "denn", "das", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "ADV", "$,", "KON", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie w\u00fcrd es selber wohl erkennen;", "tokens": ["Sie", "w\u00fcrd", "es", "sel\u00b7ber", "wohl", "er\u00b7ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nur scheuet sie der Thoren Ha\u00df.", "tokens": ["Nur", "scheu\u00b7et", "sie", "der", "Tho\u00b7ren", "Ha\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es schrecken sie die tollen Rotten,", "tokens": ["Es", "schre\u00b7cken", "sie", "die", "tol\u00b7len", "Rot\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die alles l\u00e4stern und verspotten,", "tokens": ["Die", "al\u00b7les", "l\u00e4s\u00b7tern", "und", "ver\u00b7spot\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was einer Sch\u00f6nen Griffel wagt.", "tokens": ["Was", "ei\u00b7ner", "Sch\u00f6\u00b7nen", "Grif\u00b7fel", "wagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Denn so will sie mir das versagen,", "tokens": ["Denn", "so", "will", "sie", "mir", "das", "ver\u00b7sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PPER", "PDS", "VVINF", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.10": {"text": "Was sie mir heiligst zugesagt.", "tokens": ["Was", "sie", "mir", "hei\u00b7ligst", "zu\u00b7ge\u00b7sagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Wohlan! erf\u00fclle mein Verlangen,", "tokens": ["Wo\u00b7hlan", "!", "er\u00b7f\u00fcl\u00b7le", "mein", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ermuntre meiner Freundinn Kiel;", "tokens": ["Er\u00b7munt\u00b7re", "mei\u00b7ner", "Freun\u00b7dinn", "Kiel", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du bist ihr r\u00fchmlichst vorgegangen,", "tokens": ["Du", "bist", "ihr", "r\u00fchm\u00b7lichst", "vor\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vielleicht wird noch dein Lob ihr Ziel.", "tokens": ["Viel\u00b7leicht", "wird", "noch", "dein", "Lob", "ihr", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erschein ihr, wenn sie schl\u00e4ft und tr\u00e4umet;", "tokens": ["Er\u00b7schein", "ihr", ",", "wenn", "sie", "schl\u00e4ft", "und", "tr\u00e4u\u00b7met", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und mache, da\u00df sie nichts vers\u00e4umet,", "tokens": ["Und", "ma\u00b7che", ",", "da\u00df", "sie", "nichts", "ver\u00b7s\u00e4u\u00b7met", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was ihren Ruhm unsterblich macht.", "tokens": ["Was", "ih\u00b7ren", "Ruhm", "uns\u00b7terb\u00b7lich", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du kannst ihr nur dein Beyspiel zeigen;", "tokens": ["Du", "kannst", "ihr", "nur", "dein", "Bey\u00b7spiel", "zei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und darfst ihr nichts von dem verschweigen,", "tokens": ["Und", "darfst", "ihr", "nichts", "von", "dem", "ver\u00b7schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PIS", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Was dich so hoch empor gebracht.", "tokens": ["Was", "dich", "so", "hoch", "em\u00b7por", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADJD", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Es soll geschehn! du wirst es sp\u00fcren:", "tokens": ["Es", "soll", "ge\u00b7schehn", "!", "du", "wirst", "es", "sp\u00fc\u00b7ren", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$.", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In deiner Freundinn Zimmer f\u00fchren:", "tokens": ["In", "dei\u00b7ner", "Freun\u00b7dinn", "Zim\u00b7mer", "f\u00fch\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So sprach die Heldinn, und verschwand.", "tokens": ["So", "sprach", "die", "Hel\u00b7dinn", ",", "und", "ver\u00b7schwand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vielleicht ist solches schon geschehen,", "tokens": ["Viel\u00b7leicht", "ist", "sol\u00b7ches", "schon", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein Freund hat sie dir zugeschickt.", "tokens": ["Dein", "Freund", "hat", "sie", "dir", "zu\u00b7ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum, hast du mir dein Herz gegeben:", "tokens": ["Drum", ",", "hast", "du", "mir", "dein", "Herz", "ge\u00b7ge\u00b7ben", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "VAFIN", "PPER", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So mach auch, auserw\u00e4hltes Leben!", "tokens": ["So", "mach", "auch", ",", "au\u00b7ser\u00b7w\u00e4hl\u00b7tes", "Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df solch ein kleiner Wunsch mir gl\u00fcckt!", "tokens": ["Da\u00df", "solch", "ein", "klei\u00b7ner", "Wunsch", "mir", "gl\u00fcckt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ihr Todten! k\u00f6nnt ihr uns erscheinen,", "tokens": ["Ihr", "Tod\u00b7ten", "!", "k\u00f6nnt", "ihr", "uns", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn gleich der Leib im Grabe liegt;", "tokens": ["Wenn", "gleich", "der", "Leib", "im", "Gra\u00b7be", "liegt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo auf den modernden Gebeinen", "tokens": ["Wo", "auf", "den", "mo\u00b7dern\u00b7den", "Ge\u00b7bei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verwesung, Graus und Schimmel siegt;", "tokens": ["Ver\u00b7we\u00b7sung", ",", "Graus", "und", "Schim\u00b7mel", "siegt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schwebt euer Geist noch um die Gr\u00fcfte,", "tokens": ["Schwebt", "eu\u00b7er", "Geist", "noch", "um", "die", "Gr\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bewohnt ihr noch die tiefen L\u00fcfte:", "tokens": ["Be\u00b7wohnt", "ihr", "noch", "die", "tie\u00b7fen", "L\u00fcf\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So la\u00dft doch meinen Wunsch geschehn.", "tokens": ["So", "la\u00dft", "doch", "mei\u00b7nen", "Wunsch", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ach! wollte mir ein Ruf gelingen:", "tokens": ["Ach", "!", "woll\u00b7te", "mir", "ein", "Ruf", "ge\u00b7lin\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "So lie\u00dfe sich vor allen Dingen", "tokens": ["So", "lie\u00b7\u00dfe", "sich", "vor", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die hochber\u00fchmte ", "tokens": ["Die", "hoch\u00b7be\u00b7r\u00fchm\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.15": {"line.1": {"text": "Ich irre. Nein! Euch, fromme Schatten,", "tokens": ["Ich", "ir\u00b7re", ".", "Nein", "!", "Euch", ",", "from\u00b7me", "Schat\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PTKANT", "$.", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erquicket das Elyserfeld:", "tokens": ["Er\u00b7quic\u00b7ket", "das", "E\u00b7ly\u00b7ser\u00b7feld", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da k\u00f6mmt euch euer Thun zu statten,", "tokens": ["Da", "k\u00f6mmt", "euch", "eu\u00b7er", "Thun", "zu", "stat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da denkt ihr kaum der Oberwelt.", "tokens": ["Da", "denkt", "ihr", "kaum", "der", "O\u00b7ber\u00b7welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sey du einmal auch mein Vertreter,", "tokens": ["Sey", "du", "ein\u00b7mal", "auch", "mein", "Ver\u00b7tre\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Dein Ansehn ist beym ", "tokens": ["Dein", "An\u00b7sehn", "ist", "beym"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPRART"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Durch deinen F\u00fcrspruch kann mirs gl\u00fccken;", "tokens": ["Durch", "dei\u00b7nen", "F\u00fcr\u00b7spruch", "kann", "mirs", "gl\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Er giebt dir leicht mit holden Blicken", "tokens": ["Er", "giebt", "dir", "leicht", "mit", "hol\u00b7den", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die jetzt verlangte Todte los.", "tokens": ["Die", "jetzt", "ver\u00b7lang\u00b7te", "Tod\u00b7te", "los", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Du fragst mich: Soll sie wieder leben?", "tokens": ["Du", "fragst", "mich", ":", "Soll", "sie", "wie\u00b7der", "le\u00b7ben", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "O nein, ", "tokens": ["O", "nein", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "PTKANT", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Sie soll mir nur den Anschlag geben,", "tokens": ["Sie", "soll", "mir", "nur", "den", "An\u00b7schlag", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den sich mein Herz von ihr verspricht.", "tokens": ["Den", "sich", "mein", "Herz", "von", "ihr", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Augenblick wird mich belehren:", "tokens": ["Ein", "Au\u00b7gen\u00b7blick", "wird", "mich", "be\u00b7leh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Alsdann mag sie zur\u00fccke kehren,", "tokens": ["Als\u00b7dann", "mag", "sie", "zu\u00b7r\u00fc\u00b7cke", "keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "VVINF", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.7": {"text": "Wo ihre Tugend sie belohnt.", "tokens": ["Wo", "ih\u00b7re", "Tu\u00b7gend", "sie", "be\u00b7lohnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wohlan, ich seh den G\u00f6tterbothen,", "tokens": ["Wo\u00b7hlan", ",", "ich", "seh", "den", "G\u00f6t\u00b7ter\u00b7bo\u00b7then", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Er eilt, er fliegt ins Reich der Todten,", "tokens": ["Er", "eilt", ",", "er", "fliegt", "ins", "Reich", "der", "Tod\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wo Marter und Vergn\u00fcgen wohnt.", "tokens": ["Wo", "Mar\u00b7ter", "und", "Ver\u00b7gn\u00fc\u00b7gen", "wohnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Ich bin erh\u00f6rt. Seht! Charons Nachen,", "tokens": ["Ich", "bin", "er\u00b7h\u00f6rt", ".", "Seht", "!", "Cha\u00b7rons", "Na\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "VVFIN", "$.", "NE", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der immer leer zur\u00fccke f\u00e4hrt,", "tokens": ["Der", "im\u00b7mer", "leer", "zu\u00b7r\u00fc\u00b7cke", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mu\u00df, mir zu gut, was neues machen;", "tokens": ["Mu\u00df", ",", "mir", "zu", "gut", ",", "was", "neu\u00b7es", "ma\u00b7chen", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PPER", "PTKA", "ADJD", "$,", "PWS", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dieweil es ", "tokens": ["Die\u00b7weil", "es"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Die theure ", "tokens": ["Die", "theu\u00b7re"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Sie stellt sich anfangs meinem Blicke", "tokens": ["Sie", "stellt", "sich", "an\u00b7fangs", "mei\u00b7nem", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nach Art getrennter Geister dar:", "tokens": ["Nach", "Art", "ge\u00b7trenn\u00b7ter", "Geis\u00b7ter", "dar", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch giebt ", "tokens": ["Doch", "giebt"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Durch die beruffne Wundergabe,", "tokens": ["Durch", "die", "be\u00b7ruff\u00b7ne", "Wun\u00b7der\u00b7ga\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ihr alles, was sie lebend war.", "tokens": ["Ihr", "al\u00b7les", ",", "was", "sie", "le\u00b7bend", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Sie liest. Ich seh ihr edles Wesen,", "tokens": ["Sie", "liest", ".", "Ich", "seh", "ihr", "ed\u00b7les", "We\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das ihr aus Blick und Minen stralt;", "tokens": ["Das", "ihr", "aus", "Blick", "und", "Mi\u00b7nen", "stralt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So Tracht als Gang ist auserlesen,", "tokens": ["So", "Tracht", "als", "Gang", "ist", "au\u00b7ser\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOUS", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kein K\u00fcnstler hat sie so gemalt.", "tokens": ["Kein", "K\u00fcnst\u00b7ler", "hat", "sie", "so", "ge\u00b7malt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie kehrt die scharfen Augenlichter", "tokens": ["Sie", "kehrt", "die", "schar\u00b7fen", "Au\u00b7gen\u00b7lich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Auf dich, du Vater aller Dichter!", "tokens": ["Auf", "dich", ",", "du", "Va\u00b7ter", "al\u00b7ler", "Dich\u00b7ter", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PPER", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Als dessen Schrift sie bey sich tr\u00e4gt.", "tokens": ["Als", "des\u00b7sen", "Schrift", "sie", "bey", "sich", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "VVFIN", "PPER", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sie l\u00e4chelt fast bey jeder Zeile,", "tokens": ["Sie", "l\u00e4\u00b7chelt", "fast", "bey", "je\u00b7der", "Zei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Bis sie, nach einer kurzen Weile,", "tokens": ["Bis", "sie", ",", "nach", "ei\u00b7ner", "kur\u00b7zen", "Wei\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Entz\u00fcckt in beyde H\u00e4nde schl\u00e4gt.", "tokens": ["Ent\u00b7z\u00fcckt", "in", "bey\u00b7de", "H\u00e4n\u00b7de", "schl\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "O welch ein Gl\u00fccke, dich zu schauen,", "tokens": ["O", "welch", "ein", "Gl\u00fc\u00b7cke", ",", "dich", "zu", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du Wunder der Gelehrsamkeit!", "tokens": ["Du", "Wun\u00b7der", "der", "Ge\u00b7lehr\u00b7sam\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erlaube mir, Schmuck aller Frauen!", "tokens": ["Er\u00b7lau\u00b7be", "mir", ",", "Schmuck", "al\u00b7ler", "Frau\u00b7en", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "PIAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Zu fragen, was dich so erfreut?", "tokens": ["Zu", "fra\u00b7gen", ",", "was", "dich", "so", "er\u00b7freut", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PWS", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.5": {"text": "Kann denn ", "tokens": ["Kann", "denn"], "token_info": ["word", "word"], "pos": ["VMFIN", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Dich auch im Tode noch ergetzen,", "tokens": ["Dich", "auch", "im", "To\u00b7de", "noch", "er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der doch bey uns nicht mehr gef\u00e4llt?", "tokens": ["Der", "doch", "bey", "uns", "nicht", "mehr", "ge\u00b7f\u00e4llt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPER", "PTKNEG", "ADV", "VVPP", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Ja, spricht sie: Solche Seltenheiten", "tokens": ["Ja", ",", "spricht", "sie", ":", "Sol\u00b7che", "Sel\u00b7ten\u00b7hei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$.", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Bewundern auch die Ewigkeiten", "tokens": ["Be\u00b7wun\u00b7dern", "auch", "die", "E\u00b7wig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "In unsrer tiefen Unterwelt.", "tokens": ["In", "uns\u00b7rer", "tie\u00b7fen", "Un\u00b7ter\u00b7welt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Was ist nun ferner dein Begehren?", "tokens": ["Was", "ist", "nun", "fer\u00b7ner", "dein", "Be\u00b7geh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So f\u00e4hrt sie fort: Was foderst du?", "tokens": ["So", "f\u00e4hrt", "sie", "fort", ":", "Was", "fo\u00b7derst", "du", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Warum mu\u00df ich zur\u00fccke kehren?", "tokens": ["Wa\u00b7rum", "mu\u00df", "ich", "zu\u00b7r\u00fc\u00b7cke", "keh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was st\u00f6rt man mich in meiner Ruh?", "tokens": ["Was", "st\u00f6rt", "man", "mich", "in", "mei\u00b7ner", "Ruh", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O Heldinn! deines Geistes St\u00e4rke", "tokens": ["O", "Hel\u00b7dinn", "!", "dei\u00b7nes", "Geis\u00b7tes", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "$.", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und deines Griffels Wunderwerke,", "tokens": ["Und", "dei\u00b7nes", "Grif\u00b7fels", "Wun\u00b7der\u00b7wer\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die haben mich dazu gebracht.", "tokens": ["Die", "ha\u00b7ben", "mich", "da\u00b7zu", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "PAV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich habe dir was vorzutragen,", "tokens": ["Ich", "ha\u00b7be", "dir", "was", "vor\u00b7zu\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Es steht bey dir, ob meinen Klagen", "tokens": ["Es", "steht", "bey", "dir", ",", "ob", "mei\u00b7nen", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Dein F\u00fcrspruch bald ein Ende macht.", "tokens": ["Dein", "F\u00fcr\u00b7spruch", "bald", "ein", "En\u00b7de", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Du kennst vieleicht bereits die Sch\u00f6ne,", "tokens": ["Du", "kennst", "vie\u00b7leicht", "be\u00b7reits", "die", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die dort am Weichselufer singt;", "tokens": ["Die", "dort", "am", "Weich\u00b7se\u00b7lu\u00b7fer", "singt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indem der Wohlklang ihrer T\u00f6ne", "tokens": ["In\u00b7dem", "der", "Wohl\u00b7klang", "ih\u00b7rer", "T\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gewi\u00df bis zu den Schatten dringt.", "tokens": ["Ge\u00b7wi\u00df", "bis", "zu", "den", "Schat\u00b7ten", "dringt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du kennest ihres Geistes Gaben,", "tokens": ["Du", "ken\u00b7nest", "ih\u00b7res", "Geis\u00b7tes", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die wenig ihres gleichen haben,", "tokens": ["Die", "we\u00b7nig", "ih\u00b7res", "glei\u00b7chen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PPOSAT", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und ihren nett geschnittnen Kiel;", "tokens": ["Und", "ih\u00b7ren", "nett", "ge\u00b7schnitt\u00b7nen", "Kiel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der oft den Franzen und den Britten", "tokens": ["Der", "oft", "den", "Fran\u00b7zen", "und", "den", "Brit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Den Preis der Schreibart abgestritten,", "tokens": ["Den", "Preis", "der", "Schrei\u00b7bart", "ab\u00b7ge\u00b7strit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ja Deutschland schon im Druck gefiel.", "tokens": ["Ja", "Deutschland", "schon", "im", "Druck", "ge\u00b7fiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "Du kennst, in der von ", "tokens": ["Du", "kennst", ",", "in", "der", "von"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "APPR", "ART", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Ihr Buch, vom weiblichen Geschlecht:", "tokens": ["Ihr", "Buch", ",", "vom", "weib\u00b7li\u00b7chen", "Ge\u00b7schlecht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn selbst in eures ", "tokens": ["Denn", "selbst", "in", "eu\u00b7res"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Wird solch ein Lob ihr nicht geschw\u00e4cht.", "tokens": ["Wird", "solch", "ein", "Lob", "ihr", "nicht", "ge\u00b7schw\u00e4cht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ART", "NN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die\u00df Werk, das jeden hier ergetzet,", "tokens": ["Die\u00df", "Werk", ",", "das", "je\u00b7den", "hier", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Hat meine Freundinn \u00fcbersetzet,", "tokens": ["Hat", "mei\u00b7ne", "Freun\u00b7dinn", "\u00fc\u00b7bers\u00b7et\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ja fast noch sch\u00f6ner dargestellt.", "tokens": ["Ja", "fast", "noch", "sch\u00f6\u00b7ner", "dar\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Noch mehr! Sie hat mit s\u00fc\u00dfer Zungen", "tokens": ["Noch", "mehr", "!", "Sie", "hat", "mit", "s\u00fc\u00b7\u00dfer", "Zun\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$.", "PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Auch Ru\u00dflands Kaiserinn besungen,", "tokens": ["Auch", "Ru\u00df\u00b7lands", "Kai\u00b7se\u00b7rinn", "be\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Das Wunder unsrer Oberwelt.", "tokens": ["Das", "Wun\u00b7der", "uns\u00b7rer", "O\u00b7ber\u00b7welt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Sie liebt ein kluges B\u00fccherlesen,", "tokens": ["Sie", "liebt", "ein", "klu\u00b7ges", "B\u00fc\u00b7cher\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie schreibt geschickt, und mit Verstand:", "tokens": ["Sie", "schreibt", "ge\u00b7schickt", ",", "und", "mit", "Ver\u00b7stand", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "$,", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie ha\u00dft ein abgeschmacktes Wesen,", "tokens": ["Sie", "ha\u00dft", "ein", "ab\u00b7ge\u00b7schmack\u00b7tes", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und kurz, sie ziert ihr Vaterland.", "tokens": ["Und", "kurz", ",", "sie", "ziert", "ihr", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nur eins, o Heldinn! mu\u00df ich klagen,", "tokens": ["Nur", "eins", ",", "o", "Hel\u00b7dinn", "!", "mu\u00df", "ich", "kla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "FM", "NN", "$.", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie hat mir etwas abgeschlagen,", "tokens": ["Sie", "hat", "mir", "et\u00b7was", "ab\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was ich zu ihrem Ruhme bath;", "tokens": ["Was", "ich", "zu", "ih\u00b7rem", "Ruh\u00b7me", "ba\u00b7th", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Was keine noch vor ihren Zeiten,", "tokens": ["Was", "kei\u00b7ne", "noch", "vor", "ih\u00b7ren", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Verstand und Tugend auszubreiten,", "tokens": ["Ver\u00b7stand", "und", "Tu\u00b7gend", "aus\u00b7zu\u00b7brei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Von deutschem Frauenzimmer that.", "tokens": ["Von", "deut\u00b7schem", "Frau\u00b7en\u00b7zim\u00b7mer", "that", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Es ist f\u00fcr sie nicht schwer zu nennen;", "tokens": ["Es", "ist", "f\u00fcr", "sie", "nicht", "schwer", "zu", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr Kiel vermag weit mehr, denn das:", "tokens": ["Ihr", "Kiel", "ver\u00b7mag", "weit", "mehr", ",", "denn", "das", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "ADV", "$,", "KON", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie w\u00fcrd es selber wohl erkennen;", "tokens": ["Sie", "w\u00fcrd", "es", "sel\u00b7ber", "wohl", "er\u00b7ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nur scheuet sie der Thoren Ha\u00df.", "tokens": ["Nur", "scheu\u00b7et", "sie", "der", "Tho\u00b7ren", "Ha\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es schrecken sie die tollen Rotten,", "tokens": ["Es", "schre\u00b7cken", "sie", "die", "tol\u00b7len", "Rot\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die alles l\u00e4stern und verspotten,", "tokens": ["Die", "al\u00b7les", "l\u00e4s\u00b7tern", "und", "ver\u00b7spot\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was einer Sch\u00f6nen Griffel wagt.", "tokens": ["Was", "ei\u00b7ner", "Sch\u00f6\u00b7nen", "Grif\u00b7fel", "wagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Denn so will sie mir das versagen,", "tokens": ["Denn", "so", "will", "sie", "mir", "das", "ver\u00b7sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PPER", "PDS", "VVINF", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.10": {"text": "Was sie mir heiligst zugesagt.", "tokens": ["Was", "sie", "mir", "hei\u00b7ligst", "zu\u00b7ge\u00b7sagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Wohlan! erf\u00fclle mein Verlangen,", "tokens": ["Wo\u00b7hlan", "!", "er\u00b7f\u00fcl\u00b7le", "mein", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ermuntre meiner Freundinn Kiel;", "tokens": ["Er\u00b7munt\u00b7re", "mei\u00b7ner", "Freun\u00b7dinn", "Kiel", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du bist ihr r\u00fchmlichst vorgegangen,", "tokens": ["Du", "bist", "ihr", "r\u00fchm\u00b7lichst", "vor\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vielleicht wird noch dein Lob ihr Ziel.", "tokens": ["Viel\u00b7leicht", "wird", "noch", "dein", "Lob", "ihr", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erschein ihr, wenn sie schl\u00e4ft und tr\u00e4umet;", "tokens": ["Er\u00b7schein", "ihr", ",", "wenn", "sie", "schl\u00e4ft", "und", "tr\u00e4u\u00b7met", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und mache, da\u00df sie nichts vers\u00e4umet,", "tokens": ["Und", "ma\u00b7che", ",", "da\u00df", "sie", "nichts", "ver\u00b7s\u00e4u\u00b7met", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was ihren Ruhm unsterblich macht.", "tokens": ["Was", "ih\u00b7ren", "Ruhm", "uns\u00b7terb\u00b7lich", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du kannst ihr nur dein Beyspiel zeigen;", "tokens": ["Du", "kannst", "ihr", "nur", "dein", "Bey\u00b7spiel", "zei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und darfst ihr nichts von dem verschweigen,", "tokens": ["Und", "darfst", "ihr", "nichts", "von", "dem", "ver\u00b7schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PIS", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Was dich so hoch empor gebracht.", "tokens": ["Was", "dich", "so", "hoch", "em\u00b7por", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADJD", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Es soll geschehn! du wirst es sp\u00fcren:", "tokens": ["Es", "soll", "ge\u00b7schehn", "!", "du", "wirst", "es", "sp\u00fc\u00b7ren", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$.", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In deiner Freundinn Zimmer f\u00fchren:", "tokens": ["In", "dei\u00b7ner", "Freun\u00b7dinn", "Zim\u00b7mer", "f\u00fch\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So sprach die Heldinn, und verschwand.", "tokens": ["So", "sprach", "die", "Hel\u00b7dinn", ",", "und", "ver\u00b7schwand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vielleicht ist solches schon geschehen,", "tokens": ["Viel\u00b7leicht", "ist", "sol\u00b7ches", "schon", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein Freund hat sie dir zugeschickt.", "tokens": ["Dein", "Freund", "hat", "sie", "dir", "zu\u00b7ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum, hast du mir dein Herz gegeben:", "tokens": ["Drum", ",", "hast", "du", "mir", "dein", "Herz", "ge\u00b7ge\u00b7ben", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "VAFIN", "PPER", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So mach auch, auserw\u00e4hltes Leben!", "tokens": ["So", "mach", "auch", ",", "au\u00b7ser\u00b7w\u00e4hl\u00b7tes", "Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df solch ein kleiner Wunsch mir gl\u00fcckt!", "tokens": ["Da\u00df", "solch", "ein", "klei\u00b7ner", "Wunsch", "mir", "gl\u00fcckt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}