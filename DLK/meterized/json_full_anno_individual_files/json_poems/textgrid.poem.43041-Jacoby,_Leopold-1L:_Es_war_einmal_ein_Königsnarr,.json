{"textgrid.poem.43041": {"metadata": {"author": {"name": "Jacoby, Leopold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es war einmal ein K\u00f6nigsnarr,", "genre": "verse", "period": "N.A.", "pub_year": 1867, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es war einmal ein K\u00f6nigsnarr,", "tokens": ["Es", "war", "ein\u00b7mal", "ein", "K\u00f6\u00b7nigs\u00b7narr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der manches Jahr Hofnarre war", "tokens": ["Der", "man\u00b7ches", "Jahr", "Hof\u00b7nar\u00b7re", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bei einem K\u00f6nig wohlgemuth", "tokens": ["Bei", "ei\u00b7nem", "K\u00f6\u00b7nig", "wohl\u00b7ge\u00b7muth"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und reich an Land und fromm und gut.", "tokens": ["Und", "reich", "an", "Land", "und", "fromm", "und", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der K\u00f6nig war dem Narren hold,", "tokens": ["Der", "K\u00f6\u00b7nig", "war", "dem", "Nar\u00b7ren", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hielt ihn in Ehr' und gutem Sold,", "tokens": ["Hielt", "ihn", "in", "Ehr'", "und", "gu\u00b7tem", "Sold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Daf\u00fcr der Narr ihm dankbar war", "tokens": ["Da\u00b7f\u00fcr", "der", "Narr", "ihm", "dank\u00b7bar", "war"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "PPER", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und zugethan just wie ein Narr.", "tokens": ["Und", "zu\u00b7ge\u00b7than", "just", "wie", "ein", "Narr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nun traf sich's \u00fcber kurz und lang,", "tokens": ["Nun", "traf", "sich's", "\u00fc\u00b7ber", "kurz", "und", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der K\u00f6nig wurde fieberkrank,", "tokens": ["Der", "K\u00f6\u00b7nig", "wur\u00b7de", "fie\u00b7ber\u00b7krank", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und rings umher in weiter Rund'", "tokens": ["Und", "rings", "um\u00b7her", "in", "wei\u00b7ter", "Rund'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PTKVZ", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein Arzt dem Kranken helfen kunnt.", "tokens": ["Kein", "Arzt", "dem", "Kran\u00b7ken", "hel\u00b7fen", "kunnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Da ging bei Hof ein Trauern an,", "tokens": ["Da", "ging", "bei", "Hof", "ein", "Trau\u00b7ern", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es weinten Zof' und Edelmann.", "tokens": ["Es", "wein\u00b7ten", "Zof'", "und", "E\u00b7del\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Narr war kaum bei Sinnen mehr,", "tokens": ["Der", "Narr", "war", "kaum", "bei", "Sin\u00b7nen", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er h\u00e4rmte sich ohnma\u00dfen schwer.", "tokens": ["Er", "h\u00e4rm\u00b7te", "sich", "ohn\u00b7ma\u00b7\u00dfen", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und sa\u00df und gr\u00fcbelt Tag und Nacht,", "tokens": ["Und", "sa\u00df", "und", "gr\u00fc\u00b7belt", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis er ein Mittel auserdacht,", "tokens": ["Bis", "er", "ein", "Mit\u00b7tel", "au\u00b7ser\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das ihm nach seinem Narrensinn", "tokens": ["Das", "ihm", "nach", "sei\u00b7nem", "Nar\u00b7ren\u00b7sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr seinen Herren heilsam schien.", "tokens": ["F\u00fcr", "sei\u00b7nen", "Her\u00b7ren", "heil\u00b7sam", "schien", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Im Garten bei des K\u00f6nigs Schlo\u00df", "tokens": ["Im", "Gar\u00b7ten", "bei", "des", "K\u00f6\u00b7nigs", "Schlo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da war ein Teich, darinnen flo\u00df", "tokens": ["Da", "war", "ein", "Teich", ",", "da\u00b7rin\u00b7nen", "flo\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum Wehre niederw\u00e4rts ein Bach,", "tokens": ["Zum", "Weh\u00b7re", "nie\u00b7der\u00b7w\u00e4rts", "ein", "Bach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dort war der Kranke jeden Tag.", "tokens": ["Dort", "war", "der", "Kran\u00b7ke", "je\u00b7den", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Der Narre bla\u00df, der K\u00f6nig bleich,", "tokens": ["Der", "Nar\u00b7re", "bla\u00df", ",", "der", "K\u00f6\u00b7nig", "bleich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie standen an dem Gartenteich,", "tokens": ["Sie", "stan\u00b7den", "an", "dem", "Gar\u00b7ten\u00b7teich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Sto\u00df da von des Narren Hand,", "tokens": ["Ein", "Sto\u00df", "da", "von", "des", "Nar\u00b7ren", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der K\u00f6nig taumelt \u00fcber'n Rand.", "tokens": ["Der", "K\u00f6\u00b7nig", "tau\u00b7melt", "\u00fc\u00b7ber'n", "Rand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Es fiel der K\u00f6nig in das Wehr,", "tokens": ["Es", "fiel", "der", "K\u00f6\u00b7nig", "in", "das", "Wehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Plump! \u2013 sprang der Narre hinterher.", "tokens": ["Plump", "!", "\u2013", "sprang", "der", "Nar\u00b7re", "hin\u00b7ter\u00b7her", "."], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "$(", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der K\u00f6nig fiel, der Narre sprang,", "tokens": ["Der", "K\u00f6\u00b7nig", "fiel", ",", "der", "Nar\u00b7re", "sprang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Beiden keiner untersank.", "tokens": ["Von", "Bei\u00b7den", "kei\u00b7ner", "un\u00b7ter\u00b7sank", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Sie kamen gl\u00fccklich wieder ba\u00df", "tokens": ["Sie", "ka\u00b7men", "gl\u00fcck\u00b7lich", "wie\u00b7der", "ba\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und waren alle Beide \u2013 na\u00df;", "tokens": ["Und", "wa\u00b7ren", "al\u00b7le", "Bei\u00b7de", "\u2013", "na\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "PIS", "$(", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch durch den Schreck der K\u00f6nig war", "tokens": ["Doch", "durch", "den", "Schreck", "der", "K\u00f6\u00b7nig", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Stund gesund. Es jauchzt der Narr.", "tokens": ["Von", "Stund", "ge\u00b7sund", ".", "Es", "jauchzt", "der", "Narr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$.", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Da kam der Narr, der arme Wicht,", "tokens": ["Da", "kam", "der", "Narr", ",", "der", "ar\u00b7me", "Wicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob Hochverraths vors Hofgericht,", "tokens": ["Ob", "Hoch\u00b7ver\u00b7raths", "vors", "Hof\u00b7ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und billig ward ihm zuerkannt", "tokens": ["Und", "bil\u00b7lig", "ward", "ihm", "zu\u00b7er\u00b7kannt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Tod durchs Schwert von Henkershand.", "tokens": ["Der", "Tod", "durchs", "Schwert", "von", "Hen\u00b7ker\u00b7shand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der Spruch geschah, das Urtheil blieb,", "tokens": ["Der", "Spruch", "ge\u00b7schah", ",", "das", "Ur\u00b7theil", "blieb", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der gute K\u00f6nig unterschrieb.", "tokens": ["Der", "gu\u00b7te", "K\u00f6\u00b7nig", "un\u00b7ter\u00b7schrieb", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum Henker sendet er darnach,", "tokens": ["Zum", "Hen\u00b7ker", "sen\u00b7det", "er", "dar\u00b7nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Henker kam, der K\u00f6nig sprach:", "tokens": ["Der", "Hen\u00b7ker", "kam", ",", "der", "K\u00f6\u00b7nig", "sprach", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ich will dem Narren gn\u00e4dig sein.", "tokens": ["Ich", "will", "dem", "Nar\u00b7ren", "gn\u00e4\u00b7dig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du sollst dein Amt nur thun zum Schein;", "tokens": ["Du", "sollst", "dein", "Amt", "nur", "thun", "zum", "Schein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "ADV", "VVINF", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jedoch der Narre bis zum Schlu\u00df", "tokens": ["Je\u00b7doch", "der", "Nar\u00b7re", "bis", "zum", "Schlu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Soll glauben, da\u00df er sterben mu\u00df.", "tokens": ["Soll", "glau\u00b7ben", ",", "da\u00df", "er", "ster\u00b7ben", "mu\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Drum h\u00fcte dich, da\u00df Niemand wei\u00df,", "tokens": ["Drum", "h\u00fc\u00b7te", "dich", ",", "da\u00df", "Nie\u00b7mand", "wei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was du sollst thun auf mein Gehei\u00df,", "tokens": ["Was", "du", "sollst", "thun", "auf", "mein", "Ge\u00b7hei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VMFIN", "VVINF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Sonst trifft das Urtheil dich und ihn.", "tokens": ["Sonst", "trifft", "das", "Ur\u00b7theil", "dich", "und", "ihn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Henker ging. Der Tag erschien.", "tokens": ["Der", "Hen\u00b7ker", "ging", ".", "Der", "Tag", "er\u00b7schien", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ringsum ein gro\u00df Gefolge sa\u00df.", "tokens": ["Ring\u00b7sum", "ein", "gro\u00df", "Ge\u00b7fol\u00b7ge", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Der K\u00f6nig freut sich auf den Spa\u00df.", "tokens": ["Der", "K\u00f6\u00b7nig", "freut", "sich", "auf", "den", "Spa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Narr wird auf's Schaffot gef\u00fchrt,", "tokens": ["Der", "Narr", "wird", "auf's", "Schaf\u00b7fot", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Sein starrer Blick zum K\u00f6nig stiert.", "tokens": ["Sein", "star\u00b7rer", "Blick", "zum", "K\u00f6\u00b7nig", "stiert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Der Henker ihm die Augen band", "tokens": ["Der", "Hen\u00b7ker", "ihm", "die", "Au\u00b7gen", "band"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und \u2013 statt des Schwerts aus dem Gewand", "tokens": ["Und", "\u2013", "statt", "des", "Schwerts", "aus", "dem", "Ge\u00b7wand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er eine Weidenruthe zog,", "tokens": ["Er", "ei\u00b7ne", "Wei\u00b7den\u00b7ru\u00b7the", "zog", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Henker h\u00e4lt die Ruthe hoch.", "tokens": ["Der", "Hen\u00b7ker", "h\u00e4lt", "die", "Ru\u00b7the", "hoch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Wie die des Narren K\u00f6rper strich,", "tokens": ["Wie", "die", "des", "Nar\u00b7ren", "K\u00f6r\u00b7per", "strich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ART", "NN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der zuckt zusammen f\u00fcrchterlich.", "tokens": ["Der", "zuckt", "zu\u00b7sam\u00b7men", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als man ihm nun die Gnade bot,", "tokens": ["Als", "man", "ihm", "nun", "die", "Gna\u00b7de", "bot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der dumme K\u00f6nigsnarr \u2013 war todt.", "tokens": ["Der", "dum\u00b7me", "K\u00f6\u00b7nigs\u00b7narr", "\u2013", "war", "todt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Der erste sprach: Wahrlich, das war", "tokens": ["Der", "ers\u00b7te", "sprach", ":", "Wahr\u00b7lich", ",", "das", "war"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "$.", "ADV", "$,", "PDS", "VAFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Treu bis zum Tod \u2013 ein K\u00f6nigsnarr!", "tokens": ["Treu", "bis", "zum", "Tod", "\u2013", "ein", "K\u00f6\u00b7nigs\u00b7narr", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "APPRART", "NN", "$(", "ART", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Doch wer soll nun als Richter entscheiden,", "tokens": ["Doch", "wer", "soll", "nun", "als", "Rich\u00b7ter", "ent\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "ADV", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wer das bessere Lied sang von uns beiden?", "tokens": ["Wer", "das", "bes\u00b7se\u00b7re", "Lied", "sang", "von", "uns", "bei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN", "APPR", "PPER", "PIAT", "$."], "meter": "--+--++--+-", "measure": "anapaest.di.plus"}}, "stanza.18": {"line.1": {"text": "Da rief der zweite: alle guten Geister!", "tokens": ["Da", "rief", "der", "zwei\u00b7te", ":", "al\u00b7le", "gu\u00b7ten", "Geis\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "$.", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dort kommt von den Sch\u00fclern der Meister.", "tokens": ["Dort", "kommt", "von", "den", "Sch\u00fc\u00b7lern", "der", "Meis\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Das ist ein Richter, ein kleiner, doch feiner.", "tokens": ["Das", "ist", "ein", "Rich\u00b7ter", ",", "ein", "klei\u00b7ner", ",", "doch", "fei\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "ART", "ADJA", "$,", "ADV", "ADJD", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sieh dich um, da kommt einer,", "tokens": ["Sieh", "dich", "um", ",", "da", "kommt", "ei\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKVZ", "$,", "ADV", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dem der Himmel einen Blick verlieh", "tokens": ["Dem", "der", "Him\u00b7mel", "ei\u00b7nen", "Blick", "ver\u00b7lieh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Voll fr\u00f6hlicher Melancholie.", "tokens": ["Voll", "fr\u00f6h\u00b7li\u00b7cher", "Me\u00b7lan\u00b7cho\u00b7lie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Es trat aber ein dritter Gesell in das Zimmer,", "tokens": ["Es", "trat", "a\u00b7ber", "ein", "drit\u00b7ter", "Ge\u00b7sell", "in", "das", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+---+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "De\u00df Antlitz strahlt in bleichem Schimmer.", "tokens": ["De\u00df", "Ant\u00b7litz", "strahlt", "in", "blei\u00b7chem", "Schim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Und also der erste zum zweiten spricht:", "tokens": ["Und", "al\u00b7so", "der", "ers\u00b7te", "zum", "zwei\u00b7ten", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "APPRART", "ADJA", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Nein, das verstehst du nicht.", "tokens": ["Nein", ",", "das", "ver\u00b7stehst", "du", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sieh doch nur sein Gesicht an,", "tokens": ["Sieh", "doch", "nur", "sein", "Ge\u00b7sicht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Siehst du es ihm denn nicht an?", "tokens": ["Siehst", "du", "es", "ihm", "denn", "nicht", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PPER", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Er ist ganz verz\u00fcckt", "tokens": ["Er", "ist", "ganz", "ver\u00b7z\u00fcckt"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "VVPP"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Und uns entr\u00fcckt", "tokens": ["Und", "uns", "ent\u00b7r\u00fcckt"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Und schaut in die Seligkeiten alle.", "tokens": ["Und", "schaut", "in", "die", "Se\u00b7lig\u00b7kei\u00b7ten", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PIAT", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Noch aber sah ich keinen, der blickt ins Sonnenlicht", "tokens": ["Noch", "a\u00b7ber", "sah", "ich", "kei\u00b7nen", ",", "der", "blickt", "ins", "Son\u00b7nen\u00b7licht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PIAT", "$,", "PRELS", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Und machte dazu ein gescheutes Gesicht.", "tokens": ["Und", "mach\u00b7te", "da\u00b7zu", "ein", "ge\u00b7scheu\u00b7tes", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.21": {"line.1": {"text": "Und lachend erwidert der zweite: F\u00fcrwahr,", "tokens": ["Und", "la\u00b7chend", "er\u00b7wi\u00b7dert", "der", "zwei\u00b7te", ":", "F\u00fcr\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "ADJA", "$.", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Du machst deine Sache wunderbar.", "tokens": ["Du", "machst", "dei\u00b7ne", "Sa\u00b7che", "wun\u00b7der\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wo du streichelst, packst du zu,", "tokens": ["Wo", "du", "strei\u00b7chelst", ",", "packst", "du", "zu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo du schmeichelst, bei\u00dfest du.", "tokens": ["Wo", "du", "schmei\u00b7chelst", ",", "bei\u00b7\u00dfest", "du", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Darnach", "tokens": ["Dar\u00b7nach"], "token_info": ["word"], "pos": ["PAV"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Zum dritten gewendet Jener sprach:", "tokens": ["Zum", "drit\u00b7ten", "ge\u00b7wen\u00b7det", "Je\u00b7ner", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVPP", "PDAT", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Hab' ich dich gebissen, o Freund, gewi\u00df", "tokens": ["Hab'", "ich", "dich", "ge\u00b7bis\u00b7sen", ",", "o", "Freund", ",", "ge\u00b7wi\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "PPER", "PRF", "VVPP", "$,", "FM", "NN", "$,", "ADV"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "So war es nur ein kleiner Bi\u00df,", "tokens": ["So", "war", "es", "nur", "ein", "klei\u00b7ner", "Bi\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und \u00fcber ein bischen wirst du schmollen?", "tokens": ["Und", "\u00fc\u00b7ber", "ein", "bi\u00b7schen", "wirst", "du", "schmol\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADV", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Bewahre der Himmel, das darfst du nicht wollen.", "tokens": ["Be\u00b7wah\u00b7re", "der", "Him\u00b7mel", ",", "das", "darfst", "du", "nicht", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PDS", "VMFIN", "PPER", "PTKNEG", "VMFIN", "$."], "meter": "-+--+--++-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Du bist ja ein Genie,", "tokens": ["Du", "bist", "ja", "ein", "Ge\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Und so etwas thut ein Genie", "tokens": ["Und", "so", "et\u00b7was", "thut", "ein", "Ge\u00b7nie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PIS", "VVFIN", "ART", "NN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Nie.", "tokens": ["Nie", "."], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "+", "measure": "single.up"}, "line.10": {"text": "Nun will ich dir aber ein Liedlein singen,", "tokens": ["Nun", "will", "ich", "dir", "a\u00b7ber", "ein", "Lied\u00b7lein", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Das wird deinen Ohren besser klingen;", "tokens": ["Das", "wird", "dei\u00b7nen", "Oh\u00b7ren", "bes\u00b7ser", "klin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.12": {"text": "Denn ich glaub', du klagst noch \u00fcber Wunden,", "tokens": ["Denn", "ich", "glaub'", ",", "du", "klagst", "noch", "\u00fc\u00b7ber", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.13": {"text": "Die ich schon l\u00e4ngst hab' \u00fcberwunden.", "tokens": ["Die", "ich", "schon", "l\u00e4ngst", "hab'", "\u00fc\u00b7berw\u00b7un\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Horch:", "tokens": ["Horch", ":"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.23": {"line.1": {"text": "Und ob dir auch bei jedem Schritt", "tokens": ["Und", "ob", "dir", "auch", "bei", "je\u00b7dem", "Schritt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Kleinheit der Menschen entgegentritt,", "tokens": ["Die", "Klein\u00b7heit", "der", "Men\u00b7schen", "ent\u00b7ge\u00b7gen\u00b7tritt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und die abgestumpften Philisterseelen", "tokens": ["Und", "die", "ab\u00b7ge\u00b7stumpf\u00b7ten", "Phi\u00b7lis\u00b7ter\u00b7see\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Dein sch\u00f6nheitfrohes Gem\u00fcth zerqu\u00e4len,", "tokens": ["Dein", "sch\u00f6n\u00b7heit\u00b7fro\u00b7hes", "Ge\u00b7m\u00fcth", "zer\u00b7qu\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "O lach' sie aus,", "tokens": ["O", "lach'", "sie", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Mit blutendem Herzen lach' sie aus.", "tokens": ["Mit", "blu\u00b7ten\u00b7dem", "Her\u00b7zen", "lach'", "sie", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Glaub' mir, sie sind es nimmer werth,", "tokens": ["Glaub'", "mir", ",", "sie", "sind", "es", "nim\u00b7mer", "werth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df Gram darob dein Herz beschwert.", "tokens": ["Da\u00df", "Gram", "da\u00b7rob", "dein", "Herz", "be\u00b7schwert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PAV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Blick auf die Herde nur im Gefild,", "tokens": ["Blick", "auf", "die", "Her\u00b7de", "nur", "im", "Ge\u00b7fild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Da findest du ganz ihr Ebenbild;", "tokens": ["Da", "fin\u00b7dest", "du", "ganz", "ihr", "E\u00b7ben\u00b7bild", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Denn die Philister, die sind wie", "tokens": ["Denn", "die", "Phi\u00b7lis\u00b7ter", ",", "die", "sind", "wie"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "VAFIN", "KOKOM"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Auf der Weide das Rindvieh.", "tokens": ["Auf", "der", "Wei\u00b7de", "das", "Rind\u00b7vieh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.13": {"text": "Grasen", "tokens": ["Gra\u00b7sen"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.14": {"text": "Ruhig weiter ab den Rasen,", "tokens": ["Ru\u00b7hig", "wei\u00b7ter", "ab", "den", "Ra\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Treffen sie eine Blume dann,", "tokens": ["Tref\u00b7fen", "sie", "ei\u00b7ne", "Blu\u00b7me", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Glotzen sie sie verwundert an,", "tokens": ["Glot\u00b7zen", "sie", "sie", "ver\u00b7wun\u00b7dert", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.17": {"text": "Brummen,", "tokens": ["Brum\u00b7men", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.18": {"text": "Da\u00df man sie nicht fressen kann.", "tokens": ["Da\u00df", "man", "sie", "nicht", "fres\u00b7sen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "Und der dritte darauf begann", "tokens": ["Und", "der", "drit\u00b7te", "da\u00b7rauf", "be\u00b7gann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "PAV", "VVFIN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.20": {"text": "Mit einer Stimme, deren Klang", "tokens": ["Mit", "ei\u00b7ner", "Stim\u00b7me", ",", "de\u00b7ren", "Klang"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Seltsam den H\u00f6rern zu Herzen drang:", "tokens": ["Selt\u00b7sam", "den", "H\u00f6\u00b7rern", "zu", "Her\u00b7zen", "drang", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.24": {"line.1": {"text": "Wer in der Kindheit gl\u00fccklich war,", "tokens": ["Wer", "in", "der", "Kind\u00b7heit", "gl\u00fcck\u00b7lich", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ist gesegnet f\u00fcr immerdar.", "tokens": ["Der", "ist", "ge\u00b7seg\u00b7net", "f\u00fcr", "im\u00b7mer\u00b7dar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "APPR", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er kann und wird nicht sterben an Wunden,", "tokens": ["Er", "kann", "und", "wird", "nicht", "ster\u00b7ben", "an", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KON", "VAFIN", "PTKNEG", "VVINF", "APPR", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Er will und wird immer wieder gesunden,", "tokens": ["Er", "will", "und", "wird", "im\u00b7mer", "wie\u00b7der", "ge\u00b7sun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KON", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Er ist gewappnet und bleibet so", "tokens": ["Er", "ist", "ge\u00b7wapp\u00b7net", "und", "blei\u00b7bet", "so"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "VVFIN", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "In allem Elend wunderfroh.", "tokens": ["In", "al\u00b7lem", "E\u00b7lend", "wun\u00b7der\u00b7froh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Ein sch\u00f6nes Recept, der zweite sprach,", "tokens": ["Ein", "sch\u00f6\u00b7nes", "Re\u00b7cept", ",", "der", "zwei\u00b7te", "sprach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nur Schad' ist und wird es ewig bleiben,", "tokens": ["Nur", "Schad'", "ist", "und", "wird", "es", "e\u00b7wig", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "KON", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Kein Erwachsener kann es sich mehr verschreiben. \u2013", "tokens": ["Kein", "Er\u00b7wach\u00b7se\u00b7ner", "kann", "es", "sich", "mehr", "ver\u00b7schrei\u00b7ben", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$.", "$("], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Du sollst aber nun einen Preis zustellen", "tokens": ["Du", "sollst", "a\u00b7ber", "nun", "ei\u00b7nen", "Preis", "zu\u00b7stel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ART", "NN", "VVINF"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Und \u00fcber zwei Lieder ein Urtheil f\u00e4llen.", "tokens": ["Und", "\u00fc\u00b7ber", "zwei", "Lie\u00b7der", "ein", "Ur\u00b7theil", "f\u00e4l\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "CARD", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.26": {"line.1": {"text": "Da rief der erste: Vor allen Dingen", "tokens": ["Da", "rief", "der", "ers\u00b7te", ":", "Vor", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "$.", "APPR", "PIAT", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sollst du selber ein Lied erst singen,", "tokens": ["Sollst", "du", "sel\u00b7ber", "ein", "Lied", "erst", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Denn du siehst vor dir zwei Po\u00ebten,", "tokens": ["Denn", "du", "siehst", "vor", "dir", "zwei", "Po\u00ebten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPER", "CARD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn sie auch lieber pfeifen als fl\u00f6ten.", "tokens": ["Wenn", "sie", "auch", "lie\u00b7ber", "pfei\u00b7fen", "als", "fl\u00f6\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "KOKOM", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Wer \u00fcber Dichter will ein Richter sein,", "tokens": ["Wer", "\u00fc\u00b7ber", "Dich\u00b7ter", "will", "ein", "Rich\u00b7ter", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VMFIN", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der mu\u00df selber zuerst ein Dichter sein.", "tokens": ["Der", "mu\u00df", "sel\u00b7ber", "zu\u00b7erst", "ein", "Dich\u00b7ter", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.7": {"text": "Drum sprich zuvor und bekenn' es frei,", "tokens": ["Drum", "sprich", "zu\u00b7vor", "und", "be\u00b7kenn'", "es", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Wie h\u00e4ltst du's mit der Po\u00ebterei?", "tokens": ["Wie", "h\u00e4ltst", "du's", "mit", "der", "Po\u00ebte\u00b7rei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Hast du sie schon an den Nagel geh\u00e4ngt,", "tokens": ["Hast", "du", "sie", "schon", "an", "den", "Na\u00b7gel", "ge\u00b7h\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "APPR", "ART", "NE", "VVPP", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.10": {"text": "Sei dir auch dein Kritiker-Amt geschenkt.", "tokens": ["Sei", "dir", "auch", "dein", "Kri\u00b7ti\u00b7ker\u00b7Amt", "ge\u00b7schenkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Und darauf der dritte sprach:", "tokens": ["Und", "da\u00b7rauf", "der", "drit\u00b7te", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ART", "ADJA", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.27": {"line.1": {"text": "Die Po\u00ebsie,", "tokens": ["Die", "Po\u00eb\u00b7sie", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Was w\u00e4r' die Welt und das Leben ohne sie!", "tokens": ["Was", "w\u00e4r'", "die", "Welt", "und", "das", "Le\u00b7ben", "oh\u00b7ne", "sie", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "KON", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sie ist ein Kleinod in gro\u00dfer Noth,", "tokens": ["Sie", "ist", "ein", "Klei\u00b7nod", "in", "gro\u00b7\u00dfer", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gegen alle Krankheit, die uns bedroht,", "tokens": ["Ge\u00b7gen", "al\u00b7le", "Krank\u00b7heit", ",", "die", "uns", "be\u00b7droht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Ein Zaubermittel selbst gegen den Tod.", "tokens": ["Ein", "Zau\u00b7ber\u00b7mit\u00b7tel", "selbst", "ge\u00b7gen", "den", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wie ein Spiegel ist begl\u00fcckt,", "tokens": ["Wie", "ein", "Spie\u00b7gel", "ist", "be\u00b7gl\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Vor dem sich ein liebliches M\u00e4dchen schm\u00fcckt,", "tokens": ["Vor", "dem", "sich", "ein", "lieb\u00b7li\u00b7ches", "M\u00e4d\u00b7chen", "schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Wie unter Thr\u00e4nen eine Blume lacht,", "tokens": ["Wie", "un\u00b7ter", "Thr\u00e4\u00b7nen", "ei\u00b7ne", "Blu\u00b7me", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Wenn sie ein Sonnenstrahl thaufunkelnd macht,", "tokens": ["Wenn", "sie", "ein", "Son\u00b7nen\u00b7strahl", "thau\u00b7fun\u00b7kelnd", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "So hat dem S\u00e4nger ein Gott voll Mitleidsbeben", "tokens": ["So", "hat", "dem", "S\u00e4n\u00b7ger", "ein", "Gott", "voll", "Mit\u00b7leids\u00b7be\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "ADJD", "NN"], "meter": "-+-+--+--+--", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "F\u00fcr allen Jammer in seinem Leben", "tokens": ["F\u00fcr", "al\u00b7len", "Jam\u00b7mer", "in", "sei\u00b7nem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Dies Eine gegeben,", "tokens": ["Dies", "Ei\u00b7ne", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "ART", "VVPP", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.13": {"text": "Da\u00df er am Sch\u00f6nen satt sich sauge,", "tokens": ["Da\u00df", "er", "am", "Sch\u00f6\u00b7nen", "satt", "sich", "sau\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und alles, was k\u00f6stlich ist, siehet sein Auge,", "tokens": ["Und", "al\u00b7les", ",", "was", "k\u00f6st\u00b7lich", "ist", ",", "sie\u00b7het", "sein", "Au\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Davon sein Lied auch wiederklang.", "tokens": ["Da\u00b7von", "sein", "Lied", "auch", "wie\u00b7der\u00b7klang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "So ihr h\u00f6ret den Sang,", "tokens": ["So", "ihr", "h\u00f6\u00b7ret", "den", "Sang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.17": {"text": "Es bewegt euch die Seele tief und bang'", "tokens": ["Es", "be\u00b7wegt", "euch", "die", "See\u00b7le", "tief", "und", "bang'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ADJD", "KON", "NE"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.18": {"text": "Mit Wonn' und Weh, mit Lust und Leid,", "tokens": ["Mit", "Wonn'", "und", "Weh", ",", "mit", "Lust", "und", "Leid", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Und euer Herz wird weich wie zu der Zeit,", "tokens": ["Und", "eu\u00b7er", "Herz", "wird", "weich", "wie", "zu", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Da der Fr\u00fchling thauet,", "tokens": ["Da", "der", "Fr\u00fch\u00b7ling", "thau\u00b7et", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.21": {"text": "Und der Himmel blauet", "tokens": ["Und", "der", "Him\u00b7mel", "blau\u00b7et"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.22": {"text": "Und ihr die ersten Veilchen schauet.", "tokens": ["Und", "ihr", "die", "ers\u00b7ten", "Veil\u00b7chen", "schau\u00b7et", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Ihr wollt ein Lied, wohlan, es sei,", "tokens": ["Ihr", "wollt", "ein", "Lied", ",", "wo\u00b7hlan", ",", "es", "sei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "PWAV", "$,", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hab' nur eins, ich sing' es frei,", "tokens": ["Ich", "hab'", "nur", "eins", ",", "ich", "sing'", "es", "frei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird mir zu Sinn' nicht wohl dabei.", "tokens": ["Wird", "mir", "zu", "Sinn'", "nicht", "wohl", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "PTKNEG", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Es war einmal ein K\u00f6nigsnarr,", "tokens": ["Es", "war", "ein\u00b7mal", "ein", "K\u00f6\u00b7nigs\u00b7narr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der manches Jahr Hofnarre war", "tokens": ["Der", "man\u00b7ches", "Jahr", "Hof\u00b7nar\u00b7re", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bei einem K\u00f6nig wohlgemuth", "tokens": ["Bei", "ei\u00b7nem", "K\u00f6\u00b7nig", "wohl\u00b7ge\u00b7muth"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und reich an Land und fromm und gut.", "tokens": ["Und", "reich", "an", "Land", "und", "fromm", "und", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Der K\u00f6nig war dem Narren hold,", "tokens": ["Der", "K\u00f6\u00b7nig", "war", "dem", "Nar\u00b7ren", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hielt ihn in Ehr' und gutem Sold,", "tokens": ["Hielt", "ihn", "in", "Ehr'", "und", "gu\u00b7tem", "Sold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Daf\u00fcr der Narr ihm dankbar war", "tokens": ["Da\u00b7f\u00fcr", "der", "Narr", "ihm", "dank\u00b7bar", "war"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "PPER", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und zugethan just wie ein Narr.", "tokens": ["Und", "zu\u00b7ge\u00b7than", "just", "wie", "ein", "Narr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Nun traf sich's \u00fcber kurz und lang,", "tokens": ["Nun", "traf", "sich's", "\u00fc\u00b7ber", "kurz", "und", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der K\u00f6nig wurde fieberkrank,", "tokens": ["Der", "K\u00f6\u00b7nig", "wur\u00b7de", "fie\u00b7ber\u00b7krank", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und rings umher in weiter Rund'", "tokens": ["Und", "rings", "um\u00b7her", "in", "wei\u00b7ter", "Rund'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PTKVZ", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein Arzt dem Kranken helfen kunnt.", "tokens": ["Kein", "Arzt", "dem", "Kran\u00b7ken", "hel\u00b7fen", "kunnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Da ging bei Hof ein Trauern an,", "tokens": ["Da", "ging", "bei", "Hof", "ein", "Trau\u00b7ern", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es weinten Zof' und Edelmann.", "tokens": ["Es", "wein\u00b7ten", "Zof'", "und", "E\u00b7del\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Narr war kaum bei Sinnen mehr,", "tokens": ["Der", "Narr", "war", "kaum", "bei", "Sin\u00b7nen", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er h\u00e4rmte sich ohnma\u00dfen schwer.", "tokens": ["Er", "h\u00e4rm\u00b7te", "sich", "ohn\u00b7ma\u00b7\u00dfen", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Und sa\u00df und gr\u00fcbelt Tag und Nacht,", "tokens": ["Und", "sa\u00df", "und", "gr\u00fc\u00b7belt", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis er ein Mittel auserdacht,", "tokens": ["Bis", "er", "ein", "Mit\u00b7tel", "au\u00b7ser\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das ihm nach seinem Narrensinn", "tokens": ["Das", "ihm", "nach", "sei\u00b7nem", "Nar\u00b7ren\u00b7sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr seinen Herren heilsam schien.", "tokens": ["F\u00fcr", "sei\u00b7nen", "Her\u00b7ren", "heil\u00b7sam", "schien", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Im Garten bei des K\u00f6nigs Schlo\u00df", "tokens": ["Im", "Gar\u00b7ten", "bei", "des", "K\u00f6\u00b7nigs", "Schlo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da war ein Teich, darinnen flo\u00df", "tokens": ["Da", "war", "ein", "Teich", ",", "da\u00b7rin\u00b7nen", "flo\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum Wehre niederw\u00e4rts ein Bach,", "tokens": ["Zum", "Weh\u00b7re", "nie\u00b7der\u00b7w\u00e4rts", "ein", "Bach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dort war der Kranke jeden Tag.", "tokens": ["Dort", "war", "der", "Kran\u00b7ke", "je\u00b7den", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Der Narre bla\u00df, der K\u00f6nig bleich,", "tokens": ["Der", "Nar\u00b7re", "bla\u00df", ",", "der", "K\u00f6\u00b7nig", "bleich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie standen an dem Gartenteich,", "tokens": ["Sie", "stan\u00b7den", "an", "dem", "Gar\u00b7ten\u00b7teich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Sto\u00df da von des Narren Hand,", "tokens": ["Ein", "Sto\u00df", "da", "von", "des", "Nar\u00b7ren", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der K\u00f6nig taumelt \u00fcber'n Rand.", "tokens": ["Der", "K\u00f6\u00b7nig", "tau\u00b7melt", "\u00fc\u00b7ber'n", "Rand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Es fiel der K\u00f6nig in das Wehr,", "tokens": ["Es", "fiel", "der", "K\u00f6\u00b7nig", "in", "das", "Wehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Plump! \u2013 sprang der Narre hinterher.", "tokens": ["Plump", "!", "\u2013", "sprang", "der", "Nar\u00b7re", "hin\u00b7ter\u00b7her", "."], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "$(", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der K\u00f6nig fiel, der Narre sprang,", "tokens": ["Der", "K\u00f6\u00b7nig", "fiel", ",", "der", "Nar\u00b7re", "sprang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Beiden keiner untersank.", "tokens": ["Von", "Bei\u00b7den", "kei\u00b7ner", "un\u00b7ter\u00b7sank", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Sie kamen gl\u00fccklich wieder ba\u00df", "tokens": ["Sie", "ka\u00b7men", "gl\u00fcck\u00b7lich", "wie\u00b7der", "ba\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und waren alle Beide \u2013 na\u00df;", "tokens": ["Und", "wa\u00b7ren", "al\u00b7le", "Bei\u00b7de", "\u2013", "na\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "PIS", "$(", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch durch den Schreck der K\u00f6nig war", "tokens": ["Doch", "durch", "den", "Schreck", "der", "K\u00f6\u00b7nig", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Stund gesund. Es jauchzt der Narr.", "tokens": ["Von", "Stund", "ge\u00b7sund", ".", "Es", "jauchzt", "der", "Narr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$.", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Da kam der Narr, der arme Wicht,", "tokens": ["Da", "kam", "der", "Narr", ",", "der", "ar\u00b7me", "Wicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob Hochverraths vors Hofgericht,", "tokens": ["Ob", "Hoch\u00b7ver\u00b7raths", "vors", "Hof\u00b7ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und billig ward ihm zuerkannt", "tokens": ["Und", "bil\u00b7lig", "ward", "ihm", "zu\u00b7er\u00b7kannt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Tod durchs Schwert von Henkershand.", "tokens": ["Der", "Tod", "durchs", "Schwert", "von", "Hen\u00b7ker\u00b7shand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Der Spruch geschah, das Urtheil blieb,", "tokens": ["Der", "Spruch", "ge\u00b7schah", ",", "das", "Ur\u00b7theil", "blieb", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der gute K\u00f6nig unterschrieb.", "tokens": ["Der", "gu\u00b7te", "K\u00f6\u00b7nig", "un\u00b7ter\u00b7schrieb", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum Henker sendet er darnach,", "tokens": ["Zum", "Hen\u00b7ker", "sen\u00b7det", "er", "dar\u00b7nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Henker kam, der K\u00f6nig sprach:", "tokens": ["Der", "Hen\u00b7ker", "kam", ",", "der", "K\u00f6\u00b7nig", "sprach", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Ich will dem Narren gn\u00e4dig sein.", "tokens": ["Ich", "will", "dem", "Nar\u00b7ren", "gn\u00e4\u00b7dig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du sollst dein Amt nur thun zum Schein;", "tokens": ["Du", "sollst", "dein", "Amt", "nur", "thun", "zum", "Schein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "ADV", "VVINF", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jedoch der Narre bis zum Schlu\u00df", "tokens": ["Je\u00b7doch", "der", "Nar\u00b7re", "bis", "zum", "Schlu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Soll glauben, da\u00df er sterben mu\u00df.", "tokens": ["Soll", "glau\u00b7ben", ",", "da\u00df", "er", "ster\u00b7ben", "mu\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Drum h\u00fcte dich, da\u00df Niemand wei\u00df,", "tokens": ["Drum", "h\u00fc\u00b7te", "dich", ",", "da\u00df", "Nie\u00b7mand", "wei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was du sollst thun auf mein Gehei\u00df,", "tokens": ["Was", "du", "sollst", "thun", "auf", "mein", "Ge\u00b7hei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VMFIN", "VVINF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Sonst trifft das Urtheil dich und ihn.", "tokens": ["Sonst", "trifft", "das", "Ur\u00b7theil", "dich", "und", "ihn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Henker ging. Der Tag erschien.", "tokens": ["Der", "Hen\u00b7ker", "ging", ".", "Der", "Tag", "er\u00b7schien", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Ringsum ein gro\u00df Gefolge sa\u00df.", "tokens": ["Ring\u00b7sum", "ein", "gro\u00df", "Ge\u00b7fol\u00b7ge", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Der K\u00f6nig freut sich auf den Spa\u00df.", "tokens": ["Der", "K\u00f6\u00b7nig", "freut", "sich", "auf", "den", "Spa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Narr wird auf's Schaffot gef\u00fchrt,", "tokens": ["Der", "Narr", "wird", "auf's", "Schaf\u00b7fot", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Sein starrer Blick zum K\u00f6nig stiert.", "tokens": ["Sein", "star\u00b7rer", "Blick", "zum", "K\u00f6\u00b7nig", "stiert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Der Henker ihm die Augen band", "tokens": ["Der", "Hen\u00b7ker", "ihm", "die", "Au\u00b7gen", "band"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und \u2013 statt des Schwerts aus dem Gewand", "tokens": ["Und", "\u2013", "statt", "des", "Schwerts", "aus", "dem", "Ge\u00b7wand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er eine Weidenruthe zog,", "tokens": ["Er", "ei\u00b7ne", "Wei\u00b7den\u00b7ru\u00b7the", "zog", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Henker h\u00e4lt die Ruthe hoch.", "tokens": ["Der", "Hen\u00b7ker", "h\u00e4lt", "die", "Ru\u00b7the", "hoch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Wie die des Narren K\u00f6rper strich,", "tokens": ["Wie", "die", "des", "Nar\u00b7ren", "K\u00f6r\u00b7per", "strich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ART", "NN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der zuckt zusammen f\u00fcrchterlich.", "tokens": ["Der", "zuckt", "zu\u00b7sam\u00b7men", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als man ihm nun die Gnade bot,", "tokens": ["Als", "man", "ihm", "nun", "die", "Gna\u00b7de", "bot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der dumme K\u00f6nigsnarr \u2013 war todt.", "tokens": ["Der", "dum\u00b7me", "K\u00f6\u00b7nigs\u00b7narr", "\u2013", "war", "todt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Der erste sprach: Wahrlich, das war", "tokens": ["Der", "ers\u00b7te", "sprach", ":", "Wahr\u00b7lich", ",", "das", "war"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "$.", "ADV", "$,", "PDS", "VAFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Treu bis zum Tod \u2013 ein K\u00f6nigsnarr!", "tokens": ["Treu", "bis", "zum", "Tod", "\u2013", "ein", "K\u00f6\u00b7nigs\u00b7narr", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "APPRART", "NN", "$(", "ART", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Doch wer soll nun als Richter entscheiden,", "tokens": ["Doch", "wer", "soll", "nun", "als", "Rich\u00b7ter", "ent\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "ADV", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wer das bessere Lied sang von uns beiden?", "tokens": ["Wer", "das", "bes\u00b7se\u00b7re", "Lied", "sang", "von", "uns", "bei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN", "APPR", "PPER", "PIAT", "$."], "meter": "--+--++--+-", "measure": "anapaest.di.plus"}}, "stanza.46": {"line.1": {"text": "Da rief der zweite: alle guten Geister!", "tokens": ["Da", "rief", "der", "zwei\u00b7te", ":", "al\u00b7le", "gu\u00b7ten", "Geis\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "$.", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dort kommt von den Sch\u00fclern der Meister.", "tokens": ["Dort", "kommt", "von", "den", "Sch\u00fc\u00b7lern", "der", "Meis\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Das ist ein Richter, ein kleiner, doch feiner.", "tokens": ["Das", "ist", "ein", "Rich\u00b7ter", ",", "ein", "klei\u00b7ner", ",", "doch", "fei\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "ART", "ADJA", "$,", "ADV", "ADJD", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sieh dich um, da kommt einer,", "tokens": ["Sieh", "dich", "um", ",", "da", "kommt", "ei\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKVZ", "$,", "ADV", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dem der Himmel einen Blick verlieh", "tokens": ["Dem", "der", "Him\u00b7mel", "ei\u00b7nen", "Blick", "ver\u00b7lieh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Voll fr\u00f6hlicher Melancholie.", "tokens": ["Voll", "fr\u00f6h\u00b7li\u00b7cher", "Me\u00b7lan\u00b7cho\u00b7lie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Es trat aber ein dritter Gesell in das Zimmer,", "tokens": ["Es", "trat", "a\u00b7ber", "ein", "drit\u00b7ter", "Ge\u00b7sell", "in", "das", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+---+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "De\u00df Antlitz strahlt in bleichem Schimmer.", "tokens": ["De\u00df", "Ant\u00b7litz", "strahlt", "in", "blei\u00b7chem", "Schim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Und also der erste zum zweiten spricht:", "tokens": ["Und", "al\u00b7so", "der", "ers\u00b7te", "zum", "zwei\u00b7ten", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "APPRART", "ADJA", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Nein, das verstehst du nicht.", "tokens": ["Nein", ",", "das", "ver\u00b7stehst", "du", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sieh doch nur sein Gesicht an,", "tokens": ["Sieh", "doch", "nur", "sein", "Ge\u00b7sicht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Siehst du es ihm denn nicht an?", "tokens": ["Siehst", "du", "es", "ihm", "denn", "nicht", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PPER", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Er ist ganz verz\u00fcckt", "tokens": ["Er", "ist", "ganz", "ver\u00b7z\u00fcckt"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "VVPP"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Und uns entr\u00fcckt", "tokens": ["Und", "uns", "ent\u00b7r\u00fcckt"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Und schaut in die Seligkeiten alle.", "tokens": ["Und", "schaut", "in", "die", "Se\u00b7lig\u00b7kei\u00b7ten", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PIAT", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Noch aber sah ich keinen, der blickt ins Sonnenlicht", "tokens": ["Noch", "a\u00b7ber", "sah", "ich", "kei\u00b7nen", ",", "der", "blickt", "ins", "Son\u00b7nen\u00b7licht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PIAT", "$,", "PRELS", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Und machte dazu ein gescheutes Gesicht.", "tokens": ["Und", "mach\u00b7te", "da\u00b7zu", "ein", "ge\u00b7scheu\u00b7tes", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.49": {"line.1": {"text": "Und lachend erwidert der zweite: F\u00fcrwahr,", "tokens": ["Und", "la\u00b7chend", "er\u00b7wi\u00b7dert", "der", "zwei\u00b7te", ":", "F\u00fcr\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "ADJA", "$.", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Du machst deine Sache wunderbar.", "tokens": ["Du", "machst", "dei\u00b7ne", "Sa\u00b7che", "wun\u00b7der\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wo du streichelst, packst du zu,", "tokens": ["Wo", "du", "strei\u00b7chelst", ",", "packst", "du", "zu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo du schmeichelst, bei\u00dfest du.", "tokens": ["Wo", "du", "schmei\u00b7chelst", ",", "bei\u00b7\u00dfest", "du", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "Darnach", "tokens": ["Dar\u00b7nach"], "token_info": ["word"], "pos": ["PAV"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Zum dritten gewendet Jener sprach:", "tokens": ["Zum", "drit\u00b7ten", "ge\u00b7wen\u00b7det", "Je\u00b7ner", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVPP", "PDAT", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Hab' ich dich gebissen, o Freund, gewi\u00df", "tokens": ["Hab'", "ich", "dich", "ge\u00b7bis\u00b7sen", ",", "o", "Freund", ",", "ge\u00b7wi\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "PPER", "PRF", "VVPP", "$,", "FM", "NN", "$,", "ADV"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "So war es nur ein kleiner Bi\u00df,", "tokens": ["So", "war", "es", "nur", "ein", "klei\u00b7ner", "Bi\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und \u00fcber ein bischen wirst du schmollen?", "tokens": ["Und", "\u00fc\u00b7ber", "ein", "bi\u00b7schen", "wirst", "du", "schmol\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADV", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Bewahre der Himmel, das darfst du nicht wollen.", "tokens": ["Be\u00b7wah\u00b7re", "der", "Him\u00b7mel", ",", "das", "darfst", "du", "nicht", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PDS", "VMFIN", "PPER", "PTKNEG", "VMFIN", "$."], "meter": "-+--+--++-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Du bist ja ein Genie,", "tokens": ["Du", "bist", "ja", "ein", "Ge\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Und so etwas thut ein Genie", "tokens": ["Und", "so", "et\u00b7was", "thut", "ein", "Ge\u00b7nie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PIS", "VVFIN", "ART", "NN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Nie.", "tokens": ["Nie", "."], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "+", "measure": "single.up"}, "line.10": {"text": "Nun will ich dir aber ein Liedlein singen,", "tokens": ["Nun", "will", "ich", "dir", "a\u00b7ber", "ein", "Lied\u00b7lein", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Das wird deinen Ohren besser klingen;", "tokens": ["Das", "wird", "dei\u00b7nen", "Oh\u00b7ren", "bes\u00b7ser", "klin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.12": {"text": "Denn ich glaub', du klagst noch \u00fcber Wunden,", "tokens": ["Denn", "ich", "glaub'", ",", "du", "klagst", "noch", "\u00fc\u00b7ber", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.13": {"text": "Die ich schon l\u00e4ngst hab' \u00fcberwunden.", "tokens": ["Die", "ich", "schon", "l\u00e4ngst", "hab'", "\u00fc\u00b7berw\u00b7un\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Horch:", "tokens": ["Horch", ":"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.51": {"line.1": {"text": "Und ob dir auch bei jedem Schritt", "tokens": ["Und", "ob", "dir", "auch", "bei", "je\u00b7dem", "Schritt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Kleinheit der Menschen entgegentritt,", "tokens": ["Die", "Klein\u00b7heit", "der", "Men\u00b7schen", "ent\u00b7ge\u00b7gen\u00b7tritt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und die abgestumpften Philisterseelen", "tokens": ["Und", "die", "ab\u00b7ge\u00b7stumpf\u00b7ten", "Phi\u00b7lis\u00b7ter\u00b7see\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Dein sch\u00f6nheitfrohes Gem\u00fcth zerqu\u00e4len,", "tokens": ["Dein", "sch\u00f6n\u00b7heit\u00b7fro\u00b7hes", "Ge\u00b7m\u00fcth", "zer\u00b7qu\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "O lach' sie aus,", "tokens": ["O", "lach'", "sie", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Mit blutendem Herzen lach' sie aus.", "tokens": ["Mit", "blu\u00b7ten\u00b7dem", "Her\u00b7zen", "lach'", "sie", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Glaub' mir, sie sind es nimmer werth,", "tokens": ["Glaub'", "mir", ",", "sie", "sind", "es", "nim\u00b7mer", "werth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df Gram darob dein Herz beschwert.", "tokens": ["Da\u00df", "Gram", "da\u00b7rob", "dein", "Herz", "be\u00b7schwert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PAV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Blick auf die Herde nur im Gefild,", "tokens": ["Blick", "auf", "die", "Her\u00b7de", "nur", "im", "Ge\u00b7fild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Da findest du ganz ihr Ebenbild;", "tokens": ["Da", "fin\u00b7dest", "du", "ganz", "ihr", "E\u00b7ben\u00b7bild", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Denn die Philister, die sind wie", "tokens": ["Denn", "die", "Phi\u00b7lis\u00b7ter", ",", "die", "sind", "wie"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "VAFIN", "KOKOM"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Auf der Weide das Rindvieh.", "tokens": ["Auf", "der", "Wei\u00b7de", "das", "Rind\u00b7vieh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.13": {"text": "Grasen", "tokens": ["Gra\u00b7sen"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.14": {"text": "Ruhig weiter ab den Rasen,", "tokens": ["Ru\u00b7hig", "wei\u00b7ter", "ab", "den", "Ra\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Treffen sie eine Blume dann,", "tokens": ["Tref\u00b7fen", "sie", "ei\u00b7ne", "Blu\u00b7me", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Glotzen sie sie verwundert an,", "tokens": ["Glot\u00b7zen", "sie", "sie", "ver\u00b7wun\u00b7dert", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.17": {"text": "Brummen,", "tokens": ["Brum\u00b7men", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.18": {"text": "Da\u00df man sie nicht fressen kann.", "tokens": ["Da\u00df", "man", "sie", "nicht", "fres\u00b7sen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "Und der dritte darauf begann", "tokens": ["Und", "der", "drit\u00b7te", "da\u00b7rauf", "be\u00b7gann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "PAV", "VVFIN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.20": {"text": "Mit einer Stimme, deren Klang", "tokens": ["Mit", "ei\u00b7ner", "Stim\u00b7me", ",", "de\u00b7ren", "Klang"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Seltsam den H\u00f6rern zu Herzen drang:", "tokens": ["Selt\u00b7sam", "den", "H\u00f6\u00b7rern", "zu", "Her\u00b7zen", "drang", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.52": {"line.1": {"text": "Wer in der Kindheit gl\u00fccklich war,", "tokens": ["Wer", "in", "der", "Kind\u00b7heit", "gl\u00fcck\u00b7lich", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ist gesegnet f\u00fcr immerdar.", "tokens": ["Der", "ist", "ge\u00b7seg\u00b7net", "f\u00fcr", "im\u00b7mer\u00b7dar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "APPR", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er kann und wird nicht sterben an Wunden,", "tokens": ["Er", "kann", "und", "wird", "nicht", "ster\u00b7ben", "an", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KON", "VAFIN", "PTKNEG", "VVINF", "APPR", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Er will und wird immer wieder gesunden,", "tokens": ["Er", "will", "und", "wird", "im\u00b7mer", "wie\u00b7der", "ge\u00b7sun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KON", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Er ist gewappnet und bleibet so", "tokens": ["Er", "ist", "ge\u00b7wapp\u00b7net", "und", "blei\u00b7bet", "so"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "VVFIN", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "In allem Elend wunderfroh.", "tokens": ["In", "al\u00b7lem", "E\u00b7lend", "wun\u00b7der\u00b7froh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Ein sch\u00f6nes Recept, der zweite sprach,", "tokens": ["Ein", "sch\u00f6\u00b7nes", "Re\u00b7cept", ",", "der", "zwei\u00b7te", "sprach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nur Schad' ist und wird es ewig bleiben,", "tokens": ["Nur", "Schad'", "ist", "und", "wird", "es", "e\u00b7wig", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "KON", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Kein Erwachsener kann es sich mehr verschreiben. \u2013", "tokens": ["Kein", "Er\u00b7wach\u00b7se\u00b7ner", "kann", "es", "sich", "mehr", "ver\u00b7schrei\u00b7ben", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$.", "$("], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Du sollst aber nun einen Preis zustellen", "tokens": ["Du", "sollst", "a\u00b7ber", "nun", "ei\u00b7nen", "Preis", "zu\u00b7stel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ART", "NN", "VVINF"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Und \u00fcber zwei Lieder ein Urtheil f\u00e4llen.", "tokens": ["Und", "\u00fc\u00b7ber", "zwei", "Lie\u00b7der", "ein", "Ur\u00b7theil", "f\u00e4l\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "CARD", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.54": {"line.1": {"text": "Da rief der erste: Vor allen Dingen", "tokens": ["Da", "rief", "der", "ers\u00b7te", ":", "Vor", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "$.", "APPR", "PIAT", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sollst du selber ein Lied erst singen,", "tokens": ["Sollst", "du", "sel\u00b7ber", "ein", "Lied", "erst", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Denn du siehst vor dir zwei Po\u00ebten,", "tokens": ["Denn", "du", "siehst", "vor", "dir", "zwei", "Po\u00ebten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPER", "CARD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn sie auch lieber pfeifen als fl\u00f6ten.", "tokens": ["Wenn", "sie", "auch", "lie\u00b7ber", "pfei\u00b7fen", "als", "fl\u00f6\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "KOKOM", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Wer \u00fcber Dichter will ein Richter sein,", "tokens": ["Wer", "\u00fc\u00b7ber", "Dich\u00b7ter", "will", "ein", "Rich\u00b7ter", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VMFIN", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der mu\u00df selber zuerst ein Dichter sein.", "tokens": ["Der", "mu\u00df", "sel\u00b7ber", "zu\u00b7erst", "ein", "Dich\u00b7ter", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.7": {"text": "Drum sprich zuvor und bekenn' es frei,", "tokens": ["Drum", "sprich", "zu\u00b7vor", "und", "be\u00b7kenn'", "es", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Wie h\u00e4ltst du's mit der Po\u00ebterei?", "tokens": ["Wie", "h\u00e4ltst", "du's", "mit", "der", "Po\u00ebte\u00b7rei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Hast du sie schon an den Nagel geh\u00e4ngt,", "tokens": ["Hast", "du", "sie", "schon", "an", "den", "Na\u00b7gel", "ge\u00b7h\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "APPR", "ART", "NE", "VVPP", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.10": {"text": "Sei dir auch dein Kritiker-Amt geschenkt.", "tokens": ["Sei", "dir", "auch", "dein", "Kri\u00b7ti\u00b7ker\u00b7Amt", "ge\u00b7schenkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Und darauf der dritte sprach:", "tokens": ["Und", "da\u00b7rauf", "der", "drit\u00b7te", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ART", "ADJA", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.55": {"line.1": {"text": "Die Po\u00ebsie,", "tokens": ["Die", "Po\u00eb\u00b7sie", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Was w\u00e4r' die Welt und das Leben ohne sie!", "tokens": ["Was", "w\u00e4r'", "die", "Welt", "und", "das", "Le\u00b7ben", "oh\u00b7ne", "sie", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "KON", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sie ist ein Kleinod in gro\u00dfer Noth,", "tokens": ["Sie", "ist", "ein", "Klei\u00b7nod", "in", "gro\u00b7\u00dfer", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gegen alle Krankheit, die uns bedroht,", "tokens": ["Ge\u00b7gen", "al\u00b7le", "Krank\u00b7heit", ",", "die", "uns", "be\u00b7droht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Ein Zaubermittel selbst gegen den Tod.", "tokens": ["Ein", "Zau\u00b7ber\u00b7mit\u00b7tel", "selbst", "ge\u00b7gen", "den", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wie ein Spiegel ist begl\u00fcckt,", "tokens": ["Wie", "ein", "Spie\u00b7gel", "ist", "be\u00b7gl\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Vor dem sich ein liebliches M\u00e4dchen schm\u00fcckt,", "tokens": ["Vor", "dem", "sich", "ein", "lieb\u00b7li\u00b7ches", "M\u00e4d\u00b7chen", "schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Wie unter Thr\u00e4nen eine Blume lacht,", "tokens": ["Wie", "un\u00b7ter", "Thr\u00e4\u00b7nen", "ei\u00b7ne", "Blu\u00b7me", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Wenn sie ein Sonnenstrahl thaufunkelnd macht,", "tokens": ["Wenn", "sie", "ein", "Son\u00b7nen\u00b7strahl", "thau\u00b7fun\u00b7kelnd", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "So hat dem S\u00e4nger ein Gott voll Mitleidsbeben", "tokens": ["So", "hat", "dem", "S\u00e4n\u00b7ger", "ein", "Gott", "voll", "Mit\u00b7leids\u00b7be\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "ADJD", "NN"], "meter": "-+-+--+--+--", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "F\u00fcr allen Jammer in seinem Leben", "tokens": ["F\u00fcr", "al\u00b7len", "Jam\u00b7mer", "in", "sei\u00b7nem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Dies Eine gegeben,", "tokens": ["Dies", "Ei\u00b7ne", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "ART", "VVPP", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.13": {"text": "Da\u00df er am Sch\u00f6nen satt sich sauge,", "tokens": ["Da\u00df", "er", "am", "Sch\u00f6\u00b7nen", "satt", "sich", "sau\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und alles, was k\u00f6stlich ist, siehet sein Auge,", "tokens": ["Und", "al\u00b7les", ",", "was", "k\u00f6st\u00b7lich", "ist", ",", "sie\u00b7het", "sein", "Au\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Davon sein Lied auch wiederklang.", "tokens": ["Da\u00b7von", "sein", "Lied", "auch", "wie\u00b7der\u00b7klang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "So ihr h\u00f6ret den Sang,", "tokens": ["So", "ihr", "h\u00f6\u00b7ret", "den", "Sang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.17": {"text": "Es bewegt euch die Seele tief und bang'", "tokens": ["Es", "be\u00b7wegt", "euch", "die", "See\u00b7le", "tief", "und", "bang'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ADJD", "KON", "NE"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.18": {"text": "Mit Wonn' und Weh, mit Lust und Leid,", "tokens": ["Mit", "Wonn'", "und", "Weh", ",", "mit", "Lust", "und", "Leid", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Und euer Herz wird weich wie zu der Zeit,", "tokens": ["Und", "eu\u00b7er", "Herz", "wird", "weich", "wie", "zu", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Da der Fr\u00fchling thauet,", "tokens": ["Da", "der", "Fr\u00fch\u00b7ling", "thau\u00b7et", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.21": {"text": "Und der Himmel blauet", "tokens": ["Und", "der", "Him\u00b7mel", "blau\u00b7et"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.22": {"text": "Und ihr die ersten Veilchen schauet.", "tokens": ["Und", "ihr", "die", "ers\u00b7ten", "Veil\u00b7chen", "schau\u00b7et", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Ihr wollt ein Lied, wohlan, es sei,", "tokens": ["Ihr", "wollt", "ein", "Lied", ",", "wo\u00b7hlan", ",", "es", "sei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "PWAV", "$,", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hab' nur eins, ich sing' es frei,", "tokens": ["Ich", "hab'", "nur", "eins", ",", "ich", "sing'", "es", "frei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird mir zu Sinn' nicht wohl dabei.", "tokens": ["Wird", "mir", "zu", "Sinn'", "nicht", "wohl", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "PTKNEG", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}