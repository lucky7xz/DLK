{"dta.poem.10754": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "De\u00df Ehrwerbenden Teutschen jungen  \n Adels.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Wir kommen nicht hieher/ vns selbsten vil zur\u00fchmen/", "tokens": ["Wir", "kom\u00b7men", "nicht", "hie\u00b7her", "/", "vns", "selbs\u00b7ten", "vil", "zu\u00b7r\u00fch\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PAV", "$(", "PPER", "VVFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Oder durch frembde Sprach die Warheit zuverbl\u00fcmen/", "tokens": ["O\u00b7der", "durch", "fremb\u00b7de", "Sprach", "die", "War\u00b7heit", "zu\u00b7ver\u00b7bl\u00fc\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als ob wir kemen jetzt au\u00df einem end der Welt/", "tokens": ["Als", "ob", "wir", "ke\u00b7men", "jetzt", "au\u00df", "ei\u00b7nem", "end", "der", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Oder wider-belebt vom Elisischen Feld.", "tokens": ["O\u00b7der", "wi\u00b7der\u00b7be\u00b7lebt", "vom", "E\u00b7li\u00b7si\u00b7schen", "Feld", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Nein. Teufel sind wir nicht/ noch Riesen/ noch Halb-G\u00f6tter/", "tokens": ["Nein", ".", "Teu\u00b7fel", "sind", "wir", "nicht", "/", "noch", "Rie\u00b7sen", "/", "noch", "Halb\u00b7G\u00f6t\u00b7ter", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$.", "NN", "VAFIN", "PPER", "PTKNEG", "$(", "ADV", "NN", "$(", "ADV", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Noch Helden/ noch Wildleut/ noch vnsers Lands versp\u00f6tter/", "tokens": ["Noch", "Hel\u00b7den", "/", "noch", "Wild\u00b7leut", "/", "noch", "vn\u00b7sers", "Lands", "ver\u00b7sp\u00f6t\u00b7ter", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$(", "ADV", "NE", "$(", "ADV", "ADJA", "NN", "ADJD", "$("], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Das Teutsche Reich bekant ist vnser Vatterlandt/", "tokens": ["Das", "Teut\u00b7sche", "Reich", "be\u00b7kant", "ist", "vn\u00b7ser", "Vat\u00b7ter\u00b7landt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Teutsch sein wir von Geburt/ von Stammen/ hertz vnd hand.", "tokens": ["Teutsch", "sein", "wir", "von", "Ge\u00b7burt", "/", "von", "Stam\u00b7men", "/", "hertz", "vnd", "hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "PPER", "APPR", "NN", "$(", "APPR", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was dient es/ frembden Prei\u00df vnd Namen zu entlehnen/", "tokens": ["Was", "dient", "es", "/", "fremb\u00b7den", "Prei\u00df", "vnd", "Na\u00b7men", "zu", "ent\u00b7leh\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$(", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Teutschland bedarff sich nit mit au\u00dfl\u00e4nder besch\u00f6nen/", "tokens": ["Teutschland", "be\u00b7darff", "sich", "nit", "mit", "au\u00df\u00b7l\u00e4n\u00b7der", "be\u00b7sch\u00f6\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "PTKNEG", "APPR", "NN", "VVINF", "$("], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Wie dann die Welt wohl wei\u00df/ da\u00df es zu aller Zeit", "tokens": ["Wie", "dann", "die", "Welt", "wohl", "wei\u00df", "/", "da\u00df", "es", "zu", "al\u00b7ler", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "VVFIN", "$(", "KOUS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Treffliche Leut genug hatte zum Fried vnd Streit.", "tokens": ["Treff\u00b7li\u00b7che", "Leut", "ge\u00b7nug", "hat\u00b7te", "zum", "Fried", "vnd", "Streit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "VAFIN", "APPRART", "NN", "KON", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.13": {"text": "Darumb/ ob wir wohl jung/ nit sonders vil erfahren/", "tokens": ["Da\u00b7rumb", "/", "ob", "wir", "wohl", "jung", "/", "nit", "son\u00b7ders", "vil", "er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$(", "KOUS", "PPER", "ADV", "ADJD", "$(", "PTKNEG", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Begeren wir doch nit vnsere F\u00e4ust zusparen/", "tokens": ["Be\u00b7ge\u00b7ren", "wir", "doch", "nit", "vn\u00b7se\u00b7re", "F\u00e4ust", "zu\u00b7spa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Sondern erscheinen nur in vnser teutschen tracht/", "tokens": ["Son\u00b7dern", "er\u00b7schei\u00b7nen", "nur", "in", "vn\u00b7ser", "teut\u00b7schen", "tracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.16": {"text": "Mit Teutschredlichem Muth/ vmb vnfer erste macht", "tokens": ["Mit", "Teut\u00b7schred\u00b7li\u00b7chem", "Muth", "/", "vmb", "vn\u00b7fer", "ers\u00b7te", "macht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$(", "APPR", "ADJA", "ADJA", "VVFIN"], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "An disen Rittern hier (die so hoch Triumphieren)", "tokens": ["An", "di\u00b7sen", "Rit\u00b7tern", "hier", "(", "die", "so", "hoch", "Tri\u00b7um\u00b7phie\u00b7ren", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "$(", "ART", "ADV", "ADJD", "NN", "$("], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.18": {"text": "Ihrer begird geme\u00df/ gewaffnet zu probieren/", "tokens": ["Ih\u00b7rer", "be\u00b7gird", "ge\u00b7me\u00df", "/", "ge\u00b7waff\u00b7net", "zu", "pro\u00b7bie\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "VVPP", "PTKZU", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.19": {"text": "Verhoffend zweiffels frey/ da\u00df diese erste Prob", "tokens": ["Ver\u00b7hof\u00b7fend", "zweif\u00b7fels", "frey", "/", "da\u00df", "die\u00b7se", "ers\u00b7te", "Prob"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "NN", "ADJD", "$(", "KOUS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Vollendendt jhren Ruhm/ anfangen soll das Lob/", "tokens": ["Voll\u00b7en\u00b7dendt", "jhren", "Ruhm", "/", "an\u00b7fan\u00b7gen", "soll", "das", "Lob", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "VVINF", "VMFIN", "ART", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.21": {"text": "So man von nuhn an wird durch die straich vnserw\u00f6ren", "tokens": ["So", "man", "von", "nuhn", "an", "wird", "durch", "die", "straich", "vn\u00b7ser\u00b7w\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "APPR", "ADV", "APPR", "VAFIN", "APPR", "ART", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Vnder dem Firmament t\u00e4glich erschallen h\u00f6ren.", "tokens": ["Vn\u00b7der", "dem", "Fir\u00b7ma\u00b7ment", "t\u00e4g\u00b7lich", "er\u00b7schal\u00b7len", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVINF", "VVINF", "$."], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}}}}}