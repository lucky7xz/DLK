{"dta.poem.222": {"metadata": {"author": {"name": "Gressel, Johann Georg", "birth": "N.A.", "death": "N.A."}, "title": "Er liebet nicht mehr.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1716", "urn": "urn:nbn:de:kobv:b4-200905199041", "language": ["de:0.99"], "booktitle": "Celander [i. e. Gressel, Johann Georg]: Verliebte-Galante/ Sinn-Vermischte und Grab-Gedichte. Hamburg u. a., 1716."}, "poem": {"stanza.1": {"line.1": {"text": "Von den Banden/ von den Ketten", "tokens": ["Von", "den", "Ban\u00b7den", "/", "von", "den", "Ket\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$(", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist mein Hertze nun befreyt/", "tokens": ["Ist", "mein", "Hert\u00b7ze", "nun", "be\u00b7freyt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "VVFIN", "ADV", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Davon in so langer Zeit", "tokens": ["Da\u00b7von", "in", "so", "lan\u00b7ger", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "APPR", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Es sonst kunte nichts erretten:", "tokens": ["Es", "sonst", "kun\u00b7te", "nichts", "er\u00b7ret\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "O h\u00f6chst begl\u00fcckter Tag! o angenehme Stunden!", "tokens": ["O", "h\u00f6chst", "be\u00b7gl\u00fcck\u00b7ter", "Tag", "!", "o", "an\u00b7ge\u00b7neh\u00b7me", "Stun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJA", "NN", "$.", "FM", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Darinnen ich mein Gl\u00fcck und Freyheit wiederfunden.", "tokens": ["Da\u00b7rin\u00b7nen", "ich", "mein", "Gl\u00fcck", "und", "Frey\u00b7heit", "wie\u00b7der\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Lachet ihr befreyten Sinnen/", "tokens": ["La\u00b7chet", "ihr", "be\u00b7frey\u00b7ten", "Sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und du sonst beklemmte Brust", "tokens": ["Und", "du", "sonst", "be\u00b7klemm\u00b7te", "Brust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sch\u00f6pff\u2019 aus deiner Freyheit Lust/", "tokens": ["Sch\u00f6pf\u00b7f'", "aus", "dei\u00b7ner", "Frey\u00b7heit", "Lust", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die eur th\u00f6rigtes Beginnen", "tokens": ["Die", "eur", "th\u00f6\u00b7rig\u00b7tes", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vor einem Blick vergab von ungetreuen Augen/", "tokens": ["Vor", "ei\u00b7nem", "Blick", "ver\u00b7gab", "von", "un\u00b7ge\u00b7treu\u00b7en", "Au\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die euch zu nichtes sonst als einer Folter taugen.", "tokens": ["Die", "euch", "zu", "nich\u00b7tes", "sonst", "als", "ei\u00b7ner", "Fol\u00b7ter", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PIS", "ADV", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Schaut doch an die holden Blicke/", "tokens": ["Schaut", "doch", "an", "die", "hol\u00b7den", "Bli\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So euch jetzt das Schicksahl giebt/", "tokens": ["So", "euch", "jetzt", "das", "Schick\u00b7sahl", "giebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Und wie euch so hertzlich liebt", "tokens": ["Und", "wie", "euch", "so", "hertz\u00b7lich", "liebt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADJD", "VVFIN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Ein gew\u00fcnschetes Gel\u00fccke/", "tokens": ["Ein", "ge\u00b7w\u00fcn\u00b7sche\u00b7tes", "Ge\u00b7l\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "So eure Fesseln bricht/ euch in die Freyheit setzet/", "tokens": ["So", "eu\u00b7re", "Fes\u00b7seln", "bricht", "/", "euch", "in", "die", "Frey\u00b7heit", "set\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "$(", "PPER", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und statt Egyptens Dienst in ", "tokens": ["Und", "statt", "E\u00b7gyp\u00b7tens", "Dienst", "in"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NE", "NN", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Solten euch die Augen zwingen?", "tokens": ["Sol\u00b7ten", "euch", "die", "Au\u00b7gen", "zwin\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die nur schlechter Firni\u00df sind/", "tokens": ["Die", "nur", "schlech\u00b7ter", "Fir\u00b7ni\u00df", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein! seyd nicht mehr starre-blind.", "tokens": ["Nein", "!", "seyd", "nicht", "mehr", "star\u00b7re\u00b7blind", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "VAFIN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Last euch aus dem Nebel bringen/", "tokens": ["Last", "euch", "aus", "dem", "Ne\u00b7bel", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der euch mit seinem Dunst bishero hat betrogen/", "tokens": ["Der", "euch", "mit", "sei\u00b7nem", "Dunst", "bis\u00b7he\u00b7ro", "hat", "be\u00b7tro\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und mehr als Wahrheit ist von ihr euch vorgelogen.", "tokens": ["Und", "mehr", "als", "Wahr\u00b7heit", "ist", "von", "ihr", "euch", "vor\u00b7ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "KOKOM", "NN", "VAFIN", "APPR", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wer will wol als Sclave leben/", "tokens": ["Wer", "will", "wol", "als", "Scla\u00b7ve", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "KOUS", "NN", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wenn er kan erl\u00f6set seyn?", "tokens": ["Wenn", "er", "kan", "er\u00b7l\u00f6\u00b7set", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wer geht den Wechsel ein?", "tokens": ["Und", "wer", "geht", "den", "Wech\u00b7sel", "ein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Seine Freyheit hinzugeben", "tokens": ["Sei\u00b7ne", "Frey\u00b7heit", "hin\u00b7zu\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVIZU"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vor einem falschen Blick/ vor ein betr\u00fcglichs Lachen.", "tokens": ["Vor", "ei\u00b7nem", "fal\u00b7schen", "Blick", "/", "vor", "ein", "be\u00b7tr\u00fcg\u00b7lichs", "La\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und wer l\u00e4st sich aus Lust zu einem Knechte machen?", "tokens": ["Und", "wer", "l\u00e4st", "sich", "aus", "Lust", "zu", "ei\u00b7nem", "Knech\u00b7te", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PRF", "APPR", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Sch\u00fctzt euch nun in eurem Stande", "tokens": ["Sch\u00fctzt", "euch", "nun", "in", "eu\u00b7rem", "Stan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bleibt der Freyheit zu gethan/", "tokens": ["Bleibt", "der", "Frey\u00b7heit", "zu", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKZU", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nehmt hinf\u00fchro nicht mehr an", "tokens": ["Nehmt", "hin\u00b7f\u00fch\u00b7ro", "nicht", "mehr", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PTKNEG", "ADV", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Diese so verha\u00dfte Bande/", "tokens": ["Die\u00b7se", "so", "ver\u00b7ha\u00df\u00b7te", "Ban\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bem\u00fchet euch vielmehr derjenigen zu dienen/", "tokens": ["Be\u00b7m\u00fc\u00b7het", "euch", "viel\u00b7mehr", "der\u00b7je\u00b7ni\u00b7gen", "zu", "die\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PDS", "PTKZU", "VVINF", "$("], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Bey der ihr Gegen-Gunst und Liebe sehet gr\u00fcnen.", "tokens": ["Bey", "der", "ihr", "Ge\u00b7gen\u00b7Gunst", "und", "Lie\u00b7be", "se\u00b7het", "gr\u00fc\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "NN", "KON", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}