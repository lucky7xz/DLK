{"dta.poem.841": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "XxVIII.  Auf das Fest de\u00df auferstehenden Er-  \n l\u00f6sers/ oder den H. Ostertag.  \n Marci 16.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Wo ist der H\u00f6llen Raub? wo sind de\u00df Todes Pfeyle? ", "tokens": ["Wo", "ist", "der", "H\u00f6l\u00b7len", "Raub", "?", "wo", "sind", "de\u00df", "To\u00b7des", "Pfey\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "NN", "$.", "PWAV", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo ist der S\u00fcnden macht? wo ist der Schlang\u1ebd Zahn?", "tokens": ["Wo", "ist", "der", "S\u00fcn\u00b7den", "macht", "?", "wo", "ist", "der", "Schlang\u1ebd", "Zahn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "VVFIN", "$.", "PWAV", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Wo ist de\u00df H\u00f6chsten Zorn? wo ist der H\u00f6llen Kahn?", "tokens": ["Wo", "ist", "de\u00df", "H\u00f6chs\u00b7ten", "Zorn", "?", "wo", "ist", "der", "H\u00f6l\u00b7len", "Kahn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "$.", "PWAV", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verjagt! erlegt! entzwey! Wo sind die starcken Seile", "tokens": ["Ver\u00b7jagt", "!", "er\u00b7legt", "!", "ent\u00b7zwey", "!", "Wo", "sind", "die", "star\u00b7cken", "Sei\u00b7le"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "$.", "VVPP", "$.", "PTKVZ", "$.", "PWAV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Mit den die S\u00fcnde band? Ist in so kurtzer weile", "tokens": ["Mit", "den", "die", "S\u00fcn\u00b7de", "band", "?", "Ist", "in", "so", "kurt\u00b7zer", "wei\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN", "VVFIN", "$.", "VAFIN", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "De\u00df Teufels Reich zust\u00f6rt! Ja! ", "tokens": ["De\u00df", "Teu\u00b7fels", "Reich", "zu\u00b7st\u00f6rt", "!", "Ja", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$.", "PTKANT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Lew vnd Lamb/ der Knecht vnd K\u00f6nig! hats gethan:", "tokens": ["Der", "Lew", "vnd", "Lamb", "/", "der", "Knecht", "vnd", "K\u00f6\u00b7nig", "!", "hats", "ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NE", "KON", "NN", "$(", "ART", "NN", "KON", "NN", "$.", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "O Leben! Heil! Triumph! auff! auff mein Hertz vnd eile!", "tokens": ["O", "Le\u00b7ben", "!", "Heil", "!", "Tri\u00b7umph", "!", "auff", "!", "auff", "mein", "Hertz", "vnd", "ei\u00b7le", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "NN", "$.", "NN", "$.", "PTKVZ", "$.", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dort liegen meine Schuld! hier ist das L\u00f6segeld/", "tokens": ["Dort", "lie\u00b7gen", "mei\u00b7ne", "Schuld", "!", "hier", "ist", "das", "L\u00f6\u00b7se\u00b7geld", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dort ist das leere Grab/ hier ist der starcke Held", "tokens": ["Dort", "ist", "das", "lee\u00b7re", "Grab", "/", "hier", "ist", "der", "star\u00b7cke", "Held"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$(", "ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der jedem ", "tokens": ["Der", "je\u00b7dem"], "token_info": ["word", "word"], "pos": ["ART", "PIAT"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.4": {"line.1": {"text": "Grab/ Siegel/ Hutt vnd Steintweltz ab die grosse Last", "tokens": ["Grab", "/", "Sie\u00b7gel", "/", "Hutt", "vnd", "Steint\u00b7weltz", "ab", "die", "gros\u00b7se", "Last"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "NN", "$(", "NE", "KON", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Vons Hertzens th\u00fcr/ bind auff das Schwei\u00dftuch das", "tokens": ["Vons", "Hert\u00b7zens", "th\u00fcr", "/", "bind", "auff", "das", "Schwei\u00df\u00b7tuch", "das"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "NE", "$(", "VAFIN", "APPR", "ART", "NN", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "mich fast ", "tokens": ["mich", "fast"], "token_info": ["word", "word"], "pos": ["PPER", "ADV"], "meter": "-+", "measure": "iambic.single"}}, "stanza.5": {"line.1": {"text": "Damit ich sehe/ wie der Tdd im Sieg verschlungen.", "tokens": ["Da\u00b7mit", "ich", "se\u00b7he", "/", "wie", "der", "Tdd", "im", "Sieg", "ver\u00b7schlun\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$(", "KOKOM", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}