{"dta.poem.20525": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Vermischte Arien.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Der mensch tritt nicht vor sich auff dieses rund der welt/", "tokens": ["Der", "mensch", "tritt", "nicht", "vor", "sich", "auff", "die\u00b7ses", "rund", "der", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "APPR", "PRF", "APPR", "PDAT", "ADJD", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer ist es/ dem sein mund alleine wohlgef\u00e4llt?", "tokens": ["Wer", "ist", "es", "/", "dem", "sein", "mund", "al\u00b7lei\u00b7ne", "wohl\u00b7ge\u00b7f\u00e4llt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$(", "ART", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer speiset sich mit seinen k\u00fcssen?", "tokens": ["Wer", "spei\u00b7set", "sich", "mit", "sei\u00b7nen", "k\u00fcs\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kein auge schaut sich selber an/", "tokens": ["Kein", "au\u00b7ge", "schaut", "sich", "sel\u00b7ber", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PRF", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und aus gesellschafft mu\u00df erspriessen/", "tokens": ["Und", "aus", "ge\u00b7sell\u00b7schafft", "mu\u00df", "er\u00b7spries\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was uns die noth benimmt/ und freude geben kan.", "tokens": ["Was", "uns", "die", "noth", "be\u00b7nimmt", "/", "und", "freu\u00b7de", "ge\u00b7ben", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVFIN", "$(", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}}, "stanza.2": {"line.1": {"text": "Es hatte die natur den ersten frauen mund/", "tokens": ["Es", "hat\u00b7te", "die", "na\u00b7tur", "den", "ers\u00b7ten", "frau\u00b7en", "mund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So in dem paradies vor GOtt und Adam stund/", "tokens": ["So", "in", "dem", "pa\u00b7ra\u00b7dies", "vor", "Gott", "und", "A\u00b7dam", "stund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit liebes-ziffern selbst beschrieben/", "tokens": ["Mit", "lie\u00b7bes\u00b7zif\u00b7fern", "selbst", "be\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man liebte vor dem apffel-bi\u00df.", "tokens": ["Man", "lieb\u00b7te", "vor", "dem", "apf\u00b7fel\u00b7bi\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es scheinet/ da\u00df den trieb zu lieben", "tokens": ["Es", "schei\u00b7net", "/", "da\u00df", "den", "trieb", "zu", "lie\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "ART", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gott mit dem athem bald in unsre nasen blie\u00df.", "tokens": ["Gott", "mit", "dem", "at\u00b7hem", "bald", "in", "uns\u00b7re", "na\u00b7sen", "blie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.3": {"line.1": {"text": "Der s\u00fcsse wunder-zeug/ den man die regung heist/", "tokens": ["Der", "s\u00fcs\u00b7se", "wun\u00b7der\u00b7zeug", "/", "den", "man", "die", "re\u00b7gung", "heist", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "PIS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und ohne dem die welt aus ihren angeln reist/", "tokens": ["Und", "oh\u00b7ne", "dem", "die", "welt", "aus", "ih\u00b7ren", "an\u00b7geln", "reist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRELS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und zeitlich w\u00fcrde w\u00fcste stehen/", "tokens": ["Und", "zeit\u00b7lich", "w\u00fcr\u00b7de", "w\u00fcs\u00b7te", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zeigt fleisch und blut die lebens-spur/", "tokens": ["Zeigt", "fleisch", "und", "blut", "die", "le\u00b7bens\u00b7spur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wer ihr trachtet zu entgehen/", "tokens": ["Und", "wer", "ihr", "trach\u00b7tet", "zu", "ent\u00b7ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Beschimpfft die menschlichkeit/ und st\u00f6hret die natur.", "tokens": ["Be\u00b7schimpfft", "die", "menschlich\u00b7keit", "/", "und", "st\u00f6h\u00b7ret", "die", "na\u00b7tur", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$(", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Wer in der einsamkeit lust und beh\u00e4ltni\u00df sucht/", "tokens": ["Wer", "in", "der", "ein\u00b7sam\u00b7keit", "lust", "und", "be\u00b7h\u00e4lt\u00b7ni\u00df", "sucht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "VVFIN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sich zu verlieren w\u00fcnscht/ als bl\u00fcte in der frucht/", "tokens": ["Sich", "zu", "ver\u00b7lie\u00b7ren", "w\u00fcnscht", "/", "als", "bl\u00fc\u00b7te", "in", "der", "frucht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKZU", "VVINF", "VVFIN", "$(", "KOKOM", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und lebt/ als w\u00e4r er neu gebohren/", "tokens": ["Und", "lebt", "/", "als", "w\u00e4r", "er", "neu", "ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOKOM", "VAFIN", "PPER", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der macht aus blute schnee und ei\u00df/", "tokens": ["Der", "macht", "aus", "blu\u00b7te", "schnee", "und", "ei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und hat ihm einen weg erkohren/", "tokens": ["Und", "hat", "ihm", "ei\u00b7nen", "weg", "er\u00b7koh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Den man erdulten mu\u00df/ doch nicht zu r\u00fchmen wei\u00df.", "tokens": ["Den", "man", "er\u00b7dul\u00b7ten", "mu\u00df", "/", "doch", "nicht", "zu", "r\u00fch\u00b7men", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "VMFIN", "$(", "ADV", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Den kr\u00f6net die natur/ die wei\u00dflich lebt und liebt/", "tokens": ["Den", "kr\u00f6\u00b7net", "die", "na\u00b7tur", "/", "die", "wei\u00df\u00b7lich", "lebt", "und", "liebt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$(", "ART", "ADJD", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und diesem/ was ihm gleicht/ bedachtsam sich ergiebt.", "tokens": ["Und", "die\u00b7sem", "/", "was", "ihm", "gleicht", "/", "be\u00b7dacht\u00b7sam", "sich", "er\u00b7giebt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "$(", "PWS", "PPER", "VVFIN", "$(", "ADJD", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir sind nicht engel/ auch nicht steine/", "tokens": ["Wir", "sind", "nicht", "en\u00b7gel", "/", "auch", "nicht", "stei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "NN", "$(", "ADV", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von fleisch und regung nicht befreyt/", "tokens": ["Von", "fleisch", "und", "re\u00b7gung", "nicht", "be\u00b7freyt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "NN", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir leben nicht vor uns alleine/", "tokens": ["Wir", "le\u00b7ben", "nicht", "vor", "uns", "al\u00b7lei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "PPER", "ADV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und unser ehlich seyn schmeckt nach der ewigkeit.", "tokens": ["Und", "un\u00b7ser", "eh\u00b7lich", "seyn", "schmeckt", "nach", "der", "e\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJD", "VAINF", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}