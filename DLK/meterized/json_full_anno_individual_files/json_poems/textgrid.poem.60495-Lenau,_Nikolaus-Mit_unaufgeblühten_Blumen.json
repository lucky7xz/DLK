{"textgrid.poem.60495": {"metadata": {"author": {"name": "Lenau, Nikolaus", "birth": "N.A.", "death": "N.A."}, "title": "Mit unaufgebl\u00fchten Blumen", "genre": "verse", "period": "N.A.", "pub_year": 1832, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Fr\u00fchling ist gekommen,", "tokens": ["Der", "Fr\u00fch\u00b7ling", "ist", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er zieht durch sein Revier,", "tokens": ["Er", "zieht", "durch", "sein", "Re\u00b7vier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du hast es nicht vernommen", "tokens": ["Du", "hast", "es", "nicht", "ver\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Im Krankenzimmer hier,", "tokens": ["Im", "Kran\u00b7ken\u00b7zim\u00b7mer", "hier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wie er durch seine Strahlen", "tokens": ["Wie", "er", "durch", "sei\u00b7ne", "Strah\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den Winter ganz vertrieb,", "tokens": ["Den", "Win\u00b7ter", "ganz", "ver\u00b7trieb", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df ihm in Berg und Talen", "tokens": ["Da\u00df", "ihm", "in", "Berg", "und", "Ta\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht eine St\u00e4tte blieb,", "tokens": ["Nicht", "ei\u00b7ne", "St\u00e4t\u00b7te", "blieb", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wie er den Grund erschlossen", "tokens": ["Wie", "er", "den", "Grund", "er\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und alle Keime weckt,", "tokens": ["Und", "al\u00b7le", "Kei\u00b7me", "weckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df man ein lustig Sprossen", "tokens": ["Da\u00df", "man", "ein", "lus\u00b7tig", "Spros\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schon \u00fcberall entdeckt.", "tokens": ["Schon", "\u00fc\u00b7be\u00b7rall", "ent\u00b7deckt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Doch um dir zu ersetzen,", "tokens": ["Doch", "um", "dir", "zu", "er\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Was unterdes dahin,", "tokens": ["Was", "un\u00b7ter\u00b7des", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PAV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Schickt er, dein \u00c4ug zu letzen,", "tokens": ["Schickt", "er", ",", "dein", "\u00c4ug", "zu", "let\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dir dieses frische Gr\u00fcn.", "tokens": ["Dir", "die\u00b7ses", "fri\u00b7sche", "Gr\u00fcn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Er schickt dir diese Pflanzen,", "tokens": ["Er", "schickt", "dir", "die\u00b7se", "Pflan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da\u00df sie dir ungef\u00e4hr", "tokens": ["Da\u00df", "sie", "dir", "un\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Anzeigten, wie's im ganzen", "tokens": ["An\u00b7zeig\u00b7ten", ",", "wie's", "im", "gan\u00b7zen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "APPRART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nun aussieht rings umher.", "tokens": ["Nun", "aus\u00b7sieht", "rings", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Zwar sind noch leider offen", "tokens": ["Zwar", "sind", "noch", "lei\u00b7der", "of\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die sch\u00f6nen Bl\u00fcten nicht,", "tokens": ["Die", "sch\u00f6\u00b7nen", "Bl\u00fc\u00b7ten", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch steht es wohl zu hoffen,", "tokens": ["Doch", "steht", "es", "wohl", "zu", "hof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df bald die Knospe bricht.", "tokens": ["Da\u00df", "bald", "die", "Knos\u00b7pe", "bricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "So hoff ich, da\u00df dein Leben", "tokens": ["So", "hoff", "ich", ",", "da\u00df", "dein", "Le\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Krankheit brech entzwei,", "tokens": ["Die", "Krank\u00b7heit", "brech", "ent\u00b7zwei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df es in regem Streben", "tokens": ["Da\u00df", "es", "in", "re\u00b7gem", "Stre\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Erbl\u00fche frisch und neu,", "tokens": ["Er\u00b7bl\u00fc\u00b7he", "frisch", "und", "neu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und hoff, wenn aufgegangen", "tokens": ["Und", "hoff", ",", "wenn", "auf\u00b7ge\u00b7gan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Kelch der Blumen ganz,", "tokens": ["Der", "Kelch", "der", "Blu\u00b7men", "ganz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So sollest wieder prangen", "tokens": ["So", "sol\u00b7lest", "wie\u00b7der", "pran\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auch du im Blumenglanz.", "tokens": ["Auch", "du", "im", "Blu\u00b7men\u00b7glanz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Doch aller Schein der Sonnen,", "tokens": ["Doch", "al\u00b7ler", "Schein", "der", "Son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Bl\u00fcten sch\u00f6nstes Rot", "tokens": ["Der", "Bl\u00fc\u00b7ten", "sch\u00f6ns\u00b7tes", "Rot"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und alle Fr\u00fchlingswonnen", "tokens": ["Und", "al\u00b7le", "Fr\u00fch\u00b7lings\u00b7won\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sind f\u00fcr uns hin und tot,", "tokens": ["Sind", "f\u00fcr", "uns", "hin", "und", "tot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "PTKVZ", "KON", "ADJD", "$,"], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.10": {"line.1": {"text": "Wenn Gott, der gnadenreiche,", "tokens": ["Wenn", "Gott", ",", "der", "gna\u00b7den\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dies eine nicht erteilt,", "tokens": ["Dies", "ei\u00b7ne", "nicht", "er\u00b7teilt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df er von schwerer Seuche", "tokens": ["Da\u00df", "er", "von", "schwe\u00b7rer", "Seu\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die liebe Mutter heilt.", "tokens": ["Die", "lie\u00b7be", "Mut\u00b7ter", "heilt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Drum w\u00fcnsch ich dir dies eine", "tokens": ["Drum", "w\u00fcnsch", "ich", "dir", "dies", "ei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "PDS", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nur zum Geburtstag heut,", "tokens": ["Nur", "zum", "Ge\u00b7burts\u00b7tag", "heut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADV", "$,"], "meter": "++-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df bald ihr im Vereine", "tokens": ["Da\u00df", "bald", "ihr", "im", "Ver\u00b7ei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Frisch und genesen seid.", "tokens": ["Frisch", "und", "ge\u00b7ne\u00b7sen", "seid", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVPP", "VAFIN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.12": {"line.1": {"text": "Der Fr\u00fchling ist gekommen,", "tokens": ["Der", "Fr\u00fch\u00b7ling", "ist", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er zieht durch sein Revier,", "tokens": ["Er", "zieht", "durch", "sein", "Re\u00b7vier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du hast es nicht vernommen", "tokens": ["Du", "hast", "es", "nicht", "ver\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Im Krankenzimmer hier,", "tokens": ["Im", "Kran\u00b7ken\u00b7zim\u00b7mer", "hier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Wie er durch seine Strahlen", "tokens": ["Wie", "er", "durch", "sei\u00b7ne", "Strah\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den Winter ganz vertrieb,", "tokens": ["Den", "Win\u00b7ter", "ganz", "ver\u00b7trieb", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df ihm in Berg und Talen", "tokens": ["Da\u00df", "ihm", "in", "Berg", "und", "Ta\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht eine St\u00e4tte blieb,", "tokens": ["Nicht", "ei\u00b7ne", "St\u00e4t\u00b7te", "blieb", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Wie er den Grund erschlossen", "tokens": ["Wie", "er", "den", "Grund", "er\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und alle Keime weckt,", "tokens": ["Und", "al\u00b7le", "Kei\u00b7me", "weckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df man ein lustig Sprossen", "tokens": ["Da\u00df", "man", "ein", "lus\u00b7tig", "Spros\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schon \u00fcberall entdeckt.", "tokens": ["Schon", "\u00fc\u00b7be\u00b7rall", "ent\u00b7deckt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Doch um dir zu ersetzen,", "tokens": ["Doch", "um", "dir", "zu", "er\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Was unterdes dahin,", "tokens": ["Was", "un\u00b7ter\u00b7des", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PAV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Schickt er, dein \u00c4ug zu letzen,", "tokens": ["Schickt", "er", ",", "dein", "\u00c4ug", "zu", "let\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dir dieses frische Gr\u00fcn.", "tokens": ["Dir", "die\u00b7ses", "fri\u00b7sche", "Gr\u00fcn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Er schickt dir diese Pflanzen,", "tokens": ["Er", "schickt", "dir", "die\u00b7se", "Pflan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da\u00df sie dir ungef\u00e4hr", "tokens": ["Da\u00df", "sie", "dir", "un\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Anzeigten, wie's im ganzen", "tokens": ["An\u00b7zeig\u00b7ten", ",", "wie's", "im", "gan\u00b7zen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "APPRART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nun aussieht rings umher.", "tokens": ["Nun", "aus\u00b7sieht", "rings", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Zwar sind noch leider offen", "tokens": ["Zwar", "sind", "noch", "lei\u00b7der", "of\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die sch\u00f6nen Bl\u00fcten nicht,", "tokens": ["Die", "sch\u00f6\u00b7nen", "Bl\u00fc\u00b7ten", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch steht es wohl zu hoffen,", "tokens": ["Doch", "steht", "es", "wohl", "zu", "hof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df bald die Knospe bricht.", "tokens": ["Da\u00df", "bald", "die", "Knos\u00b7pe", "bricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "So hoff ich, da\u00df dein Leben", "tokens": ["So", "hoff", "ich", ",", "da\u00df", "dein", "Le\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Krankheit brech entzwei,", "tokens": ["Die", "Krank\u00b7heit", "brech", "ent\u00b7zwei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df es in regem Streben", "tokens": ["Da\u00df", "es", "in", "re\u00b7gem", "Stre\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Erbl\u00fche frisch und neu,", "tokens": ["Er\u00b7bl\u00fc\u00b7he", "frisch", "und", "neu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Und hoff, wenn aufgegangen", "tokens": ["Und", "hoff", ",", "wenn", "auf\u00b7ge\u00b7gan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Kelch der Blumen ganz,", "tokens": ["Der", "Kelch", "der", "Blu\u00b7men", "ganz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So sollest wieder prangen", "tokens": ["So", "sol\u00b7lest", "wie\u00b7der", "pran\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auch du im Blumenglanz.", "tokens": ["Auch", "du", "im", "Blu\u00b7men\u00b7glanz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Doch aller Schein der Sonnen,", "tokens": ["Doch", "al\u00b7ler", "Schein", "der", "Son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Bl\u00fcten sch\u00f6nstes Rot", "tokens": ["Der", "Bl\u00fc\u00b7ten", "sch\u00f6ns\u00b7tes", "Rot"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und alle Fr\u00fchlingswonnen", "tokens": ["Und", "al\u00b7le", "Fr\u00fch\u00b7lings\u00b7won\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sind f\u00fcr uns hin und tot,", "tokens": ["Sind", "f\u00fcr", "uns", "hin", "und", "tot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "PTKVZ", "KON", "ADJD", "$,"], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.21": {"line.1": {"text": "Wenn Gott, der gnadenreiche,", "tokens": ["Wenn", "Gott", ",", "der", "gna\u00b7den\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dies eine nicht erteilt,", "tokens": ["Dies", "ei\u00b7ne", "nicht", "er\u00b7teilt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df er von schwerer Seuche", "tokens": ["Da\u00df", "er", "von", "schwe\u00b7rer", "Seu\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die liebe Mutter heilt.", "tokens": ["Die", "lie\u00b7be", "Mut\u00b7ter", "heilt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Drum w\u00fcnsch ich dir dies eine", "tokens": ["Drum", "w\u00fcnsch", "ich", "dir", "dies", "ei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "PDS", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nur zum Geburtstag heut,", "tokens": ["Nur", "zum", "Ge\u00b7burts\u00b7tag", "heut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADV", "$,"], "meter": "++-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df bald ihr im Vereine", "tokens": ["Da\u00df", "bald", "ihr", "im", "Ver\u00b7ei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Frisch und genesen seid.", "tokens": ["Frisch", "und", "ge\u00b7ne\u00b7sen", "seid", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVPP", "VAFIN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}}}}