{"textgrid.poem.63909": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "Literatur und Kunst", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Poeten tragen sorgenlos", "tokens": ["Po\u00b7et\u00b7en", "tra\u00b7gen", "sor\u00b7gen\u00b7los"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die heimlichsten Gef\u00fchle blo\u00df;", "tokens": ["Die", "heim\u00b7lichs\u00b7ten", "Ge\u00b7f\u00fch\u00b7le", "blo\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Doch k\u00f6nnen sie's ohne Scham nicht sehn,", "tokens": ["Doch", "k\u00f6n\u00b7nen", "sie's", "oh\u00b7ne", "Scham", "nicht", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "APPR", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wenn die Gedanken nackend gehn.", "tokens": ["Wenn", "die", "Ge\u00b7dan\u00b7ken", "na\u00b7ckend", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Was man nicht liebt, kann man nicht machen,", "tokens": ["Was", "man", "nicht", "liebt", ",", "kann", "man", "nicht", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PTKNEG", "VVFIN", "$,", "VMFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und jeder mache, was er kann.", "tokens": ["Und", "je\u00b7der", "ma\u00b7che", ",", "was", "er", "kann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$,", "PWS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bed\u00e4chten das die Starken und Schwachen,", "tokens": ["Be\u00b7d\u00e4ch\u00b7ten", "das", "die", "Star\u00b7ken", "und", "Schwa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die K\u00fcnste w\u00e4ren besser dran.", "tokens": ["Die", "K\u00fcns\u00b7te", "w\u00e4\u00b7ren", "bes\u00b7ser", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Stets bereit zu tausend Sachen", "tokens": ["Stets", "be\u00b7reit", "zu", "tau\u00b7send", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind die flotten Halbtalente.", "tokens": ["Sind", "die", "flot\u00b7ten", "Halb\u00b7ta\u00b7len\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mu\u00df man doch nicht alles machen,", "tokens": ["Mu\u00df", "man", "doch", "nicht", "al\u00b7les", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "PTKNEG", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was man auch wohl machen k\u00f6nnte.", "tokens": ["Was", "man", "auch", "wohl", "ma\u00b7chen", "k\u00f6nn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Vermische Kunst und Leben nicht,", "tokens": ["Ver\u00b7mi\u00b7sche", "Kunst", "und", "Le\u00b7ben", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mach nicht dein Leben zum Gedicht,", "tokens": ["Mach", "nicht", "dein", "Le\u00b7ben", "zum", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du m\u00f6chtest sonst die Kraft verbrauchen,", "tokens": ["Du", "m\u00f6ch\u00b7test", "sonst", "die", "Kraft", "ver\u00b7brau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Dichtung Leben einzuhauchen.", "tokens": ["Der", "Dich\u00b7tung", "Le\u00b7ben", "ein\u00b7zu\u00b7hau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Gedankenarm ein traurig Los! \u2013", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7arm", "ein", "trau\u00b7rig", "Los", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ART", "ADJD", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel lieber doch gedankenlos.", "tokens": ["Viel", "lie\u00b7ber", "doch", "ge\u00b7dan\u00b7ken\u00b7los", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Brauche nur immer deine Kraft,", "tokens": ["Brau\u00b7che", "nur", "im\u00b7mer", "dei\u00b7ne", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ob sie auch nichts vom H\u00f6chsten schafft.", "tokens": ["Ob", "sie", "auch", "nichts", "vom", "H\u00f6chs\u00b7ten", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum mindsten ist ", "tokens": ["Zum", "minds\u00b7ten", "ist"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Und das tut not in unserm Norden.", "tokens": ["Und", "das", "tut", "not", "in", "un\u00b7serm", "Nor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Weiter bringt dich's, auf falschen Wegen", "tokens": ["Wei\u00b7ter", "bringt", "dich's", ",", "auf", "fal\u00b7schen", "We\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "$,", "APPR", "ADJA", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "R\u00fcstigen Schritts voranzugehn,", "tokens": ["R\u00fcs\u00b7ti\u00b7gen", "Schritts", "vor\u00b7an\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Als auf dem rechten dich schlafen zu legen,", "tokens": ["Als", "auf", "dem", "rech\u00b7ten", "dich", "schla\u00b7fen", "zu", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "PPER", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Oder im Kreise dich umzudrehn.", "tokens": ["O\u00b7der", "im", "Krei\u00b7se", "dich", "um\u00b7zu\u00b7drehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "PPER", "VVIZU", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "Alles verstehn und verzeihn wir Deutschen: das schw\u00fclstigste Pathos,", "tokens": ["Al\u00b7les", "ver\u00b7stehn", "und", "ver\u00b7zeihn", "wir", "Deut\u00b7schen", ":", "das", "schw\u00fcls\u00b7tigs\u00b7te", "Pa\u00b7thos", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "KON", "VVFIN", "PPER", "NN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+--+---+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Sentimentales Geseufz, \u00fcppige Frivolit\u00e4t,", "tokens": ["Sen\u00b7ti\u00b7men\u00b7ta\u00b7les", "Ge\u00b7seufz", ",", "\u00fcp\u00b7pi\u00b7ge", "Fri\u00b7vo\u00b7li\u00b7t\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Nur unschuldige Grazie nicht. Die finden die Biedern", "tokens": ["Nur", "un\u00b7schul\u00b7di\u00b7ge", "Gra\u00b7zie", "nicht", ".", "Die", "fin\u00b7den", "die", "Bie\u00b7dern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "PTKNEG", "$.", "ART", "VVFIN", "ART", "NN"], "meter": "-++--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Blo\u00df affektiert, und zudem spreche sie nicht zum Gem\u00fct.", "tokens": ["Blo\u00df", "af\u00b7fek\u00b7tiert", ",", "und", "zu\u00b7dem", "spre\u00b7che", "sie", "nicht", "zum", "Ge\u00b7m\u00fct", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KON", "PAV", "VVFIN", "PPER", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "Was macht ihr nur so gro\u00dfes Wesen", "tokens": ["Was", "macht", "ihr", "nur", "so", "gro\u00b7\u00dfes", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von euren hochbelobten Alten?", "tokens": ["Von", "eu\u00b7ren", "hoch\u00b7be\u00b7lob\u00b7ten", "Al\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie konnten wohl herrlich sich entfalten,", "tokens": ["Sie", "konn\u00b7ten", "wohl", "herr\u00b7lich", "sich", "ent\u00b7fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "PRF", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sind auch eben noch ", "tokens": ["Sind", "auch", "e\u00b7ben", "noch"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Poeten tragen sorgenlos", "tokens": ["Po\u00b7et\u00b7en", "tra\u00b7gen", "sor\u00b7gen\u00b7los"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die heimlichsten Gef\u00fchle blo\u00df;", "tokens": ["Die", "heim\u00b7lichs\u00b7ten", "Ge\u00b7f\u00fch\u00b7le", "blo\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Doch k\u00f6nnen sie's ohne Scham nicht sehn,", "tokens": ["Doch", "k\u00f6n\u00b7nen", "sie's", "oh\u00b7ne", "Scham", "nicht", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "APPR", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wenn die Gedanken nackend gehn.", "tokens": ["Wenn", "die", "Ge\u00b7dan\u00b7ken", "na\u00b7ckend", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Was man nicht liebt, kann man nicht machen,", "tokens": ["Was", "man", "nicht", "liebt", ",", "kann", "man", "nicht", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PTKNEG", "VVFIN", "$,", "VMFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und jeder mache, was er kann.", "tokens": ["Und", "je\u00b7der", "ma\u00b7che", ",", "was", "er", "kann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$,", "PWS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bed\u00e4chten das die Starken und Schwachen,", "tokens": ["Be\u00b7d\u00e4ch\u00b7ten", "das", "die", "Star\u00b7ken", "und", "Schwa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die K\u00fcnste w\u00e4ren besser dran.", "tokens": ["Die", "K\u00fcns\u00b7te", "w\u00e4\u00b7ren", "bes\u00b7ser", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Stets bereit zu tausend Sachen", "tokens": ["Stets", "be\u00b7reit", "zu", "tau\u00b7send", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind die flotten Halbtalente.", "tokens": ["Sind", "die", "flot\u00b7ten", "Halb\u00b7ta\u00b7len\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mu\u00df man doch nicht alles machen,", "tokens": ["Mu\u00df", "man", "doch", "nicht", "al\u00b7les", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "PTKNEG", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was man auch wohl machen k\u00f6nnte.", "tokens": ["Was", "man", "auch", "wohl", "ma\u00b7chen", "k\u00f6nn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Vermische Kunst und Leben nicht,", "tokens": ["Ver\u00b7mi\u00b7sche", "Kunst", "und", "Le\u00b7ben", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mach nicht dein Leben zum Gedicht,", "tokens": ["Mach", "nicht", "dein", "Le\u00b7ben", "zum", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du m\u00f6chtest sonst die Kraft verbrauchen,", "tokens": ["Du", "m\u00f6ch\u00b7test", "sonst", "die", "Kraft", "ver\u00b7brau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Dichtung Leben einzuhauchen.", "tokens": ["Der", "Dich\u00b7tung", "Le\u00b7ben", "ein\u00b7zu\u00b7hau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Gedankenarm ein traurig Los! \u2013", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7arm", "ein", "trau\u00b7rig", "Los", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ART", "ADJD", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel lieber doch gedankenlos.", "tokens": ["Viel", "lie\u00b7ber", "doch", "ge\u00b7dan\u00b7ken\u00b7los", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Brauche nur immer deine Kraft,", "tokens": ["Brau\u00b7che", "nur", "im\u00b7mer", "dei\u00b7ne", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ob sie auch nichts vom H\u00f6chsten schafft.", "tokens": ["Ob", "sie", "auch", "nichts", "vom", "H\u00f6chs\u00b7ten", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum mindsten ist ", "tokens": ["Zum", "minds\u00b7ten", "ist"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Und das tut not in unserm Norden.", "tokens": ["Und", "das", "tut", "not", "in", "un\u00b7serm", "Nor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Weiter bringt dich's, auf falschen Wegen", "tokens": ["Wei\u00b7ter", "bringt", "dich's", ",", "auf", "fal\u00b7schen", "We\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "$,", "APPR", "ADJA", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "R\u00fcstigen Schritts voranzugehn,", "tokens": ["R\u00fcs\u00b7ti\u00b7gen", "Schritts", "vor\u00b7an\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Als auf dem rechten dich schlafen zu legen,", "tokens": ["Als", "auf", "dem", "rech\u00b7ten", "dich", "schla\u00b7fen", "zu", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "PPER", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Oder im Kreise dich umzudrehn.", "tokens": ["O\u00b7der", "im", "Krei\u00b7se", "dich", "um\u00b7zu\u00b7drehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "PPER", "VVIZU", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.17": {"line.1": {"text": "Alles verstehn und verzeihn wir Deutschen: das schw\u00fclstigste Pathos,", "tokens": ["Al\u00b7les", "ver\u00b7stehn", "und", "ver\u00b7zeihn", "wir", "Deut\u00b7schen", ":", "das", "schw\u00fcls\u00b7tigs\u00b7te", "Pa\u00b7thos", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "KON", "VVFIN", "PPER", "NN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+--+---+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Sentimentales Geseufz, \u00fcppige Frivolit\u00e4t,", "tokens": ["Sen\u00b7ti\u00b7men\u00b7ta\u00b7les", "Ge\u00b7seufz", ",", "\u00fcp\u00b7pi\u00b7ge", "Fri\u00b7vo\u00b7li\u00b7t\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Nur unschuldige Grazie nicht. Die finden die Biedern", "tokens": ["Nur", "un\u00b7schul\u00b7di\u00b7ge", "Gra\u00b7zie", "nicht", ".", "Die", "fin\u00b7den", "die", "Bie\u00b7dern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "PTKNEG", "$.", "ART", "VVFIN", "ART", "NN"], "meter": "-++--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Blo\u00df affektiert, und zudem spreche sie nicht zum Gem\u00fct.", "tokens": ["Blo\u00df", "af\u00b7fek\u00b7tiert", ",", "und", "zu\u00b7dem", "spre\u00b7che", "sie", "nicht", "zum", "Ge\u00b7m\u00fct", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KON", "PAV", "VVFIN", "PPER", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.18": {"line.1": {"text": "Was macht ihr nur so gro\u00dfes Wesen", "tokens": ["Was", "macht", "ihr", "nur", "so", "gro\u00b7\u00dfes", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von euren hochbelobten Alten?", "tokens": ["Von", "eu\u00b7ren", "hoch\u00b7be\u00b7lob\u00b7ten", "Al\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie konnten wohl herrlich sich entfalten,", "tokens": ["Sie", "konn\u00b7ten", "wohl", "herr\u00b7lich", "sich", "ent\u00b7fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "PRF", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sind auch eben noch ", "tokens": ["Sind", "auch", "e\u00b7ben", "noch"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}