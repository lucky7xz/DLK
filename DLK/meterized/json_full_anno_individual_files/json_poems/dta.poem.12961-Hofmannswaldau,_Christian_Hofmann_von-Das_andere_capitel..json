{"dta.poem.12961": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Das andere capitel.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Der mensch ist von natur begierig viel zu wissen:", "tokens": ["Der", "mensch", "ist", "von", "na\u00b7tur", "be\u00b7gie\u00b7rig", "viel", "zu", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch ohne gottesfurcht hilfft keine wissenschafft.", "tokens": ["Doch", "oh\u00b7ne", "got\u00b7tes\u00b7furcht", "hilfft", "kei\u00b7ne", "wis\u00b7sen\u00b7schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein bauer, der nicht erst nach hohen grillen gafft,", "tokens": ["Ein", "bau\u00b7er", ",", "der", "nicht", "erst", "nach", "ho\u00b7hen", "gril\u00b7len", "gafft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PTKNEG", "ADV", "APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und in der demuth GOtt zu dienen ist beflissen,", "tokens": ["Und", "in", "der", "de\u00b7muth", "Gott", "zu", "die\u00b7nen", "ist", "be\u00b7flis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "PTKZU", "VVINF", "VAFIN", "VVPP", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ist besser, denn ein thor, der durch die sternen rennt,", "tokens": ["Ist", "bes\u00b7ser", ",", "denn", "ein", "thor", ",", "der", "durch", "die", "ster\u00b7nen", "rennt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "KON", "ART", "NN", "$,", "PRELS", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und sich vor \u00fcbermuth und weisheit selbst nicht kennt.", "tokens": ["Und", "sich", "vor", "\u00fc\u00b7ber\u00b7muth", "und", "weis\u00b7heit", "selbst", "nicht", "kennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ADJD", "KON", "NN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wer sich nun selbst recht kennt, der wird ihm schlecht gefallen:", "tokens": ["Wer", "sich", "nun", "selbst", "recht", "kennt", ",", "der", "wird", "ihm", "schlecht", "ge\u00b7fal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADV", "ADV", "ADJD", "VVFIN", "$,", "PRELS", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich wei\u00df, es kommt ihm nichts als lauter demuth ein.", "tokens": ["Ich", "wei\u00df", ",", "es", "kommt", "ihm", "nichts", "als", "lau\u00b7ter", "de\u00b7muth", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "PIS", "KOKOM", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum mu\u00df das menschen-lob ihm h\u00f6chst verdr\u00fc\u00dflich seyn.", "tokens": ["Drum", "mu\u00df", "das", "men\u00b7schen\u00b7lob", "ihm", "h\u00f6chst", "ver\u00b7dr\u00fc\u00df\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "ART", "NN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn wenn ich alles w\u00fcst\u2019, und h\u00e4tte bey dem allen", "tokens": ["Denn", "wenn", "ich", "al\u00b7les", "w\u00fcst'", ",", "und", "h\u00e4t\u00b7te", "bey", "dem", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PIS", "VVFIN", "$,", "KON", "VAFIN", "APPR", "ART", "PIAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des H\u00f6chsten liebe nicht; so w\u00fcrd\u2019 ich doch vor GOtt,", "tokens": ["Des", "H\u00f6chs\u00b7ten", "lie\u00b7be", "nicht", ";", "so", "w\u00fcrd'", "ich", "doch", "vor", "Gott", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "$.", "ADV", "VAFIN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der auf das leben sieht, zu schanden und zum spott.", "tokens": ["Der", "auf", "das", "le\u00b7ben", "sieht", ",", "zu", "schan\u00b7den", "und", "zum", "spott", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "VVINF", "VVFIN", "$,", "PTKZU", "VVINF", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Drum setze deiner lust, zu wissen, ziel und ende.", "tokens": ["Drum", "set\u00b7ze", "dei\u00b7ner", "lust", ",", "zu", "wis\u00b7sen", ",", "ziel", "und", "en\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "$,", "PTKZU", "VVINF", "$,", "VVFIN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Viel wissen bringt viel sorg, und denn auch viel betrug.", "tokens": ["Viel", "wis\u00b7sen", "bringt", "viel", "sorg", ",", "und", "denn", "auch", "viel", "be\u00b7trug", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VVFIN", "PIAT", "NN", "$,", "KON", "ADV", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer viel gegr\u00fcbelt hat, der h\u00e4lt sich selbst vor klug,", "tokens": ["Wer", "viel", "ge\u00b7gr\u00fc\u00b7belt", "hat", ",", "der", "h\u00e4lt", "sich", "selbst", "vor", "klug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVPP", "VAFIN", "$,", "PRELS", "VVFIN", "PRF", "ADV", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und will, da\u00df alle welt zu ihm nach weisheit sende.", "tokens": ["Und", "will", ",", "da\u00df", "al\u00b7le", "welt", "zu", "ihm", "nach", "weis\u00b7heit", "sen\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "KOUS", "PIAT", "NN", "APPR", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Viel dinge n\u00fctzen nichts, wenn man sie schon mit flei\u00df", "tokens": ["Viel", "din\u00b7ge", "n\u00fct\u00b7zen", "nichts", ",", "wenn", "man", "sie", "schon", "mit", "flei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PIS", "$,", "KOUS", "PIS", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In seinen kopff gefa\u00dft, und zu entscheiden wei\u00df.", "tokens": ["In", "sei\u00b7nen", "kopff", "ge\u00b7fa\u00dft", ",", "und", "zu", "ent\u00b7schei\u00b7den", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,", "KON", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Der ist ein gro\u00dfer narr, der mehr auf andre sachen,", "tokens": ["Der", "ist", "ein", "gro\u00b7\u00dfer", "narr", ",", "der", "mehr", "auf", "and\u00b7re", "sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als an sein heyl gedenckt, daran doch alles liegt.", "tokens": ["Als", "an", "sein", "heyl", "ge\u00b7denckt", ",", "da\u00b7ran", "doch", "al\u00b7les", "liegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "VVPP", "$,", "PAV", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von vielen worten wird die seele nicht vergn\u00fcgt;", "tokens": ["Von", "vie\u00b7len", "wor\u00b7ten", "wird", "die", "see\u00b7le", "nicht", "ver\u00b7gn\u00fcgt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "ART", "VVFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es mu\u00df des Geistes krafft das hertze freudig machen.", "tokens": ["Es", "mu\u00df", "des", "Geis\u00b7tes", "krafft", "das", "hert\u00b7ze", "freu\u00b7dig", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "VVFIN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Darum, wer JEsum tief in sein gem\u00fcthe dr\u00fcckt,", "tokens": ["Da\u00b7rum", ",", "wer", "Je\u00b7sum", "tief", "in", "sein", "ge\u00b7m\u00fc\u00b7the", "dr\u00fcckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "PWS", "ADV", "ADJD", "APPR", "PPOSAT", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und ihn im glauben liebt, der wird gewi\u00df erqvickt.", "tokens": ["Und", "ihn", "im", "glau\u00b7ben", "liebt", ",", "der", "wird", "ge\u00b7wi\u00df", "er\u00b7qvickt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "VVINF", "VVFIN", "$,", "PRELS", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wer gro\u00dfe dinge wei\u00df, soll einst ein urtheil h\u00f6ren,", "tokens": ["Wer", "gro\u00b7\u00dfe", "din\u00b7ge", "wei\u00df", ",", "soll", "einst", "ein", "ur\u00b7theil", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "VVFIN", "$,", "VMFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das unertr\u00e4glich ist, wofern er \u00fcbel lebt,", "tokens": ["Das", "un\u00b7er\u00b7tr\u00e4g\u00b7lich", "ist", ",", "wo\u00b7fern", "er", "\u00fc\u00b7bel", "lebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und nicht das, was er wei\u00df, auch auszu\u00fcben strebt,", "tokens": ["Und", "nicht", "das", ",", "was", "er", "wei\u00df", ",", "auch", "aus\u00b7zu\u00b7\u00fc\u00b7ben", "strebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "PDS", "$,", "PWS", "PPER", "VVFIN", "$,", "ADV", "VVIZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Drum \u00fcberhebe dich nicht wegen hoher lehren,", "tokens": ["Drum", "\u00fc\u00b7ber\u00b7he\u00b7be", "dich", "nicht", "we\u00b7gen", "ho\u00b7her", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKNEG", "APPR", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und gro\u00dfer wissenschafft. Mein! folge meinem rath", "tokens": ["Und", "gro\u00b7\u00dfer", "wis\u00b7sen\u00b7schafft", ".", "Mein", "!", "fol\u00b7ge", "mei\u00b7nem", "rath"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$.", "PPOSAT", "$.", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und f\u00fcrchte GOtt, der dir so viel vertrauet hat.", "tokens": ["Und", "f\u00fcrch\u00b7te", "Gott", ",", "der", "dir", "so", "viel", "ver\u00b7trau\u00b7et", "hat", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Bringt dir der Satan bey: Du habest mehr vergessen,", "tokens": ["Bringt", "dir", "der", "Sa\u00b7tan", "bey", ":", "Du", "ha\u00b7best", "mehr", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als Salomo gewu\u00dft; so wi\u00df\u2019, es ist noch viel,", "tokens": ["Als", "Sa\u00b7lo\u00b7mo", "ge\u00b7wu\u00dft", ";", "so", "wi\u00df'", ",", "es", "ist", "noch", "viel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VVPP", "$.", "ADV", "PTKVZ", "$,", "PPER", "VAFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was GOtt vor dir verbirgt, und andern sagen will.", "tokens": ["Was", "Gott", "vor", "dir", "ver\u00b7birgt", ",", "und", "an\u00b7dern", "sa\u00b7gen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "PPER", "VVFIN", "$,", "KON", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du kanst die wissenschafft doch nicht alleine fressen.", "tokens": ["Du", "kanst", "die", "wis\u00b7sen\u00b7schafft", "doch", "nicht", "al\u00b7lei\u00b7ne", "fres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "VVFIN", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum sey nicht allzuklug, bekenne vielmehr frey:", "tokens": ["Drum", "sey", "nicht", "all\u00b7zu\u00b7klug", ",", "be\u00b7ken\u00b7ne", "viel\u00b7mehr", "frey", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PTKNEG", "ADJD", "$,", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df deine gantze kunst vor GOtt nur thorheit sey.", "tokens": ["Da\u00df", "dei\u00b7ne", "gant\u00b7ze", "kunst", "vor", "Gott", "nur", "thor\u00b7heit", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "APPR", "NN", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ja warum machest du aus andern idioten?", "tokens": ["Ja", "wa\u00b7rum", "ma\u00b7chest", "du", "aus", "an\u00b7dern", "i\u00b7dio\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PWAV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Kennst du denn dich und sie? o unberathner thor!", "tokens": ["Kennst", "du", "denn", "dich", "und", "sie", "?", "o", "un\u00b7be\u00b7ra\u00b7th\u00b7ner", "thor", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "KON", "PPER", "$.", "FM", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Zeuch dich dem n\u00e4chsten nicht so gar verwegen vor.", "tokens": ["Zeuch", "dich", "dem", "n\u00e4chs\u00b7ten", "nicht", "so", "gar", "ver\u00b7we\u00b7gen", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "ADJA", "PTKNEG", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Willst du recht weise seyn, so zeuch nach den geboten,", "tokens": ["Willst", "du", "recht", "wei\u00b7se", "seyn", ",", "so", "zeuch", "nach", "den", "ge\u00b7bo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VAINF", "$,", "ADV", "VVIMP", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So GOttes weisheit giebt, die stoltzen segel ein,", "tokens": ["So", "Got\u00b7tes", "weis\u00b7heit", "giebt", ",", "die", "stolt\u00b7zen", "se\u00b7gel", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und lern\u2019 in niedrigkeit still und verborgen seyn.", "tokens": ["Und", "lern'", "in", "nied\u00b7rig\u00b7keit", "still", "und", "ver\u00b7bor\u00b7gen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "PTKVZ", "KON", "VVPP", "VAINF", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Nichts ist erbaulicher, als sich rechtschaffen kennen.", "tokens": ["Nichts", "ist", "er\u00b7bau\u00b7li\u00b7cher", ",", "als", "sich", "recht\u00b7schaf\u00b7fen", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJD", "$,", "KOUS", "PRF", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer seinen n\u00e4chsten hoch, sich selbst vor gar nichts h\u00e4lt,", "tokens": ["Wer", "sei\u00b7nen", "n\u00e4chs\u00b7ten", "hoch", ",", "sich", "selbst", "vor", "gar", "nichts", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "ADJD", "$,", "PRF", "ADV", "APPR", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und ob sein bruder gleich in schwere s\u00fcnden f\u00e4llt,", "tokens": ["Und", "ob", "sein", "bru\u00b7der", "gleich", "in", "schwe\u00b7re", "s\u00fcn\u00b7den", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich doch nicht besser sch\u00e4tzt, den kan man weise nennen.", "tokens": ["Sich", "doch", "nicht", "bes\u00b7ser", "sch\u00e4tzt", ",", "den", "kan", "man", "wei\u00b7se", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "PTKNEG", "ADJD", "VVFIN", "$,", "ART", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum wenn du auch schon siehst, da\u00df ieder fallen kan,", "tokens": ["Drum", "wenn", "du", "auch", "schon", "siehst", ",", "da\u00df", "ie\u00b7der", "fal\u00b7len", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "KOUS", "PPER", "ADV", "ADV", "VVFIN", "$,", "KOUS", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So siehe dennoch dich stets vor den schw\u00e4chsten an.", "tokens": ["So", "sie\u00b7he", "den\u00b7noch", "dich", "stets", "vor", "den", "schw\u00e4chs\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ADV", "PPER", "ADV", "APPR", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}