{"textgrid.poem.56109": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "1L: O B\u00e4ume Lebens, o wann winterlich?", "genre": "verse", "period": "N.A.", "pub_year": 1915, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O B\u00e4ume Lebens, o wann winterlich?", "tokens": ["O", "B\u00e4u\u00b7me", "Le\u00b7bens", ",", "o", "wann", "win\u00b7ter\u00b7lich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "NN", "$,", "FM", "PWAV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wir sind nicht einig. Sind nicht wie die Zug-", "tokens": ["Wir", "sind", "nicht", "ei\u00b7nig", ".", "Sind", "nicht", "wie", "die", "Zug"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$.", "VAFIN", "PTKNEG", "KOKOM", "ART", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "v\u00f6gel verst\u00e4ndigt. \u00dcberholt und sp\u00e4t,", "tokens": ["v\u00f6\u00b7gel", "ver\u00b7st\u00e4n\u00b7digt", ".", "\u00dc\u00b7berh\u00b7olt", "und", "sp\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$.", "NN", "KON", "ADJD", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "so dr\u00e4ngen wir uns pl\u00f6tzlich Winden auf", "tokens": ["so", "dr\u00e4n\u00b7gen", "wir", "uns", "pl\u00f6tz\u00b7lich", "Win\u00b7den", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "NN", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und fallen ein auf teilnahmslosen Teich.", "tokens": ["und", "fal\u00b7len", "ein", "auf", "teil\u00b7nahms\u00b7lo\u00b7sen", "Teich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Bl\u00fchn und verdorrn ist uns zugleich bewu\u00dft.", "tokens": ["Bl\u00fchn", "und", "ver\u00b7dorrn", "ist", "uns", "zu\u00b7gleich", "be\u00b7wu\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.7": {"text": "Und irgendwo gehn L\u00f6wen noch und wissen,", "tokens": ["Und", "ir\u00b7gend\u00b7wo", "gehn", "L\u00f6\u00b7wen", "noch", "und", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NN", "ADV", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "solang sie herrlich sind, von keiner Ohnmacht.", "tokens": ["so\u00b7lang", "sie", "herr\u00b7lich", "sind", ",", "von", "kei\u00b7ner", "Ohn\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VAFIN", "$,", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.2": {"line.1": {"text": "Uns aber, wo wir Eines meinen, ganz,", "tokens": ["Uns", "a\u00b7ber", ",", "wo", "wir", "Ei\u00b7nes", "mei\u00b7nen", ",", "ganz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PWAV", "PPER", "PIS", "VVFIN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ist schon des andern Aufwand f\u00fchlbar. Feindschaft", "tokens": ["ist", "schon", "des", "an\u00b7dern", "Auf\u00b7wand", "f\u00fchl\u00b7bar", ".", "Feind\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "ADJD", "$.", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ist uns das N\u00e4chste. Treten Liebende", "tokens": ["ist", "uns", "das", "N\u00e4chs\u00b7te", ".", "Tre\u00b7ten", "Lie\u00b7ben\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "$.", "ADJA", "NN"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.4": {"text": "nicht immerfort an R\u00e4nder, eins im andern,", "tokens": ["nicht", "im\u00b7mer\u00b7fort", "an", "R\u00e4n\u00b7der", ",", "eins", "im", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "$,", "PIS", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "die sich versprachen Weite, Jagd und Heimat.", "tokens": ["die", "sich", "ver\u00b7spra\u00b7chen", "Wei\u00b7te", ",", "Jagd", "und", "Hei\u00b7mat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "ADJA", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Da wird f\u00fcr eines Augenblickes Zeichnung", "tokens": ["Da", "wird", "f\u00fcr", "ei\u00b7nes", "Au\u00b7gen\u00b7bli\u00b7ckes", "Zeich\u00b7nung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "ein Grund von Gegenteil bereitet, m\u00fchsam,", "tokens": ["ein", "Grund", "von", "Ge\u00b7gen\u00b7teil", "be\u00b7rei\u00b7tet", ",", "m\u00fch\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "da\u00df wir sie s\u00e4hen; denn man ist sehr deutlich", "tokens": ["da\u00df", "wir", "sie", "s\u00e4\u00b7hen", ";", "denn", "man", "ist", "sehr", "deut\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "$.", "KON", "PIS", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "mit uns. Wir kennen den Kontur", "tokens": ["mit", "uns", ".", "Wir", "ken\u00b7nen", "den", "Kon\u00b7tur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$.", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "des F\u00fchlens nicht: nur, was ihn formt von au\u00dfen.", "tokens": ["des", "F\u00fch\u00b7lens", "nicht", ":", "nur", ",", "was", "ihn", "formt", "von", "au\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "$.", "ADV", "$,", "PRELS", "PPER", "VVFIN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Wer sa\u00df nicht bang vor seines Herzens Vorhang?", "tokens": ["Wer", "sa\u00df", "nicht", "bang", "vor", "sei\u00b7nes", "Her\u00b7zens", "Vor\u00b7hang", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ADJD", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Der schlug sich auf: die Szenerie war Abschied.", "tokens": ["Der", "schlug", "sich", "auf", ":", "die", "Sze\u00b7ne\u00b7rie", "war", "Ab\u00b7schied", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "PTKVZ", "$.", "ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Leicht zu verstehen. Der bekannte Garten,", "tokens": ["Leicht", "zu", "ver\u00b7ste\u00b7hen", ".", "Der", "be\u00b7kann\u00b7te", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$.", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "und schwankte leise: dann erst kam der T\u00e4nzer.", "tokens": ["und", "schwank\u00b7te", "lei\u00b7se", ":", "dann", "erst", "kam", "der", "T\u00e4n\u00b7zer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "ADV", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht ", "tokens": ["Nicht"], "token_info": ["word"], "pos": ["PTKNEG"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "er ist verkleidet und er wird ein B\u00fcrger", "tokens": ["er", "ist", "ver\u00b7klei\u00b7det", "und", "er", "wird", "ein", "B\u00fcr\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und geht durch seine K\u00fcche in die Wohnung.", "tokens": ["und", "geht", "durch", "sei\u00b7ne", "K\u00fc\u00b7che", "in", "die", "Woh\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Ich will nicht diese halbgef\u00fcllten Masken,", "tokens": ["Ich", "will", "nicht", "die\u00b7se", "halb\u00b7ge\u00b7f\u00fcll\u00b7ten", "Mas\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "lieber die Puppe. Die ist voll. Ich will", "tokens": ["lie\u00b7ber", "die", "Pup\u00b7pe", ".", "Die", "ist", "voll", ".", "Ich", "will"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ART", "NN", "$.", "PDS", "VAFIN", "ADJD", "$.", "PPER", "VMFIN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "den Balg aushalten und den Draht und ihr", "tokens": ["den", "Balg", "aus\u00b7hal\u00b7ten", "und", "den", "Draht", "und", "ihr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "KON", "ART", "NN", "KON", "PPOSAT"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gesicht aus Aussehn. Hier. Ich bin davor.", "tokens": ["Ge\u00b7sicht", "aus", "Aus\u00b7sehn", ".", "Hier", ".", "Ich", "bin", "da\u00b7vor", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$.", "ADV", "$.", "PPER", "VAFIN", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wenn auch die Lampen ausgehn, wenn mir auch", "tokens": ["Wenn", "auch", "die", "Lam\u00b7pen", "aus\u00b7gehn", ",", "wenn", "mir", "auch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "VVINF", "$,", "KOUS", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "gesagt wird: Nichts mehr \u2013, wenn auch von der B\u00fchne", "tokens": ["ge\u00b7sagt", "wird", ":", "Nichts", "mehr", "\u2013", ",", "wenn", "auch", "von", "der", "B\u00fch\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "$.", "PIS", "ADV", "$(", "$,", "KOUS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "das Leere herkommt mit dem grauen Luftzug,", "tokens": ["das", "Lee\u00b7re", "her\u00b7kommt", "mit", "dem", "grau\u00b7en", "Luft\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "wenn auch von meinen stillen Vorfahrn keiner", "tokens": ["wenn", "auch", "von", "mei\u00b7nen", "stil\u00b7len", "Vor\u00b7fahrn", "kei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "mehr mit mir dasitzt, keine Frau, sogar", "tokens": ["mehr", "mit", "mir", "da\u00b7sitzt", ",", "kei\u00b7ne", "Frau", ",", "so\u00b7gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "APPR", "PPER", "VVPP", "$,", "PIAT", "NN", "$,", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "der Knabe nicht mehr mit dem braunen Schielaug:", "tokens": ["der", "Kna\u00b7be", "nicht", "mehr", "mit", "dem", "brau\u00b7nen", "Schiel\u00b7aug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.10": {"text": "Ich bleibe dennoch. Es giebt immer Zuschaun.", "tokens": ["Ich", "blei\u00b7be", "den\u00b7noch", ".", "Es", "giebt", "im\u00b7mer", "Zu\u00b7schaun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "ADV", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "Hab ich nicht recht? Du, der um mich so bitter", "tokens": ["Hab", "ich", "nicht", "recht", "?", "Du", ",", "der", "um", "mich", "so", "bit\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PTKNEG", "ADJD", "$.", "PPER", "$,", "PRELS", "APPR", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "das Leben schmeckte, meines kostend, Vater,", "tokens": ["das", "Le\u00b7ben", "schmeck\u00b7te", ",", "mei\u00b7nes", "kos\u00b7tend", ",", "Va\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPOSAT", "VVPP", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "den ersten tr\u00fcben Aufgu\u00df meines M\u00fcssens,", "tokens": ["den", "ers\u00b7ten", "tr\u00fc\u00b7ben", "Auf\u00b7gu\u00df", "mei\u00b7nes", "M\u00fcs\u00b7sens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "da ich heranwuchs, immer wieder kostend", "tokens": ["da", "ich", "her\u00b7an\u00b7wuchs", ",", "im\u00b7mer", "wie\u00b7der", "kos\u00b7tend"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und, mit dem Nachgeschmack so fremder Zukunft", "tokens": ["und", ",", "mit", "dem", "Nach\u00b7ge\u00b7schmack", "so", "frem\u00b7der", "Zu\u00b7kunft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "APPR", "ART", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "besch\u00e4ftigt, pr\u00fcftest mein beschlagnes Aufschaun, \u2013", "tokens": ["be\u00b7sch\u00e4f\u00b7tigt", ",", "pr\u00fcf\u00b7test", "mein", "be\u00b7schlag\u00b7nes", "Auf\u00b7schaun", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$,", "VVFIN", "PPOSAT", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "der du, mein Vater, seit du tot bist, oft", "tokens": ["der", "du", ",", "mein", "Va\u00b7ter", ",", "seit", "du", "tot", "bist", ",", "oft"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NE", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "in meiner Hoffnung, innen in mir, Angst hast,", "tokens": ["in", "mei\u00b7ner", "Hoff\u00b7nung", ",", "in\u00b7nen", "in", "mir", ",", "Angst", "hast", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "APPR", "PPER", "$,", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "und Gleichmut, wie ihn Tote haben, Reiche", "tokens": ["und", "Gleich\u00b7mut", ",", "wie", "ihn", "To\u00b7te", "ha\u00b7ben", ",", "Rei\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "NN", "$,", "PWAV", "PPER", "NN", "VAFIN", "$,", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "von Gleichmut, aufgiebst f\u00fcr mein bi\u00dfchen Schicksal,", "tokens": ["von", "Gleich\u00b7mut", ",", "auf\u00b7giebst", "f\u00fcr", "mein", "bi\u00df\u00b7chen", "Schick\u00b7sal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "hab ich nicht recht? Und ihr, hab ich nicht recht,", "tokens": ["hab", "ich", "nicht", "recht", "?", "Und", "ihr", ",", "hab", "ich", "nicht", "recht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "$.", "KON", "PPER", "$,", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.12": {"text": "die ihr mich liebtet f\u00fcr den kleinen Anfang", "tokens": ["die", "ihr", "mich", "lieb\u00b7tet", "f\u00fcr", "den", "klei\u00b7nen", "An\u00b7fang"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PRF", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Liebe zu euch, von dem ich immer abkam,", "tokens": ["Lie\u00b7be", "zu", "euch", ",", "von", "dem", "ich", "im\u00b7mer", "ab\u00b7kam", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$,", "APPR", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.14": {"text": "weil mir der Raum in eurem Angesicht,", "tokens": ["weil", "mir", "der", "Raum", "in", "eu\u00b7rem", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "da ich ihn liebte, \u00fcberging in Weltraum,", "tokens": ["da", "ich", "ihn", "lieb\u00b7te", ",", "\u00fc\u00b7ber\u00b7ging", "in", "Welt\u00b7raum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "in dem ihr nicht mehr wart....: wenn mir zumut ist,", "tokens": ["in", "dem", "ihr", "nicht", "mehr", "wart", "....", ":", "wenn", "mir", "zu\u00b7mut", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PTKNEG", "ADV", "VVFIN", "$.", "$.", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.17": {"text": "zu warten vor der Puppenb\u00fchne, nein,", "tokens": ["zu", "war\u00b7ten", "vor", "der", "Pup\u00b7pen\u00b7b\u00fch\u00b7ne", ",", "nein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "$,", "PTKANT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "so v\u00f6llig hinzuschaun, da\u00df, um mein Schauen", "tokens": ["so", "v\u00f6l\u00b7lig", "hin\u00b7zu\u00b7schaun", ",", "da\u00df", ",", "um", "mein", "Schau\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVINF", "$,", "KOUS", "$,", "KOUI", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "am Ende aufzuwiegen, dort als Spieler", "tokens": ["am", "En\u00b7de", "auf\u00b7zu\u00b7wie\u00b7gen", ",", "dort", "als", "Spie\u00b7ler"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "$,", "ADV", "KOUS", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "ein Engel hinmu\u00df, der die B\u00e4lge hochrei\u00dft.", "tokens": ["ein", "En\u00b7gel", "hin\u00b7mu\u00df", ",", "der", "die", "B\u00e4l\u00b7ge", "hoch\u00b7rei\u00dft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.21": {"text": "Engel und Puppe: dann ist endlich Schauspiel.", "tokens": ["En\u00b7gel", "und", "Pup\u00b7pe", ":", "dann", "ist", "end\u00b7lich", "Schau\u00b7spiel", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$.", "ADV", "VAFIN", "ADV", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.22": {"text": "Dann kommt zusammen, was wir immerfort", "tokens": ["Dann", "kommt", "zu\u00b7sam\u00b7men", ",", "was", "wir", "im\u00b7mer\u00b7fort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PTKVZ", "$,", "PRELS", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "entzwein, indem wir da sind. Dann entsteht", "tokens": ["ent\u00b7zwein", ",", "in\u00b7dem", "wir", "da", "sind", ".", "Dann", "ent\u00b7steht"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKVZ", "$,", "KOUS", "PPER", "ADV", "VAFIN", "$.", "ADV", "VVFIN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "aus unsern Jahreszeiten erst der Umkreis", "tokens": ["aus", "un\u00b7sern", "Jah\u00b7res\u00b7zei\u00b7ten", "erst", "der", "Um\u00b7kreis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.25": {"text": "des ganzen Wandelns. \u00dcber uns hin\u00fcber", "tokens": ["des", "gan\u00b7zen", "Wan\u00b7delns", ".", "\u00dc\u00b7ber", "uns", "hin\u00b7\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "APPR", "PPER", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "spielt dann der Engel. Sieh, die Sterbenden,", "tokens": ["spielt", "dann", "der", "En\u00b7gel", ".", "Sieh", ",", "die", "Ster\u00b7ben\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$.", "NE", "$,", "ART", "NN", "$,"], "meter": "+--+-+-+--", "measure": "iambic.tetra.invert"}, "line.27": {"text": "sollten sie nicht vermuten, wie voll Vorwand", "tokens": ["soll\u00b7ten", "sie", "nicht", "ver\u00b7mu\u00b7ten", ",", "wie", "voll", "Vor\u00b7wand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "$,", "PWAV", "ADJD", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.28": {"text": "das alles ist, was wir hier leisten. Alles", "tokens": ["das", "al\u00b7les", "ist", ",", "was", "wir", "hier", "leis\u00b7ten", ".", "Al\u00b7les"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "PIS", "VAFIN", "$,", "PRELS", "PPER", "ADV", "VVINF", "$.", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "ist nicht es selbst. O Stunden in der Kindheit,", "tokens": ["ist", "nicht", "es", "selbst", ".", "O", "Stun\u00b7den", "in", "der", "Kind\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "PPER", "ADV", "$.", "NE", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "da hinter den Figuren mehr als nur", "tokens": ["da", "hin\u00b7ter", "den", "Fi\u00b7gu\u00b7ren", "mehr", "als", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "PIAT", "KOKOM", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Vergangnes war und vor uns nicht die Zukunft.", "tokens": ["Ver\u00b7gang\u00b7nes", "war", "und", "vor", "uns", "nicht", "die", "Zu\u00b7kunft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "KON", "APPR", "PPER", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Wir wuchsen freilich und wir dr\u00e4ngten manchmal,", "tokens": ["Wir", "wuch\u00b7sen", "frei\u00b7lich", "und", "wir", "dr\u00e4ng\u00b7ten", "manch\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "bald gro\u00df zu werden, denen halb zulieb,", "tokens": ["bald", "gro\u00df", "zu", "wer\u00b7den", ",", "de\u00b7nen", "halb", "zu\u00b7lieb", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VAINF", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "die andres nicht mehr hatten, als das Gro\u00dfsein.", "tokens": ["die", "and\u00b7res", "nicht", "mehr", "hat\u00b7ten", ",", "als", "das", "Gro\u00df\u00b7sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PTKNEG", "ADV", "VAFIN", "$,", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Und waren doch, in unserem Alleingehn,", "tokens": ["Und", "wa\u00b7ren", "doch", ",", "in", "un\u00b7se\u00b7rem", "Al\u00b7lein\u00b7gehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.36": {"text": "mit Dauerndem vergn\u00fcgt und standen da", "tokens": ["mit", "Dau\u00b7ern\u00b7dem", "ver\u00b7gn\u00fcgt", "und", "stan\u00b7den", "da"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PAV", "VVPP", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.37": {"text": "im Zwischenraume zwischen Welt und Spielzeug,", "tokens": ["im", "Zwi\u00b7schen\u00b7rau\u00b7me", "zwi\u00b7schen", "Welt", "und", "Spiel\u00b7zeug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.38": {"text": "an einer Stelle, die seit Anbeginn", "tokens": ["an", "ei\u00b7ner", "Stel\u00b7le", ",", "die", "seit", "An\u00b7be\u00b7ginn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "gegr\u00fcndet war f\u00fcr einen reinen Vorgang.", "tokens": ["ge\u00b7gr\u00fcn\u00b7det", "war", "f\u00fcr", "ei\u00b7nen", "rei\u00b7nen", "Vor\u00b7gang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Wer zeigt ein Kind, so wie es steht? Wer stellt", "tokens": ["Wer", "zeigt", "ein", "Kind", ",", "so", "wie", "es", "steht", "?", "Wer", "stellt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN", "$,", "ADV", "KOKOM", "PPER", "VVFIN", "$.", "PWS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "es ins Gestirn und giebt das Ma\u00df des Abstands", "tokens": ["es", "ins", "Ge\u00b7stirn", "und", "giebt", "das", "Ma\u00df", "des", "Ab\u00b7stands"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPRART", "NN", "KON", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ihm in die Hand? Wer macht den Kindertod", "tokens": ["ihm", "in", "die", "Hand", "?", "Wer", "macht", "den", "Kin\u00b7der\u00b7tod"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "$.", "PWS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "aus grauem Brot, das hart wird, \u2013 oder l\u00e4\u00dft", "tokens": ["aus", "grau\u00b7em", "Brot", ",", "das", "hart", "wird", ",", "\u2013", "o\u00b7der", "l\u00e4\u00dft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$,", "$(", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "ihn drin im runden Mund, so wie den Gr\u00f6ps", "tokens": ["ihn", "drin", "im", "run\u00b7den", "Mund", ",", "so", "wie", "den", "Gr\u00f6ps"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPRART", "ADJA", "NN", "$,", "ADV", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "von einem sch\u00f6nen Apfel? ......M\u00f6rder sind", "tokens": ["von", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Ap\u00b7fel", "?", "......", "M\u00f6r\u00b7der", "sind"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "$(", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "leicht einzusehen. Aber dies: den Tod,", "tokens": ["leicht", "ein\u00b7zu\u00b7se\u00b7hen", ".", "A\u00b7ber", "dies", ":", "den", "Tod", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVIZU", "$.", "KON", "PDS", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "den ganzen Tod, noch ", "tokens": ["den", "gan\u00b7zen", "Tod", ",", "noch"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADV"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "sanft zu enthalten und nicht b\u00f6s zu sein,", "tokens": ["sanft", "zu", "ent\u00b7hal\u00b7ten", "und", "nicht", "b\u00f6s", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "KON", "PTKNEG", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.10": {"text": "ist unbeschreiblich.", "tokens": ["ist", "un\u00b7be\u00b7schreib\u00b7lich", "."], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "O B\u00e4ume Lebens, o wann winterlich?", "tokens": ["O", "B\u00e4u\u00b7me", "Le\u00b7bens", ",", "o", "wann", "win\u00b7ter\u00b7lich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "NN", "$,", "FM", "PWAV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wir sind nicht einig. Sind nicht wie die Zug-", "tokens": ["Wir", "sind", "nicht", "ei\u00b7nig", ".", "Sind", "nicht", "wie", "die", "Zug"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$.", "VAFIN", "PTKNEG", "KOKOM", "ART", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "v\u00f6gel verst\u00e4ndigt. \u00dcberholt und sp\u00e4t,", "tokens": ["v\u00f6\u00b7gel", "ver\u00b7st\u00e4n\u00b7digt", ".", "\u00dc\u00b7berh\u00b7olt", "und", "sp\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$.", "NN", "KON", "ADJD", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "so dr\u00e4ngen wir uns pl\u00f6tzlich Winden auf", "tokens": ["so", "dr\u00e4n\u00b7gen", "wir", "uns", "pl\u00f6tz\u00b7lich", "Win\u00b7den", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "NN", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und fallen ein auf teilnahmslosen Teich.", "tokens": ["und", "fal\u00b7len", "ein", "auf", "teil\u00b7nahms\u00b7lo\u00b7sen", "Teich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Bl\u00fchn und verdorrn ist uns zugleich bewu\u00dft.", "tokens": ["Bl\u00fchn", "und", "ver\u00b7dorrn", "ist", "uns", "zu\u00b7gleich", "be\u00b7wu\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.7": {"text": "Und irgendwo gehn L\u00f6wen noch und wissen,", "tokens": ["Und", "ir\u00b7gend\u00b7wo", "gehn", "L\u00f6\u00b7wen", "noch", "und", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NN", "ADV", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "solang sie herrlich sind, von keiner Ohnmacht.", "tokens": ["so\u00b7lang", "sie", "herr\u00b7lich", "sind", ",", "von", "kei\u00b7ner", "Ohn\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VAFIN", "$,", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.12": {"line.1": {"text": "Uns aber, wo wir Eines meinen, ganz,", "tokens": ["Uns", "a\u00b7ber", ",", "wo", "wir", "Ei\u00b7nes", "mei\u00b7nen", ",", "ganz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PWAV", "PPER", "PIS", "VVFIN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ist schon des andern Aufwand f\u00fchlbar. Feindschaft", "tokens": ["ist", "schon", "des", "an\u00b7dern", "Auf\u00b7wand", "f\u00fchl\u00b7bar", ".", "Feind\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "ADJD", "$.", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ist uns das N\u00e4chste. Treten Liebende", "tokens": ["ist", "uns", "das", "N\u00e4chs\u00b7te", ".", "Tre\u00b7ten", "Lie\u00b7ben\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "$.", "ADJA", "NN"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.4": {"text": "nicht immerfort an R\u00e4nder, eins im andern,", "tokens": ["nicht", "im\u00b7mer\u00b7fort", "an", "R\u00e4n\u00b7der", ",", "eins", "im", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "$,", "PIS", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "die sich versprachen Weite, Jagd und Heimat.", "tokens": ["die", "sich", "ver\u00b7spra\u00b7chen", "Wei\u00b7te", ",", "Jagd", "und", "Hei\u00b7mat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "ADJA", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Da wird f\u00fcr eines Augenblickes Zeichnung", "tokens": ["Da", "wird", "f\u00fcr", "ei\u00b7nes", "Au\u00b7gen\u00b7bli\u00b7ckes", "Zeich\u00b7nung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "ein Grund von Gegenteil bereitet, m\u00fchsam,", "tokens": ["ein", "Grund", "von", "Ge\u00b7gen\u00b7teil", "be\u00b7rei\u00b7tet", ",", "m\u00fch\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "da\u00df wir sie s\u00e4hen; denn man ist sehr deutlich", "tokens": ["da\u00df", "wir", "sie", "s\u00e4\u00b7hen", ";", "denn", "man", "ist", "sehr", "deut\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "$.", "KON", "PIS", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "mit uns. Wir kennen den Kontur", "tokens": ["mit", "uns", ".", "Wir", "ken\u00b7nen", "den", "Kon\u00b7tur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$.", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "des F\u00fchlens nicht: nur, was ihn formt von au\u00dfen.", "tokens": ["des", "F\u00fch\u00b7lens", "nicht", ":", "nur", ",", "was", "ihn", "formt", "von", "au\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "$.", "ADV", "$,", "PRELS", "PPER", "VVFIN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Wer sa\u00df nicht bang vor seines Herzens Vorhang?", "tokens": ["Wer", "sa\u00df", "nicht", "bang", "vor", "sei\u00b7nes", "Her\u00b7zens", "Vor\u00b7hang", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ADJD", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Der schlug sich auf: die Szenerie war Abschied.", "tokens": ["Der", "schlug", "sich", "auf", ":", "die", "Sze\u00b7ne\u00b7rie", "war", "Ab\u00b7schied", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "PTKVZ", "$.", "ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Leicht zu verstehen. Der bekannte Garten,", "tokens": ["Leicht", "zu", "ver\u00b7ste\u00b7hen", ".", "Der", "be\u00b7kann\u00b7te", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$.", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "und schwankte leise: dann erst kam der T\u00e4nzer.", "tokens": ["und", "schwank\u00b7te", "lei\u00b7se", ":", "dann", "erst", "kam", "der", "T\u00e4n\u00b7zer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "ADV", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht ", "tokens": ["Nicht"], "token_info": ["word"], "pos": ["PTKNEG"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "er ist verkleidet und er wird ein B\u00fcrger", "tokens": ["er", "ist", "ver\u00b7klei\u00b7det", "und", "er", "wird", "ein", "B\u00fcr\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und geht durch seine K\u00fcche in die Wohnung.", "tokens": ["und", "geht", "durch", "sei\u00b7ne", "K\u00fc\u00b7che", "in", "die", "Woh\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Ich will nicht diese halbgef\u00fcllten Masken,", "tokens": ["Ich", "will", "nicht", "die\u00b7se", "halb\u00b7ge\u00b7f\u00fcll\u00b7ten", "Mas\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "lieber die Puppe. Die ist voll. Ich will", "tokens": ["lie\u00b7ber", "die", "Pup\u00b7pe", ".", "Die", "ist", "voll", ".", "Ich", "will"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ART", "NN", "$.", "PDS", "VAFIN", "ADJD", "$.", "PPER", "VMFIN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "den Balg aushalten und den Draht und ihr", "tokens": ["den", "Balg", "aus\u00b7hal\u00b7ten", "und", "den", "Draht", "und", "ihr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "KON", "ART", "NN", "KON", "PPOSAT"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gesicht aus Aussehn. Hier. Ich bin davor.", "tokens": ["Ge\u00b7sicht", "aus", "Aus\u00b7sehn", ".", "Hier", ".", "Ich", "bin", "da\u00b7vor", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$.", "ADV", "$.", "PPER", "VAFIN", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wenn auch die Lampen ausgehn, wenn mir auch", "tokens": ["Wenn", "auch", "die", "Lam\u00b7pen", "aus\u00b7gehn", ",", "wenn", "mir", "auch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "VVINF", "$,", "KOUS", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "gesagt wird: Nichts mehr \u2013, wenn auch von der B\u00fchne", "tokens": ["ge\u00b7sagt", "wird", ":", "Nichts", "mehr", "\u2013", ",", "wenn", "auch", "von", "der", "B\u00fch\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "$.", "PIS", "ADV", "$(", "$,", "KOUS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "das Leere herkommt mit dem grauen Luftzug,", "tokens": ["das", "Lee\u00b7re", "her\u00b7kommt", "mit", "dem", "grau\u00b7en", "Luft\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "wenn auch von meinen stillen Vorfahrn keiner", "tokens": ["wenn", "auch", "von", "mei\u00b7nen", "stil\u00b7len", "Vor\u00b7fahrn", "kei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "mehr mit mir dasitzt, keine Frau, sogar", "tokens": ["mehr", "mit", "mir", "da\u00b7sitzt", ",", "kei\u00b7ne", "Frau", ",", "so\u00b7gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "APPR", "PPER", "VVPP", "$,", "PIAT", "NN", "$,", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "der Knabe nicht mehr mit dem braunen Schielaug:", "tokens": ["der", "Kna\u00b7be", "nicht", "mehr", "mit", "dem", "brau\u00b7nen", "Schiel\u00b7aug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.10": {"text": "Ich bleibe dennoch. Es giebt immer Zuschaun.", "tokens": ["Ich", "blei\u00b7be", "den\u00b7noch", ".", "Es", "giebt", "im\u00b7mer", "Zu\u00b7schaun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "ADV", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.19": {"line.1": {"text": "Hab ich nicht recht? Du, der um mich so bitter", "tokens": ["Hab", "ich", "nicht", "recht", "?", "Du", ",", "der", "um", "mich", "so", "bit\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PTKNEG", "ADJD", "$.", "PPER", "$,", "PRELS", "APPR", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "das Leben schmeckte, meines kostend, Vater,", "tokens": ["das", "Le\u00b7ben", "schmeck\u00b7te", ",", "mei\u00b7nes", "kos\u00b7tend", ",", "Va\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPOSAT", "VVPP", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "den ersten tr\u00fcben Aufgu\u00df meines M\u00fcssens,", "tokens": ["den", "ers\u00b7ten", "tr\u00fc\u00b7ben", "Auf\u00b7gu\u00df", "mei\u00b7nes", "M\u00fcs\u00b7sens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "da ich heranwuchs, immer wieder kostend", "tokens": ["da", "ich", "her\u00b7an\u00b7wuchs", ",", "im\u00b7mer", "wie\u00b7der", "kos\u00b7tend"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und, mit dem Nachgeschmack so fremder Zukunft", "tokens": ["und", ",", "mit", "dem", "Nach\u00b7ge\u00b7schmack", "so", "frem\u00b7der", "Zu\u00b7kunft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "APPR", "ART", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "besch\u00e4ftigt, pr\u00fcftest mein beschlagnes Aufschaun, \u2013", "tokens": ["be\u00b7sch\u00e4f\u00b7tigt", ",", "pr\u00fcf\u00b7test", "mein", "be\u00b7schlag\u00b7nes", "Auf\u00b7schaun", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$,", "VVFIN", "PPOSAT", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "der du, mein Vater, seit du tot bist, oft", "tokens": ["der", "du", ",", "mein", "Va\u00b7ter", ",", "seit", "du", "tot", "bist", ",", "oft"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NE", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "in meiner Hoffnung, innen in mir, Angst hast,", "tokens": ["in", "mei\u00b7ner", "Hoff\u00b7nung", ",", "in\u00b7nen", "in", "mir", ",", "Angst", "hast", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "APPR", "PPER", "$,", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "und Gleichmut, wie ihn Tote haben, Reiche", "tokens": ["und", "Gleich\u00b7mut", ",", "wie", "ihn", "To\u00b7te", "ha\u00b7ben", ",", "Rei\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "NN", "$,", "PWAV", "PPER", "NN", "VAFIN", "$,", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "von Gleichmut, aufgiebst f\u00fcr mein bi\u00dfchen Schicksal,", "tokens": ["von", "Gleich\u00b7mut", ",", "auf\u00b7giebst", "f\u00fcr", "mein", "bi\u00df\u00b7chen", "Schick\u00b7sal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "hab ich nicht recht? Und ihr, hab ich nicht recht,", "tokens": ["hab", "ich", "nicht", "recht", "?", "Und", "ihr", ",", "hab", "ich", "nicht", "recht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "$.", "KON", "PPER", "$,", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.12": {"text": "die ihr mich liebtet f\u00fcr den kleinen Anfang", "tokens": ["die", "ihr", "mich", "lieb\u00b7tet", "f\u00fcr", "den", "klei\u00b7nen", "An\u00b7fang"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PRF", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Liebe zu euch, von dem ich immer abkam,", "tokens": ["Lie\u00b7be", "zu", "euch", ",", "von", "dem", "ich", "im\u00b7mer", "ab\u00b7kam", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$,", "APPR", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.14": {"text": "weil mir der Raum in eurem Angesicht,", "tokens": ["weil", "mir", "der", "Raum", "in", "eu\u00b7rem", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "da ich ihn liebte, \u00fcberging in Weltraum,", "tokens": ["da", "ich", "ihn", "lieb\u00b7te", ",", "\u00fc\u00b7ber\u00b7ging", "in", "Welt\u00b7raum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "in dem ihr nicht mehr wart....: wenn mir zumut ist,", "tokens": ["in", "dem", "ihr", "nicht", "mehr", "wart", "....", ":", "wenn", "mir", "zu\u00b7mut", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PTKNEG", "ADV", "VVFIN", "$.", "$.", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.17": {"text": "zu warten vor der Puppenb\u00fchne, nein,", "tokens": ["zu", "war\u00b7ten", "vor", "der", "Pup\u00b7pen\u00b7b\u00fch\u00b7ne", ",", "nein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "$,", "PTKANT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "so v\u00f6llig hinzuschaun, da\u00df, um mein Schauen", "tokens": ["so", "v\u00f6l\u00b7lig", "hin\u00b7zu\u00b7schaun", ",", "da\u00df", ",", "um", "mein", "Schau\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVINF", "$,", "KOUS", "$,", "KOUI", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "am Ende aufzuwiegen, dort als Spieler", "tokens": ["am", "En\u00b7de", "auf\u00b7zu\u00b7wie\u00b7gen", ",", "dort", "als", "Spie\u00b7ler"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "$,", "ADV", "KOUS", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "ein Engel hinmu\u00df, der die B\u00e4lge hochrei\u00dft.", "tokens": ["ein", "En\u00b7gel", "hin\u00b7mu\u00df", ",", "der", "die", "B\u00e4l\u00b7ge", "hoch\u00b7rei\u00dft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.21": {"text": "Engel und Puppe: dann ist endlich Schauspiel.", "tokens": ["En\u00b7gel", "und", "Pup\u00b7pe", ":", "dann", "ist", "end\u00b7lich", "Schau\u00b7spiel", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$.", "ADV", "VAFIN", "ADV", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.22": {"text": "Dann kommt zusammen, was wir immerfort", "tokens": ["Dann", "kommt", "zu\u00b7sam\u00b7men", ",", "was", "wir", "im\u00b7mer\u00b7fort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PTKVZ", "$,", "PRELS", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "entzwein, indem wir da sind. Dann entsteht", "tokens": ["ent\u00b7zwein", ",", "in\u00b7dem", "wir", "da", "sind", ".", "Dann", "ent\u00b7steht"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKVZ", "$,", "KOUS", "PPER", "ADV", "VAFIN", "$.", "ADV", "VVFIN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "aus unsern Jahreszeiten erst der Umkreis", "tokens": ["aus", "un\u00b7sern", "Jah\u00b7res\u00b7zei\u00b7ten", "erst", "der", "Um\u00b7kreis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.25": {"text": "des ganzen Wandelns. \u00dcber uns hin\u00fcber", "tokens": ["des", "gan\u00b7zen", "Wan\u00b7delns", ".", "\u00dc\u00b7ber", "uns", "hin\u00b7\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "APPR", "PPER", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "spielt dann der Engel. Sieh, die Sterbenden,", "tokens": ["spielt", "dann", "der", "En\u00b7gel", ".", "Sieh", ",", "die", "Ster\u00b7ben\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$.", "NE", "$,", "ART", "NN", "$,"], "meter": "+--+-+-+--", "measure": "iambic.tetra.invert"}, "line.27": {"text": "sollten sie nicht vermuten, wie voll Vorwand", "tokens": ["soll\u00b7ten", "sie", "nicht", "ver\u00b7mu\u00b7ten", ",", "wie", "voll", "Vor\u00b7wand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "$,", "PWAV", "ADJD", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.28": {"text": "das alles ist, was wir hier leisten. Alles", "tokens": ["das", "al\u00b7les", "ist", ",", "was", "wir", "hier", "leis\u00b7ten", ".", "Al\u00b7les"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "PIS", "VAFIN", "$,", "PRELS", "PPER", "ADV", "VVINF", "$.", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "ist nicht es selbst. O Stunden in der Kindheit,", "tokens": ["ist", "nicht", "es", "selbst", ".", "O", "Stun\u00b7den", "in", "der", "Kind\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "PPER", "ADV", "$.", "NE", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "da hinter den Figuren mehr als nur", "tokens": ["da", "hin\u00b7ter", "den", "Fi\u00b7gu\u00b7ren", "mehr", "als", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "PIAT", "KOKOM", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Vergangnes war und vor uns nicht die Zukunft.", "tokens": ["Ver\u00b7gang\u00b7nes", "war", "und", "vor", "uns", "nicht", "die", "Zu\u00b7kunft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "KON", "APPR", "PPER", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Wir wuchsen freilich und wir dr\u00e4ngten manchmal,", "tokens": ["Wir", "wuch\u00b7sen", "frei\u00b7lich", "und", "wir", "dr\u00e4ng\u00b7ten", "manch\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "bald gro\u00df zu werden, denen halb zulieb,", "tokens": ["bald", "gro\u00df", "zu", "wer\u00b7den", ",", "de\u00b7nen", "halb", "zu\u00b7lieb", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VAINF", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "die andres nicht mehr hatten, als das Gro\u00dfsein.", "tokens": ["die", "and\u00b7res", "nicht", "mehr", "hat\u00b7ten", ",", "als", "das", "Gro\u00df\u00b7sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PTKNEG", "ADV", "VAFIN", "$,", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Und waren doch, in unserem Alleingehn,", "tokens": ["Und", "wa\u00b7ren", "doch", ",", "in", "un\u00b7se\u00b7rem", "Al\u00b7lein\u00b7gehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.36": {"text": "mit Dauerndem vergn\u00fcgt und standen da", "tokens": ["mit", "Dau\u00b7ern\u00b7dem", "ver\u00b7gn\u00fcgt", "und", "stan\u00b7den", "da"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PAV", "VVPP", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.37": {"text": "im Zwischenraume zwischen Welt und Spielzeug,", "tokens": ["im", "Zwi\u00b7schen\u00b7rau\u00b7me", "zwi\u00b7schen", "Welt", "und", "Spiel\u00b7zeug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.38": {"text": "an einer Stelle, die seit Anbeginn", "tokens": ["an", "ei\u00b7ner", "Stel\u00b7le", ",", "die", "seit", "An\u00b7be\u00b7ginn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "gegr\u00fcndet war f\u00fcr einen reinen Vorgang.", "tokens": ["ge\u00b7gr\u00fcn\u00b7det", "war", "f\u00fcr", "ei\u00b7nen", "rei\u00b7nen", "Vor\u00b7gang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Wer zeigt ein Kind, so wie es steht? Wer stellt", "tokens": ["Wer", "zeigt", "ein", "Kind", ",", "so", "wie", "es", "steht", "?", "Wer", "stellt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN", "$,", "ADV", "KOKOM", "PPER", "VVFIN", "$.", "PWS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "es ins Gestirn und giebt das Ma\u00df des Abstands", "tokens": ["es", "ins", "Ge\u00b7stirn", "und", "giebt", "das", "Ma\u00df", "des", "Ab\u00b7stands"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPRART", "NN", "KON", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ihm in die Hand? Wer macht den Kindertod", "tokens": ["ihm", "in", "die", "Hand", "?", "Wer", "macht", "den", "Kin\u00b7der\u00b7tod"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "$.", "PWS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "aus grauem Brot, das hart wird, \u2013 oder l\u00e4\u00dft", "tokens": ["aus", "grau\u00b7em", "Brot", ",", "das", "hart", "wird", ",", "\u2013", "o\u00b7der", "l\u00e4\u00dft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$,", "$(", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "ihn drin im runden Mund, so wie den Gr\u00f6ps", "tokens": ["ihn", "drin", "im", "run\u00b7den", "Mund", ",", "so", "wie", "den", "Gr\u00f6ps"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPRART", "ADJA", "NN", "$,", "ADV", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "von einem sch\u00f6nen Apfel? ......M\u00f6rder sind", "tokens": ["von", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Ap\u00b7fel", "?", "......", "M\u00f6r\u00b7der", "sind"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "$(", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "leicht einzusehen. Aber dies: den Tod,", "tokens": ["leicht", "ein\u00b7zu\u00b7se\u00b7hen", ".", "A\u00b7ber", "dies", ":", "den", "Tod", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVIZU", "$.", "KON", "PDS", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "den ganzen Tod, noch ", "tokens": ["den", "gan\u00b7zen", "Tod", ",", "noch"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADV"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "sanft zu enthalten und nicht b\u00f6s zu sein,", "tokens": ["sanft", "zu", "ent\u00b7hal\u00b7ten", "und", "nicht", "b\u00f6s", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "KON", "PTKNEG", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.10": {"text": "ist unbeschreiblich.", "tokens": ["ist", "un\u00b7be\u00b7schreib\u00b7lich", "."], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}}}}}