{"textgrid.poem.44573": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "Appellation an die Wirklichkeit", "genre": "verse", "period": "N.A.", "pub_year": 1849, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Weiland Alexander dem Gro\u00dfen", "tokens": ["Wei\u00b7land", "A\u00b7lex\u00b7an\u00b7der", "dem", "Gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "ART", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "War unter des Hauses Genossen", "tokens": ["War", "un\u00b7ter", "des", "Hau\u00b7ses", "Ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Ein Arzt von hoher Kunst,", "tokens": ["Ein", "Arzt", "von", "ho\u00b7her", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Nur voll von der Eitelkeit Dunst;", "tokens": ["Nur", "voll", "von", "der", "Ei\u00b7tel\u00b7keit", "Dunst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Hielt Menschenwert viel zu klein,", "tokens": ["Hielt", "Men\u00b7schen\u00b7wert", "viel", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "D\u00fcnkt sich ein Gott zu sein.", "tokens": ["D\u00fcnkt", "sich", "ein", "Gott", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Da lie\u00df der K\u00f6nig zu Nacht", "tokens": ["Da", "lie\u00df", "der", "K\u00f6\u00b7nig", "zu", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "R\u00fcsten ein Mahl mit Pracht,", "tokens": ["R\u00fcs\u00b7ten", "ein", "Mahl", "mit", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "Setzt sich samt den anderen G\u00e4sten", "tokens": ["Setzt", "sich", "samt", "den", "an\u00b7de\u00b7ren", "G\u00e4s\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.10": {"text": "Und schmaust von dem Feinsten und Besten.", "tokens": ["Und", "schmaust", "von", "dem", "Feins\u00b7ten", "und", "Bes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "KON", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.11": {"text": "Nur vor den Arzt allein", "tokens": ["Nur", "vor", "den", "Arzt", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Setzt man ein Tischchen klein,", "tokens": ["Setzt", "man", "ein", "Tischchen", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.13": {"text": "Wo statt nahrhafterer Speisen", "tokens": ["Wo", "statt", "nahr\u00b7haf\u00b7te\u00b7rer", "Spei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Ihn S\u00e4nger mit Liedern preisen,", "tokens": ["Ihn", "S\u00e4n\u00b7ger", "mit", "Lie\u00b7dern", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.15": {"text": "Und Knaben, das Rauchfa\u00df in Brand,", "tokens": ["Und", "Kna\u00b7ben", ",", "das", "Rauch\u00b7fa\u00df", "in", "Brand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.16": {"text": "Ihm opfern mit emsiger Hand.", "tokens": ["Ihm", "op\u00b7fern", "mit", "em\u00b7si\u00b7ger", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.17": {"text": "Da wird der Arzt denn inne", "tokens": ["Da", "wird", "der", "Arzt", "denn", "in\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "PTKVZ"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Durchs Zeugnis der eigenen Sinne,", "tokens": ["Durchs", "Zeug\u00b7nis", "der", "ei\u00b7ge\u00b7nen", "Sin\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.19": {"text": "Da\u00df er ein Mensch und kein Gott;", "tokens": ["Da\u00df", "er", "ein", "Mensch", "und", "kein", "Gott", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "PIAT", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.20": {"text": "Geheilt hat ihn Hunger und Spott.", "tokens": ["Ge\u00b7heilt", "hat", "ihn", "Hun\u00b7ger", "und", "Spott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.21": {"text": "Ihr machts mit mir und den andern", "tokens": ["Ihr", "machts", "mit", "mir", "und", "den", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "KON", "ART", "ADJA"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.22": {"text": "Ein wenig gleich Alexandern:", "tokens": ["Ein", "we\u00b7nig", "gleich", "A\u00b7lex\u00b7an\u00b7dern", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "NE", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "Habt mich gelobt und geehrt,", "tokens": ["Habt", "mich", "ge\u00b7lobt", "und", "ge\u00b7ehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "KON", "VVPP", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.24": {"text": "Schien jeden Preises euch wert.", "tokens": ["Schien", "je\u00b7den", "Prei\u00b7ses", "euch", "wert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PPER", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.25": {"text": "Doch bin ich kein Narr und kein Gott,", "tokens": ["Doch", "bin", "ich", "kein", "Narr", "und", "kein", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.26": {"text": "Zuviel grenzt immer an Spott,", "tokens": ["Zu\u00b7viel", "grenzt", "im\u00b7mer", "an", "Spott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.27": {"text": "Hab lange genug gesessen,", "tokens": ["Hab", "lan\u00b7ge", "ge\u00b7nug", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.28": {"text": "M\u00f6cht auch mit den andern essen.", "tokens": ["M\u00f6cht", "auch", "mit", "den", "an\u00b7dern", "es\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Weiland Alexander dem Gro\u00dfen", "tokens": ["Wei\u00b7land", "A\u00b7lex\u00b7an\u00b7der", "dem", "Gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "ART", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "War unter des Hauses Genossen", "tokens": ["War", "un\u00b7ter", "des", "Hau\u00b7ses", "Ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Ein Arzt von hoher Kunst,", "tokens": ["Ein", "Arzt", "von", "ho\u00b7her", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Nur voll von der Eitelkeit Dunst;", "tokens": ["Nur", "voll", "von", "der", "Ei\u00b7tel\u00b7keit", "Dunst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Hielt Menschenwert viel zu klein,", "tokens": ["Hielt", "Men\u00b7schen\u00b7wert", "viel", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "D\u00fcnkt sich ein Gott zu sein.", "tokens": ["D\u00fcnkt", "sich", "ein", "Gott", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Da lie\u00df der K\u00f6nig zu Nacht", "tokens": ["Da", "lie\u00df", "der", "K\u00f6\u00b7nig", "zu", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "R\u00fcsten ein Mahl mit Pracht,", "tokens": ["R\u00fcs\u00b7ten", "ein", "Mahl", "mit", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "Setzt sich samt den anderen G\u00e4sten", "tokens": ["Setzt", "sich", "samt", "den", "an\u00b7de\u00b7ren", "G\u00e4s\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.10": {"text": "Und schmaust von dem Feinsten und Besten.", "tokens": ["Und", "schmaust", "von", "dem", "Feins\u00b7ten", "und", "Bes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "KON", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.11": {"text": "Nur vor den Arzt allein", "tokens": ["Nur", "vor", "den", "Arzt", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Setzt man ein Tischchen klein,", "tokens": ["Setzt", "man", "ein", "Tischchen", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.13": {"text": "Wo statt nahrhafterer Speisen", "tokens": ["Wo", "statt", "nahr\u00b7haf\u00b7te\u00b7rer", "Spei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Ihn S\u00e4nger mit Liedern preisen,", "tokens": ["Ihn", "S\u00e4n\u00b7ger", "mit", "Lie\u00b7dern", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.15": {"text": "Und Knaben, das Rauchfa\u00df in Brand,", "tokens": ["Und", "Kna\u00b7ben", ",", "das", "Rauch\u00b7fa\u00df", "in", "Brand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.16": {"text": "Ihm opfern mit emsiger Hand.", "tokens": ["Ihm", "op\u00b7fern", "mit", "em\u00b7si\u00b7ger", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.17": {"text": "Da wird der Arzt denn inne", "tokens": ["Da", "wird", "der", "Arzt", "denn", "in\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "PTKVZ"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Durchs Zeugnis der eigenen Sinne,", "tokens": ["Durchs", "Zeug\u00b7nis", "der", "ei\u00b7ge\u00b7nen", "Sin\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.19": {"text": "Da\u00df er ein Mensch und kein Gott;", "tokens": ["Da\u00df", "er", "ein", "Mensch", "und", "kein", "Gott", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "PIAT", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.20": {"text": "Geheilt hat ihn Hunger und Spott.", "tokens": ["Ge\u00b7heilt", "hat", "ihn", "Hun\u00b7ger", "und", "Spott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.21": {"text": "Ihr machts mit mir und den andern", "tokens": ["Ihr", "machts", "mit", "mir", "und", "den", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "KON", "ART", "ADJA"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.22": {"text": "Ein wenig gleich Alexandern:", "tokens": ["Ein", "we\u00b7nig", "gleich", "A\u00b7lex\u00b7an\u00b7dern", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "NE", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "Habt mich gelobt und geehrt,", "tokens": ["Habt", "mich", "ge\u00b7lobt", "und", "ge\u00b7ehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "KON", "VVPP", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.24": {"text": "Schien jeden Preises euch wert.", "tokens": ["Schien", "je\u00b7den", "Prei\u00b7ses", "euch", "wert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PPER", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.25": {"text": "Doch bin ich kein Narr und kein Gott,", "tokens": ["Doch", "bin", "ich", "kein", "Narr", "und", "kein", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.26": {"text": "Zuviel grenzt immer an Spott,", "tokens": ["Zu\u00b7viel", "grenzt", "im\u00b7mer", "an", "Spott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.27": {"text": "Hab lange genug gesessen,", "tokens": ["Hab", "lan\u00b7ge", "ge\u00b7nug", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.28": {"text": "M\u00f6cht auch mit den andern essen.", "tokens": ["M\u00f6cht", "auch", "mit", "den", "an\u00b7dern", "es\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}