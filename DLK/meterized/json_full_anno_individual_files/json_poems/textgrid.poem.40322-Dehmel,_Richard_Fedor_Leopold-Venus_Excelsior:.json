{"textgrid.poem.40322": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "Venus Excelsior:", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich tr\u00e4ume oft von einer bleichen Rose.", "tokens": ["Ich", "tr\u00e4u\u00b7me", "oft", "von", "ei\u00b7ner", "blei\u00b7chen", "Ro\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hell ragt ein Berg; sie bl\u00fcht in seinem Schatten,", "tokens": ["Hell", "ragt", "ein", "Berg", ";", "sie", "bl\u00fcht", "in", "sei\u00b7nem", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "zum fernen Licht aufschmachtend mit dem matten", "tokens": ["zum", "fer\u00b7nen", "Licht", "auf\u00b7schmach\u00b7tend", "mit", "dem", "mat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Traumblumenblick aus ihrem dunklen Loose.", "tokens": ["Traum\u00b7blu\u00b7men\u00b7blick", "aus", "ih\u00b7rem", "dunk\u00b7len", "Loo\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Dann bangt sie mich; tief stockt mein Schritt im Moose.", "tokens": ["Dann", "bangt", "sie", "mich", ";", "tief", "stockt", "mein", "Schritt", "im", "Moo\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$.", "ADJD", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+++-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Doch weiter mu\u00df ich, mu\u00df das Ziel erreichen,", "tokens": ["Doch", "wei\u00b7ter", "mu\u00df", "ich", ",", "mu\u00df", "das", "Ziel", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "$,", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "den Gipfel mit den immergr\u00fcnen Eichen;", "tokens": ["den", "Gip\u00b7fel", "mit", "den", "im\u00b7mer\u00b7gr\u00fc\u00b7nen", "Ei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "so steh ich schwankend zwischen Berg und Rose.", "tokens": ["so", "steh", "ich", "schwan\u00b7kend", "zwi\u00b7schen", "Berg", "und", "Ro\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Denn wie sich auch mein Fu\u00df bem\u00fcht zu k\u00e4mpfen,", "tokens": ["Denn", "wie", "sich", "auch", "mein", "Fu\u00df", "be\u00b7m\u00fcht", "zu", "k\u00e4mp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "ADV", "PPOSAT", "NN", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ich kann die s\u00fc\u00dfe Sehnsucht nicht mehr d\u00e4mpfen,", "tokens": ["ich", "kann", "die", "s\u00fc\u00b7\u00dfe", "Sehn\u00b7sucht", "nicht", "mehr", "d\u00e4mp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "aus ihrem Kelch den edlen Duft zu schl\u00fcrfen.", "tokens": ["aus", "ih\u00b7rem", "Kelch", "den", "ed\u00b7len", "Duft", "zu", "schl\u00fcr\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Da \u2013: Fl\u00fcgel \u2013: frei! \u2013 und an der Brust die Blume!", "tokens": ["Da", "\u2013", ":", "Fl\u00fc\u00b7gel", "\u2013", ":", "frei", "!", "\u2013", "und", "an", "der", "Brust", "die", "Blu\u00b7me", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "$.", "NN", "$(", "$.", "ADJD", "$.", "$(", "KON", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Schon naht der Hain mit seinem Heiligtume,", "tokens": ["Schon", "naht", "der", "Hain", "mit", "sei\u00b7nem", "Hei\u00b7lig\u00b7tu\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wo auch die Rosen immergr\u00fcnen d\u00fcrfen.", "tokens": ["wo", "auch", "die", "Ro\u00b7sen", "im\u00b7mer\u00b7gr\u00fc\u00b7nen", "d\u00fcr\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.6": {"line.1": {"text": "Aller Wunder wundersamstes,", "tokens": ["Al\u00b7ler", "Wun\u00b7der", "wun\u00b7der\u00b7sams\u00b7tes", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wie ergr\u00fcnd'ich dich, du Macht,", "tokens": ["wie", "er\u00b7gr\u00fcn\u00b7d'\u00b7ich", "dich", ",", "du", "Macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "$,", "PPER", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "die du uns den Lichtweg bahntest,", "tokens": ["die", "du", "uns", "den", "Licht\u00b7weg", "bahn\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seelenwelt, geh\u00fcllt in Nacht!", "tokens": ["See\u00b7len\u00b7welt", ",", "ge\u00b7h\u00fcllt", "in", "Nacht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVPP", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Du, o Du, welch Flehn, welch Stammeln", "tokens": ["Du", ",", "o", "Du", ",", "welch", "Flehn", ",", "welch", "Stam\u00b7meln"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "FM", "PPER", "$,", "PWAT", "NN", "$,", "PWAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "doppelter Bew\u00e4ltigung:", "tokens": ["dop\u00b7pel\u00b7ter", "Be\u00b7w\u00e4l\u00b7ti\u00b7gung", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Seel in Seele st\u00fcrzt zusammen,", "tokens": ["Seel", "in", "See\u00b7le", "st\u00fcrzt", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "D\u00e4mmerung in D\u00e4mmerung.", "tokens": ["D\u00e4m\u00b7me\u00b7rung", "in", "D\u00e4m\u00b7me\u00b7rung", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+---+--", "measure": "dactylic.init"}}, "stanza.8": {"line.1": {"text": "Seele, Seele, wie entbrannten", "tokens": ["See\u00b7le", ",", "See\u00b7le", ",", "wie", "ent\u00b7brann\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "PWAV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "angstvoll dein und mein Gesicht,", "tokens": ["angst\u00b7voll", "dein", "und", "mein", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "bis wir ahnten und erkannten:", "tokens": ["bis", "wir", "ahn\u00b7ten", "und", "er\u00b7kann\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "aus der D\u00e4mmerwelt wird Licht!", "tokens": ["aus", "der", "D\u00e4m\u00b7mer\u00b7welt", "wird", "Licht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Fremde Seele, mir erzitternde,", "tokens": ["Frem\u00b7de", "See\u00b7le", ",", "mir", "er\u00b7zit\u00b7tern\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PPER", "ADJA", "$,"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "mir aus all der Seelen Schaar,", "tokens": ["mir", "aus", "all", "der", "See\u00b7len", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welt, die meine Welt ersch\u00fctterte,", "tokens": ["Welt", ",", "die", "mei\u00b7ne", "Welt", "er\u00b7sch\u00fct\u00b7ter\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "mich verwandelnd ganz und gar,", "tokens": ["mich", "ver\u00b7wan\u00b7delnd", "ganz", "und", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "ADV", "KON", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "bis aus unserm bangen Bunde", "tokens": ["bis", "aus", "un\u00b7serm", "ban\u00b7gen", "Bun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auch das letzte Staunen wich \u2013", "tokens": ["auch", "das", "letz\u00b7te", "Stau\u00b7nen", "wich", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ja, noch lebst du mir im Grunde,", "tokens": ["ja", ",", "noch", "lebst", "du", "mir", "im", "Grun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "PPER", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "lauschend, wie dein Blutgeist mich", "tokens": ["lau\u00b7schend", ",", "wie", "dein", "Blut\u00b7geist", "mich"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PWAV", "PPOSAT", "NN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "aus dem K\u00f6rperbann der Erde", "tokens": ["aus", "dem", "K\u00f6r\u00b7per\u00b7bann", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "los und in ein Lichtreich rang,", "tokens": ["los", "und", "in", "ein", "Lich\u00b7treich", "rang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wo wir stammelten: es werde!", "tokens": ["wo", "wir", "stam\u00b7mel\u00b7ten", ":", "es", "wer\u00b7de", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$.", "PPER", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wo auch ", "tokens": ["wo", "auch"], "token_info": ["word", "word"], "pos": ["PWAV", "ADV"], "meter": "-+", "measure": "iambic.single"}}, "stanza.12": {"line.1": {"text": "Ich tr\u00e4ume oft von einer bleichen Rose.", "tokens": ["Ich", "tr\u00e4u\u00b7me", "oft", "von", "ei\u00b7ner", "blei\u00b7chen", "Ro\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hell ragt ein Berg; sie bl\u00fcht in seinem Schatten,", "tokens": ["Hell", "ragt", "ein", "Berg", ";", "sie", "bl\u00fcht", "in", "sei\u00b7nem", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "zum fernen Licht aufschmachtend mit dem matten", "tokens": ["zum", "fer\u00b7nen", "Licht", "auf\u00b7schmach\u00b7tend", "mit", "dem", "mat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Traumblumenblick aus ihrem dunklen Loose.", "tokens": ["Traum\u00b7blu\u00b7men\u00b7blick", "aus", "ih\u00b7rem", "dunk\u00b7len", "Loo\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Dann bangt sie mich; tief stockt mein Schritt im Moose.", "tokens": ["Dann", "bangt", "sie", "mich", ";", "tief", "stockt", "mein", "Schritt", "im", "Moo\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$.", "ADJD", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+++-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Doch weiter mu\u00df ich, mu\u00df das Ziel erreichen,", "tokens": ["Doch", "wei\u00b7ter", "mu\u00df", "ich", ",", "mu\u00df", "das", "Ziel", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "$,", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "den Gipfel mit den immergr\u00fcnen Eichen;", "tokens": ["den", "Gip\u00b7fel", "mit", "den", "im\u00b7mer\u00b7gr\u00fc\u00b7nen", "Ei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "so steh ich schwankend zwischen Berg und Rose.", "tokens": ["so", "steh", "ich", "schwan\u00b7kend", "zwi\u00b7schen", "Berg", "und", "Ro\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Denn wie sich auch mein Fu\u00df bem\u00fcht zu k\u00e4mpfen,", "tokens": ["Denn", "wie", "sich", "auch", "mein", "Fu\u00df", "be\u00b7m\u00fcht", "zu", "k\u00e4mp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "ADV", "PPOSAT", "NN", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ich kann die s\u00fc\u00dfe Sehnsucht nicht mehr d\u00e4mpfen,", "tokens": ["ich", "kann", "die", "s\u00fc\u00b7\u00dfe", "Sehn\u00b7sucht", "nicht", "mehr", "d\u00e4mp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "aus ihrem Kelch den edlen Duft zu schl\u00fcrfen.", "tokens": ["aus", "ih\u00b7rem", "Kelch", "den", "ed\u00b7len", "Duft", "zu", "schl\u00fcr\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Da \u2013: Fl\u00fcgel \u2013: frei! \u2013 und an der Brust die Blume!", "tokens": ["Da", "\u2013", ":", "Fl\u00fc\u00b7gel", "\u2013", ":", "frei", "!", "\u2013", "und", "an", "der", "Brust", "die", "Blu\u00b7me", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "$.", "NN", "$(", "$.", "ADJD", "$.", "$(", "KON", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Schon naht der Hain mit seinem Heiligtume,", "tokens": ["Schon", "naht", "der", "Hain", "mit", "sei\u00b7nem", "Hei\u00b7lig\u00b7tu\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wo auch die Rosen immergr\u00fcnen d\u00fcrfen.", "tokens": ["wo", "auch", "die", "Ro\u00b7sen", "im\u00b7mer\u00b7gr\u00fc\u00b7nen", "d\u00fcr\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.17": {"line.1": {"text": "Aller Wunder wundersamstes,", "tokens": ["Al\u00b7ler", "Wun\u00b7der", "wun\u00b7der\u00b7sams\u00b7tes", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wie ergr\u00fcnd'ich dich, du Macht,", "tokens": ["wie", "er\u00b7gr\u00fcn\u00b7d'\u00b7ich", "dich", ",", "du", "Macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "$,", "PPER", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "die du uns den Lichtweg bahntest,", "tokens": ["die", "du", "uns", "den", "Licht\u00b7weg", "bahn\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seelenwelt, geh\u00fcllt in Nacht!", "tokens": ["See\u00b7len\u00b7welt", ",", "ge\u00b7h\u00fcllt", "in", "Nacht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVPP", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Du, o Du, welch Flehn, welch Stammeln", "tokens": ["Du", ",", "o", "Du", ",", "welch", "Flehn", ",", "welch", "Stam\u00b7meln"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "FM", "PPER", "$,", "PWAT", "NN", "$,", "PWAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "doppelter Bew\u00e4ltigung:", "tokens": ["dop\u00b7pel\u00b7ter", "Be\u00b7w\u00e4l\u00b7ti\u00b7gung", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Seel in Seele st\u00fcrzt zusammen,", "tokens": ["Seel", "in", "See\u00b7le", "st\u00fcrzt", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "D\u00e4mmerung in D\u00e4mmerung.", "tokens": ["D\u00e4m\u00b7me\u00b7rung", "in", "D\u00e4m\u00b7me\u00b7rung", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+---+--", "measure": "dactylic.init"}}, "stanza.19": {"line.1": {"text": "Seele, Seele, wie entbrannten", "tokens": ["See\u00b7le", ",", "See\u00b7le", ",", "wie", "ent\u00b7brann\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "PWAV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "angstvoll dein und mein Gesicht,", "tokens": ["angst\u00b7voll", "dein", "und", "mein", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "bis wir ahnten und erkannten:", "tokens": ["bis", "wir", "ahn\u00b7ten", "und", "er\u00b7kann\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "aus der D\u00e4mmerwelt wird Licht!", "tokens": ["aus", "der", "D\u00e4m\u00b7mer\u00b7welt", "wird", "Licht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Fremde Seele, mir erzitternde,", "tokens": ["Frem\u00b7de", "See\u00b7le", ",", "mir", "er\u00b7zit\u00b7tern\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PPER", "ADJA", "$,"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "mir aus all der Seelen Schaar,", "tokens": ["mir", "aus", "all", "der", "See\u00b7len", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welt, die meine Welt ersch\u00fctterte,", "tokens": ["Welt", ",", "die", "mei\u00b7ne", "Welt", "er\u00b7sch\u00fct\u00b7ter\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "mich verwandelnd ganz und gar,", "tokens": ["mich", "ver\u00b7wan\u00b7delnd", "ganz", "und", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "ADV", "KON", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "bis aus unserm bangen Bunde", "tokens": ["bis", "aus", "un\u00b7serm", "ban\u00b7gen", "Bun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auch das letzte Staunen wich \u2013", "tokens": ["auch", "das", "letz\u00b7te", "Stau\u00b7nen", "wich", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ja, noch lebst du mir im Grunde,", "tokens": ["ja", ",", "noch", "lebst", "du", "mir", "im", "Grun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "PPER", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "lauschend, wie dein Blutgeist mich", "tokens": ["lau\u00b7schend", ",", "wie", "dein", "Blut\u00b7geist", "mich"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PWAV", "PPOSAT", "NN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "aus dem K\u00f6rperbann der Erde", "tokens": ["aus", "dem", "K\u00f6r\u00b7per\u00b7bann", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "los und in ein Lichtreich rang,", "tokens": ["los", "und", "in", "ein", "Lich\u00b7treich", "rang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wo wir stammelten: es werde!", "tokens": ["wo", "wir", "stam\u00b7mel\u00b7ten", ":", "es", "wer\u00b7de", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$.", "PPER", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wo auch ", "tokens": ["wo", "auch"], "token_info": ["word", "word"], "pos": ["PWAV", "ADV"], "meter": "-+", "measure": "iambic.single"}}}}}