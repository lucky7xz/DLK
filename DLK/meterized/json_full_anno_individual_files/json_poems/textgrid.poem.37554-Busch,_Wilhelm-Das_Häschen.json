{"textgrid.poem.37554": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Das H\u00e4schen", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das H\u00e4schen sa\u00df im Kohl und fra\u00df und war ihm wohl.", "tokens": ["Das", "H\u00e4\u00b7schen", "sa\u00df", "im", "Kohl", "und", "fra\u00df", "und", "war", "ihm", "wohl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "KON", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht weit auf einem Rasen geht ganz gem\u00fctlich grasen", "tokens": ["Nicht", "weit", "auf", "ei\u00b7nem", "Ra\u00b7sen", "geht", "ganz", "ge\u00b7m\u00fct\u00b7lich", "gra\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "APPR", "ART", "NN", "VVFIN", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "ein L\u00e4mmlein wei\u00df und sch\u00f6n.", "tokens": ["ein", "L\u00e4mm\u00b7lein", "wei\u00df", "und", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Da ist der b\u00f6se Wolf gekommen", "tokens": ["Da", "ist", "der", "b\u00f6\u00b7se", "Wolf", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NE", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und hat das L\u00e4mmlein mitgenommen;", "tokens": ["Und", "hat", "das", "L\u00e4mm\u00b7lein", "mit\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das H\u00e4slein hat's gesehn.", "tokens": ["Das", "H\u00e4s\u00b7lein", "hat's", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Das H\u00e4schen sprang und lief", "tokens": ["Das", "H\u00e4\u00b7schen", "sprang", "und", "lief"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "zum Bauer hin und rief:", "tokens": ["zum", "Bau\u00b7er", "hin", "und", "rief", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "\u00bbo weh o weh! He, Bauer, he!", "tokens": ["\u00bb", "o", "weh", "o", "weh", "!", "He", ",", "Bau\u00b7er", ",", "he", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "FM", "FM", "FM", "PTKVZ", "$.", "NE", "$,", "NN", "$,", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Grad ist der b\u00f6se Wolf gekommen", "tokens": ["Grad", "ist", "der", "b\u00f6\u00b7se", "Wolf", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NE", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und hat dein L\u00e4mmlein", "tokens": ["und", "hat", "dein", "L\u00e4mm\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPOSAT", "NN"], "meter": "--+-+", "measure": "anapaest.init"}, "line.3": {"text": "mitgenommen!\u00ab", "tokens": ["mit\u00b7ge\u00b7nom\u00b7men", "!", "\u00ab"], "token_info": ["word", "punct", "punct"], "pos": ["VVPP", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Da nahm der Bauer R\u00fcppel", "tokens": ["Da", "nahm", "der", "Bau\u00b7er", "R\u00fcp\u00b7pel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "den dicken harten Kn\u00fcppel,", "tokens": ["den", "di\u00b7cken", "har\u00b7ten", "Kn\u00fcp\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "sprach: \u00bbDanke, lieber Hase!\u00ab", "tokens": ["sprach", ":", "\u00bb", "Dan\u00b7ke", ",", "lie\u00b7ber", "Ha\u00b7se", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$.", "$(", "PTKANT", "$,", "ADV", "NE", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "und schlug ihn auf die Nase.", "tokens": ["und", "schlug", "ihn", "auf", "die", "Na\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Dann spricht er mit Gekicher:", "tokens": ["Dann", "spricht", "er", "mit", "Ge\u00b7ki\u00b7cher", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbmein Kohl ist sicher!\u00ab", "tokens": ["\u00bb", "mein", "Kohl", "ist", "si\u00b7cher", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Und wer noch fragt,", "tokens": ["Und", "wer", "noch", "fragt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "was dies besagt,", "tokens": ["was", "dies", "be\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "ist offenbar", "tokens": ["ist", "of\u00b7fen\u00b7bar"], "token_info": ["word", "word"], "pos": ["VAFIN", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "so klug als wie das", "tokens": ["so", "klug", "als", "wie", "das"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KOKOM", "KOKOM", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "H\u00e4schen war.", "tokens": ["H\u00e4\u00b7schen", "war", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VAFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Das H\u00e4schen sa\u00df im Kohl und fra\u00df und war ihm wohl.", "tokens": ["Das", "H\u00e4\u00b7schen", "sa\u00df", "im", "Kohl", "und", "fra\u00df", "und", "war", "ihm", "wohl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "KON", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht weit auf einem Rasen geht ganz gem\u00fctlich grasen", "tokens": ["Nicht", "weit", "auf", "ei\u00b7nem", "Ra\u00b7sen", "geht", "ganz", "ge\u00b7m\u00fct\u00b7lich", "gra\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "APPR", "ART", "NN", "VVFIN", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "ein L\u00e4mmlein wei\u00df und sch\u00f6n.", "tokens": ["ein", "L\u00e4mm\u00b7lein", "wei\u00df", "und", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Da ist der b\u00f6se Wolf gekommen", "tokens": ["Da", "ist", "der", "b\u00f6\u00b7se", "Wolf", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NE", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und hat das L\u00e4mmlein mitgenommen;", "tokens": ["Und", "hat", "das", "L\u00e4mm\u00b7lein", "mit\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das H\u00e4slein hat's gesehn.", "tokens": ["Das", "H\u00e4s\u00b7lein", "hat's", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Das H\u00e4schen sprang und lief", "tokens": ["Das", "H\u00e4\u00b7schen", "sprang", "und", "lief"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "zum Bauer hin und rief:", "tokens": ["zum", "Bau\u00b7er", "hin", "und", "rief", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "\u00bbo weh o weh! He, Bauer, he!", "tokens": ["\u00bb", "o", "weh", "o", "weh", "!", "He", ",", "Bau\u00b7er", ",", "he", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "FM", "FM", "FM", "PTKVZ", "$.", "NE", "$,", "NN", "$,", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Grad ist der b\u00f6se Wolf gekommen", "tokens": ["Grad", "ist", "der", "b\u00f6\u00b7se", "Wolf", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NE", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und hat dein L\u00e4mmlein", "tokens": ["und", "hat", "dein", "L\u00e4mm\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPOSAT", "NN"], "meter": "--+-+", "measure": "anapaest.init"}, "line.3": {"text": "mitgenommen!\u00ab", "tokens": ["mit\u00b7ge\u00b7nom\u00b7men", "!", "\u00ab"], "token_info": ["word", "punct", "punct"], "pos": ["VVPP", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.10": {"line.1": {"text": "Da nahm der Bauer R\u00fcppel", "tokens": ["Da", "nahm", "der", "Bau\u00b7er", "R\u00fcp\u00b7pel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "den dicken harten Kn\u00fcppel,", "tokens": ["den", "di\u00b7cken", "har\u00b7ten", "Kn\u00fcp\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "sprach: \u00bbDanke, lieber Hase!\u00ab", "tokens": ["sprach", ":", "\u00bb", "Dan\u00b7ke", ",", "lie\u00b7ber", "Ha\u00b7se", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$.", "$(", "PTKANT", "$,", "ADV", "NE", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "und schlug ihn auf die Nase.", "tokens": ["und", "schlug", "ihn", "auf", "die", "Na\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Dann spricht er mit Gekicher:", "tokens": ["Dann", "spricht", "er", "mit", "Ge\u00b7ki\u00b7cher", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbmein Kohl ist sicher!\u00ab", "tokens": ["\u00bb", "mein", "Kohl", "ist", "si\u00b7cher", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Und wer noch fragt,", "tokens": ["Und", "wer", "noch", "fragt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "was dies besagt,", "tokens": ["was", "dies", "be\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "ist offenbar", "tokens": ["ist", "of\u00b7fen\u00b7bar"], "token_info": ["word", "word"], "pos": ["VAFIN", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "so klug als wie das", "tokens": ["so", "klug", "als", "wie", "das"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KOKOM", "KOKOM", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "H\u00e4schen war.", "tokens": ["H\u00e4\u00b7schen", "war", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VAFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}