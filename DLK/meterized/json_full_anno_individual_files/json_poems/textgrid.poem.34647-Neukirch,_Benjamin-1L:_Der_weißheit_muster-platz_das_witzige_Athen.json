{"textgrid.poem.34647": {"metadata": {"author": {"name": "Neukirch, Benjamin", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der wei\u00dfheit muster-platz/ das witzige Athen/", "genre": "verse", "period": "N.A.", "pub_year": 1697, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der wei\u00dfheit muster-platz/ das witzige Athen/", "tokens": ["Der", "wei\u00df\u00b7heit", "mus\u00b7ter\u00b7platz", "/", "das", "wit\u00b7zi\u00b7ge", "A\u00b7then", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Lie\u00df einst Minervens ruhm im tempel auffzusetzen/", "tokens": ["Lie\u00df", "einst", "Mi\u00b7ner\u00b7vens", "ruhm", "im", "tem\u00b7pel", "auff\u00b7zu\u00b7set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "NN", "APPRART", "NN", "VVINF", "$("], "meter": "+-+---+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Befehl an den Alcmen und Phidias ergehen:", "tokens": ["Be\u00b7fehl", "an", "den", "A\u00b7lcmen", "und", "Phi\u00b7di\u00b7as", "er\u00b7ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Sie solten beyderseits ihr bild in marmel \u00e4tzen.", "tokens": ["Sie", "sol\u00b7ten", "bey\u00b7der\u00b7seits", "ihr", "bild", "in", "mar\u00b7mel", "\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die arbeit ward vollbracht; Die urtheil lieffen ein.", "tokens": ["Die", "ar\u00b7beit", "ward", "voll\u00b7bracht", ";", "Die", "ur\u00b7theil", "lief\u00b7fen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und endlich ward der prei\u00df dem ersten zugesprochen;", "tokens": ["Und", "end\u00b7lich", "ward", "der", "prei\u00df", "dem", "ers\u00b7ten", "zu\u00b7ge\u00b7spro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Weil iede linie weit sch\u00e4rffer ausgestochen/", "tokens": ["Weil", "ie\u00b7de", "li\u00b7nie", "weit", "sch\u00e4rf\u00b7fer", "aus\u00b7ge\u00b7sto\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADJD", "ADJD", "VVINF", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Die stellung aber schien von mehrer kunst zu seyn:", "tokens": ["Die", "stel\u00b7lung", "a\u00b7ber", "schien", "von", "meh\u00b7rer", "kunst", "zu", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPR", "PIAT", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und menschen insgemein mit maulwurffs-augen schauen/", "tokens": ["Und", "men\u00b7schen", "ins\u00b7ge\u00b7mein", "mit", "maul\u00b7wurffs\u00b7au\u00b7gen", "schau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was sie/ wie luchsen/ doch sich zu ergr\u00fcnden trauen.", "tokens": ["Was", "sie", "/", "wie", "luch\u00b7sen", "/", "doch", "sich", "zu", "er\u00b7gr\u00fcn\u00b7den", "trau\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "$(", "KOKOM", "VVINF", "$(", "ADV", "PRF", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Doch wie ein seiden-wurm in raupen sich verkehrt;", "tokens": ["Doch", "wie", "ein", "sei\u00b7den\u00b7wurm", "in", "rau\u00b7pen", "sich", "ver\u00b7kehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "APPR", "VVFIN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So muste ieder auch ein ander urtheil f\u00e4llen;", "tokens": ["So", "mus\u00b7te", "ie\u00b7der", "auch", "ein", "an\u00b7der", "ur\u00b7theil", "f\u00e4l\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nachdem dem Phidias sein bitten ward gew\u00e4hrt/", "tokens": ["Nach\u00b7dem", "dem", "Phi\u00b7di\u00b7as", "sein", "bit\u00b7ten", "ward", "ge\u00b7w\u00e4hrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "ADJA", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und man die bilder lie\u00df auff hohe s\u00e4ulen stellen.", "tokens": ["Und", "man", "die", "bil\u00b7der", "lie\u00df", "auff", "ho\u00b7he", "s\u00e4u\u00b7len", "stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn nunmehr machte sich der fehler offenbar/", "tokens": ["Denn", "nun\u00b7mehr", "mach\u00b7te", "sich", "der", "feh\u00b7ler", "of\u00b7fen\u00b7bar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und lie\u00df die kluge welt aus allen gliedern lesen:", "tokens": ["Und", "lie\u00df", "die", "klu\u00b7ge", "welt", "aus", "al\u00b7len", "glie\u00b7dern", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df des Alcmenens witz im maase blind gewesen/", "tokens": ["Da\u00df", "des", "A\u00b7lcme\u00b7nens", "witz", "im", "maa\u00b7se", "blind", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NE", "APPRART", "NN", "ADJD", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Phidias sein werck von gr\u00e4der theilung war.", "tokens": ["Und", "Phi\u00b7di\u00b7as", "sein", "werck", "von", "gr\u00e4\u00b7der", "thei\u00b7lung", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So gar kan wissenschafft/ wie silber von der erden/", "tokens": ["So", "gar", "kan", "wis\u00b7sen\u00b7schafft", "/", "wie", "sil\u00b7ber", "von", "der", "er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "VVFIN", "$(", "KOKOM", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Durch eil und unverstand offt \u00fcberwogen werden.", "tokens": ["Durch", "eil", "und", "un\u00b7ver\u00b7stand", "offt", "\u00fc\u00b7ber\u00b7wo\u00b7gen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJD", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wer der gelehrten welt in ihren tempel gehn", "tokens": ["Wer", "der", "ge\u00b7lehr\u00b7ten", "welt", "in", "ih\u00b7ren", "tem\u00b7pel", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und eine gleichung will mit bild und b\u00fcchern machen/", "tokens": ["Und", "ei\u00b7ne", "glei\u00b7chung", "will", "mit", "bild", "und", "b\u00fc\u00b7chern", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird lernen/ da\u00df wir noch/ nicht anders als Athen/", "tokens": ["Wird", "ler\u00b7nen", "/", "da\u00df", "wir", "noch", "/", "nicht", "an\u00b7ders", "als", "A\u00b7then", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVINF", "$(", "KOUS", "PPER", "ADV", "$(", "PTKNEG", "ADV", "KOKOM", "NE", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Durch fr\u00fches urthel offt das beste werck verlachen.", "tokens": ["Durch", "fr\u00fc\u00b7hes", "ur\u00b7thel", "offt", "das", "bes\u00b7te", "werck", "ver\u00b7la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn wem ist wohl der streit der federn nicht bekandt;", "tokens": ["Denn", "wem", "ist", "wohl", "der", "streit", "der", "fe\u00b7dern", "nicht", "be\u00b7kandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer wei\u00df nicht/ wie sich wesp' und honigseim verbinden?", "tokens": ["Wer", "wei\u00df", "nicht", "/", "wie", "sich", "wesp'", "und", "ho\u00b7ni\u00b7gseim", "ver\u00b7bin\u00b7den", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "$(", "PWAV", "PRF", "PTKVZ", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die meisten fliegen sind bey marcipan zu finden;", "tokens": ["Die", "meis\u00b7ten", "flie\u00b7gen", "sind", "bey", "mar\u00b7ci\u00b7pan", "zu", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "VAFIN", "APPR", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die sch\u00f6nste stirne wird von warmer lufft verbrannt;", "tokens": ["Die", "sch\u00f6ns\u00b7te", "stir\u00b7ne", "wird", "von", "war\u00b7mer", "lufft", "ver\u00b7brannt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So wird der besten schrifft/ nachdem sie nur gebohren/", "tokens": ["So", "wird", "der", "bes\u00b7ten", "schrifft", "/", "nach\u00b7dem", "sie", "nur", "ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "VVFIN", "$(", "KOUS", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Auch die verleumdung bald zum schatten auserkohren.", "tokens": ["Auch", "die", "ver\u00b7leum\u00b7dung", "bald", "zum", "schat\u00b7ten", "au\u00b7ser\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "APPRART", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Der weise Plato ward vom sch\u00fcler schon verlacht;", "tokens": ["Der", "wei\u00b7se", "Pla\u00b7to", "ward", "vom", "sch\u00fc\u00b7ler", "schon", "ver\u00b7lacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VAFIN", "APPRART", "ADJA", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der g\u00fcldne Cicero vom Crispus umgetrieben.", "tokens": ["Der", "g\u00fcld\u00b7ne", "Ci\u00b7ce\u00b7ro", "vom", "Cris\u00b7pus", "um\u00b7ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Polybius wird noch in schulen offt veracht;", "tokens": ["Po\u00b7ly\u00b7bius", "wird", "noch", "in", "schu\u00b7len", "offt", "ver\u00b7acht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "APPR", "VVFIN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Da keiner doch so treu von Deutschen hat geschrieben.", "tokens": ["Da", "kei\u00b7ner", "doch", "so", "treu", "von", "Deut\u00b7schen", "hat", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "ADJD", "APPR", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Scioppius verwirfft den klugen Tacitus;", "tokens": ["Sciop\u00b7pius", "ver\u00b7wirfft", "den", "klu\u00b7gen", "Ta\u00b7ci\u00b7tus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Weil er der laster brunn im Nero nicht verschwiegen:", "tokens": ["Weil", "er", "der", "las\u00b7ter", "brunn", "im", "Ne\u00b7ro", "nicht", "ver\u00b7schwie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPRART", "NE", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ja Strabo suchet schon im Metrodorus l\u00fcgen/", "tokens": ["Ja", "Stra\u00b7bo", "su\u00b7chet", "schon", "im", "Me\u00b7tro\u00b7do\u00b7rus", "l\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NE", "VVFIN", "ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und hat an m\u00e4ngeln doch selbst einen \u00fcberflu\u00df.", "tokens": ["Und", "hat", "an", "m\u00e4n\u00b7geln", "doch", "selbst", "ei\u00b7nen", "\u00fc\u00b7berf\u00b7lu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So artig wissen wir durch urthel unsre flecken/", "tokens": ["So", "ar\u00b7tig", "wis\u00b7sen", "wir", "durch", "ur\u00b7thel", "uns\u00b7re", "fle\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "APPR", "NE", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie parden ihre haut im laube/ zu verstecken.", "tokens": ["Wie", "par\u00b7den", "ih\u00b7re", "haut", "im", "lau\u00b7be", "/", "zu", "ver\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "VVFIN", "APPRART", "NN", "$(", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ein eintzig kopff geb\u00fchrt offt tausendfachen streit/", "tokens": ["Ein", "eint\u00b7zig", "kopff", "ge\u00b7b\u00fchrt", "offt", "tau\u00b7send\u00b7fa\u00b7chen", "streit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gleichwie ein finsterni\u00df im meere tausend wellen.", "tokens": ["Gleich\u00b7wie", "ein", "fins\u00b7ter\u00b7ni\u00df", "im", "mee\u00b7re", "tau\u00b7send", "wel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "ADJA", "CARD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum schilt Riccobonus der R\u00f6mer lieblichkeit/", "tokens": ["Drum", "schilt", "Ric\u00b7co\u00b7bo\u00b7nus", "der", "R\u00f6\u00b7mer", "lieb\u00b7lich\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil ihre federn nicht nach seiner zunge quellen;", "tokens": ["Weil", "ih\u00b7re", "fe\u00b7dern", "nicht", "nach", "sei\u00b7ner", "zun\u00b7ge", "quel\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und meynt/ da\u00df Plinius viel worte nur geschmiert/", "tokens": ["Und", "meynt", "/", "da\u00df", "Pli\u00b7nius", "viel", "wor\u00b7te", "nur", "ge\u00b7schmiert", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "NE", "PIAT", "NN", "ADV", "VVPP", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Der Tacitus zu rauh/ und Flor zu kurtz geschrieben;", "tokens": ["Der", "Ta\u00b7ci\u00b7tus", "zu", "rauh", "/", "und", "Flor", "zu", "kurtz", "ge\u00b7schrie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "PTKA", "ADJD", "$(", "KON", "NN", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sveton und Spartian die sprache schlecht getrieben/", "tokens": ["Sve\u00b7ton", "und", "Spar\u00b7ti\u00b7an", "die", "spra\u00b7che", "schlecht", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "ART", "ADJA", "ADJD", "VVPP", "$("], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.8": {"text": "Und endlich Marcellin zu harte reden f\u00fchrt.", "tokens": ["Und", "end\u00b7lich", "Mar\u00b7cel\u00b7lin", "zu", "har\u00b7te", "re\u00b7den", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "APPR", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Als ob der sonnen licht die strahlung von den sternen/", "tokens": ["Als", "ob", "der", "son\u00b7nen", "licht", "die", "strah\u00b7lung", "von", "den", "ster\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "ADJA", "NN", "ART", "NN", "APPR", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Rom aber r\u00f6misch noch von kindern solte lernen.", "tokens": ["Rom", "a\u00b7ber", "r\u00f6\u00b7misch", "noch", "von", "kin\u00b7dern", "sol\u00b7te", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJD", "ADV", "APPR", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Der alten possen-spiel trifft auch die neue welt/", "tokens": ["Der", "al\u00b7ten", "pos\u00b7sen\u00b7spiel", "trifft", "auch", "die", "neu\u00b7e", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nur da\u00df person und platz im spiele sich verkehren.", "tokens": ["Nur", "da\u00df", "per\u00b7son", "und", "platz", "im", "spie\u00b7le", "sich", "ver\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NE", "KON", "NN", "APPRART", "VVFIN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des Comin\u00e4us ruhm/ den Gallien erh\u00e4lt/", "tokens": ["Des", "Co\u00b7mi\u00b7n\u00e4us", "ruhm", "/", "den", "Gal\u00b7li\u00b7en", "er\u00b7h\u00e4lt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "ART", "NE", "VVFIN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Sucht Mejer/ wie der blitz die cedern/ zu verzehren.", "tokens": ["Sucht", "Me\u00b7jer", "/", "wie", "der", "blitz", "die", "ce\u00b7dern", "/", "zu", "ver\u00b7zeh\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$(", "KOKOM", "ART", "NN", "ART", "NN", "$(", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sleidanus arbeit wird von vielen schlecht gesch\u00e4tzt/", "tokens": ["Slei\u00b7da\u00b7nus", "ar\u00b7beit", "wird", "von", "vie\u00b7len", "schlecht", "ge\u00b7sch\u00e4tzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "APPR", "PIAT", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und hat/ wie Strada/ schon ihr urthel recht erlitten.", "tokens": ["Und", "hat", "/", "wie", "Stra\u00b7da", "/", "schon", "ihr", "ur\u00b7thel", "recht", "er\u00b7lit\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$(", "KOKOM", "NE", "$(", "ADV", "PPOSAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie hatte den Thuan Baptista nicht verschnitten?", "tokens": ["Wie", "hat\u00b7te", "den", "Thu\u00b7an", "Bap\u00b7tis\u00b7ta", "nicht", "ver\u00b7schnit\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NE", "NE", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-++-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Wie ward dem Lipsius die feder nicht gewetzt?", "tokens": ["Wie", "ward", "dem", "Lip\u00b7sius", "die", "fe\u00b7der", "nicht", "ge\u00b7wetzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NE", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Und was will Cromer nicht vor fehler andern zeigen/", "tokens": ["Und", "was", "will", "Cro\u00b7mer", "nicht", "vor", "feh\u00b7ler", "an\u00b7dern", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "NN", "PTKNEG", "APPR", "ADJD", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die doch bey dutzenden aus seinen schrifften steigen?", "tokens": ["Die", "doch", "bey", "dut\u00b7zen\u00b7den", "aus", "sei\u00b7nen", "schriff\u00b7ten", "stei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Das macht/ die meisten seyn vor grossem eyffer blind/", "tokens": ["Das", "macht", "/", "die", "meis\u00b7ten", "seyn", "vor", "gros\u00b7sem", "eyf\u00b7fer", "blind", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "ART", "PIS", "VAINF", "APPR", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und f\u00fchren gall und zorn im kopffe wie sardellen:", "tokens": ["Und", "f\u00fch\u00b7ren", "gall", "und", "zorn", "im", "kopf\u00b7fe", "wie", "sar\u00b7del\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "KON", "NN", "APPRART", "VVFIN", "KOKOM", "VVINF", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Drum kan ihr urthel/ das von wermuth fast zerrinnt/", "tokens": ["Drum", "kan", "ihr", "ur\u00b7thel", "/", "das", "von", "wer\u00b7muth", "fast", "zer\u00b7rinnt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPOSAT", "NN", "$(", "ART", "APPR", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie quitten nicht zugleich mit mu\u00dfcateller qvellen.", "tokens": ["Wie", "quit\u00b7ten", "nicht", "zu\u00b7gleich", "mit", "mu\u00df\u00b7ca\u00b7tel\u00b7ler", "qvel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PTKNEG", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+--++-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Den andern mangelt gar zuweilen der verstand/", "tokens": ["Den", "an\u00b7dern", "man\u00b7gelt", "gar", "zu\u00b7wei\u00b7len", "der", "ver\u00b7stand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "ADV", "ART", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So wie den krebsen blut/ und wilden b\u00e4umen feigen:", "tokens": ["So", "wie", "den", "kreb\u00b7sen", "blut", "/", "und", "wil\u00b7den", "b\u00e4u\u00b7men", "fei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "$(", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ja wenn ihr geist sich soll im alterthume zeigen/", "tokens": ["Ja", "wenn", "ihr", "geist", "sich", "soll", "im", "al\u00b7ter\u00b7thu\u00b7me", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "PPER", "VVFIN", "PRF", "VMFIN", "APPRART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So ist den \u00e4rmsten offt das jota kaum bekandt;", "tokens": ["So", "ist", "den", "\u00e4rms\u00b7ten", "offt", "das", "jo\u00b7ta", "kaum", "be\u00b7kandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "ADV", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und dennoch soll ihr ruhm nach tausend klugen Griechen/", "tokens": ["Und", "den\u00b7noch", "soll", "ihr", "ruhm", "nach", "tau\u00b7send", "klu\u00b7gen", "Grie\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPOSAT", "NN", "APPR", "CARD", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und ihre feder/ wie Cardanus athem/ riechen.", "tokens": ["Und", "ih\u00b7re", "fe\u00b7der", "/", "wie", "Car\u00b7da\u00b7nus", "at\u00b7hem", "/", "rie\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$(", "KOKOM", "NE", "NE", "$(", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Doch rechte wei\u00dfheit bleibt so wenig unterdr\u00fcckt/", "tokens": ["Doch", "rech\u00b7te", "wei\u00df\u00b7heit", "bleibt", "so", "we\u00b7nig", "un\u00b7ter\u00b7dr\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "ADV", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als Pyrrhus edles hertz im feuer kan verbrennen.", "tokens": ["Als", "Pyrr\u00b7hus", "ed\u00b7les", "hertz", "im", "feu\u00b7er", "kan", "ver\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADJA", "NN", "APPRART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn sterne werden doch durch gla\u00df und kunst erblickt;", "tokens": ["Denn", "ster\u00b7ne", "wer\u00b7den", "doch", "durch", "gla\u00df", "und", "kunst", "er\u00b7blickt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADV", "APPR", "NN", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und purpur lernet man bey reinem purpur kennen:", "tokens": ["Und", "pur\u00b7pur", "ler\u00b7net", "man", "bey", "rei\u00b7nem", "pur\u00b7pur", "ken\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "APPR", "ADJA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So steigt der b\u00fccher glantz auch endlich himmel an/", "tokens": ["So", "steigt", "der", "b\u00fc\u00b7cher", "glantz", "auch", "end\u00b7lich", "him\u00b7mel", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ADV", "ADV", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn ihre schrifften sich auff hohe s\u00e4ulen stellen.", "tokens": ["Wenn", "ih\u00b7re", "schriff\u00b7ten", "sich", "auff", "ho\u00b7he", "s\u00e4u\u00b7len", "stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "VVFIN", "PRF", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das ist: wenn witz und flei\u00df das urtheil dr\u00fcber f\u00e4llen/", "tokens": ["Das", "ist", ":", "wenn", "witz", "und", "flei\u00df", "das", "ur\u00b7theil", "dr\u00fc\u00b7ber", "f\u00e4l\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$.", "KOUS", "NE", "KON", "VVFIN", "ART", "NN", "PAV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und der gelehrten spruch dem p\u00f6fel dargethan:", "tokens": ["Und", "der", "ge\u00b7lehr\u00b7ten", "spruch", "dem", "p\u00f6\u00b7fel", "dar\u00b7ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie wenig den Bodin ein Sergius erreichen/", "tokens": ["Wie", "we\u00b7nig", "den", "Bo\u00b7din", "ein", "Ser\u00b7gius", "er\u00b7rei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "ART", "NE", "VVINF", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.10": {"text": "Und sich Pallavicin kan einem Svavis gleichen.", "tokens": ["Und", "sich", "Pal\u00b7la\u00b7vi\u00b7cin", "kan", "ei\u00b7nem", "Sva\u00b7vis", "glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "NN", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Die arbeit Lohensteins hat beydes schon erlebt/", "tokens": ["Die", "ar\u00b7beit", "Lo\u00b7hen\u00b7steins", "hat", "bey\u00b7des", "schon", "er\u00b7lebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VAFIN", "PIS", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Eh noch ihr wesen recht zu leben angefangen.", "tokens": ["Eh", "noch", "ihr", "we\u00b7sen", "recht", "zu", "le\u00b7ben", "an\u00b7ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPER", "VVFIN", "ADJD", "PTKZU", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn vielen ist der ruhm/ der ihren geist erhebt/", "tokens": ["Denn", "vie\u00b7len", "ist", "der", "ruhm", "/", "der", "ih\u00b7ren", "geist", "er\u00b7hebt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ART", "NN", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht anders als der senff in nasen auffgegangen;", "tokens": ["Nicht", "an\u00b7ders", "als", "der", "senff", "in", "na\u00b7sen", "auff\u00b7ge\u00b7gan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "KOKOM", "ART", "CARD", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Viel haben ihren mosch mit pfeffer \u00fcberstreut/", "tokens": ["Viel", "ha\u00b7ben", "ih\u00b7ren", "mosch", "mit", "pfef\u00b7fer", "\u00fc\u00b7bers\u00b7treut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und nur wie Araber den balsam angerochen;", "tokens": ["Und", "nur", "wie", "A\u00b7ra\u00b7ber", "den", "bal\u00b7sam", "an\u00b7ge\u00b7ro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOKOM", "NN", "ART", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bi\u00df recht und klugheit ihr die palmen zugesprochen/", "tokens": ["Bi\u00df", "recht", "und", "klug\u00b7heit", "ihr", "die", "pal\u00b7men", "zu\u00b7ge\u00b7spro\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "NN", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und endlich wahr gemacht: da\u00df eyfersucht und neid/", "tokens": ["Und", "end\u00b7lich", "wahr", "ge\u00b7macht", ":", "da\u00df", "ey\u00b7fer\u00b7sucht", "und", "neid", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVPP", "$.", "KOUS", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie d\u00fcnste/ durch die glut der sonnen auff der erden/", "tokens": ["Wie", "d\u00fcns\u00b7te", "/", "durch", "die", "glut", "der", "son\u00b7nen", "auff", "der", "er\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$(", "APPR", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Durch schrifften zwar erregt/ doch auch gebrochen werden.", "tokens": ["Durch", "schriff\u00b7ten", "zwar", "er\u00b7regt", "/", "doch", "auch", "ge\u00b7bro\u00b7chen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADV", "VVPP", "$(", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Itzt tritt der andre theil in die gelehrte welt/", "tokens": ["Itzt", "tritt", "der", "and\u00b7re", "theil", "in", "die", "ge\u00b7lehr\u00b7te", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sich an dem ehrenprei\u00df des ersten zu ergetzen/", "tokens": ["Sich", "an", "dem", "eh\u00b7ren\u00b7prei\u00df", "des", "ers\u00b7ten", "zu", "er\u00b7get\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "ART", "ADJA", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und will den blumen-tantz/ den jener vorgestellt/", "tokens": ["Und", "will", "den", "blu\u00b7men\u00b7tantz", "/", "den", "je\u00b7ner", "vor\u00b7ge\u00b7stellt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "$(", "ART", "PDS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch einen wunder-streit von b\u00e4umen hier ersetzen.", "tokens": ["Durch", "ei\u00b7nen", "wun\u00b7der\u00b7streit", "von", "b\u00e4u\u00b7men", "hier", "er\u00b7set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vielleicht zum zeugnisse: da\u00df rosen und jesmin/", "tokens": ["Viel\u00b7leicht", "zum", "zeug\u00b7nis\u00b7se", ":", "da\u00df", "ro\u00b7sen", "und", "jes\u00b7min", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$.", "KOUS", "NE", "KON", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch am geruche noch dem myrrhen-saffte weichen/", "tokens": ["Doch", "am", "ge\u00b7ru\u00b7che", "noch", "dem", "myr\u00b7rhen\u00b7\u00b7saff\u00b7te", "wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "ADV", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Chineser \u00e4pffel mehr als liljen anmuth reichen/", "tokens": ["Chi\u00b7ne\u00b7ser", "\u00e4pf\u00b7fel", "mehr", "als", "lil\u00b7jen", "an\u00b7muth", "rei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PIAT", "KOKOM", "ADJA", "NN", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Und b\u00fccher insgemein mit grosser arbeit bl\u00fchn;", "tokens": ["Und", "b\u00fc\u00b7cher", "ins\u00b7ge\u00b7mein", "mit", "gros\u00b7ser", "ar\u00b7beit", "bl\u00fchn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Im schliessen aber so wie reiffende morellen/", "tokens": ["Im", "schlies\u00b7sen", "a\u00b7ber", "so", "wie", "reif\u00b7fen\u00b7de", "mo\u00b7rel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "ADV", "ADV", "KOKOM", "ADJA", "NN", "$("], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.10": {"text": "Auch von sich selber offt mit s\u00fcssem zucker qvellen.", "tokens": ["Auch", "von", "sich", "sel\u00b7ber", "offt", "mit", "s\u00fcs\u00b7sem", "zu\u00b7cker", "qvel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PRF", "ADV", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Und warlich allzu recht. Denn dorten blitzt der krieg/", "tokens": ["Und", "war\u00b7lich", "all\u00b7zu", "recht", ".", "Denn", "dor\u00b7ten", "blitzt", "der", "krieg", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKA", "ADJD", "$.", "KON", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und l\u00e4st das teutsche reich in flammen fast zerfliessen;", "tokens": ["Und", "l\u00e4st", "das", "teut\u00b7sche", "reich", "in", "flam\u00b7men", "fast", "zer\u00b7flies\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "ADJD", "APPR", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier schleu\u00dft Arminius den friedens-vollen sieg/", "tokens": ["Hier", "schleu\u00dft", "Ar\u00b7mi\u00b7nius", "den", "frie\u00b7dens\u00b7vol\u00b7len", "sieg", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Und hat das vaterland der R\u00f6mer macht entrissen.", "tokens": ["Und", "hat", "das", "va\u00b7ter\u00b7land", "der", "R\u00f6\u00b7mer", "macht", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das erste haben schon die barbarn ausgedacht;", "tokens": ["Das", "ers\u00b7te", "ha\u00b7ben", "schon", "die", "bar\u00b7barn", "aus\u00b7ge\u00b7dacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier aber werden viel die klugen lehren finden:", "tokens": ["Hier", "a\u00b7ber", "wer\u00b7den", "viel", "die", "klu\u00b7gen", "leh\u00b7ren", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df/ wer den frieden will auff blosses eisen gr\u00fcnden/", "tokens": ["Da\u00df", "/", "wer", "den", "frie\u00b7den", "will", "auff", "blos\u00b7ses", "ei\u00b7sen", "gr\u00fcn\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "PWS", "ART", "NN", "VMFIN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ihn/ wie oliven-safft in bley/ zu nichte macht/", "tokens": ["Ihn", "/", "wie", "o\u00b7li\u00b7ven\u00b7\u00b7safft", "in", "bley", "/", "zu", "nich\u00b7te", "macht", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "KOKOM", "NN", "APPR", "NN", "$(", "PTKA", "PIS", "VVFIN", "$("], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Und f\u00fcrsten r\u00fchmlicher mit schlauen crocodilen/", "tokens": ["Und", "f\u00fcrs\u00b7ten", "r\u00fchm\u00b7li\u00b7cher", "mit", "schlau\u00b7en", "cro\u00b7co\u00b7di\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Durch weichen und verstand/ als scharffe waffen spielen.", "tokens": ["Durch", "wei\u00b7chen", "und", "ver\u00b7stand", "/", "als", "scharf\u00b7fe", "waf\u00b7fen", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "KON", "VVFIN", "$(", "KOUS", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wo aber heb' ich an/ den ungemeinen geist", "tokens": ["Wo", "a\u00b7ber", "heb'", "ich", "an", "/", "den", "un\u00b7ge\u00b7mei\u00b7nen", "geist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "PTKVZ", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des edlen Lohensteins nach w\u00fcrden auszudr\u00fccken?", "tokens": ["Des", "ed\u00b7len", "Lo\u00b7hen\u00b7steins", "nach", "w\u00fcr\u00b7den", "aus\u00b7zu\u00b7dr\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "VAFIN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der/ was in andern man nur glieder-weise preist/", "tokens": ["Der", "/", "was", "in", "an\u00b7dern", "man", "nur", "glie\u00b7der\u00b7wei\u00b7se", "preist", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "PWS", "APPR", "ADJA", "PIS", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hier voller wunder l\u00e4st aus einem buche blicken.", "tokens": ["Hier", "vol\u00b7ler", "wun\u00b7der", "l\u00e4st", "aus", "ei\u00b7nem", "bu\u00b7che", "bli\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn auch gelehrte sind mit ihrer phantasey/", "tokens": ["Denn", "auch", "ge\u00b7lehr\u00b7te", "sind", "mit", "ih\u00b7rer", "phan\u00b7ta\u00b7sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "VAFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie affen offtermahls mit honig/ nicht zu f\u00fcllen;", "tokens": ["Wie", "af\u00b7fen", "off\u00b7ter\u00b7mahls", "mit", "ho\u00b7nig", "/", "nicht", "zu", "f\u00fcl\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "APPR", "NN", "$(", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Drum mi\u00dft Mirandula der grobheit tausend grillen/", "tokens": ["Drum", "mi\u00dft", "Mi\u00b7ran\u00b7du\u00b7la", "der", "grob\u00b7heit", "tau\u00b7send", "gril\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "ART", "NN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Anaxagoras dem monde berge bey.", "tokens": ["Und", "A\u00b7na\u00b7xa\u00b7go\u00b7ras", "dem", "mon\u00b7de", "ber\u00b7ge", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er aber war bem\u00fcht/ wie bienen zu ergr\u00fcnden/", "tokens": ["Er", "a\u00b7ber", "war", "be\u00b7m\u00fcht", "/", "wie", "bie\u00b7nen", "zu", "er\u00b7gr\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "VVPP", "$(", "KOKOM", "VVINF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie man viel blumen soll in einen teig verbinden.", "tokens": ["Wie", "man", "viel", "blu\u00b7men", "soll", "in", "ei\u00b7nen", "teig", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "VVINF", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Der menschen erstes licht ist himmel und natur/", "tokens": ["Der", "men\u00b7schen", "ers\u00b7tes", "licht", "ist", "him\u00b7mel", "und", "na\u00b7tur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VAFIN", "NN", "KON", "NN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Wie schwefel-werck und saltz das leben dieser erden.", "tokens": ["Wie", "schwe\u00b7fel\u00b7\u00b7werck", "und", "saltz", "das", "le\u00b7ben", "die\u00b7ser", "er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "ADJD", "PDS", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein unvern\u00fcnfftig thier mu\u00df witzig durch die spur/", "tokens": ["Ein", "un\u00b7ver\u00b7n\u00fcnff\u00b7tig", "thier", "mu\u00df", "wit\u00b7zig", "durch", "die", "spur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VMFIN", "ADJD", "APPR", "ART", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die seele durch vernunfft zu einem engel werden.", "tokens": ["Die", "see\u00b7le", "durch", "ver\u00b7nunfft", "zu", "ei\u00b7nem", "en\u00b7gel", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer sieht nicht/ was sein flei\u00df vor proben abgelegt?", "tokens": ["Wer", "sieht", "nicht", "/", "was", "sein", "flei\u00df", "vor", "pro\u00b7ben", "ab\u00b7ge\u00b7legt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "$(", "PWS", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie er das kluge wachs der alten umgegossen/", "tokens": ["Wie", "er", "das", "klu\u00b7ge", "wachs", "der", "al\u00b7ten", "um\u00b7ge\u00b7gos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "ART", "ADJA", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den geist des Socrates von neuem auffgeschlossen/", "tokens": ["Den", "geist", "des", "So\u00b7cra\u00b7tes", "von", "neu\u00b7em", "auff\u00b7ge\u00b7schlos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ADJA", "VVINF", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Den weisen Seneca Thusnelden eingepr\u00e4gt/", "tokens": ["Den", "wei\u00b7sen", "Se\u00b7ne\u00b7ca", "Thus\u00b7nel\u00b7den", "ein\u00b7ge\u00b7pr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und endlich durch sein licht im schreiben mehr erwiesen/", "tokens": ["Und", "end\u00b7lich", "durch", "sein", "licht", "im", "schrei\u00b7ben", "mehr", "er\u00b7wie\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "APPRART", "VVFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als man an dem Petrarch' und Loredan gepriesen.", "tokens": ["Als", "man", "an", "dem", "Pe\u00b7tra\u00b7rch'", "und", "Lo\u00b7re\u00b7dan", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "KON", "NE", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.14": {"line.1": {"text": "Die staats-kunst/ die nechst Gott des scepters auge seyn/", "tokens": ["Die", "staats\u00b7kunst", "/", "die", "nechst", "Gott", "des", "scep\u00b7ters", "au\u00b7ge", "seyn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "VVFIN", "NN", "ART", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und f\u00fcrsten/ wie den leib der schatten soll bedecken/", "tokens": ["Und", "f\u00fcrs\u00b7ten", "/", "wie", "den", "leib", "der", "schat\u00b7ten", "soll", "be\u00b7de\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOKOM", "ART", "NN", "ART", "ADJA", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schleu\u00dft er weit lustiger in liebes-zucker ein;", "tokens": ["Schleu\u00dft", "er", "weit", "lus\u00b7ti\u00b7ger", "in", "lie\u00b7bes\u00b7zu\u00b7cker", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJD", "APPR", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Als sie Savedra wei\u00df in bilder zu verstecken.", "tokens": ["Als", "sie", "Sa\u00b7ve\u00b7dra", "wei\u00df", "in", "bil\u00b7der", "zu", "ver\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "VVFIN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der tieffe Gracian legt seinen Ferdinand/", "tokens": ["Der", "tief\u00b7fe", "Gra\u00b7ci\u00b7an", "legt", "sei\u00b7nen", "Fer\u00b7di\u00b7nand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie eher sich August/ vor seinem Hermann nieder.", "tokens": ["Wie", "e\u00b7her", "sich", "Au\u00b7gust", "/", "vor", "sei\u00b7nem", "Her\u00b7mann", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PRF", "NN", "$(", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Uns aber scheint der glantz der alten zeiten wieder;", "tokens": ["Uns", "a\u00b7ber", "scheint", "der", "glantz", "der", "al\u00b7ten", "zei\u00b7ten", "wie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Weil wir des letzten bild im Leopold erkannt/", "tokens": ["Weil", "wir", "des", "letz\u00b7ten", "bild", "im", "Leo\u00b7pold", "er\u00b7kannt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPRART", "NE", "VVPP", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Und uns ein Lohenstein in alten finsternissen", "tokens": ["Und", "uns", "ein", "Lo\u00b7hen\u00b7stein", "in", "al\u00b7ten", "fins\u00b7ter\u00b7nis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ART", "NN", "APPR", "ADJA", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die sonne dieser zeit so artig abgerissen.", "tokens": ["Die", "son\u00b7ne", "die\u00b7ser", "zeit", "so", "ar\u00b7tig", "ab\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Doch staats-gedancken sind in f\u00fcrsten kinder-art/", "tokens": ["Doch", "staats\u00b7ge\u00b7dan\u00b7cken", "sind", "in", "f\u00fcrs\u00b7ten", "kin\u00b7der\u00b7art", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn beyde pflegen sich beym feuer zu verbrennen/", "tokens": ["Denn", "bey\u00b7de", "pfle\u00b7gen", "sich", "beym", "feu\u00b7er", "zu", "ver\u00b7bren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PRF", "APPRART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So lange nicht ihr witz sich mit erfahrung paart/", "tokens": ["So", "lan\u00b7ge", "nicht", "ihr", "witz", "sich", "mit", "er\u00b7fah\u00b7rung", "paart", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "PPOSAT", "NN", "PRF", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sie ihr ungel\u00fcck aus fremder angst erkennen.", "tokens": ["Und", "sie", "ihr", "un\u00b7ge\u00b7l\u00fcck", "aus", "frem\u00b7der", "angst", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum laufft sein eyffer auch in die vergangne welt/", "tokens": ["Drum", "laufft", "sein", "eyf\u00b7fer", "auch", "in", "die", "ver\u00b7gang\u00b7ne", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und forscht/ woher der brunn der Deutschen sey entsprungen/", "tokens": ["Und", "forscht", "/", "wo\u00b7her", "der", "brunn", "der", "Deut\u00b7schen", "sey", "ent\u00b7sprun\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "PWAV", "ART", "NN", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie weit der Marobod den degen hat geschwungen/", "tokens": ["Wie", "weit", "der", "Ma\u00b7ro\u00b7bod", "den", "de\u00b7gen", "hat", "ge\u00b7schwun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und das verh\u00e4ngni\u00df Rom die grentzen ausgestellt?", "tokens": ["Und", "das", "ver\u00b7h\u00e4ng\u00b7ni\u00df", "Rom", "die", "grent\u00b7zen", "aus\u00b7ge\u00b7stellt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NE", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch so/ da\u00df mehrentheils gleich wie in purpur-schnecken/", "tokens": ["Doch", "so", "/", "da\u00df", "meh\u00b7ren\u00b7theils", "gleich", "wie", "in", "pur\u00b7pur\u00b7schne\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "KOUS", "ADV", "ADV", "KOKOM", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die perlen neuer zeit in alten schalen stecken.", "tokens": ["Die", "per\u00b7len", "neu\u00b7er", "zeit", "in", "al\u00b7ten", "scha\u00b7len", "ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "APPR", "ADJA", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Di\u00df ernst-erf\u00fcllte werck mischt sein ge\u00fcbter geist/", "tokens": ["Di\u00df", "ernst\u00b7er\u00b7f\u00fcll\u00b7te", "werck", "mischt", "sein", "ge\u00b7\u00fcb\u00b7ter", "geist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie k\u00f6che kostbar fleisch mit s\u00fcssen mandel-kuchen/", "tokens": ["Wie", "k\u00f6\u00b7che", "kost\u00b7bar", "fleisch", "mit", "s\u00fcs\u00b7sen", "man\u00b7del\u00b7ku\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADJD", "ADJD", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn er die eigenschafft der dinge besser weist/", "tokens": ["Wenn", "er", "die", "ei\u00b7gen\u00b7schafft", "der", "din\u00b7ge", "bes\u00b7ser", "weist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als Schott- und Lemnius mit vieler arbeit suchen:", "tokens": ["Als", "Schot\u00b7t", "und", "Lem\u00b7ni\u00b7us", "mit", "vie\u00b7ler", "ar\u00b7beit", "su\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "TRUNC", "KON", "NE", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Bald auch den gottesdienst der alten welt betracht/", "tokens": ["Bald", "auch", "den", "got\u00b7tes\u00b7dienst", "der", "al\u00b7ten", "welt", "be\u00b7tracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und seine fehler wei\u00df im grunde vorzustellen/", "tokens": ["Und", "sei\u00b7ne", "feh\u00b7ler", "wei\u00df", "im", "grun\u00b7de", "vor\u00b7zu\u00b7stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zu zeigen/ da\u00df auch most den magen kan verg\u00e4llen;", "tokens": ["Zu", "zei\u00b7gen", "/", "da\u00df", "auch", "most", "den", "ma\u00b7gen", "kan", "ver\u00b7g\u00e4l\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "KOUS", "ADV", "ADV", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der beste bisem offt wie knobloch eckel macht/", "tokens": ["Der", "bes\u00b7te", "bi\u00b7sem", "offt", "wie", "kno\u00b7bloch", "ec\u00b7kel", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "ADV", "KOKOM", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und lehren/ wenn wir sie zu viel und h\u00e4uffig brauchen/", "tokens": ["Und", "leh\u00b7ren", "/", "wenn", "wir", "sie", "zu", "viel", "und", "h\u00e4uf\u00b7fig", "brau\u00b7chen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "KOUS", "PPER", "PPER", "APPR", "PIAT", "KON", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie falscher weyrauch leicht ohn alle glut verrauchen.", "tokens": ["Wie", "fal\u00b7scher", "wey\u00b7rauch", "leicht", "ohn", "al\u00b7le", "glut", "ver\u00b7rau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "ADJD", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Ich wei\u00df nicht/ ob ich auch noch von der poesie/", "tokens": ["Ich", "wei\u00df", "nicht", "/", "ob", "ich", "auch", "noch", "von", "der", "po\u00b7e\u00b7sie", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "KOUS", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der feder Lohensteins soll ihren ruhm erheben?", "tokens": ["Der", "fe\u00b7der", "Lo\u00b7hen\u00b7steins", "soll", "ih\u00b7ren", "ruhm", "er\u00b7he\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn ver\u00dfe kosten so/ wie blumen/ grosse m\u00fch/", "tokens": ["Denn", "ver\u00b7\u00dfe", "kos\u00b7ten", "so", "/", "wie", "blu\u00b7men", "/", "gros\u00b7se", "m\u00fch", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVFIN", "ADV", "$(", "KOKOM", "NN", "$(", "ADJA", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da beyde mit der zeit doch keine fr\u00fcchte geben.", "tokens": ["Da", "bey\u00b7de", "mit", "der", "zeit", "doch", "kei\u00b7ne", "fr\u00fcch\u00b7te", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "ADV", "PIAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und hat auff erden gleich ein Constantin regiert/", "tokens": ["Und", "hat", "auff", "er\u00b7den", "gleich", "ein", "Con\u00b7stan\u00b7tin", "re\u00b7giert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+---+-++--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Der nur in seinen rath poeten auffgenommen;", "tokens": ["Der", "nur", "in", "sei\u00b7nen", "rath", "po\u00b7e\u00b7ten", "auff\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So sind doch hundert schon in seine stelle kommen/", "tokens": ["So", "sind", "doch", "hun\u00b7dert", "schon", "in", "sei\u00b7ne", "stel\u00b7le", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "CARD", "ADV", "APPR", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die dieser k\u00f6pffe gold mit flecken angeschmiert/", "tokens": ["Die", "die\u00b7ser", "k\u00f6pf\u00b7fe", "gold", "mit", "fle\u00b7cken", "an\u00b7ge\u00b7schmiert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "ADJA", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und eher gips und kalck/ und stumme marmel-g\u00f6tzen/", "tokens": ["Und", "e\u00b7her", "gips", "und", "kalck", "/", "und", "stum\u00b7me", "mar\u00b7mel\u00b7g\u00f6t\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "KON", "NN", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als einen Sannazar/ auff ihre schrancken setzen.", "tokens": ["Als", "ei\u00b7nen", "San\u00b7na\u00b7zar", "/", "auff", "ih\u00b7re", "schran\u00b7cken", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$(", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Di\u00df aber wei\u00df ich wohl/ da\u00df diese kluge schrifft/", "tokens": ["Di\u00df", "a\u00b7ber", "wei\u00df", "ich", "wohl", "/", "da\u00df", "die\u00b7se", "klu\u00b7ge", "schrifft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "ADV", "$(", "KOUS", "PDAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So wie Erasmus werck aus krancker hand entsprossen;", "tokens": ["So", "wie", "Er\u00b7as\u00b7mus", "werck", "aus", "kran\u00b7cker", "hand", "ent\u00b7spros\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "NE", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn nun ein Plautus ihm noch ehren-mahle stifft/", "tokens": ["Wenn", "nun", "ein", "Plau\u00b7tus", "ihm", "noch", "eh\u00b7ren\u00b7mah\u00b7le", "stifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NE", "PPER", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil ihm bey m\u00fchlen offt das beste spiel geflossen;", "tokens": ["Weil", "ihm", "bey", "m\u00fch\u00b7len", "offt", "das", "bes\u00b7te", "spiel", "ge\u00b7flos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "VMFIN", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Magius sich r\u00fchmt/ da\u00df er ein grosses Buch/", "tokens": ["Ein", "Ma\u00b7gius", "sich", "r\u00fchmt", "/", "da\u00df", "er", "ein", "gros\u00b7ses", "Buch", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "PRF", "VVFIN", "$(", "KOUS", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Wie Campanella gar in fesseln hat geschrieben;", "tokens": ["Wie", "Cam\u00b7pa\u00b7nel\u00b7la", "gar", "in", "fes\u00b7seln", "hat", "ge\u00b7schrie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So fordert ja der geist/ der diesen kiel getrieben/", "tokens": ["So", "for\u00b7dert", "ja", "der", "geist", "/", "der", "die\u00b7sen", "kiel", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$(", "ART", "PDAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zur dinte ceder-safft/ zur taffel purpur-tuch;", "tokens": ["Zur", "din\u00b7te", "ce\u00b7der\u00b7\u00b7safft", "/", "zur", "taf\u00b7fel", "pur\u00b7pur\u00b7tuch", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$(", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Weil unser Lohenstein bey kranckheit und bey sorgen", "tokens": ["Weil", "un\u00b7ser", "Lo\u00b7hen\u00b7stein", "bey", "kran\u00b7ck\u00b7heit", "und", "bey", "sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-+--", "measure": "unknown.measure.hexa"}, "line.10": {"text": "Ihm \u00f6ffters auch die zeit zum schreiben muste borgen.", "tokens": ["Ihm", "\u00f6ff\u00b7ters", "auch", "die", "zeit", "zum", "schrei\u00b7ben", "mus\u00b7te", "bor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ART", "NN", "APPRART", "VVINF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Drum splittert/ wie ihr wolt/ ihr richter kluger welt/", "tokens": ["Drum", "split\u00b7tert", "/", "wie", "ihr", "wolt", "/", "ihr", "rich\u00b7ter", "klu\u00b7ger", "welt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$(", "PWAV", "PPER", "VMFIN", "$(", "PPOSAT", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und macht durch urthel euch zu grossen b\u00fccher-riesen/", "tokens": ["Und", "macht", "durch", "ur\u00b7thel", "euch", "zu", "gros\u00b7sen", "b\u00fc\u00b7cher\u00b7rie\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df/ was eur unverstand an dieser schrift verg\u00e4llt/", "tokens": ["Di\u00df", "/", "was", "eur", "un\u00b7ver\u00b7stand", "an", "die\u00b7ser", "schrift", "ver\u00b7g\u00e4llt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$(", "PWS", "PPOSAT", "NN", "APPR", "PDAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hat/ eh' ihr sie gesehn/ schon der verstand gepriesen.", "tokens": ["Hat", "/", "eh'", "ihr", "sie", "ge\u00b7sehn", "/", "schon", "der", "ver\u00b7stand", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "KOUS", "PPER", "PPER", "VVPP", "$(", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein buch geht wie der meth nicht allen lieblich ein;", "tokens": ["Ein", "buch", "geht", "wie", "der", "me\u00b7th", "nicht", "al\u00b7len", "lieb\u00b7lich", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "ART", "VVFIN", "PTKNEG", "PIAT", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.6": {"text": "Weil viel wie kinder sich am schatten auch ergetzen;", "tokens": ["Weil", "viel", "wie", "kin\u00b7der", "sich", "am", "schat\u00b7ten", "auch", "er\u00b7get\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "KOKOM", "NN", "PRF", "APPRART", "ADJA", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die klugheit nur allein kan hohe seelen sch\u00e4tzen;", "tokens": ["Die", "klug\u00b7heit", "nur", "al\u00b7lein", "kan", "ho\u00b7he", "see\u00b7len", "sch\u00e4t\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VMFIN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und die geheimnisse noch unergr\u00fcndet seyn/", "tokens": ["Und", "die", "ge\u00b7heim\u00b7nis\u00b7se", "noch", "un\u00b7er\u00b7gr\u00fcn\u00b7det", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Warum die rosen nur den bienen geist und leben/", "tokens": ["Wa\u00b7rum", "die", "ro\u00b7sen", "nur", "den", "bie\u00b7nen", "geist", "und", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "ADV", "ART", "ADJA", "NN", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den k\u00e4fern aber nichts als tod und eckel geben.", "tokens": ["Den", "k\u00e4\u00b7fern", "a\u00b7ber", "nichts", "als", "tod", "und", "ec\u00b7kel", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PIS", "KOKOM", "NN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Der wei\u00dfheit muster-platz/ das witzige Athen/", "tokens": ["Der", "wei\u00df\u00b7heit", "mus\u00b7ter\u00b7platz", "/", "das", "wit\u00b7zi\u00b7ge", "A\u00b7then", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Lie\u00df einst Minervens ruhm im tempel auffzusetzen/", "tokens": ["Lie\u00df", "einst", "Mi\u00b7ner\u00b7vens", "ruhm", "im", "tem\u00b7pel", "auff\u00b7zu\u00b7set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "NN", "APPRART", "NN", "VVINF", "$("], "meter": "+-+---+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Befehl an den Alcmen und Phidias ergehen:", "tokens": ["Be\u00b7fehl", "an", "den", "A\u00b7lcmen", "und", "Phi\u00b7di\u00b7as", "er\u00b7ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Sie solten beyderseits ihr bild in marmel \u00e4tzen.", "tokens": ["Sie", "sol\u00b7ten", "bey\u00b7der\u00b7seits", "ihr", "bild", "in", "mar\u00b7mel", "\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die arbeit ward vollbracht; Die urtheil lieffen ein.", "tokens": ["Die", "ar\u00b7beit", "ward", "voll\u00b7bracht", ";", "Die", "ur\u00b7theil", "lief\u00b7fen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und endlich ward der prei\u00df dem ersten zugesprochen;", "tokens": ["Und", "end\u00b7lich", "ward", "der", "prei\u00df", "dem", "ers\u00b7ten", "zu\u00b7ge\u00b7spro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Weil iede linie weit sch\u00e4rffer ausgestochen/", "tokens": ["Weil", "ie\u00b7de", "li\u00b7nie", "weit", "sch\u00e4rf\u00b7fer", "aus\u00b7ge\u00b7sto\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADJD", "ADJD", "VVINF", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Die stellung aber schien von mehrer kunst zu seyn:", "tokens": ["Die", "stel\u00b7lung", "a\u00b7ber", "schien", "von", "meh\u00b7rer", "kunst", "zu", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPR", "PIAT", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und menschen insgemein mit maulwurffs-augen schauen/", "tokens": ["Und", "men\u00b7schen", "ins\u00b7ge\u00b7mein", "mit", "maul\u00b7wurffs\u00b7au\u00b7gen", "schau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was sie/ wie luchsen/ doch sich zu ergr\u00fcnden trauen.", "tokens": ["Was", "sie", "/", "wie", "luch\u00b7sen", "/", "doch", "sich", "zu", "er\u00b7gr\u00fcn\u00b7den", "trau\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "$(", "KOKOM", "VVINF", "$(", "ADV", "PRF", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Doch wie ein seiden-wurm in raupen sich verkehrt;", "tokens": ["Doch", "wie", "ein", "sei\u00b7den\u00b7wurm", "in", "rau\u00b7pen", "sich", "ver\u00b7kehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "APPR", "VVFIN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So muste ieder auch ein ander urtheil f\u00e4llen;", "tokens": ["So", "mus\u00b7te", "ie\u00b7der", "auch", "ein", "an\u00b7der", "ur\u00b7theil", "f\u00e4l\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nachdem dem Phidias sein bitten ward gew\u00e4hrt/", "tokens": ["Nach\u00b7dem", "dem", "Phi\u00b7di\u00b7as", "sein", "bit\u00b7ten", "ward", "ge\u00b7w\u00e4hrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "ADJA", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und man die bilder lie\u00df auff hohe s\u00e4ulen stellen.", "tokens": ["Und", "man", "die", "bil\u00b7der", "lie\u00df", "auff", "ho\u00b7he", "s\u00e4u\u00b7len", "stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn nunmehr machte sich der fehler offenbar/", "tokens": ["Denn", "nun\u00b7mehr", "mach\u00b7te", "sich", "der", "feh\u00b7ler", "of\u00b7fen\u00b7bar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und lie\u00df die kluge welt aus allen gliedern lesen:", "tokens": ["Und", "lie\u00df", "die", "klu\u00b7ge", "welt", "aus", "al\u00b7len", "glie\u00b7dern", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df des Alcmenens witz im maase blind gewesen/", "tokens": ["Da\u00df", "des", "A\u00b7lcme\u00b7nens", "witz", "im", "maa\u00b7se", "blind", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NE", "APPRART", "NN", "ADJD", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Phidias sein werck von gr\u00e4der theilung war.", "tokens": ["Und", "Phi\u00b7di\u00b7as", "sein", "werck", "von", "gr\u00e4\u00b7der", "thei\u00b7lung", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So gar kan wissenschafft/ wie silber von der erden/", "tokens": ["So", "gar", "kan", "wis\u00b7sen\u00b7schafft", "/", "wie", "sil\u00b7ber", "von", "der", "er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "VVFIN", "$(", "KOKOM", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Durch eil und unverstand offt \u00fcberwogen werden.", "tokens": ["Durch", "eil", "und", "un\u00b7ver\u00b7stand", "offt", "\u00fc\u00b7ber\u00b7wo\u00b7gen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJD", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Wer der gelehrten welt in ihren tempel gehn", "tokens": ["Wer", "der", "ge\u00b7lehr\u00b7ten", "welt", "in", "ih\u00b7ren", "tem\u00b7pel", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und eine gleichung will mit bild und b\u00fcchern machen/", "tokens": ["Und", "ei\u00b7ne", "glei\u00b7chung", "will", "mit", "bild", "und", "b\u00fc\u00b7chern", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird lernen/ da\u00df wir noch/ nicht anders als Athen/", "tokens": ["Wird", "ler\u00b7nen", "/", "da\u00df", "wir", "noch", "/", "nicht", "an\u00b7ders", "als", "A\u00b7then", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVINF", "$(", "KOUS", "PPER", "ADV", "$(", "PTKNEG", "ADV", "KOKOM", "NE", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Durch fr\u00fches urthel offt das beste werck verlachen.", "tokens": ["Durch", "fr\u00fc\u00b7hes", "ur\u00b7thel", "offt", "das", "bes\u00b7te", "werck", "ver\u00b7la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn wem ist wohl der streit der federn nicht bekandt;", "tokens": ["Denn", "wem", "ist", "wohl", "der", "streit", "der", "fe\u00b7dern", "nicht", "be\u00b7kandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer wei\u00df nicht/ wie sich wesp' und honigseim verbinden?", "tokens": ["Wer", "wei\u00df", "nicht", "/", "wie", "sich", "wesp'", "und", "ho\u00b7ni\u00b7gseim", "ver\u00b7bin\u00b7den", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "$(", "PWAV", "PRF", "PTKVZ", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die meisten fliegen sind bey marcipan zu finden;", "tokens": ["Die", "meis\u00b7ten", "flie\u00b7gen", "sind", "bey", "mar\u00b7ci\u00b7pan", "zu", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "VAFIN", "APPR", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die sch\u00f6nste stirne wird von warmer lufft verbrannt;", "tokens": ["Die", "sch\u00f6ns\u00b7te", "stir\u00b7ne", "wird", "von", "war\u00b7mer", "lufft", "ver\u00b7brannt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So wird der besten schrifft/ nachdem sie nur gebohren/", "tokens": ["So", "wird", "der", "bes\u00b7ten", "schrifft", "/", "nach\u00b7dem", "sie", "nur", "ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "VVFIN", "$(", "KOUS", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Auch die verleumdung bald zum schatten auserkohren.", "tokens": ["Auch", "die", "ver\u00b7leum\u00b7dung", "bald", "zum", "schat\u00b7ten", "au\u00b7ser\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "APPRART", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Der weise Plato ward vom sch\u00fcler schon verlacht;", "tokens": ["Der", "wei\u00b7se", "Pla\u00b7to", "ward", "vom", "sch\u00fc\u00b7ler", "schon", "ver\u00b7lacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VAFIN", "APPRART", "ADJA", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der g\u00fcldne Cicero vom Crispus umgetrieben.", "tokens": ["Der", "g\u00fcld\u00b7ne", "Ci\u00b7ce\u00b7ro", "vom", "Cris\u00b7pus", "um\u00b7ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Polybius wird noch in schulen offt veracht;", "tokens": ["Po\u00b7ly\u00b7bius", "wird", "noch", "in", "schu\u00b7len", "offt", "ver\u00b7acht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "APPR", "VVFIN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Da keiner doch so treu von Deutschen hat geschrieben.", "tokens": ["Da", "kei\u00b7ner", "doch", "so", "treu", "von", "Deut\u00b7schen", "hat", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "ADJD", "APPR", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Scioppius verwirfft den klugen Tacitus;", "tokens": ["Sciop\u00b7pius", "ver\u00b7wirfft", "den", "klu\u00b7gen", "Ta\u00b7ci\u00b7tus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Weil er der laster brunn im Nero nicht verschwiegen:", "tokens": ["Weil", "er", "der", "las\u00b7ter", "brunn", "im", "Ne\u00b7ro", "nicht", "ver\u00b7schwie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPRART", "NE", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ja Strabo suchet schon im Metrodorus l\u00fcgen/", "tokens": ["Ja", "Stra\u00b7bo", "su\u00b7chet", "schon", "im", "Me\u00b7tro\u00b7do\u00b7rus", "l\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NE", "VVFIN", "ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und hat an m\u00e4ngeln doch selbst einen \u00fcberflu\u00df.", "tokens": ["Und", "hat", "an", "m\u00e4n\u00b7geln", "doch", "selbst", "ei\u00b7nen", "\u00fc\u00b7berf\u00b7lu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So artig wissen wir durch urthel unsre flecken/", "tokens": ["So", "ar\u00b7tig", "wis\u00b7sen", "wir", "durch", "ur\u00b7thel", "uns\u00b7re", "fle\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "APPR", "NE", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie parden ihre haut im laube/ zu verstecken.", "tokens": ["Wie", "par\u00b7den", "ih\u00b7re", "haut", "im", "lau\u00b7be", "/", "zu", "ver\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "VVFIN", "APPRART", "NN", "$(", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Ein eintzig kopff geb\u00fchrt offt tausendfachen streit/", "tokens": ["Ein", "eint\u00b7zig", "kopff", "ge\u00b7b\u00fchrt", "offt", "tau\u00b7send\u00b7fa\u00b7chen", "streit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gleichwie ein finsterni\u00df im meere tausend wellen.", "tokens": ["Gleich\u00b7wie", "ein", "fins\u00b7ter\u00b7ni\u00df", "im", "mee\u00b7re", "tau\u00b7send", "wel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "ADJA", "CARD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum schilt Riccobonus der R\u00f6mer lieblichkeit/", "tokens": ["Drum", "schilt", "Ric\u00b7co\u00b7bo\u00b7nus", "der", "R\u00f6\u00b7mer", "lieb\u00b7lich\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil ihre federn nicht nach seiner zunge quellen;", "tokens": ["Weil", "ih\u00b7re", "fe\u00b7dern", "nicht", "nach", "sei\u00b7ner", "zun\u00b7ge", "quel\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und meynt/ da\u00df Plinius viel worte nur geschmiert/", "tokens": ["Und", "meynt", "/", "da\u00df", "Pli\u00b7nius", "viel", "wor\u00b7te", "nur", "ge\u00b7schmiert", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "NE", "PIAT", "NN", "ADV", "VVPP", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Der Tacitus zu rauh/ und Flor zu kurtz geschrieben;", "tokens": ["Der", "Ta\u00b7ci\u00b7tus", "zu", "rauh", "/", "und", "Flor", "zu", "kurtz", "ge\u00b7schrie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "PTKA", "ADJD", "$(", "KON", "NN", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sveton und Spartian die sprache schlecht getrieben/", "tokens": ["Sve\u00b7ton", "und", "Spar\u00b7ti\u00b7an", "die", "spra\u00b7che", "schlecht", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "ART", "ADJA", "ADJD", "VVPP", "$("], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.8": {"text": "Und endlich Marcellin zu harte reden f\u00fchrt.", "tokens": ["Und", "end\u00b7lich", "Mar\u00b7cel\u00b7lin", "zu", "har\u00b7te", "re\u00b7den", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "APPR", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Als ob der sonnen licht die strahlung von den sternen/", "tokens": ["Als", "ob", "der", "son\u00b7nen", "licht", "die", "strah\u00b7lung", "von", "den", "ster\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "ADJA", "NN", "ART", "NN", "APPR", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Rom aber r\u00f6misch noch von kindern solte lernen.", "tokens": ["Rom", "a\u00b7ber", "r\u00f6\u00b7misch", "noch", "von", "kin\u00b7dern", "sol\u00b7te", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJD", "ADV", "APPR", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Der alten possen-spiel trifft auch die neue welt/", "tokens": ["Der", "al\u00b7ten", "pos\u00b7sen\u00b7spiel", "trifft", "auch", "die", "neu\u00b7e", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nur da\u00df person und platz im spiele sich verkehren.", "tokens": ["Nur", "da\u00df", "per\u00b7son", "und", "platz", "im", "spie\u00b7le", "sich", "ver\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NE", "KON", "NN", "APPRART", "VVFIN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des Comin\u00e4us ruhm/ den Gallien erh\u00e4lt/", "tokens": ["Des", "Co\u00b7mi\u00b7n\u00e4us", "ruhm", "/", "den", "Gal\u00b7li\u00b7en", "er\u00b7h\u00e4lt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "ART", "NE", "VVFIN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Sucht Mejer/ wie der blitz die cedern/ zu verzehren.", "tokens": ["Sucht", "Me\u00b7jer", "/", "wie", "der", "blitz", "die", "ce\u00b7dern", "/", "zu", "ver\u00b7zeh\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$(", "KOKOM", "ART", "NN", "ART", "NN", "$(", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sleidanus arbeit wird von vielen schlecht gesch\u00e4tzt/", "tokens": ["Slei\u00b7da\u00b7nus", "ar\u00b7beit", "wird", "von", "vie\u00b7len", "schlecht", "ge\u00b7sch\u00e4tzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "APPR", "PIAT", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und hat/ wie Strada/ schon ihr urthel recht erlitten.", "tokens": ["Und", "hat", "/", "wie", "Stra\u00b7da", "/", "schon", "ihr", "ur\u00b7thel", "recht", "er\u00b7lit\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$(", "KOKOM", "NE", "$(", "ADV", "PPOSAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie hatte den Thuan Baptista nicht verschnitten?", "tokens": ["Wie", "hat\u00b7te", "den", "Thu\u00b7an", "Bap\u00b7tis\u00b7ta", "nicht", "ver\u00b7schnit\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NE", "NE", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-++-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Wie ward dem Lipsius die feder nicht gewetzt?", "tokens": ["Wie", "ward", "dem", "Lip\u00b7sius", "die", "fe\u00b7der", "nicht", "ge\u00b7wetzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NE", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Und was will Cromer nicht vor fehler andern zeigen/", "tokens": ["Und", "was", "will", "Cro\u00b7mer", "nicht", "vor", "feh\u00b7ler", "an\u00b7dern", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "NN", "PTKNEG", "APPR", "ADJD", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die doch bey dutzenden aus seinen schrifften steigen?", "tokens": ["Die", "doch", "bey", "dut\u00b7zen\u00b7den", "aus", "sei\u00b7nen", "schriff\u00b7ten", "stei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Das macht/ die meisten seyn vor grossem eyffer blind/", "tokens": ["Das", "macht", "/", "die", "meis\u00b7ten", "seyn", "vor", "gros\u00b7sem", "eyf\u00b7fer", "blind", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "ART", "PIS", "VAINF", "APPR", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und f\u00fchren gall und zorn im kopffe wie sardellen:", "tokens": ["Und", "f\u00fch\u00b7ren", "gall", "und", "zorn", "im", "kopf\u00b7fe", "wie", "sar\u00b7del\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "KON", "NN", "APPRART", "VVFIN", "KOKOM", "VVINF", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Drum kan ihr urthel/ das von wermuth fast zerrinnt/", "tokens": ["Drum", "kan", "ihr", "ur\u00b7thel", "/", "das", "von", "wer\u00b7muth", "fast", "zer\u00b7rinnt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPOSAT", "NN", "$(", "ART", "APPR", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie quitten nicht zugleich mit mu\u00dfcateller qvellen.", "tokens": ["Wie", "quit\u00b7ten", "nicht", "zu\u00b7gleich", "mit", "mu\u00df\u00b7ca\u00b7tel\u00b7ler", "qvel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PTKNEG", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+--++-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Den andern mangelt gar zuweilen der verstand/", "tokens": ["Den", "an\u00b7dern", "man\u00b7gelt", "gar", "zu\u00b7wei\u00b7len", "der", "ver\u00b7stand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "ADV", "ART", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So wie den krebsen blut/ und wilden b\u00e4umen feigen:", "tokens": ["So", "wie", "den", "kreb\u00b7sen", "blut", "/", "und", "wil\u00b7den", "b\u00e4u\u00b7men", "fei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "$(", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ja wenn ihr geist sich soll im alterthume zeigen/", "tokens": ["Ja", "wenn", "ihr", "geist", "sich", "soll", "im", "al\u00b7ter\u00b7thu\u00b7me", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "PPER", "VVFIN", "PRF", "VMFIN", "APPRART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So ist den \u00e4rmsten offt das jota kaum bekandt;", "tokens": ["So", "ist", "den", "\u00e4rms\u00b7ten", "offt", "das", "jo\u00b7ta", "kaum", "be\u00b7kandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "ADV", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und dennoch soll ihr ruhm nach tausend klugen Griechen/", "tokens": ["Und", "den\u00b7noch", "soll", "ihr", "ruhm", "nach", "tau\u00b7send", "klu\u00b7gen", "Grie\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPOSAT", "NN", "APPR", "CARD", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und ihre feder/ wie Cardanus athem/ riechen.", "tokens": ["Und", "ih\u00b7re", "fe\u00b7der", "/", "wie", "Car\u00b7da\u00b7nus", "at\u00b7hem", "/", "rie\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$(", "KOKOM", "NE", "NE", "$(", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.27": {"line.1": {"text": "Doch rechte wei\u00dfheit bleibt so wenig unterdr\u00fcckt/", "tokens": ["Doch", "rech\u00b7te", "wei\u00df\u00b7heit", "bleibt", "so", "we\u00b7nig", "un\u00b7ter\u00b7dr\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "ADV", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als Pyrrhus edles hertz im feuer kan verbrennen.", "tokens": ["Als", "Pyrr\u00b7hus", "ed\u00b7les", "hertz", "im", "feu\u00b7er", "kan", "ver\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADJA", "NN", "APPRART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn sterne werden doch durch gla\u00df und kunst erblickt;", "tokens": ["Denn", "ster\u00b7ne", "wer\u00b7den", "doch", "durch", "gla\u00df", "und", "kunst", "er\u00b7blickt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADV", "APPR", "NN", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und purpur lernet man bey reinem purpur kennen:", "tokens": ["Und", "pur\u00b7pur", "ler\u00b7net", "man", "bey", "rei\u00b7nem", "pur\u00b7pur", "ken\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "APPR", "ADJA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So steigt der b\u00fccher glantz auch endlich himmel an/", "tokens": ["So", "steigt", "der", "b\u00fc\u00b7cher", "glantz", "auch", "end\u00b7lich", "him\u00b7mel", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ADV", "ADV", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn ihre schrifften sich auff hohe s\u00e4ulen stellen.", "tokens": ["Wenn", "ih\u00b7re", "schriff\u00b7ten", "sich", "auff", "ho\u00b7he", "s\u00e4u\u00b7len", "stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "VVFIN", "PRF", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das ist: wenn witz und flei\u00df das urtheil dr\u00fcber f\u00e4llen/", "tokens": ["Das", "ist", ":", "wenn", "witz", "und", "flei\u00df", "das", "ur\u00b7theil", "dr\u00fc\u00b7ber", "f\u00e4l\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$.", "KOUS", "NE", "KON", "VVFIN", "ART", "NN", "PAV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und der gelehrten spruch dem p\u00f6fel dargethan:", "tokens": ["Und", "der", "ge\u00b7lehr\u00b7ten", "spruch", "dem", "p\u00f6\u00b7fel", "dar\u00b7ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie wenig den Bodin ein Sergius erreichen/", "tokens": ["Wie", "we\u00b7nig", "den", "Bo\u00b7din", "ein", "Ser\u00b7gius", "er\u00b7rei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "ART", "NE", "VVINF", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.10": {"text": "Und sich Pallavicin kan einem Svavis gleichen.", "tokens": ["Und", "sich", "Pal\u00b7la\u00b7vi\u00b7cin", "kan", "ei\u00b7nem", "Sva\u00b7vis", "glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "NN", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Die arbeit Lohensteins hat beydes schon erlebt/", "tokens": ["Die", "ar\u00b7beit", "Lo\u00b7hen\u00b7steins", "hat", "bey\u00b7des", "schon", "er\u00b7lebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VAFIN", "PIS", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Eh noch ihr wesen recht zu leben angefangen.", "tokens": ["Eh", "noch", "ihr", "we\u00b7sen", "recht", "zu", "le\u00b7ben", "an\u00b7ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPER", "VVFIN", "ADJD", "PTKZU", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn vielen ist der ruhm/ der ihren geist erhebt/", "tokens": ["Denn", "vie\u00b7len", "ist", "der", "ruhm", "/", "der", "ih\u00b7ren", "geist", "er\u00b7hebt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ART", "NN", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht anders als der senff in nasen auffgegangen;", "tokens": ["Nicht", "an\u00b7ders", "als", "der", "senff", "in", "na\u00b7sen", "auff\u00b7ge\u00b7gan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "KOKOM", "ART", "CARD", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Viel haben ihren mosch mit pfeffer \u00fcberstreut/", "tokens": ["Viel", "ha\u00b7ben", "ih\u00b7ren", "mosch", "mit", "pfef\u00b7fer", "\u00fc\u00b7bers\u00b7treut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und nur wie Araber den balsam angerochen;", "tokens": ["Und", "nur", "wie", "A\u00b7ra\u00b7ber", "den", "bal\u00b7sam", "an\u00b7ge\u00b7ro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOKOM", "NN", "ART", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bi\u00df recht und klugheit ihr die palmen zugesprochen/", "tokens": ["Bi\u00df", "recht", "und", "klug\u00b7heit", "ihr", "die", "pal\u00b7men", "zu\u00b7ge\u00b7spro\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "NN", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und endlich wahr gemacht: da\u00df eyfersucht und neid/", "tokens": ["Und", "end\u00b7lich", "wahr", "ge\u00b7macht", ":", "da\u00df", "ey\u00b7fer\u00b7sucht", "und", "neid", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVPP", "$.", "KOUS", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie d\u00fcnste/ durch die glut der sonnen auff der erden/", "tokens": ["Wie", "d\u00fcns\u00b7te", "/", "durch", "die", "glut", "der", "son\u00b7nen", "auff", "der", "er\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$(", "APPR", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Durch schrifften zwar erregt/ doch auch gebrochen werden.", "tokens": ["Durch", "schriff\u00b7ten", "zwar", "er\u00b7regt", "/", "doch", "auch", "ge\u00b7bro\u00b7chen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADV", "VVPP", "$(", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Itzt tritt der andre theil in die gelehrte welt/", "tokens": ["Itzt", "tritt", "der", "and\u00b7re", "theil", "in", "die", "ge\u00b7lehr\u00b7te", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sich an dem ehrenprei\u00df des ersten zu ergetzen/", "tokens": ["Sich", "an", "dem", "eh\u00b7ren\u00b7prei\u00df", "des", "ers\u00b7ten", "zu", "er\u00b7get\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "ART", "ADJA", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und will den blumen-tantz/ den jener vorgestellt/", "tokens": ["Und", "will", "den", "blu\u00b7men\u00b7tantz", "/", "den", "je\u00b7ner", "vor\u00b7ge\u00b7stellt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "$(", "ART", "PDS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch einen wunder-streit von b\u00e4umen hier ersetzen.", "tokens": ["Durch", "ei\u00b7nen", "wun\u00b7der\u00b7streit", "von", "b\u00e4u\u00b7men", "hier", "er\u00b7set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vielleicht zum zeugnisse: da\u00df rosen und jesmin/", "tokens": ["Viel\u00b7leicht", "zum", "zeug\u00b7nis\u00b7se", ":", "da\u00df", "ro\u00b7sen", "und", "jes\u00b7min", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$.", "KOUS", "NE", "KON", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch am geruche noch dem myrrhen-saffte weichen/", "tokens": ["Doch", "am", "ge\u00b7ru\u00b7che", "noch", "dem", "myr\u00b7rhen\u00b7\u00b7saff\u00b7te", "wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "ADV", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Chineser \u00e4pffel mehr als liljen anmuth reichen/", "tokens": ["Chi\u00b7ne\u00b7ser", "\u00e4pf\u00b7fel", "mehr", "als", "lil\u00b7jen", "an\u00b7muth", "rei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PIAT", "KOKOM", "ADJA", "NN", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Und b\u00fccher insgemein mit grosser arbeit bl\u00fchn;", "tokens": ["Und", "b\u00fc\u00b7cher", "ins\u00b7ge\u00b7mein", "mit", "gros\u00b7ser", "ar\u00b7beit", "bl\u00fchn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Im schliessen aber so wie reiffende morellen/", "tokens": ["Im", "schlies\u00b7sen", "a\u00b7ber", "so", "wie", "reif\u00b7fen\u00b7de", "mo\u00b7rel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "ADV", "ADV", "KOKOM", "ADJA", "NN", "$("], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.10": {"text": "Auch von sich selber offt mit s\u00fcssem zucker qvellen.", "tokens": ["Auch", "von", "sich", "sel\u00b7ber", "offt", "mit", "s\u00fcs\u00b7sem", "zu\u00b7cker", "qvel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PRF", "ADV", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Und warlich allzu recht. Denn dorten blitzt der krieg/", "tokens": ["Und", "war\u00b7lich", "all\u00b7zu", "recht", ".", "Denn", "dor\u00b7ten", "blitzt", "der", "krieg", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKA", "ADJD", "$.", "KON", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und l\u00e4st das teutsche reich in flammen fast zerfliessen;", "tokens": ["Und", "l\u00e4st", "das", "teut\u00b7sche", "reich", "in", "flam\u00b7men", "fast", "zer\u00b7flies\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "ADJD", "APPR", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier schleu\u00dft Arminius den friedens-vollen sieg/", "tokens": ["Hier", "schleu\u00dft", "Ar\u00b7mi\u00b7nius", "den", "frie\u00b7dens\u00b7vol\u00b7len", "sieg", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Und hat das vaterland der R\u00f6mer macht entrissen.", "tokens": ["Und", "hat", "das", "va\u00b7ter\u00b7land", "der", "R\u00f6\u00b7mer", "macht", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das erste haben schon die barbarn ausgedacht;", "tokens": ["Das", "ers\u00b7te", "ha\u00b7ben", "schon", "die", "bar\u00b7barn", "aus\u00b7ge\u00b7dacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier aber werden viel die klugen lehren finden:", "tokens": ["Hier", "a\u00b7ber", "wer\u00b7den", "viel", "die", "klu\u00b7gen", "leh\u00b7ren", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df/ wer den frieden will auff blosses eisen gr\u00fcnden/", "tokens": ["Da\u00df", "/", "wer", "den", "frie\u00b7den", "will", "auff", "blos\u00b7ses", "ei\u00b7sen", "gr\u00fcn\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "PWS", "ART", "NN", "VMFIN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ihn/ wie oliven-safft in bley/ zu nichte macht/", "tokens": ["Ihn", "/", "wie", "o\u00b7li\u00b7ven\u00b7\u00b7safft", "in", "bley", "/", "zu", "nich\u00b7te", "macht", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "KOKOM", "NN", "APPR", "NN", "$(", "PTKA", "PIS", "VVFIN", "$("], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Und f\u00fcrsten r\u00fchmlicher mit schlauen crocodilen/", "tokens": ["Und", "f\u00fcrs\u00b7ten", "r\u00fchm\u00b7li\u00b7cher", "mit", "schlau\u00b7en", "cro\u00b7co\u00b7di\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Durch weichen und verstand/ als scharffe waffen spielen.", "tokens": ["Durch", "wei\u00b7chen", "und", "ver\u00b7stand", "/", "als", "scharf\u00b7fe", "waf\u00b7fen", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "KON", "VVFIN", "$(", "KOUS", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Wo aber heb' ich an/ den ungemeinen geist", "tokens": ["Wo", "a\u00b7ber", "heb'", "ich", "an", "/", "den", "un\u00b7ge\u00b7mei\u00b7nen", "geist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "PTKVZ", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des edlen Lohensteins nach w\u00fcrden auszudr\u00fccken?", "tokens": ["Des", "ed\u00b7len", "Lo\u00b7hen\u00b7steins", "nach", "w\u00fcr\u00b7den", "aus\u00b7zu\u00b7dr\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "VAFIN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der/ was in andern man nur glieder-weise preist/", "tokens": ["Der", "/", "was", "in", "an\u00b7dern", "man", "nur", "glie\u00b7der\u00b7wei\u00b7se", "preist", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "PWS", "APPR", "ADJA", "PIS", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hier voller wunder l\u00e4st aus einem buche blicken.", "tokens": ["Hier", "vol\u00b7ler", "wun\u00b7der", "l\u00e4st", "aus", "ei\u00b7nem", "bu\u00b7che", "bli\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn auch gelehrte sind mit ihrer phantasey/", "tokens": ["Denn", "auch", "ge\u00b7lehr\u00b7te", "sind", "mit", "ih\u00b7rer", "phan\u00b7ta\u00b7sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "VAFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie affen offtermahls mit honig/ nicht zu f\u00fcllen;", "tokens": ["Wie", "af\u00b7fen", "off\u00b7ter\u00b7mahls", "mit", "ho\u00b7nig", "/", "nicht", "zu", "f\u00fcl\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "APPR", "NN", "$(", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Drum mi\u00dft Mirandula der grobheit tausend grillen/", "tokens": ["Drum", "mi\u00dft", "Mi\u00b7ran\u00b7du\u00b7la", "der", "grob\u00b7heit", "tau\u00b7send", "gril\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "ART", "NN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Anaxagoras dem monde berge bey.", "tokens": ["Und", "A\u00b7na\u00b7xa\u00b7go\u00b7ras", "dem", "mon\u00b7de", "ber\u00b7ge", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er aber war bem\u00fcht/ wie bienen zu ergr\u00fcnden/", "tokens": ["Er", "a\u00b7ber", "war", "be\u00b7m\u00fcht", "/", "wie", "bie\u00b7nen", "zu", "er\u00b7gr\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "VVPP", "$(", "KOKOM", "VVINF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie man viel blumen soll in einen teig verbinden.", "tokens": ["Wie", "man", "viel", "blu\u00b7men", "soll", "in", "ei\u00b7nen", "teig", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "VVINF", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Der menschen erstes licht ist himmel und natur/", "tokens": ["Der", "men\u00b7schen", "ers\u00b7tes", "licht", "ist", "him\u00b7mel", "und", "na\u00b7tur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VAFIN", "NN", "KON", "NN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Wie schwefel-werck und saltz das leben dieser erden.", "tokens": ["Wie", "schwe\u00b7fel\u00b7\u00b7werck", "und", "saltz", "das", "le\u00b7ben", "die\u00b7ser", "er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "ADJD", "PDS", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein unvern\u00fcnfftig thier mu\u00df witzig durch die spur/", "tokens": ["Ein", "un\u00b7ver\u00b7n\u00fcnff\u00b7tig", "thier", "mu\u00df", "wit\u00b7zig", "durch", "die", "spur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VMFIN", "ADJD", "APPR", "ART", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die seele durch vernunfft zu einem engel werden.", "tokens": ["Die", "see\u00b7le", "durch", "ver\u00b7nunfft", "zu", "ei\u00b7nem", "en\u00b7gel", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer sieht nicht/ was sein flei\u00df vor proben abgelegt?", "tokens": ["Wer", "sieht", "nicht", "/", "was", "sein", "flei\u00df", "vor", "pro\u00b7ben", "ab\u00b7ge\u00b7legt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "$(", "PWS", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie er das kluge wachs der alten umgegossen/", "tokens": ["Wie", "er", "das", "klu\u00b7ge", "wachs", "der", "al\u00b7ten", "um\u00b7ge\u00b7gos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "ART", "ADJA", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den geist des Socrates von neuem auffgeschlossen/", "tokens": ["Den", "geist", "des", "So\u00b7cra\u00b7tes", "von", "neu\u00b7em", "auff\u00b7ge\u00b7schlos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ADJA", "VVINF", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Den weisen Seneca Thusnelden eingepr\u00e4gt/", "tokens": ["Den", "wei\u00b7sen", "Se\u00b7ne\u00b7ca", "Thus\u00b7nel\u00b7den", "ein\u00b7ge\u00b7pr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und endlich durch sein licht im schreiben mehr erwiesen/", "tokens": ["Und", "end\u00b7lich", "durch", "sein", "licht", "im", "schrei\u00b7ben", "mehr", "er\u00b7wie\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "APPRART", "VVFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als man an dem Petrarch' und Loredan gepriesen.", "tokens": ["Als", "man", "an", "dem", "Pe\u00b7tra\u00b7rch'", "und", "Lo\u00b7re\u00b7dan", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "KON", "NE", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.33": {"line.1": {"text": "Die staats-kunst/ die nechst Gott des scepters auge seyn/", "tokens": ["Die", "staats\u00b7kunst", "/", "die", "nechst", "Gott", "des", "scep\u00b7ters", "au\u00b7ge", "seyn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "VVFIN", "NN", "ART", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und f\u00fcrsten/ wie den leib der schatten soll bedecken/", "tokens": ["Und", "f\u00fcrs\u00b7ten", "/", "wie", "den", "leib", "der", "schat\u00b7ten", "soll", "be\u00b7de\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOKOM", "ART", "NN", "ART", "ADJA", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schleu\u00dft er weit lustiger in liebes-zucker ein;", "tokens": ["Schleu\u00dft", "er", "weit", "lus\u00b7ti\u00b7ger", "in", "lie\u00b7bes\u00b7zu\u00b7cker", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJD", "APPR", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Als sie Savedra wei\u00df in bilder zu verstecken.", "tokens": ["Als", "sie", "Sa\u00b7ve\u00b7dra", "wei\u00df", "in", "bil\u00b7der", "zu", "ver\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "VVFIN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der tieffe Gracian legt seinen Ferdinand/", "tokens": ["Der", "tief\u00b7fe", "Gra\u00b7ci\u00b7an", "legt", "sei\u00b7nen", "Fer\u00b7di\u00b7nand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie eher sich August/ vor seinem Hermann nieder.", "tokens": ["Wie", "e\u00b7her", "sich", "Au\u00b7gust", "/", "vor", "sei\u00b7nem", "Her\u00b7mann", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PRF", "NN", "$(", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Uns aber scheint der glantz der alten zeiten wieder;", "tokens": ["Uns", "a\u00b7ber", "scheint", "der", "glantz", "der", "al\u00b7ten", "zei\u00b7ten", "wie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Weil wir des letzten bild im Leopold erkannt/", "tokens": ["Weil", "wir", "des", "letz\u00b7ten", "bild", "im", "Leo\u00b7pold", "er\u00b7kannt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPRART", "NE", "VVPP", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Und uns ein Lohenstein in alten finsternissen", "tokens": ["Und", "uns", "ein", "Lo\u00b7hen\u00b7stein", "in", "al\u00b7ten", "fins\u00b7ter\u00b7nis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ART", "NN", "APPR", "ADJA", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die sonne dieser zeit so artig abgerissen.", "tokens": ["Die", "son\u00b7ne", "die\u00b7ser", "zeit", "so", "ar\u00b7tig", "ab\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Doch staats-gedancken sind in f\u00fcrsten kinder-art/", "tokens": ["Doch", "staats\u00b7ge\u00b7dan\u00b7cken", "sind", "in", "f\u00fcrs\u00b7ten", "kin\u00b7der\u00b7art", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn beyde pflegen sich beym feuer zu verbrennen/", "tokens": ["Denn", "bey\u00b7de", "pfle\u00b7gen", "sich", "beym", "feu\u00b7er", "zu", "ver\u00b7bren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PRF", "APPRART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So lange nicht ihr witz sich mit erfahrung paart/", "tokens": ["So", "lan\u00b7ge", "nicht", "ihr", "witz", "sich", "mit", "er\u00b7fah\u00b7rung", "paart", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "PPOSAT", "NN", "PRF", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sie ihr ungel\u00fcck aus fremder angst erkennen.", "tokens": ["Und", "sie", "ihr", "un\u00b7ge\u00b7l\u00fcck", "aus", "frem\u00b7der", "angst", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum laufft sein eyffer auch in die vergangne welt/", "tokens": ["Drum", "laufft", "sein", "eyf\u00b7fer", "auch", "in", "die", "ver\u00b7gang\u00b7ne", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und forscht/ woher der brunn der Deutschen sey entsprungen/", "tokens": ["Und", "forscht", "/", "wo\u00b7her", "der", "brunn", "der", "Deut\u00b7schen", "sey", "ent\u00b7sprun\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "PWAV", "ART", "NN", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie weit der Marobod den degen hat geschwungen/", "tokens": ["Wie", "weit", "der", "Ma\u00b7ro\u00b7bod", "den", "de\u00b7gen", "hat", "ge\u00b7schwun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und das verh\u00e4ngni\u00df Rom die grentzen ausgestellt?", "tokens": ["Und", "das", "ver\u00b7h\u00e4ng\u00b7ni\u00df", "Rom", "die", "grent\u00b7zen", "aus\u00b7ge\u00b7stellt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NE", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch so/ da\u00df mehrentheils gleich wie in purpur-schnecken/", "tokens": ["Doch", "so", "/", "da\u00df", "meh\u00b7ren\u00b7theils", "gleich", "wie", "in", "pur\u00b7pur\u00b7schne\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "KOUS", "ADV", "ADV", "KOKOM", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die perlen neuer zeit in alten schalen stecken.", "tokens": ["Die", "per\u00b7len", "neu\u00b7er", "zeit", "in", "al\u00b7ten", "scha\u00b7len", "ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "APPR", "ADJA", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Di\u00df ernst-erf\u00fcllte werck mischt sein ge\u00fcbter geist/", "tokens": ["Di\u00df", "ernst\u00b7er\u00b7f\u00fcll\u00b7te", "werck", "mischt", "sein", "ge\u00b7\u00fcb\u00b7ter", "geist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie k\u00f6che kostbar fleisch mit s\u00fcssen mandel-kuchen/", "tokens": ["Wie", "k\u00f6\u00b7che", "kost\u00b7bar", "fleisch", "mit", "s\u00fcs\u00b7sen", "man\u00b7del\u00b7ku\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADJD", "ADJD", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn er die eigenschafft der dinge besser weist/", "tokens": ["Wenn", "er", "die", "ei\u00b7gen\u00b7schafft", "der", "din\u00b7ge", "bes\u00b7ser", "weist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als Schott- und Lemnius mit vieler arbeit suchen:", "tokens": ["Als", "Schot\u00b7t", "und", "Lem\u00b7ni\u00b7us", "mit", "vie\u00b7ler", "ar\u00b7beit", "su\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "TRUNC", "KON", "NE", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Bald auch den gottesdienst der alten welt betracht/", "tokens": ["Bald", "auch", "den", "got\u00b7tes\u00b7dienst", "der", "al\u00b7ten", "welt", "be\u00b7tracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und seine fehler wei\u00df im grunde vorzustellen/", "tokens": ["Und", "sei\u00b7ne", "feh\u00b7ler", "wei\u00df", "im", "grun\u00b7de", "vor\u00b7zu\u00b7stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zu zeigen/ da\u00df auch most den magen kan verg\u00e4llen;", "tokens": ["Zu", "zei\u00b7gen", "/", "da\u00df", "auch", "most", "den", "ma\u00b7gen", "kan", "ver\u00b7g\u00e4l\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "KOUS", "ADV", "ADV", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der beste bisem offt wie knobloch eckel macht/", "tokens": ["Der", "bes\u00b7te", "bi\u00b7sem", "offt", "wie", "kno\u00b7bloch", "ec\u00b7kel", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "ADV", "KOKOM", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und lehren/ wenn wir sie zu viel und h\u00e4uffig brauchen/", "tokens": ["Und", "leh\u00b7ren", "/", "wenn", "wir", "sie", "zu", "viel", "und", "h\u00e4uf\u00b7fig", "brau\u00b7chen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "KOUS", "PPER", "PPER", "APPR", "PIAT", "KON", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie falscher weyrauch leicht ohn alle glut verrauchen.", "tokens": ["Wie", "fal\u00b7scher", "wey\u00b7rauch", "leicht", "ohn", "al\u00b7le", "glut", "ver\u00b7rau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "ADJD", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Ich wei\u00df nicht/ ob ich auch noch von der poesie/", "tokens": ["Ich", "wei\u00df", "nicht", "/", "ob", "ich", "auch", "noch", "von", "der", "po\u00b7e\u00b7sie", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "KOUS", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der feder Lohensteins soll ihren ruhm erheben?", "tokens": ["Der", "fe\u00b7der", "Lo\u00b7hen\u00b7steins", "soll", "ih\u00b7ren", "ruhm", "er\u00b7he\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn ver\u00dfe kosten so/ wie blumen/ grosse m\u00fch/", "tokens": ["Denn", "ver\u00b7\u00dfe", "kos\u00b7ten", "so", "/", "wie", "blu\u00b7men", "/", "gros\u00b7se", "m\u00fch", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVFIN", "ADV", "$(", "KOKOM", "NN", "$(", "ADJA", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da beyde mit der zeit doch keine fr\u00fcchte geben.", "tokens": ["Da", "bey\u00b7de", "mit", "der", "zeit", "doch", "kei\u00b7ne", "fr\u00fcch\u00b7te", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "ADV", "PIAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und hat auff erden gleich ein Constantin regiert/", "tokens": ["Und", "hat", "auff", "er\u00b7den", "gleich", "ein", "Con\u00b7stan\u00b7tin", "re\u00b7giert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+---+-++--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Der nur in seinen rath poeten auffgenommen;", "tokens": ["Der", "nur", "in", "sei\u00b7nen", "rath", "po\u00b7e\u00b7ten", "auff\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So sind doch hundert schon in seine stelle kommen/", "tokens": ["So", "sind", "doch", "hun\u00b7dert", "schon", "in", "sei\u00b7ne", "stel\u00b7le", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "CARD", "ADV", "APPR", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die dieser k\u00f6pffe gold mit flecken angeschmiert/", "tokens": ["Die", "die\u00b7ser", "k\u00f6pf\u00b7fe", "gold", "mit", "fle\u00b7cken", "an\u00b7ge\u00b7schmiert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "ADJA", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und eher gips und kalck/ und stumme marmel-g\u00f6tzen/", "tokens": ["Und", "e\u00b7her", "gips", "und", "kalck", "/", "und", "stum\u00b7me", "mar\u00b7mel\u00b7g\u00f6t\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "KON", "NN", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als einen Sannazar/ auff ihre schrancken setzen.", "tokens": ["Als", "ei\u00b7nen", "San\u00b7na\u00b7zar", "/", "auff", "ih\u00b7re", "schran\u00b7cken", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$(", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Di\u00df aber wei\u00df ich wohl/ da\u00df diese kluge schrifft/", "tokens": ["Di\u00df", "a\u00b7ber", "wei\u00df", "ich", "wohl", "/", "da\u00df", "die\u00b7se", "klu\u00b7ge", "schrifft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "ADV", "$(", "KOUS", "PDAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So wie Erasmus werck aus krancker hand entsprossen;", "tokens": ["So", "wie", "Er\u00b7as\u00b7mus", "werck", "aus", "kran\u00b7cker", "hand", "ent\u00b7spros\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "NE", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn nun ein Plautus ihm noch ehren-mahle stifft/", "tokens": ["Wenn", "nun", "ein", "Plau\u00b7tus", "ihm", "noch", "eh\u00b7ren\u00b7mah\u00b7le", "stifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NE", "PPER", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil ihm bey m\u00fchlen offt das beste spiel geflossen;", "tokens": ["Weil", "ihm", "bey", "m\u00fch\u00b7len", "offt", "das", "bes\u00b7te", "spiel", "ge\u00b7flos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "VMFIN", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Magius sich r\u00fchmt/ da\u00df er ein grosses Buch/", "tokens": ["Ein", "Ma\u00b7gius", "sich", "r\u00fchmt", "/", "da\u00df", "er", "ein", "gros\u00b7ses", "Buch", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "PRF", "VVFIN", "$(", "KOUS", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Wie Campanella gar in fesseln hat geschrieben;", "tokens": ["Wie", "Cam\u00b7pa\u00b7nel\u00b7la", "gar", "in", "fes\u00b7seln", "hat", "ge\u00b7schrie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So fordert ja der geist/ der diesen kiel getrieben/", "tokens": ["So", "for\u00b7dert", "ja", "der", "geist", "/", "der", "die\u00b7sen", "kiel", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$(", "ART", "PDAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zur dinte ceder-safft/ zur taffel purpur-tuch;", "tokens": ["Zur", "din\u00b7te", "ce\u00b7der\u00b7\u00b7safft", "/", "zur", "taf\u00b7fel", "pur\u00b7pur\u00b7tuch", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$(", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Weil unser Lohenstein bey kranckheit und bey sorgen", "tokens": ["Weil", "un\u00b7ser", "Lo\u00b7hen\u00b7stein", "bey", "kran\u00b7ck\u00b7heit", "und", "bey", "sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-+--", "measure": "unknown.measure.hexa"}, "line.10": {"text": "Ihm \u00f6ffters auch die zeit zum schreiben muste borgen.", "tokens": ["Ihm", "\u00f6ff\u00b7ters", "auch", "die", "zeit", "zum", "schrei\u00b7ben", "mus\u00b7te", "bor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ART", "NN", "APPRART", "VVINF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Drum splittert/ wie ihr wolt/ ihr richter kluger welt/", "tokens": ["Drum", "split\u00b7tert", "/", "wie", "ihr", "wolt", "/", "ihr", "rich\u00b7ter", "klu\u00b7ger", "welt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$(", "PWAV", "PPER", "VMFIN", "$(", "PPOSAT", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und macht durch urthel euch zu grossen b\u00fccher-riesen/", "tokens": ["Und", "macht", "durch", "ur\u00b7thel", "euch", "zu", "gros\u00b7sen", "b\u00fc\u00b7cher\u00b7rie\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df/ was eur unverstand an dieser schrift verg\u00e4llt/", "tokens": ["Di\u00df", "/", "was", "eur", "un\u00b7ver\u00b7stand", "an", "die\u00b7ser", "schrift", "ver\u00b7g\u00e4llt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$(", "PWS", "PPOSAT", "NN", "APPR", "PDAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hat/ eh' ihr sie gesehn/ schon der verstand gepriesen.", "tokens": ["Hat", "/", "eh'", "ihr", "sie", "ge\u00b7sehn", "/", "schon", "der", "ver\u00b7stand", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "KOUS", "PPER", "PPER", "VVPP", "$(", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein buch geht wie der meth nicht allen lieblich ein;", "tokens": ["Ein", "buch", "geht", "wie", "der", "me\u00b7th", "nicht", "al\u00b7len", "lieb\u00b7lich", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "ART", "VVFIN", "PTKNEG", "PIAT", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.6": {"text": "Weil viel wie kinder sich am schatten auch ergetzen;", "tokens": ["Weil", "viel", "wie", "kin\u00b7der", "sich", "am", "schat\u00b7ten", "auch", "er\u00b7get\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "KOKOM", "NN", "PRF", "APPRART", "ADJA", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die klugheit nur allein kan hohe seelen sch\u00e4tzen;", "tokens": ["Die", "klug\u00b7heit", "nur", "al\u00b7lein", "kan", "ho\u00b7he", "see\u00b7len", "sch\u00e4t\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VMFIN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und die geheimnisse noch unergr\u00fcndet seyn/", "tokens": ["Und", "die", "ge\u00b7heim\u00b7nis\u00b7se", "noch", "un\u00b7er\u00b7gr\u00fcn\u00b7det", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Warum die rosen nur den bienen geist und leben/", "tokens": ["Wa\u00b7rum", "die", "ro\u00b7sen", "nur", "den", "bie\u00b7nen", "geist", "und", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "ADV", "ART", "ADJA", "NN", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den k\u00e4fern aber nichts als tod und eckel geben.", "tokens": ["Den", "k\u00e4\u00b7fern", "a\u00b7ber", "nichts", "als", "tod", "und", "ec\u00b7kel", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PIS", "KOKOM", "NN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}