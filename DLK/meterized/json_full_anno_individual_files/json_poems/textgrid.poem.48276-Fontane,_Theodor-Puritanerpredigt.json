{"textgrid.poem.48276": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Puritanerpredigt", "genre": "verse", "period": "N.A.", "pub_year": 1849, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": " ... Landsleute, Volk von London, h\u00f6rt mich an:", "tokens": ["...", "Lands\u00b7leu\u00b7te", ",", "Volk", "von", "Lon\u00b7don", ",", "h\u00f6rt", "mich", "an", ":"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$,", "NN", "APPR", "NE", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ihr denkt, der K\u00f6nig ist's; ", "tokens": ["Ihr", "denkt", ",", "der", "K\u00f6\u00b7nig", "ist's", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von Frankreich kommt's und nennt sich", "tokens": ["Von", "Fran\u00b7kreich", "kommt's", "und", "nennt", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NE", "KON", "VVFIN", "PRF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und dazu ", "tokens": ["Und", "da\u00b7zu"], "token_info": ["word", "word"], "pos": ["KON", "PAV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Papistisch alle, Gott dem Herrn ein Greul,", "tokens": ["Pa\u00b7pis\u00b7tisch", "al\u00b7le", ",", "Gott", "dem", "Herrn", "ein", "Greul", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "$,", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Am meisten aber sie, das blut'ge Buhlweib,", "tokens": ["Am", "meis\u00b7ten", "a\u00b7ber", "sie", ",", "das", "blut'\u00b7ge", "Buhl\u00b7weib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "PIS", "ADV", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Das Frankreichs Thron befleckte: ", "tokens": ["Das", "Fran\u00b7kreichs", "Thron", "be\u00b7fleck\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Landsleute, tretet n\u00e4her, h\u00f6rt mich an,", "tokens": ["Lands\u00b7leu\u00b7te", ",", "tre\u00b7tet", "n\u00e4\u00b7her", ",", "h\u00f6rt", "mich", "an", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ADJD", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Von diesem Buhlweib will ich euch erz\u00e4hlen.", "tokens": ["Von", "die\u00b7sem", "Buhl\u00b7weib", "will", "ich", "euch", "er\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Bluthochzeit feierte die Stadt Paris,", "tokens": ["Blut\u00b7hoch\u00b7zeit", "fei\u00b7er\u00b7te", "die", "Stadt", "Pa\u00b7ris", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Glocke Zeichen war in Nacht verklungen,", "tokens": ["Der", "Glo\u00b7cke", "Zei\u00b7chen", "war", "in", "Nacht", "ver\u00b7klun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und durch die Stra\u00dfen, wie gehetztes Wild,", "tokens": ["Und", "durch", "die", "Stra\u00b7\u00dfen", ",", "wie", "ge\u00b7hetz\u00b7tes", "Wild", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wehschreiend, betend, floh der Hugenott.", "tokens": ["Weh\u00b7schrei\u00b7end", ",", "be\u00b7tend", ",", "floh", "der", "Hu\u00b7ge\u00b7nott", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Schon zog ein Blutstreif durch den Seine-Flu\u00df,", "tokens": ["Schon", "zog", "ein", "Blut\u00b7streif", "durch", "den", "Sei\u00b7ne\u00b7Flu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Schon lag verst\u00fcmmelt, siebenfach durchbohrt,", "tokens": ["Schon", "lag", "ver\u00b7st\u00fcm\u00b7melt", ",", "sie\u00b7ben\u00b7fach", "durch\u00b7bohrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVPP", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Auf offnem Platz der greise Coligny,", "tokens": ["Auf", "off\u00b7nem", "Platz", "der", "grei\u00b7se", "Co\u00b7lig\u00b7ny", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und immer noch, den Mord zum Morde mahnend,", "tokens": ["Und", "im\u00b7mer", "noch", ",", "den", "Mord", "zum", "Mor\u00b7de", "mah\u00b7nend", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$,", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbla\u00dft Ader!\u00ab schrie der t\u00fcckische Tavannes.", "tokens": ["\u00bb", "la\u00dft", "A\u00b7der", "!", "\u00ab", "schrie", "der", "t\u00fc\u00b7cki\u00b7sche", "Ta\u00b7van\u00b7nes", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "NN", "$.", "$(", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Im Schlosse aber, das sie Louvre nennen,", "tokens": ["Im", "Schlos\u00b7se", "a\u00b7ber", ",", "das", "sie", "Louv\u00b7re", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "$,", "PRELS", "PPER", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "An jener hohen Bogenfenster einem,", "tokens": ["An", "je\u00b7ner", "ho\u00b7hen", "Bo\u00b7gen\u00b7fens\u00b7ter", "ei\u00b7nem", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "ART", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Stand K\u00f6nig Karl, der neunte seines Namens,", "tokens": ["Stand", "K\u00f6\u00b7nig", "Karl", ",", "der", "neun\u00b7te", "sei\u00b7nes", "Na\u00b7mens", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "NE", "$,", "ART", "ADJA", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.13": {"text": "Und zitterte. Der ungeheure Frevel", "tokens": ["Und", "zit\u00b7ter\u00b7te", ".", "Der", "un\u00b7ge\u00b7heu\u00b7re", "Fre\u00b7vel"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Griff ihm ins Herz. Trotz Licht und Fackelglanz", "tokens": ["Griff", "ihm", "ins", "Herz", ".", "Trotz", "Licht", "und", "Fa\u00b7ckel\u00b7glanz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPRART", "NN", "$.", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Nacht war's um ihn. Er warf die B\u00fcchse fort:", "tokens": ["Nacht", "wa\u00b7r's", "um", "ihn", ".", "Er", "warf", "die", "B\u00fcch\u00b7se", "fort", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPER", "$.", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.16": {"text": "\u00bbich ", "tokens": ["\u00bb", "ich"], "token_info": ["punct", "word"], "pos": ["$(", "PPER"], "meter": "-", "measure": "single.down"}, "line.17": {"text": "Da trat sie selber vor, schwarz war ihr Haar,", "tokens": ["Da", "trat", "sie", "sel\u00b7ber", "vor", ",", "schwarz", "war", "ihr", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Schwarz wie der Sammet ihres Schleppenkleides,", "tokens": ["Schwarz", "wie", "der", "Sam\u00b7met", "ih\u00b7res", "Schlep\u00b7pen\u00b7klei\u00b7des", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOKOM", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.19": {"text": "Und ihrem Aug' entflammte tiefre Glut", "tokens": ["Und", "ih\u00b7rem", "Aug'", "ent\u00b7flamm\u00b7te", "tief\u00b7re", "Glut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Als dem Rubin, der ihr am Nacken blitzte.", "tokens": ["Als", "dem", "Ru\u00b7bin", ",", "der", "ihr", "am", "Na\u00b7cken", "blitz\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NE", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.21": {"text": "\u00bbbist du ein Mann?\u00ab so raunte sie ihm zu,", "tokens": ["\u00bb", "bist", "du", "ein", "Mann", "?", "\u00ab", "so", "raun\u00b7te", "sie", "ihm", "zu", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ART", "NN", "$.", "$(", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "\u00bbein K\u00f6nig und so feig? ich mag's nicht glauben.\u00ab", "tokens": ["\u00bb", "ein", "K\u00f6\u00b7nig", "und", "so", "feig", "?", "ich", "mag's", "nicht", "glau\u00b7ben", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "KON", "ADV", "ADJD", "$.", "PPER", "VMFIN", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Ergriff er neu das Rohr, sie aber rief:", "tokens": ["Er\u00b7griff", "er", "neu", "das", "Rohr", ",", "sie", "a\u00b7ber", "rief", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "NN", "$,", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "\u00bbschau dort das Weib, das Hugenottenweib,", "tokens": ["\u00bb", "schau", "dort", "das", "Weib", ",", "das", "Hu\u00b7ge\u00b7not\u00b7ten\u00b7weib", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "ADV", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.25": {"text": "Sie flieht und birgt den S\u00e4ugling an der Brust,", "tokens": ["Sie", "flieht", "und", "birgt", "den", "S\u00e4ug\u00b7ling", "an", "der", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Zertritt das Raupennest! Der K\u00f6nig scho\u00df;", "tokens": ["Zer\u00b7tritt", "das", "Rau\u00b7pen\u00b7nest", "!", "Der", "K\u00f6\u00b7nig", "scho\u00df", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Ein Wehschrei klang herauf; sie aber klatschte", "tokens": ["Ein", "Weh\u00b7schrei", "klang", "her\u00b7auf", ";", "sie", "a\u00b7ber", "klatschte"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Dem Sch\u00fctzen Beifall ...", "tokens": ["Dem", "Sch\u00fct\u00b7zen", "Bei\u00b7fall", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Die unsre hei\u00dft ", "tokens": ["Die", "uns\u00b7re", "hei\u00dft"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Sonst ", "tokens": ["Sonst"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}, "stanza.4": {"line.1": {"text": " ... Landsleute, Volk von London, h\u00f6rt mich an:", "tokens": ["...", "Lands\u00b7leu\u00b7te", ",", "Volk", "von", "Lon\u00b7don", ",", "h\u00f6rt", "mich", "an", ":"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$,", "NN", "APPR", "NE", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ihr denkt, der K\u00f6nig ist's; ", "tokens": ["Ihr", "denkt", ",", "der", "K\u00f6\u00b7nig", "ist's", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von Frankreich kommt's und nennt sich", "tokens": ["Von", "Fran\u00b7kreich", "kommt's", "und", "nennt", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NE", "KON", "VVFIN", "PRF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und dazu ", "tokens": ["Und", "da\u00b7zu"], "token_info": ["word", "word"], "pos": ["KON", "PAV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Papistisch alle, Gott dem Herrn ein Greul,", "tokens": ["Pa\u00b7pis\u00b7tisch", "al\u00b7le", ",", "Gott", "dem", "Herrn", "ein", "Greul", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "$,", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Am meisten aber sie, das blut'ge Buhlweib,", "tokens": ["Am", "meis\u00b7ten", "a\u00b7ber", "sie", ",", "das", "blut'\u00b7ge", "Buhl\u00b7weib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "PIS", "ADV", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Das Frankreichs Thron befleckte: ", "tokens": ["Das", "Fran\u00b7kreichs", "Thron", "be\u00b7fleck\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Landsleute, tretet n\u00e4her, h\u00f6rt mich an,", "tokens": ["Lands\u00b7leu\u00b7te", ",", "tre\u00b7tet", "n\u00e4\u00b7her", ",", "h\u00f6rt", "mich", "an", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ADJD", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Von diesem Buhlweib will ich euch erz\u00e4hlen.", "tokens": ["Von", "die\u00b7sem", "Buhl\u00b7weib", "will", "ich", "euch", "er\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Bluthochzeit feierte die Stadt Paris,", "tokens": ["Blut\u00b7hoch\u00b7zeit", "fei\u00b7er\u00b7te", "die", "Stadt", "Pa\u00b7ris", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Glocke Zeichen war in Nacht verklungen,", "tokens": ["Der", "Glo\u00b7cke", "Zei\u00b7chen", "war", "in", "Nacht", "ver\u00b7klun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und durch die Stra\u00dfen, wie gehetztes Wild,", "tokens": ["Und", "durch", "die", "Stra\u00b7\u00dfen", ",", "wie", "ge\u00b7hetz\u00b7tes", "Wild", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wehschreiend, betend, floh der Hugenott.", "tokens": ["Weh\u00b7schrei\u00b7end", ",", "be\u00b7tend", ",", "floh", "der", "Hu\u00b7ge\u00b7nott", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Schon zog ein Blutstreif durch den Seine-Flu\u00df,", "tokens": ["Schon", "zog", "ein", "Blut\u00b7streif", "durch", "den", "Sei\u00b7ne\u00b7Flu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Schon lag verst\u00fcmmelt, siebenfach durchbohrt,", "tokens": ["Schon", "lag", "ver\u00b7st\u00fcm\u00b7melt", ",", "sie\u00b7ben\u00b7fach", "durch\u00b7bohrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVPP", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Auf offnem Platz der greise Coligny,", "tokens": ["Auf", "off\u00b7nem", "Platz", "der", "grei\u00b7se", "Co\u00b7lig\u00b7ny", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und immer noch, den Mord zum Morde mahnend,", "tokens": ["Und", "im\u00b7mer", "noch", ",", "den", "Mord", "zum", "Mor\u00b7de", "mah\u00b7nend", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$,", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbla\u00dft Ader!\u00ab schrie der t\u00fcckische Tavannes.", "tokens": ["\u00bb", "la\u00dft", "A\u00b7der", "!", "\u00ab", "schrie", "der", "t\u00fc\u00b7cki\u00b7sche", "Ta\u00b7van\u00b7nes", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "NN", "$.", "$(", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Im Schlosse aber, das sie Louvre nennen,", "tokens": ["Im", "Schlos\u00b7se", "a\u00b7ber", ",", "das", "sie", "Louv\u00b7re", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "$,", "PRELS", "PPER", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "An jener hohen Bogenfenster einem,", "tokens": ["An", "je\u00b7ner", "ho\u00b7hen", "Bo\u00b7gen\u00b7fens\u00b7ter", "ei\u00b7nem", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "ART", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Stand K\u00f6nig Karl, der neunte seines Namens,", "tokens": ["Stand", "K\u00f6\u00b7nig", "Karl", ",", "der", "neun\u00b7te", "sei\u00b7nes", "Na\u00b7mens", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "NE", "$,", "ART", "ADJA", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.13": {"text": "Und zitterte. Der ungeheure Frevel", "tokens": ["Und", "zit\u00b7ter\u00b7te", ".", "Der", "un\u00b7ge\u00b7heu\u00b7re", "Fre\u00b7vel"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Griff ihm ins Herz. Trotz Licht und Fackelglanz", "tokens": ["Griff", "ihm", "ins", "Herz", ".", "Trotz", "Licht", "und", "Fa\u00b7ckel\u00b7glanz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPRART", "NN", "$.", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Nacht war's um ihn. Er warf die B\u00fcchse fort:", "tokens": ["Nacht", "wa\u00b7r's", "um", "ihn", ".", "Er", "warf", "die", "B\u00fcch\u00b7se", "fort", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPER", "$.", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.16": {"text": "\u00bbich ", "tokens": ["\u00bb", "ich"], "token_info": ["punct", "word"], "pos": ["$(", "PPER"], "meter": "-", "measure": "single.down"}, "line.17": {"text": "Da trat sie selber vor, schwarz war ihr Haar,", "tokens": ["Da", "trat", "sie", "sel\u00b7ber", "vor", ",", "schwarz", "war", "ihr", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Schwarz wie der Sammet ihres Schleppenkleides,", "tokens": ["Schwarz", "wie", "der", "Sam\u00b7met", "ih\u00b7res", "Schlep\u00b7pen\u00b7klei\u00b7des", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOKOM", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.19": {"text": "Und ihrem Aug' entflammte tiefre Glut", "tokens": ["Und", "ih\u00b7rem", "Aug'", "ent\u00b7flamm\u00b7te", "tief\u00b7re", "Glut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Als dem Rubin, der ihr am Nacken blitzte.", "tokens": ["Als", "dem", "Ru\u00b7bin", ",", "der", "ihr", "am", "Na\u00b7cken", "blitz\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NE", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.21": {"text": "\u00bbbist du ein Mann?\u00ab so raunte sie ihm zu,", "tokens": ["\u00bb", "bist", "du", "ein", "Mann", "?", "\u00ab", "so", "raun\u00b7te", "sie", "ihm", "zu", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ART", "NN", "$.", "$(", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "\u00bbein K\u00f6nig und so feig? ich mag's nicht glauben.\u00ab", "tokens": ["\u00bb", "ein", "K\u00f6\u00b7nig", "und", "so", "feig", "?", "ich", "mag's", "nicht", "glau\u00b7ben", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "KON", "ADV", "ADJD", "$.", "PPER", "VMFIN", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Ergriff er neu das Rohr, sie aber rief:", "tokens": ["Er\u00b7griff", "er", "neu", "das", "Rohr", ",", "sie", "a\u00b7ber", "rief", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "NN", "$,", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "\u00bbschau dort das Weib, das Hugenottenweib,", "tokens": ["\u00bb", "schau", "dort", "das", "Weib", ",", "das", "Hu\u00b7ge\u00b7not\u00b7ten\u00b7weib", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "ADV", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.25": {"text": "Sie flieht und birgt den S\u00e4ugling an der Brust,", "tokens": ["Sie", "flieht", "und", "birgt", "den", "S\u00e4ug\u00b7ling", "an", "der", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Zertritt das Raupennest! Der K\u00f6nig scho\u00df;", "tokens": ["Zer\u00b7tritt", "das", "Rau\u00b7pen\u00b7nest", "!", "Der", "K\u00f6\u00b7nig", "scho\u00df", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Ein Wehschrei klang herauf; sie aber klatschte", "tokens": ["Ein", "Weh\u00b7schrei", "klang", "her\u00b7auf", ";", "sie", "a\u00b7ber", "klatschte"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Dem Sch\u00fctzen Beifall ...", "tokens": ["Dem", "Sch\u00fct\u00b7zen", "Bei\u00b7fall", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Die unsre hei\u00dft ", "tokens": ["Die", "uns\u00b7re", "hei\u00dft"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Sonst ", "tokens": ["Sonst"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}}}}