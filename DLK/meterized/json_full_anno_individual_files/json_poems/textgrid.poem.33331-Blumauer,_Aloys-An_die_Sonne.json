{"textgrid.poem.33331": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "An die Sonne", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Frau Sonne, diesmal trifft sie's nicht,", "tokens": ["Frau", "Son\u00b7ne", ",", "dies\u00b7mal", "trifft", "sie's", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn sie von meinem Liede", "tokens": ["Wenn", "sie", "von", "mei\u00b7nem", "Lie\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sich nichts, als Schmeichelei, verspricht;", "tokens": ["Sich", "nichts", ",", "als", "Schmei\u00b7che\u00b7lei", ",", "ver\u00b7spricht", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "PIS", "$,", "KOUS", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich bin des Lobens m\u00fcde.", "tokens": ["Ich", "bin", "des", "Lo\u00b7bens", "m\u00fc\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "D'rum h\u00f6re sie: Trotz ihrem Glanz,", "tokens": ["D'\u00b7rum", "h\u00f6\u00b7re", "sie", ":", "Trotz", "ih\u00b7rem", "Glanz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$.", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Und Strahlenrock und Sternenkranz,", "tokens": ["Und", "Strah\u00b7len\u00b7rock", "und", "Ster\u00b7nen\u00b7kranz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Trotz ihrer gold'nen Scheitel,", "tokens": ["Trotz", "ih\u00b7rer", "gold'\u00b7nen", "Schei\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Ist sie ein Weib \u2013 und eitel.", "tokens": ["Ist", "sie", "ein", "Weib", "\u2013", "und", "ei\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$(", "KON", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Bespiegelt und beg\u00e4ffelt sie", "tokens": ["Be\u00b7spie\u00b7gelt", "und", "be\u00b7g\u00e4f\u00b7felt", "sie"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich nicht in jedem Teiche?", "tokens": ["Sich", "nicht", "in", "je\u00b7dem", "Tei\u00b7che", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Begeht sie nicht, so sp\u00e4t als fr\u00fch,", "tokens": ["Be\u00b7geht", "sie", "nicht", ",", "so", "sp\u00e4t", "als", "fr\u00fch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,", "ADV", "ADJD", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die tollsten Weiberstreiche?", "tokens": ["Die", "tolls\u00b7ten", "Wei\u00b7bers\u00b7trei\u00b7che", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ein wundersch\u00f6ner Lebenslauf! \u2013", "tokens": ["Ein", "wun\u00b7der\u00b7sch\u00f6\u00b7ner", "Le\u00b7bens\u00b7lauf", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geschminkt steht sie des Morgens auf,", "tokens": ["Ge\u00b7schminkt", "steht", "sie", "des", "Mor\u00b7gens", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ART", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Geschminkt geht sie zu Bette,", "tokens": ["Ge\u00b7schminkt", "geht", "sie", "zu", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wie eine Erzkokette.", "tokens": ["Wie", "ei\u00b7ne", "Erz\u00b7ko\u00b7ket\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Sie pr\u00e4tendirt, die ganze Welt", "tokens": ["Sie", "pr\u00e4\u00b7ten\u00b7dirt", ",", "die", "gan\u00b7ze", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVPP", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Soll sich in sie vergaffen;", "tokens": ["Soll", "sich", "in", "sie", "ver\u00b7gaf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "APPR", "PPER", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Sobald ihr's aufzusteh'n gef\u00e4llt,", "tokens": ["So\u00b7bald", "ih\u00b7r's", "auf\u00b7zu\u00b7steh'n", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVIZU", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Da soll kein Thier mehr schlafen:", "tokens": ["Da", "soll", "kein", "Thier", "mehr", "schla\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der Hahn mu\u00df auf zum Morgengru\u00df,", "tokens": ["Der", "Hahn", "mu\u00df", "auf", "zum", "Mor\u00b7gen\u00b7gru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sogar die Sonnenblume mu\u00df", "tokens": ["So\u00b7gar", "die", "Son\u00b7nen\u00b7blu\u00b7me", "mu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den Seladon ihr spielen,", "tokens": ["Den", "Se\u00b7la\u00b7don", "ihr", "spie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und stets nach ihr nur schielen.", "tokens": ["Und", "stets", "nach", "ihr", "nur", "schie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Sie glaubt, die V\u00f6gel \u00fcbeten", "tokens": ["Sie", "glaubt", ",", "die", "V\u00f6\u00b7gel", "\u00fc\u00b7be\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "F\u00fcr sie nur ihre Kehlen,", "tokens": ["F\u00fcr", "sie", "nur", "ih\u00b7re", "Keh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sch\u00e4mt sich nicht, uns Schlafenden", "tokens": ["Und", "sch\u00e4mt", "sich", "nicht", ",", "uns", "Schla\u00b7fen\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "PTKNEG", "$,", "PPER", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Die Fr\u00fchmusik zu stehlen:", "tokens": ["Die", "Fr\u00fch\u00b7mu\u00b7sik", "zu", "steh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und k\u00f6nnen Abends die nicht mehr,", "tokens": ["Und", "k\u00f6n\u00b7nen", "A\u00b7bends", "die", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So m\u00fcssen Fr\u00f6sch' und Grillen her,", "tokens": ["So", "m\u00fcs\u00b7sen", "Fr\u00f6sch'", "und", "Gril\u00b7len", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und ihr ein Tutti singen,", "tokens": ["Und", "ihr", "ein", "Tut\u00b7ti", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Um sie in Schlaf zu bringen.", "tokens": ["Um", "sie", "in", "Schlaf", "zu", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Auch ist sie gar zu sehr erpicht,", "tokens": ["Auch", "ist", "sie", "gar", "zu", "sehr", "er\u00b7picht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKA", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit ihrem Reiz zu prahlen,", "tokens": ["Mit", "ih\u00b7rem", "Reiz", "zu", "prah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Stets soll er uns in's Angesicht", "tokens": ["Stets", "soll", "er", "uns", "in's", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz ohne Schleier strahlen;", "tokens": ["Ganz", "oh\u00b7ne", "Schlei\u00b7er", "strah\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Schlei'rt ihn ein Sommerw\u00f6lkchen ein,", "tokens": ["Schlei'rt", "ihn", "ein", "Som\u00b7mer\u00b7w\u00f6lk\u00b7chen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So blitzt und donnert sie darein", "tokens": ["So", "blitzt", "und", "don\u00b7nert", "sie", "da\u00b7rein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PPER", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bei hellen Thr\u00e4neng\u00fcssen,", "tokens": ["Bei", "hel\u00b7len", "Thr\u00e4\u00b7nen\u00b7g\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Bis sie den Schlei'r zerrissen.", "tokens": ["Bis", "sie", "den", "Schlei'r", "zer\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Da schwimmt nun ihre Majest\u00e4t", "tokens": ["Da", "schwimmt", "nun", "ih\u00b7re", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In einem Meer von Glanze,", "tokens": ["In", "ei\u00b7nem", "Meer", "von", "Glan\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und wo sie nur vor\u00fcbergeht,", "tokens": ["Und", "wo", "sie", "nur", "vor\u00b7\u00fc\u00b7ber\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da huldigt Strauch und Pflanze.", "tokens": ["Da", "hul\u00b7digt", "Strauch", "und", "Pflan\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die armen Bl\u00fcmchen dauern mich,", "tokens": ["Die", "ar\u00b7men", "Bl\u00fcm\u00b7chen", "dau\u00b7ern", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie b\u00fccken bis zur Erde sich;", "tokens": ["Sie", "b\u00fc\u00b7cken", "bis", "zur", "Er\u00b7de", "sich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPRART", "NN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kein's darf das K\u00f6pfchen heben,", "tokens": ["Kein's", "darf", "das", "K\u00f6pf\u00b7chen", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Bis sie sich wegbegeben.", "tokens": ["Bis", "sie", "sich", "weg\u00b7be\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Doch, da\u00df sie niemand d'rum besieht,", "tokens": ["Doch", ",", "da\u00df", "sie", "nie\u00b7mand", "d'\u00b7rum", "be\u00b7sieht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PIS", "PAV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie ihr die Runzeln lassen,", "tokens": ["Wie", "ihr", "die", "Run\u00b7zeln", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So pflastert sie sich t\u00e4glich mit", "tokens": ["So", "pflas\u00b7tert", "sie", "sich", "t\u00e4g\u00b7lich", "mit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Demanten und Topassen:", "tokens": ["De\u00b7man\u00b7ten", "und", "To\u00b7pas\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das treibt sie bis zum Augenweh;", "tokens": ["Das", "treibt", "sie", "bis", "zum", "Au\u00b7gen\u00b7weh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch pflegte sie im Neglig\u00e9", "tokens": ["Doch", "pfleg\u00b7te", "sie", "im", "Ne\u00b7gli\u00b7g\u00e9"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nur einmal auszugehen,", "tokens": ["Nur", "ein\u00b7mal", "aus\u00b7zu\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wir w\u00fcrden Wunder sehen.", "tokens": ["Wir", "w\u00fcr\u00b7den", "Wun\u00b7der", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Mit sch\u00f6nen M\u00e4dchen treibt sie gar", "tokens": ["Mit", "sch\u00f6\u00b7nen", "M\u00e4d\u00b7chen", "treibt", "sie", "gar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein j\u00e4mmerlich Spektakel:", "tokens": ["Ein", "j\u00e4m\u00b7mer\u00b7lich", "Spek\u00b7ta\u00b7kel", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nimmt sie nur ein's von weitem wahr,", "tokens": ["Nimmt", "sie", "nur", "ein's", "von", "wei\u00b7tem", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "APPR", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Husch sch\u00fcttelt sie die Fackel,", "tokens": ["Husch", "sch\u00fct\u00b7telt", "sie", "die", "Fa\u00b7ckel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und brennt die feinste Lilienhaut", "tokens": ["Und", "brennt", "die", "feins\u00b7te", "Li\u00b7li\u00b7en\u00b7haut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "So kohlpechschwarz, da\u00df einem graut", "tokens": ["So", "kohl\u00b7pech\u00b7schwarz", ",", "da\u00df", "ei\u00b7nem", "graut"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und k\u00f6nnte sie, ich glaube,", "tokens": ["Und", "k\u00f6nn\u00b7te", "sie", ",", "ich", "glau\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Sie brennte sie zu Staube.", "tokens": ["Sie", "brenn\u00b7te", "sie", "zu", "Stau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Doch wissen ihr auch ritterlich", "tokens": ["Doch", "wis\u00b7sen", "ihr", "auch", "rit\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sch\u00f6nen Trotz zu bieten,", "tokens": ["Die", "Sch\u00f6\u00b7nen", "Trotz", "zu", "bie\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und k\u00e4mpfen gegen ihren Stich", "tokens": ["Und", "k\u00e4mp\u00b7fen", "ge\u00b7gen", "ih\u00b7ren", "Stich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit F\u00e4cher, Schirm und H\u00fcten:", "tokens": ["Mit", "F\u00e4\u00b7cher", ",", "Schirm", "und", "H\u00fc\u00b7ten", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "D'rum hat Madam wohl hundertmal", "tokens": ["D'\u00b7rum", "hat", "Ma\u00b7dam", "wohl", "hun\u00b7dert\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "NN", "ADV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Gew\u00fcnscht: Ha! da\u00df die Dirnen all'", "tokens": ["Ge\u00b7w\u00fcnscht", ":", "Ha", "!", "da\u00df", "die", "Dir\u00b7nen", "all'"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "ITJ", "$.", "KOUS", "ART", "NN", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Von Schmalz und Butter w\u00e4ren,", "tokens": ["Von", "Schmalz", "und", "But\u00b7ter", "w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wie wollt' ich sie zerst\u00f6ren!", "tokens": ["Wie", "wollt'", "ich", "sie", "zer\u00b7st\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Zwar, da\u00df sie gern sich tr\u00e4gt zur Schau,", "tokens": ["Zwar", ",", "da\u00df", "sie", "gern", "sich", "tr\u00e4gt", "zur", "Schau", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "PRF", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lie\u00df sich noch \u00fcbersehen;", "tokens": ["Lie\u00df", "sich", "noch", "\u00fc\u00b7ber\u00b7se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch ihre Neugier, gn\u00e4d'ge Frau,", "tokens": ["Doch", "ih\u00b7re", "Neu\u00b7gier", ",", "gn\u00e4d'\u00b7ge", "Frau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist gar nicht auszustehen.", "tokens": ["Ist", "gar", "nicht", "aus\u00b7zu\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn, weil sie grosse Augen hat,", "tokens": ["Denn", ",", "weil", "sie", "gros\u00b7se", "Au\u00b7gen", "hat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So, meint sie, d\u00fcrf' in Feld und Stadt", "tokens": ["So", ",", "meint", "sie", ",", "d\u00fcr\u00b7f'", "in", "Feld", "und", "Stadt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VMFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Nichts unbegafft geschehen,", "tokens": ["Nichts", "un\u00b7be\u00b7gafft", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Sie m\u00fcsse alles sehen.", "tokens": ["Sie", "m\u00fcs\u00b7se", "al\u00b7les", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Da guckt, wenn man im Bett noch liegt,", "tokens": ["Da", "guckt", ",", "wenn", "man", "im", "Bett", "noch", "liegt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PIS", "APPRART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie durch die Fensterscheiben,", "tokens": ["Sie", "durch", "die", "Fens\u00b7ter\u00b7schei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Kein M\u00e4dchen will, so ungeblickt,", "tokens": ["Kein", "M\u00e4d\u00b7chen", "will", ",", "so", "un\u00b7ge\u00b7blickt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dann mehr im Bette bleiben:", "tokens": ["Dann", "mehr", "im", "Bet\u00b7te", "blei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das thut sie blo\u00df aus Eifersucht:", "tokens": ["Das", "thut", "sie", "blo\u00df", "aus", "Ei\u00b7fer\u00b7sucht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In Grotten und in Lauben sucht", "tokens": ["In", "Grot\u00b7ten", "und", "in", "Lau\u00b7ben", "sucht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sie sich hineinzustehlen,", "tokens": ["Sie", "sich", "hin\u00b7ein\u00b7zu\u00b7steh\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Die Liebenden zu qu\u00e4len.", "tokens": ["Die", "Lie\u00b7ben\u00b7den", "zu", "qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Ey pfui, Madam, so kurios", "tokens": ["Ey", "pfui", ",", "Ma\u00b7dam", ",", "so", "ku\u00b7ri\u00b7os"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "NE", "$,", "NN", "$,", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist wohl kein Weib auf Erden.", "tokens": ["Ist", "wohl", "kein", "Weib", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So mu\u00df denn alles, klein und gro\u00df,", "tokens": ["So", "mu\u00df", "denn", "al\u00b7les", ",", "klein", "und", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PIS", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von ihr beglasaugt werden?", "tokens": ["Von", "ihr", "be\u00b7gla\u00b7saugt", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Was hilft's? verkr\u00f6che man sich auch", "tokens": ["Was", "hilft's", "?", "ver\u00b7kr\u00f6\u00b7che", "man", "sich", "auch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$.", "VVFIN", "PIS", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Selbst in der Mutter Erde Bauch,", "tokens": ["Selbst", "in", "der", "Mut\u00b7ter", "Er\u00b7de", "Bauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sie ist im Stand der Alten", "tokens": ["Sie", "ist", "im", "Stand", "der", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Den Bauch entzwei zu spalten.", "tokens": ["Den", "Bauch", "ent\u00b7zwei", "zu", "spal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Sie selbst gibt doch den Frauen kein", "tokens": ["Sie", "selbst", "gibt", "doch", "den", "Frau\u00b7en", "kein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ART", "NN", "PIAT"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Gar sonderlich Exempel.", "tokens": ["Gar", "son\u00b7der\u00b7lich", "Ex\u00b7em\u00b7pel", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wo sie ist, trollt Herr Mondenschein", "tokens": ["Wo", "sie", "ist", ",", "trollt", "Herr", "Mon\u00b7den\u00b7schein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "VAFIN", "$,", "VVFIN", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich flugs hinaus zum Tempel.", "tokens": ["Sich", "flugs", "hin\u00b7aus", "zum", "Tem\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APZR", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Man wei\u00df ja wohl Frau Ueberall,", "tokens": ["Man", "wei\u00df", "ja", "wohl", "Frau", "Ue\u00b7be\u00b7rall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Warum sie diesen zum Gemahl", "tokens": ["Wa\u00b7rum", "sie", "die\u00b7sen", "zum", "Ge\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PDAT", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vor allen auserlesen \u2013", "tokens": ["Vor", "al\u00b7len", "au\u00b7ser\u00b7le\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Weil er stockblind gewesen.", "tokens": ["Weil", "er", "stock\u00b7blind", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.14": {"line.1": {"text": "Kein so verbuhltes Weib gibt's nicht", "tokens": ["Kein", "so", "ver\u00b7buhl\u00b7tes", "Weib", "gibt's", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADV", "ADJA", "NN", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Himmel und auf Erden;", "tokens": ["Im", "Him\u00b7mel", "und", "auf", "Er\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bek\u00e4m' Herr Mond sein Augenlicht,", "tokens": ["Be\u00b7k\u00e4m'", "Herr", "Mond", "sein", "Au\u00b7gen\u00b7licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er m\u00fc\u00dfte rasend werden.", "tokens": ["Er", "m\u00fc\u00df\u00b7te", "ra\u00b7send", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Bis mit den Sternen sie nicht satt", "tokens": ["Bis", "mit", "den", "Ster\u00b7nen", "sie", "nicht", "satt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN", "PPER", "PTKNEG", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gebuhlt und liebge\u00e4ugelt hat,", "tokens": ["Ge\u00b7buhlt", "und", "lieb\u00b7ge\u00b7\u00e4u\u00b7gelt", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Eh pflegt sie ihren Grauen", "tokens": ["Eh", "pflegt", "sie", "ih\u00b7ren", "Grau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Nicht einmal anzuschauen.", "tokens": ["Nicht", "ein\u00b7mal", "an\u00b7zu\u00b7schau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Sie kann, so oft es ihr gef\u00e4llt,", "tokens": ["Sie", "kann", ",", "so", "oft", "es", "ihr", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "ADV", "ADV", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Schnippchen ihm versetzen,", "tokens": ["Ein", "Schnipp\u00b7chen", "ihm", "ver\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "D'rum tr\u00e4gt er auch vor aller Welt", "tokens": ["D'\u00b7rum", "tr\u00e4gt", "er", "auch", "vor", "al\u00b7ler", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Zwei H\u00f6rner zum Entsetzen;", "tokens": ["Zwei", "H\u00f6r\u00b7ner", "zum", "Ent\u00b7set\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und will der Hahnrei seinem Weib", "tokens": ["Und", "will", "der", "Hahn\u00b7rei", "sei\u00b7nem", "Weib"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zuweilen n\u00e4her auf den Leib,", "tokens": ["Zu\u00b7wei\u00b7len", "n\u00e4\u00b7her", "auf", "den", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So kriegt er finst're Blicke", "tokens": ["So", "kriegt", "er", "finst'\u00b7re", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und mu\u00df besch\u00e4mt zur\u00fccke.", "tokens": ["Und", "mu\u00df", "be\u00b7sch\u00e4mt", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Sie l\u00e4\u00dft sich zwar die K\u00f6nigin", "tokens": ["Sie", "l\u00e4\u00dft", "sich", "zwar", "die", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Sternenhimmels schelten;", "tokens": ["Des", "Ster\u00b7nen\u00b7him\u00b7mels", "schel\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allein den k\u00f6niglichen Sinn", "tokens": ["Al\u00b7lein", "den", "k\u00f6\u00b7nig\u00b7li\u00b7chen", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mu\u00df man genug entgelten:", "tokens": ["Mu\u00df", "man", "ge\u00b7nug", "ent\u00b7gel\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sie sengt und brennt ja m\u00f6rderlich,", "tokens": ["Sie", "sengt", "und", "brennt", "ja", "m\u00f6r\u00b7der\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wei\u00df dabei \u2013 recht k\u00f6niglich, \u2013", "tokens": ["Und", "wei\u00df", "da\u00b7bei", "\u2013", "recht", "k\u00f6\u00b7nig\u00b7lich", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PAV", "$(", "ADJD", "ADJD", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "F\u00fcr ihre Hand voll Weizen", "tokens": ["F\u00fcr", "ih\u00b7re", "Hand", "voll", "Wei\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Des Pfl\u00fcgers Haut zu beizen.", "tokens": ["Des", "Pfl\u00fc\u00b7gers", "Haut", "zu", "bei\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Gibt sie die eine Hand uns voll,", "tokens": ["Gibt", "sie", "die", "ei\u00b7ne", "Hand", "uns", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ART", "NN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So nimmt sie mit der andern:", "tokens": ["So", "nimmt", "sie", "mit", "der", "an\u00b7dern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie geht ja um mit Kraut und Kohl,", "tokens": ["Sie", "geht", "ja", "um", "mit", "Kraut", "und", "Kohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als wie mit Salamandern:", "tokens": ["Als", "wie", "mit", "Sa\u00b7la\u00b7man\u00b7dern", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mit \u00e4chter K\u00f6nigspolitik", "tokens": ["Mit", "\u00e4ch\u00b7ter", "K\u00f6\u00b7nigs\u00b7po\u00b7li\u00b7tik"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Versenget sie oft St\u00fcck f\u00fcr St\u00fcck,", "tokens": ["Ver\u00b7sen\u00b7get", "sie", "oft", "St\u00fcck", "f\u00fcr", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NN", "APPR", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.7": {"text": "Die Felder und die Saaten,", "tokens": ["Die", "Fel\u00b7der", "und", "die", "Saa\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "L\u00e4\u00dft Trauben nur gerathen.", "tokens": ["L\u00e4\u00dft", "Trau\u00b7ben", "nur", "ge\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Ey, f\u00fcr ein k\u00f6nigliches Haupt", "tokens": ["Ey", ",", "f\u00fcr", "ein", "k\u00f6\u00b7nig\u00b7li\u00b7ches", "Haupt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hei\u00dft das sich sehr vergessen,", "tokens": ["Hei\u00dft", "das", "sich", "sehr", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn man von Unterthanen glaubt,", "tokens": ["Wenn", "man", "von", "Un\u00b7ter\u00b7tha\u00b7nen", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie k\u00f6nnten Kohlen fressen.", "tokens": ["Sie", "k\u00f6nn\u00b7ten", "Koh\u00b7len", "fres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nicht wahr, Frau Klug, ihr fiel nicht ein,", "tokens": ["Nicht", "wahr", ",", "Frau", "Klug", ",", "ihr", "fiel", "nicht", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "NN", "NE", "$,", "PPER", "VVFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df man beim allerbesten Wein", "tokens": ["Da\u00df", "man", "beim", "al\u00b7ler\u00b7bes\u00b7ten", "Wein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und einer leeren Tenne", "tokens": ["Und", "ei\u00b7ner", "lee\u00b7ren", "Ten\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Fein h\u00fcbsch verhungern k\u00f6nne.", "tokens": ["Fein", "h\u00fcbsch", "ver\u00b7hun\u00b7gern", "k\u00f6n\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Man nennt mit Recht sie das Modell", "tokens": ["Man", "nennt", "mit", "Recht", "sie", "das", "Mo\u00b7dell"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "NN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von k\u00f6niglichen Geistern,", "tokens": ["Von", "k\u00f6\u00b7nig\u00b7li\u00b7chen", "Geis\u00b7tern", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die mit dem ersten Blicke schnell", "tokens": ["Die", "mit", "dem", "ers\u00b7ten", "Bli\u00b7cke", "schnell"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein ganzes Weltall meistern:", "tokens": ["Ein", "gan\u00b7zes", "Wel\u00b7tall", "meis\u00b7tern", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn auch Madam mit ihrem Licht", "tokens": ["Denn", "auch", "Ma\u00b7dam", "mit", "ih\u00b7rem", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sieht alles \u2013 nur sich selber nicht,", "tokens": ["Sieht", "al\u00b7les", "\u2013", "nur", "sich", "sel\u00b7ber", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$(", "ADV", "PRF", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und wird an sich die Flecken", "tokens": ["Und", "wird", "an", "sich", "die", "Fle\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "PRF", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wohl nimmermehr entdecken.", "tokens": ["Wohl", "nim\u00b7mer\u00b7mehr", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Ich aber bin nicht undankbar,", "tokens": ["Ich", "a\u00b7ber", "bin", "nicht", "un\u00b7dank\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich von ihr gebeichtet,", "tokens": ["Da\u00df", "ich", "von", "ihr", "ge\u00b7beich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was lang mir auf dem Herzen war,", "tokens": ["Was", "lang", "mir", "auf", "dem", "Her\u00b7zen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "PPER", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Inde\u00df sie mir geleuchtet;", "tokens": ["In\u00b7de\u00df", "sie", "mir", "ge\u00b7leuch\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn, um f\u00fcr ihren Sonnenschein", "tokens": ["Denn", ",", "um", "f\u00fcr", "ih\u00b7ren", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUI", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr gar nicht obligirt zu sein,", "tokens": ["Ihr", "gar", "nicht", "ob\u00b7li\u00b7girt", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Schrieb ich an dem Gedichte", "tokens": ["Schrieb", "ich", "an", "dem", "Ge\u00b7dich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.8": {"text": "Nur Nachts \u2013 beim Kerzenlichte.", "tokens": ["Nur", "Nachts", "\u2013", "beim", "Ker\u00b7zen\u00b7lich\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Frau Sonne, diesmal trifft sie's nicht,", "tokens": ["Frau", "Son\u00b7ne", ",", "dies\u00b7mal", "trifft", "sie's", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn sie von meinem Liede", "tokens": ["Wenn", "sie", "von", "mei\u00b7nem", "Lie\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sich nichts, als Schmeichelei, verspricht;", "tokens": ["Sich", "nichts", ",", "als", "Schmei\u00b7che\u00b7lei", ",", "ver\u00b7spricht", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "PIS", "$,", "KOUS", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich bin des Lobens m\u00fcde.", "tokens": ["Ich", "bin", "des", "Lo\u00b7bens", "m\u00fc\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "D'rum h\u00f6re sie: Trotz ihrem Glanz,", "tokens": ["D'\u00b7rum", "h\u00f6\u00b7re", "sie", ":", "Trotz", "ih\u00b7rem", "Glanz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$.", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Und Strahlenrock und Sternenkranz,", "tokens": ["Und", "Strah\u00b7len\u00b7rock", "und", "Ster\u00b7nen\u00b7kranz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Trotz ihrer gold'nen Scheitel,", "tokens": ["Trotz", "ih\u00b7rer", "gold'\u00b7nen", "Schei\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Ist sie ein Weib \u2013 und eitel.", "tokens": ["Ist", "sie", "ein", "Weib", "\u2013", "und", "ei\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$(", "KON", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Bespiegelt und beg\u00e4ffelt sie", "tokens": ["Be\u00b7spie\u00b7gelt", "und", "be\u00b7g\u00e4f\u00b7felt", "sie"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich nicht in jedem Teiche?", "tokens": ["Sich", "nicht", "in", "je\u00b7dem", "Tei\u00b7che", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Begeht sie nicht, so sp\u00e4t als fr\u00fch,", "tokens": ["Be\u00b7geht", "sie", "nicht", ",", "so", "sp\u00e4t", "als", "fr\u00fch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,", "ADV", "ADJD", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die tollsten Weiberstreiche?", "tokens": ["Die", "tolls\u00b7ten", "Wei\u00b7bers\u00b7trei\u00b7che", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ein wundersch\u00f6ner Lebenslauf! \u2013", "tokens": ["Ein", "wun\u00b7der\u00b7sch\u00f6\u00b7ner", "Le\u00b7bens\u00b7lauf", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geschminkt steht sie des Morgens auf,", "tokens": ["Ge\u00b7schminkt", "steht", "sie", "des", "Mor\u00b7gens", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ART", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Geschminkt geht sie zu Bette,", "tokens": ["Ge\u00b7schminkt", "geht", "sie", "zu", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wie eine Erzkokette.", "tokens": ["Wie", "ei\u00b7ne", "Erz\u00b7ko\u00b7ket\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Sie pr\u00e4tendirt, die ganze Welt", "tokens": ["Sie", "pr\u00e4\u00b7ten\u00b7dirt", ",", "die", "gan\u00b7ze", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVPP", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Soll sich in sie vergaffen;", "tokens": ["Soll", "sich", "in", "sie", "ver\u00b7gaf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "APPR", "PPER", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Sobald ihr's aufzusteh'n gef\u00e4llt,", "tokens": ["So\u00b7bald", "ih\u00b7r's", "auf\u00b7zu\u00b7steh'n", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVIZU", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Da soll kein Thier mehr schlafen:", "tokens": ["Da", "soll", "kein", "Thier", "mehr", "schla\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der Hahn mu\u00df auf zum Morgengru\u00df,", "tokens": ["Der", "Hahn", "mu\u00df", "auf", "zum", "Mor\u00b7gen\u00b7gru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sogar die Sonnenblume mu\u00df", "tokens": ["So\u00b7gar", "die", "Son\u00b7nen\u00b7blu\u00b7me", "mu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den Seladon ihr spielen,", "tokens": ["Den", "Se\u00b7la\u00b7don", "ihr", "spie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und stets nach ihr nur schielen.", "tokens": ["Und", "stets", "nach", "ihr", "nur", "schie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Sie glaubt, die V\u00f6gel \u00fcbeten", "tokens": ["Sie", "glaubt", ",", "die", "V\u00f6\u00b7gel", "\u00fc\u00b7be\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "F\u00fcr sie nur ihre Kehlen,", "tokens": ["F\u00fcr", "sie", "nur", "ih\u00b7re", "Keh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sch\u00e4mt sich nicht, uns Schlafenden", "tokens": ["Und", "sch\u00e4mt", "sich", "nicht", ",", "uns", "Schla\u00b7fen\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "PTKNEG", "$,", "PPER", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Die Fr\u00fchmusik zu stehlen:", "tokens": ["Die", "Fr\u00fch\u00b7mu\u00b7sik", "zu", "steh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und k\u00f6nnen Abends die nicht mehr,", "tokens": ["Und", "k\u00f6n\u00b7nen", "A\u00b7bends", "die", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So m\u00fcssen Fr\u00f6sch' und Grillen her,", "tokens": ["So", "m\u00fcs\u00b7sen", "Fr\u00f6sch'", "und", "Gril\u00b7len", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und ihr ein Tutti singen,", "tokens": ["Und", "ihr", "ein", "Tut\u00b7ti", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Um sie in Schlaf zu bringen.", "tokens": ["Um", "sie", "in", "Schlaf", "zu", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Auch ist sie gar zu sehr erpicht,", "tokens": ["Auch", "ist", "sie", "gar", "zu", "sehr", "er\u00b7picht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKA", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit ihrem Reiz zu prahlen,", "tokens": ["Mit", "ih\u00b7rem", "Reiz", "zu", "prah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Stets soll er uns in's Angesicht", "tokens": ["Stets", "soll", "er", "uns", "in's", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz ohne Schleier strahlen;", "tokens": ["Ganz", "oh\u00b7ne", "Schlei\u00b7er", "strah\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Schlei'rt ihn ein Sommerw\u00f6lkchen ein,", "tokens": ["Schlei'rt", "ihn", "ein", "Som\u00b7mer\u00b7w\u00f6lk\u00b7chen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So blitzt und donnert sie darein", "tokens": ["So", "blitzt", "und", "don\u00b7nert", "sie", "da\u00b7rein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PPER", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bei hellen Thr\u00e4neng\u00fcssen,", "tokens": ["Bei", "hel\u00b7len", "Thr\u00e4\u00b7nen\u00b7g\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Bis sie den Schlei'r zerrissen.", "tokens": ["Bis", "sie", "den", "Schlei'r", "zer\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Da schwimmt nun ihre Majest\u00e4t", "tokens": ["Da", "schwimmt", "nun", "ih\u00b7re", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In einem Meer von Glanze,", "tokens": ["In", "ei\u00b7nem", "Meer", "von", "Glan\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und wo sie nur vor\u00fcbergeht,", "tokens": ["Und", "wo", "sie", "nur", "vor\u00b7\u00fc\u00b7ber\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da huldigt Strauch und Pflanze.", "tokens": ["Da", "hul\u00b7digt", "Strauch", "und", "Pflan\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die armen Bl\u00fcmchen dauern mich,", "tokens": ["Die", "ar\u00b7men", "Bl\u00fcm\u00b7chen", "dau\u00b7ern", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie b\u00fccken bis zur Erde sich;", "tokens": ["Sie", "b\u00fc\u00b7cken", "bis", "zur", "Er\u00b7de", "sich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPRART", "NN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kein's darf das K\u00f6pfchen heben,", "tokens": ["Kein's", "darf", "das", "K\u00f6pf\u00b7chen", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Bis sie sich wegbegeben.", "tokens": ["Bis", "sie", "sich", "weg\u00b7be\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Doch, da\u00df sie niemand d'rum besieht,", "tokens": ["Doch", ",", "da\u00df", "sie", "nie\u00b7mand", "d'\u00b7rum", "be\u00b7sieht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PIS", "PAV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie ihr die Runzeln lassen,", "tokens": ["Wie", "ihr", "die", "Run\u00b7zeln", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So pflastert sie sich t\u00e4glich mit", "tokens": ["So", "pflas\u00b7tert", "sie", "sich", "t\u00e4g\u00b7lich", "mit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Demanten und Topassen:", "tokens": ["De\u00b7man\u00b7ten", "und", "To\u00b7pas\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das treibt sie bis zum Augenweh;", "tokens": ["Das", "treibt", "sie", "bis", "zum", "Au\u00b7gen\u00b7weh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch pflegte sie im Neglig\u00e9", "tokens": ["Doch", "pfleg\u00b7te", "sie", "im", "Ne\u00b7gli\u00b7g\u00e9"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nur einmal auszugehen,", "tokens": ["Nur", "ein\u00b7mal", "aus\u00b7zu\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wir w\u00fcrden Wunder sehen.", "tokens": ["Wir", "w\u00fcr\u00b7den", "Wun\u00b7der", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Mit sch\u00f6nen M\u00e4dchen treibt sie gar", "tokens": ["Mit", "sch\u00f6\u00b7nen", "M\u00e4d\u00b7chen", "treibt", "sie", "gar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein j\u00e4mmerlich Spektakel:", "tokens": ["Ein", "j\u00e4m\u00b7mer\u00b7lich", "Spek\u00b7ta\u00b7kel", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nimmt sie nur ein's von weitem wahr,", "tokens": ["Nimmt", "sie", "nur", "ein's", "von", "wei\u00b7tem", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "APPR", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Husch sch\u00fcttelt sie die Fackel,", "tokens": ["Husch", "sch\u00fct\u00b7telt", "sie", "die", "Fa\u00b7ckel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und brennt die feinste Lilienhaut", "tokens": ["Und", "brennt", "die", "feins\u00b7te", "Li\u00b7li\u00b7en\u00b7haut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "So kohlpechschwarz, da\u00df einem graut", "tokens": ["So", "kohl\u00b7pech\u00b7schwarz", ",", "da\u00df", "ei\u00b7nem", "graut"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und k\u00f6nnte sie, ich glaube,", "tokens": ["Und", "k\u00f6nn\u00b7te", "sie", ",", "ich", "glau\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Sie brennte sie zu Staube.", "tokens": ["Sie", "brenn\u00b7te", "sie", "zu", "Stau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Doch wissen ihr auch ritterlich", "tokens": ["Doch", "wis\u00b7sen", "ihr", "auch", "rit\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sch\u00f6nen Trotz zu bieten,", "tokens": ["Die", "Sch\u00f6\u00b7nen", "Trotz", "zu", "bie\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und k\u00e4mpfen gegen ihren Stich", "tokens": ["Und", "k\u00e4mp\u00b7fen", "ge\u00b7gen", "ih\u00b7ren", "Stich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit F\u00e4cher, Schirm und H\u00fcten:", "tokens": ["Mit", "F\u00e4\u00b7cher", ",", "Schirm", "und", "H\u00fc\u00b7ten", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "D'rum hat Madam wohl hundertmal", "tokens": ["D'\u00b7rum", "hat", "Ma\u00b7dam", "wohl", "hun\u00b7dert\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "NN", "ADV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Gew\u00fcnscht: Ha! da\u00df die Dirnen all'", "tokens": ["Ge\u00b7w\u00fcnscht", ":", "Ha", "!", "da\u00df", "die", "Dir\u00b7nen", "all'"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "ITJ", "$.", "KOUS", "ART", "NN", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Von Schmalz und Butter w\u00e4ren,", "tokens": ["Von", "Schmalz", "und", "But\u00b7ter", "w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wie wollt' ich sie zerst\u00f6ren!", "tokens": ["Wie", "wollt'", "ich", "sie", "zer\u00b7st\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Zwar, da\u00df sie gern sich tr\u00e4gt zur Schau,", "tokens": ["Zwar", ",", "da\u00df", "sie", "gern", "sich", "tr\u00e4gt", "zur", "Schau", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "PRF", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lie\u00df sich noch \u00fcbersehen;", "tokens": ["Lie\u00df", "sich", "noch", "\u00fc\u00b7ber\u00b7se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch ihre Neugier, gn\u00e4d'ge Frau,", "tokens": ["Doch", "ih\u00b7re", "Neu\u00b7gier", ",", "gn\u00e4d'\u00b7ge", "Frau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist gar nicht auszustehen.", "tokens": ["Ist", "gar", "nicht", "aus\u00b7zu\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn, weil sie grosse Augen hat,", "tokens": ["Denn", ",", "weil", "sie", "gros\u00b7se", "Au\u00b7gen", "hat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So, meint sie, d\u00fcrf' in Feld und Stadt", "tokens": ["So", ",", "meint", "sie", ",", "d\u00fcr\u00b7f'", "in", "Feld", "und", "Stadt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VMFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Nichts unbegafft geschehen,", "tokens": ["Nichts", "un\u00b7be\u00b7gafft", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Sie m\u00fcsse alles sehen.", "tokens": ["Sie", "m\u00fcs\u00b7se", "al\u00b7les", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Da guckt, wenn man im Bett noch liegt,", "tokens": ["Da", "guckt", ",", "wenn", "man", "im", "Bett", "noch", "liegt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PIS", "APPRART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie durch die Fensterscheiben,", "tokens": ["Sie", "durch", "die", "Fens\u00b7ter\u00b7schei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Kein M\u00e4dchen will, so ungeblickt,", "tokens": ["Kein", "M\u00e4d\u00b7chen", "will", ",", "so", "un\u00b7ge\u00b7blickt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dann mehr im Bette bleiben:", "tokens": ["Dann", "mehr", "im", "Bet\u00b7te", "blei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das thut sie blo\u00df aus Eifersucht:", "tokens": ["Das", "thut", "sie", "blo\u00df", "aus", "Ei\u00b7fer\u00b7sucht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In Grotten und in Lauben sucht", "tokens": ["In", "Grot\u00b7ten", "und", "in", "Lau\u00b7ben", "sucht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sie sich hineinzustehlen,", "tokens": ["Sie", "sich", "hin\u00b7ein\u00b7zu\u00b7steh\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Die Liebenden zu qu\u00e4len.", "tokens": ["Die", "Lie\u00b7ben\u00b7den", "zu", "qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Ey pfui, Madam, so kurios", "tokens": ["Ey", "pfui", ",", "Ma\u00b7dam", ",", "so", "ku\u00b7ri\u00b7os"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "NE", "$,", "NN", "$,", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist wohl kein Weib auf Erden.", "tokens": ["Ist", "wohl", "kein", "Weib", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So mu\u00df denn alles, klein und gro\u00df,", "tokens": ["So", "mu\u00df", "denn", "al\u00b7les", ",", "klein", "und", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PIS", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von ihr beglasaugt werden?", "tokens": ["Von", "ihr", "be\u00b7gla\u00b7saugt", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Was hilft's? verkr\u00f6che man sich auch", "tokens": ["Was", "hilft's", "?", "ver\u00b7kr\u00f6\u00b7che", "man", "sich", "auch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$.", "VVFIN", "PIS", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Selbst in der Mutter Erde Bauch,", "tokens": ["Selbst", "in", "der", "Mut\u00b7ter", "Er\u00b7de", "Bauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sie ist im Stand der Alten", "tokens": ["Sie", "ist", "im", "Stand", "der", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Den Bauch entzwei zu spalten.", "tokens": ["Den", "Bauch", "ent\u00b7zwei", "zu", "spal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Sie selbst gibt doch den Frauen kein", "tokens": ["Sie", "selbst", "gibt", "doch", "den", "Frau\u00b7en", "kein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ART", "NN", "PIAT"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Gar sonderlich Exempel.", "tokens": ["Gar", "son\u00b7der\u00b7lich", "Ex\u00b7em\u00b7pel", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wo sie ist, trollt Herr Mondenschein", "tokens": ["Wo", "sie", "ist", ",", "trollt", "Herr", "Mon\u00b7den\u00b7schein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "VAFIN", "$,", "VVFIN", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich flugs hinaus zum Tempel.", "tokens": ["Sich", "flugs", "hin\u00b7aus", "zum", "Tem\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APZR", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Man wei\u00df ja wohl Frau Ueberall,", "tokens": ["Man", "wei\u00df", "ja", "wohl", "Frau", "Ue\u00b7be\u00b7rall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Warum sie diesen zum Gemahl", "tokens": ["Wa\u00b7rum", "sie", "die\u00b7sen", "zum", "Ge\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PDAT", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vor allen auserlesen \u2013", "tokens": ["Vor", "al\u00b7len", "au\u00b7ser\u00b7le\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Weil er stockblind gewesen.", "tokens": ["Weil", "er", "stock\u00b7blind", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.34": {"line.1": {"text": "Kein so verbuhltes Weib gibt's nicht", "tokens": ["Kein", "so", "ver\u00b7buhl\u00b7tes", "Weib", "gibt's", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADV", "ADJA", "NN", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Himmel und auf Erden;", "tokens": ["Im", "Him\u00b7mel", "und", "auf", "Er\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bek\u00e4m' Herr Mond sein Augenlicht,", "tokens": ["Be\u00b7k\u00e4m'", "Herr", "Mond", "sein", "Au\u00b7gen\u00b7licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er m\u00fc\u00dfte rasend werden.", "tokens": ["Er", "m\u00fc\u00df\u00b7te", "ra\u00b7send", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Bis mit den Sternen sie nicht satt", "tokens": ["Bis", "mit", "den", "Ster\u00b7nen", "sie", "nicht", "satt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN", "PPER", "PTKNEG", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gebuhlt und liebge\u00e4ugelt hat,", "tokens": ["Ge\u00b7buhlt", "und", "lieb\u00b7ge\u00b7\u00e4u\u00b7gelt", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Eh pflegt sie ihren Grauen", "tokens": ["Eh", "pflegt", "sie", "ih\u00b7ren", "Grau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Nicht einmal anzuschauen.", "tokens": ["Nicht", "ein\u00b7mal", "an\u00b7zu\u00b7schau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Sie kann, so oft es ihr gef\u00e4llt,", "tokens": ["Sie", "kann", ",", "so", "oft", "es", "ihr", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "ADV", "ADV", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Schnippchen ihm versetzen,", "tokens": ["Ein", "Schnipp\u00b7chen", "ihm", "ver\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "D'rum tr\u00e4gt er auch vor aller Welt", "tokens": ["D'\u00b7rum", "tr\u00e4gt", "er", "auch", "vor", "al\u00b7ler", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Zwei H\u00f6rner zum Entsetzen;", "tokens": ["Zwei", "H\u00f6r\u00b7ner", "zum", "Ent\u00b7set\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und will der Hahnrei seinem Weib", "tokens": ["Und", "will", "der", "Hahn\u00b7rei", "sei\u00b7nem", "Weib"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zuweilen n\u00e4her auf den Leib,", "tokens": ["Zu\u00b7wei\u00b7len", "n\u00e4\u00b7her", "auf", "den", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So kriegt er finst're Blicke", "tokens": ["So", "kriegt", "er", "finst'\u00b7re", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und mu\u00df besch\u00e4mt zur\u00fccke.", "tokens": ["Und", "mu\u00df", "be\u00b7sch\u00e4mt", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Sie l\u00e4\u00dft sich zwar die K\u00f6nigin", "tokens": ["Sie", "l\u00e4\u00dft", "sich", "zwar", "die", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Sternenhimmels schelten;", "tokens": ["Des", "Ster\u00b7nen\u00b7him\u00b7mels", "schel\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allein den k\u00f6niglichen Sinn", "tokens": ["Al\u00b7lein", "den", "k\u00f6\u00b7nig\u00b7li\u00b7chen", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mu\u00df man genug entgelten:", "tokens": ["Mu\u00df", "man", "ge\u00b7nug", "ent\u00b7gel\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sie sengt und brennt ja m\u00f6rderlich,", "tokens": ["Sie", "sengt", "und", "brennt", "ja", "m\u00f6r\u00b7der\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wei\u00df dabei \u2013 recht k\u00f6niglich, \u2013", "tokens": ["Und", "wei\u00df", "da\u00b7bei", "\u2013", "recht", "k\u00f6\u00b7nig\u00b7lich", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PAV", "$(", "ADJD", "ADJD", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "F\u00fcr ihre Hand voll Weizen", "tokens": ["F\u00fcr", "ih\u00b7re", "Hand", "voll", "Wei\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Des Pfl\u00fcgers Haut zu beizen.", "tokens": ["Des", "Pfl\u00fc\u00b7gers", "Haut", "zu", "bei\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Gibt sie die eine Hand uns voll,", "tokens": ["Gibt", "sie", "die", "ei\u00b7ne", "Hand", "uns", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ART", "NN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So nimmt sie mit der andern:", "tokens": ["So", "nimmt", "sie", "mit", "der", "an\u00b7dern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie geht ja um mit Kraut und Kohl,", "tokens": ["Sie", "geht", "ja", "um", "mit", "Kraut", "und", "Kohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als wie mit Salamandern:", "tokens": ["Als", "wie", "mit", "Sa\u00b7la\u00b7man\u00b7dern", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mit \u00e4chter K\u00f6nigspolitik", "tokens": ["Mit", "\u00e4ch\u00b7ter", "K\u00f6\u00b7nigs\u00b7po\u00b7li\u00b7tik"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Versenget sie oft St\u00fcck f\u00fcr St\u00fcck,", "tokens": ["Ver\u00b7sen\u00b7get", "sie", "oft", "St\u00fcck", "f\u00fcr", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NN", "APPR", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.7": {"text": "Die Felder und die Saaten,", "tokens": ["Die", "Fel\u00b7der", "und", "die", "Saa\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "L\u00e4\u00dft Trauben nur gerathen.", "tokens": ["L\u00e4\u00dft", "Trau\u00b7ben", "nur", "ge\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Ey, f\u00fcr ein k\u00f6nigliches Haupt", "tokens": ["Ey", ",", "f\u00fcr", "ein", "k\u00f6\u00b7nig\u00b7li\u00b7ches", "Haupt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hei\u00dft das sich sehr vergessen,", "tokens": ["Hei\u00dft", "das", "sich", "sehr", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn man von Unterthanen glaubt,", "tokens": ["Wenn", "man", "von", "Un\u00b7ter\u00b7tha\u00b7nen", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie k\u00f6nnten Kohlen fressen.", "tokens": ["Sie", "k\u00f6nn\u00b7ten", "Koh\u00b7len", "fres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nicht wahr, Frau Klug, ihr fiel nicht ein,", "tokens": ["Nicht", "wahr", ",", "Frau", "Klug", ",", "ihr", "fiel", "nicht", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "NN", "NE", "$,", "PPER", "VVFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df man beim allerbesten Wein", "tokens": ["Da\u00df", "man", "beim", "al\u00b7ler\u00b7bes\u00b7ten", "Wein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und einer leeren Tenne", "tokens": ["Und", "ei\u00b7ner", "lee\u00b7ren", "Ten\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Fein h\u00fcbsch verhungern k\u00f6nne.", "tokens": ["Fein", "h\u00fcbsch", "ver\u00b7hun\u00b7gern", "k\u00f6n\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Man nennt mit Recht sie das Modell", "tokens": ["Man", "nennt", "mit", "Recht", "sie", "das", "Mo\u00b7dell"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "NN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von k\u00f6niglichen Geistern,", "tokens": ["Von", "k\u00f6\u00b7nig\u00b7li\u00b7chen", "Geis\u00b7tern", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die mit dem ersten Blicke schnell", "tokens": ["Die", "mit", "dem", "ers\u00b7ten", "Bli\u00b7cke", "schnell"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein ganzes Weltall meistern:", "tokens": ["Ein", "gan\u00b7zes", "Wel\u00b7tall", "meis\u00b7tern", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn auch Madam mit ihrem Licht", "tokens": ["Denn", "auch", "Ma\u00b7dam", "mit", "ih\u00b7rem", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sieht alles \u2013 nur sich selber nicht,", "tokens": ["Sieht", "al\u00b7les", "\u2013", "nur", "sich", "sel\u00b7ber", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$(", "ADV", "PRF", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und wird an sich die Flecken", "tokens": ["Und", "wird", "an", "sich", "die", "Fle\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "PRF", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wohl nimmermehr entdecken.", "tokens": ["Wohl", "nim\u00b7mer\u00b7mehr", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Ich aber bin nicht undankbar,", "tokens": ["Ich", "a\u00b7ber", "bin", "nicht", "un\u00b7dank\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich von ihr gebeichtet,", "tokens": ["Da\u00df", "ich", "von", "ihr", "ge\u00b7beich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was lang mir auf dem Herzen war,", "tokens": ["Was", "lang", "mir", "auf", "dem", "Her\u00b7zen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "PPER", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Inde\u00df sie mir geleuchtet;", "tokens": ["In\u00b7de\u00df", "sie", "mir", "ge\u00b7leuch\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn, um f\u00fcr ihren Sonnenschein", "tokens": ["Denn", ",", "um", "f\u00fcr", "ih\u00b7ren", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUI", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr gar nicht obligirt zu sein,", "tokens": ["Ihr", "gar", "nicht", "ob\u00b7li\u00b7girt", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Schrieb ich an dem Gedichte", "tokens": ["Schrieb", "ich", "an", "dem", "Ge\u00b7dich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.8": {"text": "Nur Nachts \u2013 beim Kerzenlichte.", "tokens": ["Nur", "Nachts", "\u2013", "beim", "Ker\u00b7zen\u00b7lich\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}