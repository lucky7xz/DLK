{"dta.poem.20614": {"metadata": {"author": {"name": "Hebel, Johann Peter", "birth": "N.A.", "death": "N.A."}, "title": "Der Wegweiser .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1803", "urn": "urn:nbn:de:kobv:b4-200905192133", "language": ["de:0.99"], "booktitle": "[Hebel, Johann Peter]: Allemannische Gedichte. Karlsruhe, 1803."}, "poem": {"stanza.1": {"line.1": {"text": "Weisch, wo der Weg zum Mehlfa\u00df isch,               ", "tokens": ["Weisch", ",", "wo", "der", "Weg", "zum", "Mehl\u00b7fa\u00df", "isch", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "APPRART", "NN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "zum volle Fa\u00df? Im Morgeroth", "tokens": ["zum", "vol\u00b7le", "Fa\u00df", "?", "Im", "Mor\u00b7ge\u00b7roth"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$.", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mit Pflug und Charst dur\u2019s Weizefeld,", "tokens": ["mit", "Pflug", "und", "Charst", "dur's", "Wei\u00b7ze\u00b7feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "bis Stern und Stern am Himmel stoht.", "tokens": ["bis", "Stern", "und", "Stern", "am", "Him\u00b7mel", "stoht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Me hackt, so lang der Tag eim hilft,", "tokens": ["Me", "hackt", ",", "so", "lang", "der", "Tag", "eim", "hilft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "ADV", "ADJD", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "me luegt nit um, und blibt nit stoh;", "tokens": ["me", "luegt", "nit", "um", ",", "und", "blibt", "nit", "stoh", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "PTKNEG", "PTKVZ", "$,", "KON", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "z\u2019 lezt goht der Weg dur \u2019s Sch\u00fcre-Tenn", "tokens": ["z'", "lezt", "goht", "der", "Weg", "dur", "'s", "Sch\u00fc\u00b7re\u00b7Tenn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "VVFIN", "ART", "NN", "VVFIN", "PPER", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "in d\u2019 Chuchchi, und do hemmers io!", "tokens": ["in", "d'", "Chuch\u00b7chi", ",", "und", "do", "hem\u00b7mers", "i\u00b7o", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "$,", "KON", "FM", "FM", "FM", "$."], "meter": "+-+-++----", "measure": "unknown.measure.tetra"}}, "stanza.3": {"line.1": {"text": "Weisch wo der Weg zum Gulden isch?", "tokens": ["Weisch", "wo", "der", "Weg", "zum", "Gul\u00b7den", "isch", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PWAV", "ART", "NN", "APPRART", "NN", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Er goht de rothe Chr\u00fctzere no,", "tokens": ["Er", "goht", "de", "ro\u00b7the", "Chr\u00fct\u00b7ze\u00b7re", "no", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "FM", "FM", "FM", "FM", "FM", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "und wer nit uffe Chr\u00fctzer luegt,", "tokens": ["und", "wer", "nit", "uf\u00b7fe", "Chr\u00fct\u00b7zer", "luegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der wird zum Gulde schwerli cho.", "tokens": ["der", "wird", "zum", "Gul\u00b7de", "schwer\u00b7li", "cho", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "APPRART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wo isch der Weg zur Sunntig-Freud?", "tokens": ["Wo", "isch", "der", "Weg", "zur", "Sunn\u00b7tig\u00b7Freud", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gang ohni Gfohr im Werchtig no", "tokens": ["Gang", "oh\u00b7ni", "Gfohr", "im", "Werch\u00b7tig", "no"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "APPRART", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "dur d\u2019 Werkstatt ", "tokens": ["dur", "d'", "Werk\u00b7statt"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NE", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "der Sunntig wird scho selber cho.", "tokens": ["der", "Sunn\u00b7tig", "wird", "scho", "sel\u00b7ber", "cho", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "ADV", "ADV", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Am Samstig isch er nit gar wit.", "tokens": ["Am", "Sams\u00b7tig", "isch", "er", "nit", "gar", "wit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "ADJD", "PPER", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was deckt er echt im Ch\u00f6rbli zu?", "tokens": ["Was", "deckt", "er", "echt", "im", "Ch\u00f6rb\u00b7li", "zu", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denkwol e Pf\u00fcndli Fleisch ins Gm\u00fces,", "tokens": ["Denk\u00b7wol", "e", "Pf\u00fcnd\u00b7li", "Fleisch", "ins", "Gm\u00fces", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u2019s cha sy, ne Sch\u00f6pli Wi derzu.", "tokens": ["'s", "cha", "sy", ",", "ne", "Sch\u00f6p\u00b7li", "Wi", "der\u00b7zu", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "NE", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Weisch, wo der Weg in d\u2019 Armeth goht?", "tokens": ["Weisch", ",", "wo", "der", "Weg", "in", "d'", "Ar\u00b7meth", "goht", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "APPR", "NE", "NE", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Lueg numme, wo Tafere sin!", "tokens": ["Lu\u00b7eg", "num\u00b7me", ",", "wo", "Ta\u00b7fe\u00b7re", "sin", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "PWAV", "NN", "PTKVZ", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Gang nit verbey, \u2019s isch gute Wi,", "tokens": ["Gang", "nit", "ver\u00b7bey", ",", "'s", "isch", "gu\u00b7te", "Wi", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PTKVZ", "$,", "PPER", "ADJD", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "\u2019s sin nagelneui Charte d\u2019inn!", "tokens": ["'s", "sin", "na\u00b7gel\u00b7neu\u00b7i", "Char\u00b7te", "d'\u00b7inn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "FM", "FM", "FM", "FM", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.7": {"line.1": {"text": "Im letste Wirthshus hangt e Sack,", "tokens": ["Im", "lets\u00b7te", "Wirths\u00b7hus", "hangt", "e", "Sack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und wenn de furt gohsch, henk en a!", "tokens": ["und", "wenn", "de", "furt", "goh\u00b7sch", ",", "henk", "en", "a", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NE", "NE", "ADJD", "$,", "FM", "FM", "FM", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u201edu alte Lump, wie stoht der nit", "tokens": ["\u201e", "du", "al\u00b7te", "Lump", ",", "wie", "stoht", "der", "nit"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "ADJA", "NN", "$,", "PWAV", "VVFIN", "ART", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eder Bettelsack so zierlig a!\u201c", "tokens": ["\u201e", "der", "Bet\u00b7tel\u00b7sack", "so", "zier\u00b7lig", "a", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "ADV", "ADJD", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Es isch e h\u00f6lzene Becher drinn,", "tokens": ["Es", "isch", "e", "h\u00f6l\u00b7ze\u00b7ne", "Be\u00b7cher", "drinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NE", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "gib achtig druf, verliehr en nit!", "tokens": ["gib", "ach\u00b7tig", "druf", ",", "ver\u00b7liehr", "en", "nit", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJD", "PAV", "$,", "FM", "FM", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wenn de an e W\u00e4sserli chunnsch", "tokens": ["Und", "wenn", "de", "an", "e", "W\u00e4s\u00b7ser\u00b7li", "chunnsch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "NE", "APPR", "NE", "NE", "NE"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "und trinke magsch, se sch\u00f6pf dermit!", "tokens": ["und", "trin\u00b7ke", "magsch", ",", "se", "sch\u00f6pf", "der\u00b7mit", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Wo isch der Weg zu Fried und Ehr,", "tokens": ["Wo", "isch", "der", "Weg", "zu", "Fried", "und", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der Weg zum guten Alter echt?", "tokens": ["der", "Weg", "zum", "gu\u00b7ten", "Al\u00b7ter", "echt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Grad f\u00fcrsi gohts in M\u00e4\u00dfigkeit", "tokens": ["Grad", "f\u00fcr\u00b7si", "gohts", "in", "M\u00e4\u00b7\u00dfig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "FM", "FM", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mit stillem Sinn in Pflicht und Recht.", "tokens": ["mit", "stil\u00b7lem", "Sinn", "in", "Pflicht", "und", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Und wenn de amme Chr\u00fctzweg stohsch,", "tokens": ["Und", "wenn", "de", "am\u00b7me", "Chr\u00fctz\u00b7weg", "stohsch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NE", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und n\u00fcmme weisch, wo \u2019s ane goht,", "tokens": ["und", "n\u00fcm\u00b7me", "weisch", ",", "wo", "'s", "a\u00b7ne", "goht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "PWAV", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "halt still, und frog di Gwisse z\u2019erst,", "tokens": ["halt", "still", ",", "und", "frog", "di", "Gwis\u00b7se", "z'\u00b7erst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u2019s cha d\u00fctsch, Gottlob, und folg si\u2019m Roth!", "tokens": ["'s", "cha", "d\u00fctsch", ",", "Gott\u00b7lob", ",", "und", "folg", "si'm", "Roth", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "ADJD", "$,", "NN", "$,", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Wo mag der Weg zum Chilchhof sy?", "tokens": ["Wo", "mag", "der", "Weg", "zum", "Chilch\u00b7hof", "sy", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "NN", "APPRART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was frogsch no lang? Gang, wo de witt!", "tokens": ["Was", "frogsch", "no", "lang", "?", "Gang", ",", "wo", "de", "witt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "NE", "ADJD", "$.", "NN", "$,", "PWAV", "NE", "VVFIN", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Zum stille Grab im ch\u00fcele Grund", "tokens": ["Zum", "stil\u00b7le", "Grab", "im", "ch\u00fce\u00b7le", "Grund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "f\u00fchrt iede Weg, und \u2019s fehlt si nit.", "tokens": ["f\u00fchrt", "ie\u00b7de", "Weg", ",", "und", "'s", "fehlt", "si", "nit", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.12": {"line.1": {"text": "Doch wandle du in Gottis Furcht,", "tokens": ["Doch", "wand\u00b7le", "du", "in", "Got\u00b7tis", "Furcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "i roth der, was i rothe cha!", "tokens": ["i", "roth", "der", ",", "was", "i", "ro\u00b7the", "cha", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ART", "$,", "PWS", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sel Pl\u00e4tzli het e gheimi Th\u00fcr,", "tokens": ["Sel", "Pl\u00e4tz\u00b7li", "het", "e", "ghei\u00b7mi", "Th\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "FM", "FM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und \u2019s sin no Sachen ehne dra.", "tokens": ["und", "'s", "sin", "no", "Sa\u00b7chen", "eh\u00b7ne", "dra", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}