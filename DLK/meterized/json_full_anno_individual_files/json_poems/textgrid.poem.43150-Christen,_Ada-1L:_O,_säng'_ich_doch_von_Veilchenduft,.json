{"textgrid.poem.43150": {"metadata": {"author": {"name": "Christen, Ada", "birth": "N.A.", "death": "N.A."}, "title": "1L: O, s\u00e4ng' ich doch von Veilchenduft,", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O, s\u00e4ng' ich doch von Veilchenduft,", "tokens": ["O", ",", "s\u00e4ng'", "ich", "doch", "von", "Veil\u00b7chen\u00b7duft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gleich Dir von Lieb' und Mondenschein,", "tokens": ["Gleich", "Dir", "von", "Lieb'", "und", "Mon\u00b7den\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von Waldesgr\u00fcn und Himmelszelt,", "tokens": ["Von", "Wal\u00b7des\u00b7gr\u00fcn", "und", "Him\u00b7mels\u00b7zelt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Fr\u00fchlingspracht und V\u00f6gelein!", "tokens": ["Von", "Fr\u00fch\u00b7lings\u00b7pracht", "und", "V\u00f6\u00b7ge\u00b7lein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Du s\u00e4uselst laue Treibhausluft", "tokens": ["Du", "s\u00e4u\u00b7selst", "lau\u00b7e", "Treib\u00b7haus\u00b7luft"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und weinst gew\u00e4rmte Thr\u00e4nelein,", "tokens": ["Und", "weinst", "ge\u00b7w\u00e4rm\u00b7te", "Thr\u00e4\u00b7ne\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und meinst, es m\u00fc\u00dft' die ganze Welt,", "tokens": ["Und", "meinst", ",", "es", "m\u00fc\u00dft'", "die", "gan\u00b7ze", "Welt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PPER", "VMFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur weil Du klagst, auch kl\u00e4glich sein.", "tokens": ["Nur", "weil", "Du", "klagst", ",", "auch", "kl\u00e4g\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVFIN", "$,", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "O, honigs\u00fc\u00dfes Dichterlein,", "tokens": ["O", ",", "ho\u00b7nig\u00b7s\u00fc\u00b7\u00dfes", "Dich\u00b7ter\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Du aus B\u00fcchern dichten lernst", "tokens": ["Der", "Du", "aus", "B\u00fc\u00b7chern", "dich\u00b7ten", "lernst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und flau besingst, was stets Dich mied:", "tokens": ["Und", "flau", "be\u00b7singst", ",", "was", "stets", "Dich", "mied", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,", "PWS", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Lebens echten Schmerz und Ernst.", "tokens": ["Des", "Le\u00b7bens", "ech\u00b7ten", "Schmerz", "und", "Ernst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und doch! s\u00e4ng' ich so zierlich fein", "tokens": ["Und", "doch", "!", "s\u00e4ng'", "ich", "so", "zier\u00b7lich", "fein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "VVFIN", "PPER", "ADV", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gelernten Schmerz, geles'ne Lust,", "tokens": ["Ge\u00b7lern\u00b7ten", "Schmerz", ",", "ge\u00b7les'\u00b7ne", "Lust", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht spr\u00e4ng' mir jedes kleine Lied", "tokens": ["Nicht", "spr\u00e4ng'", "mir", "je\u00b7des", "klei\u00b7ne", "Lied"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVFIN", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein blutig M\u00e4uslein aus der Brust.", "tokens": ["Ein", "blu\u00b7tig", "M\u00e4us\u00b7lein", "aus", "der", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "O, s\u00e4ng' ich doch von Veilchenduft,", "tokens": ["O", ",", "s\u00e4ng'", "ich", "doch", "von", "Veil\u00b7chen\u00b7duft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gleich Dir von Lieb' und Mondenschein,", "tokens": ["Gleich", "Dir", "von", "Lieb'", "und", "Mon\u00b7den\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von Waldesgr\u00fcn und Himmelszelt,", "tokens": ["Von", "Wal\u00b7des\u00b7gr\u00fcn", "und", "Him\u00b7mels\u00b7zelt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Fr\u00fchlingspracht und V\u00f6gelein!", "tokens": ["Von", "Fr\u00fch\u00b7lings\u00b7pracht", "und", "V\u00f6\u00b7ge\u00b7lein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Du s\u00e4uselst laue Treibhausluft", "tokens": ["Du", "s\u00e4u\u00b7selst", "lau\u00b7e", "Treib\u00b7haus\u00b7luft"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und weinst gew\u00e4rmte Thr\u00e4nelein,", "tokens": ["Und", "weinst", "ge\u00b7w\u00e4rm\u00b7te", "Thr\u00e4\u00b7ne\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und meinst, es m\u00fc\u00dft' die ganze Welt,", "tokens": ["Und", "meinst", ",", "es", "m\u00fc\u00dft'", "die", "gan\u00b7ze", "Welt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PPER", "VMFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur weil Du klagst, auch kl\u00e4glich sein.", "tokens": ["Nur", "weil", "Du", "klagst", ",", "auch", "kl\u00e4g\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVFIN", "$,", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "O, honigs\u00fc\u00dfes Dichterlein,", "tokens": ["O", ",", "ho\u00b7nig\u00b7s\u00fc\u00b7\u00dfes", "Dich\u00b7ter\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Du aus B\u00fcchern dichten lernst", "tokens": ["Der", "Du", "aus", "B\u00fc\u00b7chern", "dich\u00b7ten", "lernst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und flau besingst, was stets Dich mied:", "tokens": ["Und", "flau", "be\u00b7singst", ",", "was", "stets", "Dich", "mied", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,", "PWS", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Lebens echten Schmerz und Ernst.", "tokens": ["Des", "Le\u00b7bens", "ech\u00b7ten", "Schmerz", "und", "Ernst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Und doch! s\u00e4ng' ich so zierlich fein", "tokens": ["Und", "doch", "!", "s\u00e4ng'", "ich", "so", "zier\u00b7lich", "fein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "VVFIN", "PPER", "ADV", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gelernten Schmerz, geles'ne Lust,", "tokens": ["Ge\u00b7lern\u00b7ten", "Schmerz", ",", "ge\u00b7les'\u00b7ne", "Lust", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht spr\u00e4ng' mir jedes kleine Lied", "tokens": ["Nicht", "spr\u00e4ng'", "mir", "je\u00b7des", "klei\u00b7ne", "Lied"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVFIN", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein blutig M\u00e4uslein aus der Brust.", "tokens": ["Ein", "blu\u00b7tig", "M\u00e4us\u00b7lein", "aus", "der", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}