{"textgrid.poem.66114": {"metadata": {"author": {"name": "Falke, Gustav", "birth": "N.A.", "death": "N.A."}, "title": "Das Opferkind", "genre": "verse", "period": "N.A.", "pub_year": 1884, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bei Heiligenstedten, der St\u00f6rdeich wars,", "tokens": ["Bei", "Hei\u00b7li\u00b7gen\u00b7sted\u00b7ten", ",", "der", "St\u00f6r\u00b7deich", "wars", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der Deich wollte nicht halten.", "tokens": ["Der", "Deich", "woll\u00b7te", "nicht", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Ein Loch klaffte, man kriegt es nicht zu,", "tokens": ["Ein", "Loch", "klaff\u00b7te", ",", "man", "kriegt", "es", "nicht", "zu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Die Flut wei\u00df zu sp\u00fclen, zu spalten.", "tokens": ["Die", "Flut", "wei\u00df", "zu", "sp\u00fc\u00b7len", ",", "zu", "spal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "So viel man auch stopft mit Erde und Stein,", "tokens": ["So", "viel", "man", "auch", "stopft", "mit", "Er\u00b7de", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "ADV", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das Meer st\u00f6\u00dft ein neues Loch hinein.", "tokens": ["Das", "Meer", "st\u00f6\u00dft", "ein", "neu\u00b7es", "Loch", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Da war Not. Wich der Deich,", "tokens": ["Da", "war", "Not", ".", "Wich", "der", "Deich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$.", "NN", "ART", "NN", "$,"], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "Das Land mu\u00dfte ersaufen.", "tokens": ["Das", "Land", "mu\u00df\u00b7te", "er\u00b7sau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Eine alte Frau wu\u00dfte Rat,", "tokens": ["Ei\u00b7ne", "al\u00b7te", "Frau", "wu\u00df\u00b7te", "Rat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Man k\u00f6nnt es dem Teufel abkaufen:", "tokens": ["Man", "k\u00f6nnt", "es", "dem", "Teu\u00b7fel", "ab\u00b7kau\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+--+-++-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Freiwillig mu\u00df ein Kind da hinab,", "tokens": ["Frei\u00b7wil\u00b7lig", "mu\u00df", "ein", "Kind", "da", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Das hilft, freiwillig hinein da ins Grab.", "tokens": ["Das", "hilft", ",", "frei\u00b7wil\u00b7lig", "hin\u00b7ein", "da", "ins", "Grab", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "ADJD", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Ein Kind! Einer Mutter Kind!", "tokens": ["Ein", "Kind", "!", "Ei\u00b7ner", "Mut\u00b7ter", "Kind", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "NN", "NN", "$."], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "H\u00e4lt jede ihrs fester am Herzen.", "tokens": ["H\u00e4lt", "je\u00b7de", "ihrs", "fes\u00b7ter", "am", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADJD", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und wenn die ganze Marsch ers\u00e4uft,", "tokens": ["Und", "wenn", "die", "gan\u00b7ze", "Marsch", "er\u00b7s\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kann eine ihr Kind verschmerzen?", "tokens": ["Kann", "ei\u00b7ne", "ihr", "Kind", "ver\u00b7schmer\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Da war Not. Das Loch mu\u00df zu.", "tokens": ["Da", "war", "Not", ".", "Das", "Loch", "mu\u00df", "zu", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$.", "ART", "NN", "VMFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "He, Tatersch, h\u00f6r mal, bettelst du?", "tokens": ["He", ",", "Ta\u00b7ter\u00b7sch", ",", "h\u00f6r", "mal", ",", "bet\u00b7telst", "du", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$,", "VVFIN", "ADV", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Hier, tausend Taler! Klimperts nicht gut?", "tokens": ["Hier", ",", "tau\u00b7send", "Ta\u00b7ler", "!", "Klim\u00b7perts", "nicht", "gut", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "CARD", "NN", "$.", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Der Zigeunerin funkeln die Augen.", "tokens": ["Der", "Zi\u00b7geu\u00b7ne\u00b7rin", "fun\u00b7keln", "die", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Tausend Taler? Nehmt den Balg!", "tokens": ["Tau\u00b7send", "Ta\u00b7ler", "?", "Nehmt", "den", "Balg", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$.", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kann doch nur zum Bettel taugen.", "tokens": ["Kann", "doch", "nur", "zum", "Bet\u00b7tel", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "So Schilling f\u00fcr Schilling erscharrt sichs schlecht.", "tokens": ["So", "Schil\u00b7ling", "f\u00fcr", "Schil\u00b7ling", "er\u00b7scharrt", "sichs", "schlecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "NN", "VVFIN", "PIS", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Gebt her! Wer ist gern Hungers Knecht.", "tokens": ["Gebt", "her", "!", "Wer", "ist", "gern", "Hun\u00b7gers", "Knecht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$.", "PWS", "VAFIN", "ADV", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Sie legen ein Brett \u00fcber das Loch", "tokens": ["Sie", "le\u00b7gen", "ein", "Brett", "\u00fc\u00b7ber", "das", "Loch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und ein wei\u00dfes Brot in die Mitte.", "tokens": ["Und", "ein", "wei\u00b7\u00dfes", "Brot", "in", "die", "Mit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der hungrige Knabe schwankt daher,", "tokens": ["Der", "hung\u00b7ri\u00b7ge", "Kna\u00b7be", "schwankt", "da\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PAV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Kleine, hastige Schritte.", "tokens": ["Klei\u00b7ne", ",", "has\u00b7ti\u00b7ge", "Schrit\u00b7te", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Jetzt langt er nach dem Brot. Weh! Das Brett", "tokens": ["Jetzt", "langt", "er", "nach", "dem", "Brot", ".", "Weh", "!", "Das", "Brett"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "NN", "$.", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Schl\u00e4gt \u00fcber und wirft ihn ins nasse Bett.", "tokens": ["Schl\u00e4gt", "\u00fc\u00b7ber", "und", "wirft", "ihn", "ins", "nas\u00b7se", "Bett", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "KON", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.6": {"line.1": {"text": "Kein Schrei. Alles stiert", "tokens": ["Kein", "Schrei", ".", "Al\u00b7les", "stiert"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$.", "PIS", "VVFIN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Stumm aufs Quirlen und Quellen.", "tokens": ["Stumm", "aufs", "Quir\u00b7len", "und", "Quel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "KON", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Da taucht es auf, ein bla\u00df Gesicht,", "tokens": ["Da", "taucht", "es", "auf", ",", "ein", "bla\u00df", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus den lehmigen Wellen,", "tokens": ["Aus", "den", "leh\u00b7mi\u00b7gen", "Wel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Taucht auf und spricht ein W\u00f6rtchen blo\u00df:", "tokens": ["Taucht", "auf", "und", "spricht", "ein", "W\u00f6rt\u00b7chen", "blo\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbist nichts so weich als Mutters Scho\u00df.\u00ab", "tokens": ["\u00bb", "ist", "nichts", "so", "weich", "als", "Mut\u00b7ters", "Scho\u00df", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PIS", "ADV", "ADJD", "KOKOM", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und taucht zum zweitenmal auf und spricht:", "tokens": ["Und", "taucht", "zum", "zwei\u00b7ten\u00b7mal", "auf", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADV", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbist nichts so s\u00fc\u00df, als Mutters Liebe.\u00ab", "tokens": ["\u00bb", "ist", "nichts", "so", "s\u00fc\u00df", ",", "als", "Mut\u00b7ters", "Lie\u00b7be", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PIS", "ADV", "ADJD", "$,", "KOUS", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie das Wort alle packt und brennt.", "tokens": ["Wie", "das", "Wort", "al\u00b7le", "packt", "und", "brennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Wenn doch das Kind endlich unten bliebe!", "tokens": ["Wenn", "doch", "das", "Kind", "end\u00b7lich", "un\u00b7ten", "blie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Doch kommt es zum dritten und spricht aufs neu:", "tokens": ["Doch", "kommt", "es", "zum", "drit\u00b7ten", "und", "spricht", "aufs", "neu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "ADJA", "KON", "VVFIN", "APPRART", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "\u00bbist nichts so fest als Mutters Treu.\u00ab", "tokens": ["\u00bb", "ist", "nichts", "so", "fest", "als", "Mut\u00b7ters", "Treu", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PIS", "ADV", "ADJD", "KOKOM", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Dann sinkt es weg. \u2013 Sie atmen auf,", "tokens": ["Dann", "sinkt", "es", "weg", ".", "\u2013", "Sie", "at\u00b7men", "auf", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nun mu\u00df das Werk geraten!", "tokens": ["Nun", "mu\u00df", "das", "Werk", "ge\u00b7ra\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die G\u00e4ule keuchen, die Karren knarrn,", "tokens": ["Die", "G\u00e4u\u00b7le", "keu\u00b7chen", ",", "die", "Kar\u00b7ren", "knarrn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es \u00e4chzen und knirschen die Spaten.", "tokens": ["Es", "\u00e4ch\u00b7zen", "und", "knir\u00b7schen", "die", "Spa\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Erde und Stein hinein ins Loch!", "tokens": ["Er\u00b7de", "und", "Stein", "hin\u00b7ein", "ins", "Loch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "APPRART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Ein teurer Deich, aber jetzt h\u00e4lt er doch.", "tokens": ["Ein", "teu\u00b7rer", "Deich", ",", "a\u00b7ber", "jetzt", "h\u00e4lt", "er", "doch", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Bei Heiligenstedten, der St\u00f6rdeich wars,", "tokens": ["Bei", "Hei\u00b7li\u00b7gen\u00b7sted\u00b7ten", ",", "der", "St\u00f6r\u00b7deich", "wars", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der Deich wollte nicht halten.", "tokens": ["Der", "Deich", "woll\u00b7te", "nicht", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Ein Loch klaffte, man kriegt es nicht zu,", "tokens": ["Ein", "Loch", "klaff\u00b7te", ",", "man", "kriegt", "es", "nicht", "zu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Die Flut wei\u00df zu sp\u00fclen, zu spalten.", "tokens": ["Die", "Flut", "wei\u00df", "zu", "sp\u00fc\u00b7len", ",", "zu", "spal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "So viel man auch stopft mit Erde und Stein,", "tokens": ["So", "viel", "man", "auch", "stopft", "mit", "Er\u00b7de", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "ADV", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das Meer st\u00f6\u00dft ein neues Loch hinein.", "tokens": ["Das", "Meer", "st\u00f6\u00dft", "ein", "neu\u00b7es", "Loch", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Da war Not. Wich der Deich,", "tokens": ["Da", "war", "Not", ".", "Wich", "der", "Deich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$.", "NN", "ART", "NN", "$,"], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "Das Land mu\u00dfte ersaufen.", "tokens": ["Das", "Land", "mu\u00df\u00b7te", "er\u00b7sau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Eine alte Frau wu\u00dfte Rat,", "tokens": ["Ei\u00b7ne", "al\u00b7te", "Frau", "wu\u00df\u00b7te", "Rat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Man k\u00f6nnt es dem Teufel abkaufen:", "tokens": ["Man", "k\u00f6nnt", "es", "dem", "Teu\u00b7fel", "ab\u00b7kau\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+--+-++-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Freiwillig mu\u00df ein Kind da hinab,", "tokens": ["Frei\u00b7wil\u00b7lig", "mu\u00df", "ein", "Kind", "da", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Das hilft, freiwillig hinein da ins Grab.", "tokens": ["Das", "hilft", ",", "frei\u00b7wil\u00b7lig", "hin\u00b7ein", "da", "ins", "Grab", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "ADJD", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Ein Kind! Einer Mutter Kind!", "tokens": ["Ein", "Kind", "!", "Ei\u00b7ner", "Mut\u00b7ter", "Kind", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "NN", "NN", "$."], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "H\u00e4lt jede ihrs fester am Herzen.", "tokens": ["H\u00e4lt", "je\u00b7de", "ihrs", "fes\u00b7ter", "am", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADJD", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und wenn die ganze Marsch ers\u00e4uft,", "tokens": ["Und", "wenn", "die", "gan\u00b7ze", "Marsch", "er\u00b7s\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kann eine ihr Kind verschmerzen?", "tokens": ["Kann", "ei\u00b7ne", "ihr", "Kind", "ver\u00b7schmer\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Da war Not. Das Loch mu\u00df zu.", "tokens": ["Da", "war", "Not", ".", "Das", "Loch", "mu\u00df", "zu", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$.", "ART", "NN", "VMFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "He, Tatersch, h\u00f6r mal, bettelst du?", "tokens": ["He", ",", "Ta\u00b7ter\u00b7sch", ",", "h\u00f6r", "mal", ",", "bet\u00b7telst", "du", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$,", "VVFIN", "ADV", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Hier, tausend Taler! Klimperts nicht gut?", "tokens": ["Hier", ",", "tau\u00b7send", "Ta\u00b7ler", "!", "Klim\u00b7perts", "nicht", "gut", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "CARD", "NN", "$.", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Der Zigeunerin funkeln die Augen.", "tokens": ["Der", "Zi\u00b7geu\u00b7ne\u00b7rin", "fun\u00b7keln", "die", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Tausend Taler? Nehmt den Balg!", "tokens": ["Tau\u00b7send", "Ta\u00b7ler", "?", "Nehmt", "den", "Balg", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$.", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kann doch nur zum Bettel taugen.", "tokens": ["Kann", "doch", "nur", "zum", "Bet\u00b7tel", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "So Schilling f\u00fcr Schilling erscharrt sichs schlecht.", "tokens": ["So", "Schil\u00b7ling", "f\u00fcr", "Schil\u00b7ling", "er\u00b7scharrt", "sichs", "schlecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "NN", "VVFIN", "PIS", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Gebt her! Wer ist gern Hungers Knecht.", "tokens": ["Gebt", "her", "!", "Wer", "ist", "gern", "Hun\u00b7gers", "Knecht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$.", "PWS", "VAFIN", "ADV", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Sie legen ein Brett \u00fcber das Loch", "tokens": ["Sie", "le\u00b7gen", "ein", "Brett", "\u00fc\u00b7ber", "das", "Loch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und ein wei\u00dfes Brot in die Mitte.", "tokens": ["Und", "ein", "wei\u00b7\u00dfes", "Brot", "in", "die", "Mit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der hungrige Knabe schwankt daher,", "tokens": ["Der", "hung\u00b7ri\u00b7ge", "Kna\u00b7be", "schwankt", "da\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PAV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Kleine, hastige Schritte.", "tokens": ["Klei\u00b7ne", ",", "has\u00b7ti\u00b7ge", "Schrit\u00b7te", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Jetzt langt er nach dem Brot. Weh! Das Brett", "tokens": ["Jetzt", "langt", "er", "nach", "dem", "Brot", ".", "Weh", "!", "Das", "Brett"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "NN", "$.", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Schl\u00e4gt \u00fcber und wirft ihn ins nasse Bett.", "tokens": ["Schl\u00e4gt", "\u00fc\u00b7ber", "und", "wirft", "ihn", "ins", "nas\u00b7se", "Bett", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "KON", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.14": {"line.1": {"text": "Kein Schrei. Alles stiert", "tokens": ["Kein", "Schrei", ".", "Al\u00b7les", "stiert"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$.", "PIS", "VVFIN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Stumm aufs Quirlen und Quellen.", "tokens": ["Stumm", "aufs", "Quir\u00b7len", "und", "Quel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "KON", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Da taucht es auf, ein bla\u00df Gesicht,", "tokens": ["Da", "taucht", "es", "auf", ",", "ein", "bla\u00df", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus den lehmigen Wellen,", "tokens": ["Aus", "den", "leh\u00b7mi\u00b7gen", "Wel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Taucht auf und spricht ein W\u00f6rtchen blo\u00df:", "tokens": ["Taucht", "auf", "und", "spricht", "ein", "W\u00f6rt\u00b7chen", "blo\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbist nichts so weich als Mutters Scho\u00df.\u00ab", "tokens": ["\u00bb", "ist", "nichts", "so", "weich", "als", "Mut\u00b7ters", "Scho\u00df", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PIS", "ADV", "ADJD", "KOKOM", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Und taucht zum zweitenmal auf und spricht:", "tokens": ["Und", "taucht", "zum", "zwei\u00b7ten\u00b7mal", "auf", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADV", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbist nichts so s\u00fc\u00df, als Mutters Liebe.\u00ab", "tokens": ["\u00bb", "ist", "nichts", "so", "s\u00fc\u00df", ",", "als", "Mut\u00b7ters", "Lie\u00b7be", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PIS", "ADV", "ADJD", "$,", "KOUS", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie das Wort alle packt und brennt.", "tokens": ["Wie", "das", "Wort", "al\u00b7le", "packt", "und", "brennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Wenn doch das Kind endlich unten bliebe!", "tokens": ["Wenn", "doch", "das", "Kind", "end\u00b7lich", "un\u00b7ten", "blie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Doch kommt es zum dritten und spricht aufs neu:", "tokens": ["Doch", "kommt", "es", "zum", "drit\u00b7ten", "und", "spricht", "aufs", "neu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "ADJA", "KON", "VVFIN", "APPRART", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "\u00bbist nichts so fest als Mutters Treu.\u00ab", "tokens": ["\u00bb", "ist", "nichts", "so", "fest", "als", "Mut\u00b7ters", "Treu", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PIS", "ADV", "ADJD", "KOKOM", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Dann sinkt es weg. \u2013 Sie atmen auf,", "tokens": ["Dann", "sinkt", "es", "weg", ".", "\u2013", "Sie", "at\u00b7men", "auf", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nun mu\u00df das Werk geraten!", "tokens": ["Nun", "mu\u00df", "das", "Werk", "ge\u00b7ra\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die G\u00e4ule keuchen, die Karren knarrn,", "tokens": ["Die", "G\u00e4u\u00b7le", "keu\u00b7chen", ",", "die", "Kar\u00b7ren", "knarrn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es \u00e4chzen und knirschen die Spaten.", "tokens": ["Es", "\u00e4ch\u00b7zen", "und", "knir\u00b7schen", "die", "Spa\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Erde und Stein hinein ins Loch!", "tokens": ["Er\u00b7de", "und", "Stein", "hin\u00b7ein", "ins", "Loch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "APPRART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Ein teurer Deich, aber jetzt h\u00e4lt er doch.", "tokens": ["Ein", "teu\u00b7rer", "Deich", ",", "a\u00b7ber", "jetzt", "h\u00e4lt", "er", "doch", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}