{"textgrid.poem.44562": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "[jellachich und Windischgratz]", "genre": "verse", "period": "N.A.", "pub_year": 1848, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Jellachich und Windischgratz", "tokens": ["Jel\u00b7la\u00b7chich", "und", "Win\u00b7dischgratz"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und Radetzkys Degen", "tokens": ["Und", "Ra\u00b7detz\u00b7kys", "De\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["KON", "NE", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Heben neu an seinen Platz,", "tokens": ["He\u00b7ben", "neu", "an", "sei\u00b7nen", "Platz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was zerst\u00f6rt gelegen.", "tokens": ["Was", "zer\u00b7st\u00f6rt", "ge\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "T\u00e4tig da nur, wo es gilt,", "tokens": ["T\u00e4\u00b7tig", "da", "nur", ",", "wo", "es", "gilt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Einfach t\u00fcchtge M\u00e4nner,", "tokens": ["Ein\u00b7fach", "t\u00fccht\u00b7ge", "M\u00e4n\u00b7ner", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die wohl gar veraltet schilt", "tokens": ["Die", "wohl", "gar", "ver\u00b7al\u00b7tet", "schilt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "VVPP", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Neurer Weisheit Kenner.", "tokens": ["Neu\u00b7rer", "Weis\u00b7heit", "Ken\u00b7ner", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Aber eins bewahrten sie,", "tokens": ["A\u00b7ber", "eins", "be\u00b7wahr\u00b7ten", "sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was mit uns geboren,", "tokens": ["Was", "mit", "uns", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und das Kl\u00fcgeln findet nie,", "tokens": ["Und", "das", "Kl\u00fc\u00b7geln", "fin\u00b7det", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenns das Herz verloren:", "tokens": ["Wenns", "das", "Herz", "ver\u00b7lo\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "...", "tokens": ["..."], "token_info": ["punct"], "pos": ["$("]}}, "stanza.4": {"line.1": {"text": "Jellachich und Windischgratz", "tokens": ["Jel\u00b7la\u00b7chich", "und", "Win\u00b7dischgratz"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und Radetzkys Degen", "tokens": ["Und", "Ra\u00b7detz\u00b7kys", "De\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["KON", "NE", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Heben neu an seinen Platz,", "tokens": ["He\u00b7ben", "neu", "an", "sei\u00b7nen", "Platz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was zerst\u00f6rt gelegen.", "tokens": ["Was", "zer\u00b7st\u00f6rt", "ge\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "T\u00e4tig da nur, wo es gilt,", "tokens": ["T\u00e4\u00b7tig", "da", "nur", ",", "wo", "es", "gilt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Einfach t\u00fcchtge M\u00e4nner,", "tokens": ["Ein\u00b7fach", "t\u00fccht\u00b7ge", "M\u00e4n\u00b7ner", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die wohl gar veraltet schilt", "tokens": ["Die", "wohl", "gar", "ver\u00b7al\u00b7tet", "schilt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "VVPP", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Neurer Weisheit Kenner.", "tokens": ["Neu\u00b7rer", "Weis\u00b7heit", "Ken\u00b7ner", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Aber eins bewahrten sie,", "tokens": ["A\u00b7ber", "eins", "be\u00b7wahr\u00b7ten", "sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was mit uns geboren,", "tokens": ["Was", "mit", "uns", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und das Kl\u00fcgeln findet nie,", "tokens": ["Und", "das", "Kl\u00fc\u00b7geln", "fin\u00b7det", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenns das Herz verloren:", "tokens": ["Wenns", "das", "Herz", "ver\u00b7lo\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "...", "tokens": ["..."], "token_info": ["punct"], "pos": ["$("]}}}}}