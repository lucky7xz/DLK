{"textgrid.poem.61403": {"metadata": {"author": {"name": "Geibel, Emanuel", "birth": "N.A.", "death": "N.A."}, "title": "1L: J\u00fcnglings Zorn und Lieben ist Flamm' in Stroh und Dorn,", "genre": "verse", "period": "N.A.", "pub_year": 1833, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "J\u00fcnglings Zorn und Lieben ist Flamm' in Stroh und Dorn,", "tokens": ["J\u00fcng\u00b7lings", "Zorn", "und", "Lie\u00b7ben", "ist", "Flamm'", "in", "Stroh", "und", "Dorn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "ADJA", "VAFIN", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Doch wie gl\u00fchend Eisen ist Greises Lieb' und Zorn:", "tokens": ["Doch", "wie", "gl\u00fc\u00b7hend", "Ei\u00b7sen", "ist", "Grei\u00b7ses", "Lieb'", "und", "Zorn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJD", "NN", "VAFIN", "NE", "NN", "KON", "NN", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Das mu\u00dften bald erfahren die k\u00fchnen Br\u00fcder beid',", "tokens": ["Das", "mu\u00df\u00b7ten", "bald", "er\u00b7fah\u00b7ren", "die", "k\u00fch\u00b7nen", "Br\u00fc\u00b7der", "beid'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "VVINF", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Dazu Alfsonn' im Goldhaar zu \u00fcbergro\u00dfem Leid.", "tokens": ["Da\u00b7zu", "Alf\u00b7sonn'", "im", "Gold\u00b7haar", "zu", "\u00fc\u00b7ber\u00b7gro\u00b7\u00dfem", "Leid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NE", "APPRART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "--+--++-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.2": {"line.1": {"text": "Es war die Zeit gekommen, da im gr\u00fcnen Hag", "tokens": ["Es", "war", "die", "Zeit", "ge\u00b7kom\u00b7men", ",", "da", "im", "gr\u00fc\u00b7nen", "Hag"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$,", "KOUS", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man k\u00fchle Schatten suchet, und Nachtigallenschlag", "tokens": ["Man", "k\u00fch\u00b7le", "Schat\u00b7ten", "su\u00b7chet", ",", "und", "Nach\u00b7ti\u00b7gal\u00b7len\u00b7schlag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIS", "ADJA", "NN", "VVFIN", "$,", "KON", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "An den Br\u00fcnnlein schallet: da kam, den Sporn voll Blut,", "tokens": ["An", "den", "Br\u00fcnn\u00b7lein", "schal\u00b7let", ":", "da", "kam", ",", "den", "Sporn", "voll", "Blut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "$,", "ART", "NN", "ADJD", "NN", "$,"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ein Reiter gen Alfheim, des Kunde war nicht gut.", "tokens": ["Ein", "Rei\u00b7ter", "gen", "Alf\u00b7heim", ",", "des", "Kun\u00b7de", "war", "nicht", "gut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$,", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Er sprach: \u00bbEs hat entboten bei lautem H\u00f6rnerschall", "tokens": ["Er", "sprach", ":", "\u00bb", "Es", "hat", "ent\u00b7bo\u00b7ten", "bei", "lau\u00b7tem", "H\u00f6r\u00b7ner\u00b7schall"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VAFIN", "VVPP", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sigurd der Vielgrimme seine Degen all;", "tokens": ["Si\u00b7gurd", "der", "Viel\u00b7grim\u00b7me", "sei\u00b7ne", "De\u00b7gen", "all", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "PPOSAT", "NN", "PIAT", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mit Rossen und Streitwagen zieht er nun daher", "tokens": ["Mit", "Ros\u00b7sen", "und", "Streit\u00b7wa\u00b7gen", "zieht", "er", "nun", "da\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "ADV", "PAV"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Auf mehr denn hundert Schiffen. So viele trug noch nie das Meer.", "tokens": ["Auf", "mehr", "denn", "hun\u00b7dert", "Schif\u00b7fen", ".", "So", "vie\u00b7le", "trug", "noch", "nie", "das", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "CARD", "NN", "$.", "ADV", "PIS", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.4": {"line.1": {"text": "Auch hat er sich verschworen mit einem teuern Eid,", "tokens": ["Auch", "hat", "er", "sich", "ver\u00b7schwo\u00b7ren", "mit", "ei\u00b7nem", "teu\u00b7ern", "Eid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Nimmerdar von Alfheim zu kehren aus dem Streit,", "tokens": ["Nim\u00b7mer\u00b7dar", "von", "Alf\u00b7heim", "zu", "keh\u00b7ren", "aus", "dem", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Ohne mit Alfsonnen. Nun pfleget Rats geschwind!", "tokens": ["Oh\u00b7ne", "mit", "Alf\u00b7son\u00b7nen", ".", "Nun", "pfle\u00b7get", "Rats", "ge\u00b7schwind", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NN", "$.", "ADV", "VVFIN", "NN", "VVPP", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Der K\u00f6nig zaudert nimmer und f\u00e4hrt mit gutem Wind.\u00ab", "tokens": ["Der", "K\u00f6\u00b7nig", "zau\u00b7dert", "nim\u00b7mer", "und", "f\u00e4hrt", "mit", "gu\u00b7tem", "Wind", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KON", "VVFIN", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Da sprach der junge Erek: \u00bbDas geht an unsern Leib,", "tokens": ["Da", "sprach", "der", "jun\u00b7ge", "E\u00b7rek", ":", "\u00bb", "Das", "geht", "an", "un\u00b7sern", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "$(", "PDS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es sei denn, da\u00df die Schwester w\u00fcrde Sigurds Weib;", "tokens": ["Es", "sei", "denn", ",", "da\u00df", "die", "Schwes\u00b7ter", "w\u00fcr\u00b7de", "Si\u00b7gurds", "Weib", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "KOUS", "ART", "NN", "VAFIN", "NE", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch m\u00f6cht' ich des entraten. Es m\u00fc\u00dft' im Eis vergehn", "tokens": ["Doch", "m\u00f6cht'", "ich", "des", "ent\u00b7ra\u00b7ten", ".", "Es", "m\u00fc\u00dft'", "im", "Eis", "ver\u00b7gehn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ART", "ADJA", "$.", "PPER", "VMFIN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Traurig unser R\u00f6slein.\u00ab \u2013 \u00bbDas soll\u00ab, sprach Alf, \u00bbniemals geschehn.", "tokens": ["Trau\u00b7rig", "un\u00b7ser", "R\u00f6s\u00b7lein", ".", "\u00ab", "\u2013", "\u00bb", "Das", "soll", "\u00ab", ",", "sprach", "Alf", ",", "\u00bb", "nie\u00b7mals", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "$.", "$(", "$(", "$(", "PDS", "VMFIN", "$(", "$,", "VVFIN", "NE", "$,", "$(", "ADV", "VVPP", "$."], "meter": "+-+-+--+--+--+", "measure": "trochaic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Lieber will ich liegen auf der Heide breit", "tokens": ["Lie\u00b7ber", "will", "ich", "lie\u00b7gen", "auf", "der", "Hei\u00b7de", "breit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "ADJD"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Im blutgef\u00e4rbten Ginster, ja, lieber mag die Maid", "tokens": ["Im", "blut\u00b7ge\u00b7f\u00e4rb\u00b7ten", "Gins\u00b7ter", ",", "ja", ",", "lie\u00b7ber", "mag", "die", "Maid"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$,", "PTKANT", "$,", "ADV", "VMFIN", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ihr jungfrisches Leben veratmen in den Wind,", "tokens": ["Ihr", "jung\u00b7fri\u00b7sches", "Le\u00b7ben", "ver\u00b7at\u00b7men", "in", "den", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Eh' sie wird des Greisen, den ihr Herz nicht minnt.\u00ab", "tokens": ["Eh'", "sie", "wird", "des", "Grei\u00b7sen", ",", "den", "ihr", "Herz", "nicht", "minnt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "PTKNEG", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.7": {"line.1": {"text": "Am hohen Bogenfenster von ihren Sorgen schwer", "tokens": ["Am", "ho\u00b7hen", "Bo\u00b7gen\u00b7fens\u00b7ter", "von", "ih\u00b7ren", "Sor\u00b7gen", "schwer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Red'ten so die beiden; da sahn sie \u00fcbers Meer", "tokens": ["Re\u00b7d'\u00b7ten", "so", "die", "bei\u00b7den", ";", "da", "sahn", "sie", "\u00fc\u00b7bers", "Meer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "PIAT", "$.", "ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Viel wei\u00dfe Segel kommen wie mit Schwalbenflug;", "tokens": ["Viel", "wei\u00b7\u00dfe", "Se\u00b7gel", "kom\u00b7men", "wie", "mit", "Schwal\u00b7ben\u00b7flug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVINF", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das war die Sigurdsflotte, nicht enden wollte der Zug.", "tokens": ["Das", "war", "die", "Si\u00b7gurds\u00b7flot\u00b7te", ",", "nicht", "en\u00b7den", "woll\u00b7te", "der", "Zug", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PTKNEG", "VVINF", "VMFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Auf den Schiffen blitzt' es und glei\u00dft' im Sonnenlicht", "tokens": ["Auf", "den", "Schif\u00b7fen", "blitzt'", "es", "und", "glei\u00dft'", "im", "Son\u00b7nen\u00b7licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "KON", "VVFIN", "APPRART", "NN"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Von blanken Stahlpanzern, die Speere starrten dicht", "tokens": ["Von", "blan\u00b7ken", "Stahl\u00b7pan\u00b7zern", ",", "die", "Spee\u00b7re", "starr\u00b7ten", "dicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie des Kornfelds \u00c4hren, wann man m\u00e4hen will;", "tokens": ["Wie", "des", "Korn\u00b7felds", "\u00c4h\u00b7ren", ",", "wann", "man", "m\u00e4\u00b7hen", "will", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Ins Auge sahn die Br\u00fcder sich leidvoll und still.", "tokens": ["Ins", "Au\u00b7ge", "sahn", "die", "Br\u00fc\u00b7der", "sich", "leid\u00b7voll", "und", "still", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "PRF", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Sie schritten nach dem S\u00f6ller. Da sa\u00df die holde Maid", "tokens": ["Sie", "schrit\u00b7ten", "nach", "dem", "S\u00f6l\u00b7ler", ".", "Da", "sa\u00df", "die", "hol\u00b7de", "Maid"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Alfsonn' im Goldgelocke; sie webte sich ein Kleid", "tokens": ["Alf\u00b7sonn'", "im", "Gold\u00b7ge\u00b7lo\u00b7cke", ";", "sie", "web\u00b7te", "sich", "ein", "Kleid"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "APPRART", "NN", "$.", "PPER", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Von schneewei\u00dfem Linnen am Webestuhl und sang,", "tokens": ["Von", "schnee\u00b7wei\u00b7\u00dfem", "Lin\u00b7nen", "am", "We\u00b7be\u00b7stuhl", "und", "sang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "KON", "VVFIN", "$,"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Dazu das Schifflein silbern hellklingend durch die F\u00e4den sprang.", "tokens": ["Da\u00b7zu", "das", "Schif\u00b7flein", "sil\u00b7bern", "hell\u00b7klin\u00b7gend", "durch", "die", "F\u00e4\u00b7den", "sprang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.10": {"line.1": {"text": "Da sie der Br\u00fcder wahrnahm, frug sie: \u00bbWas hat den Mut", "tokens": ["Da", "sie", "der", "Br\u00fc\u00b7der", "wahr\u00b7nahm", ",", "frug", "sie", ":", "\u00bb", "Was", "hat", "den", "Mut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "$.", "$(", "PWS", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Also euch verst\u00f6ret? Euch ist das lichte Blut", "tokens": ["Al\u00b7so", "euch", "ver\u00b7st\u00f6\u00b7ret", "?", "Euch", "ist", "das", "lich\u00b7te", "Blut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+----+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Gewichen aus den Wangen; der Grund ist nicht gering.\u00ab \u2013", "tokens": ["Ge\u00b7wi\u00b7chen", "aus", "den", "Wan\u00b7gen", ";", "der", "Grund", "ist", "nicht", "ge\u00b7ring", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$.", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbes r\u00fcckt\u00ab, sprach Alf Blondbart, \u00bbvor Alfheim Sigurd Ring.", "tokens": ["\u00bb", "es", "r\u00fcckt", "\u00ab", ",", "sprach", "Alf", "Blond\u00b7bart", ",", "\u00bb", "vor", "Alf\u00b7heim", "Si\u00b7gurd", "Ring", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$(", "$,", "VVFIN", "NE", "NE", "$,", "$(", "APPR", "NE", "NE", "NN", "$."], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}}, "stanza.11": {"line.1": {"text": "An zehntausend Klingen f\u00fchret er daher;", "tokens": ["An", "zehn\u00b7tau\u00b7send", "Klin\u00b7gen", "f\u00fch\u00b7ret", "er", "da\u00b7her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "PPER", "PAV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Zur Minne dich zu zwingen, das d\u00fcnkt uns sein Begehr.", "tokens": ["Zur", "Min\u00b7ne", "dich", "zu", "zwin\u00b7gen", ",", "das", "d\u00fcnkt", "uns", "sein", "Be\u00b7gehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PTKZU", "VVINF", "$,", "PDS", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wir k\u00f6nnen ihm nicht wehren, zu klein ist unsre Kraft.", "tokens": ["Wir", "k\u00f6n\u00b7nen", "ihm", "nicht", "weh\u00b7ren", ",", "zu", "klein", "ist", "uns\u00b7re", "Kraft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,", "PTKA", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wer sieht zu deinen Ehren, wenn uns die Feldschlacht hingerafft?\u00ab", "tokens": ["Wer", "sieht", "zu", "dei\u00b7nen", "Eh\u00b7ren", ",", "wenn", "uns", "die", "Feld\u00b7schlacht", "hin\u00b7ge\u00b7rafft", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.12": {"line.1": {"text": "Bleich ward Alfsonne, da sie das vernahm;", "tokens": ["Bleich", "ward", "Alf\u00b7son\u00b7ne", ",", "da", "sie", "das", "ver\u00b7nahm", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "NE", "$,", "KOUS", "PPER", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ihrer lichten Tr\u00e4nen hatte sie nicht Scham,", "tokens": ["Ih\u00b7rer", "lich\u00b7ten", "Tr\u00e4\u00b7nen", "hat\u00b7te", "sie", "nicht", "Scham", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PPER", "PTKNEG", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Die sprangen aus den Wimpern. Dann sprach sie: \u00bbBr\u00fcder mein,", "tokens": ["Die", "spran\u00b7gen", "aus", "den", "Wim\u00b7pern", ".", "Dann", "sprach", "sie", ":", "\u00bb", "Br\u00fc\u00b7der", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "$.", "ADV", "VVFIN", "PPER", "$.", "$(", "NN", "PPOSAT", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ich wei\u00df, was mir geziemet. Ruhig m\u00f6gt ihr sein.", "tokens": ["Ich", "wei\u00df", ",", "was", "mir", "ge\u00b7zie\u00b7met", ".", "Ru\u00b7hig", "m\u00f6gt", "ihr", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VVPP", "$.", "NE", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Alfs Tochter d\u00fcnkt es besser, zu frein den kalten Tod,", "tokens": ["Alfs", "Toch\u00b7ter", "d\u00fcnkt", "es", "bes\u00b7ser", ",", "zu", "frein", "den", "kal\u00b7ten", "Tod", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "PPER", "ADJD", "$,", "PTKA", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Denn in des K\u00f6nigs Bette zu legen sich aus Not", "tokens": ["Denn", "in", "des", "K\u00f6\u00b7nigs", "Bet\u00b7te", "zu", "le\u00b7gen", "sich", "aus", "Not"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NN", "PTKZU", "VVINF", "PRF", "APPR", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "An eines Greisen Seite. Auch hab' ich einen Trank,", "tokens": ["An", "ei\u00b7nes", "Grei\u00b7sen", "Sei\u00b7te", ".", "Auch", "hab'", "ich", "ei\u00b7nen", "Trank", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$.", "ADV", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Einen vielmilden, des wei\u00df ich heut den G\u00f6ttern Dank.", "tokens": ["Ei\u00b7nen", "viel\u00b7mil\u00b7den", ",", "des", "wei\u00df", "ich", "heut", "den", "G\u00f6t\u00b7tern", "Dank", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PDS", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}}, "stanza.14": {"line.1": {"text": "Der hilft mir diese Stunde. Doch seh' ich dort am Strand", "tokens": ["Der", "hilft", "mir", "die\u00b7se", "Stun\u00b7de", ".", "Doch", "seh'", "ich", "dort", "am", "Strand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PDAT", "NN", "$.", "KON", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Schon die Br\u00fcnnen leuchten und Helm und Schildesrand.", "tokens": ["Schon", "die", "Br\u00fcn\u00b7nen", "leuch\u00b7ten", "und", "Helm", "und", "Schil\u00b7des\u00b7rand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "KON", "NN", "KON", "NN", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mich d\u00fcnkt, mein Werk hat Eile, so wollt mich einsam lan,", "tokens": ["Mich", "d\u00fcnkt", ",", "mein", "Werk", "hat", "Ei\u00b7le", ",", "so", "wollt", "mich", "ein\u00b7sam", "lan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPOSAT", "NN", "VAFIN", "NN", "$,", "ADV", "VMFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da\u00df ich zur Fahrt mich r\u00fcste. Was not tut, das ist bald getan.\u00ab", "tokens": ["Da\u00df", "ich", "zur", "Fahrt", "mich", "r\u00fcs\u00b7te", ".", "Was", "not", "tut", ",", "das", "ist", "bald", "ge\u00b7tan", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PPER", "VVFIN", "$.", "PWS", "NN", "VVFIN", "$,", "PDS", "VAFIN", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+---+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.15": {"line.1": {"text": "Mit festen Schritten, schweigend schritt Alf aus der Hall';", "tokens": ["Mit", "fes\u00b7ten", "Schrit\u00b7ten", ",", "schwei\u00b7gend", "schritt", "Alf", "aus", "der", "Hall'", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJD", "VVFIN", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Auf die Augen k\u00fc\u00dfte sie Erek Harfenschall,", "tokens": ["Auf", "die", "Au\u00b7gen", "k\u00fc\u00df\u00b7te", "sie", "E\u00b7rek", "Har\u00b7fen\u00b7schall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "NE", "NE", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Da\u00df sie nicht s\u00e4h' sein Weinen. Dann lie\u00df er sie allein.", "tokens": ["Da\u00df", "sie", "nicht", "s\u00e4h'", "sein", "Wei\u00b7nen", ".", "Dann", "lie\u00df", "er", "sie", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Nicht zauderte die Jungfrau, sie ging an ihren Schrein;", "tokens": ["Nicht", "zau\u00b7der\u00b7te", "die", "Jung\u00b7frau", ",", "sie", "ging", "an", "ih\u00b7ren", "Schrein", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "Einen Becher g\u00fclden nahm sie aus der Haft,", "tokens": ["Ei\u00b7nen", "Be\u00b7cher", "g\u00fcl\u00b7den", "nahm", "sie", "aus", "der", "Haft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Dazu ein silbern Fl\u00e4schlein, darinnen war ein Saft", "tokens": ["Da\u00b7zu", "ein", "sil\u00b7bern", "Fl\u00e4\u00b7schlein", ",", "da\u00b7rin\u00b7nen", "war", "ein", "Saft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJA", "NN", "$,", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Von blutroter Farbe; den hatt' aus Zauberkraut", "tokens": ["Von", "blut\u00b7ro\u00b7ter", "Far\u00b7be", ";", "den", "hatt'", "aus", "Zau\u00b7ber\u00b7kraut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "ART", "VAFIN", "APPR", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "In der Nacht des Neumonds die Drude klug gebraut.", "tokens": ["In", "der", "Nacht", "des", "Neu\u00b7monds", "die", "Dru\u00b7de", "klug", "ge\u00b7braut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "+-+-++-+-+-+", "measure": "unknown.measure.septa"}}, "stanza.17": {"line.1": {"text": "Auf die Zinne trat sie; da lagen weit im Ring", "tokens": ["Auf", "die", "Zin\u00b7ne", "trat", "sie", ";", "da", "la\u00b7gen", "weit", "im", "Ring"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "$.", "ADV", "VVFIN", "ADJD", "APPRART", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Nordlands Meer und Berge, die Sonne niederging,", "tokens": ["Nord\u00b7lands", "Meer", "und", "Ber\u00b7ge", ",", "die", "Son\u00b7ne", "nie\u00b7der\u00b7ging", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Es glomm der letzte Schimmer um Wald und Felsenh\u00f6hn;", "tokens": ["Es", "glomm", "der", "letz\u00b7te", "Schim\u00b7mer", "um", "Wald", "und", "Fel\u00b7sen\u00b7h\u00f6hn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ihr war's, sie h\u00e4tte nimmer die Welt geschaut so sch\u00f6n.", "tokens": ["Ihr", "wa\u00b7r's", ",", "sie", "h\u00e4t\u00b7te", "nim\u00b7mer", "die", "Welt", "ge\u00b7schaut", "so", "sch\u00f6n", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VAFIN", "ADV", "ART", "NN", "VVPP", "ADV", "ADJD", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.18": {"line.1": {"text": "Sie sprach: \u00bbFahr wohl, o Sonne, du rosenroter Tag,", "tokens": ["Sie", "sprach", ":", "\u00bb", "Fahr", "wohl", ",", "o", "Son\u00b7ne", ",", "du", "ro\u00b7sen\u00b7ro\u00b7ter", "Tag", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "VVIMP", "ADV", "$,", "FM", "NN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Meiner Augen Wonne, fahr wohl, du Fr\u00fchlingshag!", "tokens": ["Mei\u00b7ner", "Au\u00b7gen", "Won\u00b7ne", ",", "fahr", "wohl", ",", "du", "Fr\u00fch\u00b7lings\u00b7hag", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,", "VVFIN", "ADV", "$,", "PPER", "NN", "$."], "meter": "+-+-+----+-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Ihr Br\u00fcnnlein an der Halde, die all mein Spiel gesehn,", "tokens": ["Ihr", "Br\u00fcnn\u00b7lein", "an", "der", "Hal\u00b7de", ",", "die", "all", "mein", "Spiel", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$,", "PRELS", "PIAT", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Fahrt wohl, ihr Veilchen im Walde! Ich soll euch nimmer pfl\u00fccken gehn.", "tokens": ["Fahrt", "wohl", ",", "ihr", "Veil\u00b7chen", "im", "Wal\u00b7de", "!", "Ich", "soll", "euch", "nim\u00b7mer", "pfl\u00fc\u00b7cken", "gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PPOSAT", "NN", "APPRART", "NN", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "VVINF", "$."], "meter": "+--+--+--+-+-+-+", "measure": "dactylic.tri.plus"}}, "stanza.19": {"line.1": {"text": "Nimmer soll ich h\u00f6ren der kleinen V\u00f6glein Scherz", "tokens": ["Nim\u00b7mer", "soll", "ich", "h\u00f6\u00b7ren", "der", "klei\u00b7nen", "V\u00f6\u00b7glein", "Scherz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "In lichten Maientagen; es soll auch nie mein Herz", "tokens": ["In", "lich\u00b7ten", "Mai\u00b7en\u00b7ta\u00b7gen", ";", "es", "soll", "auch", "nie", "mein", "Herz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "PPER", "VMFIN", "ADV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "S\u00fc\u00dfer Minne pflegen, und bin doch jung und rot.", "tokens": ["S\u00fc\u00b7\u00dfer", "Min\u00b7ne", "pfle\u00b7gen", ",", "und", "bin", "doch", "jung", "und", "rot", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,", "KON", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "O Sigurd Ring, was treibst du so fr\u00fch mich in den Tod?\u00ab", "tokens": ["O", "Si\u00b7gurd", "Ring", ",", "was", "treibst", "du", "so", "fr\u00fch", "mich", "in", "den", "Tod", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "NN", "$,", "PWS", "VVFIN", "PPER", "ADV", "ADJD", "PRF", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.20": {"line.1": {"text": "Den g\u00fcldnen Becher nahm sie und leert' ihn bis zum Grund,", "tokens": ["Den", "g\u00fcld\u00b7nen", "Be\u00b7cher", "nahm", "sie", "und", "leert'", "ihn", "bis", "zum", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da wurden ihr schwer die Wimpern; sie sank mit bleichem Mund", "tokens": ["Da", "wur\u00b7den", "ihr", "schwer", "die", "Wim\u00b7pern", ";", "sie", "sank", "mit", "blei\u00b7chem", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ART", "NN", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Auf den Steinboden; die Locken fielen dicht", "tokens": ["Auf", "den", "Stein\u00b7bo\u00b7den", ";", "die", "Lo\u00b7cken", "fie\u00b7len", "dicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "ART", "NN", "VVFIN", "ADJD"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Als wie ein g\u00fcldener Schleier \u00fcber ihr Angesicht.", "tokens": ["Als", "wie", "ein", "g\u00fcl\u00b7de\u00b7ner", "Schlei\u00b7er", "\u00fc\u00b7ber", "ihr", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.21": {"line.1": {"text": "Darnach ward eine Stille. Vergangen war der Tag", "tokens": ["Dar\u00b7nach", "ward", "ei\u00b7ne", "Stil\u00b7le", ".", "Ver\u00b7gan\u00b7gen", "war", "der", "Tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ART", "NN", "$.", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mit der lichten Sonne. Da kam ein Fl\u00fcgelschlag", "tokens": ["Mit", "der", "lich\u00b7ten", "Son\u00b7ne", ".", "Da", "kam", "ein", "Fl\u00fc\u00b7gel\u00b7schlag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "ADV", "VVFIN", "ART", "NN"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Aus den L\u00fcften nieder, das war ihr Falke gut,", "tokens": ["Aus", "den", "L\u00fcf\u00b7ten", "nie\u00b7der", ",", "das", "war", "ihr", "Fal\u00b7ke", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der kehrte jeden Abend in seiner Herrin Hut.", "tokens": ["Der", "kehr\u00b7te", "je\u00b7den", "A\u00b7bend", "in", "sei\u00b7ner", "Her\u00b7rin", "Hut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIAT", "NN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.22": {"line.1": {"text": "Da er Alfsonnen so stille liegen fand:", "tokens": ["Da", "er", "Alf\u00b7son\u00b7nen", "so", "stil\u00b7le", "lie\u00b7gen", "fand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "ADJA", "VVINF", "VVFIN", "$."], "meter": "---+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dreimal zog er kreisend um der Zinnen Rand,", "tokens": ["Drei\u00b7mal", "zog", "er", "krei\u00b7send", "um", "der", "Zin\u00b7nen", "Rand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Als wollt' er sie erwecken. Doch gl\u00fcckt' es ihm nicht.", "tokens": ["Als", "wollt'", "er", "sie", "er\u00b7we\u00b7cken", ".", "Doch", "gl\u00fcckt'", "es", "ihm", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "PPER", "VVINF", "$.", "KON", "VVFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Da flog er hochaufsteigend hinauf ins k\u00fchle Mondenlicht.", "tokens": ["Da", "flog", "er", "hoch\u00b7auf\u00b7stei\u00b7gend", "hin\u00b7auf", "ins", "k\u00fch\u00b7le", "Mon\u00b7den\u00b7licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.23": {"line.1": {"text": "J\u00fcnglings Zorn und Lieben ist Flamm' in Stroh und Dorn,", "tokens": ["J\u00fcng\u00b7lings", "Zorn", "und", "Lie\u00b7ben", "ist", "Flamm'", "in", "Stroh", "und", "Dorn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "ADJA", "VAFIN", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Doch wie gl\u00fchend Eisen ist Greises Lieb' und Zorn:", "tokens": ["Doch", "wie", "gl\u00fc\u00b7hend", "Ei\u00b7sen", "ist", "Grei\u00b7ses", "Lieb'", "und", "Zorn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJD", "NN", "VAFIN", "NE", "NN", "KON", "NN", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Das mu\u00dften bald erfahren die k\u00fchnen Br\u00fcder beid',", "tokens": ["Das", "mu\u00df\u00b7ten", "bald", "er\u00b7fah\u00b7ren", "die", "k\u00fch\u00b7nen", "Br\u00fc\u00b7der", "beid'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "VVINF", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Dazu Alfsonn' im Goldhaar zu \u00fcbergro\u00dfem Leid.", "tokens": ["Da\u00b7zu", "Alf\u00b7sonn'", "im", "Gold\u00b7haar", "zu", "\u00fc\u00b7ber\u00b7gro\u00b7\u00dfem", "Leid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NE", "APPRART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "--+--++-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.24": {"line.1": {"text": "Es war die Zeit gekommen, da im gr\u00fcnen Hag", "tokens": ["Es", "war", "die", "Zeit", "ge\u00b7kom\u00b7men", ",", "da", "im", "gr\u00fc\u00b7nen", "Hag"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$,", "KOUS", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man k\u00fchle Schatten suchet, und Nachtigallenschlag", "tokens": ["Man", "k\u00fch\u00b7le", "Schat\u00b7ten", "su\u00b7chet", ",", "und", "Nach\u00b7ti\u00b7gal\u00b7len\u00b7schlag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIS", "ADJA", "NN", "VVFIN", "$,", "KON", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "An den Br\u00fcnnlein schallet: da kam, den Sporn voll Blut,", "tokens": ["An", "den", "Br\u00fcnn\u00b7lein", "schal\u00b7let", ":", "da", "kam", ",", "den", "Sporn", "voll", "Blut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "$,", "ART", "NN", "ADJD", "NN", "$,"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ein Reiter gen Alfheim, des Kunde war nicht gut.", "tokens": ["Ein", "Rei\u00b7ter", "gen", "Alf\u00b7heim", ",", "des", "Kun\u00b7de", "war", "nicht", "gut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$,", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Er sprach: \u00bbEs hat entboten bei lautem H\u00f6rnerschall", "tokens": ["Er", "sprach", ":", "\u00bb", "Es", "hat", "ent\u00b7bo\u00b7ten", "bei", "lau\u00b7tem", "H\u00f6r\u00b7ner\u00b7schall"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VAFIN", "VVPP", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sigurd der Vielgrimme seine Degen all;", "tokens": ["Si\u00b7gurd", "der", "Viel\u00b7grim\u00b7me", "sei\u00b7ne", "De\u00b7gen", "all", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "PPOSAT", "NN", "PIAT", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mit Rossen und Streitwagen zieht er nun daher", "tokens": ["Mit", "Ros\u00b7sen", "und", "Streit\u00b7wa\u00b7gen", "zieht", "er", "nun", "da\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "ADV", "PAV"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Auf mehr denn hundert Schiffen. So viele trug noch nie das Meer.", "tokens": ["Auf", "mehr", "denn", "hun\u00b7dert", "Schif\u00b7fen", ".", "So", "vie\u00b7le", "trug", "noch", "nie", "das", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "CARD", "NN", "$.", "ADV", "PIS", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.26": {"line.1": {"text": "Auch hat er sich verschworen mit einem teuern Eid,", "tokens": ["Auch", "hat", "er", "sich", "ver\u00b7schwo\u00b7ren", "mit", "ei\u00b7nem", "teu\u00b7ern", "Eid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Nimmerdar von Alfheim zu kehren aus dem Streit,", "tokens": ["Nim\u00b7mer\u00b7dar", "von", "Alf\u00b7heim", "zu", "keh\u00b7ren", "aus", "dem", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Ohne mit Alfsonnen. Nun pfleget Rats geschwind!", "tokens": ["Oh\u00b7ne", "mit", "Alf\u00b7son\u00b7nen", ".", "Nun", "pfle\u00b7get", "Rats", "ge\u00b7schwind", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NN", "$.", "ADV", "VVFIN", "NN", "VVPP", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Der K\u00f6nig zaudert nimmer und f\u00e4hrt mit gutem Wind.\u00ab", "tokens": ["Der", "K\u00f6\u00b7nig", "zau\u00b7dert", "nim\u00b7mer", "und", "f\u00e4hrt", "mit", "gu\u00b7tem", "Wind", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KON", "VVFIN", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.27": {"line.1": {"text": "Da sprach der junge Erek: \u00bbDas geht an unsern Leib,", "tokens": ["Da", "sprach", "der", "jun\u00b7ge", "E\u00b7rek", ":", "\u00bb", "Das", "geht", "an", "un\u00b7sern", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "$(", "PDS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es sei denn, da\u00df die Schwester w\u00fcrde Sigurds Weib;", "tokens": ["Es", "sei", "denn", ",", "da\u00df", "die", "Schwes\u00b7ter", "w\u00fcr\u00b7de", "Si\u00b7gurds", "Weib", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "KOUS", "ART", "NN", "VAFIN", "NE", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch m\u00f6cht' ich des entraten. Es m\u00fc\u00dft' im Eis vergehn", "tokens": ["Doch", "m\u00f6cht'", "ich", "des", "ent\u00b7ra\u00b7ten", ".", "Es", "m\u00fc\u00dft'", "im", "Eis", "ver\u00b7gehn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ART", "ADJA", "$.", "PPER", "VMFIN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Traurig unser R\u00f6slein.\u00ab \u2013 \u00bbDas soll\u00ab, sprach Alf, \u00bbniemals geschehn.", "tokens": ["Trau\u00b7rig", "un\u00b7ser", "R\u00f6s\u00b7lein", ".", "\u00ab", "\u2013", "\u00bb", "Das", "soll", "\u00ab", ",", "sprach", "Alf", ",", "\u00bb", "nie\u00b7mals", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "$.", "$(", "$(", "$(", "PDS", "VMFIN", "$(", "$,", "VVFIN", "NE", "$,", "$(", "ADV", "VVPP", "$."], "meter": "+-+-+--+--+--+", "measure": "trochaic.hexa.relaxed"}}, "stanza.28": {"line.1": {"text": "Lieber will ich liegen auf der Heide breit", "tokens": ["Lie\u00b7ber", "will", "ich", "lie\u00b7gen", "auf", "der", "Hei\u00b7de", "breit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "ADJD"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Im blutgef\u00e4rbten Ginster, ja, lieber mag die Maid", "tokens": ["Im", "blut\u00b7ge\u00b7f\u00e4rb\u00b7ten", "Gins\u00b7ter", ",", "ja", ",", "lie\u00b7ber", "mag", "die", "Maid"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$,", "PTKANT", "$,", "ADV", "VMFIN", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ihr jungfrisches Leben veratmen in den Wind,", "tokens": ["Ihr", "jung\u00b7fri\u00b7sches", "Le\u00b7ben", "ver\u00b7at\u00b7men", "in", "den", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Eh' sie wird des Greisen, den ihr Herz nicht minnt.\u00ab", "tokens": ["Eh'", "sie", "wird", "des", "Grei\u00b7sen", ",", "den", "ihr", "Herz", "nicht", "minnt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "PTKNEG", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.29": {"line.1": {"text": "Am hohen Bogenfenster von ihren Sorgen schwer", "tokens": ["Am", "ho\u00b7hen", "Bo\u00b7gen\u00b7fens\u00b7ter", "von", "ih\u00b7ren", "Sor\u00b7gen", "schwer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Red'ten so die beiden; da sahn sie \u00fcbers Meer", "tokens": ["Re\u00b7d'\u00b7ten", "so", "die", "bei\u00b7den", ";", "da", "sahn", "sie", "\u00fc\u00b7bers", "Meer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "PIAT", "$.", "ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Viel wei\u00dfe Segel kommen wie mit Schwalbenflug;", "tokens": ["Viel", "wei\u00b7\u00dfe", "Se\u00b7gel", "kom\u00b7men", "wie", "mit", "Schwal\u00b7ben\u00b7flug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVINF", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das war die Sigurdsflotte, nicht enden wollte der Zug.", "tokens": ["Das", "war", "die", "Si\u00b7gurds\u00b7flot\u00b7te", ",", "nicht", "en\u00b7den", "woll\u00b7te", "der", "Zug", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PTKNEG", "VVINF", "VMFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.30": {"line.1": {"text": "Auf den Schiffen blitzt' es und glei\u00dft' im Sonnenlicht", "tokens": ["Auf", "den", "Schif\u00b7fen", "blitzt'", "es", "und", "glei\u00dft'", "im", "Son\u00b7nen\u00b7licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "KON", "VVFIN", "APPRART", "NN"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Von blanken Stahlpanzern, die Speere starrten dicht", "tokens": ["Von", "blan\u00b7ken", "Stahl\u00b7pan\u00b7zern", ",", "die", "Spee\u00b7re", "starr\u00b7ten", "dicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie des Kornfelds \u00c4hren, wann man m\u00e4hen will;", "tokens": ["Wie", "des", "Korn\u00b7felds", "\u00c4h\u00b7ren", ",", "wann", "man", "m\u00e4\u00b7hen", "will", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Ins Auge sahn die Br\u00fcder sich leidvoll und still.", "tokens": ["Ins", "Au\u00b7ge", "sahn", "die", "Br\u00fc\u00b7der", "sich", "leid\u00b7voll", "und", "still", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "PRF", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Sie schritten nach dem S\u00f6ller. Da sa\u00df die holde Maid", "tokens": ["Sie", "schrit\u00b7ten", "nach", "dem", "S\u00f6l\u00b7ler", ".", "Da", "sa\u00df", "die", "hol\u00b7de", "Maid"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Alfsonn' im Goldgelocke; sie webte sich ein Kleid", "tokens": ["Alf\u00b7sonn'", "im", "Gold\u00b7ge\u00b7lo\u00b7cke", ";", "sie", "web\u00b7te", "sich", "ein", "Kleid"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "APPRART", "NN", "$.", "PPER", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Von schneewei\u00dfem Linnen am Webestuhl und sang,", "tokens": ["Von", "schnee\u00b7wei\u00b7\u00dfem", "Lin\u00b7nen", "am", "We\u00b7be\u00b7stuhl", "und", "sang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "KON", "VVFIN", "$,"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Dazu das Schifflein silbern hellklingend durch die F\u00e4den sprang.", "tokens": ["Da\u00b7zu", "das", "Schif\u00b7flein", "sil\u00b7bern", "hell\u00b7klin\u00b7gend", "durch", "die", "F\u00e4\u00b7den", "sprang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.32": {"line.1": {"text": "Da sie der Br\u00fcder wahrnahm, frug sie: \u00bbWas hat den Mut", "tokens": ["Da", "sie", "der", "Br\u00fc\u00b7der", "wahr\u00b7nahm", ",", "frug", "sie", ":", "\u00bb", "Was", "hat", "den", "Mut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "$.", "$(", "PWS", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Also euch verst\u00f6ret? Euch ist das lichte Blut", "tokens": ["Al\u00b7so", "euch", "ver\u00b7st\u00f6\u00b7ret", "?", "Euch", "ist", "das", "lich\u00b7te", "Blut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+----+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Gewichen aus den Wangen; der Grund ist nicht gering.\u00ab \u2013", "tokens": ["Ge\u00b7wi\u00b7chen", "aus", "den", "Wan\u00b7gen", ";", "der", "Grund", "ist", "nicht", "ge\u00b7ring", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$.", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbes r\u00fcckt\u00ab, sprach Alf Blondbart, \u00bbvor Alfheim Sigurd Ring.", "tokens": ["\u00bb", "es", "r\u00fcckt", "\u00ab", ",", "sprach", "Alf", "Blond\u00b7bart", ",", "\u00bb", "vor", "Alf\u00b7heim", "Si\u00b7gurd", "Ring", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$(", "$,", "VVFIN", "NE", "NE", "$,", "$(", "APPR", "NE", "NE", "NN", "$."], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}}, "stanza.33": {"line.1": {"text": "An zehntausend Klingen f\u00fchret er daher;", "tokens": ["An", "zehn\u00b7tau\u00b7send", "Klin\u00b7gen", "f\u00fch\u00b7ret", "er", "da\u00b7her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "PPER", "PAV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Zur Minne dich zu zwingen, das d\u00fcnkt uns sein Begehr.", "tokens": ["Zur", "Min\u00b7ne", "dich", "zu", "zwin\u00b7gen", ",", "das", "d\u00fcnkt", "uns", "sein", "Be\u00b7gehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PTKZU", "VVINF", "$,", "PDS", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wir k\u00f6nnen ihm nicht wehren, zu klein ist unsre Kraft.", "tokens": ["Wir", "k\u00f6n\u00b7nen", "ihm", "nicht", "weh\u00b7ren", ",", "zu", "klein", "ist", "uns\u00b7re", "Kraft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,", "PTKA", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wer sieht zu deinen Ehren, wenn uns die Feldschlacht hingerafft?\u00ab", "tokens": ["Wer", "sieht", "zu", "dei\u00b7nen", "Eh\u00b7ren", ",", "wenn", "uns", "die", "Feld\u00b7schlacht", "hin\u00b7ge\u00b7rafft", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.34": {"line.1": {"text": "Bleich ward Alfsonne, da sie das vernahm;", "tokens": ["Bleich", "ward", "Alf\u00b7son\u00b7ne", ",", "da", "sie", "das", "ver\u00b7nahm", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "NE", "$,", "KOUS", "PPER", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ihrer lichten Tr\u00e4nen hatte sie nicht Scham,", "tokens": ["Ih\u00b7rer", "lich\u00b7ten", "Tr\u00e4\u00b7nen", "hat\u00b7te", "sie", "nicht", "Scham", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PPER", "PTKNEG", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Die sprangen aus den Wimpern. Dann sprach sie: \u00bbBr\u00fcder mein,", "tokens": ["Die", "spran\u00b7gen", "aus", "den", "Wim\u00b7pern", ".", "Dann", "sprach", "sie", ":", "\u00bb", "Br\u00fc\u00b7der", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "$.", "ADV", "VVFIN", "PPER", "$.", "$(", "NN", "PPOSAT", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ich wei\u00df, was mir geziemet. Ruhig m\u00f6gt ihr sein.", "tokens": ["Ich", "wei\u00df", ",", "was", "mir", "ge\u00b7zie\u00b7met", ".", "Ru\u00b7hig", "m\u00f6gt", "ihr", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VVPP", "$.", "NE", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Alfs Tochter d\u00fcnkt es besser, zu frein den kalten Tod,", "tokens": ["Alfs", "Toch\u00b7ter", "d\u00fcnkt", "es", "bes\u00b7ser", ",", "zu", "frein", "den", "kal\u00b7ten", "Tod", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "PPER", "ADJD", "$,", "PTKA", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Denn in des K\u00f6nigs Bette zu legen sich aus Not", "tokens": ["Denn", "in", "des", "K\u00f6\u00b7nigs", "Bet\u00b7te", "zu", "le\u00b7gen", "sich", "aus", "Not"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NN", "PTKZU", "VVINF", "PRF", "APPR", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "An eines Greisen Seite. Auch hab' ich einen Trank,", "tokens": ["An", "ei\u00b7nes", "Grei\u00b7sen", "Sei\u00b7te", ".", "Auch", "hab'", "ich", "ei\u00b7nen", "Trank", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$.", "ADV", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Einen vielmilden, des wei\u00df ich heut den G\u00f6ttern Dank.", "tokens": ["Ei\u00b7nen", "viel\u00b7mil\u00b7den", ",", "des", "wei\u00df", "ich", "heut", "den", "G\u00f6t\u00b7tern", "Dank", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PDS", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}}, "stanza.36": {"line.1": {"text": "Der hilft mir diese Stunde. Doch seh' ich dort am Strand", "tokens": ["Der", "hilft", "mir", "die\u00b7se", "Stun\u00b7de", ".", "Doch", "seh'", "ich", "dort", "am", "Strand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PDAT", "NN", "$.", "KON", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Schon die Br\u00fcnnen leuchten und Helm und Schildesrand.", "tokens": ["Schon", "die", "Br\u00fcn\u00b7nen", "leuch\u00b7ten", "und", "Helm", "und", "Schil\u00b7des\u00b7rand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "KON", "NN", "KON", "NN", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mich d\u00fcnkt, mein Werk hat Eile, so wollt mich einsam lan,", "tokens": ["Mich", "d\u00fcnkt", ",", "mein", "Werk", "hat", "Ei\u00b7le", ",", "so", "wollt", "mich", "ein\u00b7sam", "lan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPOSAT", "NN", "VAFIN", "NN", "$,", "ADV", "VMFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da\u00df ich zur Fahrt mich r\u00fcste. Was not tut, das ist bald getan.\u00ab", "tokens": ["Da\u00df", "ich", "zur", "Fahrt", "mich", "r\u00fcs\u00b7te", ".", "Was", "not", "tut", ",", "das", "ist", "bald", "ge\u00b7tan", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PPER", "VVFIN", "$.", "PWS", "NN", "VVFIN", "$,", "PDS", "VAFIN", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+---+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.37": {"line.1": {"text": "Mit festen Schritten, schweigend schritt Alf aus der Hall';", "tokens": ["Mit", "fes\u00b7ten", "Schrit\u00b7ten", ",", "schwei\u00b7gend", "schritt", "Alf", "aus", "der", "Hall'", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJD", "VVFIN", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Auf die Augen k\u00fc\u00dfte sie Erek Harfenschall,", "tokens": ["Auf", "die", "Au\u00b7gen", "k\u00fc\u00df\u00b7te", "sie", "E\u00b7rek", "Har\u00b7fen\u00b7schall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "NE", "NE", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Da\u00df sie nicht s\u00e4h' sein Weinen. Dann lie\u00df er sie allein.", "tokens": ["Da\u00df", "sie", "nicht", "s\u00e4h'", "sein", "Wei\u00b7nen", ".", "Dann", "lie\u00df", "er", "sie", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Nicht zauderte die Jungfrau, sie ging an ihren Schrein;", "tokens": ["Nicht", "zau\u00b7der\u00b7te", "die", "Jung\u00b7frau", ",", "sie", "ging", "an", "ih\u00b7ren", "Schrein", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.38": {"line.1": {"text": "Einen Becher g\u00fclden nahm sie aus der Haft,", "tokens": ["Ei\u00b7nen", "Be\u00b7cher", "g\u00fcl\u00b7den", "nahm", "sie", "aus", "der", "Haft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Dazu ein silbern Fl\u00e4schlein, darinnen war ein Saft", "tokens": ["Da\u00b7zu", "ein", "sil\u00b7bern", "Fl\u00e4\u00b7schlein", ",", "da\u00b7rin\u00b7nen", "war", "ein", "Saft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJA", "NN", "$,", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Von blutroter Farbe; den hatt' aus Zauberkraut", "tokens": ["Von", "blut\u00b7ro\u00b7ter", "Far\u00b7be", ";", "den", "hatt'", "aus", "Zau\u00b7ber\u00b7kraut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "ART", "VAFIN", "APPR", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "In der Nacht des Neumonds die Drude klug gebraut.", "tokens": ["In", "der", "Nacht", "des", "Neu\u00b7monds", "die", "Dru\u00b7de", "klug", "ge\u00b7braut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "+-+-++-+-+-+", "measure": "unknown.measure.septa"}}, "stanza.39": {"line.1": {"text": "Auf die Zinne trat sie; da lagen weit im Ring", "tokens": ["Auf", "die", "Zin\u00b7ne", "trat", "sie", ";", "da", "la\u00b7gen", "weit", "im", "Ring"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "$.", "ADV", "VVFIN", "ADJD", "APPRART", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Nordlands Meer und Berge, die Sonne niederging,", "tokens": ["Nord\u00b7lands", "Meer", "und", "Ber\u00b7ge", ",", "die", "Son\u00b7ne", "nie\u00b7der\u00b7ging", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Es glomm der letzte Schimmer um Wald und Felsenh\u00f6hn;", "tokens": ["Es", "glomm", "der", "letz\u00b7te", "Schim\u00b7mer", "um", "Wald", "und", "Fel\u00b7sen\u00b7h\u00f6hn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ihr war's, sie h\u00e4tte nimmer die Welt geschaut so sch\u00f6n.", "tokens": ["Ihr", "wa\u00b7r's", ",", "sie", "h\u00e4t\u00b7te", "nim\u00b7mer", "die", "Welt", "ge\u00b7schaut", "so", "sch\u00f6n", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VAFIN", "ADV", "ART", "NN", "VVPP", "ADV", "ADJD", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.40": {"line.1": {"text": "Sie sprach: \u00bbFahr wohl, o Sonne, du rosenroter Tag,", "tokens": ["Sie", "sprach", ":", "\u00bb", "Fahr", "wohl", ",", "o", "Son\u00b7ne", ",", "du", "ro\u00b7sen\u00b7ro\u00b7ter", "Tag", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "VVIMP", "ADV", "$,", "FM", "NN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Meiner Augen Wonne, fahr wohl, du Fr\u00fchlingshag!", "tokens": ["Mei\u00b7ner", "Au\u00b7gen", "Won\u00b7ne", ",", "fahr", "wohl", ",", "du", "Fr\u00fch\u00b7lings\u00b7hag", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,", "VVFIN", "ADV", "$,", "PPER", "NN", "$."], "meter": "+-+-+----+-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Ihr Br\u00fcnnlein an der Halde, die all mein Spiel gesehn,", "tokens": ["Ihr", "Br\u00fcnn\u00b7lein", "an", "der", "Hal\u00b7de", ",", "die", "all", "mein", "Spiel", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$,", "PRELS", "PIAT", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Fahrt wohl, ihr Veilchen im Walde! Ich soll euch nimmer pfl\u00fccken gehn.", "tokens": ["Fahrt", "wohl", ",", "ihr", "Veil\u00b7chen", "im", "Wal\u00b7de", "!", "Ich", "soll", "euch", "nim\u00b7mer", "pfl\u00fc\u00b7cken", "gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PPOSAT", "NN", "APPRART", "NN", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "VVINF", "$."], "meter": "+--+--+--+-+-+-+", "measure": "dactylic.tri.plus"}}, "stanza.41": {"line.1": {"text": "Nimmer soll ich h\u00f6ren der kleinen V\u00f6glein Scherz", "tokens": ["Nim\u00b7mer", "soll", "ich", "h\u00f6\u00b7ren", "der", "klei\u00b7nen", "V\u00f6\u00b7glein", "Scherz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "In lichten Maientagen; es soll auch nie mein Herz", "tokens": ["In", "lich\u00b7ten", "Mai\u00b7en\u00b7ta\u00b7gen", ";", "es", "soll", "auch", "nie", "mein", "Herz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "PPER", "VMFIN", "ADV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "S\u00fc\u00dfer Minne pflegen, und bin doch jung und rot.", "tokens": ["S\u00fc\u00b7\u00dfer", "Min\u00b7ne", "pfle\u00b7gen", ",", "und", "bin", "doch", "jung", "und", "rot", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,", "KON", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "O Sigurd Ring, was treibst du so fr\u00fch mich in den Tod?\u00ab", "tokens": ["O", "Si\u00b7gurd", "Ring", ",", "was", "treibst", "du", "so", "fr\u00fch", "mich", "in", "den", "Tod", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "NN", "$,", "PWS", "VVFIN", "PPER", "ADV", "ADJD", "PRF", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.42": {"line.1": {"text": "Den g\u00fcldnen Becher nahm sie und leert' ihn bis zum Grund,", "tokens": ["Den", "g\u00fcld\u00b7nen", "Be\u00b7cher", "nahm", "sie", "und", "leert'", "ihn", "bis", "zum", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da wurden ihr schwer die Wimpern; sie sank mit bleichem Mund", "tokens": ["Da", "wur\u00b7den", "ihr", "schwer", "die", "Wim\u00b7pern", ";", "sie", "sank", "mit", "blei\u00b7chem", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ART", "NN", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Auf den Steinboden; die Locken fielen dicht", "tokens": ["Auf", "den", "Stein\u00b7bo\u00b7den", ";", "die", "Lo\u00b7cken", "fie\u00b7len", "dicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "ART", "NN", "VVFIN", "ADJD"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Als wie ein g\u00fcldener Schleier \u00fcber ihr Angesicht.", "tokens": ["Als", "wie", "ein", "g\u00fcl\u00b7de\u00b7ner", "Schlei\u00b7er", "\u00fc\u00b7ber", "ihr", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.43": {"line.1": {"text": "Darnach ward eine Stille. Vergangen war der Tag", "tokens": ["Dar\u00b7nach", "ward", "ei\u00b7ne", "Stil\u00b7le", ".", "Ver\u00b7gan\u00b7gen", "war", "der", "Tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ART", "NN", "$.", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mit der lichten Sonne. Da kam ein Fl\u00fcgelschlag", "tokens": ["Mit", "der", "lich\u00b7ten", "Son\u00b7ne", ".", "Da", "kam", "ein", "Fl\u00fc\u00b7gel\u00b7schlag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "ADV", "VVFIN", "ART", "NN"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Aus den L\u00fcften nieder, das war ihr Falke gut,", "tokens": ["Aus", "den", "L\u00fcf\u00b7ten", "nie\u00b7der", ",", "das", "war", "ihr", "Fal\u00b7ke", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der kehrte jeden Abend in seiner Herrin Hut.", "tokens": ["Der", "kehr\u00b7te", "je\u00b7den", "A\u00b7bend", "in", "sei\u00b7ner", "Her\u00b7rin", "Hut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIAT", "NN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.44": {"line.1": {"text": "Da er Alfsonnen so stille liegen fand:", "tokens": ["Da", "er", "Alf\u00b7son\u00b7nen", "so", "stil\u00b7le", "lie\u00b7gen", "fand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "ADJA", "VVINF", "VVFIN", "$."], "meter": "---+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dreimal zog er kreisend um der Zinnen Rand,", "tokens": ["Drei\u00b7mal", "zog", "er", "krei\u00b7send", "um", "der", "Zin\u00b7nen", "Rand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Als wollt' er sie erwecken. Doch gl\u00fcckt' es ihm nicht.", "tokens": ["Als", "wollt'", "er", "sie", "er\u00b7we\u00b7cken", ".", "Doch", "gl\u00fcckt'", "es", "ihm", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "PPER", "VVINF", "$.", "KON", "VVFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Da flog er hochaufsteigend hinauf ins k\u00fchle Mondenlicht.", "tokens": ["Da", "flog", "er", "hoch\u00b7auf\u00b7stei\u00b7gend", "hin\u00b7auf", "ins", "k\u00fch\u00b7le", "Mon\u00b7den\u00b7licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}}}}}