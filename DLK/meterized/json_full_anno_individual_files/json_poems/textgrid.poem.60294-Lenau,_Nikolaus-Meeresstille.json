{"textgrid.poem.60294": {"metadata": {"author": {"name": "Lenau, Nikolaus", "birth": "N.A.", "death": "N.A."}, "title": "Meeresstille", "genre": "verse", "period": "N.A.", "pub_year": 1832, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Stille! \u2013 jedes L\u00fcftchen schweiget,", "tokens": ["Stil\u00b7le", "!", "\u2013", "je\u00b7des", "L\u00fcft\u00b7chen", "schwei\u00b7get", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jede Welle sank in Ruh,", "tokens": ["Je\u00b7de", "Wel\u00b7le", "sank", "in", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die matte Sonne neiget", "tokens": ["Und", "die", "mat\u00b7te", "Son\u00b7ne", "nei\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich dem Untergange zu.", "tokens": ["Sich", "dem", "Un\u00b7ter\u00b7gan\u00b7ge", "zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ob die Wolke ihn bel\u00fcde", "tokens": ["Ob", "die", "Wol\u00b7ke", "ihn", "be\u00b7l\u00fc\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Allzutr\u00fcbe, allzuschwer,", "tokens": ["All\u00b7zu\u00b7tr\u00fc\u00b7be", ",", "all\u00b7zu\u00b7schwer", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Leget sich der Himmel, m\u00fcde,", "tokens": ["Le\u00b7get", "sich", "der", "Him\u00b7mel", ",", "m\u00fc\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$,", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nieder auf das weiche Meer.", "tokens": ["Nie\u00b7der", "auf", "das", "wei\u00b7che", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Und vergessend seiner Bahnen,", "tokens": ["Und", "ver\u00b7ges\u00b7send", "sei\u00b7ner", "Bah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seines Zieles, noch so weit!", "tokens": ["Sei\u00b7nes", "Zie\u00b7les", ",", "noch", "so", "weit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ruht das Schiff mit schlaffen Fahnen", "tokens": ["Ruht", "das", "Schiff", "mit", "schlaf\u00b7fen", "Fah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In der tiefen Einsamkeit.", "tokens": ["In", "der", "tie\u00b7fen", "Ein\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Da\u00df den Weg ein Vogel n\u00e4hme,", "tokens": ["Da\u00df", "den", "Weg", "ein", "Vo\u00b7gel", "n\u00e4h\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meinem Aug ein holder Fund!", "tokens": ["Mei\u00b7nem", "Aug", "ein", "hol\u00b7der", "Fund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df doch nur ein Fischlein k\u00e4me,", "tokens": ["Da\u00df", "doch", "nur", "ein", "Fisc\u00b7hlein", "k\u00e4\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fr\u00f6hlich tauchend aus dem Grund!", "tokens": ["Fr\u00f6h\u00b7lich", "tau\u00b7chend", "aus", "dem", "Grund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Doch kein Fisch, der sich erh\u00fcbe,", "tokens": ["Doch", "kein", "Fisch", ",", "der", "sich", "er\u00b7h\u00fc\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und kein Vogel kommen will.", "tokens": ["Und", "kein", "Vo\u00b7gel", "kom\u00b7men", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist es unten auch so tr\u00fcbe?", "tokens": ["Ist", "es", "un\u00b7ten", "auch", "so", "tr\u00fc\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist es unten auch so still? \u2013", "tokens": ["Ist", "es", "un\u00b7ten", "auch", "so", "still", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wie mich oft in gr\u00fcnen Hainen", "tokens": ["Wie", "mich", "oft", "in", "gr\u00fc\u00b7nen", "Hai\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00dcberrascht' ein dunkles Weh,", "tokens": ["\u00dc\u00b7ber\u00b7rascht'", "ein", "dunk\u00b7les", "Weh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mu\u00df ich nun auch pl\u00f6tzlich weinen,", "tokens": ["Mu\u00df", "ich", "nun", "auch", "pl\u00f6tz\u00b7lich", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00df nicht wie? \u2013 hier auf der See.", "tokens": ["Wei\u00df", "nicht", "wie", "?", "\u2013", "hier", "auf", "der", "See", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PWAV", "$.", "$(", "ADV", "APPR", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.7": {"line.1": {"text": "Tr\u00e4gt Natur auf allen Wegen", "tokens": ["Tr\u00e4gt", "Na\u00b7tur", "auf", "al\u00b7len", "We\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einen gro\u00dfen, ewgen Schmerz,", "tokens": ["Ei\u00b7nen", "gro\u00b7\u00dfen", ",", "ew\u00b7gen", "Schmerz", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Den sie mir als Muttersegen", "tokens": ["Den", "sie", "mir", "als", "Mut\u00b7ter\u00b7se\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PPER", "KOUS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Heimlich str\u00f6met in das Herz?", "tokens": ["Heim\u00b7lich", "str\u00f6\u00b7met", "in", "das", "Herz", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "O, dann ist es keine L\u00fcge,", "tokens": ["O", ",", "dann", "ist", "es", "kei\u00b7ne", "L\u00fc\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df im Scho\u00df der Wellennacht", "tokens": ["Da\u00df", "im", "Scho\u00df", "der", "Wel\u00b7len\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In verborgener Gen\u00fcge", "tokens": ["In", "ver\u00b7bor\u00b7ge\u00b7ner", "Ge\u00b7n\u00fc\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Ein Geschlecht von Menschen wacht.", "tokens": ["Ein", "Ge\u00b7schlecht", "von", "Men\u00b7schen", "wacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Dort auch darf der Freund nicht fehlen,", "tokens": ["Dort", "auch", "darf", "der", "Freund", "nicht", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie im hellen Sonnentag,", "tokens": ["Wie", "im", "hel\u00b7len", "Son\u00b7nen\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dem Natur ihr Leid erz\u00e4hlen,", "tokens": ["Dem", "Na\u00b7tur", "ihr", "Leid", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der mit ihr empfinden mag.", "tokens": ["Der", "mit", "ihr", "emp\u00b7fin\u00b7den", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["ART", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Doch geheim ist seine Stelle", "tokens": ["Doch", "ge\u00b7heim", "ist", "sei\u00b7ne", "Stel\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und Geheimnis, was er f\u00fchlt,", "tokens": ["Und", "Ge\u00b7heim\u00b7nis", ",", "was", "er", "f\u00fchlt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dem die Tr\u00e4nen an der Quelle", "tokens": ["Dem", "die", "Tr\u00e4\u00b7nen", "an", "der", "Quel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schon das Meer von dannen sp\u00fclt.", "tokens": ["Schon", "das", "Meer", "von", "dan\u00b7nen", "sp\u00fclt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Stille! \u2013 jedes L\u00fcftchen schweiget,", "tokens": ["Stil\u00b7le", "!", "\u2013", "je\u00b7des", "L\u00fcft\u00b7chen", "schwei\u00b7get", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jede Welle sank in Ruh,", "tokens": ["Je\u00b7de", "Wel\u00b7le", "sank", "in", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die matte Sonne neiget", "tokens": ["Und", "die", "mat\u00b7te", "Son\u00b7ne", "nei\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich dem Untergange zu.", "tokens": ["Sich", "dem", "Un\u00b7ter\u00b7gan\u00b7ge", "zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Ob die Wolke ihn bel\u00fcde", "tokens": ["Ob", "die", "Wol\u00b7ke", "ihn", "be\u00b7l\u00fc\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Allzutr\u00fcbe, allzuschwer,", "tokens": ["All\u00b7zu\u00b7tr\u00fc\u00b7be", ",", "all\u00b7zu\u00b7schwer", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Leget sich der Himmel, m\u00fcde,", "tokens": ["Le\u00b7get", "sich", "der", "Him\u00b7mel", ",", "m\u00fc\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$,", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nieder auf das weiche Meer.", "tokens": ["Nie\u00b7der", "auf", "das", "wei\u00b7che", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Und vergessend seiner Bahnen,", "tokens": ["Und", "ver\u00b7ges\u00b7send", "sei\u00b7ner", "Bah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seines Zieles, noch so weit!", "tokens": ["Sei\u00b7nes", "Zie\u00b7les", ",", "noch", "so", "weit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ruht das Schiff mit schlaffen Fahnen", "tokens": ["Ruht", "das", "Schiff", "mit", "schlaf\u00b7fen", "Fah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In der tiefen Einsamkeit.", "tokens": ["In", "der", "tie\u00b7fen", "Ein\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Da\u00df den Weg ein Vogel n\u00e4hme,", "tokens": ["Da\u00df", "den", "Weg", "ein", "Vo\u00b7gel", "n\u00e4h\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meinem Aug ein holder Fund!", "tokens": ["Mei\u00b7nem", "Aug", "ein", "hol\u00b7der", "Fund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df doch nur ein Fischlein k\u00e4me,", "tokens": ["Da\u00df", "doch", "nur", "ein", "Fisc\u00b7hlein", "k\u00e4\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fr\u00f6hlich tauchend aus dem Grund!", "tokens": ["Fr\u00f6h\u00b7lich", "tau\u00b7chend", "aus", "dem", "Grund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Doch kein Fisch, der sich erh\u00fcbe,", "tokens": ["Doch", "kein", "Fisch", ",", "der", "sich", "er\u00b7h\u00fc\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und kein Vogel kommen will.", "tokens": ["Und", "kein", "Vo\u00b7gel", "kom\u00b7men", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist es unten auch so tr\u00fcbe?", "tokens": ["Ist", "es", "un\u00b7ten", "auch", "so", "tr\u00fc\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist es unten auch so still? \u2013", "tokens": ["Ist", "es", "un\u00b7ten", "auch", "so", "still", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Wie mich oft in gr\u00fcnen Hainen", "tokens": ["Wie", "mich", "oft", "in", "gr\u00fc\u00b7nen", "Hai\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00dcberrascht' ein dunkles Weh,", "tokens": ["\u00dc\u00b7ber\u00b7rascht'", "ein", "dunk\u00b7les", "Weh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mu\u00df ich nun auch pl\u00f6tzlich weinen,", "tokens": ["Mu\u00df", "ich", "nun", "auch", "pl\u00f6tz\u00b7lich", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00df nicht wie? \u2013 hier auf der See.", "tokens": ["Wei\u00df", "nicht", "wie", "?", "\u2013", "hier", "auf", "der", "See", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PWAV", "$.", "$(", "ADV", "APPR", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.17": {"line.1": {"text": "Tr\u00e4gt Natur auf allen Wegen", "tokens": ["Tr\u00e4gt", "Na\u00b7tur", "auf", "al\u00b7len", "We\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einen gro\u00dfen, ewgen Schmerz,", "tokens": ["Ei\u00b7nen", "gro\u00b7\u00dfen", ",", "ew\u00b7gen", "Schmerz", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Den sie mir als Muttersegen", "tokens": ["Den", "sie", "mir", "als", "Mut\u00b7ter\u00b7se\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PPER", "KOUS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Heimlich str\u00f6met in das Herz?", "tokens": ["Heim\u00b7lich", "str\u00f6\u00b7met", "in", "das", "Herz", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "O, dann ist es keine L\u00fcge,", "tokens": ["O", ",", "dann", "ist", "es", "kei\u00b7ne", "L\u00fc\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df im Scho\u00df der Wellennacht", "tokens": ["Da\u00df", "im", "Scho\u00df", "der", "Wel\u00b7len\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In verborgener Gen\u00fcge", "tokens": ["In", "ver\u00b7bor\u00b7ge\u00b7ner", "Ge\u00b7n\u00fc\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Ein Geschlecht von Menschen wacht.", "tokens": ["Ein", "Ge\u00b7schlecht", "von", "Men\u00b7schen", "wacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Dort auch darf der Freund nicht fehlen,", "tokens": ["Dort", "auch", "darf", "der", "Freund", "nicht", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie im hellen Sonnentag,", "tokens": ["Wie", "im", "hel\u00b7len", "Son\u00b7nen\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dem Natur ihr Leid erz\u00e4hlen,", "tokens": ["Dem", "Na\u00b7tur", "ihr", "Leid", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der mit ihr empfinden mag.", "tokens": ["Der", "mit", "ihr", "emp\u00b7fin\u00b7den", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["ART", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Doch geheim ist seine Stelle", "tokens": ["Doch", "ge\u00b7heim", "ist", "sei\u00b7ne", "Stel\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und Geheimnis, was er f\u00fchlt,", "tokens": ["Und", "Ge\u00b7heim\u00b7nis", ",", "was", "er", "f\u00fchlt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dem die Tr\u00e4nen an der Quelle", "tokens": ["Dem", "die", "Tr\u00e4\u00b7nen", "an", "der", "Quel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schon das Meer von dannen sp\u00fclt.", "tokens": ["Schon", "das", "Meer", "von", "dan\u00b7nen", "sp\u00fclt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}