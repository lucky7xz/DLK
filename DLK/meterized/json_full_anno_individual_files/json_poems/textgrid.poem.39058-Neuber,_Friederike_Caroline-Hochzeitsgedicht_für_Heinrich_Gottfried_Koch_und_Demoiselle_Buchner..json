{"textgrid.poem.39058": {"metadata": {"author": {"name": "Neuber, Friederike Caroline", "birth": "N.A.", "death": "N.A."}, "title": "Hochzeitsgedicht f\u00fcr Heinrich Gottfried Koch und Demoiselle Buchner.", "genre": "verse", "period": "N.A.", "pub_year": 1728, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Gesellschafft zu verehren,", "tokens": ["Die", "Ge\u00b7sell\u00b7schafft", "zu", "ver\u00b7eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4st sich meine Muse h\u00f6ren;", "tokens": ["L\u00e4st", "sich", "mei\u00b7ne", "Mu\u00b7se", "h\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die sonst schlecht und heischer singt,", "tokens": ["Die", "sonst", "schlecht", "und", "hei\u00b7scher", "singt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und nicht viel zusammen bringt,", "tokens": ["Und", "nicht", "viel", "zu\u00b7sam\u00b7men", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch ich will es immer wagen,", "tokens": ["Doch", "ich", "will", "es", "im\u00b7mer", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und getrost die Meynung sagen.", "tokens": ["Und", "ge\u00b7trost", "die", "Mey\u00b7nung", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Braut und Br\u00e4utgam ehr ich schweigend!", "tokens": ["Braut", "und", "Br\u00e4ut\u00b7gam", "ehr", "ich", "schwei\u00b7gend", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "NN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Denn mein Flei\u00df ist \u00fcberzeugend:", "tokens": ["Denn", "mein", "Flei\u00df", "ist", "\u00fc\u00b7berz\u00b7eu\u00b7gend", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ihr Gl\u00fcck auch mich erfreut.", "tokens": ["Da\u00df", "ihr", "Gl\u00fcck", "auch", "mich", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich thu ihnen nichts zu leyd,", "tokens": ["Ich", "thu", "ih\u00b7nen", "nichts", "zu", "leyd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und sie werden nichts ver\u00fcben", "tokens": ["Und", "sie", "wer\u00b7den", "nichts", "ver\u00b7\u00fc\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das mich k\u00fcnftig k\u00f6nt betr\u00fcben.", "tokens": ["Das", "mich", "k\u00fcnf\u00b7tig", "k\u00f6nt", "be\u00b7tr\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADJD", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Hochzeitreime hinzuschreiben", "tokens": ["Hoch\u00b7zei\u00b7trei\u00b7me", "hin\u00b7zu\u00b7schrei\u00b7ben"], "token_info": ["word", "word"], "pos": ["NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und dabey im Schranken bleiben", "tokens": ["Und", "da\u00b7bey", "im", "Schran\u00b7ken", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "APPRART", "NN", "VVINF"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Ist ein schweres Werk vor mich.", "tokens": ["Ist", "ein", "schwe\u00b7res", "Werk", "vor", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Darum wollen du und ich,", "tokens": ["Da\u00b7rum", "wol\u00b7len", "du", "und", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "KON", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Lieber Leser! darauf denken,", "tokens": ["Lie\u00b7ber", "Le\u00b7ser", "!", "da\u00b7rauf", "den\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "NN", "$.", "PAV", "VVINF", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.6": {"text": "Was uns die Vernunft wird schenken.", "tokens": ["Was", "uns", "die", "Ver\u00b7nunft", "wird", "schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Mir will sie den Einwurf machen,", "tokens": ["Mir", "will", "sie", "den", "Ein\u00b7wurf", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich zwar zu hohen Sachen", "tokens": ["Da\u00df", "ich", "zwar", "zu", "ho\u00b7hen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht geschickt und w\u00fcrdig bin,", "tokens": ["Nicht", "ge\u00b7schickt", "und", "w\u00fcr\u00b7dig", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "KON", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dennoch spricht sie: Schreib nur hin!", "tokens": ["Den\u00b7noch", "spricht", "sie", ":", "Schreib", "nur", "hin", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wies die Redlichkeit verlanget,", "tokens": ["Wies", "die", "Red\u00b7lich\u00b7keit", "ver\u00b7lan\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn sie nicht mit Schminke pranget.", "tokens": ["Wenn", "sie", "nicht", "mit", "Schmin\u00b7ke", "pran\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Dich, mein Leser! l\u00e4st sie bitten,", "tokens": ["Dich", ",", "mein", "Le\u00b7ser", "!", "l\u00e4st", "sie", "bit\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn ich etwas \u00fcberschritten", "tokens": ["Wenn", "ich", "et\u00b7was", "\u00fc\u00b7bersc\u00b7hrit\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nicht alle Regeln gab,", "tokens": ["Und", "nicht", "al\u00b7le", "Re\u00b7geln", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Rechne fein vern\u00fcnftig ab,", "tokens": ["Rech\u00b7ne", "fein", "ver\u00b7n\u00fcnf\u00b7tig", "ab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn zuweilen auch dein Leben,", "tokens": ["Wenn", "zu\u00b7wei\u00b7len", "auch", "dein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns kan wenig Regeln geben.", "tokens": ["Uns", "kan", "we\u00b7nig", "Re\u00b7geln", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Alle St\u00e4nde durchzugehen,", "tokens": ["Al\u00b7le", "St\u00e4n\u00b7de", "durch\u00b7zu\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihren Wehrt recht einzusehen,", "tokens": ["Ih\u00b7ren", "Wehrt", "recht", "ein\u00b7zu\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Macht den kl\u00fcgsten Mann zu thun,", "tokens": ["Macht", "den", "kl\u00fcgs\u00b7ten", "Mann", "zu", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ich untersteh mich nun", "tokens": ["Und", "ich", "un\u00b7ter\u00b7steh", "mich", "nun"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf den Schauplatz alle Sachen", "tokens": ["Auf", "den", "Schau\u00b7platz", "al\u00b7le", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Rein und k\u00e4nntlicher zu machen.", "tokens": ["Rein", "und", "k\u00e4nnt\u00b7li\u00b7cher", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ist der Vorwitz nicht zu k\u00fchne", "tokens": ["Ist", "der", "Vor\u00b7witz", "nicht", "zu", "k\u00fch\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "PTKZU", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich mich des Rechts bediene,", "tokens": ["Da\u00df", "ich", "mich", "des", "Rechts", "be\u00b7die\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sonst M\u00e4nnern nur geh\u00f6rt,", "tokens": ["Da\u00df", "sonst", "M\u00e4n\u00b7nern", "nur", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn mein Flei\u00df die Bo\u00dfheit st\u00f6rt,", "tokens": ["Wenn", "mein", "Flei\u00df", "die", "Bo\u00df\u00b7heit", "st\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn ich allen Lastern fluche,", "tokens": ["Wenn", "ich", "al\u00b7len", "Las\u00b7tern", "flu\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und die Tugend eifrigst suche.", "tokens": ["Und", "die", "Tu\u00b7gend", "eif\u00b7rigst", "su\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Ja, spricht offt die Welt mit Lachen,", "tokens": ["Ja", ",", "spricht", "offt", "die", "Welt", "mit", "La\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Du willst uns ein St\u00fcckgen machen", "tokens": ["Du", "willst", "uns", "ein", "St\u00fcck\u00b7gen", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ART", "NN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das der Tugend Titul f\u00fchrt,", "tokens": ["Das", "der", "Tu\u00b7gend", "Ti\u00b7tul", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weist du denn was ihr geb\u00fchrt?", "tokens": ["Weist", "du", "denn", "was", "ihr", "ge\u00b7b\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KON", "PWS", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch du nennest ihren Namen", "tokens": ["Doch", "du", "nen\u00b7nest", "ih\u00b7ren", "Na\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und weist listig nachzuahmen.", "tokens": ["Und", "weist", "lis\u00b7tig", "nach\u00b7zu\u00b7ah\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "La\u00df der Tugend ihre Seyde", "tokens": ["La\u00df", "der", "Tu\u00b7gend", "ih\u00b7re", "Sey\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von dem schlechten Narrenkleide,", "tokens": ["Von", "dem", "schlech\u00b7ten", "Nar\u00b7ren\u00b7klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Du und sie sind nicht verwant,", "tokens": ["Du", "und", "sie", "sind", "nicht", "ver\u00b7want", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPER", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sie ist dir gar nicht bekannt,", "tokens": ["Sie", "ist", "dir", "gar", "nicht", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Dir geh\u00f6rt ein schlechtes Leben,", "tokens": ["Dir", "ge\u00b7h\u00f6rt", "ein", "schlech\u00b7tes", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und dich allen Preis zu geben.", "tokens": ["Und", "dich", "al\u00b7len", "Preis", "zu", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Was? ein Schauspiel? ein Gedichte?", "tokens": ["Was", "?", "ein", "Schau\u00b7spiel", "?", "ein", "Ge\u00b7dich\u00b7te", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "$.", "ART", "NN", "$.", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4tt den Eindruck, das Gewichte,", "tokens": ["H\u00e4tt", "den", "Ein\u00b7druck", ",", "das", "Ge\u00b7wich\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ein reines Herz dabey", "tokens": ["Da\u00df", "ein", "rei\u00b7nes", "Herz", "da\u00b7bey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Edel, klug, vern\u00fcnftig sey?", "tokens": ["E\u00b7del", ",", "klug", ",", "ver\u00b7n\u00fcnf\u00b7tig", "sey", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "$,", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein! wahrhaftig diese Leute", "tokens": ["Nein", "!", "wahr\u00b7haf\u00b7tig", "die\u00b7se", "Leu\u00b7te"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$.", "ADJD", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "M\u00fcssen auf die linke Seite.", "tokens": ["M\u00fcs\u00b7sen", "auf", "die", "lin\u00b7ke", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Denkt: wo seyd ihr hergekommen,", "tokens": ["Denkt", ":", "wo", "seyd", "ihr", "her\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PWAV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Euer Ursprung ward genommen", "tokens": ["Eu\u00b7er", "Ur\u00b7sprung", "ward", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Von dem wilden Bachus Fest", "tokens": ["Von", "dem", "wil\u00b7den", "Ba\u00b7chus", "Fest"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NE", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das kein Laster \u00fcbrig l\u00e4st,", "tokens": ["Das", "kein", "Las\u00b7ter", "\u00fcb\u00b7rig", "l\u00e4st", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo man in der Wollust w\u00fchlen", "tokens": ["Wo", "man", "in", "der", "Wol\u00b7lust", "w\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Taumelnd singen stumm kont spielen.", "tokens": ["Tau\u00b7melnd", "sin\u00b7gen", "stumm", "kont", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ADJD", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Ey, sind das nicht sch\u00f6ne Gr\u00fcnde?", "tokens": ["Ey", ",", "sind", "das", "nicht", "sch\u00f6\u00b7ne", "Gr\u00fcn\u00b7de", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PDS", "PTKNEG", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird die Tugend da zum Kinde,", "tokens": ["Wird", "die", "Tu\u00b7gend", "da", "zum", "Kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo die Laster M\u00fctter sind?", "tokens": ["Wo", "die", "Las\u00b7ter", "M\u00fct\u00b7ter", "sind", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Geht doch; helfft dem guten Kind", "tokens": ["Geht", "doch", ";", "helfft", "dem", "gu\u00b7ten", "Kind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$.", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf dem Schauplatz auf die Beine,", "tokens": ["Auf", "dem", "Schau\u00b7platz", "auf", "die", "Bei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der allein ist keusch und reine.", "tokens": ["Der", "al\u00b7lein", "ist", "keusch", "und", "rei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VAFIN", "ADJD", "KON", "ADJA", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.13": {"line.1": {"text": "Der ist unser Sittenrichter,", "tokens": ["Der", "ist", "un\u00b7ser", "Sit\u00b7ten\u00b7rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der verziert uns die Gesichter", "tokens": ["Der", "ver\u00b7ziert", "uns", "die", "Ge\u00b7sich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn der Stellung was gebricht.", "tokens": ["Wenn", "der", "Stel\u00b7lung", "was", "ge\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PWS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Folgt dem Lehrer, h\u00f6rt ihr nicht?", "tokens": ["Folgt", "dem", "Leh\u00b7rer", ",", "h\u00f6rt", "ihr", "nicht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Seht ihr nicht die gro\u00dfen Thaten", "tokens": ["Seht", "ihr", "nicht", "die", "gro\u00b7\u00dfen", "Tha\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die des Staats verbe\u00dfrung rathen?", "tokens": ["Die", "des", "Staats", "ver\u00b7be\u00df\u00b7rung", "ra\u00b7then", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Welt und Laster mu\u00df ich schweigen!", "tokens": ["Welt", "und", "Las\u00b7ter", "mu\u00df", "ich", "schwei\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So m\u00fcst ihr mir das bezeugen,", "tokens": ["So", "m\u00fcst", "ihr", "mir", "das", "be\u00b7zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "PDS", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df der Hohn euch mehr betrifft,", "tokens": ["Da\u00df", "der", "Hohn", "euch", "mehr", "be\u00b7tr\u00b7ifft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Saugt ihr doch aus Rosen Gifft;", "tokens": ["Saugt", "ihr", "doch", "aus", "Ro\u00b7sen", "Gifft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sind doch alle Himmels Lehren", "tokens": ["Sind", "doch", "al\u00b7le", "Him\u00b7mels", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Viel zu schwach / Nicht genug euch zu bekehren.", "tokens": ["Viel", "zu", "schwach", "/", "Nicht", "ge\u00b7nug", "euch", "zu", "be\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "$(", "PTKNEG", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Tret ihr doch das Kraut mit F\u00fcssen", "tokens": ["Tret", "ihr", "doch", "das", "Kraut", "mit", "F\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das euch sonst erhalten m\u00fcssen", "tokens": ["Das", "euch", "sonst", "er\u00b7hal\u00b7ten", "m\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "ADV", "VVINF", "VMINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das euch zur Gesundheit dient.", "tokens": ["Das", "euch", "zur", "Ge\u00b7sund\u00b7heit", "dient", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "O! wer sich so viel erk\u00fchnt,", "tokens": ["O", "!", "wer", "sich", "so", "viel", "er\u00b7k\u00fchnt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWS", "PRF", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Selbst sein Gutes zu verachten,", "tokens": ["Selbst", "sein", "Gu\u00b7tes", "zu", "ver\u00b7ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mag mich nimmer schlecht betrachten.", "tokens": ["Mag", "mich", "nim\u00b7mer", "schlecht", "be\u00b7trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Ihr habt Recht: doch euch zur Schande", "tokens": ["Ihr", "habt", "Recht", ":", "doch", "euch", "zur", "Schan\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$.", "ADV", "PPER", "APPRART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Da\u00df ihr offt in gr\u00f6\u00dfern / bessern Stande", "tokens": ["Da\u00df", "ihr", "offt", "in", "gr\u00f6\u00b7\u00dfern", "/", "bes\u00b7sern", "Stan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADJA", "$(", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Noch viel kleiner / wilder seyd als ich,", "tokens": ["Noch", "viel", "klei\u00b7ner", "/", "wil\u00b7der", "seyd", "als", "ich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$(", "ADJA", "VAFIN", "KOUS", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Glaubt: ich Arme kenne mich,", "tokens": ["Glaubt", ":", "ich", "Ar\u00b7me", "ken\u00b7ne", "mich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPER", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und d\u00fcrft ich euch k\u00e4ntlich machen,", "tokens": ["Und", "d\u00fcrft", "ich", "euch", "k\u00e4nt\u00b7lich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "G\u00e4b es \u00f6ffters viel zu lachen.", "tokens": ["G\u00e4b", "es", "\u00f6ff\u00b7ters", "viel", "zu", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Wenn wir an den Ursprung denken,", "tokens": ["Wenn", "wir", "an", "den", "Ur\u00b7sprung", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "M\u00fcssen wir uns alle kr\u00e4nken,", "tokens": ["M\u00fcs\u00b7sen", "wir", "uns", "al\u00b7le", "kr\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn der Mutter Erde Schoo\u00df", "tokens": ["Denn", "der", "Mut\u00b7ter", "Er\u00b7de", "Schoo\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Zieht uns wahrlich alle gro\u00df,", "tokens": ["Zieht", "uns", "wahr\u00b7lich", "al\u00b7le", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kriegt gleich mancher mehr zum Kleide,", "tokens": ["Kriegt", "gleich", "man\u00b7cher", "mehr", "zum", "Klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIS", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Spinnt ihm doch der Wurm die Seide.", "tokens": ["Spinnt", "ihm", "doch", "der", "Wurm", "die", "Sei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Wer die alte Wahrheit liebet", "tokens": ["Wer", "die", "al\u00b7te", "Wahr\u00b7heit", "lie\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die neue nicht betr\u00fcbet", "tokens": ["Und", "die", "neu\u00b7e", "nicht", "be\u00b7tr\u00fc\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "PTKNEG", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denkt zuweilen auch an sich:", "tokens": ["Denkt", "zu\u00b7wei\u00b7len", "auch", "an", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein! warum erheb ich mich?", "tokens": ["Mein", "!", "wa\u00b7rum", "er\u00b7heb", "ich", "mich", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWAV", "VVFIN", "PPER", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Darum: da\u00df die andern lachen", "tokens": ["Da\u00b7rum", ":", "da\u00df", "die", "an\u00b7dern", "la\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "$.", "KOUS", "ART", "ADJA", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und aus mir ein M\u00e4hrgen machen.", "tokens": ["Und", "aus", "mir", "ein", "M\u00e4hr\u00b7gen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Welt und Laster! seyd gebethen,", "tokens": ["Welt", "und", "Las\u00b7ter", "!", "seyd", "ge\u00b7be\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$.", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn ihr etwas \u00fcbertretten", "tokens": ["Wenn", "ihr", "et\u00b7was", "\u00fc\u00b7bert\u00b7ret\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Me\u00dfet mir die Schuld nicht bey,", "tokens": ["Me\u00b7\u00dfet", "mir", "die", "Schuld", "nicht", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fehlt ihr: so gestehts auch frey!", "tokens": ["Fehlt", "ihr", ":", "so", "ge\u00b7stehts", "auch", "frey", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "ADV", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn im Spiegel sind die Flecken", "tokens": ["Denn", "im", "Spie\u00b7gel", "sind", "die", "Fle\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nicht so k\u00fcnstlich zu bedecken.", "tokens": ["Nicht", "so", "k\u00fcnst\u00b7lich", "zu", "be\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Ich mag euch nicht mehr besch\u00e4men,", "tokens": ["Ich", "mag", "euch", "nicht", "mehr", "be\u00b7sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und ihr k\u00f6nnt kein Vorbild nehmen,", "tokens": ["Und", "ihr", "k\u00f6nnt", "kein", "Vor\u00b7bild", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn gleich Treu und Redlichkeit", "tokens": ["Wenn", "gleich", "Treu", "und", "Red\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Euch dazu den Weg bereit.", "tokens": ["Euch", "da\u00b7zu", "den", "Weg", "be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PAV", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nun so bleibt: ich kann euch leyden", "tokens": ["Nun", "so", "bleibt", ":", "ich", "kann", "euch", "ley\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "$.", "PPER", "VMFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und will euch doch ewig meiden.", "tokens": ["Und", "will", "euch", "doch", "e\u00b7wig", "mei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Last der Schauspielkunst die Ehre,", "tokens": ["Last", "der", "Schau\u00b7spiel\u00b7kunst", "die", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und gestehts: da\u00df ihre Lehre", "tokens": ["Und", "ge\u00b7stehts", ":", "da\u00df", "ih\u00b7re", "Leh\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn sie rein, vern\u00fcnfftig ist,", "tokens": ["Wenn", "sie", "rein", ",", "ver\u00b7n\u00fcnff\u00b7tig", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "$,", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sehr viel Gutes in sich schliest,", "tokens": ["Sehr", "viel", "Gu\u00b7tes", "in", "sich", "schliest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer nicht sieht, nicht h\u00f6rt, nicht f\u00fchlet,", "tokens": ["Wer", "nicht", "sieht", ",", "nicht", "h\u00f6rt", ",", "nicht", "f\u00fch\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVFIN", "$,", "PTKNEG", "VVFIN", "$,", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Diesen wird auch nicht gespielet.", "tokens": ["Die\u00b7sen", "wird", "auch", "nicht", "ge\u00b7spie\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Nun ich seh, ich kan im Schreiben", "tokens": ["Nun", "ich", "seh", ",", "ich", "kan", "im", "Schrei\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht gar wohl im Schranken bleiben,", "tokens": ["Nicht", "gar", "wohl", "im", "Schran\u00b7ken", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Drum ists besser: Ausgemacht!", "tokens": ["Drum", "ists", "bes\u00b7ser", ":", "Aus\u00b7ge\u00b7macht", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "VAFIN", "ADJD", "$.", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Koch hat sich erst lang bedacht,", "tokens": ["Koch", "hat", "sich", "erst", "lang", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PRF", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Fest entschlo\u00dfen, fest gewehlet,", "tokens": ["Fest", "ent\u00b7schlo\u00b7\u00dfen", ",", "fest", "ge\u00b7weh\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df ihm nur mein Wunsch noch fehlet.", "tokens": ["Da\u00df", "ihm", "nur", "mein", "Wunsch", "noch", "feh\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Der soll ihm zu statten kommen,", "tokens": ["Der", "soll", "ihm", "zu", "stat\u00b7ten", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PTKZU", "VVFIN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Was er heute vorgenommen,", "tokens": ["Was", "er", "heu\u00b7te", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seegne Gott mit seiner Hand,", "tokens": ["Seeg\u00b7ne", "Gott", "mit", "sei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In dem neu erwehlten Stand;", "tokens": ["In", "dem", "neu", "er\u00b7wehl\u00b7ten", "Stand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie ich ihm das beste g\u00f6nne,", "tokens": ["Wie", "ich", "ihm", "das", "bes\u00b7te", "g\u00f6n\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Und mich heute Mutter nenne.", "tokens": ["Und", "mich", "heu\u00b7te", "Mut\u00b7ter", "nen\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Die Gesellschafft zu verehren,", "tokens": ["Die", "Ge\u00b7sell\u00b7schafft", "zu", "ver\u00b7eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4st sich meine Muse h\u00f6ren;", "tokens": ["L\u00e4st", "sich", "mei\u00b7ne", "Mu\u00b7se", "h\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die sonst schlecht und heischer singt,", "tokens": ["Die", "sonst", "schlecht", "und", "hei\u00b7scher", "singt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und nicht viel zusammen bringt,", "tokens": ["Und", "nicht", "viel", "zu\u00b7sam\u00b7men", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch ich will es immer wagen,", "tokens": ["Doch", "ich", "will", "es", "im\u00b7mer", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und getrost die Meynung sagen.", "tokens": ["Und", "ge\u00b7trost", "die", "Mey\u00b7nung", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Braut und Br\u00e4utgam ehr ich schweigend!", "tokens": ["Braut", "und", "Br\u00e4ut\u00b7gam", "ehr", "ich", "schwei\u00b7gend", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "NN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Denn mein Flei\u00df ist \u00fcberzeugend:", "tokens": ["Denn", "mein", "Flei\u00df", "ist", "\u00fc\u00b7berz\u00b7eu\u00b7gend", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ihr Gl\u00fcck auch mich erfreut.", "tokens": ["Da\u00df", "ihr", "Gl\u00fcck", "auch", "mich", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich thu ihnen nichts zu leyd,", "tokens": ["Ich", "thu", "ih\u00b7nen", "nichts", "zu", "leyd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und sie werden nichts ver\u00fcben", "tokens": ["Und", "sie", "wer\u00b7den", "nichts", "ver\u00b7\u00fc\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das mich k\u00fcnftig k\u00f6nt betr\u00fcben.", "tokens": ["Das", "mich", "k\u00fcnf\u00b7tig", "k\u00f6nt", "be\u00b7tr\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADJD", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Hochzeitreime hinzuschreiben", "tokens": ["Hoch\u00b7zei\u00b7trei\u00b7me", "hin\u00b7zu\u00b7schrei\u00b7ben"], "token_info": ["word", "word"], "pos": ["NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und dabey im Schranken bleiben", "tokens": ["Und", "da\u00b7bey", "im", "Schran\u00b7ken", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "APPRART", "NN", "VVINF"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Ist ein schweres Werk vor mich.", "tokens": ["Ist", "ein", "schwe\u00b7res", "Werk", "vor", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Darum wollen du und ich,", "tokens": ["Da\u00b7rum", "wol\u00b7len", "du", "und", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "KON", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Lieber Leser! darauf denken,", "tokens": ["Lie\u00b7ber", "Le\u00b7ser", "!", "da\u00b7rauf", "den\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "NN", "$.", "PAV", "VVINF", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.6": {"text": "Was uns die Vernunft wird schenken.", "tokens": ["Was", "uns", "die", "Ver\u00b7nunft", "wird", "schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Mir will sie den Einwurf machen,", "tokens": ["Mir", "will", "sie", "den", "Ein\u00b7wurf", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich zwar zu hohen Sachen", "tokens": ["Da\u00df", "ich", "zwar", "zu", "ho\u00b7hen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht geschickt und w\u00fcrdig bin,", "tokens": ["Nicht", "ge\u00b7schickt", "und", "w\u00fcr\u00b7dig", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "KON", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dennoch spricht sie: Schreib nur hin!", "tokens": ["Den\u00b7noch", "spricht", "sie", ":", "Schreib", "nur", "hin", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wies die Redlichkeit verlanget,", "tokens": ["Wies", "die", "Red\u00b7lich\u00b7keit", "ver\u00b7lan\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn sie nicht mit Schminke pranget.", "tokens": ["Wenn", "sie", "nicht", "mit", "Schmin\u00b7ke", "pran\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Dich, mein Leser! l\u00e4st sie bitten,", "tokens": ["Dich", ",", "mein", "Le\u00b7ser", "!", "l\u00e4st", "sie", "bit\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn ich etwas \u00fcberschritten", "tokens": ["Wenn", "ich", "et\u00b7was", "\u00fc\u00b7bersc\u00b7hrit\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nicht alle Regeln gab,", "tokens": ["Und", "nicht", "al\u00b7le", "Re\u00b7geln", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Rechne fein vern\u00fcnftig ab,", "tokens": ["Rech\u00b7ne", "fein", "ver\u00b7n\u00fcnf\u00b7tig", "ab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn zuweilen auch dein Leben,", "tokens": ["Wenn", "zu\u00b7wei\u00b7len", "auch", "dein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns kan wenig Regeln geben.", "tokens": ["Uns", "kan", "we\u00b7nig", "Re\u00b7geln", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.29": {"line.1": {"text": "Alle St\u00e4nde durchzugehen,", "tokens": ["Al\u00b7le", "St\u00e4n\u00b7de", "durch\u00b7zu\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihren Wehrt recht einzusehen,", "tokens": ["Ih\u00b7ren", "Wehrt", "recht", "ein\u00b7zu\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Macht den kl\u00fcgsten Mann zu thun,", "tokens": ["Macht", "den", "kl\u00fcgs\u00b7ten", "Mann", "zu", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ich untersteh mich nun", "tokens": ["Und", "ich", "un\u00b7ter\u00b7steh", "mich", "nun"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf den Schauplatz alle Sachen", "tokens": ["Auf", "den", "Schau\u00b7platz", "al\u00b7le", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Rein und k\u00e4nntlicher zu machen.", "tokens": ["Rein", "und", "k\u00e4nnt\u00b7li\u00b7cher", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Ist der Vorwitz nicht zu k\u00fchne", "tokens": ["Ist", "der", "Vor\u00b7witz", "nicht", "zu", "k\u00fch\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "PTKZU", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich mich des Rechts bediene,", "tokens": ["Da\u00df", "ich", "mich", "des", "Rechts", "be\u00b7die\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sonst M\u00e4nnern nur geh\u00f6rt,", "tokens": ["Da\u00df", "sonst", "M\u00e4n\u00b7nern", "nur", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn mein Flei\u00df die Bo\u00dfheit st\u00f6rt,", "tokens": ["Wenn", "mein", "Flei\u00df", "die", "Bo\u00df\u00b7heit", "st\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn ich allen Lastern fluche,", "tokens": ["Wenn", "ich", "al\u00b7len", "Las\u00b7tern", "flu\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und die Tugend eifrigst suche.", "tokens": ["Und", "die", "Tu\u00b7gend", "eif\u00b7rigst", "su\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Ja, spricht offt die Welt mit Lachen,", "tokens": ["Ja", ",", "spricht", "offt", "die", "Welt", "mit", "La\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Du willst uns ein St\u00fcckgen machen", "tokens": ["Du", "willst", "uns", "ein", "St\u00fcck\u00b7gen", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ART", "NN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das der Tugend Titul f\u00fchrt,", "tokens": ["Das", "der", "Tu\u00b7gend", "Ti\u00b7tul", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weist du denn was ihr geb\u00fchrt?", "tokens": ["Weist", "du", "denn", "was", "ihr", "ge\u00b7b\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KON", "PWS", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch du nennest ihren Namen", "tokens": ["Doch", "du", "nen\u00b7nest", "ih\u00b7ren", "Na\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und weist listig nachzuahmen.", "tokens": ["Und", "weist", "lis\u00b7tig", "nach\u00b7zu\u00b7ah\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "La\u00df der Tugend ihre Seyde", "tokens": ["La\u00df", "der", "Tu\u00b7gend", "ih\u00b7re", "Sey\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von dem schlechten Narrenkleide,", "tokens": ["Von", "dem", "schlech\u00b7ten", "Nar\u00b7ren\u00b7klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Du und sie sind nicht verwant,", "tokens": ["Du", "und", "sie", "sind", "nicht", "ver\u00b7want", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPER", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sie ist dir gar nicht bekannt,", "tokens": ["Sie", "ist", "dir", "gar", "nicht", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Dir geh\u00f6rt ein schlechtes Leben,", "tokens": ["Dir", "ge\u00b7h\u00f6rt", "ein", "schlech\u00b7tes", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und dich allen Preis zu geben.", "tokens": ["Und", "dich", "al\u00b7len", "Preis", "zu", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Was? ein Schauspiel? ein Gedichte?", "tokens": ["Was", "?", "ein", "Schau\u00b7spiel", "?", "ein", "Ge\u00b7dich\u00b7te", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "$.", "ART", "NN", "$.", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4tt den Eindruck, das Gewichte,", "tokens": ["H\u00e4tt", "den", "Ein\u00b7druck", ",", "das", "Ge\u00b7wich\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ein reines Herz dabey", "tokens": ["Da\u00df", "ein", "rei\u00b7nes", "Herz", "da\u00b7bey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Edel, klug, vern\u00fcnftig sey?", "tokens": ["E\u00b7del", ",", "klug", ",", "ver\u00b7n\u00fcnf\u00b7tig", "sey", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "$,", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein! wahrhaftig diese Leute", "tokens": ["Nein", "!", "wahr\u00b7haf\u00b7tig", "die\u00b7se", "Leu\u00b7te"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$.", "ADJD", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "M\u00fcssen auf die linke Seite.", "tokens": ["M\u00fcs\u00b7sen", "auf", "die", "lin\u00b7ke", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Denkt: wo seyd ihr hergekommen,", "tokens": ["Denkt", ":", "wo", "seyd", "ihr", "her\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PWAV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Euer Ursprung ward genommen", "tokens": ["Eu\u00b7er", "Ur\u00b7sprung", "ward", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Von dem wilden Bachus Fest", "tokens": ["Von", "dem", "wil\u00b7den", "Ba\u00b7chus", "Fest"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NE", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das kein Laster \u00fcbrig l\u00e4st,", "tokens": ["Das", "kein", "Las\u00b7ter", "\u00fcb\u00b7rig", "l\u00e4st", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo man in der Wollust w\u00fchlen", "tokens": ["Wo", "man", "in", "der", "Wol\u00b7lust", "w\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Taumelnd singen stumm kont spielen.", "tokens": ["Tau\u00b7melnd", "sin\u00b7gen", "stumm", "kont", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ADJD", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Ey, sind das nicht sch\u00f6ne Gr\u00fcnde?", "tokens": ["Ey", ",", "sind", "das", "nicht", "sch\u00f6\u00b7ne", "Gr\u00fcn\u00b7de", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PDS", "PTKNEG", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird die Tugend da zum Kinde,", "tokens": ["Wird", "die", "Tu\u00b7gend", "da", "zum", "Kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo die Laster M\u00fctter sind?", "tokens": ["Wo", "die", "Las\u00b7ter", "M\u00fct\u00b7ter", "sind", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Geht doch; helfft dem guten Kind", "tokens": ["Geht", "doch", ";", "helfft", "dem", "gu\u00b7ten", "Kind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$.", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf dem Schauplatz auf die Beine,", "tokens": ["Auf", "dem", "Schau\u00b7platz", "auf", "die", "Bei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der allein ist keusch und reine.", "tokens": ["Der", "al\u00b7lein", "ist", "keusch", "und", "rei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VAFIN", "ADJD", "KON", "ADJA", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.36": {"line.1": {"text": "Der ist unser Sittenrichter,", "tokens": ["Der", "ist", "un\u00b7ser", "Sit\u00b7ten\u00b7rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der verziert uns die Gesichter", "tokens": ["Der", "ver\u00b7ziert", "uns", "die", "Ge\u00b7sich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn der Stellung was gebricht.", "tokens": ["Wenn", "der", "Stel\u00b7lung", "was", "ge\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PWS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Folgt dem Lehrer, h\u00f6rt ihr nicht?", "tokens": ["Folgt", "dem", "Leh\u00b7rer", ",", "h\u00f6rt", "ihr", "nicht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Seht ihr nicht die gro\u00dfen Thaten", "tokens": ["Seht", "ihr", "nicht", "die", "gro\u00b7\u00dfen", "Tha\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die des Staats verbe\u00dfrung rathen?", "tokens": ["Die", "des", "Staats", "ver\u00b7be\u00df\u00b7rung", "ra\u00b7then", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Welt und Laster mu\u00df ich schweigen!", "tokens": ["Welt", "und", "Las\u00b7ter", "mu\u00df", "ich", "schwei\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So m\u00fcst ihr mir das bezeugen,", "tokens": ["So", "m\u00fcst", "ihr", "mir", "das", "be\u00b7zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "PDS", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df der Hohn euch mehr betrifft,", "tokens": ["Da\u00df", "der", "Hohn", "euch", "mehr", "be\u00b7tr\u00b7ifft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Saugt ihr doch aus Rosen Gifft;", "tokens": ["Saugt", "ihr", "doch", "aus", "Ro\u00b7sen", "Gifft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sind doch alle Himmels Lehren", "tokens": ["Sind", "doch", "al\u00b7le", "Him\u00b7mels", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Viel zu schwach / Nicht genug euch zu bekehren.", "tokens": ["Viel", "zu", "schwach", "/", "Nicht", "ge\u00b7nug", "euch", "zu", "be\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "$(", "PTKNEG", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.38": {"line.1": {"text": "Tret ihr doch das Kraut mit F\u00fcssen", "tokens": ["Tret", "ihr", "doch", "das", "Kraut", "mit", "F\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das euch sonst erhalten m\u00fcssen", "tokens": ["Das", "euch", "sonst", "er\u00b7hal\u00b7ten", "m\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "ADV", "VVINF", "VMINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das euch zur Gesundheit dient.", "tokens": ["Das", "euch", "zur", "Ge\u00b7sund\u00b7heit", "dient", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "O! wer sich so viel erk\u00fchnt,", "tokens": ["O", "!", "wer", "sich", "so", "viel", "er\u00b7k\u00fchnt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWS", "PRF", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Selbst sein Gutes zu verachten,", "tokens": ["Selbst", "sein", "Gu\u00b7tes", "zu", "ver\u00b7ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mag mich nimmer schlecht betrachten.", "tokens": ["Mag", "mich", "nim\u00b7mer", "schlecht", "be\u00b7trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Ihr habt Recht: doch euch zur Schande", "tokens": ["Ihr", "habt", "Recht", ":", "doch", "euch", "zur", "Schan\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$.", "ADV", "PPER", "APPRART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Da\u00df ihr offt in gr\u00f6\u00dfern / bessern Stande", "tokens": ["Da\u00df", "ihr", "offt", "in", "gr\u00f6\u00b7\u00dfern", "/", "bes\u00b7sern", "Stan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADJA", "$(", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Noch viel kleiner / wilder seyd als ich,", "tokens": ["Noch", "viel", "klei\u00b7ner", "/", "wil\u00b7der", "seyd", "als", "ich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$(", "ADJA", "VAFIN", "KOUS", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Glaubt: ich Arme kenne mich,", "tokens": ["Glaubt", ":", "ich", "Ar\u00b7me", "ken\u00b7ne", "mich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPER", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und d\u00fcrft ich euch k\u00e4ntlich machen,", "tokens": ["Und", "d\u00fcrft", "ich", "euch", "k\u00e4nt\u00b7lich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "G\u00e4b es \u00f6ffters viel zu lachen.", "tokens": ["G\u00e4b", "es", "\u00f6ff\u00b7ters", "viel", "zu", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Wenn wir an den Ursprung denken,", "tokens": ["Wenn", "wir", "an", "den", "Ur\u00b7sprung", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "M\u00fcssen wir uns alle kr\u00e4nken,", "tokens": ["M\u00fcs\u00b7sen", "wir", "uns", "al\u00b7le", "kr\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn der Mutter Erde Schoo\u00df", "tokens": ["Denn", "der", "Mut\u00b7ter", "Er\u00b7de", "Schoo\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Zieht uns wahrlich alle gro\u00df,", "tokens": ["Zieht", "uns", "wahr\u00b7lich", "al\u00b7le", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kriegt gleich mancher mehr zum Kleide,", "tokens": ["Kriegt", "gleich", "man\u00b7cher", "mehr", "zum", "Klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIS", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Spinnt ihm doch der Wurm die Seide.", "tokens": ["Spinnt", "ihm", "doch", "der", "Wurm", "die", "Sei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Wer die alte Wahrheit liebet", "tokens": ["Wer", "die", "al\u00b7te", "Wahr\u00b7heit", "lie\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die neue nicht betr\u00fcbet", "tokens": ["Und", "die", "neu\u00b7e", "nicht", "be\u00b7tr\u00fc\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "PTKNEG", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denkt zuweilen auch an sich:", "tokens": ["Denkt", "zu\u00b7wei\u00b7len", "auch", "an", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein! warum erheb ich mich?", "tokens": ["Mein", "!", "wa\u00b7rum", "er\u00b7heb", "ich", "mich", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWAV", "VVFIN", "PPER", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Darum: da\u00df die andern lachen", "tokens": ["Da\u00b7rum", ":", "da\u00df", "die", "an\u00b7dern", "la\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "$.", "KOUS", "ART", "ADJA", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und aus mir ein M\u00e4hrgen machen.", "tokens": ["Und", "aus", "mir", "ein", "M\u00e4hr\u00b7gen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.42": {"line.1": {"text": "Welt und Laster! seyd gebethen,", "tokens": ["Welt", "und", "Las\u00b7ter", "!", "seyd", "ge\u00b7be\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$.", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn ihr etwas \u00fcbertretten", "tokens": ["Wenn", "ihr", "et\u00b7was", "\u00fc\u00b7bert\u00b7ret\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Me\u00dfet mir die Schuld nicht bey,", "tokens": ["Me\u00b7\u00dfet", "mir", "die", "Schuld", "nicht", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fehlt ihr: so gestehts auch frey!", "tokens": ["Fehlt", "ihr", ":", "so", "ge\u00b7stehts", "auch", "frey", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "ADV", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn im Spiegel sind die Flecken", "tokens": ["Denn", "im", "Spie\u00b7gel", "sind", "die", "Fle\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nicht so k\u00fcnstlich zu bedecken.", "tokens": ["Nicht", "so", "k\u00fcnst\u00b7lich", "zu", "be\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Ich mag euch nicht mehr besch\u00e4men,", "tokens": ["Ich", "mag", "euch", "nicht", "mehr", "be\u00b7sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und ihr k\u00f6nnt kein Vorbild nehmen,", "tokens": ["Und", "ihr", "k\u00f6nnt", "kein", "Vor\u00b7bild", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn gleich Treu und Redlichkeit", "tokens": ["Wenn", "gleich", "Treu", "und", "Red\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Euch dazu den Weg bereit.", "tokens": ["Euch", "da\u00b7zu", "den", "Weg", "be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PAV", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nun so bleibt: ich kann euch leyden", "tokens": ["Nun", "so", "bleibt", ":", "ich", "kann", "euch", "ley\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "$.", "PPER", "VMFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und will euch doch ewig meiden.", "tokens": ["Und", "will", "euch", "doch", "e\u00b7wig", "mei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.44": {"line.1": {"text": "Last der Schauspielkunst die Ehre,", "tokens": ["Last", "der", "Schau\u00b7spiel\u00b7kunst", "die", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und gestehts: da\u00df ihre Lehre", "tokens": ["Und", "ge\u00b7stehts", ":", "da\u00df", "ih\u00b7re", "Leh\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn sie rein, vern\u00fcnfftig ist,", "tokens": ["Wenn", "sie", "rein", ",", "ver\u00b7n\u00fcnff\u00b7tig", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "$,", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sehr viel Gutes in sich schliest,", "tokens": ["Sehr", "viel", "Gu\u00b7tes", "in", "sich", "schliest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer nicht sieht, nicht h\u00f6rt, nicht f\u00fchlet,", "tokens": ["Wer", "nicht", "sieht", ",", "nicht", "h\u00f6rt", ",", "nicht", "f\u00fch\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVFIN", "$,", "PTKNEG", "VVFIN", "$,", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Diesen wird auch nicht gespielet.", "tokens": ["Die\u00b7sen", "wird", "auch", "nicht", "ge\u00b7spie\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Nun ich seh, ich kan im Schreiben", "tokens": ["Nun", "ich", "seh", ",", "ich", "kan", "im", "Schrei\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht gar wohl im Schranken bleiben,", "tokens": ["Nicht", "gar", "wohl", "im", "Schran\u00b7ken", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Drum ists besser: Ausgemacht!", "tokens": ["Drum", "ists", "bes\u00b7ser", ":", "Aus\u00b7ge\u00b7macht", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "VAFIN", "ADJD", "$.", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Koch hat sich erst lang bedacht,", "tokens": ["Koch", "hat", "sich", "erst", "lang", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PRF", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Fest entschlo\u00dfen, fest gewehlet,", "tokens": ["Fest", "ent\u00b7schlo\u00b7\u00dfen", ",", "fest", "ge\u00b7weh\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df ihm nur mein Wunsch noch fehlet.", "tokens": ["Da\u00df", "ihm", "nur", "mein", "Wunsch", "noch", "feh\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "Der soll ihm zu statten kommen,", "tokens": ["Der", "soll", "ihm", "zu", "stat\u00b7ten", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PTKZU", "VVFIN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Was er heute vorgenommen,", "tokens": ["Was", "er", "heu\u00b7te", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seegne Gott mit seiner Hand,", "tokens": ["Seeg\u00b7ne", "Gott", "mit", "sei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In dem neu erwehlten Stand;", "tokens": ["In", "dem", "neu", "er\u00b7wehl\u00b7ten", "Stand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie ich ihm das beste g\u00f6nne,", "tokens": ["Wie", "ich", "ihm", "das", "bes\u00b7te", "g\u00f6n\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Und mich heute Mutter nenne.", "tokens": ["Und", "mich", "heu\u00b7te", "Mut\u00b7ter", "nen\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}