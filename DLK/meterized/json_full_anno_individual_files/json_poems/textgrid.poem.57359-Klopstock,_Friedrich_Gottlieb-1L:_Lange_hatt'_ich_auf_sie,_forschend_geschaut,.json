{"textgrid.poem.57359": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Lange hatt' ich auf sie, forschend geschaut,", "genre": "verse", "period": "N.A.", "pub_year": 1793, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lange hatt' ich auf sie, forschend geschaut,", "tokens": ["Lan\u00b7ge", "hatt'", "ich", "auf", "sie", ",", "for\u00b7schend", "ge\u00b7schaut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPER", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Auf die redenden nicht; die Th\u00e4ter! war,", "tokens": ["Auf", "die", "re\u00b7den\u00b7den", "nicht", ";", "die", "Th\u00e4\u00b7ter", "!", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PTKNEG", "$.", "ART", "NN", "$.", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bey den Maalen der Geschichte", "tokens": ["Bey", "den", "Maa\u00b7len", "der", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wandelnd, den Franken gefolgt.", "tokens": ["Wan\u00b7delnd", ",", "den", "Fran\u00b7ken", "ge\u00b7folgt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ART", "NN", "VVPP", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.2": {"line.1": {"text": "Die an V\u00f6lkern du r\u00e4chst, K\u00f6nigen r\u00e4chst,", "tokens": ["Die", "an", "V\u00f6l\u00b7kern", "du", "r\u00e4chst", ",", "K\u00f6\u00b7ni\u00b7gen", "r\u00e4chst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "PPER", "VVFIN", "$,", "NN", "VVFIN", "$,"], "meter": "-+---++--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Priestern, die Menschheit, wie war's, Geschichte, voll", "tokens": ["Pries\u00b7tern", ",", "die", "Menschheit", ",", "wie", "wa\u00b7r's", ",", "Ge\u00b7schich\u00b7te", ",", "voll"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "ART", "NN", "$,", "PWAV", "VAFIN", "$,", "NN", "$,", "ADJD"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Von Gem\u00e4hlden, die der Gute,", "tokens": ["Von", "Ge\u00b7m\u00e4hl\u00b7den", ",", "die", "der", "Gu\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bleich, vor Entsetzen erblickt.", "tokens": ["Bleich", ",", "vor", "Ent\u00b7set\u00b7zen", "er\u00b7blickt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Dennoch, glaubt' ich, und ach Wonne war mir,", "tokens": ["Den\u00b7noch", ",", "glaubt'", "ich", ",", "und", "ach", "Won\u00b7ne", "war", "mir", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "KON", "XY", "NN", "VAFIN", "PPER", "$,"], "meter": "+-+-+-+-++", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Morgenr\u00f6thlicher Glanz der goldne Traum!", "tokens": ["Mor\u00b7gen\u00b7r\u00f6th\u00b7li\u00b7cher", "Glanz", "der", "gold\u00b7ne", "Traum", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "War ein Zauber, wie gehofter", "tokens": ["War", "ein", "Zau\u00b7ber", ",", "wie", "ge\u00b7hof\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "PWAV", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Liebe, dem trunkenen Geist!", "tokens": ["Lie\u00b7be", ",", "dem", "trun\u00b7ke\u00b7nen", "Geist", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.4": {"line.1": {"text": "Freyheit, Mutter des Heils, daucht' es mich, du", "tokens": ["Frey\u00b7heit", ",", "Mut\u00b7ter", "des", "Heils", ",", "daucht'", "es", "mich", ",", "du"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["NN", "$,", "NN", "ART", "NN", "$,", "VVFIN", "PPER", "PRF", "$,", "PPER"], "meter": "+-+--+---+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "W\u00fcrdest Sch\u00f6pferin seyn, die Gl\u00fccklichen,", "tokens": ["W\u00fcr\u00b7dest", "Sch\u00f6p\u00b7fe\u00b7rin", "seyn", ",", "die", "Gl\u00fcck\u00b7li\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VAINF", "$,", "ART", "NN", "$,"], "meter": "+-+-+--+--", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Die so ganz du dir erkohrest,", "tokens": ["Die", "so", "ganz", "du", "dir", "er\u00b7koh\u00b7rest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Umzuschaffen gesandt!", "tokens": ["Um\u00b7zu\u00b7schaf\u00b7fen", "ge\u00b7sandt", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "Bist du nicht Sch\u00f6pferin mehr? oder sind sie", "tokens": ["Bist", "du", "nicht", "Sch\u00f6p\u00b7fe\u00b7rin", "mehr", "?", "o\u00b7der", "sind", "sie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "NN", "ADV", "$.", "KON", "VAFIN", "PPER"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Nicht umschafbar, die du entfesseltest?", "tokens": ["Nicht", "um\u00b7schaf\u00b7bar", ",", "die", "du", "ent\u00b7fes\u00b7sel\u00b7test", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "--+-++-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Ist ihr Herz Fels, und ihr Auge", "tokens": ["Ist", "ihr", "Herz", "Fels", ",", "und", "ihr", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "NE", "$,", "KON", "PPOSAT", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Nacht, zu sehn, wer du bist?", "tokens": ["Nacht", ",", "zu", "sehn", ",", "wer", "du", "bist", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PTKZU", "VVINF", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "Deine Seel' ist Gesetz! Aber ihr Blick", "tokens": ["Dei\u00b7ne", "Seel'", "ist", "Ge\u00b7setz", "!", "A\u00b7ber", "ihr", "Blick"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$.", "KON", "PPOSAT", "NN"], "meter": "+-+--+---+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Wird des Falken, ihr Herz wird Feuerstrom;", "tokens": ["Wird", "des", "Fal\u00b7ken", ",", "ihr", "Herz", "wird", "Feu\u00b7er\u00b7strom", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PPOSAT", "NN", "VAFIN", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ha er funkelt, und es gl\u00fchet;", "tokens": ["Ha", "er", "fun\u00b7kelt", ",", "und", "es", "gl\u00fc\u00b7het", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn das Ungesetz winkt.", "tokens": ["Wenn", "das", "Un\u00b7ge\u00b7setz", "winkt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$."], "meter": "+-+---", "measure": "unknown.measure.di"}}, "stanza.7": {"line.1": {"text": "Dieses kennen sie, dich kennen sie nicht!", "tokens": ["Die\u00b7ses", "ken\u00b7nen", "sie", ",", "dich", "ken\u00b7nen", "sie", "nicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Das das lieben sie! Doch dein Name t\u00f6nt.", "tokens": ["Das", "das", "lie\u00b7ben", "sie", "!", "Doch", "dein", "Na\u00b7me", "t\u00f6nt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PDS", "VVFIN", "PPER", "$.", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Wenn die Guten das verruchte", "tokens": ["Wenn", "die", "Gu\u00b7ten", "das", "ver\u00b7ruch\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwert trift: schallt es von dir!", "tokens": ["Schwert", "trift", ":", "schallt", "es", "von", "dir", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Freyheit, Mutter des Heils, nanten sie dich", "tokens": ["Frey\u00b7heit", ",", "Mut\u00b7ter", "des", "Heils", ",", "nan\u00b7ten", "sie", "dich"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "ART", "NN", "$,", "VVFIN", "PPER", "PRF"], "meter": "+-+--++--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Nicht selbst da noch, als nun Eroberungskrieg,", "tokens": ["Nicht", "selbst", "da", "noch", ",", "als", "nun", "Er\u00b7o\u00b7be\u00b7rungs\u00b7krieg", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "ADV", "$,", "KOUS", "ADV", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Mit dem Bruche des gegebnen", "tokens": ["Mit", "dem", "Bru\u00b7che", "des", "ge\u00b7geb\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Edlen Wortes, begann?", "tokens": ["Ed\u00b7len", "Wor\u00b7tes", ",", "be\u00b7gann", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.9": {"line.1": {"text": "Ach des goldenen Traums Wonn' ist dahin,", "tokens": ["Ach", "des", "gol\u00b7de\u00b7nen", "Traums", "Wonn'", "ist", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "NN", "VAFIN", "PAV", "$,"], "meter": "+-+---+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Mich umschwebet nicht mehr sein Morgenglanz,", "tokens": ["Mich", "um\u00b7schwe\u00b7bet", "nicht", "mehr", "sein", "Mor\u00b7gen\u00b7glanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "PPOSAT", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und ein Kammer, wie verschm\u00e4hter", "tokens": ["Und", "ein", "Kam\u00b7mer", ",", "wie", "ver\u00b7schm\u00e4h\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "PWAV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Liebe, k\u00fcmmert mein Herz.", "tokens": ["Lie\u00b7be", ",", "k\u00fcm\u00b7mert", "mein", "Herz", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.10": {"line.1": {"text": "M\u00fcde labet auch wohl Schatten am Weg'", "tokens": ["M\u00fc\u00b7de", "la\u00b7bet", "auch", "wohl", "Schat\u00b7ten", "am", "Weg'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "ADV", "NN", "APPRART", "NN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "In der \u00d6de, der weit umher sich kr\u00fcmt;", "tokens": ["In", "der", "\u00d6\u00b7de", ",", "der", "weit", "um\u00b7her", "sich", "kr\u00fcmt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADJD", "PTKVZ", "PRF", "VVFIN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "So hat j\u00fcngst mich die erhabne", "tokens": ["So", "hat", "j\u00fcngst", "mich", "die", "er\u00b7hab\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PPER", "ART", "ADJA"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "M\u00e4nnin, Kord\u00e4 gelabt.", "tokens": ["M\u00e4n\u00b7nin", ",", "Kor\u00b7d\u00e4", "ge\u00b7labt", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VVPP", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.11": {"line.1": {"text": "Richter sch\u00e4ndeten sich, sprachen es los,", "tokens": ["Rich\u00b7ter", "sch\u00e4n\u00b7de\u00b7ten", "sich", ",", "spra\u00b7chen", "es", "los", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+---+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "'s Ungeheuer: sie sprach nicht los, und that,", "tokens": ["'s", "Un\u00b7ge\u00b7heu\u00b7er", ":", "sie", "sprach", "nicht", "los", ",", "und", "that", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$.", "PPER", "VVFIN", "PTKNEG", "PTKVZ", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Was mit Glut einst auf der Wange,", "tokens": ["Was", "mit", "Glut", "einst", "auf", "der", "Wan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Thr\u00e4nen, der Enkel erz\u00e4hlt.", "tokens": ["Thr\u00e4\u00b7nen", ",", "der", "En\u00b7kel", "er\u00b7z\u00e4hlt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.12": {"line.1": {"text": "Lange hatt' ich auf sie, forschend geschaut,", "tokens": ["Lan\u00b7ge", "hatt'", "ich", "auf", "sie", ",", "for\u00b7schend", "ge\u00b7schaut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPER", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Auf die redenden nicht; die Th\u00e4ter! war,", "tokens": ["Auf", "die", "re\u00b7den\u00b7den", "nicht", ";", "die", "Th\u00e4\u00b7ter", "!", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PTKNEG", "$.", "ART", "NN", "$.", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bey den Maalen der Geschichte", "tokens": ["Bey", "den", "Maa\u00b7len", "der", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wandelnd, den Franken gefolgt.", "tokens": ["Wan\u00b7delnd", ",", "den", "Fran\u00b7ken", "ge\u00b7folgt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ART", "NN", "VVPP", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.13": {"line.1": {"text": "Die an V\u00f6lkern du r\u00e4chst, K\u00f6nigen r\u00e4chst,", "tokens": ["Die", "an", "V\u00f6l\u00b7kern", "du", "r\u00e4chst", ",", "K\u00f6\u00b7ni\u00b7gen", "r\u00e4chst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "PPER", "VVFIN", "$,", "NN", "VVFIN", "$,"], "meter": "-+---++--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Priestern, die Menschheit, wie war's, Geschichte, voll", "tokens": ["Pries\u00b7tern", ",", "die", "Menschheit", ",", "wie", "wa\u00b7r's", ",", "Ge\u00b7schich\u00b7te", ",", "voll"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "ART", "NN", "$,", "PWAV", "VAFIN", "$,", "NN", "$,", "ADJD"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Von Gem\u00e4hlden, die der Gute,", "tokens": ["Von", "Ge\u00b7m\u00e4hl\u00b7den", ",", "die", "der", "Gu\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bleich, vor Entsetzen erblickt.", "tokens": ["Bleich", ",", "vor", "Ent\u00b7set\u00b7zen", "er\u00b7blickt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.14": {"line.1": {"text": "Dennoch, glaubt' ich, und ach Wonne war mir,", "tokens": ["Den\u00b7noch", ",", "glaubt'", "ich", ",", "und", "ach", "Won\u00b7ne", "war", "mir", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "KON", "XY", "NN", "VAFIN", "PPER", "$,"], "meter": "+-+-+-+-++", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Morgenr\u00f6thlicher Glanz der goldne Traum!", "tokens": ["Mor\u00b7gen\u00b7r\u00f6th\u00b7li\u00b7cher", "Glanz", "der", "gold\u00b7ne", "Traum", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "War ein Zauber, wie gehofter", "tokens": ["War", "ein", "Zau\u00b7ber", ",", "wie", "ge\u00b7hof\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "PWAV", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Liebe, dem trunkenen Geist!", "tokens": ["Lie\u00b7be", ",", "dem", "trun\u00b7ke\u00b7nen", "Geist", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.15": {"line.1": {"text": "Freyheit, Mutter des Heils, daucht' es mich, du", "tokens": ["Frey\u00b7heit", ",", "Mut\u00b7ter", "des", "Heils", ",", "daucht'", "es", "mich", ",", "du"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["NN", "$,", "NN", "ART", "NN", "$,", "VVFIN", "PPER", "PRF", "$,", "PPER"], "meter": "+-+--+---+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "W\u00fcrdest Sch\u00f6pferin seyn, die Gl\u00fccklichen,", "tokens": ["W\u00fcr\u00b7dest", "Sch\u00f6p\u00b7fe\u00b7rin", "seyn", ",", "die", "Gl\u00fcck\u00b7li\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VAINF", "$,", "ART", "NN", "$,"], "meter": "+-+-+--+--", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Die so ganz du dir erkohrest,", "tokens": ["Die", "so", "ganz", "du", "dir", "er\u00b7koh\u00b7rest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Umzuschaffen gesandt!", "tokens": ["Um\u00b7zu\u00b7schaf\u00b7fen", "ge\u00b7sandt", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.16": {"line.1": {"text": "Bist du nicht Sch\u00f6pferin mehr? oder sind sie", "tokens": ["Bist", "du", "nicht", "Sch\u00f6p\u00b7fe\u00b7rin", "mehr", "?", "o\u00b7der", "sind", "sie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "NN", "ADV", "$.", "KON", "VAFIN", "PPER"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Nicht umschafbar, die du entfesseltest?", "tokens": ["Nicht", "um\u00b7schaf\u00b7bar", ",", "die", "du", "ent\u00b7fes\u00b7sel\u00b7test", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "--+-++-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Ist ihr Herz Fels, und ihr Auge", "tokens": ["Ist", "ihr", "Herz", "Fels", ",", "und", "ihr", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "NE", "$,", "KON", "PPOSAT", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Nacht, zu sehn, wer du bist?", "tokens": ["Nacht", ",", "zu", "sehn", ",", "wer", "du", "bist", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PTKZU", "VVINF", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.17": {"line.1": {"text": "Deine Seel' ist Gesetz! Aber ihr Blick", "tokens": ["Dei\u00b7ne", "Seel'", "ist", "Ge\u00b7setz", "!", "A\u00b7ber", "ihr", "Blick"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$.", "KON", "PPOSAT", "NN"], "meter": "+-+--+---+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Wird des Falken, ihr Herz wird Feuerstrom;", "tokens": ["Wird", "des", "Fal\u00b7ken", ",", "ihr", "Herz", "wird", "Feu\u00b7er\u00b7strom", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PPOSAT", "NN", "VAFIN", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ha er funkelt, und es gl\u00fchet;", "tokens": ["Ha", "er", "fun\u00b7kelt", ",", "und", "es", "gl\u00fc\u00b7het", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn das Ungesetz winkt.", "tokens": ["Wenn", "das", "Un\u00b7ge\u00b7setz", "winkt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$."], "meter": "+-+---", "measure": "unknown.measure.di"}}, "stanza.18": {"line.1": {"text": "Dieses kennen sie, dich kennen sie nicht!", "tokens": ["Die\u00b7ses", "ken\u00b7nen", "sie", ",", "dich", "ken\u00b7nen", "sie", "nicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Das das lieben sie! Doch dein Name t\u00f6nt.", "tokens": ["Das", "das", "lie\u00b7ben", "sie", "!", "Doch", "dein", "Na\u00b7me", "t\u00f6nt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PDS", "VVFIN", "PPER", "$.", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Wenn die Guten das verruchte", "tokens": ["Wenn", "die", "Gu\u00b7ten", "das", "ver\u00b7ruch\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwert trift: schallt es von dir!", "tokens": ["Schwert", "trift", ":", "schallt", "es", "von", "dir", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.19": {"line.1": {"text": "Freyheit, Mutter des Heils, nanten sie dich", "tokens": ["Frey\u00b7heit", ",", "Mut\u00b7ter", "des", "Heils", ",", "nan\u00b7ten", "sie", "dich"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "ART", "NN", "$,", "VVFIN", "PPER", "PRF"], "meter": "+-+--++--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Nicht selbst da noch, als nun Eroberungskrieg,", "tokens": ["Nicht", "selbst", "da", "noch", ",", "als", "nun", "Er\u00b7o\u00b7be\u00b7rungs\u00b7krieg", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "ADV", "$,", "KOUS", "ADV", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Mit dem Bruche des gegebnen", "tokens": ["Mit", "dem", "Bru\u00b7che", "des", "ge\u00b7geb\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Edlen Wortes, begann?", "tokens": ["Ed\u00b7len", "Wor\u00b7tes", ",", "be\u00b7gann", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.20": {"line.1": {"text": "Ach des goldenen Traums Wonn' ist dahin,", "tokens": ["Ach", "des", "gol\u00b7de\u00b7nen", "Traums", "Wonn'", "ist", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "NN", "VAFIN", "PAV", "$,"], "meter": "+-+---+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Mich umschwebet nicht mehr sein Morgenglanz,", "tokens": ["Mich", "um\u00b7schwe\u00b7bet", "nicht", "mehr", "sein", "Mor\u00b7gen\u00b7glanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "PPOSAT", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und ein Kammer, wie verschm\u00e4hter", "tokens": ["Und", "ein", "Kam\u00b7mer", ",", "wie", "ver\u00b7schm\u00e4h\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "PWAV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Liebe, k\u00fcmmert mein Herz.", "tokens": ["Lie\u00b7be", ",", "k\u00fcm\u00b7mert", "mein", "Herz", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.21": {"line.1": {"text": "M\u00fcde labet auch wohl Schatten am Weg'", "tokens": ["M\u00fc\u00b7de", "la\u00b7bet", "auch", "wohl", "Schat\u00b7ten", "am", "Weg'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "ADV", "NN", "APPRART", "NN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "In der \u00d6de, der weit umher sich kr\u00fcmt;", "tokens": ["In", "der", "\u00d6\u00b7de", ",", "der", "weit", "um\u00b7her", "sich", "kr\u00fcmt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADJD", "PTKVZ", "PRF", "VVFIN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "So hat j\u00fcngst mich die erhabne", "tokens": ["So", "hat", "j\u00fcngst", "mich", "die", "er\u00b7hab\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PPER", "ART", "ADJA"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "M\u00e4nnin, Kord\u00e4 gelabt.", "tokens": ["M\u00e4n\u00b7nin", ",", "Kor\u00b7d\u00e4", "ge\u00b7labt", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VVPP", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.22": {"line.1": {"text": "Richter sch\u00e4ndeten sich, sprachen es los,", "tokens": ["Rich\u00b7ter", "sch\u00e4n\u00b7de\u00b7ten", "sich", ",", "spra\u00b7chen", "es", "los", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+---+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "'s Ungeheuer: sie sprach nicht los, und that,", "tokens": ["'s", "Un\u00b7ge\u00b7heu\u00b7er", ":", "sie", "sprach", "nicht", "los", ",", "und", "that", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$.", "PPER", "VVFIN", "PTKNEG", "PTKVZ", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Was mit Glut einst auf der Wange,", "tokens": ["Was", "mit", "Glut", "einst", "auf", "der", "Wan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Thr\u00e4nen, der Enkel erz\u00e4hlt.", "tokens": ["Thr\u00e4\u00b7nen", ",", "der", "En\u00b7kel", "er\u00b7z\u00e4hlt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}}}}