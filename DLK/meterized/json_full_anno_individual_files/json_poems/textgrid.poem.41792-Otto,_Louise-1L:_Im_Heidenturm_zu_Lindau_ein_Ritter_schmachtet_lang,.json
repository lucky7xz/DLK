{"textgrid.poem.41792": {"metadata": {"author": {"name": "Otto, Louise", "birth": "N.A.", "death": "N.A."}, "title": "1L: Im Heidenturm zu Lindau ein Ritter schmachtet lang,", "genre": "verse", "period": "N.A.", "pub_year": 1857, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Im Heidenturm zu Lindau ein Ritter schmachtet lang,", "tokens": ["Im", "Hei\u00b7den\u00b7turm", "zu", "Lin\u00b7dau", "ein", "Rit\u00b7ter", "schmach\u00b7tet", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Er ist verurteilt worden \u00bbzum Tode durch den Strang\u00ab", "tokens": ["Er", "ist", "ver\u00b7ur\u00b7teilt", "wor\u00b7den", "\u00bb", "zum", "To\u00b7de", "durch", "den", "Strang", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "VAPP", "$(", "APPRART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dieweil er st\u00fcrmend, raubend, frech durch das Land gezogen,", "tokens": ["Die\u00b7weil", "er", "st\u00fcr\u00b7mend", ",", "rau\u00b7bend", ",", "frech", "durch", "das", "Land", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "$,", "VVPP", "$,", "ADJD", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wild, wie sich oftmals heben des Bodans gr\u00fcne Wogen.", "tokens": ["Wild", ",", "wie", "sich", "oft\u00b7mals", "he\u00b7ben", "des", "Bo\u00b7dans", "gr\u00fc\u00b7ne", "Wo\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PRF", "ADV", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "+--+-+--+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.2": {"line.1": {"text": "Jetzt blickt er durch das Gitter, das ihm den Weg versperrt,", "tokens": ["Jetzt", "blickt", "er", "durch", "das", "Git\u00b7ter", ",", "das", "ihm", "den", "Weg", "ver\u00b7sperrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Dem stolzen edlen Ritter, dem wilden Kunibert.", "tokens": ["Dem", "stol\u00b7zen", "ed\u00b7len", "Rit\u00b7ter", ",", "dem", "wil\u00b7den", "Ku\u00b7ni\u00b7bert", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und wie zu seinen F\u00fc\u00dfen des Seees Fluten branden,", "tokens": ["Und", "wie", "zu", "sei\u00b7nen", "F\u00fc\u00b7\u00dfen", "des", "See\u00b7es", "Flu\u00b7ten", "bran\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPR", "PPOSAT", "NN", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So denkt er an die St\u00fcrme, die er einst selbst bestanden.", "tokens": ["So", "denkt", "er", "an", "die", "St\u00fcr\u00b7me", ",", "die", "er", "einst", "selbst", "be\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Er liebte eine Jungfrau, Mechthild ward sie genannt,", "tokens": ["Er", "lieb\u00b7te", "ei\u00b7ne", "Jung\u00b7frau", ",", "Mecht\u00b7hild", "ward", "sie", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "NE", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Doch ihres Vaters Strenge versagt' ihm ihre Hand \u2013", "tokens": ["Doch", "ih\u00b7res", "Va\u00b7ters", "Stren\u00b7ge", "ver\u00b7sagt'", "ihm", "ih\u00b7re", "Hand", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da wollte sie der Ritter sich mit Gewalt erringen,", "tokens": ["Da", "woll\u00b7te", "sie", "der", "Rit\u00b7ter", "sich", "mit", "Ge\u00b7walt", "er\u00b7rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Den Widerstand des Vaters im eignen Schlo\u00df bezwingen.", "tokens": ["Den", "Wi\u00b7der\u00b7stand", "des", "Va\u00b7ters", "im", "eig\u00b7nen", "Schlo\u00df", "be\u00b7zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Er zog vor seine Veste und nahm mit Sturm sie ein,", "tokens": ["Er", "zog", "vor", "sei\u00b7ne", "Ves\u00b7te", "und", "nahm", "mit", "Sturm", "sie", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "APPR", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Warf gier'ge Feuerbr\u00e4nde mit eigner Hand hinein,", "tokens": ["Warf", "gier'\u00b7ge", "Feu\u00b7er\u00b7br\u00e4n\u00b7de", "mit", "eig\u00b7ner", "Hand", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Den Vater der Geliebten erstach der wilde Freier, \u2013", "tokens": ["Den", "Va\u00b7ter", "der", "Ge\u00b7lieb\u00b7ten", "er\u00b7stach", "der", "wil\u00b7de", "Frei\u00b7er", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Doch sie entfloh ins Kloster und nahm den Nonnenschleier.", "tokens": ["Doch", "sie", "ent\u00b7floh", "ins", "Klos\u00b7ter", "und", "nahm", "den", "Non\u00b7nen\u00b7schlei\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Und nun im wilden Grimme, verzweifelnd sonder Rast,", "tokens": ["Und", "nun", "im", "wil\u00b7den", "Grim\u00b7me", ",", "ver\u00b7zwei\u00b7felnd", "son\u00b7der", "Rast", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN", "$,", "VVPP", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Erliegend seiner Thaten und seines Jammers Last,", "tokens": ["Er\u00b7lie\u00b7gend", "sei\u00b7ner", "Tha\u00b7ten", "und", "sei\u00b7nes", "Jam\u00b7mers", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sucht Kunibert Bet\u00e4ubung im K\u00e4mpfen, Rauben, Morden \u2013", "tokens": ["Sucht", "Ku\u00b7ni\u00b7bert", "Be\u00b7t\u00e4u\u00b7bung", "im", "K\u00e4mp\u00b7fen", ",", "Rau\u00b7ben", ",", "Mor\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "APPRART", "NN", "$,", "NN", "$,", "NN", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Nun ist in Kerkermauern ihm daf\u00fcr Lohn geworden.", "tokens": ["Nun", "ist", "in", "Ker\u00b7ker\u00b7mau\u00b7ern", "ihm", "da\u00b7f\u00fcr", "Lohn", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "PPER", "PAV", "NN", "VAPP", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Jetzt f\u00fchrt man ihn zum Richtplatz \u2013 der Henker steht bereit \u2013", "tokens": ["Jetzt", "f\u00fchrt", "man", "ihn", "zum", "Richt\u00b7platz", "\u2013", "der", "Hen\u00b7ker", "steht", "be\u00b7reit", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "APPRART", "NN", "$(", "ART", "NN", "VVFIN", "ADJD", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da naht Lindaus Aebtissin im wei\u00dfen Feierkleid.", "tokens": ["Da", "naht", "Lin\u00b7daus", "A\u00b7eb\u00b7tis\u00b7sin", "im", "wei\u00b7\u00dfen", "Fei\u00b7er\u00b7kleid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "--+--+-+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Die Menge sieht es staunend \u2013 \u00bbDas ist der Gnade Zeichen!\u00ab", "tokens": ["Die", "Men\u00b7ge", "sieht", "es", "stau\u00b7nend", "\u2013", "\u00bb", "Das", "ist", "der", "Gna\u00b7de", "Zei\u00b7chen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$(", "$(", "PDS", "VAFIN", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein donnernd \u00bbHoch!\u00ab dann wieder, ein ehrfurchtsvolles Schweigen.", "tokens": ["Ein", "don\u00b7nernd", "\u00bb", "Hoch", "!", "\u00ab", "dann", "wie\u00b7der", ",", "ein", "ehr\u00b7furchts\u00b7vol\u00b7les", "Schwei\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$(", "ADJD", "$.", "$(", "ADV", "ADV", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "Der Ritter sieht es staunend \u2013 der Henker h\u00e4lt den Strang \u2013", "tokens": ["Der", "Rit\u00b7ter", "sieht", "es", "stau\u00b7nend", "\u2013", "der", "Hen\u00b7ker", "h\u00e4lt", "den", "Strang", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$(", "ART", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Als ihren Dolch, den blanken, die hohe Nonne schwang.", "tokens": ["Als", "ih\u00b7ren", "Dolch", ",", "den", "blan\u00b7ken", ",", "die", "ho\u00b7he", "Non\u00b7ne", "schwang", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "ART", "ADJA", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie spricht: \u00bbDas Recht der Gnade, das einmal mir gegeben,", "tokens": ["Sie", "spricht", ":", "\u00bb", "Das", "Recht", "der", "Gna\u00b7de", ",", "das", "ein\u00b7mal", "mir", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ART", "NN", "ART", "NN", "$,", "PRELS", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ich darf es jetzt auch \u00fcben, ich weihe dich dem Leben!\u00ab \u2013", "tokens": ["Ich", "darf", "es", "jetzt", "auch", "\u00fc\u00b7ben", ",", "ich", "wei\u00b7he", "dich", "dem", "Le\u00b7ben", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,", "PPER", "VVFIN", "PRF", "ART", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "\u00bbo wi\u00dft Ihr, hohe Fraue, wie Schweres er verbrach?\u00ab", "tokens": ["\u00bb", "o", "wi\u00dft", "Ihr", ",", "ho\u00b7he", "Frau\u00b7e", ",", "wie", "Schwe\u00b7res", "er", "ver\u00b7brach", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,", "PWAV", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Henker zur Aebtissin mit grimmen Blicken sprach.", "tokens": ["Der", "Hen\u00b7ker", "zur", "A\u00b7eb\u00b7tis\u00b7sin", "mit", "grim\u00b7men", "Bli\u00b7cken", "sprach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Sie l\u00e4chelt stolz und ruhig und hat den Strang zerschnitten:", "tokens": ["Sie", "l\u00e4\u00b7chelt", "stolz", "und", "ru\u00b7hig", "und", "hat", "den", "Strang", "zer\u00b7schnit\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "KON", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbich hab f\u00fcr ihn geb\u00fc\u00dfet, ich hab f\u00fcr ihn gelitten!\u00ab", "tokens": ["\u00bb", "ich", "hab", "f\u00fcr", "ihn", "ge\u00b7b\u00fc\u00b7\u00dfet", ",", "ich", "hab", "f\u00fcr", "ihn", "ge\u00b7lit\u00b7ten", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "APPR", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "\u00bbein Zeichen, da\u00df der Himmel dir Deine Schuld vergiebt,", "tokens": ["\u00bb", "ein", "Zei\u00b7chen", ",", "da\u00df", "der", "Him\u00b7mel", "dir", "Dei\u00b7ne", "Schuld", "ver\u00b7giebt", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "KOUS", "ART", "NN", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da\u00df ich Dir darf vergeben, was B\u00f6ses Du ver\u00fcbt\u00ab \u2013", "tokens": ["Da\u00df", "ich", "Dir", "darf", "ver\u00b7ge\u00b7ben", ",", "was", "B\u00f6\u00b7ses", "Du", "ver\u00b7\u00fcbt", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "VMFIN", "VVPP", "$,", "PWS", "NN", "PPER", "VVFIN", "$(", "$("], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Und Kunibert erzittert vor ihre Blicke Leuchten,", "tokens": ["Und", "Ku\u00b7ni\u00b7bert", "er\u00b7zit\u00b7tert", "vor", "ih\u00b7re", "Bli\u00b7cke", "Leuch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Zum ersten mal im Leben sich seine Wangen feuchten.", "tokens": ["Zum", "ers\u00b7ten", "mal", "im", "Le\u00b7ben", "sich", "sei\u00b7ne", "Wan\u00b7gen", "feuch\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "APPRART", "NN", "PRF", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "\u00bbmechthilde!\u00ab ruft er bebend und hat die Maid erkannt,", "tokens": ["\u00bb", "mecht\u00b7hil\u00b7de", "!", "\u00ab", "ruft", "er", "be\u00b7bend", "und", "hat", "die", "Maid", "er\u00b7kannt", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$.", "$(", "VVFIN", "PPER", "VVPP", "KON", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+----+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Zu der in Liebesflammen er gl\u00fchend einst entbrannt.", "tokens": ["Zu", "der", "in", "Lie\u00b7bes\u00b7flam\u00b7men", "er", "gl\u00fc\u00b7hend", "einst", "ent\u00b7brannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPR", "NN", "PPER", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und ihre Hand ruht segnend auf des Verbrechers Stirne \u2013", "tokens": ["Und", "ih\u00b7re", "Hand", "ruht", "seg\u00b7nend", "auf", "des", "Ver\u00b7bre\u00b7chers", "Stir\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So ruht die Sonne freudig auf hoher Alpen Firne.", "tokens": ["So", "ruht", "die", "Son\u00b7ne", "freu\u00b7dig", "auf", "ho\u00b7her", "Al\u00b7pen", "Fir\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.11": {"line.1": {"text": "\u00bbich bin es!\u00ab spricht sie milde und schaut ihn ruhig an,", "tokens": ["\u00bb", "ich", "bin", "es", "!", "\u00ab", "spricht", "sie", "mil\u00b7de", "und", "schaut", "ihn", "ru\u00b7hig", "an", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "$.", "$(", "VVFIN", "PPER", "ADJD", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So wie das Mondlicht scheinet, auf w\u00fcste Felsenbahn.", "tokens": ["So", "wie", "das", "Mond\u00b7licht", "schei\u00b7net", ",", "auf", "w\u00fcs\u00b7te", "Fel\u00b7sen\u00b7bahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "VVFIN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er ruft zu ihren F\u00fc\u00dfen: \u00bb", "tokens": ["Er", "ruft", "zu", "ih\u00b7ren", "F\u00fc\u00b7\u00dfen", ":", "\u00bb"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da eine Heil'ge nahte, mir Gnade zu verk\u00fcnden.\u00ab \u2013", "tokens": ["Da", "ei\u00b7ne", "Heil'\u00b7ge", "nah\u00b7te", ",", "mir", "Gna\u00b7de", "zu", "ver\u00b7k\u00fcn\u00b7den", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,", "PPER", "NN", "PTKZU", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.12": {"line.1": {"text": "Ein neues Kloster steiget am Bodan bald empor,", "tokens": ["Ein", "neu\u00b7es", "Klos\u00b7ter", "stei\u00b7get", "am", "Bo\u00b7dan", "bald", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPRART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das Kunibert erbaute und sich zur Wohnung kor. \u2013", "tokens": ["Das", "Ku\u00b7ni\u00b7bert", "er\u00b7bau\u00b7te", "und", "sich", "zur", "Woh\u00b7nung", "kor", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADJA", "KON", "PRF", "APPRART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die Liebe, die ihn einstens den Pfad der Schuld getrieben", "tokens": ["Die", "Lie\u00b7be", ",", "die", "ihn", "eins\u00b7tens", "den", "Pfad", "der", "Schuld", "ge\u00b7trie\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "ART", "NN", "ART", "NN", "VVPP"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die hat ihn auch erl\u00f6set, durch eines Weibes Lieben.", "tokens": ["Die", "hat", "ihn", "auch", "er\u00b7l\u00f6\u00b7set", ",", "durch", "ei\u00b7nes", "Wei\u00b7bes", "Lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVFIN", "$,", "APPR", "ART", "NN", "ADJA", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "Im Heidenturm zu Lindau ein Ritter schmachtet lang,", "tokens": ["Im", "Hei\u00b7den\u00b7turm", "zu", "Lin\u00b7dau", "ein", "Rit\u00b7ter", "schmach\u00b7tet", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Er ist verurteilt worden \u00bbzum Tode durch den Strang\u00ab", "tokens": ["Er", "ist", "ver\u00b7ur\u00b7teilt", "wor\u00b7den", "\u00bb", "zum", "To\u00b7de", "durch", "den", "Strang", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "VAPP", "$(", "APPRART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dieweil er st\u00fcrmend, raubend, frech durch das Land gezogen,", "tokens": ["Die\u00b7weil", "er", "st\u00fcr\u00b7mend", ",", "rau\u00b7bend", ",", "frech", "durch", "das", "Land", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "$,", "VVPP", "$,", "ADJD", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wild, wie sich oftmals heben des Bodans gr\u00fcne Wogen.", "tokens": ["Wild", ",", "wie", "sich", "oft\u00b7mals", "he\u00b7ben", "des", "Bo\u00b7dans", "gr\u00fc\u00b7ne", "Wo\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PRF", "ADV", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "+--+-+--+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.14": {"line.1": {"text": "Jetzt blickt er durch das Gitter, das ihm den Weg versperrt,", "tokens": ["Jetzt", "blickt", "er", "durch", "das", "Git\u00b7ter", ",", "das", "ihm", "den", "Weg", "ver\u00b7sperrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Dem stolzen edlen Ritter, dem wilden Kunibert.", "tokens": ["Dem", "stol\u00b7zen", "ed\u00b7len", "Rit\u00b7ter", ",", "dem", "wil\u00b7den", "Ku\u00b7ni\u00b7bert", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und wie zu seinen F\u00fc\u00dfen des Seees Fluten branden,", "tokens": ["Und", "wie", "zu", "sei\u00b7nen", "F\u00fc\u00b7\u00dfen", "des", "See\u00b7es", "Flu\u00b7ten", "bran\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPR", "PPOSAT", "NN", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So denkt er an die St\u00fcrme, die er einst selbst bestanden.", "tokens": ["So", "denkt", "er", "an", "die", "St\u00fcr\u00b7me", ",", "die", "er", "einst", "selbst", "be\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.15": {"line.1": {"text": "Er liebte eine Jungfrau, Mechthild ward sie genannt,", "tokens": ["Er", "lieb\u00b7te", "ei\u00b7ne", "Jung\u00b7frau", ",", "Mecht\u00b7hild", "ward", "sie", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "NE", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Doch ihres Vaters Strenge versagt' ihm ihre Hand \u2013", "tokens": ["Doch", "ih\u00b7res", "Va\u00b7ters", "Stren\u00b7ge", "ver\u00b7sagt'", "ihm", "ih\u00b7re", "Hand", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da wollte sie der Ritter sich mit Gewalt erringen,", "tokens": ["Da", "woll\u00b7te", "sie", "der", "Rit\u00b7ter", "sich", "mit", "Ge\u00b7walt", "er\u00b7rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Den Widerstand des Vaters im eignen Schlo\u00df bezwingen.", "tokens": ["Den", "Wi\u00b7der\u00b7stand", "des", "Va\u00b7ters", "im", "eig\u00b7nen", "Schlo\u00df", "be\u00b7zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "Er zog vor seine Veste und nahm mit Sturm sie ein,", "tokens": ["Er", "zog", "vor", "sei\u00b7ne", "Ves\u00b7te", "und", "nahm", "mit", "Sturm", "sie", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "APPR", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Warf gier'ge Feuerbr\u00e4nde mit eigner Hand hinein,", "tokens": ["Warf", "gier'\u00b7ge", "Feu\u00b7er\u00b7br\u00e4n\u00b7de", "mit", "eig\u00b7ner", "Hand", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Den Vater der Geliebten erstach der wilde Freier, \u2013", "tokens": ["Den", "Va\u00b7ter", "der", "Ge\u00b7lieb\u00b7ten", "er\u00b7stach", "der", "wil\u00b7de", "Frei\u00b7er", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Doch sie entfloh ins Kloster und nahm den Nonnenschleier.", "tokens": ["Doch", "sie", "ent\u00b7floh", "ins", "Klos\u00b7ter", "und", "nahm", "den", "Non\u00b7nen\u00b7schlei\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.17": {"line.1": {"text": "Und nun im wilden Grimme, verzweifelnd sonder Rast,", "tokens": ["Und", "nun", "im", "wil\u00b7den", "Grim\u00b7me", ",", "ver\u00b7zwei\u00b7felnd", "son\u00b7der", "Rast", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN", "$,", "VVPP", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Erliegend seiner Thaten und seines Jammers Last,", "tokens": ["Er\u00b7lie\u00b7gend", "sei\u00b7ner", "Tha\u00b7ten", "und", "sei\u00b7nes", "Jam\u00b7mers", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sucht Kunibert Bet\u00e4ubung im K\u00e4mpfen, Rauben, Morden \u2013", "tokens": ["Sucht", "Ku\u00b7ni\u00b7bert", "Be\u00b7t\u00e4u\u00b7bung", "im", "K\u00e4mp\u00b7fen", ",", "Rau\u00b7ben", ",", "Mor\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "APPRART", "NN", "$,", "NN", "$,", "NN", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Nun ist in Kerkermauern ihm daf\u00fcr Lohn geworden.", "tokens": ["Nun", "ist", "in", "Ker\u00b7ker\u00b7mau\u00b7ern", "ihm", "da\u00b7f\u00fcr", "Lohn", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "PPER", "PAV", "NN", "VAPP", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.18": {"line.1": {"text": "Jetzt f\u00fchrt man ihn zum Richtplatz \u2013 der Henker steht bereit \u2013", "tokens": ["Jetzt", "f\u00fchrt", "man", "ihn", "zum", "Richt\u00b7platz", "\u2013", "der", "Hen\u00b7ker", "steht", "be\u00b7reit", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "APPRART", "NN", "$(", "ART", "NN", "VVFIN", "ADJD", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da naht Lindaus Aebtissin im wei\u00dfen Feierkleid.", "tokens": ["Da", "naht", "Lin\u00b7daus", "A\u00b7eb\u00b7tis\u00b7sin", "im", "wei\u00b7\u00dfen", "Fei\u00b7er\u00b7kleid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "--+--+-+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Die Menge sieht es staunend \u2013 \u00bbDas ist der Gnade Zeichen!\u00ab", "tokens": ["Die", "Men\u00b7ge", "sieht", "es", "stau\u00b7nend", "\u2013", "\u00bb", "Das", "ist", "der", "Gna\u00b7de", "Zei\u00b7chen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$(", "$(", "PDS", "VAFIN", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein donnernd \u00bbHoch!\u00ab dann wieder, ein ehrfurchtsvolles Schweigen.", "tokens": ["Ein", "don\u00b7nernd", "\u00bb", "Hoch", "!", "\u00ab", "dann", "wie\u00b7der", ",", "ein", "ehr\u00b7furchts\u00b7vol\u00b7les", "Schwei\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$(", "ADJD", "$.", "$(", "ADV", "ADV", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.19": {"line.1": {"text": "Der Ritter sieht es staunend \u2013 der Henker h\u00e4lt den Strang \u2013", "tokens": ["Der", "Rit\u00b7ter", "sieht", "es", "stau\u00b7nend", "\u2013", "der", "Hen\u00b7ker", "h\u00e4lt", "den", "Strang", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$(", "ART", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Als ihren Dolch, den blanken, die hohe Nonne schwang.", "tokens": ["Als", "ih\u00b7ren", "Dolch", ",", "den", "blan\u00b7ken", ",", "die", "ho\u00b7he", "Non\u00b7ne", "schwang", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "ART", "ADJA", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie spricht: \u00bbDas Recht der Gnade, das einmal mir gegeben,", "tokens": ["Sie", "spricht", ":", "\u00bb", "Das", "Recht", "der", "Gna\u00b7de", ",", "das", "ein\u00b7mal", "mir", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ART", "NN", "ART", "NN", "$,", "PRELS", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ich darf es jetzt auch \u00fcben, ich weihe dich dem Leben!\u00ab \u2013", "tokens": ["Ich", "darf", "es", "jetzt", "auch", "\u00fc\u00b7ben", ",", "ich", "wei\u00b7he", "dich", "dem", "Le\u00b7ben", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,", "PPER", "VVFIN", "PRF", "ART", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.20": {"line.1": {"text": "\u00bbo wi\u00dft Ihr, hohe Fraue, wie Schweres er verbrach?\u00ab", "tokens": ["\u00bb", "o", "wi\u00dft", "Ihr", ",", "ho\u00b7he", "Frau\u00b7e", ",", "wie", "Schwe\u00b7res", "er", "ver\u00b7brach", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,", "PWAV", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Henker zur Aebtissin mit grimmen Blicken sprach.", "tokens": ["Der", "Hen\u00b7ker", "zur", "A\u00b7eb\u00b7tis\u00b7sin", "mit", "grim\u00b7men", "Bli\u00b7cken", "sprach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Sie l\u00e4chelt stolz und ruhig und hat den Strang zerschnitten:", "tokens": ["Sie", "l\u00e4\u00b7chelt", "stolz", "und", "ru\u00b7hig", "und", "hat", "den", "Strang", "zer\u00b7schnit\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "KON", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbich hab f\u00fcr ihn geb\u00fc\u00dfet, ich hab f\u00fcr ihn gelitten!\u00ab", "tokens": ["\u00bb", "ich", "hab", "f\u00fcr", "ihn", "ge\u00b7b\u00fc\u00b7\u00dfet", ",", "ich", "hab", "f\u00fcr", "ihn", "ge\u00b7lit\u00b7ten", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "APPR", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.21": {"line.1": {"text": "\u00bbein Zeichen, da\u00df der Himmel dir Deine Schuld vergiebt,", "tokens": ["\u00bb", "ein", "Zei\u00b7chen", ",", "da\u00df", "der", "Him\u00b7mel", "dir", "Dei\u00b7ne", "Schuld", "ver\u00b7giebt", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "KOUS", "ART", "NN", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da\u00df ich Dir darf vergeben, was B\u00f6ses Du ver\u00fcbt\u00ab \u2013", "tokens": ["Da\u00df", "ich", "Dir", "darf", "ver\u00b7ge\u00b7ben", ",", "was", "B\u00f6\u00b7ses", "Du", "ver\u00b7\u00fcbt", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "VMFIN", "VVPP", "$,", "PWS", "NN", "PPER", "VVFIN", "$(", "$("], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Und Kunibert erzittert vor ihre Blicke Leuchten,", "tokens": ["Und", "Ku\u00b7ni\u00b7bert", "er\u00b7zit\u00b7tert", "vor", "ih\u00b7re", "Bli\u00b7cke", "Leuch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Zum ersten mal im Leben sich seine Wangen feuchten.", "tokens": ["Zum", "ers\u00b7ten", "mal", "im", "Le\u00b7ben", "sich", "sei\u00b7ne", "Wan\u00b7gen", "feuch\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "APPRART", "NN", "PRF", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.22": {"line.1": {"text": "\u00bbmechthilde!\u00ab ruft er bebend und hat die Maid erkannt,", "tokens": ["\u00bb", "mecht\u00b7hil\u00b7de", "!", "\u00ab", "ruft", "er", "be\u00b7bend", "und", "hat", "die", "Maid", "er\u00b7kannt", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$.", "$(", "VVFIN", "PPER", "VVPP", "KON", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+----+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Zu der in Liebesflammen er gl\u00fchend einst entbrannt.", "tokens": ["Zu", "der", "in", "Lie\u00b7bes\u00b7flam\u00b7men", "er", "gl\u00fc\u00b7hend", "einst", "ent\u00b7brannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPR", "NN", "PPER", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und ihre Hand ruht segnend auf des Verbrechers Stirne \u2013", "tokens": ["Und", "ih\u00b7re", "Hand", "ruht", "seg\u00b7nend", "auf", "des", "Ver\u00b7bre\u00b7chers", "Stir\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So ruht die Sonne freudig auf hoher Alpen Firne.", "tokens": ["So", "ruht", "die", "Son\u00b7ne", "freu\u00b7dig", "auf", "ho\u00b7her", "Al\u00b7pen", "Fir\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.23": {"line.1": {"text": "\u00bbich bin es!\u00ab spricht sie milde und schaut ihn ruhig an,", "tokens": ["\u00bb", "ich", "bin", "es", "!", "\u00ab", "spricht", "sie", "mil\u00b7de", "und", "schaut", "ihn", "ru\u00b7hig", "an", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "$.", "$(", "VVFIN", "PPER", "ADJD", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So wie das Mondlicht scheinet, auf w\u00fcste Felsenbahn.", "tokens": ["So", "wie", "das", "Mond\u00b7licht", "schei\u00b7net", ",", "auf", "w\u00fcs\u00b7te", "Fel\u00b7sen\u00b7bahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "VVFIN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er ruft zu ihren F\u00fc\u00dfen: \u00bb", "tokens": ["Er", "ruft", "zu", "ih\u00b7ren", "F\u00fc\u00b7\u00dfen", ":", "\u00bb"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da eine Heil'ge nahte, mir Gnade zu verk\u00fcnden.\u00ab \u2013", "tokens": ["Da", "ei\u00b7ne", "Heil'\u00b7ge", "nah\u00b7te", ",", "mir", "Gna\u00b7de", "zu", "ver\u00b7k\u00fcn\u00b7den", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,", "PPER", "NN", "PTKZU", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.24": {"line.1": {"text": "Ein neues Kloster steiget am Bodan bald empor,", "tokens": ["Ein", "neu\u00b7es", "Klos\u00b7ter", "stei\u00b7get", "am", "Bo\u00b7dan", "bald", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPRART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das Kunibert erbaute und sich zur Wohnung kor. \u2013", "tokens": ["Das", "Ku\u00b7ni\u00b7bert", "er\u00b7bau\u00b7te", "und", "sich", "zur", "Woh\u00b7nung", "kor", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADJA", "KON", "PRF", "APPRART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die Liebe, die ihn einstens den Pfad der Schuld getrieben", "tokens": ["Die", "Lie\u00b7be", ",", "die", "ihn", "eins\u00b7tens", "den", "Pfad", "der", "Schuld", "ge\u00b7trie\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "ART", "NN", "ART", "NN", "VVPP"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die hat ihn auch erl\u00f6set, durch eines Weibes Lieben.", "tokens": ["Die", "hat", "ihn", "auch", "er\u00b7l\u00f6\u00b7set", ",", "durch", "ei\u00b7nes", "Wei\u00b7bes", "Lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVFIN", "$,", "APPR", "ART", "NN", "ADJA", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}}}}