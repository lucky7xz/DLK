{"textgrid.poem.32320": {"metadata": {"author": {"name": "Lessing, Gotthold Ephraim", "birth": "N.A.", "death": "N.A."}, "title": "6. Der Eintritt des Jahres 1753 in Berlin", "genre": "verse", "period": "N.A.", "pub_year": 1755, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie zaudernd ungern sich die Jahre trennen mochten,", "tokens": ["Wie", "zau\u00b7dernd", "un\u00b7gern", "sich", "die", "Jah\u00b7re", "tren\u00b7nen", "moch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADV", "PRF", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die eine G\u00f6tterhand", "tokens": ["Die", "ei\u00b7ne", "G\u00f6t\u00b7ter\u00b7hand"], "token_info": ["word", "word", "word"], "pos": ["ART", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Durch Kr\u00e4nze mancher Art, mit Pracht und Scherz durchflochten,", "tokens": ["Durch", "Kr\u00e4n\u00b7ze", "man\u00b7cher", "Art", ",", "mit", "Pracht", "und", "Scherz", "durch\u00b7floch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PIAT", "NN", "$,", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Uns in einander wand!", "tokens": ["Uns", "in", "ein\u00b7an\u00b7der", "wand", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "So tr\u00e4g, als h\u00fcbe sich ein Adler in die L\u00fcfte,", "tokens": ["So", "tr\u00e4g", ",", "als", "h\u00fc\u00b7be", "sich", "ein", "Ad\u00b7ler", "in", "die", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADJA", "PRF", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den man vom Raube scheucht:", "tokens": ["Den", "man", "vom", "Rau\u00b7be", "scheucht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Noch schwebt er dr\u00fcber her, und witternd fette D\u00fcfte,", "tokens": ["Noch", "schwebt", "er", "dr\u00fc\u00b7ber", "her", ",", "und", "wit\u00b7ternd", "fet\u00b7te", "D\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "PTKVZ", "$,", "KON", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Entflieht er minder leicht.", "tokens": ["Ent\u00b7flieht", "er", "min\u00b7der", "leicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Welch langsam Ph\u00e4nomen durchstreicht des \u00c4thers Wogen,", "tokens": ["Welch", "lang\u00b7sam", "Ph\u00e4\u00b7no\u00b7men", "durch\u00b7streicht", "des", "\u00c4\u00b7thers", "Wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Dort wo Saturn gebeut?", "tokens": ["Dort", "wo", "Sa\u00b7turn", "ge\u00b7beut", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ist es? Es ists, das Jahr, das reuend uns entflogen,", "tokens": ["Ist", "es", "?", "Es", "ists", ",", "das", "Jahr", ",", "das", "reu\u00b7end", "uns", "ent\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$.", "PPER", "VAFIN", "$,", "ART", "NN", "$,", "PRELS", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es fliegt zur Ewigkeit.", "tokens": ["Es", "fliegt", "zur", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Das reuend uns entflog, Dir ", "tokens": ["Das", "reu\u00b7end", "uns", "ent\u00b7flog", ",", "Dir"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "ADJD", "PPER", "VVFIN", "$,", "PPER"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Kein S\u00e4kulum zu sein;", "tokens": ["Kein", "S\u00e4\u00b7ku\u00b7lum", "zu", "sein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit Deinem ganzen Ruhm belastet fort zu gehen,", "tokens": ["Mit", "Dei\u00b7nem", "gan\u00b7zen", "Ruhm", "be\u00b7las\u00b7tet", "fort", "zu", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sich der Last zu freun.", "tokens": ["Und", "sich", "der", "Last", "zu", "freun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Noch oft soll manches Jahr so traurig von uns fliegen,", "tokens": ["Noch", "oft", "soll", "man\u00b7ches", "Jahr", "so", "trau\u00b7rig", "von", "uns", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PIAT", "NN", "ADV", "ADJD", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch oft, zu unserm Gl\u00fcck.", "tokens": ["Noch", "oft", ",", "zu", "un\u00b7serm", "Gl\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vom Himmel bist Du, Herr, zu uns herabgestiegen;", "tokens": ["Vom", "Him\u00b7mel", "bist", "Du", ",", "Herr", ",", "zu", "uns", "her\u00b7ab\u00b7ge\u00b7stie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "$,", "NN", "$,", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kehr' sp\u00e4t! kehr' sp\u00e4t zur\u00fcck!", "tokens": ["Kehr'", "sp\u00e4t", "!", "kehr'", "sp\u00e4t", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$.", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "La\u00df Dich noch lange, Herr, den Namen ", "tokens": ["La\u00df", "Dich", "noch", "lan\u00b7ge", ",", "Herr", ",", "den", "Na\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "$,", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und den: ", "tokens": ["Und", "den", ":"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ART", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Dort wird der Himmel zwar nach seiner Zierde geizen;", "tokens": ["Dort", "wird", "der", "Him\u00b7mel", "zwar", "nach", "sei\u00b7ner", "Zier\u00b7de", "gei\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch hier braucht Dich die Welt.", "tokens": ["Doch", "hier", "braucht", "Dich", "die", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Noch seh' ich mich f\u00fcr Dich mit raschen Richteraugen", "tokens": ["Noch", "seh'", "ich", "mich", "f\u00fcr", "Dich", "mit", "ra\u00b7schen", "Rich\u00b7ter\u00b7au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nach einem Dichter um.", "tokens": ["Nach", "ei\u00b7nem", "Dich\u00b7ter", "um", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dort einer! hier und da! Sie taugen viel, und taugen", "tokens": ["Dort", "ei\u00b7ner", "!", "hier", "und", "da", "!", "Sie", "tau\u00b7gen", "viel", ",", "und", "tau\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ART", "$.", "ADV", "KON", "ADV", "$.", "PPER", "VVFIN", "ADV", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch nichts f\u00fcr Deinen Ruhm.", "tokens": ["Doch", "nichts", "f\u00fcr", "Dei\u00b7nen", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ist er nicht etwa schon, und singt noch wenig Ohren,", "tokens": ["Ist", "er", "nicht", "et\u00b7wa", "schon", ",", "und", "singt", "noch", "we\u00b7nig", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ADV", "$,", "KON", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil er die Kr\u00e4fte wiegt:", "tokens": ["Weil", "er", "die", "Kr\u00e4f\u00b7te", "wiegt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So werd' er dieses Jahr, der seltne Geist, geboren,", "tokens": ["So", "werd'", "er", "die\u00b7ses", "Jahr", ",", "der", "selt\u00b7ne", "Geist", ",", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDAT", "NN", "$,", "ART", "ADJA", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der diesen Kranz erfliegt.", "tokens": ["Der", "die\u00b7sen", "Kranz", "er\u00b7fliegt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wenn er der Mutter dann sich leicht vom Herzen windet,", "tokens": ["Wenn", "er", "der", "Mut\u00b7ter", "dann", "sich", "leicht", "vom", "Her\u00b7zen", "win\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "PRF", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O Muse, lach' ihn an!", "tokens": ["O", "Mu\u00b7se", ",", "lach'", "ihn", "an", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Damit er Feur und Witz dem Edelmut verbindet,", "tokens": ["Da\u00b7mit", "er", "Feur", "und", "Witz", "dem", "E\u00b7del\u00b7mut", "ver\u00b7bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Poet und Biedermann.", "tokens": ["Po\u00b7et", "und", "Bie\u00b7der\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "H\u00f6rt! oder t\u00e4uschen mich beliebte Rasereien?", "tokens": ["H\u00f6rt", "!", "o\u00b7der", "t\u00e4u\u00b7schen", "mich", "be\u00b7lieb\u00b7te", "Ra\u00b7se\u00b7rei\u00b7en", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "KON", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nein, nein, ich h\u00f6r' ihn schon.", "tokens": ["Nein", ",", "nein", ",", "ich", "h\u00f6r'", "ihn", "schon", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Heere ziehend L\u00e4rm sind seine Melodeien,", "tokens": ["Der", "Hee\u00b7re", "zie\u00b7hend", "L\u00e4rm", "sind", "sei\u00b7ne", "Me\u00b7lo\u00b7dei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.11": {"line.1": {"text": "Wie zaudernd ungern sich die Jahre trennen mochten,", "tokens": ["Wie", "zau\u00b7dernd", "un\u00b7gern", "sich", "die", "Jah\u00b7re", "tren\u00b7nen", "moch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADV", "PRF", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die eine G\u00f6tterhand", "tokens": ["Die", "ei\u00b7ne", "G\u00f6t\u00b7ter\u00b7hand"], "token_info": ["word", "word", "word"], "pos": ["ART", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Durch Kr\u00e4nze mancher Art, mit Pracht und Scherz durchflochten,", "tokens": ["Durch", "Kr\u00e4n\u00b7ze", "man\u00b7cher", "Art", ",", "mit", "Pracht", "und", "Scherz", "durch\u00b7floch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PIAT", "NN", "$,", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Uns in einander wand!", "tokens": ["Uns", "in", "ein\u00b7an\u00b7der", "wand", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "So tr\u00e4g, als h\u00fcbe sich ein Adler in die L\u00fcfte,", "tokens": ["So", "tr\u00e4g", ",", "als", "h\u00fc\u00b7be", "sich", "ein", "Ad\u00b7ler", "in", "die", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADJA", "PRF", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den man vom Raube scheucht:", "tokens": ["Den", "man", "vom", "Rau\u00b7be", "scheucht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Noch schwebt er dr\u00fcber her, und witternd fette D\u00fcfte,", "tokens": ["Noch", "schwebt", "er", "dr\u00fc\u00b7ber", "her", ",", "und", "wit\u00b7ternd", "fet\u00b7te", "D\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "PTKVZ", "$,", "KON", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Entflieht er minder leicht.", "tokens": ["Ent\u00b7flieht", "er", "min\u00b7der", "leicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Welch langsam Ph\u00e4nomen durchstreicht des \u00c4thers Wogen,", "tokens": ["Welch", "lang\u00b7sam", "Ph\u00e4\u00b7no\u00b7men", "durch\u00b7streicht", "des", "\u00c4\u00b7thers", "Wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Dort wo Saturn gebeut?", "tokens": ["Dort", "wo", "Sa\u00b7turn", "ge\u00b7beut", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ist es? Es ists, das Jahr, das reuend uns entflogen,", "tokens": ["Ist", "es", "?", "Es", "ists", ",", "das", "Jahr", ",", "das", "reu\u00b7end", "uns", "ent\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$.", "PPER", "VAFIN", "$,", "ART", "NN", "$,", "PRELS", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es fliegt zur Ewigkeit.", "tokens": ["Es", "fliegt", "zur", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Das reuend uns entflog, Dir ", "tokens": ["Das", "reu\u00b7end", "uns", "ent\u00b7flog", ",", "Dir"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "ADJD", "PPER", "VVFIN", "$,", "PPER"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Kein S\u00e4kulum zu sein;", "tokens": ["Kein", "S\u00e4\u00b7ku\u00b7lum", "zu", "sein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit Deinem ganzen Ruhm belastet fort zu gehen,", "tokens": ["Mit", "Dei\u00b7nem", "gan\u00b7zen", "Ruhm", "be\u00b7las\u00b7tet", "fort", "zu", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sich der Last zu freun.", "tokens": ["Und", "sich", "der", "Last", "zu", "freun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Noch oft soll manches Jahr so traurig von uns fliegen,", "tokens": ["Noch", "oft", "soll", "man\u00b7ches", "Jahr", "so", "trau\u00b7rig", "von", "uns", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PIAT", "NN", "ADV", "ADJD", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch oft, zu unserm Gl\u00fcck.", "tokens": ["Noch", "oft", ",", "zu", "un\u00b7serm", "Gl\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vom Himmel bist Du, Herr, zu uns herabgestiegen;", "tokens": ["Vom", "Him\u00b7mel", "bist", "Du", ",", "Herr", ",", "zu", "uns", "her\u00b7ab\u00b7ge\u00b7stie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "$,", "NN", "$,", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kehr' sp\u00e4t! kehr' sp\u00e4t zur\u00fcck!", "tokens": ["Kehr'", "sp\u00e4t", "!", "kehr'", "sp\u00e4t", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$.", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "La\u00df Dich noch lange, Herr, den Namen ", "tokens": ["La\u00df", "Dich", "noch", "lan\u00b7ge", ",", "Herr", ",", "den", "Na\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "$,", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und den: ", "tokens": ["Und", "den", ":"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ART", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Dort wird der Himmel zwar nach seiner Zierde geizen;", "tokens": ["Dort", "wird", "der", "Him\u00b7mel", "zwar", "nach", "sei\u00b7ner", "Zier\u00b7de", "gei\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch hier braucht Dich die Welt.", "tokens": ["Doch", "hier", "braucht", "Dich", "die", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Noch seh' ich mich f\u00fcr Dich mit raschen Richteraugen", "tokens": ["Noch", "seh'", "ich", "mich", "f\u00fcr", "Dich", "mit", "ra\u00b7schen", "Rich\u00b7ter\u00b7au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nach einem Dichter um.", "tokens": ["Nach", "ei\u00b7nem", "Dich\u00b7ter", "um", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dort einer! hier und da! Sie taugen viel, und taugen", "tokens": ["Dort", "ei\u00b7ner", "!", "hier", "und", "da", "!", "Sie", "tau\u00b7gen", "viel", ",", "und", "tau\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ART", "$.", "ADV", "KON", "ADV", "$.", "PPER", "VVFIN", "ADV", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch nichts f\u00fcr Deinen Ruhm.", "tokens": ["Doch", "nichts", "f\u00fcr", "Dei\u00b7nen", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Ist er nicht etwa schon, und singt noch wenig Ohren,", "tokens": ["Ist", "er", "nicht", "et\u00b7wa", "schon", ",", "und", "singt", "noch", "we\u00b7nig", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ADV", "$,", "KON", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil er die Kr\u00e4fte wiegt:", "tokens": ["Weil", "er", "die", "Kr\u00e4f\u00b7te", "wiegt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So werd' er dieses Jahr, der seltne Geist, geboren,", "tokens": ["So", "werd'", "er", "die\u00b7ses", "Jahr", ",", "der", "selt\u00b7ne", "Geist", ",", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDAT", "NN", "$,", "ART", "ADJA", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der diesen Kranz erfliegt.", "tokens": ["Der", "die\u00b7sen", "Kranz", "er\u00b7fliegt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Wenn er der Mutter dann sich leicht vom Herzen windet,", "tokens": ["Wenn", "er", "der", "Mut\u00b7ter", "dann", "sich", "leicht", "vom", "Her\u00b7zen", "win\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "PRF", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O Muse, lach' ihn an!", "tokens": ["O", "Mu\u00b7se", ",", "lach'", "ihn", "an", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Damit er Feur und Witz dem Edelmut verbindet,", "tokens": ["Da\u00b7mit", "er", "Feur", "und", "Witz", "dem", "E\u00b7del\u00b7mut", "ver\u00b7bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Poet und Biedermann.", "tokens": ["Po\u00b7et", "und", "Bie\u00b7der\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "H\u00f6rt! oder t\u00e4uschen mich beliebte Rasereien?", "tokens": ["H\u00f6rt", "!", "o\u00b7der", "t\u00e4u\u00b7schen", "mich", "be\u00b7lieb\u00b7te", "Ra\u00b7se\u00b7rei\u00b7en", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "KON", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nein, nein, ich h\u00f6r' ihn schon.", "tokens": ["Nein", ",", "nein", ",", "ich", "h\u00f6r'", "ihn", "schon", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Heere ziehend L\u00e4rm sind seine Melodeien,", "tokens": ["Der", "Hee\u00b7re", "zie\u00b7hend", "L\u00e4rm", "sind", "sei\u00b7ne", "Me\u00b7lo\u00b7dei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}}}}