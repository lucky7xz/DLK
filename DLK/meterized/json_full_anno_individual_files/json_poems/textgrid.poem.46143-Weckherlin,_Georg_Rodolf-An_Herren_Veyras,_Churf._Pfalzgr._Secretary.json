{"textgrid.poem.46143": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "An Herren Veyras, Churf. Pfalzgr. Secretary", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dein lob, so ich zu aller stund", "tokens": ["Dein", "lob", ",", "so", "ich", "zu", "al\u00b7ler", "stund"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ADV", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von manchem lobbewehrten mund,", "tokens": ["von", "man\u00b7chem", "lob\u00b7be\u00b7wehr\u00b7ten", "mund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mein Veyras, williglich vernommen,", "tokens": ["mein", "Vey\u00b7ras", ",", "wil\u00b7lig\u00b7lich", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vermehrte die begird in mir,", "tokens": ["Ver\u00b7mehr\u00b7te", "die", "be\u00b7gird", "in", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die ich zuvor lang hat, mit dir", "tokens": ["die", "ich", "zu\u00b7vor", "lang", "hat", ",", "mit", "dir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PRELS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "in bessre kundschaft bald zu kommen,", "tokens": ["in", "bess\u00b7re", "kund\u00b7schaft", "bald", "zu", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hab demnach kaum ersuchet dich,", "tokens": ["Hab", "dem\u00b7nach", "kaum", "er\u00b7su\u00b7chet", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "da\u00df du alsbald ganz freindlich mich", "tokens": ["da\u00df", "du", "als\u00b7bald", "ganz", "freind\u00b7lich", "mich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "hast under deine freind genommen.", "tokens": ["hast", "un\u00b7der", "dei\u00b7ne", "freind", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Kont also weder geiz noch lust,", "tokens": ["Kont", "al\u00b7so", "we\u00b7der", "geiz", "noch", "lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "KON", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wie sunst der brauch, in unsrer brust", "tokens": ["wie", "sunst", "der", "brauch", ",", "in", "uns\u00b7rer", "brust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein solches feur der lieb anz\u00fcnden,", "tokens": ["ein", "sol\u00b7ches", "feur", "der", "lieb", "an\u00b7z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ART", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sondern der tugend eigne hand", "tokens": ["Son\u00b7dern", "der", "tu\u00b7gend", "eig\u00b7ne", "hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "mit ihrem t\u00fcchtig besten band", "tokens": ["mit", "ih\u00b7rem", "t\u00fcch\u00b7tig", "bes\u00b7ten", "band"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "must unsre herzen recht verbinden:", "tokens": ["must", "uns\u00b7re", "her\u00b7zen", "recht", "ver\u00b7bin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und solches band ist so wehrhaft,", "tokens": ["Und", "sol\u00b7ches", "band", "ist", "so", "wehr\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "da\u00df damit leichtlich die freindschaft", "tokens": ["da\u00df", "da\u00b7mit", "leicht\u00b7lich", "die", "freind\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PAV", "ADJD", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.9": {"text": "kan gl\u00fcck, zeit und tod \u00fcberwinden.", "tokens": ["kan", "gl\u00fcck", ",", "zeit", "und", "tod", "\u00fc\u00b7berw\u00b7in\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Darum ich nu k\u00fchn von dir schreib", "tokens": ["Da\u00b7rum", "ich", "nu", "k\u00fchn", "von", "dir", "schreib"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PPER", "ADV", "ADJD", "APPR", "PPER", "VVFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "und auch in guter hofnung bleib,", "tokens": ["und", "auch", "in", "gu\u00b7ter", "hof\u00b7nung", "bleib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "du werdest dich gar nicht beschweren,", "tokens": ["du", "wer\u00b7dest", "dich", "gar", "nicht", "be\u00b7schwe\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wan ich durch dise schrift begehr,", "tokens": ["Wan", "ich", "durch", "di\u00b7se", "schrift", "be\u00b7gehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PDS", "VVFIN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "mit meinem namen deine ehr", "tokens": ["mit", "mei\u00b7nem", "na\u00b7men", "dei\u00b7ne", "ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und deinen namen zu vermehren;", "tokens": ["und", "dei\u00b7nen", "na\u00b7men", "zu", "ver\u00b7meh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Indem ich anderst nicht thun kan,", "tokens": ["In\u00b7dem", "ich", "an\u00b7derst", "nicht", "thun", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "weil ehren einen werten man,", "tokens": ["weil", "eh\u00b7ren", "ei\u00b7nen", "wer\u00b7ten", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVINF", "ART", "ADJA", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ist gleich so vil, als selbs sich ehren.", "tokens": ["ist", "gleich", "so", "vil", ",", "als", "selbs", "sich", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "$,", "KOUS", "ADV", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich wei\u00df wol, wie der g\u00f6tter gunst", "tokens": ["Ich", "wei\u00df", "wol", ",", "wie", "der", "g\u00f6t\u00b7ter", "gunst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "dein haupt mit weisheit, tugend, kunst,", "tokens": ["dein", "haupt", "mit", "weis\u00b7heit", ",", "tu\u00b7gend", ",", "kunst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "$,", "ADJD", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "lehr und erfahrenheit gezieret:", "tokens": ["lehr", "und", "er\u00b7fah\u00b7ren\u00b7heit", "ge\u00b7zie\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "NN", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wie deine red, kunstreich und weis,", "tokens": ["Wie", "dei\u00b7ne", "red", ",", "kuns\u00b7treich", "und", "weis", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "VVFIN", "$,", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "als des gem\u00fcts kraftreiche speis,", "tokens": ["als", "des", "ge\u00b7m\u00fcts", "kraft\u00b7rei\u00b7che", "speis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "in allen herzen triumfieret:", "tokens": ["in", "al\u00b7len", "her\u00b7zen", "tri\u00b7um\u00b7fie\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und wie des besten nektars kraft", "tokens": ["Und", "wie", "des", "bes\u00b7ten", "nek\u00b7tars", "kraft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "und der kastalisch beste saft", "tokens": ["und", "der", "kas\u00b7ta\u00b7lisch", "bes\u00b7te", "saft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "von deiner federn distillieret.", "tokens": ["von", "dei\u00b7ner", "fe\u00b7dern", "dis\u00b7til\u00b7lie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wan, wie Pythagoras gewolt,", "tokens": ["Wan", ",", "wie", "Py\u00b7tha\u00b7go\u00b7ras", "ge\u00b7wolt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "NE", "VVPP", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "man f\u00fcr unl\u00e4ugbar halten solt,", "tokens": ["man", "f\u00fcr", "un\u00b7l\u00e4ug\u00b7bar", "hal\u00b7ten", "solt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df fremde seelen uns beleben,", "tokens": ["da\u00df", "frem\u00b7de", "see\u00b7len", "uns", "be\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So hielt die welt, halt ich, darf\u00fcr", "tokens": ["So", "hielt", "die", "welt", ",", "halt", "ich", ",", "dar\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "VVFIN", "PPER", "$,", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und w\u00e4r auch gl\u00e4ublich, da\u00df in dir", "tokens": ["und", "w\u00e4r", "auch", "gl\u00e4ub\u00b7lich", ",", "da\u00df", "in", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$,", "KOUS", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "man seh nu jenen wider leben,", "tokens": ["man", "seh", "nu", "je\u00b7nen", "wi\u00b7der", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PDS", "PTKVZ", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dem, als er sehr jung sein ruh nam", "tokens": ["Dem", ",", "als", "er", "sehr", "jung", "sein", "ruh", "nam"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "KOUS", "PPER", "ADV", "ADJD", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "die binen ihren honigsam", "tokens": ["die", "bi\u00b7nen", "ih\u00b7ren", "ho\u00b7nig\u00b7sam"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "f\u00fcr seine erste speis gegeben.", "tokens": ["f\u00fcr", "sei\u00b7ne", "ers\u00b7te", "speis", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Darum dir, solchem verdienst nach,", "tokens": ["Da\u00b7rum", "dir", ",", "sol\u00b7chem", "ver\u00b7dienst", "nach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "$,", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "auch wegen ein und andrer sprach,", "tokens": ["auch", "we\u00b7gen", "ein", "und", "an\u00b7drer", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "KON", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "vil f\u00fcrsten billich g\u00fcnstig bleiben;", "tokens": ["vil", "f\u00fcrs\u00b7ten", "bil\u00b7lich", "g\u00fcns\u00b7tig", "blei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und du (dieweil ja ihr anblick", "tokens": ["Und", "du", "(", "die\u00b7weil", "ja", "ihr", "an\u00b7blick"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$(", "KOUS", "ADV", "PPOSAT", "NN"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "und gnad kan als das beste gl\u00fcck", "tokens": ["und", "gnad", "kan", "als", "das", "bes\u00b7te", "gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VMFIN", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "all sorg und forcht von uns vertreiben)", "tokens": ["all", "sorg", "und", "forcht", "von", "uns", "ver\u00b7trei\u00b7ben", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "VVFIN", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Thust recht zu ihr und deinem preis", "tokens": ["Thust", "recht", "zu", "ihr", "und", "dei\u00b7nem", "preis"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "gedenkw\u00fcrdige werk mit flei\u00df", "tokens": ["ge\u00b7denk\u00b7w\u00fcr\u00b7di\u00b7ge", "werk", "mit", "flei\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "in ein und andrer sprach zu schreiben.", "tokens": ["in", "ein", "und", "an\u00b7drer", "sprach", "zu", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "KON", "ADJA", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ich meines theils, in dessen herz", "tokens": ["Ich", "mei\u00b7nes", "theils", ",", "in", "des\u00b7sen", "herz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "ADV", "$,", "APPR", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der ehrgeiz weder sorg noch schmerz,", "tokens": ["der", "ehr\u00b7geiz", "we\u00b7der", "sorg", "noch", "schmerz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "noch hofnung, noch auch forcht erwecket,", "tokens": ["noch", "hof\u00b7nung", ",", "noch", "auch", "forcht", "er\u00b7we\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Besuch vil lieber das gr\u00fcn feld", "tokens": ["Be\u00b7such", "vil", "lie\u00b7ber", "das", "gr\u00fcn", "feld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "und frische br\u00fcnlein, stille w\u00e4ld", "tokens": ["und", "fri\u00b7sche", "br\u00fcn\u00b7lein", ",", "stil\u00b7le", "w\u00e4ld"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und b\u00e4ch, die noch kein thier beflecket,", "tokens": ["und", "b\u00e4ch", ",", "die", "noch", "kein", "thier", "be\u00b7fle\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PRELS", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dan die pall\u00e4st von marberstein", "tokens": ["Dan", "die", "pal\u00b7l\u00e4st", "von", "mar\u00b7bers\u00b7tein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "mit gold und andrer reichtum schein", "tokens": ["mit", "gold", "und", "an\u00b7drer", "reich\u00b7tum", "schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "gef\u00fcttert und mit blei bedecket.", "tokens": ["ge\u00b7f\u00fct\u00b7tert", "und", "mit", "blei", "be\u00b7de\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ja, so vil immer ich vermag,", "tokens": ["Ja", ",", "so", "vil", "im\u00b7mer", "ich", "ver\u00b7mag", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "flieh ich den p\u00f6fel, meine tag", "tokens": ["flieh", "ich", "den", "p\u00f6\u00b7fel", ",", "mei\u00b7ne", "tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wol mit den Musen zu volbringen,", "tokens": ["wol", "mit", "den", "Mu\u00b7sen", "zu", "vol\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Die lehren mich und ich lehr sie", "tokens": ["Die", "leh\u00b7ren", "mich", "und", "ich", "lehr", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "KON", "PPER", "VVFIN", "PPER"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "auf neue weis mit s\u00fc\u00dfer m\u00fch", "tokens": ["auf", "neu\u00b7e", "weis", "mit", "s\u00fc\u00b7\u00dfer", "m\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "PTKVZ", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "ein gutes teutsches lied zu singen,", "tokens": ["ein", "gu\u00b7tes", "teut\u00b7sches", "lied", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und mit vor unerh\u00f6rter prob", "tokens": ["Und", "mit", "vor", "un\u00b7er\u00b7h\u00f6r\u00b7ter", "prob"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "der helden und der Nymfen lob,", "tokens": ["der", "hel\u00b7den", "und", "der", "Nym\u00b7fen", "lob", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ja Amors ehr auch zu erklingen.", "tokens": ["ja", "A\u00b7mors", "ehr", "auch", "zu", "er\u00b7klin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Wan der Homer, der den wein sehr", "tokens": ["Wan", "der", "Ho\u00b7mer", ",", "der", "den", "wein", "sehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NE", "$,", "PRELS", "ART", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "gelobt, weins\u00fcchtig gwesen w\u00e4r,", "tokens": ["ge\u00b7lobt", ",", "wein\u00b7s\u00fcch\u00b7tig", "gwe\u00b7sen", "w\u00e4r", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wie gleichwol ich nicht kan gedenken,", "tokens": ["wie", "gleich\u00b7wol", "ich", "nicht", "kan", "ge\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gedenk doch du, mein Veyras, nicht,", "tokens": ["Ge\u00b7denk", "doch", "du", ",", "mein", "Vey\u00b7ras", ",", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "KON", "PPER", "$,", "PPOSAT", "NN", "$,", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df, wan ich von dem wein auch dicht,", "tokens": ["da\u00df", ",", "wan", "ich", "von", "dem", "wein", "auch", "dicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWAV", "PPER", "APPR", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "ich so gern sei bei dem weinschenken;", "tokens": ["ich", "so", "gern", "sei", "bei", "dem", "wein\u00b7schen\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VAFIN", "APPR", "ART", "VVINF", "$."], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.7": {"text": "Dan wider meiner landsleut wohn", "tokens": ["Dan", "wi\u00b7der", "mei\u00b7ner", "lands\u00b7leut", "wohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "glaub ich, da\u00df der Semelen sohn,", "tokens": ["glaub", "ich", ",", "da\u00df", "der", "Se\u00b7me\u00b7len", "sohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.9": {"text": "ohn ma\u00df, thu leib und seel bekr\u00e4nken.", "tokens": ["ohn", "ma\u00df", ",", "thu", "leib", "und", "seel", "be\u00b7kr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVFIN", "NN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "So glaub ich, da\u00df es auch gnug sei,", "tokens": ["So", "glaub", "ich", ",", "da\u00df", "es", "auch", "gnug", "sei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wan der poet ohn heuchelei", "tokens": ["wan", "der", "poet", "ohn", "heu\u00b7che\u00b7lei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ein from und keusches leben f\u00fchret,", "tokens": ["ein", "from", "und", "keu\u00b7sches", "le\u00b7ben", "f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJA", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Obschon bisweilen sein gesang", "tokens": ["Ob\u00b7schon", "bis\u00b7wei\u00b7len", "sein", "ge\u00b7sang"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "mit frecher sprach und geilem klang", "tokens": ["mit", "fre\u00b7cher", "sprach", "und", "gei\u00b7lem", "klang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "VVFIN", "KON", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die ohren \u00fcppiglich ber\u00fchret;", "tokens": ["die", "oh\u00b7ren", "\u00fcp\u00b7pig\u00b7lich", "be\u00b7r\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ob es auch wol die loben nicht,", "tokens": ["Ob", "es", "auch", "wol", "die", "lo\u00b7ben", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "die Timon gleich von angesicht,", "tokens": ["die", "Ti\u00b7mon", "gleich", "von", "an\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "weil Epikur ihr herz regieret.", "tokens": ["weil", "E\u00b7pi\u00b7kur", "ihr", "herz", "re\u00b7gie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Jedoch ist es schon mehr dan gnug", "tokens": ["Je\u00b7doch", "ist", "es", "schon", "mehr", "dan", "gnug"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "weil ich schon h\u00f6r und sih den flug", "tokens": ["weil", "ich", "schon", "h\u00f6r", "und", "sih", "den", "flug"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "KON", "VVIMP", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "der lauten rappen, hetzen, kr\u00e4hen.", "tokens": ["der", "lau\u00b7ten", "rap\u00b7pen", ",", "het\u00b7zen", ",", "kr\u00e4\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Darum, ihr Musen, eilet fort,", "tokens": ["Da\u00b7rum", ",", "ihr", "Mu\u00b7sen", ",", "ei\u00b7let", "fort", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df wir uns, in ein stilles ort", "tokens": ["da\u00df", "wir", "uns", ",", "in", "ein", "stil\u00b7les", "ort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "verstehlend, dem geschrei entgehen.", "tokens": ["ver\u00b7steh\u00b7lend", ",", "dem", "ge\u00b7schrei", "ent\u00b7ge\u00b7hen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PRELS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du, Veyras, unsrer Musen ruhm", "tokens": ["Du", ",", "Vey\u00b7ras", ",", "uns\u00b7rer", "Mu\u00b7sen", "ruhm"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "NE", "$,", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "f\u00fcr einen kranz wirst diese blum,", "tokens": ["f\u00fcr", "ei\u00b7nen", "kranz", "wirst", "die\u00b7se", "blum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "hoff ich, zu nehmen nicht verschm\u00e4hen.", "tokens": ["hoff", "ich", ",", "zu", "neh\u00b7men", "nicht", "ver\u00b7schm\u00e4\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PTKZU", "VVINF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Dein lob, so ich zu aller stund", "tokens": ["Dein", "lob", ",", "so", "ich", "zu", "al\u00b7ler", "stund"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ADV", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von manchem lobbewehrten mund,", "tokens": ["von", "man\u00b7chem", "lob\u00b7be\u00b7wehr\u00b7ten", "mund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mein Veyras, williglich vernommen,", "tokens": ["mein", "Vey\u00b7ras", ",", "wil\u00b7lig\u00b7lich", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vermehrte die begird in mir,", "tokens": ["Ver\u00b7mehr\u00b7te", "die", "be\u00b7gird", "in", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die ich zuvor lang hat, mit dir", "tokens": ["die", "ich", "zu\u00b7vor", "lang", "hat", ",", "mit", "dir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PRELS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "in bessre kundschaft bald zu kommen,", "tokens": ["in", "bess\u00b7re", "kund\u00b7schaft", "bald", "zu", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hab demnach kaum ersuchet dich,", "tokens": ["Hab", "dem\u00b7nach", "kaum", "er\u00b7su\u00b7chet", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "da\u00df du alsbald ganz freindlich mich", "tokens": ["da\u00df", "du", "als\u00b7bald", "ganz", "freind\u00b7lich", "mich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "hast under deine freind genommen.", "tokens": ["hast", "un\u00b7der", "dei\u00b7ne", "freind", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Kont also weder geiz noch lust,", "tokens": ["Kont", "al\u00b7so", "we\u00b7der", "geiz", "noch", "lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "KON", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wie sunst der brauch, in unsrer brust", "tokens": ["wie", "sunst", "der", "brauch", ",", "in", "uns\u00b7rer", "brust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein solches feur der lieb anz\u00fcnden,", "tokens": ["ein", "sol\u00b7ches", "feur", "der", "lieb", "an\u00b7z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ART", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sondern der tugend eigne hand", "tokens": ["Son\u00b7dern", "der", "tu\u00b7gend", "eig\u00b7ne", "hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "mit ihrem t\u00fcchtig besten band", "tokens": ["mit", "ih\u00b7rem", "t\u00fcch\u00b7tig", "bes\u00b7ten", "band"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "must unsre herzen recht verbinden:", "tokens": ["must", "uns\u00b7re", "her\u00b7zen", "recht", "ver\u00b7bin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und solches band ist so wehrhaft,", "tokens": ["Und", "sol\u00b7ches", "band", "ist", "so", "wehr\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "da\u00df damit leichtlich die freindschaft", "tokens": ["da\u00df", "da\u00b7mit", "leicht\u00b7lich", "die", "freind\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PAV", "ADJD", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.9": {"text": "kan gl\u00fcck, zeit und tod \u00fcberwinden.", "tokens": ["kan", "gl\u00fcck", ",", "zeit", "und", "tod", "\u00fc\u00b7berw\u00b7in\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Darum ich nu k\u00fchn von dir schreib", "tokens": ["Da\u00b7rum", "ich", "nu", "k\u00fchn", "von", "dir", "schreib"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PPER", "ADV", "ADJD", "APPR", "PPER", "VVFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "und auch in guter hofnung bleib,", "tokens": ["und", "auch", "in", "gu\u00b7ter", "hof\u00b7nung", "bleib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "du werdest dich gar nicht beschweren,", "tokens": ["du", "wer\u00b7dest", "dich", "gar", "nicht", "be\u00b7schwe\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wan ich durch dise schrift begehr,", "tokens": ["Wan", "ich", "durch", "di\u00b7se", "schrift", "be\u00b7gehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PDS", "VVFIN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "mit meinem namen deine ehr", "tokens": ["mit", "mei\u00b7nem", "na\u00b7men", "dei\u00b7ne", "ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und deinen namen zu vermehren;", "tokens": ["und", "dei\u00b7nen", "na\u00b7men", "zu", "ver\u00b7meh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Indem ich anderst nicht thun kan,", "tokens": ["In\u00b7dem", "ich", "an\u00b7derst", "nicht", "thun", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "weil ehren einen werten man,", "tokens": ["weil", "eh\u00b7ren", "ei\u00b7nen", "wer\u00b7ten", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVINF", "ART", "ADJA", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ist gleich so vil, als selbs sich ehren.", "tokens": ["ist", "gleich", "so", "vil", ",", "als", "selbs", "sich", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "$,", "KOUS", "ADV", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Ich wei\u00df wol, wie der g\u00f6tter gunst", "tokens": ["Ich", "wei\u00df", "wol", ",", "wie", "der", "g\u00f6t\u00b7ter", "gunst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "dein haupt mit weisheit, tugend, kunst,", "tokens": ["dein", "haupt", "mit", "weis\u00b7heit", ",", "tu\u00b7gend", ",", "kunst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "$,", "ADJD", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "lehr und erfahrenheit gezieret:", "tokens": ["lehr", "und", "er\u00b7fah\u00b7ren\u00b7heit", "ge\u00b7zie\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "NN", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wie deine red, kunstreich und weis,", "tokens": ["Wie", "dei\u00b7ne", "red", ",", "kuns\u00b7treich", "und", "weis", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "VVFIN", "$,", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "als des gem\u00fcts kraftreiche speis,", "tokens": ["als", "des", "ge\u00b7m\u00fcts", "kraft\u00b7rei\u00b7che", "speis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "in allen herzen triumfieret:", "tokens": ["in", "al\u00b7len", "her\u00b7zen", "tri\u00b7um\u00b7fie\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und wie des besten nektars kraft", "tokens": ["Und", "wie", "des", "bes\u00b7ten", "nek\u00b7tars", "kraft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "und der kastalisch beste saft", "tokens": ["und", "der", "kas\u00b7ta\u00b7lisch", "bes\u00b7te", "saft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "von deiner federn distillieret.", "tokens": ["von", "dei\u00b7ner", "fe\u00b7dern", "dis\u00b7til\u00b7lie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Wan, wie Pythagoras gewolt,", "tokens": ["Wan", ",", "wie", "Py\u00b7tha\u00b7go\u00b7ras", "ge\u00b7wolt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "NE", "VVPP", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "man f\u00fcr unl\u00e4ugbar halten solt,", "tokens": ["man", "f\u00fcr", "un\u00b7l\u00e4ug\u00b7bar", "hal\u00b7ten", "solt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df fremde seelen uns beleben,", "tokens": ["da\u00df", "frem\u00b7de", "see\u00b7len", "uns", "be\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So hielt die welt, halt ich, darf\u00fcr", "tokens": ["So", "hielt", "die", "welt", ",", "halt", "ich", ",", "dar\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "VVFIN", "PPER", "$,", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und w\u00e4r auch gl\u00e4ublich, da\u00df in dir", "tokens": ["und", "w\u00e4r", "auch", "gl\u00e4ub\u00b7lich", ",", "da\u00df", "in", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$,", "KOUS", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "man seh nu jenen wider leben,", "tokens": ["man", "seh", "nu", "je\u00b7nen", "wi\u00b7der", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PDS", "PTKVZ", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dem, als er sehr jung sein ruh nam", "tokens": ["Dem", ",", "als", "er", "sehr", "jung", "sein", "ruh", "nam"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "KOUS", "PPER", "ADV", "ADJD", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "die binen ihren honigsam", "tokens": ["die", "bi\u00b7nen", "ih\u00b7ren", "ho\u00b7nig\u00b7sam"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "f\u00fcr seine erste speis gegeben.", "tokens": ["f\u00fcr", "sei\u00b7ne", "ers\u00b7te", "speis", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Darum dir, solchem verdienst nach,", "tokens": ["Da\u00b7rum", "dir", ",", "sol\u00b7chem", "ver\u00b7dienst", "nach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "$,", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "auch wegen ein und andrer sprach,", "tokens": ["auch", "we\u00b7gen", "ein", "und", "an\u00b7drer", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "KON", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "vil f\u00fcrsten billich g\u00fcnstig bleiben;", "tokens": ["vil", "f\u00fcrs\u00b7ten", "bil\u00b7lich", "g\u00fcns\u00b7tig", "blei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und du (dieweil ja ihr anblick", "tokens": ["Und", "du", "(", "die\u00b7weil", "ja", "ihr", "an\u00b7blick"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$(", "KOUS", "ADV", "PPOSAT", "NN"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "und gnad kan als das beste gl\u00fcck", "tokens": ["und", "gnad", "kan", "als", "das", "bes\u00b7te", "gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VMFIN", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "all sorg und forcht von uns vertreiben)", "tokens": ["all", "sorg", "und", "forcht", "von", "uns", "ver\u00b7trei\u00b7ben", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "VVFIN", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Thust recht zu ihr und deinem preis", "tokens": ["Thust", "recht", "zu", "ihr", "und", "dei\u00b7nem", "preis"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "gedenkw\u00fcrdige werk mit flei\u00df", "tokens": ["ge\u00b7denk\u00b7w\u00fcr\u00b7di\u00b7ge", "werk", "mit", "flei\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "in ein und andrer sprach zu schreiben.", "tokens": ["in", "ein", "und", "an\u00b7drer", "sprach", "zu", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "KON", "ADJA", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Ich meines theils, in dessen herz", "tokens": ["Ich", "mei\u00b7nes", "theils", ",", "in", "des\u00b7sen", "herz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "ADV", "$,", "APPR", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der ehrgeiz weder sorg noch schmerz,", "tokens": ["der", "ehr\u00b7geiz", "we\u00b7der", "sorg", "noch", "schmerz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "noch hofnung, noch auch forcht erwecket,", "tokens": ["noch", "hof\u00b7nung", ",", "noch", "auch", "forcht", "er\u00b7we\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Besuch vil lieber das gr\u00fcn feld", "tokens": ["Be\u00b7such", "vil", "lie\u00b7ber", "das", "gr\u00fcn", "feld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "und frische br\u00fcnlein, stille w\u00e4ld", "tokens": ["und", "fri\u00b7sche", "br\u00fcn\u00b7lein", ",", "stil\u00b7le", "w\u00e4ld"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und b\u00e4ch, die noch kein thier beflecket,", "tokens": ["und", "b\u00e4ch", ",", "die", "noch", "kein", "thier", "be\u00b7fle\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PRELS", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dan die pall\u00e4st von marberstein", "tokens": ["Dan", "die", "pal\u00b7l\u00e4st", "von", "mar\u00b7bers\u00b7tein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "mit gold und andrer reichtum schein", "tokens": ["mit", "gold", "und", "an\u00b7drer", "reich\u00b7tum", "schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "gef\u00fcttert und mit blei bedecket.", "tokens": ["ge\u00b7f\u00fct\u00b7tert", "und", "mit", "blei", "be\u00b7de\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Ja, so vil immer ich vermag,", "tokens": ["Ja", ",", "so", "vil", "im\u00b7mer", "ich", "ver\u00b7mag", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "flieh ich den p\u00f6fel, meine tag", "tokens": ["flieh", "ich", "den", "p\u00f6\u00b7fel", ",", "mei\u00b7ne", "tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wol mit den Musen zu volbringen,", "tokens": ["wol", "mit", "den", "Mu\u00b7sen", "zu", "vol\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Die lehren mich und ich lehr sie", "tokens": ["Die", "leh\u00b7ren", "mich", "und", "ich", "lehr", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "KON", "PPER", "VVFIN", "PPER"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "auf neue weis mit s\u00fc\u00dfer m\u00fch", "tokens": ["auf", "neu\u00b7e", "weis", "mit", "s\u00fc\u00b7\u00dfer", "m\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "PTKVZ", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "ein gutes teutsches lied zu singen,", "tokens": ["ein", "gu\u00b7tes", "teut\u00b7sches", "lied", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und mit vor unerh\u00f6rter prob", "tokens": ["Und", "mit", "vor", "un\u00b7er\u00b7h\u00f6r\u00b7ter", "prob"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "der helden und der Nymfen lob,", "tokens": ["der", "hel\u00b7den", "und", "der", "Nym\u00b7fen", "lob", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ja Amors ehr auch zu erklingen.", "tokens": ["ja", "A\u00b7mors", "ehr", "auch", "zu", "er\u00b7klin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Wan der Homer, der den wein sehr", "tokens": ["Wan", "der", "Ho\u00b7mer", ",", "der", "den", "wein", "sehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NE", "$,", "PRELS", "ART", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "gelobt, weins\u00fcchtig gwesen w\u00e4r,", "tokens": ["ge\u00b7lobt", ",", "wein\u00b7s\u00fcch\u00b7tig", "gwe\u00b7sen", "w\u00e4r", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wie gleichwol ich nicht kan gedenken,", "tokens": ["wie", "gleich\u00b7wol", "ich", "nicht", "kan", "ge\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gedenk doch du, mein Veyras, nicht,", "tokens": ["Ge\u00b7denk", "doch", "du", ",", "mein", "Vey\u00b7ras", ",", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "KON", "PPER", "$,", "PPOSAT", "NN", "$,", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df, wan ich von dem wein auch dicht,", "tokens": ["da\u00df", ",", "wan", "ich", "von", "dem", "wein", "auch", "dicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWAV", "PPER", "APPR", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "ich so gern sei bei dem weinschenken;", "tokens": ["ich", "so", "gern", "sei", "bei", "dem", "wein\u00b7schen\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VAFIN", "APPR", "ART", "VVINF", "$."], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.7": {"text": "Dan wider meiner landsleut wohn", "tokens": ["Dan", "wi\u00b7der", "mei\u00b7ner", "lands\u00b7leut", "wohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "glaub ich, da\u00df der Semelen sohn,", "tokens": ["glaub", "ich", ",", "da\u00df", "der", "Se\u00b7me\u00b7len", "sohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.9": {"text": "ohn ma\u00df, thu leib und seel bekr\u00e4nken.", "tokens": ["ohn", "ma\u00df", ",", "thu", "leib", "und", "seel", "be\u00b7kr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVFIN", "NN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "So glaub ich, da\u00df es auch gnug sei,", "tokens": ["So", "glaub", "ich", ",", "da\u00df", "es", "auch", "gnug", "sei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wan der poet ohn heuchelei", "tokens": ["wan", "der", "poet", "ohn", "heu\u00b7che\u00b7lei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ein from und keusches leben f\u00fchret,", "tokens": ["ein", "from", "und", "keu\u00b7sches", "le\u00b7ben", "f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJA", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Obschon bisweilen sein gesang", "tokens": ["Ob\u00b7schon", "bis\u00b7wei\u00b7len", "sein", "ge\u00b7sang"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "mit frecher sprach und geilem klang", "tokens": ["mit", "fre\u00b7cher", "sprach", "und", "gei\u00b7lem", "klang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "VVFIN", "KON", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die ohren \u00fcppiglich ber\u00fchret;", "tokens": ["die", "oh\u00b7ren", "\u00fcp\u00b7pig\u00b7lich", "be\u00b7r\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ob es auch wol die loben nicht,", "tokens": ["Ob", "es", "auch", "wol", "die", "lo\u00b7ben", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "die Timon gleich von angesicht,", "tokens": ["die", "Ti\u00b7mon", "gleich", "von", "an\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "weil Epikur ihr herz regieret.", "tokens": ["weil", "E\u00b7pi\u00b7kur", "ihr", "herz", "re\u00b7gie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Jedoch ist es schon mehr dan gnug", "tokens": ["Je\u00b7doch", "ist", "es", "schon", "mehr", "dan", "gnug"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "weil ich schon h\u00f6r und sih den flug", "tokens": ["weil", "ich", "schon", "h\u00f6r", "und", "sih", "den", "flug"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "KON", "VVIMP", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "der lauten rappen, hetzen, kr\u00e4hen.", "tokens": ["der", "lau\u00b7ten", "rap\u00b7pen", ",", "het\u00b7zen", ",", "kr\u00e4\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Darum, ihr Musen, eilet fort,", "tokens": ["Da\u00b7rum", ",", "ihr", "Mu\u00b7sen", ",", "ei\u00b7let", "fort", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df wir uns, in ein stilles ort", "tokens": ["da\u00df", "wir", "uns", ",", "in", "ein", "stil\u00b7les", "ort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "verstehlend, dem geschrei entgehen.", "tokens": ["ver\u00b7steh\u00b7lend", ",", "dem", "ge\u00b7schrei", "ent\u00b7ge\u00b7hen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PRELS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du, Veyras, unsrer Musen ruhm", "tokens": ["Du", ",", "Vey\u00b7ras", ",", "uns\u00b7rer", "Mu\u00b7sen", "ruhm"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "NE", "$,", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "f\u00fcr einen kranz wirst diese blum,", "tokens": ["f\u00fcr", "ei\u00b7nen", "kranz", "wirst", "die\u00b7se", "blum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "hoff ich, zu nehmen nicht verschm\u00e4hen.", "tokens": ["hoff", "ich", ",", "zu", "neh\u00b7men", "nicht", "ver\u00b7schm\u00e4\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PTKZU", "VVINF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}