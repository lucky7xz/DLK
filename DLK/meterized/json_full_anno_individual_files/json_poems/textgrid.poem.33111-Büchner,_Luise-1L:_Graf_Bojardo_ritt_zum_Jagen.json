{"textgrid.poem.33111": {"metadata": {"author": {"name": "B\u00fcchner, Luise", "birth": "N.A.", "death": "N.A."}, "title": "1L: Graf Bojardo ritt zum Jagen", "genre": "verse", "period": "N.A.", "pub_year": 1849, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Graf Bojardo ritt zum Jagen", "tokens": ["Graf", "Bo\u00b7jar\u00b7do", "ritt", "zum", "Ja\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "APPRART", "NN"], "meter": "++-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Aber nicht auf Hirsch' und Rehe,", "tokens": ["A\u00b7ber", "nicht", "auf", "Hirsch'", "und", "Re\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn in seinem Innern nagen", "tokens": ["Denn", "in", "sei\u00b7nem", "In\u00b7nern", "na\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eines Dichters Gram und Wehe.", "tokens": ["Ei\u00b7nes", "Dich\u00b7ters", "Gram", "und", "We\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Er, der k\u00fchne Rolands\u00e4nger,", "tokens": ["Er", ",", "der", "k\u00fch\u00b7ne", "Ro\u00b7land\u00b7s\u00e4n\u00b7ger", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sonst um Namen nicht verlegen,", "tokens": ["Sonst", "um", "Na\u00b7men", "nicht", "ver\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sucht just einen immer l\u00e4nger", "tokens": ["Sucht", "just", "ei\u00b7nen", "im\u00b7mer", "l\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr den kecksten seiner Degen.", "tokens": ["F\u00fcr", "den", "kecks\u00b7ten", "sei\u00b7ner", "De\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Denn der Name schien zur Sache", "tokens": ["Denn", "der", "Na\u00b7me", "schien", "zur", "Sa\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wichtig ihm aus vielen Gr\u00fcnden;", "tokens": ["Wich\u00b7tig", "ihm", "aus", "vie\u00b7len", "Gr\u00fcn\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unter'm gr\u00fcnen Waldesdache", "tokens": ["Un\u00b7ter'm", "gr\u00fc\u00b7nen", "Wal\u00b7des\u00b7da\u00b7che"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hofft' er heute ihn zu finden.", "tokens": ["Hofft'", "er", "heu\u00b7te", "ihn", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Horch, da rei\u00dft vom Bergesstollen", "tokens": ["Horch", ",", "da", "rei\u00dft", "vom", "Ber\u00b7ges\u00b7stol\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "ADV", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich ein Fels mit einem Male,", "tokens": ["Sich", "ein", "Fels", "mit", "ei\u00b7nem", "Ma\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit ungest\u00fcmem Rollen", "tokens": ["Und", "mit", "un\u00b7ge\u00b7st\u00fc\u00b7mem", "Rol\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "St\u00fcrzt er donnernd in die Thale.", "tokens": ["St\u00fcrzt", "er", "don\u00b7nernd", "in", "die", "Tha\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Hei! so wild, unb\u00e4ndig pr\u00e4chtig", "tokens": ["Hei", "!", "so", "wild", ",", "un\u00b7b\u00e4n\u00b7dig", "pr\u00e4ch\u00b7tig"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "$.", "ADV", "ADJD", "$,", "ADJD", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist Bojardo's Held erfunden:", "tokens": ["Ist", "Bo\u00b7jar\u00b7do's", "Held", "er\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "VVPP", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Aus den Tr\u00e4umen rei\u00dft's ihn m\u00e4chtig,", "tokens": ["Aus", "den", "Tr\u00e4u\u00b7men", "rei\u00dft's", "ihn", "m\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und \u2013 der Name ist gefunden!", "tokens": ["Und", "\u2013", "der", "Na\u00b7me", "ist", "ge\u00b7fun\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.2": {"text": "Jauchzt' er laut auf hohem Rosse", "tokens": ["Jauchzt'", "er", "laut", "auf", "ho\u00b7hem", "Ros\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und, so eilig als er konnte,", "tokens": ["Und", ",", "so", "ei\u00b7lig", "als", "er", "konn\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "ADJD", "KOKOM", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sprengt' er heimw\u00e4rts nach dem Schlosse.", "tokens": ["Sprengt'", "er", "heim\u00b7w\u00e4rts", "nach", "dem", "Schlos\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "L\u00e4\u00dft mit seinen Glocken allen", "tokens": ["L\u00e4\u00dft", "mit", "sei\u00b7nen", "Glo\u00b7cken", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4uten, was man l\u00e4uten konnte,", "tokens": ["L\u00e4u\u00b7ten", ",", "was", "man", "l\u00e4u\u00b7ten", "konn\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch Scandiano's weite Hallen,", "tokens": ["Durch", "Scan\u00b7dia\u00b7no's", "wei\u00b7te", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "T\u00f6nt sein jubelnd: \u00bb", "tokens": ["T\u00f6nt", "sein", "ju\u00b7belnd", ":", "\u00bb"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPOSAT", "VVPP", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.8": {"line.1": {"text": "Volk und Diener \u00e4ngstlich flohen", "tokens": ["Volk", "und", "Die\u00b7ner", "\u00e4ngst\u00b7lich", "flo\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hier- und dorthin bei dem L\u00e4uten,", "tokens": ["Hier", "und", "dor\u00b7thin", "bei", "dem", "L\u00e4u\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch \u2013 kein Feuer sieht man lohen,", "tokens": ["Doch", "\u2013", "kein", "Feu\u00b7er", "sieht", "man", "lo\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PIAT", "NN", "VVFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Niemand wei\u00df den L\u00e4rm zu deuten.", "tokens": ["Nie\u00b7mand", "wei\u00df", "den", "L\u00e4rm", "zu", "deu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wie nun Alles stand im Kranze", "tokens": ["Wie", "nun", "Al\u00b7les", "stand", "im", "Kran\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PIS", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und nicht g'nug sich wundern konnte,", "tokens": ["Und", "nicht", "g'\u00b7nug", "sich", "wun\u00b7dern", "konn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Schrieb Bojard die erste Stanze", "tokens": ["Schrieb", "Bo\u00b7jard", "die", "ers\u00b7te", "Stan\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NE", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Von dem Helden ", "tokens": ["Von", "dem", "Hel\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.10": {"line.1": {"text": "Und, dieweil ein Stein' alleine", "tokens": ["Und", ",", "die\u00b7weil", "ein", "Stein'", "al\u00b7lei\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "ADV"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Schon bewirkte solche Thaten,", "tokens": ["Schon", "be\u00b7wirk\u00b7te", "sol\u00b7che", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nennt man Alles, was zum Scheine", "tokens": ["Nennt", "man", "Al\u00b7les", ",", "was", "zum", "Schei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PIS", "$,", "PRELS", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00e4rmen macht: ", "tokens": ["L\u00e4r\u00b7men", "macht", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.11": {"line.1": {"text": "Graf Bojardo ritt zum Jagen", "tokens": ["Graf", "Bo\u00b7jar\u00b7do", "ritt", "zum", "Ja\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "APPRART", "NN"], "meter": "++-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Aber nicht auf Hirsch' und Rehe,", "tokens": ["A\u00b7ber", "nicht", "auf", "Hirsch'", "und", "Re\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn in seinem Innern nagen", "tokens": ["Denn", "in", "sei\u00b7nem", "In\u00b7nern", "na\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eines Dichters Gram und Wehe.", "tokens": ["Ei\u00b7nes", "Dich\u00b7ters", "Gram", "und", "We\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Er, der k\u00fchne Rolands\u00e4nger,", "tokens": ["Er", ",", "der", "k\u00fch\u00b7ne", "Ro\u00b7land\u00b7s\u00e4n\u00b7ger", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sonst um Namen nicht verlegen,", "tokens": ["Sonst", "um", "Na\u00b7men", "nicht", "ver\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sucht just einen immer l\u00e4nger", "tokens": ["Sucht", "just", "ei\u00b7nen", "im\u00b7mer", "l\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr den kecksten seiner Degen.", "tokens": ["F\u00fcr", "den", "kecks\u00b7ten", "sei\u00b7ner", "De\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Denn der Name schien zur Sache", "tokens": ["Denn", "der", "Na\u00b7me", "schien", "zur", "Sa\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wichtig ihm aus vielen Gr\u00fcnden;", "tokens": ["Wich\u00b7tig", "ihm", "aus", "vie\u00b7len", "Gr\u00fcn\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unter'm gr\u00fcnen Waldesdache", "tokens": ["Un\u00b7ter'm", "gr\u00fc\u00b7nen", "Wal\u00b7des\u00b7da\u00b7che"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hofft' er heute ihn zu finden.", "tokens": ["Hofft'", "er", "heu\u00b7te", "ihn", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Horch, da rei\u00dft vom Bergesstollen", "tokens": ["Horch", ",", "da", "rei\u00dft", "vom", "Ber\u00b7ges\u00b7stol\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "ADV", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich ein Fels mit einem Male,", "tokens": ["Sich", "ein", "Fels", "mit", "ei\u00b7nem", "Ma\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit ungest\u00fcmem Rollen", "tokens": ["Und", "mit", "un\u00b7ge\u00b7st\u00fc\u00b7mem", "Rol\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "St\u00fcrzt er donnernd in die Thale.", "tokens": ["St\u00fcrzt", "er", "don\u00b7nernd", "in", "die", "Tha\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Hei! so wild, unb\u00e4ndig pr\u00e4chtig", "tokens": ["Hei", "!", "so", "wild", ",", "un\u00b7b\u00e4n\u00b7dig", "pr\u00e4ch\u00b7tig"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "$.", "ADV", "ADJD", "$,", "ADJD", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist Bojardo's Held erfunden:", "tokens": ["Ist", "Bo\u00b7jar\u00b7do's", "Held", "er\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "VVPP", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Aus den Tr\u00e4umen rei\u00dft's ihn m\u00e4chtig,", "tokens": ["Aus", "den", "Tr\u00e4u\u00b7men", "rei\u00dft's", "ihn", "m\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und \u2013 der Name ist gefunden!", "tokens": ["Und", "\u2013", "der", "Na\u00b7me", "ist", "ge\u00b7fun\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.2": {"text": "Jauchzt' er laut auf hohem Rosse", "tokens": ["Jauchzt'", "er", "laut", "auf", "ho\u00b7hem", "Ros\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und, so eilig als er konnte,", "tokens": ["Und", ",", "so", "ei\u00b7lig", "als", "er", "konn\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "ADJD", "KOKOM", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sprengt' er heimw\u00e4rts nach dem Schlosse.", "tokens": ["Sprengt'", "er", "heim\u00b7w\u00e4rts", "nach", "dem", "Schlos\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "L\u00e4\u00dft mit seinen Glocken allen", "tokens": ["L\u00e4\u00dft", "mit", "sei\u00b7nen", "Glo\u00b7cken", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4uten, was man l\u00e4uten konnte,", "tokens": ["L\u00e4u\u00b7ten", ",", "was", "man", "l\u00e4u\u00b7ten", "konn\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch Scandiano's weite Hallen,", "tokens": ["Durch", "Scan\u00b7dia\u00b7no's", "wei\u00b7te", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "T\u00f6nt sein jubelnd: \u00bb", "tokens": ["T\u00f6nt", "sein", "ju\u00b7belnd", ":", "\u00bb"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPOSAT", "VVPP", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.18": {"line.1": {"text": "Volk und Diener \u00e4ngstlich flohen", "tokens": ["Volk", "und", "Die\u00b7ner", "\u00e4ngst\u00b7lich", "flo\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hier- und dorthin bei dem L\u00e4uten,", "tokens": ["Hier", "und", "dor\u00b7thin", "bei", "dem", "L\u00e4u\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch \u2013 kein Feuer sieht man lohen,", "tokens": ["Doch", "\u2013", "kein", "Feu\u00b7er", "sieht", "man", "lo\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PIAT", "NN", "VVFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Niemand wei\u00df den L\u00e4rm zu deuten.", "tokens": ["Nie\u00b7mand", "wei\u00df", "den", "L\u00e4rm", "zu", "deu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Wie nun Alles stand im Kranze", "tokens": ["Wie", "nun", "Al\u00b7les", "stand", "im", "Kran\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PIS", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und nicht g'nug sich wundern konnte,", "tokens": ["Und", "nicht", "g'\u00b7nug", "sich", "wun\u00b7dern", "konn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Schrieb Bojard die erste Stanze", "tokens": ["Schrieb", "Bo\u00b7jard", "die", "ers\u00b7te", "Stan\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NE", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Von dem Helden ", "tokens": ["Von", "dem", "Hel\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.20": {"line.1": {"text": "Und, dieweil ein Stein' alleine", "tokens": ["Und", ",", "die\u00b7weil", "ein", "Stein'", "al\u00b7lei\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "ADV"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Schon bewirkte solche Thaten,", "tokens": ["Schon", "be\u00b7wirk\u00b7te", "sol\u00b7che", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nennt man Alles, was zum Scheine", "tokens": ["Nennt", "man", "Al\u00b7les", ",", "was", "zum", "Schei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PIS", "$,", "PRELS", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00e4rmen macht: ", "tokens": ["L\u00e4r\u00b7men", "macht", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}