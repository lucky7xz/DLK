{"textgrid.poem.24151": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "Das M\u00e4dchen ohne Br\u00e4utigam", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn ich Braut bin, wenn ich Braut bin,", "tokens": ["Wenn", "ich", "Braut", "bin", ",", "wenn", "ich", "Braut", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAFIN", "$,", "KOUS", "PPER", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Will ich haben kein wei\u00dfes Kleid,", "tokens": ["Will", "ich", "ha\u00b7ben", "kein", "wei\u00b7\u00dfes", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Kein wei\u00dfes Kleid;", "tokens": ["Kein", "wei\u00b7\u00dfes", "Kleid", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Aus schwarzer Seide, so soll es sein,", "tokens": ["Aus", "schwar\u00b7zer", "Sei\u00b7de", ",", "so", "soll", "es", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADV", "VMFIN", "PPER", "VAINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Aber viele, viele wei\u00dfe Rosen drein,", "tokens": ["A\u00b7ber", "vie\u00b7le", ",", "vie\u00b7le", "wei\u00b7\u00dfe", "Ro\u00b7sen", "drein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PIAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Gro\u00dfe, wei\u00dfe Rosen gestickt.", "tokens": ["Gro\u00b7\u00dfe", ",", "wei\u00b7\u00dfe", "Ro\u00b7sen", "ge\u00b7stickt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "So will ich gehen, so will ich gehen,", "tokens": ["So", "will", "ich", "ge\u00b7hen", ",", "so", "will", "ich", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ganz langsam, langsam an den Altar.", "tokens": ["Ganz", "lang\u00b7sam", ",", "lang\u00b7sam", "an", "den", "Al\u00b7tar", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Aber rote Rosen, ganz dunkelrote Rosen", "tokens": ["A\u00b7ber", "ro\u00b7te", "Ro\u00b7sen", ",", "ganz", "dun\u00b7kel\u00b7ro\u00b7te", "Ro\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$,", "ADV", "ADJA", "NN"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Im Haar.", "tokens": ["Im", "Haar", "."], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.2": {"line.1": {"text": "Und mein Brauthemd? Mein Brauthemd?", "tokens": ["Und", "mein", "Brau\u00b7themd", "?", "Mein", "Brau\u00b7themd", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Wie soll das sein?", "tokens": ["Wie", "soll", "das", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Vom allerfeinsten Linnen", "tokens": ["Vom", "al\u00b7ler\u00b7feins\u00b7ten", "Lin\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und schneewei\u00df soll es sein.", "tokens": ["Und", "schnee\u00b7wei\u00df", "soll", "es", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Blos oben am Halse von Spitzen ein Rand", "tokens": ["Blos", "o\u00b7ben", "am", "Hal\u00b7se", "von", "Spit\u00b7zen", "ein", "Rand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPRART", "NN", "APPR", "NN", "ART", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und unter den Spitzen ein bla\u00dfblaues Band.", "tokens": ["Und", "un\u00b7ter", "den", "Spit\u00b7zen", "ein", "bla\u00df\u00b7blau\u00b7es", "Band", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+++-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "So soll mein wei\u00dfes Brauthemd sein.", "tokens": ["So", "soll", "mein", "wei\u00b7\u00dfes", "Brau\u00b7themd", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und dein Br\u00e4utigam, M\u00e4del, wie soll der sein?", "tokens": ["Und", "dein", "Br\u00e4u\u00b7ti\u00b7gam", ",", "M\u00e4\u00b7del", ",", "wie", "soll", "der", "sein", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NE", "$,", "NN", "$,", "PWAV", "VMFIN", "ART", "VAINF", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}}, "stanza.5": {"line.1": {"text": "Sch\u00f6n und stark soll mein Br\u00e4utigam sein,", "tokens": ["Sch\u00f6n", "und", "stark", "soll", "mein", "Br\u00e4u\u00b7ti\u00b7gam", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "VMFIN", "PPOSAT", "NN", "VAINF", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Nicht gar so baumlang, aber auch nicht klein,", "tokens": ["Nicht", "gar", "so", "baum\u00b7lang", ",", "a\u00b7ber", "auch", "nicht", "klein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "VVFIN", "$,", "ADV", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und nicht schniegelb\u00fcgelglatt;", "tokens": ["Und", "nicht", "schnie\u00b7gel\u00b7b\u00fc\u00b7gel\u00b7glatt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit den Augen soll er lachen,", "tokens": ["Mit", "den", "Au\u00b7gen", "soll", "er", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn er im Arme mich hat.", "tokens": ["Wenn", "er", "im", "Ar\u00b7me", "mich", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "Kennst du so Einen?", "tokens": ["Kennst", "du", "so", "Ei\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Gott, bist du dumm! Ich kenne keinen.", "tokens": ["Gott", ",", "bist", "du", "dumm", "!", "Ich", "ken\u00b7ne", "kei\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PPER", "ADJD", "$.", "PPER", "VVFIN", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn ich einen kennte und h\u00e4tt ihn lieb,", "tokens": ["Wenn", "ich", "ei\u00b7nen", "kenn\u00b7te", "und", "h\u00e4tt", "ihn", "lieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVFIN", "KON", "VAFIN", "PPER", "ADJD", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mir keine Zeit zum Ausmalen blieb.", "tokens": ["Mir", "kei\u00b7ne", "Zeit", "zum", "Aus\u00b7ma\u00b7len", "blieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "N\u00e4hm ihn, wie er w\u00e4re, ob gro\u00df oder klein;", "tokens": ["N\u00e4hm", "ihn", ",", "wie", "er", "w\u00e4\u00b7re", ",", "ob", "gro\u00df", "o\u00b7der", "klein", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PWAV", "PPER", "VAFIN", "$,", "KOUS", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Auch das Brautkleid sollte mir einerlei sein.", "tokens": ["Auch", "das", "Braut\u00b7kleid", "soll\u00b7te", "mir", "ei\u00b7ner\u00b7lei", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "W\u00fcrde nach seinem Auge mich kleiden", "tokens": ["W\u00fcr\u00b7de", "nach", "sei\u00b7nem", "Au\u00b7ge", "mich", "klei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "PPER", "VVINF"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "In schwarze oder wei\u00dfe Seiden.", "tokens": ["In", "schwar\u00b7ze", "o\u00b7der", "wei\u00b7\u00dfe", "Sei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wei\u00df doch, da\u00df mir alles steht.", "tokens": ["Wei\u00df", "doch", ",", "da\u00df", "mir", "al\u00b7les", "steht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "So ist dir gar nicht ernst, was du sagst!", "tokens": ["So", "ist", "dir", "gar", "nicht", "ernst", ",", "was", "du", "sagst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "Nein bist du dumm, wie so ernst du fragst!", "tokens": ["Nein", "bist", "du", "dumm", ",", "wie", "so", "ernst", "du", "fragst", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "PPER", "ADJD", "$,", "PWAV", "ADV", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Blos, da\u00df die Zeit vor\u00fcbergeht,", "tokens": ["Blos", ",", "da\u00df", "die", "Zeit", "vor\u00b7\u00fc\u00b7ber\u00b7geht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bis er kommt, den ich und der mich mag,", "tokens": ["Bis", "er", "kommt", ",", "den", "ich", "und", "der", "mich", "mag", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PRELS", "PPER", "KON", "ART", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Vermal ich bunt mir so den Tag.", "tokens": ["Ver\u00b7mal", "ich", "bunt", "mir", "so", "den", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach, dann, wenn er da ist, dann, ach, dann,", "tokens": ["Ach", ",", "dann", ",", "wenn", "er", "da", "ist", ",", "dann", ",", "ach", ",", "dann", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "$,", "KOUS", "PPER", "ADV", "VAFIN", "$,", "ADV", "$,", "ITJ", "$,", "ADV", "$,"], "meter": "-----+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Mal ich mir weder Kleid noch Mann.", "tokens": ["Mal", "ich", "mir", "we\u00b7der", "Kleid", "noch", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "KON", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dann thu ich ... Was denn?", "tokens": ["Dann", "thu", "ich", "...", "Was", "denn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "PWS", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Hasche mich, du!", "tokens": ["Ha\u00b7sche", "mich", ",", "du", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "$,", "PPER", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Na, so komme doch, lauf doch, greif doch zu!", "tokens": ["Na", ",", "so", "kom\u00b7me", "doch", ",", "lauf", "doch", ",", "greif", "doch", "zu", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "ADV", "$,", "ADV", "ADV", "$,", "ADJD", "ADV", "PTKVZ", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Gott, bist du langsam! Wenn ihr Alle so seid,", "tokens": ["Gott", ",", "bist", "du", "lang\u00b7sam", "!", "Wenn", "ihr", "Al\u00b7le", "so", "seid", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PPER", "ADJD", "$.", "KOUS", "PPER", "PIS", "ADV", "VAFIN", "$,"], "meter": "+--+---+--+", "measure": "dactylic.di.plus"}, "line.11": {"text": "Brauch ich niemals ein Hochzeitskleid.", "tokens": ["Brauch", "ich", "nie\u00b7mals", "ein", "Hoch\u00b7zeits\u00b7kleid", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.10": {"line.1": {"text": "Wenn ich Braut bin, wenn ich Braut bin,", "tokens": ["Wenn", "ich", "Braut", "bin", ",", "wenn", "ich", "Braut", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAFIN", "$,", "KOUS", "PPER", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Will ich haben kein wei\u00dfes Kleid,", "tokens": ["Will", "ich", "ha\u00b7ben", "kein", "wei\u00b7\u00dfes", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Kein wei\u00dfes Kleid;", "tokens": ["Kein", "wei\u00b7\u00dfes", "Kleid", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Aus schwarzer Seide, so soll es sein,", "tokens": ["Aus", "schwar\u00b7zer", "Sei\u00b7de", ",", "so", "soll", "es", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADV", "VMFIN", "PPER", "VAINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Aber viele, viele wei\u00dfe Rosen drein,", "tokens": ["A\u00b7ber", "vie\u00b7le", ",", "vie\u00b7le", "wei\u00b7\u00dfe", "Ro\u00b7sen", "drein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PIAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Gro\u00dfe, wei\u00dfe Rosen gestickt.", "tokens": ["Gro\u00b7\u00dfe", ",", "wei\u00b7\u00dfe", "Ro\u00b7sen", "ge\u00b7stickt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "So will ich gehen, so will ich gehen,", "tokens": ["So", "will", "ich", "ge\u00b7hen", ",", "so", "will", "ich", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ganz langsam, langsam an den Altar.", "tokens": ["Ganz", "lang\u00b7sam", ",", "lang\u00b7sam", "an", "den", "Al\u00b7tar", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Aber rote Rosen, ganz dunkelrote Rosen", "tokens": ["A\u00b7ber", "ro\u00b7te", "Ro\u00b7sen", ",", "ganz", "dun\u00b7kel\u00b7ro\u00b7te", "Ro\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$,", "ADV", "ADJA", "NN"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Im Haar.", "tokens": ["Im", "Haar", "."], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.11": {"line.1": {"text": "Und mein Brauthemd? Mein Brauthemd?", "tokens": ["Und", "mein", "Brau\u00b7themd", "?", "Mein", "Brau\u00b7themd", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Wie soll das sein?", "tokens": ["Wie", "soll", "das", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Vom allerfeinsten Linnen", "tokens": ["Vom", "al\u00b7ler\u00b7feins\u00b7ten", "Lin\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und schneewei\u00df soll es sein.", "tokens": ["Und", "schnee\u00b7wei\u00df", "soll", "es", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Blos oben am Halse von Spitzen ein Rand", "tokens": ["Blos", "o\u00b7ben", "am", "Hal\u00b7se", "von", "Spit\u00b7zen", "ein", "Rand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPRART", "NN", "APPR", "NN", "ART", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und unter den Spitzen ein bla\u00dfblaues Band.", "tokens": ["Und", "un\u00b7ter", "den", "Spit\u00b7zen", "ein", "bla\u00df\u00b7blau\u00b7es", "Band", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+++-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "So soll mein wei\u00dfes Brauthemd sein.", "tokens": ["So", "soll", "mein", "wei\u00b7\u00dfes", "Brau\u00b7themd", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und dein Br\u00e4utigam, M\u00e4del, wie soll der sein?", "tokens": ["Und", "dein", "Br\u00e4u\u00b7ti\u00b7gam", ",", "M\u00e4\u00b7del", ",", "wie", "soll", "der", "sein", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NE", "$,", "NN", "$,", "PWAV", "VMFIN", "ART", "VAINF", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}}, "stanza.14": {"line.1": {"text": "Sch\u00f6n und stark soll mein Br\u00e4utigam sein,", "tokens": ["Sch\u00f6n", "und", "stark", "soll", "mein", "Br\u00e4u\u00b7ti\u00b7gam", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "VMFIN", "PPOSAT", "NN", "VAINF", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Nicht gar so baumlang, aber auch nicht klein,", "tokens": ["Nicht", "gar", "so", "baum\u00b7lang", ",", "a\u00b7ber", "auch", "nicht", "klein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "VVFIN", "$,", "ADV", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und nicht schniegelb\u00fcgelglatt;", "tokens": ["Und", "nicht", "schnie\u00b7gel\u00b7b\u00fc\u00b7gel\u00b7glatt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit den Augen soll er lachen,", "tokens": ["Mit", "den", "Au\u00b7gen", "soll", "er", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn er im Arme mich hat.", "tokens": ["Wenn", "er", "im", "Ar\u00b7me", "mich", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.15": {"line.1": {"text": "Kennst du so Einen?", "tokens": ["Kennst", "du", "so", "Ei\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "Gott, bist du dumm! Ich kenne keinen.", "tokens": ["Gott", ",", "bist", "du", "dumm", "!", "Ich", "ken\u00b7ne", "kei\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PPER", "ADJD", "$.", "PPER", "VVFIN", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn ich einen kennte und h\u00e4tt ihn lieb,", "tokens": ["Wenn", "ich", "ei\u00b7nen", "kenn\u00b7te", "und", "h\u00e4tt", "ihn", "lieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVFIN", "KON", "VAFIN", "PPER", "ADJD", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mir keine Zeit zum Ausmalen blieb.", "tokens": ["Mir", "kei\u00b7ne", "Zeit", "zum", "Aus\u00b7ma\u00b7len", "blieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "N\u00e4hm ihn, wie er w\u00e4re, ob gro\u00df oder klein;", "tokens": ["N\u00e4hm", "ihn", ",", "wie", "er", "w\u00e4\u00b7re", ",", "ob", "gro\u00df", "o\u00b7der", "klein", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PWAV", "PPER", "VAFIN", "$,", "KOUS", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Auch das Brautkleid sollte mir einerlei sein.", "tokens": ["Auch", "das", "Braut\u00b7kleid", "soll\u00b7te", "mir", "ei\u00b7ner\u00b7lei", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "W\u00fcrde nach seinem Auge mich kleiden", "tokens": ["W\u00fcr\u00b7de", "nach", "sei\u00b7nem", "Au\u00b7ge", "mich", "klei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "PPER", "VVINF"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "In schwarze oder wei\u00dfe Seiden.", "tokens": ["In", "schwar\u00b7ze", "o\u00b7der", "wei\u00b7\u00dfe", "Sei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wei\u00df doch, da\u00df mir alles steht.", "tokens": ["Wei\u00df", "doch", ",", "da\u00df", "mir", "al\u00b7les", "steht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "So ist dir gar nicht ernst, was du sagst!", "tokens": ["So", "ist", "dir", "gar", "nicht", "ernst", ",", "was", "du", "sagst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.18": {"line.1": {"text": "Nein bist du dumm, wie so ernst du fragst!", "tokens": ["Nein", "bist", "du", "dumm", ",", "wie", "so", "ernst", "du", "fragst", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "PPER", "ADJD", "$,", "PWAV", "ADV", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Blos, da\u00df die Zeit vor\u00fcbergeht,", "tokens": ["Blos", ",", "da\u00df", "die", "Zeit", "vor\u00b7\u00fc\u00b7ber\u00b7geht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bis er kommt, den ich und der mich mag,", "tokens": ["Bis", "er", "kommt", ",", "den", "ich", "und", "der", "mich", "mag", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PRELS", "PPER", "KON", "ART", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Vermal ich bunt mir so den Tag.", "tokens": ["Ver\u00b7mal", "ich", "bunt", "mir", "so", "den", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach, dann, wenn er da ist, dann, ach, dann,", "tokens": ["Ach", ",", "dann", ",", "wenn", "er", "da", "ist", ",", "dann", ",", "ach", ",", "dann", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "$,", "KOUS", "PPER", "ADV", "VAFIN", "$,", "ADV", "$,", "ITJ", "$,", "ADV", "$,"], "meter": "-----+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Mal ich mir weder Kleid noch Mann.", "tokens": ["Mal", "ich", "mir", "we\u00b7der", "Kleid", "noch", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "KON", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dann thu ich ... Was denn?", "tokens": ["Dann", "thu", "ich", "...", "Was", "denn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "PWS", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Hasche mich, du!", "tokens": ["Ha\u00b7sche", "mich", ",", "du", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "$,", "PPER", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Na, so komme doch, lauf doch, greif doch zu!", "tokens": ["Na", ",", "so", "kom\u00b7me", "doch", ",", "lauf", "doch", ",", "greif", "doch", "zu", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "ADV", "$,", "ADV", "ADV", "$,", "ADJD", "ADV", "PTKVZ", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Gott, bist du langsam! Wenn ihr Alle so seid,", "tokens": ["Gott", ",", "bist", "du", "lang\u00b7sam", "!", "Wenn", "ihr", "Al\u00b7le", "so", "seid", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PPER", "ADJD", "$.", "KOUS", "PPER", "PIS", "ADV", "VAFIN", "$,"], "meter": "+--+---+--+", "measure": "dactylic.di.plus"}, "line.11": {"text": "Brauch ich niemals ein Hochzeitskleid.", "tokens": ["Brauch", "ich", "nie\u00b7mals", "ein", "Hoch\u00b7zeits\u00b7kleid", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}