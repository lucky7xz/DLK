{"textgrid.poem.41406": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der Blumenkranz", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dort, wo die Alster sich in engen Ufern kr\u00fcmmt,", "tokens": ["Dort", ",", "wo", "die", "Als\u00b7ter", "sich", "in", "en\u00b7gen", "U\u00b7fern", "kr\u00fcmmt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und rauschend ihren Lauf durch Busch und W\u00e4lder nimmt,", "tokens": ["Und", "rau\u00b7schend", "ih\u00b7ren", "Lauf", "durch", "Busch", "und", "W\u00e4l\u00b7der", "nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo deutsche Treue sich beim deutschen Handschlag findet,", "tokens": ["Wo", "deut\u00b7sche", "Treu\u00b7e", "sich", "beim", "deut\u00b7schen", "Hand\u00b7schlag", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "PRF", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des Landmanns froher Flei\u00df f\u00fcr sich die Garben bindet", "tokens": ["Des", "Land\u00b7manns", "fro\u00b7her", "Flei\u00df", "f\u00fcr", "sich", "die", "Gar\u00b7ben", "bin\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "PRF", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und alte Freiheit noch den angeerbten Hut", "tokens": ["Und", "al\u00b7te", "Frei\u00b7heit", "noch", "den", "an\u00b7ge\u00b7erb\u00b7ten", "Hut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Frisch in die Augen dr\u00fcckt, und unbefehdet ruht;", "tokens": ["Frisch", "in", "die", "Au\u00b7gen", "dr\u00fcckt", ",", "und", "un\u00b7be\u00b7feh\u00b7det", "ruht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da ist ein k\u00fchler Ort, dem keine Sch\u00f6nheit fehlet,", "tokens": ["Da", "ist", "ein", "k\u00fch\u00b7ler", "Ort", ",", "dem", "kei\u00b7ne", "Sch\u00f6n\u00b7heit", "feh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Amor hundert Mal der Eifersucht verhehlet,", "tokens": ["Den", "A\u00b7mor", "hun\u00b7dert", "Mal", "der", "Ei\u00b7fer\u00b7sucht", "ver\u00b7heh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "CARD", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und dem allein entdeckt, der ihn zum F\u00fchrer w\u00e4hlet.", "tokens": ["Und", "dem", "al\u00b7lein", "ent\u00b7deckt", ",", "der", "ihn", "zum", "F\u00fch\u00b7rer", "w\u00e4h\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "VVPP", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Der Zephyr folgt mit Lust den kurzen Wellen nach,", "tokens": ["Der", "Ze\u00b7phyr", "folgt", "mit", "Lust", "den", "kur\u00b7zen", "Wel\u00b7len", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die hier in gr\u00fcne Tiefen fallen;", "tokens": ["Die", "hier", "in", "gr\u00fc\u00b7ne", "Tie\u00b7fen", "fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Sch\u00e4fer nennen's einen Bach,", "tokens": ["Die", "Sch\u00e4\u00b7fer", "nen\u00b7nen's", "ei\u00b7nen", "Bach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Wir Dichter flie\u00dfende Krystallen.", "tokens": ["Wir", "Dich\u00b7ter", "flie\u00b7\u00dfen\u00b7de", "Krys\u00b7tal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADJA", "NN", "$."], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.5": {"text": "Ein dick' Gestr\u00e4uch umschr\u00e4nkt die innre Spur,", "tokens": ["Ein", "dick'", "Ge\u00b7str\u00e4uch", "um\u00b7schr\u00e4nkt", "die", "inn\u00b7re", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wohin oft Wunsch und Sehnsucht leiten,", "tokens": ["Wo\u00b7hin", "oft", "Wunsch", "und", "Sehn\u00b7sucht", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Auf diesen Platz lockt uns die Liebe nur,", "tokens": ["Auf", "die\u00b7sen", "Platz", "lockt", "uns", "die", "Lie\u00b7be", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und ihre Mutter, die Natur.", "tokens": ["Und", "ih\u00b7re", "Mut\u00b7ter", ",", "die", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Hier sa\u00df Matild'. Es eilet ihr zur Seiten", "tokens": ["Hier", "sa\u00df", "Ma\u00b7tild'", ".", "Es", "ei\u00b7let", "ihr", "zur", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "$.", "PPER", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein kleiner Schwarm verbuhlter Fr\u00f6hlichkeiten:", "tokens": ["Ein", "klei\u00b7ner", "Schwarm", "ver\u00b7buhl\u00b7ter", "Fr\u00f6h\u00b7lich\u00b7kei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der schlaue Scherz, die s\u00fc\u00dfe Schmeichelei,", "tokens": ["Der", "schlau\u00b7e", "Scherz", ",", "die", "s\u00fc\u00b7\u00dfe", "Schmei\u00b7che\u00b7lei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die Hoffnung selbst, und Reinhold k\u00f6mmt herbei,", "tokens": ["Die", "Hoff\u00b7nung", "selbst", ",", "und", "Rein\u00b7hold", "k\u00f6mmt", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "KON", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der sie so oft besingt, so unverstellt verehret,", "tokens": ["Der", "sie", "so", "oft", "be\u00b7singt", ",", "so", "un\u00b7ver\u00b7stellt", "ver\u00b7eh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVFIN", "$,", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und in der Einsamkeit sie blos aus Liebe st\u00f6ret.", "tokens": ["Und", "in", "der", "Ein\u00b7sam\u00b7keit", "sie", "blos", "aus", "Lie\u00b7be", "st\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Auf seinen Wangen ist zu schaun,", "tokens": ["Auf", "sei\u00b7nen", "Wan\u00b7gen", "ist", "zu", "schaun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Anstatt der Jugend Milch, ein lebhaft, m\u00e4nnlich Braun.", "tokens": ["An\u00b7statt", "der", "Ju\u00b7gend", "Milch", ",", "ein", "leb\u00b7haft", ",", "m\u00e4nn\u00b7lich", "Braun", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "ART", "ADJD", "$,", "ADJD", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den Augen fehlt kein Geist, noch Ehrfurcht den Geberden.", "tokens": ["Den", "Au\u00b7gen", "fehlt", "kein", "Geist", ",", "noch", "Ehr\u00b7furcht", "den", "Ge\u00b7ber\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$,", "ADV", "NN", "ART", "NN", "$."], "meter": "-+-+-+-++-+--", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Er hat, was man gebraucht, nie sehr geha\u00dft zu werden.", "tokens": ["Er", "hat", ",", "was", "man", "ge\u00b7braucht", ",", "nie", "sehr", "ge\u00b7ha\u00dft", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PIS", "VVPP", "$,", "ADV", "ADV", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Dies ist des Reinholds Bild, der seiner Sch\u00f6nen Hand", "tokens": ["Dies", "ist", "des", "Rein\u00b7holds", "Bild", ",", "der", "sei\u00b7ner", "Sch\u00f6\u00b7nen", "Hand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "$,", "PRELS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Voll auserles'ner Blumen fand,", "tokens": ["Voll", "aus\u00b7er\u00b7les'\u00b7ner", "Blu\u00b7men", "fand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Woraus sie einen Kranz zu kn\u00fcpfen angefangen,", "tokens": ["Wo\u00b7raus", "sie", "ei\u00b7nen", "Kranz", "zu", "kn\u00fcp\u00b7fen", "an\u00b7ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "PTKZU", "VVINF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den unerkauften Schmuck, mit dem nur Hirten prangen.", "tokens": ["Den", "un\u00b7er\u00b7kauf\u00b7ten", "Schmuck", ",", "mit", "dem", "nur", "Hir\u00b7ten", "pran\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Allein, sobald sie hier den muntern Freund erblickt,", "tokens": ["Al\u00b7lein", ",", "so\u00b7bald", "sie", "hier", "den", "mun\u00b7tern", "Freund", "er\u00b7blickt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Will ihr die Arbeit nicht, so wie zuvor, gelingen.", "tokens": ["Will", "ihr", "die", "Ar\u00b7beit", "nicht", ",", "so", "wie", "zu\u00b7vor", ",", "ge\u00b7lin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "PTKNEG", "$,", "ADV", "KOKOM", "ADV", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Fast jeder Stengel wird durch ihr Versehn zerknickt,", "tokens": ["Fast", "je\u00b7der", "Sten\u00b7gel", "wird", "durch", "ihr", "Ver\u00b7sehn", "zer\u00b7knickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Reinhold wird versandt, ihr frische herzubringen.", "tokens": ["Und", "Rein\u00b7hold", "wird", "ver\u00b7sandt", ",", "ihr", "fri\u00b7sche", "her\u00b7zu\u00b7brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "VVPP", "$,", "PPOSAT", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er thut es; doch umsonst, und siehet mit Verdru\u00df", "tokens": ["Er", "thut", "es", ";", "doch", "um\u00b7sonst", ",", "und", "sie\u00b7het", "mit", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$.", "ADV", "ADV", "$,", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Blumen, die er reicht, so wie die ersten, brechen.", "tokens": ["Die", "Blu\u00b7men", ",", "die", "er", "reicht", ",", "so", "wie", "die", "ers\u00b7ten", ",", "bre\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "KOKOM", "ART", "ADJA", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dies, spricht er, ist zu viel! Ich will durch \u00f6ftern Ku\u00df", "tokens": ["Dies", ",", "spricht", "er", ",", "ist", "zu", "viel", "!", "Ich", "will", "durch", "\u00f6f\u00b7tern", "Ku\u00df"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PTKA", "PIS", "$.", "PPER", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Unvorsichtigkeit bei jeder Blume r\u00e4chen.", "tokens": ["Die", "Un\u00b7vor\u00b7sich\u00b7tig\u00b7keit", "bei", "je\u00b7der", "Blu\u00b7me", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sie l\u00e4chelt, und schweigt still, f\u00e4ngt auch von neuem an.", "tokens": ["Sie", "l\u00e4\u00b7chelt", ",", "und", "schweigt", "still", ",", "f\u00e4ngt", "auch", "von", "neu\u00b7em", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "PTKVZ", "$,", "VVFIN", "ADV", "APPR", "ADJA", "PTKVZ", "$."], "meter": "-+--++-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Wiewol, wer kann vorher des Schicksals T\u00fccke wissen?", "tokens": ["Wie\u00b7wol", ",", "wer", "kann", "vor\u00b7her", "des", "Schick\u00b7sals", "T\u00fc\u00b7cke", "wis\u00b7sen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "VMFIN", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da ihr auch der Versuch noch minder gl\u00fccken kann,", "tokens": ["Da", "ihr", "auch", "der", "Ver\u00b7such", "noch", "min\u00b7der", "gl\u00fc\u00b7cken", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So wird der ganze Kranz, voll Ungeduld, zerrissen;", "tokens": ["So", "wird", "der", "gan\u00b7ze", "Kranz", ",", "voll", "Un\u00b7ge\u00b7duld", ",", "zer\u00b7ris\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,", "ADJD", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und Reinhold gibt nunmehr gerechter Strenge Raum.", "tokens": ["Und", "Rein\u00b7hold", "gibt", "nun\u00b7mehr", "ge\u00b7rech\u00b7ter", "Stren\u00b7ge", "Raum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADV", "ADJD", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wem wird im K\u00fcssen nicht die Rache s\u00fc\u00dfer schmecken?", "tokens": ["Wem", "wird", "im", "K\u00fcs\u00b7sen", "nicht", "die", "Ra\u00b7che", "s\u00fc\u00b7\u00dfer", "schme\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPRART", "NN", "PTKNEG", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Er n\u00e4hert sich, sie seufzt: er straft, sie murret kaum.", "tokens": ["Er", "n\u00e4\u00b7hert", "sich", ",", "sie", "seufzt", ":", "er", "straft", ",", "sie", "mur\u00b7ret", "kaum", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "PPER", "VVFIN", "$.", "PPER", "ADJD", "$,", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Hier schlie\u00dft sich Busch und Wald, sie hilfreich zu verstecken.", "tokens": ["Hier", "schlie\u00dft", "sich", "Busch", "und", "Wald", ",", "sie", "hilf\u00b7reich", "zu", "ver\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NN", "KON", "NN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Man glaubt, sie thaten dies, was einst Aeneas that,", "tokens": ["Man", "glaubt", ",", "sie", "tha\u00b7ten", "dies", ",", "was", "einst", "A\u00b7e\u00b7neas", "that", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "PDS", "$,", "PRELS", "ADV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als Dido und der Held in einer H\u00f6hle waren.", "tokens": ["Als", "Di\u00b7do", "und", "der", "Held", "in", "ei\u00b7ner", "H\u00f6h\u00b7le", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "KON", "ART", "NN", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was aber thaten die? Wer das zu fragen hat,", "tokens": ["Was", "a\u00b7ber", "tha\u00b7ten", "die", "?", "Wer", "das", "zu", "fra\u00b7gen", "hat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "ART", "$.", "PWS", "PDS", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der ist nicht werth, es zu erfahren.", "tokens": ["Der", "ist", "nicht", "werth", ",", "es", "zu", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADJD", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Dort, wo die Alster sich in engen Ufern kr\u00fcmmt,", "tokens": ["Dort", ",", "wo", "die", "Als\u00b7ter", "sich", "in", "en\u00b7gen", "U\u00b7fern", "kr\u00fcmmt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und rauschend ihren Lauf durch Busch und W\u00e4lder nimmt,", "tokens": ["Und", "rau\u00b7schend", "ih\u00b7ren", "Lauf", "durch", "Busch", "und", "W\u00e4l\u00b7der", "nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo deutsche Treue sich beim deutschen Handschlag findet,", "tokens": ["Wo", "deut\u00b7sche", "Treu\u00b7e", "sich", "beim", "deut\u00b7schen", "Hand\u00b7schlag", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "PRF", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des Landmanns froher Flei\u00df f\u00fcr sich die Garben bindet", "tokens": ["Des", "Land\u00b7manns", "fro\u00b7her", "Flei\u00df", "f\u00fcr", "sich", "die", "Gar\u00b7ben", "bin\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "PRF", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und alte Freiheit noch den angeerbten Hut", "tokens": ["Und", "al\u00b7te", "Frei\u00b7heit", "noch", "den", "an\u00b7ge\u00b7erb\u00b7ten", "Hut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Frisch in die Augen dr\u00fcckt, und unbefehdet ruht;", "tokens": ["Frisch", "in", "die", "Au\u00b7gen", "dr\u00fcckt", ",", "und", "un\u00b7be\u00b7feh\u00b7det", "ruht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da ist ein k\u00fchler Ort, dem keine Sch\u00f6nheit fehlet,", "tokens": ["Da", "ist", "ein", "k\u00fch\u00b7ler", "Ort", ",", "dem", "kei\u00b7ne", "Sch\u00f6n\u00b7heit", "feh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Amor hundert Mal der Eifersucht verhehlet,", "tokens": ["Den", "A\u00b7mor", "hun\u00b7dert", "Mal", "der", "Ei\u00b7fer\u00b7sucht", "ver\u00b7heh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "CARD", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und dem allein entdeckt, der ihn zum F\u00fchrer w\u00e4hlet.", "tokens": ["Und", "dem", "al\u00b7lein", "ent\u00b7deckt", ",", "der", "ihn", "zum", "F\u00fch\u00b7rer", "w\u00e4h\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "VVPP", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Der Zephyr folgt mit Lust den kurzen Wellen nach,", "tokens": ["Der", "Ze\u00b7phyr", "folgt", "mit", "Lust", "den", "kur\u00b7zen", "Wel\u00b7len", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die hier in gr\u00fcne Tiefen fallen;", "tokens": ["Die", "hier", "in", "gr\u00fc\u00b7ne", "Tie\u00b7fen", "fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Sch\u00e4fer nennen's einen Bach,", "tokens": ["Die", "Sch\u00e4\u00b7fer", "nen\u00b7nen's", "ei\u00b7nen", "Bach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Wir Dichter flie\u00dfende Krystallen.", "tokens": ["Wir", "Dich\u00b7ter", "flie\u00b7\u00dfen\u00b7de", "Krys\u00b7tal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADJA", "NN", "$."], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.5": {"text": "Ein dick' Gestr\u00e4uch umschr\u00e4nkt die innre Spur,", "tokens": ["Ein", "dick'", "Ge\u00b7str\u00e4uch", "um\u00b7schr\u00e4nkt", "die", "inn\u00b7re", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wohin oft Wunsch und Sehnsucht leiten,", "tokens": ["Wo\u00b7hin", "oft", "Wunsch", "und", "Sehn\u00b7sucht", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Auf diesen Platz lockt uns die Liebe nur,", "tokens": ["Auf", "die\u00b7sen", "Platz", "lockt", "uns", "die", "Lie\u00b7be", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und ihre Mutter, die Natur.", "tokens": ["Und", "ih\u00b7re", "Mut\u00b7ter", ",", "die", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Hier sa\u00df Matild'. Es eilet ihr zur Seiten", "tokens": ["Hier", "sa\u00df", "Ma\u00b7tild'", ".", "Es", "ei\u00b7let", "ihr", "zur", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "$.", "PPER", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein kleiner Schwarm verbuhlter Fr\u00f6hlichkeiten:", "tokens": ["Ein", "klei\u00b7ner", "Schwarm", "ver\u00b7buhl\u00b7ter", "Fr\u00f6h\u00b7lich\u00b7kei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der schlaue Scherz, die s\u00fc\u00dfe Schmeichelei,", "tokens": ["Der", "schlau\u00b7e", "Scherz", ",", "die", "s\u00fc\u00b7\u00dfe", "Schmei\u00b7che\u00b7lei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die Hoffnung selbst, und Reinhold k\u00f6mmt herbei,", "tokens": ["Die", "Hoff\u00b7nung", "selbst", ",", "und", "Rein\u00b7hold", "k\u00f6mmt", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "KON", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der sie so oft besingt, so unverstellt verehret,", "tokens": ["Der", "sie", "so", "oft", "be\u00b7singt", ",", "so", "un\u00b7ver\u00b7stellt", "ver\u00b7eh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVFIN", "$,", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und in der Einsamkeit sie blos aus Liebe st\u00f6ret.", "tokens": ["Und", "in", "der", "Ein\u00b7sam\u00b7keit", "sie", "blos", "aus", "Lie\u00b7be", "st\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Auf seinen Wangen ist zu schaun,", "tokens": ["Auf", "sei\u00b7nen", "Wan\u00b7gen", "ist", "zu", "schaun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Anstatt der Jugend Milch, ein lebhaft, m\u00e4nnlich Braun.", "tokens": ["An\u00b7statt", "der", "Ju\u00b7gend", "Milch", ",", "ein", "leb\u00b7haft", ",", "m\u00e4nn\u00b7lich", "Braun", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "ART", "ADJD", "$,", "ADJD", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den Augen fehlt kein Geist, noch Ehrfurcht den Geberden.", "tokens": ["Den", "Au\u00b7gen", "fehlt", "kein", "Geist", ",", "noch", "Ehr\u00b7furcht", "den", "Ge\u00b7ber\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$,", "ADV", "NN", "ART", "NN", "$."], "meter": "-+-+-+-++-+--", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Er hat, was man gebraucht, nie sehr geha\u00dft zu werden.", "tokens": ["Er", "hat", ",", "was", "man", "ge\u00b7braucht", ",", "nie", "sehr", "ge\u00b7ha\u00dft", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PIS", "VVPP", "$,", "ADV", "ADV", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Dies ist des Reinholds Bild, der seiner Sch\u00f6nen Hand", "tokens": ["Dies", "ist", "des", "Rein\u00b7holds", "Bild", ",", "der", "sei\u00b7ner", "Sch\u00f6\u00b7nen", "Hand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "$,", "PRELS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Voll auserles'ner Blumen fand,", "tokens": ["Voll", "aus\u00b7er\u00b7les'\u00b7ner", "Blu\u00b7men", "fand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Woraus sie einen Kranz zu kn\u00fcpfen angefangen,", "tokens": ["Wo\u00b7raus", "sie", "ei\u00b7nen", "Kranz", "zu", "kn\u00fcp\u00b7fen", "an\u00b7ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "PTKZU", "VVINF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den unerkauften Schmuck, mit dem nur Hirten prangen.", "tokens": ["Den", "un\u00b7er\u00b7kauf\u00b7ten", "Schmuck", ",", "mit", "dem", "nur", "Hir\u00b7ten", "pran\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Allein, sobald sie hier den muntern Freund erblickt,", "tokens": ["Al\u00b7lein", ",", "so\u00b7bald", "sie", "hier", "den", "mun\u00b7tern", "Freund", "er\u00b7blickt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Will ihr die Arbeit nicht, so wie zuvor, gelingen.", "tokens": ["Will", "ihr", "die", "Ar\u00b7beit", "nicht", ",", "so", "wie", "zu\u00b7vor", ",", "ge\u00b7lin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "PTKNEG", "$,", "ADV", "KOKOM", "ADV", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Fast jeder Stengel wird durch ihr Versehn zerknickt,", "tokens": ["Fast", "je\u00b7der", "Sten\u00b7gel", "wird", "durch", "ihr", "Ver\u00b7sehn", "zer\u00b7knickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Reinhold wird versandt, ihr frische herzubringen.", "tokens": ["Und", "Rein\u00b7hold", "wird", "ver\u00b7sandt", ",", "ihr", "fri\u00b7sche", "her\u00b7zu\u00b7brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "VVPP", "$,", "PPOSAT", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er thut es; doch umsonst, und siehet mit Verdru\u00df", "tokens": ["Er", "thut", "es", ";", "doch", "um\u00b7sonst", ",", "und", "sie\u00b7het", "mit", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$.", "ADV", "ADV", "$,", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Blumen, die er reicht, so wie die ersten, brechen.", "tokens": ["Die", "Blu\u00b7men", ",", "die", "er", "reicht", ",", "so", "wie", "die", "ers\u00b7ten", ",", "bre\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "KOKOM", "ART", "ADJA", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dies, spricht er, ist zu viel! Ich will durch \u00f6ftern Ku\u00df", "tokens": ["Dies", ",", "spricht", "er", ",", "ist", "zu", "viel", "!", "Ich", "will", "durch", "\u00f6f\u00b7tern", "Ku\u00df"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PTKA", "PIS", "$.", "PPER", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Unvorsichtigkeit bei jeder Blume r\u00e4chen.", "tokens": ["Die", "Un\u00b7vor\u00b7sich\u00b7tig\u00b7keit", "bei", "je\u00b7der", "Blu\u00b7me", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sie l\u00e4chelt, und schweigt still, f\u00e4ngt auch von neuem an.", "tokens": ["Sie", "l\u00e4\u00b7chelt", ",", "und", "schweigt", "still", ",", "f\u00e4ngt", "auch", "von", "neu\u00b7em", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "PTKVZ", "$,", "VVFIN", "ADV", "APPR", "ADJA", "PTKVZ", "$."], "meter": "-+--++-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Wiewol, wer kann vorher des Schicksals T\u00fccke wissen?", "tokens": ["Wie\u00b7wol", ",", "wer", "kann", "vor\u00b7her", "des", "Schick\u00b7sals", "T\u00fc\u00b7cke", "wis\u00b7sen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "VMFIN", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da ihr auch der Versuch noch minder gl\u00fccken kann,", "tokens": ["Da", "ihr", "auch", "der", "Ver\u00b7such", "noch", "min\u00b7der", "gl\u00fc\u00b7cken", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So wird der ganze Kranz, voll Ungeduld, zerrissen;", "tokens": ["So", "wird", "der", "gan\u00b7ze", "Kranz", ",", "voll", "Un\u00b7ge\u00b7duld", ",", "zer\u00b7ris\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,", "ADJD", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und Reinhold gibt nunmehr gerechter Strenge Raum.", "tokens": ["Und", "Rein\u00b7hold", "gibt", "nun\u00b7mehr", "ge\u00b7rech\u00b7ter", "Stren\u00b7ge", "Raum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADV", "ADJD", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wem wird im K\u00fcssen nicht die Rache s\u00fc\u00dfer schmecken?", "tokens": ["Wem", "wird", "im", "K\u00fcs\u00b7sen", "nicht", "die", "Ra\u00b7che", "s\u00fc\u00b7\u00dfer", "schme\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPRART", "NN", "PTKNEG", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Er n\u00e4hert sich, sie seufzt: er straft, sie murret kaum.", "tokens": ["Er", "n\u00e4\u00b7hert", "sich", ",", "sie", "seufzt", ":", "er", "straft", ",", "sie", "mur\u00b7ret", "kaum", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "PPER", "VVFIN", "$.", "PPER", "ADJD", "$,", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Hier schlie\u00dft sich Busch und Wald, sie hilfreich zu verstecken.", "tokens": ["Hier", "schlie\u00dft", "sich", "Busch", "und", "Wald", ",", "sie", "hilf\u00b7reich", "zu", "ver\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NN", "KON", "NN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Man glaubt, sie thaten dies, was einst Aeneas that,", "tokens": ["Man", "glaubt", ",", "sie", "tha\u00b7ten", "dies", ",", "was", "einst", "A\u00b7e\u00b7neas", "that", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "PDS", "$,", "PRELS", "ADV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als Dido und der Held in einer H\u00f6hle waren.", "tokens": ["Als", "Di\u00b7do", "und", "der", "Held", "in", "ei\u00b7ner", "H\u00f6h\u00b7le", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "KON", "ART", "NN", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was aber thaten die? Wer das zu fragen hat,", "tokens": ["Was", "a\u00b7ber", "tha\u00b7ten", "die", "?", "Wer", "das", "zu", "fra\u00b7gen", "hat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "ART", "$.", "PWS", "PDS", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der ist nicht werth, es zu erfahren.", "tokens": ["Der", "ist", "nicht", "werth", ",", "es", "zu", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADJD", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}