{"textgrid.poem.61891": {"metadata": {"author": {"name": "Geibel, Emanuel", "birth": "N.A.", "death": "N.A."}, "title": "Neugriechischer Mythus", "genre": "verse", "period": "N.A.", "pub_year": 1833, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hoch auf Suniums Felsenklippe", "tokens": ["Hoch", "auf", "Su\u00b7ni\u00b7ums", "Fel\u00b7sen\u00b7klip\u00b7pe"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "An zerborstner Tempelwand", "tokens": ["An", "zer\u00b7borst\u00b7ner", "Tem\u00b7pel\u00b7wand"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwischen Schutt und Dorngestrippe", "tokens": ["Zwi\u00b7schen", "Schutt", "und", "Dorn\u00b7ge\u00b7strip\u00b7pe"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lehnt' ich, als der Abend schwand.", "tokens": ["Lehnt'", "ich", ",", "als", "der", "A\u00b7bend", "schwand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Um die S\u00e4ulenkn\u00e4ufe flogen", "tokens": ["Um", "die", "S\u00e4u\u00b7len\u00b7kn\u00e4u\u00b7fe", "flo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "M\u00f6wenschw\u00e4rme kreischend her,", "tokens": ["M\u00f6\u00b7wen\u00b7schw\u00e4r\u00b7me", "krei\u00b7schend", "her", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und im endlos weiten Bogen", "tokens": ["Und", "im", "end\u00b7los", "wei\u00b7ten", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJD", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Mir zu F\u00fc\u00dfen lag das Meer.", "tokens": ["Mir", "zu", "F\u00fc\u00b7\u00dfen", "lag", "das", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Und indes im Sp\u00e4trotscheine", "tokens": ["Und", "in\u00b7des", "im", "Sp\u00e4t\u00b7rot\u00b7schei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Fern den Blick ich schweifen lie\u00df,", "tokens": ["Fern", "den", "Blick", "ich", "schwei\u00b7fen", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPER", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Plauderte die braune Kleine,", "tokens": ["Plau\u00b7der\u00b7te", "die", "brau\u00b7ne", "Klei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die vom Tal den Pfad mir wies.", "tokens": ["Die", "vom", "Tal", "den", "Pfad", "mir", "wies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Vieles wu\u00dfte sie zu melden", "tokens": ["Vie\u00b7les", "wu\u00df\u00b7te", "sie", "zu", "mel\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von der gro\u00dfen Perserschlacht,", "tokens": ["Von", "der", "gro\u00b7\u00dfen", "Per\u00b7ser\u00b7schlacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Von Themistokles, dem Helden,", "tokens": ["Von", "The\u00b7mis\u00b7to\u00b7kles", ",", "dem", "Hel\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Welcher Hellas frei gemacht;", "tokens": ["Wel\u00b7cher", "Hel\u00b7las", "frei", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wie er klug den Sieg erworben,", "tokens": ["Wie", "er", "klug", "den", "Sieg", "er\u00b7wor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch geweihten Spruch belehrt,", "tokens": ["Durch", "ge\u00b7weih\u00b7ten", "Spruch", "be\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie er drauf verbannt gestorben", "tokens": ["Wie", "er", "drauf", "ver\u00b7bannt", "ge\u00b7stor\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PAV", "VVFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und im Tod erst heimgekehrt.", "tokens": ["Und", "im", "Tod", "erst", "heim\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.6": {"line.1": {"text": "\u00bbdort an jener Felsenecke\u00ab,", "tokens": ["\u00bb", "dort", "an", "je\u00b7ner", "Fel\u00b7sen\u00b7ec\u00b7ke", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "APPR", "PDAT", "NN", "$(", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprach sie, \u00bbgl\u00e4nzt an stillem Tag", "tokens": ["Sprach", "sie", ",", "\u00bb", "gl\u00e4nzt", "an", "stil\u00b7lem", "Tag"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "$(", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch die gr\u00fcne Wasserdecke", "tokens": ["Durch", "die", "gr\u00fc\u00b7ne", "Was\u00b7ser\u00b7de\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein versunkner Sarkophag.", "tokens": ["Ein", "ver\u00b7sun\u00b7kner", "Sar\u00b7ko\u00b7phag", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Drinnen lag der Held begraben,", "tokens": ["Drin\u00b7nen", "lag", "der", "Held", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch das Meer hat ihn erw\u00fchlt,", "tokens": ["Doch", "das", "Meer", "hat", "ihn", "er\u00b7w\u00fchlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die gro\u00dfen Wogen haben", "tokens": ["Und", "die", "gro\u00b7\u00dfen", "Wo\u00b7gen", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sein Gebein hinweggesp\u00fclt.", "tokens": ["Sein", "Ge\u00b7bein", "hin\u00b7weg\u00b7ge\u00b7sp\u00fclt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Aber einst, hab' ich vernommen,", "tokens": ["A\u00b7ber", "einst", ",", "hab'", "ich", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird der Retter Griechenlands", "tokens": ["Wird", "der", "Ret\u00b7ter", "Grie\u00b7chen\u00b7lands"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus der Tiefe wiederkommen", "tokens": ["Aus", "der", "Tie\u00b7fe", "wie\u00b7der\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und uns f\u00fchren gen Byzanz;", "tokens": ["Und", "uns", "f\u00fch\u00b7ren", "gen", "By\u00b7zanz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wird uns dort das Reich best\u00e4t'gen", "tokens": ["Wird", "uns", "dort", "das", "Reich", "be\u00b7st\u00e4t'\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und erh\u00f6hn das Kreuzpanier!\u00ab \u2013", "tokens": ["Und", "er\u00b7h\u00f6hn", "das", "Kreuz\u00b7pa\u00b7nier", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Also sprach das Hirtenm\u00e4dchen,", "tokens": ["Al\u00b7so", "sprach", "das", "Hir\u00b7ten\u00b7m\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Augen gl\u00e4nzten ihr.", "tokens": ["Und", "die", "Au\u00b7gen", "gl\u00e4nz\u00b7ten", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Fern vergingen Luft und Welle", "tokens": ["Fern", "ver\u00b7gin\u00b7gen", "Luft", "und", "Wel\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In azurner Finsternis,", "tokens": ["In", "a\u00b7zur\u00b7ner", "Fins\u00b7ter\u00b7nis", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und des Vollmonds erste Helle", "tokens": ["Und", "des", "Voll\u00b7monds", "ers\u00b7te", "Hel\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "D\u00e4mmert' \u00fcber Salamis.", "tokens": ["D\u00e4m\u00b7mert'", "\u00fc\u00b7ber", "Sa\u00b7la\u00b7mis", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Hoch auf Suniums Felsenklippe", "tokens": ["Hoch", "auf", "Su\u00b7ni\u00b7ums", "Fel\u00b7sen\u00b7klip\u00b7pe"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "An zerborstner Tempelwand", "tokens": ["An", "zer\u00b7borst\u00b7ner", "Tem\u00b7pel\u00b7wand"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwischen Schutt und Dorngestrippe", "tokens": ["Zwi\u00b7schen", "Schutt", "und", "Dorn\u00b7ge\u00b7strip\u00b7pe"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lehnt' ich, als der Abend schwand.", "tokens": ["Lehnt'", "ich", ",", "als", "der", "A\u00b7bend", "schwand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Um die S\u00e4ulenkn\u00e4ufe flogen", "tokens": ["Um", "die", "S\u00e4u\u00b7len\u00b7kn\u00e4u\u00b7fe", "flo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "M\u00f6wenschw\u00e4rme kreischend her,", "tokens": ["M\u00f6\u00b7wen\u00b7schw\u00e4r\u00b7me", "krei\u00b7schend", "her", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und im endlos weiten Bogen", "tokens": ["Und", "im", "end\u00b7los", "wei\u00b7ten", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJD", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Mir zu F\u00fc\u00dfen lag das Meer.", "tokens": ["Mir", "zu", "F\u00fc\u00b7\u00dfen", "lag", "das", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Und indes im Sp\u00e4trotscheine", "tokens": ["Und", "in\u00b7des", "im", "Sp\u00e4t\u00b7rot\u00b7schei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Fern den Blick ich schweifen lie\u00df,", "tokens": ["Fern", "den", "Blick", "ich", "schwei\u00b7fen", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPER", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Plauderte die braune Kleine,", "tokens": ["Plau\u00b7der\u00b7te", "die", "brau\u00b7ne", "Klei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die vom Tal den Pfad mir wies.", "tokens": ["Die", "vom", "Tal", "den", "Pfad", "mir", "wies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Vieles wu\u00dfte sie zu melden", "tokens": ["Vie\u00b7les", "wu\u00df\u00b7te", "sie", "zu", "mel\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von der gro\u00dfen Perserschlacht,", "tokens": ["Von", "der", "gro\u00b7\u00dfen", "Per\u00b7ser\u00b7schlacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Von Themistokles, dem Helden,", "tokens": ["Von", "The\u00b7mis\u00b7to\u00b7kles", ",", "dem", "Hel\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Welcher Hellas frei gemacht;", "tokens": ["Wel\u00b7cher", "Hel\u00b7las", "frei", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Wie er klug den Sieg erworben,", "tokens": ["Wie", "er", "klug", "den", "Sieg", "er\u00b7wor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch geweihten Spruch belehrt,", "tokens": ["Durch", "ge\u00b7weih\u00b7ten", "Spruch", "be\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie er drauf verbannt gestorben", "tokens": ["Wie", "er", "drauf", "ver\u00b7bannt", "ge\u00b7stor\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PAV", "VVFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und im Tod erst heimgekehrt.", "tokens": ["Und", "im", "Tod", "erst", "heim\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.16": {"line.1": {"text": "\u00bbdort an jener Felsenecke\u00ab,", "tokens": ["\u00bb", "dort", "an", "je\u00b7ner", "Fel\u00b7sen\u00b7ec\u00b7ke", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "APPR", "PDAT", "NN", "$(", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprach sie, \u00bbgl\u00e4nzt an stillem Tag", "tokens": ["Sprach", "sie", ",", "\u00bb", "gl\u00e4nzt", "an", "stil\u00b7lem", "Tag"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "$(", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch die gr\u00fcne Wasserdecke", "tokens": ["Durch", "die", "gr\u00fc\u00b7ne", "Was\u00b7ser\u00b7de\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein versunkner Sarkophag.", "tokens": ["Ein", "ver\u00b7sun\u00b7kner", "Sar\u00b7ko\u00b7phag", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Drinnen lag der Held begraben,", "tokens": ["Drin\u00b7nen", "lag", "der", "Held", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch das Meer hat ihn erw\u00fchlt,", "tokens": ["Doch", "das", "Meer", "hat", "ihn", "er\u00b7w\u00fchlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die gro\u00dfen Wogen haben", "tokens": ["Und", "die", "gro\u00b7\u00dfen", "Wo\u00b7gen", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sein Gebein hinweggesp\u00fclt.", "tokens": ["Sein", "Ge\u00b7bein", "hin\u00b7weg\u00b7ge\u00b7sp\u00fclt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Aber einst, hab' ich vernommen,", "tokens": ["A\u00b7ber", "einst", ",", "hab'", "ich", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird der Retter Griechenlands", "tokens": ["Wird", "der", "Ret\u00b7ter", "Grie\u00b7chen\u00b7lands"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus der Tiefe wiederkommen", "tokens": ["Aus", "der", "Tie\u00b7fe", "wie\u00b7der\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und uns f\u00fchren gen Byzanz;", "tokens": ["Und", "uns", "f\u00fch\u00b7ren", "gen", "By\u00b7zanz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Wird uns dort das Reich best\u00e4t'gen", "tokens": ["Wird", "uns", "dort", "das", "Reich", "be\u00b7st\u00e4t'\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und erh\u00f6hn das Kreuzpanier!\u00ab \u2013", "tokens": ["Und", "er\u00b7h\u00f6hn", "das", "Kreuz\u00b7pa\u00b7nier", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Also sprach das Hirtenm\u00e4dchen,", "tokens": ["Al\u00b7so", "sprach", "das", "Hir\u00b7ten\u00b7m\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Augen gl\u00e4nzten ihr.", "tokens": ["Und", "die", "Au\u00b7gen", "gl\u00e4nz\u00b7ten", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Fern vergingen Luft und Welle", "tokens": ["Fern", "ver\u00b7gin\u00b7gen", "Luft", "und", "Wel\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In azurner Finsternis,", "tokens": ["In", "a\u00b7zur\u00b7ner", "Fins\u00b7ter\u00b7nis", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und des Vollmonds erste Helle", "tokens": ["Und", "des", "Voll\u00b7monds", "ers\u00b7te", "Hel\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "D\u00e4mmert' \u00fcber Salamis.", "tokens": ["D\u00e4m\u00b7mert'", "\u00fc\u00b7ber", "Sa\u00b7la\u00b7mis", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}