{"dta.poem.19751": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Auf diese Gunst machen alle Gewerbe  \n Anspruch .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es war einmal ein Zimmergesell,               ", "tokens": ["Es", "war", "ein\u00b7mal", "ein", "Zim\u00b7mer\u00b7ge\u00b7sell", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "War gar ein jung frisch Blut,", "tokens": ["War", "gar", "ein", "jung", "frisch", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJD", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er baut dem jungen Markgrafen ein Haus,", "tokens": ["Er", "baut", "dem", "jun\u00b7gen", "Mark\u00b7gra\u00b7fen", "ein", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.4": {"text": "Sechshundert Schaul\u00e4den hinaus.", "tokens": ["Sechs\u00b7hun\u00b7dert", "Schau\u00b7l\u00e4\u00b7den", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "PTKVZ", "$."], "meter": "-+-+---+", "measure": "unknown.measure.tri"}}, "stanza.2": {"line.1": {"text": "Und als das Haus gebauet war,", "tokens": ["Und", "als", "das", "Haus", "ge\u00b7bau\u00b7et", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Legt er sich nieder und schlief,", "tokens": ["Legt", "er", "sich", "nie\u00b7der", "und", "schlief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Da kam des jungen Markgrafen sein Weib,", "tokens": ["Da", "kam", "des", "jun\u00b7gen", "Mark\u00b7gra\u00b7fen", "sein", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.4": {"text": "Zum zweiten und drittenmal rief.", "tokens": ["Zum", "zwei\u00b7ten", "und", "drit\u00b7ten\u00b7mal", "rief", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "KON", "ADV", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.3": {"line.1": {"text": "\u201esteh auf, steh auf gut Zimmergesell,", "tokens": ["\u201e", "steh", "auf", ",", "steh", "auf", "gut", "Zim\u00b7mer\u00b7ge\u00b7sell", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "VVFIN", "APPR", "ADJD", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u201edenn es ist an der Stund", "tokens": ["\u201e", "denn", "es", "ist", "an", "der", "Stund"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u201ehast du so wohl ja gebauet das Haus", "tokens": ["\u201e", "hast", "du", "so", "wohl", "ja", "ge\u00b7bau\u00b7et", "das", "Haus"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "ADV", "ADV", "ADV", "VVFIN", "ART", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "\u201eso k\u00fc\u00df' mich an meinen Mund.\u201c", "tokens": ["\u201e", "so", "k\u00fc\u00df'", "mich", "an", "mei\u00b7nen", "Mund", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "\u201each nein, ach nein, Markgr\u00e4fin fein,", "tokens": ["\u201e", "ach", "nein", ",", "ach", "nein", ",", "Mark\u00b7gr\u00e4\u00b7fin", "fein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "PTKANT", "$,", "XY", "PTKANT", "$,", "NN", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u201edas w\u00e4r uns beiden ein Schand,", "tokens": ["\u201e", "das", "w\u00e4r", "uns", "bei\u00b7den", "ein", "Schand", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "PPER", "PIAT", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u201eund wenn es der junge Markgrafe erf\u00fchr,", "tokens": ["\u201e", "und", "wenn", "es", "der", "jun\u00b7ge", "Mark\u00b7gra\u00b7fe", "er\u00b7f\u00fchr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "\u201emu\u00dft ich wohl meiden das Land.\u201c", "tokens": ["\u201e", "mu\u00dft", "ich", "wohl", "mei\u00b7den", "das", "Land", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "PPER", "ADV", "VVINF", "ART", "NN", "$.", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.5": {"line.1": {"text": "Und da die beiden beisammen waren,", "tokens": ["Und", "da", "die", "bei\u00b7den", "bei\u00b7sam\u00b7men", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "PIAT", "PIS", "VAFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie meinen sie w\u00e4ren allein,", "tokens": ["Sie", "mei\u00b7nen", "sie", "w\u00e4\u00b7ren", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VAFIN", "ADV", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Da schlich wohl das \u00e4lteste Kammerweib her,", "tokens": ["Da", "schlich", "wohl", "das", "\u00e4l\u00b7tes\u00b7te", "Kam\u00b7mer\u00b7weib", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Zum Schl\u00fcsselloch schaut sie hinein.", "tokens": ["Zum", "Schl\u00fcs\u00b7sel\u00b7loch", "schaut", "sie", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "\u201each edler Herr, ach edler Herr!", "tokens": ["\u201e", "ach", "ed\u00b7ler", "Herr", ",", "ach", "ed\u00b7ler", "Herr", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201egro\u00df Wunder, zu dieser Stund", "tokens": ["\u201e", "gro\u00df", "Wun\u00b7der", ",", "zu", "die\u00b7ser", "Stund"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADJD", "NN", "$,", "APPR", "PDAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u201eda k\u00fc\u00dfet der jung frische Zimmergesell,", "tokens": ["\u201e", "da", "k\u00fc\u00b7\u00dfet", "der", "jung", "fri\u00b7sche", "Zim\u00b7mer\u00b7ge\u00b7sell", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "\u201edie Frau Markgr\u00e4fin an Mund.\u201c", "tokens": ["\u201e", "die", "Frau", "Mark\u00b7gr\u00e4\u00b7fin", "an", "Mund", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "NN", "APPR", "NN", "$.", "$("], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}}, "stanza.7": {"line.1": {"text": "\u201eund hat er gek\u00fc\u00dft meine sch\u00f6ne Frau,", "tokens": ["\u201e", "und", "hat", "er", "ge\u00b7k\u00fc\u00dft", "mei\u00b7ne", "sch\u00f6\u00b7ne", "Frau", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "VVPP", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u201edes Todes mu\u00df er mir sein,", "tokens": ["\u201e", "des", "To\u00b7des", "mu\u00df", "er", "mir", "sein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "PPER", "PPER", "VAINF", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u201eein Galgen soll er sich selber baun", "tokens": ["\u201e", "ein", "Gal\u00b7gen", "soll", "er", "sich", "sel\u00b7ber", "baun"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "VMFIN", "PPER", "PRF", "ADV", "VVINF"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201ezu Schafhausen draus an dem Rhein.\u201c", "tokens": ["\u201e", "zu", "Schaf\u00b7hau\u00b7sen", "draus", "an", "dem", "Rhein", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "NN", "PAV", "APPR", "ART", "NE", "$.", "$("], "meter": "-++-+--+", "measure": "iambic.tetra.chol"}}, "stanza.8": {"line.1": {"text": "Und als der Galgen gebauet war,", "tokens": ["Und", "als", "der", "Gal\u00b7gen", "ge\u00b7bau\u00b7et", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sechshundert Schauladen hinaus,", "tokens": ["Sechs\u00b7hun\u00b7dert", "Schau\u00b7la\u00b7den", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "APZR", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Von lauter Silber und Edelgestein,", "tokens": ["Von", "lau\u00b7ter", "Sil\u00b7ber", "und", "E\u00b7del\u00b7ge\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Steckt er darauf ein Straus.", "tokens": ["Steckt", "er", "da\u00b7rauf", "ein", "Straus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Da sprach der Markgraf selber, wohl", "tokens": ["Da", "sprach", "der", "Mark\u00b7graf", "sel\u00b7ber", ",", "wohl"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir wollen ihn leben lan,", "tokens": ["Wir", "wol\u00b7len", "ihn", "le\u00b7ben", "lan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ist keiner doch unter uns Allen hier", "tokens": ["Ist", "kei\u00b7ner", "doch", "un\u00b7ter", "uns", "Al\u00b7len", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "ADV", "APPR", "PPER", "PIS", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Der dies nicht h\u00e4tte gethan.", "tokens": ["Der", "dies", "nicht", "h\u00e4t\u00b7te", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "PTKNEG", "VAFIN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.10": {"line.1": {"text": "Was zog er aus der Tasche heraus", "tokens": ["Was", "zog", "er", "aus", "der", "Ta\u00b7sche", "he\u00b7raus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Wohl hundert Goldkronen so roth,", "tokens": ["Wohl", "hun\u00b7dert", "Gold\u00b7kro\u00b7nen", "so", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "ADV", "ADJD", "$,"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Geh mir, geh mir aus dem Land hinaus,", "tokens": ["Geh", "mir", ",", "geh", "mir", "aus", "dem", "Land", "hin\u00b7aus", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "APZR", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Du findest wohl \u00fcberall Brod.", "tokens": ["Du", "fin\u00b7dest", "wohl", "\u00fc\u00b7be\u00b7rall", "Brod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.11": {"line.1": {"text": "Und als er hinaus gezogen war,", "tokens": ["Und", "als", "er", "hin\u00b7aus", "ge\u00b7zo\u00b7gen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APZR", "VVPP", "VAFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da ging er \u00fcber die Haid,", "tokens": ["Da", "ging", "er", "\u00fc\u00b7ber", "die", "Haid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Da steht wohl des jungen Markgrafen sein Weib,", "tokens": ["Da", "steht", "wohl", "des", "jun\u00b7gen", "Mark\u00b7gra\u00b7fen", "sein", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+---+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In ihrem schneewei\u00dfen Kleid.", "tokens": ["In", "ih\u00b7rem", "schnee\u00b7wei\u00b7\u00dfen", "Kleid", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}}, "stanza.12": {"line.1": {"text": "Was zog sie aus der Tasche gar schnell,", "tokens": ["Was", "zog", "sie", "aus", "der", "Ta\u00b7sche", "gar", "schnell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Viel hundert Duckaten von Gold:", "tokens": ["Viel", "hun\u00b7dert", "Duc\u00b7ka\u00b7ten", "von", "Gold", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "APPR", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "\u201enimms hin, du sch\u00f6ner du feiner Gesell.", "tokens": ["\u201e", "nimms", "hin", ",", "du", "sch\u00f6\u00b7ner", "du", "fei\u00b7ner", "Ge\u00b7sell", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PTKVZ", "$,", "PPER", "ADJA", "PPER", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201enimms hin zu deinem Gold.", "tokens": ["\u201e", "nimms", "hin", "zu", "dei\u00b7nem", "Gold", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "\u201eund wenn dir Wein zu sauer ist,", "tokens": ["\u201e", "und", "wenn", "dir", "Wein", "zu", "sau\u00b7er", "ist", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "KOUS", "PPER", "NN", "PTKA", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eso trinke du Malvasier,", "tokens": ["\u201e", "so", "trin\u00b7ke", "du", "Mal\u00b7va\u00b7sier", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u201eund wenn mein M\u00fcndlein dir s\u00fc\u00dfer ist", "tokens": ["\u201e", "und", "wenn", "mein", "M\u00fcnd\u00b7lein", "dir", "s\u00fc\u00b7\u00dfer", "ist"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "KOUS", "PPOSAT", "NN", "PPER", "ADJD", "VAFIN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "\u201eso komme nur wieder zu mir.", "tokens": ["\u201e", "so", "kom\u00b7me", "nur", "wie\u00b7der", "zu", "mir", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}}}}