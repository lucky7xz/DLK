{"textgrid.poem.42920": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Fernflug", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Viel H\u00f6flichkeit wird uns am Start geboten.", "tokens": ["Viel", "H\u00f6f\u00b7lich\u00b7keit", "wird", "uns", "am", "Start", "ge\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Flugfahrthelfer und Piloten", "tokens": ["Die", "Flug\u00b7fahr\u00b7thel\u00b7fer", "und", "Pi\u00b7lo\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sind wohlerzogen, pflichtbewu\u00dft", "tokens": ["Sind", "woh\u00b7ler\u00b7zo\u00b7gen", ",", "pflicht\u00b7be\u00b7wu\u00dft"], "token_info": ["word", "word", "punct", "word"], "pos": ["VAFIN", "ADJD", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und jung. Auch die, die alt an Jahren,", "tokens": ["Und", "jung", ".", "Auch", "die", ",", "die", "alt", "an", "Jah\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "ADV", "ART", "$,", "PRELS", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sind zeitvoran, doch welterfahren.", "tokens": ["Sind", "zeit\u00b7vo\u00b7ran", ",", "doch", "wel\u00b7ter\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Da schwellt sich auf dem Festplatz unsre Brust,", "tokens": ["Da", "schwellt", "sich", "auf", "dem", "Fest\u00b7platz", "uns\u00b7re", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Denn Festplatz darf ich diesen Flugplatz nennen,", "tokens": ["Denn", "Fest\u00b7platz", "darf", "ich", "die\u00b7sen", "Flug\u00b7platz", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "PPER", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit seinen Masten, Flaggen und Antennen.", "tokens": ["Mit", "sei\u00b7nen", "Mas\u00b7ten", ",", "Flag\u00b7gen", "und", "An\u00b7ten\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gez\u00e4hmte Riesenv\u00f6gel gibt's zu sehn.", "tokens": ["Ge\u00b7z\u00e4hm\u00b7te", "Rie\u00b7sen\u00b7v\u00f6\u00b7gel", "gibt's", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dort landen sie in Kurven, sanft gelenkt,", "tokens": ["Dort", "lan\u00b7den", "sie", "in", "Kur\u00b7ven", ",", "sanft", "ge\u00b7lenkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Torkeln ein wenig, zwei, drei Schritte,", "tokens": ["Tor\u00b7keln", "ein", "we\u00b7nig", ",", "zwei", ",", "drei", "Schrit\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "PIS", "$,", "CARD", "$,", "CARD", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Da\u00df man an Regenschirm und Raben denkt,", "tokens": ["Da\u00df", "man", "an", "Re\u00b7gen\u00b7schirm", "und", "Ra\u00b7ben", "denkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und stehn.", "tokens": ["Und", "stehn", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVINF", "$."], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "\u00bbaussteigen bitte!\u00ab", "tokens": ["\u00bb", "aus\u00b7stei\u00b7gen", "bit\u00b7te", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVPP", "PTKANT", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Und wie nun wir in ihrem Bauch bequem", "tokens": ["Und", "wie", "nun", "wir", "in", "ih\u00b7rem", "Bauch", "be\u00b7quem"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADV", "PPER", "APPR", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In weiche Polsterst\u00fchle niedersinken,", "tokens": ["In", "wei\u00b7che", "Pols\u00b7ter\u00b7st\u00fch\u00b7le", "nie\u00b7der\u00b7sin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Empfinden wir den Fortschritt angenehm,", "tokens": ["Emp\u00b7fin\u00b7den", "wir", "den", "Fort\u00b7schritt", "an\u00b7ge\u00b7nehm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "L\u00e4cheln durchs Fenster Menschen zu, die winken.", "tokens": ["L\u00e4\u00b7cheln", "durchs", "Fens\u00b7ter", "Men\u00b7schen", "zu", ",", "die", "win\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "NN", "PTKVZ", "$,", "PRELS", "VVFIN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "Und fahren pl\u00f6tzlich \u00fcber gr\u00fcne Wiesen", "tokens": ["Und", "fah\u00b7ren", "pl\u00f6tz\u00b7lich", "\u00fc\u00b7ber", "gr\u00fc\u00b7ne", "Wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Im Auto hin. Auto? O nein, wir schweben", "tokens": ["Im", "Au\u00b7to", "hin", ".", "Au\u00b7to", "?", "O", "nein", ",", "wir", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "PTKVZ", "$.", "NN", "$.", "NE", "PTKANT", "$,", "PPER", "VVFIN"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Bereits. Ach, da\u00df wir das erleben,", "tokens": ["Be\u00b7reits", ".", "Ach", ",", "da\u00df", "wir", "das", "er\u00b7le\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ITJ", "$,", "KOUS", "PPER", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Erlernen durften und genie\u00dfen!", "tokens": ["Er\u00b7ler\u00b7nen", "durf\u00b7ten", "und", "ge\u00b7nie\u00b7\u00dfen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Wir sind vom Erdball fort, schaun auf ein Teppichmuster", "tokens": ["Wir", "sind", "vom", "Erd\u00b7ball", "fort", ",", "schaun", "auf", "ein", "Tep\u00b7pich\u00b7mus\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "PTKVZ", "$,", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Aus W\u00e4ldern, Feldern, Spielzeugkram gewebt,", "tokens": ["Aus", "W\u00e4l\u00b7dern", ",", "Fel\u00b7dern", ",", "Spiel\u00b7zeug\u00b7kram", "ge\u00b7webt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Werden der Himmelsn\u00e4he j\u00e4h bewu\u00dfter.", "tokens": ["Wer\u00b7den", "der", "Him\u00b7mels\u00b7n\u00e4\u00b7he", "j\u00e4h", "be\u00b7wu\u00df\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Wie klein sich doch da unten alles lebt.", "tokens": ["Wie", "klein", "sich", "doch", "da", "un\u00b7ten", "al\u00b7les", "lebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PRF", "ADV", "ADV", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Dort geht ein Dienstm\u00e4dchen von Stadt zu Stadt.", "tokens": ["Dort", "geht", "ein", "Dienst\u00b7m\u00e4d\u00b7chen", "von", "Stadt", "zu", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie ich den weiten Schl\u00e4ngweg \u00fcberseh,", "tokens": ["Wie", "ich", "den", "wei\u00b7ten", "Schl\u00e4ng\u00b7weg", "\u00fc\u00b7ber\u00b7seh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den sie zur\u00fcckzulegen hat,", "tokens": ["Den", "sie", "zu\u00b7r\u00fcck\u00b7zu\u00b7le\u00b7gen", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wei\u00df ich, der tun nachher die Beine weh.", "tokens": ["Wei\u00df", "ich", ",", "der", "tun", "nach\u00b7her", "die", "Bei\u00b7ne", "weh", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Und wie wir h\u00f6her streben, werden", "tokens": ["Und", "wie", "wir", "h\u00f6\u00b7her", "stre\u00b7ben", ",", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PWAV", "PPER", "ADJD", "VVFIN", "$,", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Dinge unten winziger, schon sind", "tokens": ["Die", "Din\u00b7ge", "un\u00b7ten", "win\u00b7zi\u00b7ger", ",", "schon", "sind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "ADJD", "$,", "ADV", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wagen nur noch Insekten, ist ein Kind", "tokens": ["Wa\u00b7gen", "nur", "noch", "In\u00b7sek\u00b7ten", ",", "ist", "ein", "Kind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "NN", "$,", "VAFIN", "ART", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Nurmehr ein Punkt, und gro\u00dfe Rinderherden", "tokens": ["Nur\u00b7mehr", "ein", "Punkt", ",", "und", "gro\u00b7\u00dfe", "Rin\u00b7der\u00b7her\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sehn aus wie Kommas, kreuz und quer gestellt.", "tokens": ["Sehn", "aus", "wie", "Kom\u00b7mas", ",", "kreuz", "und", "quer", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KOKOM", "NE", "$,", "NN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die Schifflein stehen still im Flu\u00df, sind W\u00fcrmlein.", "tokens": ["Die", "Schif\u00b7flein", "ste\u00b7hen", "still", "im", "Flu\u00df", ",", "sind", "W\u00fcrm\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPRART", "NN", "$,", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ein Dorf ist H\u00e4ufchen H\u00e4uschen, um ein T\u00fcrmlein,", "tokens": ["Ein", "Dorf", "ist", "H\u00e4uf\u00b7chen", "H\u00e4usc\u00b7hen", ",", "um", "ein", "T\u00fcrm\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "NN", "$,", "KOUI", "ART", "NN", "$,"], "meter": "-+-+-+--++-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Und das war unsre sorgenvolle Welt.", "tokens": ["Und", "das", "war", "uns\u00b7re", "sor\u00b7gen\u00b7vol\u00b7le", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "\u00bbei, ei, Herr Nachbar, warum pl\u00f6tzlich", "tokens": ["\u00bb", "ei", ",", "ei", ",", "Herr", "Nach\u00b7bar", ",", "wa\u00b7rum", "pl\u00f6tz\u00b7lich"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "ITJ", "$,", "ITJ", "$,", "NN", "NN", "$,", "PWAV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So bla\u00df \u2013 seekrank? Nein? Dr\u00fcckt Ihr Kissen", "tokens": ["So", "bla\u00df", "\u2013", "see\u00b7krank", "?", "Nein", "?", "Dr\u00fcckt", "Ihr", "Kis\u00b7sen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$(", "VVFIN", "$.", "PTKANT", "$.", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Oder vielleicht Ihr \u00e4ngstliches Gewissen?", "tokens": ["O\u00b7der", "viel\u00b7leicht", "Ihr", "\u00e4ngst\u00b7li\u00b7ches", "Ge\u00b7wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Der Blick zur Tiefe ist doch h\u00f6chst erg\u00f6tzlich!\u00ab", "tokens": ["Der", "Blick", "zur", "Tie\u00b7fe", "ist", "doch", "h\u00f6chst", "er\u00b7g\u00f6tz\u00b7lich", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Jetzt: Unter uns entrollen sich Balladen.", "tokens": ["Jetzt", ":", "Un\u00b7ter", "uns", "ent\u00b7rol\u00b7len", "sich", "Bal\u00b7la\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "APPR", "PPER", "VVFIN", "PRF", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da ziehen dichtgeballte Nebelschwaden,", "tokens": ["Da", "zie\u00b7hen", "dicht\u00b7ge\u00b7ball\u00b7te", "Ne\u00b7bel\u00b7schwa\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wolkenkolosse hin, bedr\u00fcckt und stumm", "tokens": ["Wol\u00b7ken\u00b7ko\u00b7los\u00b7se", "hin", ",", "be\u00b7dr\u00fcckt", "und", "stumm"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "ADJD", "KON", "ADJD"], "meter": "+----+-+-+", "measure": "dactylic.init"}, "line.8": {"text": "Und grell von h\u00f6herer Gewalt besonnt.", "tokens": ["Und", "grell", "von", "h\u00f6\u00b7he\u00b7rer", "Ge\u00b7walt", "be\u00b7sonnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und Land und Luft verschwimmt am Horizont", "tokens": ["Und", "Land", "und", "Luft", "ver\u00b7schwimmt", "am", "Ho\u00b7ri\u00b7zont"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "In einer Landschaft aus dem Arktikum.", "tokens": ["In", "ei\u00b7ner", "Land\u00b7schaft", "aus", "dem", "Ark\u00b7ti\u00b7kum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und da wir nun noch h\u00f6her uns erheben", "tokens": ["Und", "da", "wir", "nun", "noch", "h\u00f6\u00b7her", "uns", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "ADJD", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und auf die dunkle, starre Erde schauen,", "tokens": ["Und", "auf", "die", "dunk\u00b7le", ",", "star\u00b7re", "Er\u00b7de", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "$,", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wo sich kein Mensch mehr zeigt, kein Tier, kein Leben,", "tokens": ["Wo", "sich", "kein", "Mensch", "mehr", "zeigt", ",", "kein", "Tier", ",", "kein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PRF", "PIAT", "NN", "ADV", "VVFIN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als h\u00e4tte eine S\u00fcndflut \u2013 \u2013 O mit Grauen", "tokens": ["Als", "h\u00e4t\u00b7te", "ei\u00b7ne", "S\u00fcnd\u00b7flut", "\u2013", "\u2013", "O", "mit", "Grau\u00b7en"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "ART", "NN", "$(", "$(", "NE", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Stell ich mir vor, wir s\u00e4\u00dfen jetzt zu zwein", "tokens": ["Stell", "ich", "mir", "vor", ",", "wir", "s\u00e4\u00b7\u00dfen", "jetzt", "zu", "zwein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "In einer Arche Noah ganz allein.", "tokens": ["In", "ei\u00b7ner", "Ar\u00b7che", "Noah", "ganz", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "ADV", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "\u00bbnachbar, ich h\u00f6re Ihren Pulsschlag pochen.", "tokens": ["\u00bb", "nach\u00b7bar", ",", "ich", "h\u00f6\u00b7re", "Ih\u00b7ren", "Puls\u00b7schlag", "po\u00b7chen", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie schielen \u00e4ngstlich nach den schlanken Knochen,", "tokens": ["Sie", "schie\u00b7len", "\u00e4ngst\u00b7lich", "nach", "den", "schlan\u00b7ken", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die unsres Vogels Fl\u00fcgel st\u00fctzen", "tokens": ["Die", "uns\u00b7res", "Vo\u00b7gels", "Fl\u00fc\u00b7gel", "st\u00fct\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und, wie Sie meinen, unser Leben sch\u00fctzen.", "tokens": ["Und", ",", "wie", "Sie", "mei\u00b7nen", ",", "un\u00b7ser", "Le\u00b7ben", "sch\u00fct\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPER", "VVFIN", "$,", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es stirbt sich sowieso und \u00fcberall,", "tokens": ["Es", "stirbt", "sich", "so\u00b7wi\u00b7e\u00b7so", "und", "\u00fc\u00b7be\u00b7rall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "KON", "ADV", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und jedes Ding veranla\u00dft Ungl\u00fccksfall.", "tokens": ["Und", "je\u00b7des", "Ding", "ver\u00b7an\u00b7la\u00dft", "Un\u00b7gl\u00fccks\u00b7fall", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVPP", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Vergessen Sie nicht t\u00f6richt \u00fcber diesen", "tokens": ["Ver\u00b7ges\u00b7sen", "Sie", "nicht", "t\u00f6\u00b7richt", "\u00fc\u00b7ber", "die\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "VVFIN", "APPR", "PDAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gedanken, sch\u00f6nste Freiheit zu genie\u00dfen.", "tokens": ["Ge\u00b7dan\u00b7ken", ",", "sch\u00f6ns\u00b7te", "Frei\u00b7heit", "zu", "ge\u00b7nie\u00b7\u00dfen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was Tage einst, das schaffen heute Stunden.", "tokens": ["Was", "Ta\u00b7ge", "einst", ",", "das", "schaf\u00b7fen", "heu\u00b7te", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADV", "$,", "PDS", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Noch kurze Zeit, dann werden wir's erfinden,", "tokens": ["Noch", "kur\u00b7ze", "Zeit", ",", "dann", "wer\u00b7den", "wir's", "er\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADV", "VAFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Den Nebel und den Schnee zu \u00fcberwinden.", "tokens": ["Den", "Ne\u00b7bel", "und", "den", "Schnee", "zu", "\u00fc\u00b7berw\u00b7in\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das Flugzeug selber ist erfunden", "tokens": ["Das", "Flug\u00b7zeug", "sel\u00b7ber", "ist", "er\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und wird so wie die Eisenbahn bestehn.", "tokens": ["Und", "wird", "so", "wie", "die", "Ei\u00b7sen\u00b7bahn", "be\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "KOKOM", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wie die zu jenem sich verh\u00e4lt,", "tokens": ["Wie", "die", "zu", "je\u00b7nem", "sich", "ver\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "APPR", "PDAT", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Gilt's nicht, da\u00df eins von beiden siege.", "tokens": ["Gilt's", "nicht", ",", "da\u00df", "eins", "von", "bei\u00b7den", "sie\u00b7ge", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "$,", "KOUS", "PIS", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.10": {"text": "Es reise jeder, wie es ihm gef\u00e4llt.", "tokens": ["Es", "rei\u00b7se", "je\u00b7der", ",", "wie", "es", "ihm", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "PWAV", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ich \u2013 l\u00e4\u00dft es irgendwie sich drehn \u2013", "tokens": ["Ich", "\u2013", "l\u00e4\u00dft", "es", "ir\u00b7gend\u00b7wie", "sich", "drehn", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "VVFIN", "PPER", "ADV", "PRF", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Ich fliege!\u00ab", "tokens": ["Ich", "flie\u00b7ge", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$("], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.10": {"line.1": {"text": "Viel H\u00f6flichkeit wird uns am Start geboten.", "tokens": ["Viel", "H\u00f6f\u00b7lich\u00b7keit", "wird", "uns", "am", "Start", "ge\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Flugfahrthelfer und Piloten", "tokens": ["Die", "Flug\u00b7fahr\u00b7thel\u00b7fer", "und", "Pi\u00b7lo\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sind wohlerzogen, pflichtbewu\u00dft", "tokens": ["Sind", "woh\u00b7ler\u00b7zo\u00b7gen", ",", "pflicht\u00b7be\u00b7wu\u00dft"], "token_info": ["word", "word", "punct", "word"], "pos": ["VAFIN", "ADJD", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und jung. Auch die, die alt an Jahren,", "tokens": ["Und", "jung", ".", "Auch", "die", ",", "die", "alt", "an", "Jah\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "ADV", "ART", "$,", "PRELS", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sind zeitvoran, doch welterfahren.", "tokens": ["Sind", "zeit\u00b7vo\u00b7ran", ",", "doch", "wel\u00b7ter\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Da schwellt sich auf dem Festplatz unsre Brust,", "tokens": ["Da", "schwellt", "sich", "auf", "dem", "Fest\u00b7platz", "uns\u00b7re", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Denn Festplatz darf ich diesen Flugplatz nennen,", "tokens": ["Denn", "Fest\u00b7platz", "darf", "ich", "die\u00b7sen", "Flug\u00b7platz", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "PPER", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit seinen Masten, Flaggen und Antennen.", "tokens": ["Mit", "sei\u00b7nen", "Mas\u00b7ten", ",", "Flag\u00b7gen", "und", "An\u00b7ten\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gez\u00e4hmte Riesenv\u00f6gel gibt's zu sehn.", "tokens": ["Ge\u00b7z\u00e4hm\u00b7te", "Rie\u00b7sen\u00b7v\u00f6\u00b7gel", "gibt's", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dort landen sie in Kurven, sanft gelenkt,", "tokens": ["Dort", "lan\u00b7den", "sie", "in", "Kur\u00b7ven", ",", "sanft", "ge\u00b7lenkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Torkeln ein wenig, zwei, drei Schritte,", "tokens": ["Tor\u00b7keln", "ein", "we\u00b7nig", ",", "zwei", ",", "drei", "Schrit\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "PIS", "$,", "CARD", "$,", "CARD", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Da\u00df man an Regenschirm und Raben denkt,", "tokens": ["Da\u00df", "man", "an", "Re\u00b7gen\u00b7schirm", "und", "Ra\u00b7ben", "denkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und stehn.", "tokens": ["Und", "stehn", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVINF", "$."], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "\u00bbaussteigen bitte!\u00ab", "tokens": ["\u00bb", "aus\u00b7stei\u00b7gen", "bit\u00b7te", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVPP", "PTKANT", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Und wie nun wir in ihrem Bauch bequem", "tokens": ["Und", "wie", "nun", "wir", "in", "ih\u00b7rem", "Bauch", "be\u00b7quem"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADV", "PPER", "APPR", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In weiche Polsterst\u00fchle niedersinken,", "tokens": ["In", "wei\u00b7che", "Pols\u00b7ter\u00b7st\u00fch\u00b7le", "nie\u00b7der\u00b7sin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Empfinden wir den Fortschritt angenehm,", "tokens": ["Emp\u00b7fin\u00b7den", "wir", "den", "Fort\u00b7schritt", "an\u00b7ge\u00b7nehm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "L\u00e4cheln durchs Fenster Menschen zu, die winken.", "tokens": ["L\u00e4\u00b7cheln", "durchs", "Fens\u00b7ter", "Men\u00b7schen", "zu", ",", "die", "win\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "NN", "PTKVZ", "$,", "PRELS", "VVFIN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "Und fahren pl\u00f6tzlich \u00fcber gr\u00fcne Wiesen", "tokens": ["Und", "fah\u00b7ren", "pl\u00f6tz\u00b7lich", "\u00fc\u00b7ber", "gr\u00fc\u00b7ne", "Wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Im Auto hin. Auto? O nein, wir schweben", "tokens": ["Im", "Au\u00b7to", "hin", ".", "Au\u00b7to", "?", "O", "nein", ",", "wir", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "PTKVZ", "$.", "NN", "$.", "NE", "PTKANT", "$,", "PPER", "VVFIN"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Bereits. Ach, da\u00df wir das erleben,", "tokens": ["Be\u00b7reits", ".", "Ach", ",", "da\u00df", "wir", "das", "er\u00b7le\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ITJ", "$,", "KOUS", "PPER", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Erlernen durften und genie\u00dfen!", "tokens": ["Er\u00b7ler\u00b7nen", "durf\u00b7ten", "und", "ge\u00b7nie\u00b7\u00dfen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Wir sind vom Erdball fort, schaun auf ein Teppichmuster", "tokens": ["Wir", "sind", "vom", "Erd\u00b7ball", "fort", ",", "schaun", "auf", "ein", "Tep\u00b7pich\u00b7mus\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "PTKVZ", "$,", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Aus W\u00e4ldern, Feldern, Spielzeugkram gewebt,", "tokens": ["Aus", "W\u00e4l\u00b7dern", ",", "Fel\u00b7dern", ",", "Spiel\u00b7zeug\u00b7kram", "ge\u00b7webt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Werden der Himmelsn\u00e4he j\u00e4h bewu\u00dfter.", "tokens": ["Wer\u00b7den", "der", "Him\u00b7mels\u00b7n\u00e4\u00b7he", "j\u00e4h", "be\u00b7wu\u00df\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Wie klein sich doch da unten alles lebt.", "tokens": ["Wie", "klein", "sich", "doch", "da", "un\u00b7ten", "al\u00b7les", "lebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PRF", "ADV", "ADV", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Dort geht ein Dienstm\u00e4dchen von Stadt zu Stadt.", "tokens": ["Dort", "geht", "ein", "Dienst\u00b7m\u00e4d\u00b7chen", "von", "Stadt", "zu", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie ich den weiten Schl\u00e4ngweg \u00fcberseh,", "tokens": ["Wie", "ich", "den", "wei\u00b7ten", "Schl\u00e4ng\u00b7weg", "\u00fc\u00b7ber\u00b7seh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den sie zur\u00fcckzulegen hat,", "tokens": ["Den", "sie", "zu\u00b7r\u00fcck\u00b7zu\u00b7le\u00b7gen", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wei\u00df ich, der tun nachher die Beine weh.", "tokens": ["Wei\u00df", "ich", ",", "der", "tun", "nach\u00b7her", "die", "Bei\u00b7ne", "weh", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Und wie wir h\u00f6her streben, werden", "tokens": ["Und", "wie", "wir", "h\u00f6\u00b7her", "stre\u00b7ben", ",", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PWAV", "PPER", "ADJD", "VVFIN", "$,", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Dinge unten winziger, schon sind", "tokens": ["Die", "Din\u00b7ge", "un\u00b7ten", "win\u00b7zi\u00b7ger", ",", "schon", "sind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "ADJD", "$,", "ADV", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wagen nur noch Insekten, ist ein Kind", "tokens": ["Wa\u00b7gen", "nur", "noch", "In\u00b7sek\u00b7ten", ",", "ist", "ein", "Kind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "NN", "$,", "VAFIN", "ART", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Nurmehr ein Punkt, und gro\u00dfe Rinderherden", "tokens": ["Nur\u00b7mehr", "ein", "Punkt", ",", "und", "gro\u00b7\u00dfe", "Rin\u00b7der\u00b7her\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sehn aus wie Kommas, kreuz und quer gestellt.", "tokens": ["Sehn", "aus", "wie", "Kom\u00b7mas", ",", "kreuz", "und", "quer", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KOKOM", "NE", "$,", "NN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die Schifflein stehen still im Flu\u00df, sind W\u00fcrmlein.", "tokens": ["Die", "Schif\u00b7flein", "ste\u00b7hen", "still", "im", "Flu\u00df", ",", "sind", "W\u00fcrm\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPRART", "NN", "$,", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ein Dorf ist H\u00e4ufchen H\u00e4uschen, um ein T\u00fcrmlein,", "tokens": ["Ein", "Dorf", "ist", "H\u00e4uf\u00b7chen", "H\u00e4usc\u00b7hen", ",", "um", "ein", "T\u00fcrm\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "NN", "$,", "KOUI", "ART", "NN", "$,"], "meter": "-+-+-+--++-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Und das war unsre sorgenvolle Welt.", "tokens": ["Und", "das", "war", "uns\u00b7re", "sor\u00b7gen\u00b7vol\u00b7le", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.15": {"line.1": {"text": "\u00bbei, ei, Herr Nachbar, warum pl\u00f6tzlich", "tokens": ["\u00bb", "ei", ",", "ei", ",", "Herr", "Nach\u00b7bar", ",", "wa\u00b7rum", "pl\u00f6tz\u00b7lich"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "ITJ", "$,", "ITJ", "$,", "NN", "NN", "$,", "PWAV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So bla\u00df \u2013 seekrank? Nein? Dr\u00fcckt Ihr Kissen", "tokens": ["So", "bla\u00df", "\u2013", "see\u00b7krank", "?", "Nein", "?", "Dr\u00fcckt", "Ihr", "Kis\u00b7sen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$(", "VVFIN", "$.", "PTKANT", "$.", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Oder vielleicht Ihr \u00e4ngstliches Gewissen?", "tokens": ["O\u00b7der", "viel\u00b7leicht", "Ihr", "\u00e4ngst\u00b7li\u00b7ches", "Ge\u00b7wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Der Blick zur Tiefe ist doch h\u00f6chst erg\u00f6tzlich!\u00ab", "tokens": ["Der", "Blick", "zur", "Tie\u00b7fe", "ist", "doch", "h\u00f6chst", "er\u00b7g\u00f6tz\u00b7lich", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Jetzt: Unter uns entrollen sich Balladen.", "tokens": ["Jetzt", ":", "Un\u00b7ter", "uns", "ent\u00b7rol\u00b7len", "sich", "Bal\u00b7la\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "APPR", "PPER", "VVFIN", "PRF", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da ziehen dichtgeballte Nebelschwaden,", "tokens": ["Da", "zie\u00b7hen", "dicht\u00b7ge\u00b7ball\u00b7te", "Ne\u00b7bel\u00b7schwa\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wolkenkolosse hin, bedr\u00fcckt und stumm", "tokens": ["Wol\u00b7ken\u00b7ko\u00b7los\u00b7se", "hin", ",", "be\u00b7dr\u00fcckt", "und", "stumm"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "ADJD", "KON", "ADJD"], "meter": "+----+-+-+", "measure": "dactylic.init"}, "line.8": {"text": "Und grell von h\u00f6herer Gewalt besonnt.", "tokens": ["Und", "grell", "von", "h\u00f6\u00b7he\u00b7rer", "Ge\u00b7walt", "be\u00b7sonnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und Land und Luft verschwimmt am Horizont", "tokens": ["Und", "Land", "und", "Luft", "ver\u00b7schwimmt", "am", "Ho\u00b7ri\u00b7zont"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "In einer Landschaft aus dem Arktikum.", "tokens": ["In", "ei\u00b7ner", "Land\u00b7schaft", "aus", "dem", "Ark\u00b7ti\u00b7kum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Und da wir nun noch h\u00f6her uns erheben", "tokens": ["Und", "da", "wir", "nun", "noch", "h\u00f6\u00b7her", "uns", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "ADJD", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und auf die dunkle, starre Erde schauen,", "tokens": ["Und", "auf", "die", "dunk\u00b7le", ",", "star\u00b7re", "Er\u00b7de", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "$,", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wo sich kein Mensch mehr zeigt, kein Tier, kein Leben,", "tokens": ["Wo", "sich", "kein", "Mensch", "mehr", "zeigt", ",", "kein", "Tier", ",", "kein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PRF", "PIAT", "NN", "ADV", "VVFIN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als h\u00e4tte eine S\u00fcndflut \u2013 \u2013 O mit Grauen", "tokens": ["Als", "h\u00e4t\u00b7te", "ei\u00b7ne", "S\u00fcnd\u00b7flut", "\u2013", "\u2013", "O", "mit", "Grau\u00b7en"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "ART", "NN", "$(", "$(", "NE", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Stell ich mir vor, wir s\u00e4\u00dfen jetzt zu zwein", "tokens": ["Stell", "ich", "mir", "vor", ",", "wir", "s\u00e4\u00b7\u00dfen", "jetzt", "zu", "zwein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "In einer Arche Noah ganz allein.", "tokens": ["In", "ei\u00b7ner", "Ar\u00b7che", "Noah", "ganz", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "ADV", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "\u00bbnachbar, ich h\u00f6re Ihren Pulsschlag pochen.", "tokens": ["\u00bb", "nach\u00b7bar", ",", "ich", "h\u00f6\u00b7re", "Ih\u00b7ren", "Puls\u00b7schlag", "po\u00b7chen", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie schielen \u00e4ngstlich nach den schlanken Knochen,", "tokens": ["Sie", "schie\u00b7len", "\u00e4ngst\u00b7lich", "nach", "den", "schlan\u00b7ken", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die unsres Vogels Fl\u00fcgel st\u00fctzen", "tokens": ["Die", "uns\u00b7res", "Vo\u00b7gels", "Fl\u00fc\u00b7gel", "st\u00fct\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und, wie Sie meinen, unser Leben sch\u00fctzen.", "tokens": ["Und", ",", "wie", "Sie", "mei\u00b7nen", ",", "un\u00b7ser", "Le\u00b7ben", "sch\u00fct\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPER", "VVFIN", "$,", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es stirbt sich sowieso und \u00fcberall,", "tokens": ["Es", "stirbt", "sich", "so\u00b7wi\u00b7e\u00b7so", "und", "\u00fc\u00b7be\u00b7rall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "KON", "ADV", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und jedes Ding veranla\u00dft Ungl\u00fccksfall.", "tokens": ["Und", "je\u00b7des", "Ding", "ver\u00b7an\u00b7la\u00dft", "Un\u00b7gl\u00fccks\u00b7fall", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVPP", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Vergessen Sie nicht t\u00f6richt \u00fcber diesen", "tokens": ["Ver\u00b7ges\u00b7sen", "Sie", "nicht", "t\u00f6\u00b7richt", "\u00fc\u00b7ber", "die\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "VVFIN", "APPR", "PDAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gedanken, sch\u00f6nste Freiheit zu genie\u00dfen.", "tokens": ["Ge\u00b7dan\u00b7ken", ",", "sch\u00f6ns\u00b7te", "Frei\u00b7heit", "zu", "ge\u00b7nie\u00b7\u00dfen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was Tage einst, das schaffen heute Stunden.", "tokens": ["Was", "Ta\u00b7ge", "einst", ",", "das", "schaf\u00b7fen", "heu\u00b7te", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADV", "$,", "PDS", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Noch kurze Zeit, dann werden wir's erfinden,", "tokens": ["Noch", "kur\u00b7ze", "Zeit", ",", "dann", "wer\u00b7den", "wir's", "er\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADV", "VAFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Den Nebel und den Schnee zu \u00fcberwinden.", "tokens": ["Den", "Ne\u00b7bel", "und", "den", "Schnee", "zu", "\u00fc\u00b7berw\u00b7in\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das Flugzeug selber ist erfunden", "tokens": ["Das", "Flug\u00b7zeug", "sel\u00b7ber", "ist", "er\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und wird so wie die Eisenbahn bestehn.", "tokens": ["Und", "wird", "so", "wie", "die", "Ei\u00b7sen\u00b7bahn", "be\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "KOKOM", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wie die zu jenem sich verh\u00e4lt,", "tokens": ["Wie", "die", "zu", "je\u00b7nem", "sich", "ver\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "APPR", "PDAT", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Gilt's nicht, da\u00df eins von beiden siege.", "tokens": ["Gilt's", "nicht", ",", "da\u00df", "eins", "von", "bei\u00b7den", "sie\u00b7ge", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "$,", "KOUS", "PIS", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.10": {"text": "Es reise jeder, wie es ihm gef\u00e4llt.", "tokens": ["Es", "rei\u00b7se", "je\u00b7der", ",", "wie", "es", "ihm", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "PWAV", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ich \u2013 l\u00e4\u00dft es irgendwie sich drehn \u2013", "tokens": ["Ich", "\u2013", "l\u00e4\u00dft", "es", "ir\u00b7gend\u00b7wie", "sich", "drehn", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "VVFIN", "PPER", "ADV", "PRF", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Ich fliege!\u00ab", "tokens": ["Ich", "flie\u00b7ge", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$("], "meter": "-+-", "measure": "amphibrach.single"}}}}}