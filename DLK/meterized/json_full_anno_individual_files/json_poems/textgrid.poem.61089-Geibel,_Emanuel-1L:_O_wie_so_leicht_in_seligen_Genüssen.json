{"textgrid.poem.61089": {"metadata": {"author": {"name": "Geibel, Emanuel", "birth": "N.A.", "death": "N.A."}, "title": "1L: O wie so leicht in seligen Gen\u00fcssen", "genre": "verse", "period": "N.A.", "pub_year": 1833, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O wie so leicht in seligen Gen\u00fcssen", "tokens": ["O", "wie", "so", "leicht", "in", "se\u00b7li\u00b7gen", "Ge\u00b7n\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOKOM", "ADV", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sich mir die Stunden jetzt dahin bewegen!", "tokens": ["Sich", "mir", "die", "Stun\u00b7den", "jetzt", "da\u00b7hin", "be\u00b7we\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPER", "ART", "NN", "ADV", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ins Auge schau' ich dir, bist du zugegen,", "tokens": ["Ins", "Au\u00b7ge", "schau'", "ich", "dir", ",", "bist", "du", "zu\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PPER", "$,", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und von dir tr\u00e4um' ich, wenn wir scheiden m\u00fcssen.", "tokens": ["Und", "von", "dir", "tr\u00e4um'", "ich", ",", "wenn", "wir", "schei\u00b7den", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Oft z\u00fcgeln wir die Sehnsucht mit Entschl\u00fcssen,", "tokens": ["Oft", "z\u00fc\u00b7geln", "wir", "die", "Sehn\u00b7sucht", "mit", "Ent\u00b7schl\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch will sich stets ein neu Verlangen regen,", "tokens": ["Doch", "will", "sich", "stets", "ein", "neu", "Ver\u00b7lan\u00b7gen", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ADV", "ART", "ADJD", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn wir kaum verst\u00e4nd'ger Rede pflegen,", "tokens": ["Und", "wenn", "wir", "kaum", "ver\u00b7st\u00e4n\u00b7d'\u00b7ger", "Re\u00b7de", "pfle\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Zerschmilzt sie wieder uns und wird zu K\u00fcssen.", "tokens": ["Zer\u00b7schmilzt", "sie", "wie\u00b7der", "uns", "und", "wird", "zu", "K\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "KON", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Der erste weckt Begier nach tausend neuen,", "tokens": ["Der", "ers\u00b7te", "weckt", "Be\u00b7gier", "nach", "tau\u00b7send", "neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "NN", "APPR", "CARD", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es folgt auf Liebeszeichen Liebeszeichen,", "tokens": ["Es", "folgt", "auf", "Lie\u00b7bes\u00b7zei\u00b7chen", "Lie\u00b7bes\u00b7zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und jedes scheint uns h\u00f6her zu erfreuen.", "tokens": ["Und", "je\u00b7des", "scheint", "uns", "h\u00f6\u00b7her", "zu", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "VVFIN", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Nun erst begreif' ich ganz den Lenz, den reichen,", "tokens": ["Nun", "erst", "be\u00b7greif'", "ich", "ganz", "den", "Lenz", ",", "den", "rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn er nicht endet, Rosen auszustreuen,", "tokens": ["Wenn", "er", "nicht", "en\u00b7det", ",", "Ro\u00b7sen", "aus\u00b7zu\u00b7streu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die alle sch\u00f6n sind und sich alle gleichen.", "tokens": ["Die", "al\u00b7le", "sch\u00f6n", "sind", "und", "sich", "al\u00b7le", "glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "VAFIN", "KON", "PRF", "PIAT", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "O wie so leicht in seligen Gen\u00fcssen", "tokens": ["O", "wie", "so", "leicht", "in", "se\u00b7li\u00b7gen", "Ge\u00b7n\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOKOM", "ADV", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sich mir die Stunden jetzt dahin bewegen!", "tokens": ["Sich", "mir", "die", "Stun\u00b7den", "jetzt", "da\u00b7hin", "be\u00b7we\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPER", "ART", "NN", "ADV", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ins Auge schau' ich dir, bist du zugegen,", "tokens": ["Ins", "Au\u00b7ge", "schau'", "ich", "dir", ",", "bist", "du", "zu\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PPER", "$,", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und von dir tr\u00e4um' ich, wenn wir scheiden m\u00fcssen.", "tokens": ["Und", "von", "dir", "tr\u00e4um'", "ich", ",", "wenn", "wir", "schei\u00b7den", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Oft z\u00fcgeln wir die Sehnsucht mit Entschl\u00fcssen,", "tokens": ["Oft", "z\u00fc\u00b7geln", "wir", "die", "Sehn\u00b7sucht", "mit", "Ent\u00b7schl\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch will sich stets ein neu Verlangen regen,", "tokens": ["Doch", "will", "sich", "stets", "ein", "neu", "Ver\u00b7lan\u00b7gen", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ADV", "ART", "ADJD", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn wir kaum verst\u00e4nd'ger Rede pflegen,", "tokens": ["Und", "wenn", "wir", "kaum", "ver\u00b7st\u00e4n\u00b7d'\u00b7ger", "Re\u00b7de", "pfle\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Zerschmilzt sie wieder uns und wird zu K\u00fcssen.", "tokens": ["Zer\u00b7schmilzt", "sie", "wie\u00b7der", "uns", "und", "wird", "zu", "K\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "KON", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Der erste weckt Begier nach tausend neuen,", "tokens": ["Der", "ers\u00b7te", "weckt", "Be\u00b7gier", "nach", "tau\u00b7send", "neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "NN", "APPR", "CARD", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es folgt auf Liebeszeichen Liebeszeichen,", "tokens": ["Es", "folgt", "auf", "Lie\u00b7bes\u00b7zei\u00b7chen", "Lie\u00b7bes\u00b7zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und jedes scheint uns h\u00f6her zu erfreuen.", "tokens": ["Und", "je\u00b7des", "scheint", "uns", "h\u00f6\u00b7her", "zu", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "VVFIN", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Nun erst begreif' ich ganz den Lenz, den reichen,", "tokens": ["Nun", "erst", "be\u00b7greif'", "ich", "ganz", "den", "Lenz", ",", "den", "rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn er nicht endet, Rosen auszustreuen,", "tokens": ["Wenn", "er", "nicht", "en\u00b7det", ",", "Ro\u00b7sen", "aus\u00b7zu\u00b7streu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die alle sch\u00f6n sind und sich alle gleichen.", "tokens": ["Die", "al\u00b7le", "sch\u00f6n", "sind", "und", "sich", "al\u00b7le", "glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "VAFIN", "KON", "PRF", "PIAT", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}