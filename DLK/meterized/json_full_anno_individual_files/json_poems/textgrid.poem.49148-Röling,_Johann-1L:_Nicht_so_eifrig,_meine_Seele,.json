{"textgrid.poem.49148": {"metadata": {"author": {"name": "R\u00f6ling, Johann", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nicht so eifrig, meine Seele,", "genre": "verse", "period": "N.A.", "pub_year": 1656, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nicht so eifrig, meine Seele,", "tokens": ["Nicht", "so", "eif\u00b7rig", ",", "mei\u00b7ne", "See\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du und deine schwache H\u00f6hle", "tokens": ["Du", "und", "dei\u00b7ne", "schwa\u00b7che", "H\u00f6h\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00e4llet euch so vor der Zeit.", "tokens": ["F\u00e4l\u00b7let", "euch", "so", "vor", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn die Biene wen gestochen", "tokens": ["Wenn", "die", "Bie\u00b7ne", "wen", "ge\u00b7sto\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PWS", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und den Stachel hat gebrochen,", "tokens": ["Und", "den", "Sta\u00b7chel", "hat", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist ihr Ende selbst nicht weit.", "tokens": ["Ist", "ihr", "En\u00b7de", "selbst", "nicht", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Durch den Honig sanffter G\u00fcte", "tokens": ["Durch", "den", "Ho\u00b7nig", "sanff\u00b7ter", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gleicht dem Himmel das Gem\u00fcthe,", "tokens": ["Gleicht", "dem", "Him\u00b7mel", "das", "Ge\u00b7m\u00fc\u00b7the", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der auch B\u00f6sen Gutes thut;", "tokens": ["Der", "auch", "B\u00f6\u00b7sen", "Gu\u00b7tes", "thut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch des Zorns gereitzte Flammen", "tokens": ["Durch", "des", "Zorns", "ge\u00b7reitz\u00b7te", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ziehn wir \u00fcber uns zusammen", "tokens": ["Ziehn", "wir", "\u00fc\u00b7ber", "uns", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gottes und der H\u00f6llen Glut.", "tokens": ["Got\u00b7tes", "und", "der", "H\u00f6l\u00b7len", "Glut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Mein, spricht der, ist nur die Rache,", "tokens": ["Mein", ",", "spricht", "der", ",", "ist", "nur", "die", "Ra\u00b7che", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$,", "VVFIN", "ART", "$,", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mir befehle deine Sache;", "tokens": ["Mir", "be\u00b7feh\u00b7le", "dei\u00b7ne", "Sa\u00b7che", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was denn greiffest du ihm ein?", "tokens": ["Was", "denn", "greif\u00b7fest", "du", "ihm", "ein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er ist unser Aller Richter,", "tokens": ["Er", "ist", "un\u00b7ser", "Al\u00b7ler", "Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Er mu\u00df unsers Streites Schlichter", "tokens": ["Er", "mu\u00df", "un\u00b7sers", "Strei\u00b7tes", "Schlich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "ADJA", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Auch bey unserm Rechte seyn.", "tokens": ["Auch", "bey", "un\u00b7serm", "Rech\u00b7te", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Denk, wie offt du dich verbrochen,", "tokens": ["Denk", ",", "wie", "offt", "du", "dich", "ver\u00b7bro\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ADV", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da er sich nicht hat gerochen,", "tokens": ["Da", "er", "sich", "nicht", "hat", "ge\u00b7ro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und so thut er st\u00fcndlich dir,", "tokens": ["Und", "so", "thut", "er", "st\u00fcnd\u00b7lich", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJD", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schenket dir zu tausend Pfunden,", "tokens": ["Schen\u00b7ket", "dir", "zu", "tau\u00b7send", "Pfun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und du h\u00e4lst dich nicht verbunden,", "tokens": ["Und", "du", "h\u00e4lst", "dich", "nicht", "ver\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df du Groschen gebst daf\u00fcr.", "tokens": ["Da\u00df", "du", "Gro\u00b7schen", "gebst", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "F\u00fcrchte, da\u00df mit selber Ma\u00dfe", "tokens": ["F\u00fcrch\u00b7te", ",", "da\u00df", "mit", "sel\u00b7ber", "Ma\u00b7\u00dfe"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Er dir wieder me\u00dfen la\u00dfe,", "tokens": ["Er", "dir", "wie\u00b7der", "me\u00b7\u00dfen", "la\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADV", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die zur Au\u00dfgab deine Lust,", "tokens": ["Die", "zur", "Au\u00df\u00b7gab", "dei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn du selbst willst dieses eben,", "tokens": ["Denn", "du", "selbst", "willst", "die\u00b7ses", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VMFIN", "PDS", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn du bittst, dir zu vergeben,", "tokens": ["Wenn", "du", "bittst", ",", "dir", "zu", "ver\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So, wie du dem Nechsten thust.", "tokens": ["So", ",", "wie", "du", "dem", "Nechs\u00b7ten", "thust", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.6": {"line.1": {"text": "Rachgier treibt geringe Geister", "tokens": ["Rach\u00b7gier", "treibt", "ge\u00b7rin\u00b7ge", "Geis\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die selbst nicht ihrer Meister;", "tokens": ["Und", "die", "selbst", "nicht", "ih\u00b7rer", "Meis\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sanfftmuth wohnt in Helden-Muth,", "tokens": ["Sanfft\u00b7muth", "wohnt", "in", "Hel\u00b7den\u00b7Muth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der den Hohn weit \u00fcbersteiget", "tokens": ["Der", "den", "Hohn", "weit", "\u00fc\u00b7bers\u00b7tei\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und durch Lieb' und Gunst den beuget,", "tokens": ["Und", "durch", "Lieb'", "und", "Gunst", "den", "beu\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "ART", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der ihm Schmach und Unrecht thut.", "tokens": ["Der", "ihm", "Schmach", "und", "Un\u00b7recht", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Geht dir dies noch nicht zu Hertzen", "tokens": ["Geht", "dir", "dies", "noch", "nicht", "zu", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PDS", "ADV", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, so sieh in seinen Schmertzen", "tokens": ["Ach", ",", "so", "sieh", "in", "sei\u00b7nen", "Schmert\u00b7zen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deinen frommen Heyland an;", "tokens": ["Dei\u00b7nen", "from\u00b7men", "Hey\u00b7land", "an", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht schalt er, wie er verachtet,", "tokens": ["Nicht", "schalt", "er", ",", "wie", "er", "ver\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wie ein Schaaff ward er geschlachtet,", "tokens": ["Wie", "ein", "Schaaff", "ward", "er", "ge\u00b7schlach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "--++--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Das den Mund nicht auffgethan.", "tokens": ["Das", "den", "Mund", "nicht", "auff\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Sch\u00e4fflein sind wir seiner Weide,", "tokens": ["Sch\u00e4f\u00b7flein", "sind", "wir", "sei\u00b7ner", "Wei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sch\u00e4fflein nehmen seine Freude,", "tokens": ["Sch\u00e4f\u00b7flein", "neh\u00b7men", "sei\u00b7ne", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die er uns beschieden, ein,", "tokens": ["Die", "er", "uns", "be\u00b7schie\u00b7den", ",", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "PRF", "VVINF", "$,", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo sie nun das Lamm her prangen;", "tokens": ["Wo", "sie", "nun", "das", "Lamm", "her", "pran\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "APZR", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wilstu hieher auch gelangen,", "tokens": ["Wils\u00b7tu", "hie\u00b7her", "auch", "ge\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PAV", "ADV", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.6": {"text": "Mustu ihnen \u00e4hnlich seyn.", "tokens": ["Mus\u00b7tu", "ih\u00b7nen", "\u00e4hn\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "W\u00f6lffe, welche die zerrei\u00dfen,", "tokens": ["W\u00f6lf\u00b7fe", ",", "wel\u00b7che", "die", "zer\u00b7rei\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ART", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hunde, die sich allzeit bei\u00dfen,", "tokens": ["Hun\u00b7de", ",", "die", "sich", "all\u00b7zeit", "bei\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "B\u00e4ren, die ergrimmt aussehn,", "tokens": ["B\u00e4\u00b7ren", ",", "die", "er\u00b7grimmt", "aus\u00b7sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "B\u00f6cke, die sich sto\u00dfen gerne,", "tokens": ["B\u00f6\u00b7cke", ",", "die", "sich", "sto\u00b7\u00dfen", "ger\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PRF", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Diese hei\u00dft er von sich ferne", "tokens": ["Die\u00b7se", "hei\u00dft", "er", "von", "sich", "fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "PRF", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "In den finstern Abgrund gehn.", "tokens": ["In", "den", "fins\u00b7tern", "Ab\u00b7grund", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Jesu, Vorbild aller Liebe,", "tokens": ["Je\u00b7su", ",", "Vor\u00b7bild", "al\u00b7ler", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn ich hie dein Abdruck bliebe!", "tokens": ["Wenn", "ich", "hie", "dein", "Ab\u00b7druck", "blie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, auch ich entbrenne sehr,", "tokens": ["Ach", ",", "auch", "ich", "ent\u00b7bren\u00b7ne", "sehr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch ein Wort, das ungleich f\u00e4llet,", "tokens": ["Auch", "ein", "Wort", ",", "das", "un\u00b7gleich", "f\u00e4l\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Machet offt mich so entstellet,", "tokens": ["Ma\u00b7chet", "offt", "mich", "so", "ent\u00b7stel\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Als wenn ich ein Land verl\u00f6r.", "tokens": ["Als", "wenn", "ich", "ein", "Land", "ver\u00b7l\u00f6r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ART", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "F\u00fcll mein Hertz mit deiner G\u00fcte,", "tokens": ["F\u00fcll", "mein", "Hertz", "mit", "dei\u00b7ner", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00fchl das siedende Gebl\u00fcte,", "tokens": ["K\u00fchl", "das", "sie\u00b7den\u00b7de", "Ge\u00b7bl\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Leg des leichten Sinnes Loh,", "tokens": ["Leg", "des", "leich\u00b7ten", "Sin\u00b7nes", "Loh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00df mein Wort, Werk und Geberden", "tokens": ["La\u00df", "mein", "Wort", ",", "Werk", "und", "Ge\u00b7ber\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPOSAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-++-+--", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Alle deiner Huld voll werden", "tokens": ["Al\u00b7le", "dei\u00b7ner", "Huld", "voll", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "PPOSAT", "NN", "ADJD", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und thu meinem Feind' auch so.", "tokens": ["Und", "thu", "mei\u00b7nem", "Feind'", "auch", "so", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Wird mir wer zu nahe treten,", "tokens": ["Wird", "mir", "wer", "zu", "na\u00b7he", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PWS", "PTKA", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Herr, so will ich zu dir beten,", "tokens": ["Herr", ",", "so", "will", "ich", "zu", "dir", "be\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieses la\u00dfe Kohlen seyn", "tokens": ["Die\u00b7ses", "la\u00b7\u00dfe", "Koh\u00b7len", "seyn"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die sein Unrecht ihm vergelten;", "tokens": ["Die", "sein", "Un\u00b7recht", "ihm", "ver\u00b7gel\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Mich la\u00df z\u00fcrnen, mich la\u00df schelten", "tokens": ["Mich", "la\u00df", "z\u00fcr\u00b7nen", ",", "mich", "la\u00df", "schel\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "VVINF", "$,", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00dcber meine S\u00fcnd' allein.", "tokens": ["\u00dc\u00b7ber", "mei\u00b7ne", "S\u00fcnd'", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Nicht so eifrig, meine Seele,", "tokens": ["Nicht", "so", "eif\u00b7rig", ",", "mei\u00b7ne", "See\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du und deine schwache H\u00f6hle", "tokens": ["Du", "und", "dei\u00b7ne", "schwa\u00b7che", "H\u00f6h\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00e4llet euch so vor der Zeit.", "tokens": ["F\u00e4l\u00b7let", "euch", "so", "vor", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn die Biene wen gestochen", "tokens": ["Wenn", "die", "Bie\u00b7ne", "wen", "ge\u00b7sto\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PWS", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und den Stachel hat gebrochen,", "tokens": ["Und", "den", "Sta\u00b7chel", "hat", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist ihr Ende selbst nicht weit.", "tokens": ["Ist", "ihr", "En\u00b7de", "selbst", "nicht", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Durch den Honig sanffter G\u00fcte", "tokens": ["Durch", "den", "Ho\u00b7nig", "sanff\u00b7ter", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gleicht dem Himmel das Gem\u00fcthe,", "tokens": ["Gleicht", "dem", "Him\u00b7mel", "das", "Ge\u00b7m\u00fc\u00b7the", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der auch B\u00f6sen Gutes thut;", "tokens": ["Der", "auch", "B\u00f6\u00b7sen", "Gu\u00b7tes", "thut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch des Zorns gereitzte Flammen", "tokens": ["Durch", "des", "Zorns", "ge\u00b7reitz\u00b7te", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ziehn wir \u00fcber uns zusammen", "tokens": ["Ziehn", "wir", "\u00fc\u00b7ber", "uns", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gottes und der H\u00f6llen Glut.", "tokens": ["Got\u00b7tes", "und", "der", "H\u00f6l\u00b7len", "Glut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Mein, spricht der, ist nur die Rache,", "tokens": ["Mein", ",", "spricht", "der", ",", "ist", "nur", "die", "Ra\u00b7che", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$,", "VVFIN", "ART", "$,", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mir befehle deine Sache;", "tokens": ["Mir", "be\u00b7feh\u00b7le", "dei\u00b7ne", "Sa\u00b7che", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was denn greiffest du ihm ein?", "tokens": ["Was", "denn", "greif\u00b7fest", "du", "ihm", "ein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er ist unser Aller Richter,", "tokens": ["Er", "ist", "un\u00b7ser", "Al\u00b7ler", "Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Er mu\u00df unsers Streites Schlichter", "tokens": ["Er", "mu\u00df", "un\u00b7sers", "Strei\u00b7tes", "Schlich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "ADJA", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Auch bey unserm Rechte seyn.", "tokens": ["Auch", "bey", "un\u00b7serm", "Rech\u00b7te", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Denk, wie offt du dich verbrochen,", "tokens": ["Denk", ",", "wie", "offt", "du", "dich", "ver\u00b7bro\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ADV", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da er sich nicht hat gerochen,", "tokens": ["Da", "er", "sich", "nicht", "hat", "ge\u00b7ro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und so thut er st\u00fcndlich dir,", "tokens": ["Und", "so", "thut", "er", "st\u00fcnd\u00b7lich", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJD", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schenket dir zu tausend Pfunden,", "tokens": ["Schen\u00b7ket", "dir", "zu", "tau\u00b7send", "Pfun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und du h\u00e4lst dich nicht verbunden,", "tokens": ["Und", "du", "h\u00e4lst", "dich", "nicht", "ver\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df du Groschen gebst daf\u00fcr.", "tokens": ["Da\u00df", "du", "Gro\u00b7schen", "gebst", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "F\u00fcrchte, da\u00df mit selber Ma\u00dfe", "tokens": ["F\u00fcrch\u00b7te", ",", "da\u00df", "mit", "sel\u00b7ber", "Ma\u00b7\u00dfe"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Er dir wieder me\u00dfen la\u00dfe,", "tokens": ["Er", "dir", "wie\u00b7der", "me\u00b7\u00dfen", "la\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADV", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die zur Au\u00dfgab deine Lust,", "tokens": ["Die", "zur", "Au\u00df\u00b7gab", "dei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn du selbst willst dieses eben,", "tokens": ["Denn", "du", "selbst", "willst", "die\u00b7ses", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VMFIN", "PDS", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn du bittst, dir zu vergeben,", "tokens": ["Wenn", "du", "bittst", ",", "dir", "zu", "ver\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So, wie du dem Nechsten thust.", "tokens": ["So", ",", "wie", "du", "dem", "Nechs\u00b7ten", "thust", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.18": {"line.1": {"text": "Rachgier treibt geringe Geister", "tokens": ["Rach\u00b7gier", "treibt", "ge\u00b7rin\u00b7ge", "Geis\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die selbst nicht ihrer Meister;", "tokens": ["Und", "die", "selbst", "nicht", "ih\u00b7rer", "Meis\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sanfftmuth wohnt in Helden-Muth,", "tokens": ["Sanfft\u00b7muth", "wohnt", "in", "Hel\u00b7den\u00b7Muth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der den Hohn weit \u00fcbersteiget", "tokens": ["Der", "den", "Hohn", "weit", "\u00fc\u00b7bers\u00b7tei\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und durch Lieb' und Gunst den beuget,", "tokens": ["Und", "durch", "Lieb'", "und", "Gunst", "den", "beu\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "ART", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der ihm Schmach und Unrecht thut.", "tokens": ["Der", "ihm", "Schmach", "und", "Un\u00b7recht", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Geht dir dies noch nicht zu Hertzen", "tokens": ["Geht", "dir", "dies", "noch", "nicht", "zu", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PDS", "ADV", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, so sieh in seinen Schmertzen", "tokens": ["Ach", ",", "so", "sieh", "in", "sei\u00b7nen", "Schmert\u00b7zen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deinen frommen Heyland an;", "tokens": ["Dei\u00b7nen", "from\u00b7men", "Hey\u00b7land", "an", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht schalt er, wie er verachtet,", "tokens": ["Nicht", "schalt", "er", ",", "wie", "er", "ver\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wie ein Schaaff ward er geschlachtet,", "tokens": ["Wie", "ein", "Schaaff", "ward", "er", "ge\u00b7schlach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "--++--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Das den Mund nicht auffgethan.", "tokens": ["Das", "den", "Mund", "nicht", "auff\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Sch\u00e4fflein sind wir seiner Weide,", "tokens": ["Sch\u00e4f\u00b7flein", "sind", "wir", "sei\u00b7ner", "Wei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sch\u00e4fflein nehmen seine Freude,", "tokens": ["Sch\u00e4f\u00b7flein", "neh\u00b7men", "sei\u00b7ne", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die er uns beschieden, ein,", "tokens": ["Die", "er", "uns", "be\u00b7schie\u00b7den", ",", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "PRF", "VVINF", "$,", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo sie nun das Lamm her prangen;", "tokens": ["Wo", "sie", "nun", "das", "Lamm", "her", "pran\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "APZR", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wilstu hieher auch gelangen,", "tokens": ["Wils\u00b7tu", "hie\u00b7her", "auch", "ge\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PAV", "ADV", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.6": {"text": "Mustu ihnen \u00e4hnlich seyn.", "tokens": ["Mus\u00b7tu", "ih\u00b7nen", "\u00e4hn\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "W\u00f6lffe, welche die zerrei\u00dfen,", "tokens": ["W\u00f6lf\u00b7fe", ",", "wel\u00b7che", "die", "zer\u00b7rei\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ART", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hunde, die sich allzeit bei\u00dfen,", "tokens": ["Hun\u00b7de", ",", "die", "sich", "all\u00b7zeit", "bei\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "B\u00e4ren, die ergrimmt aussehn,", "tokens": ["B\u00e4\u00b7ren", ",", "die", "er\u00b7grimmt", "aus\u00b7sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "B\u00f6cke, die sich sto\u00dfen gerne,", "tokens": ["B\u00f6\u00b7cke", ",", "die", "sich", "sto\u00b7\u00dfen", "ger\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PRF", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Diese hei\u00dft er von sich ferne", "tokens": ["Die\u00b7se", "hei\u00dft", "er", "von", "sich", "fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "PRF", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "In den finstern Abgrund gehn.", "tokens": ["In", "den", "fins\u00b7tern", "Ab\u00b7grund", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Jesu, Vorbild aller Liebe,", "tokens": ["Je\u00b7su", ",", "Vor\u00b7bild", "al\u00b7ler", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn ich hie dein Abdruck bliebe!", "tokens": ["Wenn", "ich", "hie", "dein", "Ab\u00b7druck", "blie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, auch ich entbrenne sehr,", "tokens": ["Ach", ",", "auch", "ich", "ent\u00b7bren\u00b7ne", "sehr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch ein Wort, das ungleich f\u00e4llet,", "tokens": ["Auch", "ein", "Wort", ",", "das", "un\u00b7gleich", "f\u00e4l\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Machet offt mich so entstellet,", "tokens": ["Ma\u00b7chet", "offt", "mich", "so", "ent\u00b7stel\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Als wenn ich ein Land verl\u00f6r.", "tokens": ["Als", "wenn", "ich", "ein", "Land", "ver\u00b7l\u00f6r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ART", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "F\u00fcll mein Hertz mit deiner G\u00fcte,", "tokens": ["F\u00fcll", "mein", "Hertz", "mit", "dei\u00b7ner", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00fchl das siedende Gebl\u00fcte,", "tokens": ["K\u00fchl", "das", "sie\u00b7den\u00b7de", "Ge\u00b7bl\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Leg des leichten Sinnes Loh,", "tokens": ["Leg", "des", "leich\u00b7ten", "Sin\u00b7nes", "Loh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00df mein Wort, Werk und Geberden", "tokens": ["La\u00df", "mein", "Wort", ",", "Werk", "und", "Ge\u00b7ber\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPOSAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-++-+--", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Alle deiner Huld voll werden", "tokens": ["Al\u00b7le", "dei\u00b7ner", "Huld", "voll", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "PPOSAT", "NN", "ADJD", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und thu meinem Feind' auch so.", "tokens": ["Und", "thu", "mei\u00b7nem", "Feind'", "auch", "so", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.24": {"line.1": {"text": "Wird mir wer zu nahe treten,", "tokens": ["Wird", "mir", "wer", "zu", "na\u00b7he", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PWS", "PTKA", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Herr, so will ich zu dir beten,", "tokens": ["Herr", ",", "so", "will", "ich", "zu", "dir", "be\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieses la\u00dfe Kohlen seyn", "tokens": ["Die\u00b7ses", "la\u00b7\u00dfe", "Koh\u00b7len", "seyn"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die sein Unrecht ihm vergelten;", "tokens": ["Die", "sein", "Un\u00b7recht", "ihm", "ver\u00b7gel\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Mich la\u00df z\u00fcrnen, mich la\u00df schelten", "tokens": ["Mich", "la\u00df", "z\u00fcr\u00b7nen", ",", "mich", "la\u00df", "schel\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "VVINF", "$,", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00dcber meine S\u00fcnd' allein.", "tokens": ["\u00dc\u00b7ber", "mei\u00b7ne", "S\u00fcnd'", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}