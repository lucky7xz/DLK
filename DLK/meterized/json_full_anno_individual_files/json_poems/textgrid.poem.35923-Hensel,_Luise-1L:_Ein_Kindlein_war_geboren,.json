{"textgrid.poem.35923": {"metadata": {"author": {"name": "Hensel, Luise", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein Kindlein war geboren,", "genre": "verse", "period": "N.A.", "pub_year": 1815, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Kindlein war geboren,", "tokens": ["Ein", "Kin\u00b7dlein", "war", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein M\u00e4gdlein zart und licht;", "tokens": ["Ein", "M\u00e4gd\u00b7lein", "zart", "und", "licht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ach, ist es denn verloren?", "tokens": ["Ach", ",", "ist", "es", "denn", "ver\u00b7lo\u00b7ren", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich such', und find' es nicht.", "tokens": ["Ich", "such'", ",", "und", "find'", "es", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die blauen Augen blickten", "tokens": ["Die", "blau\u00b7en", "Au\u00b7gen", "blick\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mich an so fromm und mild,", "tokens": ["Mich", "an", "so", "fromm", "und", "mild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und goldne Locken schm\u00fcckten", "tokens": ["Und", "gold\u00b7ne", "Lo\u00b7cken", "schm\u00fcck\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das liebe klare Bild.", "tokens": ["Das", "lie\u00b7be", "kla\u00b7re", "Bild", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Es sa\u00df so lieb und sinnig", "tokens": ["Es", "sa\u00df", "so", "lieb", "und", "sin\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Auf gr\u00fcner Fr\u00fchlingsau", "tokens": ["Auf", "gr\u00fc\u00b7ner", "Fr\u00fch\u00b7lin\u00b7gsau"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und l\u00e4chelte so innig", "tokens": ["Und", "l\u00e4\u00b7chel\u00b7te", "so", "in\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hinauf in's Himmelsblau.", "tokens": ["Hin\u00b7auf", "in's", "Him\u00b7mels\u00b7blau", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ich sah es wol im Garten,", "tokens": ["Ich", "sah", "es", "wol", "im", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wenn hell der Lenz erschien,", "tokens": ["Wenn", "hell", "der", "Lenz", "er\u00b7schien", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Maienblumen warten", "tokens": ["Der", "Mai\u00b7en\u00b7blu\u00b7men", "war\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und selbst wie Bl\u00fcmlein bl\u00fchn.", "tokens": ["Und", "selbst", "wie", "Bl\u00fcm\u00b7lein", "bl\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOKOM", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Es ging so gern alleine", "tokens": ["Es", "ging", "so", "gern", "al\u00b7lei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im fr\u00fchen Morgenroth;", "tokens": ["Im", "fr\u00fc\u00b7hen", "Mor\u00b7gen\u00b7roth", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wo ist das Kindlein reine?", "tokens": ["Wo", "ist", "das", "Kin\u00b7dlein", "rei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sagt, Blumen, ist es todt?", "tokens": ["Sagt", ",", "Blu\u00b7men", ",", "ist", "es", "todt", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u00bbwie man so pflegt zu sagen,", "tokens": ["\u00bb", "wie", "man", "so", "pflegt", "zu", "sa\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PIS", "ADV", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Du fremder Wandersmann;", "tokens": ["Du", "frem\u00b7der", "Wan\u00b7ders\u00b7mann", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch la\u00df Dein \u00e4ngstlich Fragen", "tokens": ["Doch", "la\u00df", "Dein", "\u00e4ngst\u00b7lich", "Fra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und sieh uns Rosen an.", "tokens": ["Und", "sieh", "uns", "Ro\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Wir wei\u00dfen Rosen scheinen", "tokens": ["Wir", "wei\u00b7\u00dfen", "Ro\u00b7sen", "schei\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Von einem H\u00fcgel klein,", "tokens": ["Von", "ei\u00b7nem", "H\u00fc\u00b7gel", "klein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da legten sie mit Weinen", "tokens": ["Da", "leg\u00b7ten", "sie", "mit", "Wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein M\u00e4gdlein j\u00fcngst hinein,", "tokens": ["Ein", "M\u00e4gd\u00b7lein", "j\u00fcngst", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Das schlief auf Maienglocken", "tokens": ["Das", "schlief", "auf", "Mai\u00b7en\u00b7glo\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So still, unschuldig, fein,", "tokens": ["So", "still", ",", "un\u00b7schul\u00b7dig", ",", "fein", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das schm\u00fcckten goldne Locken", "tokens": ["Das", "schm\u00fcck\u00b7ten", "gold\u00b7ne", "Lo\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Fast wie ein Engelein.", "tokens": ["Fast", "wie", "ein", "En\u00b7ge\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wir wei\u00dfen Rosen bl\u00fchen", "tokens": ["Wir", "wei\u00b7\u00dfen", "Ro\u00b7sen", "bl\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Gern \u00fcber seiner Brust;", "tokens": ["Gern", "\u00fc\u00b7ber", "sei\u00b7ner", "Brust", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch was wir aus ihm bl\u00fchen,", "tokens": ["Doch", "was", "wir", "aus", "ihm", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das ist uns unbewu\u00dft.", "tokens": ["Das", "ist", "uns", "un\u00b7be\u00b7wu\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Hast Du nach ihm Verlangen,", "tokens": ["Hast", "Du", "nach", "ihm", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "So sieh zum Himmel auf;", "tokens": ["So", "sieh", "zum", "Him\u00b7mel", "auf", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es ist nur heimgegangen;", "tokens": ["Es", "ist", "nur", "heim\u00b7ge\u00b7gan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Willst Du nicht auch hinauf?", "tokens": ["Willst", "Du", "nicht", "auch", "hin\u00b7auf", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Wir Rosen m\u00fcssen stehen", "tokens": ["Wir", "Ro\u00b7sen", "m\u00fcs\u00b7sen", "ste\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hier als des Todes Zier,", "tokens": ["Hier", "als", "des", "To\u00b7des", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und wenn wir welk vergehen,", "tokens": ["Und", "wenn", "wir", "welk", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mein Freund, dann sprechen wir:", "tokens": ["Mein", "Freund", ",", "dann", "spre\u00b7chen", "wir", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Staub wird dies Lustgewimmel", "tokens": ["Staub", "wird", "dies", "Lust\u00b7ge\u00b7wim\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PDS", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Der Blumen Glanz und Gluth.", "tokens": ["Der", "Blu\u00b7men", "Glanz", "und", "Gluth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Vater in dem Himmel", "tokens": ["Der", "Va\u00b7ter", "in", "dem", "Him\u00b7mel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Allein ist sch\u00f6n und gut.\u00ab", "tokens": ["Al\u00b7lein", "ist", "sch\u00f6n", "und", "gut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Ein Kindlein war geboren,", "tokens": ["Ein", "Kin\u00b7dlein", "war", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein M\u00e4gdlein zart und licht;", "tokens": ["Ein", "M\u00e4gd\u00b7lein", "zart", "und", "licht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ach, ist es denn verloren?", "tokens": ["Ach", ",", "ist", "es", "denn", "ver\u00b7lo\u00b7ren", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich such', und find' es nicht.", "tokens": ["Ich", "such'", ",", "und", "find'", "es", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Die blauen Augen blickten", "tokens": ["Die", "blau\u00b7en", "Au\u00b7gen", "blick\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mich an so fromm und mild,", "tokens": ["Mich", "an", "so", "fromm", "und", "mild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und goldne Locken schm\u00fcckten", "tokens": ["Und", "gold\u00b7ne", "Lo\u00b7cken", "schm\u00fcck\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das liebe klare Bild.", "tokens": ["Das", "lie\u00b7be", "kla\u00b7re", "Bild", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Es sa\u00df so lieb und sinnig", "tokens": ["Es", "sa\u00df", "so", "lieb", "und", "sin\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Auf gr\u00fcner Fr\u00fchlingsau", "tokens": ["Auf", "gr\u00fc\u00b7ner", "Fr\u00fch\u00b7lin\u00b7gsau"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und l\u00e4chelte so innig", "tokens": ["Und", "l\u00e4\u00b7chel\u00b7te", "so", "in\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hinauf in's Himmelsblau.", "tokens": ["Hin\u00b7auf", "in's", "Him\u00b7mels\u00b7blau", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Ich sah es wol im Garten,", "tokens": ["Ich", "sah", "es", "wol", "im", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wenn hell der Lenz erschien,", "tokens": ["Wenn", "hell", "der", "Lenz", "er\u00b7schien", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Maienblumen warten", "tokens": ["Der", "Mai\u00b7en\u00b7blu\u00b7men", "war\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und selbst wie Bl\u00fcmlein bl\u00fchn.", "tokens": ["Und", "selbst", "wie", "Bl\u00fcm\u00b7lein", "bl\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOKOM", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Es ging so gern alleine", "tokens": ["Es", "ging", "so", "gern", "al\u00b7lei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im fr\u00fchen Morgenroth;", "tokens": ["Im", "fr\u00fc\u00b7hen", "Mor\u00b7gen\u00b7roth", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wo ist das Kindlein reine?", "tokens": ["Wo", "ist", "das", "Kin\u00b7dlein", "rei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sagt, Blumen, ist es todt?", "tokens": ["Sagt", ",", "Blu\u00b7men", ",", "ist", "es", "todt", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "\u00bbwie man so pflegt zu sagen,", "tokens": ["\u00bb", "wie", "man", "so", "pflegt", "zu", "sa\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PIS", "ADV", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Du fremder Wandersmann;", "tokens": ["Du", "frem\u00b7der", "Wan\u00b7ders\u00b7mann", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch la\u00df Dein \u00e4ngstlich Fragen", "tokens": ["Doch", "la\u00df", "Dein", "\u00e4ngst\u00b7lich", "Fra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und sieh uns Rosen an.", "tokens": ["Und", "sieh", "uns", "Ro\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Wir wei\u00dfen Rosen scheinen", "tokens": ["Wir", "wei\u00b7\u00dfen", "Ro\u00b7sen", "schei\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Von einem H\u00fcgel klein,", "tokens": ["Von", "ei\u00b7nem", "H\u00fc\u00b7gel", "klein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da legten sie mit Weinen", "tokens": ["Da", "leg\u00b7ten", "sie", "mit", "Wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein M\u00e4gdlein j\u00fcngst hinein,", "tokens": ["Ein", "M\u00e4gd\u00b7lein", "j\u00fcngst", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Das schlief auf Maienglocken", "tokens": ["Das", "schlief", "auf", "Mai\u00b7en\u00b7glo\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So still, unschuldig, fein,", "tokens": ["So", "still", ",", "un\u00b7schul\u00b7dig", ",", "fein", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das schm\u00fcckten goldne Locken", "tokens": ["Das", "schm\u00fcck\u00b7ten", "gold\u00b7ne", "Lo\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Fast wie ein Engelein.", "tokens": ["Fast", "wie", "ein", "En\u00b7ge\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Wir wei\u00dfen Rosen bl\u00fchen", "tokens": ["Wir", "wei\u00b7\u00dfen", "Ro\u00b7sen", "bl\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Gern \u00fcber seiner Brust;", "tokens": ["Gern", "\u00fc\u00b7ber", "sei\u00b7ner", "Brust", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch was wir aus ihm bl\u00fchen,", "tokens": ["Doch", "was", "wir", "aus", "ihm", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das ist uns unbewu\u00dft.", "tokens": ["Das", "ist", "uns", "un\u00b7be\u00b7wu\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Hast Du nach ihm Verlangen,", "tokens": ["Hast", "Du", "nach", "ihm", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "So sieh zum Himmel auf;", "tokens": ["So", "sieh", "zum", "Him\u00b7mel", "auf", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es ist nur heimgegangen;", "tokens": ["Es", "ist", "nur", "heim\u00b7ge\u00b7gan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Willst Du nicht auch hinauf?", "tokens": ["Willst", "Du", "nicht", "auch", "hin\u00b7auf", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Wir Rosen m\u00fcssen stehen", "tokens": ["Wir", "Ro\u00b7sen", "m\u00fcs\u00b7sen", "ste\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hier als des Todes Zier,", "tokens": ["Hier", "als", "des", "To\u00b7des", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und wenn wir welk vergehen,", "tokens": ["Und", "wenn", "wir", "welk", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mein Freund, dann sprechen wir:", "tokens": ["Mein", "Freund", ",", "dann", "spre\u00b7chen", "wir", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Staub wird dies Lustgewimmel", "tokens": ["Staub", "wird", "dies", "Lust\u00b7ge\u00b7wim\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PDS", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Der Blumen Glanz und Gluth.", "tokens": ["Der", "Blu\u00b7men", "Glanz", "und", "Gluth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Vater in dem Himmel", "tokens": ["Der", "Va\u00b7ter", "in", "dem", "Him\u00b7mel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Allein ist sch\u00f6n und gut.\u00ab", "tokens": ["Al\u00b7lein", "ist", "sch\u00f6n", "und", "gut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}