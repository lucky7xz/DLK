{"textgrid.poem.39051": {"metadata": {"author": {"name": "Neuber, Friederike Caroline", "birth": "N.A.", "death": "N.A."}, "title": "1L: Durchlauchtigster!", "genre": "verse", "period": "N.A.", "pub_year": 1728, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Durchlauchtigster!", "tokens": ["Durch\u00b7lauch\u00b7tigs\u00b7ter", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Du treibst mich so!", "tokens": ["Du", "treibst", "mich", "so", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Du zwingst mich jetzt ein Lied zu dichten!", "tokens": ["Du", "zwingst", "mich", "jetzt", "ein", "Lied", "zu", "dich\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du machst die halbe Welt vergn\u00fcgt und hertzlich froh!", "tokens": ["Du", "machst", "die", "hal\u00b7be", "Welt", "ver\u00b7gn\u00fcgt", "und", "hertz\u00b7lich", "froh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "VVPP", "KON", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kann ich auch das geschickt verrichten,", "tokens": ["Kann", "ich", "auch", "das", "ge\u00b7schickt", "ver\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "was M\u00e4nnern viel zu schaffen macht,", "tokens": ["was", "M\u00e4n\u00b7nern", "viel", "zu", "schaf\u00b7fen", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "die gut und hoch zu dencken wissen;", "tokens": ["die", "gut", "und", "hoch", "zu", "den\u00b7cken", "wis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "die grosser Helden That oft lebhaft abgerissen;", "tokens": ["die", "gros\u00b7ser", "Hel\u00b7den", "That", "oft", "leb\u00b7haft", "ab\u00b7ge\u00b7ris\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "und die, bey ", "tokens": ["und", "die", ",", "bey"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "ART", "$,", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "die Kunst und Wissenschaft auch h\u00f6her noch getrieben,", "tokens": ["die", "Kunst", "und", "Wis\u00b7sen\u00b7schaft", "auch", "h\u00f6\u00b7her", "noch", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "dass mir so gar nichts \u00fcbrig blieben?", "tokens": ["dass", "mir", "so", "gar", "nichts", "\u00fcb\u00b7rig", "blie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PIS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Doch ihre Kunst bet\u00e4ubt mich nicht:", "tokens": ["Doch", "ih\u00b7re", "Kunst", "be\u00b7t\u00e4ubt", "mich", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Regung bleibt; die Pflicht muss sprechen.", "tokens": ["Die", "Re\u00b7gung", "bleibt", ";", "die", "Pflicht", "muss", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der schlauen Kunst den Stoltz zu brechen;", "tokens": ["der", "schlau\u00b7en", "Kunst", "den", "Stoltz", "zu", "bre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dass ich mit Ehrfurcht dencken kan,", "tokens": ["dass", "ich", "mit", "Ehr\u00b7furcht", "den\u00b7cken", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "behertzt, aus reiner Treue, schreibe,", "tokens": ["be\u00b7hertzt", ",", "aus", "rei\u00b7ner", "Treu\u00b7e", ",", "schrei\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "durch ", "tokens": ["durch"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Das ist mein Trieb! der reitzt mich an;", "tokens": ["Das", "ist", "mein", "Trieb", "!", "der", "reitzt", "mich", "an", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$.", "ART", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "den setz ich hier allein der Wissenschaft entgegen;", "tokens": ["den", "setz", "ich", "hier", "al\u00b7lein", "der", "Wis\u00b7sen\u00b7schaft", "ent\u00b7ge\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "der hilft mir reiflich \u00fcberlegen.", "tokens": ["der", "hilft", "mir", "reif\u00b7lich", "\u00fc\u00b7berl\u00b7e\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Du Br\u00e4utgam in der gr\u00f6ssten Bl\u00fcthe!", "tokens": ["Du", "Br\u00e4ut\u00b7gam", "in", "der", "gr\u00f6ss\u00b7ten", "Bl\u00fc\u00b7the", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "zeigst nicht die Hoffnung nur: Du bringst, Du giebst sie schon.", "tokens": ["zeigst", "nicht", "die", "Hoff\u00b7nung", "nur", ":", "Du", "bringst", ",", "Du", "giebst", "sie", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "ADV", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "der Trieb zu ", "tokens": ["der", "Trieb", "zu"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "PTKZU"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "der Hoffnung st\u00e4rkt und Helden reget,", "tokens": ["der", "Hoff\u00b7nung", "st\u00e4rkt", "und", "Hel\u00b7den", "re\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "dass ", "tokens": ["dass"], "token_info": ["word"], "pos": ["KOUS"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Bringt ", "tokens": ["Bringt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "das keinen andern Zug, Trieb, Gunst, Lust und Verlangen", "tokens": ["das", "kei\u00b7nen", "an\u00b7dern", "Zug", ",", "Trieb", ",", "Gunst", ",", "Lust", "und", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "PIAT", "ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "als nur nach Dir allein empfangen.", "tokens": ["als", "nur", "nach", "Dir", "al\u00b7lein", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "wie ", "tokens": ["wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Er lebet nur, mit ", "tokens": ["Er", "le\u00b7bet", "nur", ",", "mit"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "So w\u00fcrdig ist ", "tokens": ["So", "w\u00fcr\u00b7dig", "ist"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "und Freunde K\u00f6niglich besieget", "tokens": ["und", "Freun\u00b7de", "K\u00f6\u00b7nig\u00b7lich", "be\u00b7sie\u00b7get"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hast ", "tokens": ["Hast"], "token_info": ["word"], "pos": ["NE"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "das es mit stiller Liebe krieget?", "tokens": ["das", "es", "mit", "stil\u00b7ler", "Lie\u00b7be", "krie\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nun gilt kein Donner in der Luft,", "tokens": ["Nun", "gilt", "kein", "Don\u00b7ner", "in", "der", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "der Felsen sprengt und Berge reisset,", "tokens": ["der", "Fel\u00b7sen", "sprengt", "und", "Ber\u00b7ge", "reis\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "den Wall verw\u00fcst, durchw\u00fchlt, die Th\u00fcren niederschmeisset;", "tokens": ["den", "Wall", "ver\u00b7w\u00fcst", ",", "durch\u00b7w\u00fchlt", ",", "die", "Th\u00fc\u00b7ren", "nie\u00b7der\u00b7schmeis\u00b7set", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und niemand, der: ", "tokens": ["Und", "nie\u00b7mand", ",", "der", ":"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "$."], "meter": "-+--", "measure": "dactylic.init"}, "line.8": {"text": "Doch ja! der St\u00fccke Knall blitzt, schmettert, f\u00e4hrt geschwinder", "tokens": ["Doch", "ja", "!", "der", "St\u00fc\u00b7cke", "Knall", "blitzt", ",", "schmet\u00b7tert", ",", "f\u00e4hrt", "ge\u00b7schwin\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "$.", "ART", "NN", "NN", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "zu Ehren ", "tokens": ["zu", "Eh\u00b7ren"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.6": {"line.1": {"text": "O! Preussens ", "tokens": ["O", "!", "Preus\u00b7sens"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$.", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Du hast des jungen Friedrichs Tugend", "tokens": ["Du", "hast", "des", "jun\u00b7gen", "Fried\u00b7richs", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "vor ", "tokens": ["vor"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "und ", "tokens": ["und"], "token_info": ["word"], "pos": ["KON"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Liebst ", "tokens": ["Liebst"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "sprichst ein zufriednes ", "tokens": ["sprichst", "ein", "zu\u00b7fried\u00b7nes"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "und liebst in ", "tokens": ["und", "liebst", "in"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.7": {"line.1": {"text": "Begl\u00fcckter ", "tokens": ["Be\u00b7gl\u00fcck\u00b7ter"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Vergn\u00fcgter Vater! Nun empfinde!", "tokens": ["Ver\u00b7gn\u00fcg\u00b7ter", "Va\u00b7ter", "!", "Nun", "emp\u00b7fin\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Lass ", "tokens": ["Lass"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Sprich Seegen; Gieb die Hand; verbinde;", "tokens": ["Sprich", "See\u00b7gen", ";", "Gieb", "die", "Hand", ";", "ver\u00b7bin\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVIMP", "NN", "$.", "VVIMP", "ART", "NN", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sprich jedes Wort mit neuer Kraft", "tokens": ["Sprich", "je\u00b7des", "Wort", "mit", "neu\u00b7er", "Kraft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PIAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zur Tochter, ", "tokens": ["zur", "Toch\u00b7ter", ","], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Nun ist ", "tokens": ["Nun", "ist"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.8": {"text": "GoTT, der ", "tokens": ["GoTT", ",", "der"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$,", "PRELS"], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "muss selber seine Lust an der Verbindung sehen:", "tokens": ["muss", "sel\u00b7ber", "sei\u00b7ne", "Lust", "an", "der", "Ver\u00b7bin\u00b7dung", "se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Er wollte: Nun Sie ist geschehen.", "tokens": ["Er", "woll\u00b7te", ":", "Nun", "Sie", "ist", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$.", "ADV", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Heut, ", "tokens": ["Heut", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "der Freuden-Thr\u00e4nen kaum erwehren:", "tokens": ["der", "Freu\u00b7den\u00b7Thr\u00e4\u00b7nen", "kaum", "er\u00b7weh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der Preussen Stamm und Hauss vermehren.", "tokens": ["der", "Preus\u00b7sen", "Stamm", "und", "Hauss", "ver\u00b7meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und, Dir zum h\u00f6chsten Ruhm, die Braut erwehlen m\u00fcssen,", "tokens": ["und", ",", "Dir", "zum", "h\u00f6chs\u00b7ten", "Ruhm", ",", "die", "Braut", "er\u00b7weh\u00b7len", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPER", "APPRART", "ADJA", "NN", "$,", "ART", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "sieht auch den Tag auf ", "tokens": ["sieht", "auch", "den", "Tag", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "bringt sie dem Br\u00e4utigam zur\u00fccke.", "tokens": ["bringt", "sie", "dem", "Br\u00e4u\u00b7ti\u00b7gam", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NE", "PTKVZ", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.9": {"line.1": {"text": "gelassne Huld und Helden-Flammen;", "tokens": ["ge\u00b7lass\u00b7ne", "Huld", "und", "Hel\u00b7den\u00b7Flam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und zwar im h\u00f6chsten Grad, zusammen.", "tokens": ["und", "zwar", "im", "h\u00f6chs\u00b7ten", "Grad", ",", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "als ", "tokens": ["als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "So gehst ", "tokens": ["So", "gehst"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Kannst ", "tokens": ["Kannst"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "So kannst ", "tokens": ["So", "kannst"], "token_info": ["word", "word"], "pos": ["ADV", "VMFIN"], "meter": "-+", "measure": "iambic.single"}}, "stanza.10": {"line.1": {"text": "und Braut von ", "tokens": ["und", "Braut", "von"], "token_info": ["word", "word", "word"], "pos": ["KON", "NN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Die Tugend wird von ", "tokens": ["Die", "Tu\u00b7gend", "wird", "von"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "die reinste Wahrheit selber melden.", "tokens": ["die", "reins\u00b7te", "Wahr\u00b7heit", "sel\u00b7ber", "mel\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Das B\u00fcndniss, das ", "tokens": ["Das", "B\u00fcnd\u00b7niss", ",", "das"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PRELS"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Es f\u00e4ngt itzt an; Befestigt sich;", "tokens": ["Es", "f\u00e4ngt", "itzt", "an", ";", "Be\u00b7fes\u00b7tigt", "sich", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$.", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nimmt zu; wird ", "tokens": ["Nimmt", "zu", ";", "wird"], "token_info": ["word", "word", "punct", "word"], "pos": ["VVFIN", "PTKVZ", "$.", "VAFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "die allergr\u00f6ssten Helden geben.", "tokens": ["die", "al\u00b7ler\u00b7gr\u00f6ss\u00b7ten", "Hel\u00b7den", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Was grosse ", "tokens": ["Was", "gros\u00b7se"], "token_info": ["word", "word"], "pos": ["PWS", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Und was ein ", "tokens": ["Und", "was", "ein"], "token_info": ["word", "word", "word"], "pos": ["KON", "PWS", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Das haben ", "tokens": ["Das", "ha\u00b7ben"], "token_info": ["word", "word"], "pos": ["PDS", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "von ", "tokens": ["von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Bist selbst ein Held. Kanst Helden zwingen.", "tokens": ["Bist", "selbst", "ein", "Held", ".", "Kanst", "Hel\u00b7den", "zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$.", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Helden suchen sich an ", "tokens": ["Die", "Hel\u00b7den", "su\u00b7chen", "sich", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "und spahren weder Pracht noch M\u00fch.", "tokens": ["und", "spah\u00b7ren", "we\u00b7der", "Pracht", "noch", "M\u00fch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "KON", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "zu ", "tokens": ["zu"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}}, "stanza.12": {"line.1": {"text": "Was Ehrfurcht macht, und Grossmuth hat;", "tokens": ["Was", "Ehr\u00b7furcht", "macht", ",", "und", "Gross\u00b7muth", "hat", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "$,", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verstand, Vernunft und Weissheit heget:", "tokens": ["Ver\u00b7stand", ",", "Ver\u00b7nunft", "und", "Weiss\u00b7heit", "he\u00b7get", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bist ", "tokens": ["Bist"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Dahin ist diese Kraft geleget,", "tokens": ["Da\u00b7hin", "ist", "die\u00b7se", "Kraft", "ge\u00b7le\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die folgen lehrt, die Kinder zieht;", "tokens": ["die", "fol\u00b7gen", "lehrt", ",", "die", "Kin\u00b7der", "zieht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die Hertzen r\u00fchrt, und Helden f\u00fchret;", "tokens": ["die", "Hert\u00b7zen", "r\u00fchrt", ",", "und", "Hel\u00b7den", "f\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du bist die Gross-Mama, so gantz Europa zieret,", "tokens": ["Du", "bist", "die", "Gross\u00b7Ma\u00b7ma", ",", "so", "gantz", "Eu\u00b7ro\u00b7pa", "zie\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ADV", "ADV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "und ihrer Fr\u00fcchte Bl\u00fcthen sieht;", "tokens": ["und", "ih\u00b7rer", "Fr\u00fcch\u00b7te", "Bl\u00fc\u00b7then", "sieht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Kayser S\u00f6hne nennt, und F\u00fcrsten T\u00f6chter giebet;", "tokens": ["Die", "Kay\u00b7ser", "S\u00f6h\u00b7ne", "nennt", ",", "und", "F\u00fcrs\u00b7ten", "T\u00f6ch\u00b7ter", "gie\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "KON", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die klug befiehlt, und z\u00e4rtlich liebet.", "tokens": ["Die", "klug", "be\u00b7fiehlt", ",", "und", "z\u00e4rt\u00b7lich", "lie\u00b7bet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "GoTT, ", "tokens": ["GoTT", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Wie Seine grossen Eigenschafften", "tokens": ["Wie", "Sei\u00b7ne", "gros\u00b7sen", "Ei\u00b7gen\u00b7schaff\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "in eigner Kraft und Macht starck, wahrhafft, ewig, treu,", "tokens": ["in", "eig\u00b7ner", "Kraft", "und", "Macht", "starck", ",", "wahr\u00b7hafft", ",", "e\u00b7wig", ",", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "PTKVZ", "$,", "VVFIN", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "unnennbarlich zusammen haften.", "tokens": ["un\u00b7nenn\u00b7bar\u00b7lich", "zu\u00b7sam\u00b7men", "haf\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Wie festgestellt Sein Vorsatz ist;", "tokens": ["Wie", "fest\u00b7ge\u00b7stellt", "Sein", "Vor\u00b7satz", "ist", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie Seine Weissheit Menschen f\u00fchret;", "tokens": ["Wie", "Sei\u00b7ne", "Weiss\u00b7heit", "Men\u00b7schen", "f\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "die H\u00f6chsten F\u00fcrsten setzt, und K\u00f6nige regieret;", "tokens": ["die", "H\u00f6chs\u00b7ten", "F\u00fcrs\u00b7ten", "setzt", ",", "und", "K\u00f6\u00b7ni\u00b7ge", "re\u00b7gie\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie wenig Er Sein Wort vergisst:", "tokens": ["Wie", "we\u00b7nig", "Er", "Sein", "Wort", "ver\u00b7gisst", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So kr\u00e4ftig, so gewiss, so reich wird er den Seegen", "tokens": ["So", "kr\u00e4f\u00b7tig", ",", "so", "ge\u00b7wiss", ",", "so", "reich", "wird", "er", "den", "See\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "auf ", "tokens": ["auf"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}}, "stanza.14": {"line.1": {"text": "Durchlauchtigster!", "tokens": ["Durch\u00b7lauch\u00b7tigs\u00b7ter", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Du treibst mich so!", "tokens": ["Du", "treibst", "mich", "so", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Du zwingst mich jetzt ein Lied zu dichten!", "tokens": ["Du", "zwingst", "mich", "jetzt", "ein", "Lied", "zu", "dich\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du machst die halbe Welt vergn\u00fcgt und hertzlich froh!", "tokens": ["Du", "machst", "die", "hal\u00b7be", "Welt", "ver\u00b7gn\u00fcgt", "und", "hertz\u00b7lich", "froh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "VVPP", "KON", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kann ich auch das geschickt verrichten,", "tokens": ["Kann", "ich", "auch", "das", "ge\u00b7schickt", "ver\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "was M\u00e4nnern viel zu schaffen macht,", "tokens": ["was", "M\u00e4n\u00b7nern", "viel", "zu", "schaf\u00b7fen", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "die gut und hoch zu dencken wissen;", "tokens": ["die", "gut", "und", "hoch", "zu", "den\u00b7cken", "wis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "die grosser Helden That oft lebhaft abgerissen;", "tokens": ["die", "gros\u00b7ser", "Hel\u00b7den", "That", "oft", "leb\u00b7haft", "ab\u00b7ge\u00b7ris\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "und die, bey ", "tokens": ["und", "die", ",", "bey"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "ART", "$,", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "die Kunst und Wissenschaft auch h\u00f6her noch getrieben,", "tokens": ["die", "Kunst", "und", "Wis\u00b7sen\u00b7schaft", "auch", "h\u00f6\u00b7her", "noch", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "dass mir so gar nichts \u00fcbrig blieben?", "tokens": ["dass", "mir", "so", "gar", "nichts", "\u00fcb\u00b7rig", "blie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PIS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Doch ihre Kunst bet\u00e4ubt mich nicht:", "tokens": ["Doch", "ih\u00b7re", "Kunst", "be\u00b7t\u00e4ubt", "mich", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Regung bleibt; die Pflicht muss sprechen.", "tokens": ["Die", "Re\u00b7gung", "bleibt", ";", "die", "Pflicht", "muss", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der schlauen Kunst den Stoltz zu brechen;", "tokens": ["der", "schlau\u00b7en", "Kunst", "den", "Stoltz", "zu", "bre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dass ich mit Ehrfurcht dencken kan,", "tokens": ["dass", "ich", "mit", "Ehr\u00b7furcht", "den\u00b7cken", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "behertzt, aus reiner Treue, schreibe,", "tokens": ["be\u00b7hertzt", ",", "aus", "rei\u00b7ner", "Treu\u00b7e", ",", "schrei\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "durch ", "tokens": ["durch"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Das ist mein Trieb! der reitzt mich an;", "tokens": ["Das", "ist", "mein", "Trieb", "!", "der", "reitzt", "mich", "an", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$.", "ART", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "den setz ich hier allein der Wissenschaft entgegen;", "tokens": ["den", "setz", "ich", "hier", "al\u00b7lein", "der", "Wis\u00b7sen\u00b7schaft", "ent\u00b7ge\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "der hilft mir reiflich \u00fcberlegen.", "tokens": ["der", "hilft", "mir", "reif\u00b7lich", "\u00fc\u00b7berl\u00b7e\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Du Br\u00e4utgam in der gr\u00f6ssten Bl\u00fcthe!", "tokens": ["Du", "Br\u00e4ut\u00b7gam", "in", "der", "gr\u00f6ss\u00b7ten", "Bl\u00fc\u00b7the", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "zeigst nicht die Hoffnung nur: Du bringst, Du giebst sie schon.", "tokens": ["zeigst", "nicht", "die", "Hoff\u00b7nung", "nur", ":", "Du", "bringst", ",", "Du", "giebst", "sie", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "ADV", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "der Trieb zu ", "tokens": ["der", "Trieb", "zu"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "PTKZU"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "der Hoffnung st\u00e4rkt und Helden reget,", "tokens": ["der", "Hoff\u00b7nung", "st\u00e4rkt", "und", "Hel\u00b7den", "re\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "dass ", "tokens": ["dass"], "token_info": ["word"], "pos": ["KOUS"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Bringt ", "tokens": ["Bringt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "das keinen andern Zug, Trieb, Gunst, Lust und Verlangen", "tokens": ["das", "kei\u00b7nen", "an\u00b7dern", "Zug", ",", "Trieb", ",", "Gunst", ",", "Lust", "und", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "PIAT", "ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "als nur nach Dir allein empfangen.", "tokens": ["als", "nur", "nach", "Dir", "al\u00b7lein", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "wie ", "tokens": ["wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Er lebet nur, mit ", "tokens": ["Er", "le\u00b7bet", "nur", ",", "mit"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "So w\u00fcrdig ist ", "tokens": ["So", "w\u00fcr\u00b7dig", "ist"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.18": {"line.1": {"text": "und Freunde K\u00f6niglich besieget", "tokens": ["und", "Freun\u00b7de", "K\u00f6\u00b7nig\u00b7lich", "be\u00b7sie\u00b7get"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hast ", "tokens": ["Hast"], "token_info": ["word"], "pos": ["NE"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "das es mit stiller Liebe krieget?", "tokens": ["das", "es", "mit", "stil\u00b7ler", "Lie\u00b7be", "krie\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nun gilt kein Donner in der Luft,", "tokens": ["Nun", "gilt", "kein", "Don\u00b7ner", "in", "der", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "der Felsen sprengt und Berge reisset,", "tokens": ["der", "Fel\u00b7sen", "sprengt", "und", "Ber\u00b7ge", "reis\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "den Wall verw\u00fcst, durchw\u00fchlt, die Th\u00fcren niederschmeisset;", "tokens": ["den", "Wall", "ver\u00b7w\u00fcst", ",", "durch\u00b7w\u00fchlt", ",", "die", "Th\u00fc\u00b7ren", "nie\u00b7der\u00b7schmeis\u00b7set", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und niemand, der: ", "tokens": ["Und", "nie\u00b7mand", ",", "der", ":"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "$."], "meter": "-+--", "measure": "dactylic.init"}, "line.8": {"text": "Doch ja! der St\u00fccke Knall blitzt, schmettert, f\u00e4hrt geschwinder", "tokens": ["Doch", "ja", "!", "der", "St\u00fc\u00b7cke", "Knall", "blitzt", ",", "schmet\u00b7tert", ",", "f\u00e4hrt", "ge\u00b7schwin\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "$.", "ART", "NN", "NN", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "zu Ehren ", "tokens": ["zu", "Eh\u00b7ren"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.19": {"line.1": {"text": "O! Preussens ", "tokens": ["O", "!", "Preus\u00b7sens"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$.", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Du hast des jungen Friedrichs Tugend", "tokens": ["Du", "hast", "des", "jun\u00b7gen", "Fried\u00b7richs", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "vor ", "tokens": ["vor"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "und ", "tokens": ["und"], "token_info": ["word"], "pos": ["KON"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Liebst ", "tokens": ["Liebst"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "sprichst ein zufriednes ", "tokens": ["sprichst", "ein", "zu\u00b7fried\u00b7nes"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "und liebst in ", "tokens": ["und", "liebst", "in"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.20": {"line.1": {"text": "Begl\u00fcckter ", "tokens": ["Be\u00b7gl\u00fcck\u00b7ter"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Vergn\u00fcgter Vater! Nun empfinde!", "tokens": ["Ver\u00b7gn\u00fcg\u00b7ter", "Va\u00b7ter", "!", "Nun", "emp\u00b7fin\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Lass ", "tokens": ["Lass"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Sprich Seegen; Gieb die Hand; verbinde;", "tokens": ["Sprich", "See\u00b7gen", ";", "Gieb", "die", "Hand", ";", "ver\u00b7bin\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVIMP", "NN", "$.", "VVIMP", "ART", "NN", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sprich jedes Wort mit neuer Kraft", "tokens": ["Sprich", "je\u00b7des", "Wort", "mit", "neu\u00b7er", "Kraft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PIAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zur Tochter, ", "tokens": ["zur", "Toch\u00b7ter", ","], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Nun ist ", "tokens": ["Nun", "ist"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.8": {"text": "GoTT, der ", "tokens": ["GoTT", ",", "der"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$,", "PRELS"], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "muss selber seine Lust an der Verbindung sehen:", "tokens": ["muss", "sel\u00b7ber", "sei\u00b7ne", "Lust", "an", "der", "Ver\u00b7bin\u00b7dung", "se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Er wollte: Nun Sie ist geschehen.", "tokens": ["Er", "woll\u00b7te", ":", "Nun", "Sie", "ist", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$.", "ADV", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Heut, ", "tokens": ["Heut", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "der Freuden-Thr\u00e4nen kaum erwehren:", "tokens": ["der", "Freu\u00b7den\u00b7Thr\u00e4\u00b7nen", "kaum", "er\u00b7weh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der Preussen Stamm und Hauss vermehren.", "tokens": ["der", "Preus\u00b7sen", "Stamm", "und", "Hauss", "ver\u00b7meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und, Dir zum h\u00f6chsten Ruhm, die Braut erwehlen m\u00fcssen,", "tokens": ["und", ",", "Dir", "zum", "h\u00f6chs\u00b7ten", "Ruhm", ",", "die", "Braut", "er\u00b7weh\u00b7len", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPER", "APPRART", "ADJA", "NN", "$,", "ART", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "sieht auch den Tag auf ", "tokens": ["sieht", "auch", "den", "Tag", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "bringt sie dem Br\u00e4utigam zur\u00fccke.", "tokens": ["bringt", "sie", "dem", "Br\u00e4u\u00b7ti\u00b7gam", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NE", "PTKVZ", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.22": {"line.1": {"text": "gelassne Huld und Helden-Flammen;", "tokens": ["ge\u00b7lass\u00b7ne", "Huld", "und", "Hel\u00b7den\u00b7Flam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und zwar im h\u00f6chsten Grad, zusammen.", "tokens": ["und", "zwar", "im", "h\u00f6chs\u00b7ten", "Grad", ",", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "als ", "tokens": ["als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "So gehst ", "tokens": ["So", "gehst"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Kannst ", "tokens": ["Kannst"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "So kannst ", "tokens": ["So", "kannst"], "token_info": ["word", "word"], "pos": ["ADV", "VMFIN"], "meter": "-+", "measure": "iambic.single"}}, "stanza.23": {"line.1": {"text": "und Braut von ", "tokens": ["und", "Braut", "von"], "token_info": ["word", "word", "word"], "pos": ["KON", "NN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Die Tugend wird von ", "tokens": ["Die", "Tu\u00b7gend", "wird", "von"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "die reinste Wahrheit selber melden.", "tokens": ["die", "reins\u00b7te", "Wahr\u00b7heit", "sel\u00b7ber", "mel\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Das B\u00fcndniss, das ", "tokens": ["Das", "B\u00fcnd\u00b7niss", ",", "das"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PRELS"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Es f\u00e4ngt itzt an; Befestigt sich;", "tokens": ["Es", "f\u00e4ngt", "itzt", "an", ";", "Be\u00b7fes\u00b7tigt", "sich", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$.", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nimmt zu; wird ", "tokens": ["Nimmt", "zu", ";", "wird"], "token_info": ["word", "word", "punct", "word"], "pos": ["VVFIN", "PTKVZ", "$.", "VAFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "die allergr\u00f6ssten Helden geben.", "tokens": ["die", "al\u00b7ler\u00b7gr\u00f6ss\u00b7ten", "Hel\u00b7den", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Was grosse ", "tokens": ["Was", "gros\u00b7se"], "token_info": ["word", "word"], "pos": ["PWS", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Und was ein ", "tokens": ["Und", "was", "ein"], "token_info": ["word", "word", "word"], "pos": ["KON", "PWS", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Das haben ", "tokens": ["Das", "ha\u00b7ben"], "token_info": ["word", "word"], "pos": ["PDS", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "von ", "tokens": ["von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Bist selbst ein Held. Kanst Helden zwingen.", "tokens": ["Bist", "selbst", "ein", "Held", ".", "Kanst", "Hel\u00b7den", "zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$.", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Helden suchen sich an ", "tokens": ["Die", "Hel\u00b7den", "su\u00b7chen", "sich", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "und spahren weder Pracht noch M\u00fch.", "tokens": ["und", "spah\u00b7ren", "we\u00b7der", "Pracht", "noch", "M\u00fch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "KON", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "zu ", "tokens": ["zu"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}}, "stanza.25": {"line.1": {"text": "Was Ehrfurcht macht, und Grossmuth hat;", "tokens": ["Was", "Ehr\u00b7furcht", "macht", ",", "und", "Gross\u00b7muth", "hat", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "$,", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verstand, Vernunft und Weissheit heget:", "tokens": ["Ver\u00b7stand", ",", "Ver\u00b7nunft", "und", "Weiss\u00b7heit", "he\u00b7get", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bist ", "tokens": ["Bist"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Dahin ist diese Kraft geleget,", "tokens": ["Da\u00b7hin", "ist", "die\u00b7se", "Kraft", "ge\u00b7le\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die folgen lehrt, die Kinder zieht;", "tokens": ["die", "fol\u00b7gen", "lehrt", ",", "die", "Kin\u00b7der", "zieht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die Hertzen r\u00fchrt, und Helden f\u00fchret;", "tokens": ["die", "Hert\u00b7zen", "r\u00fchrt", ",", "und", "Hel\u00b7den", "f\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du bist die Gross-Mama, so gantz Europa zieret,", "tokens": ["Du", "bist", "die", "Gross\u00b7Ma\u00b7ma", ",", "so", "gantz", "Eu\u00b7ro\u00b7pa", "zie\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ADV", "ADV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "und ihrer Fr\u00fcchte Bl\u00fcthen sieht;", "tokens": ["und", "ih\u00b7rer", "Fr\u00fcch\u00b7te", "Bl\u00fc\u00b7then", "sieht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Kayser S\u00f6hne nennt, und F\u00fcrsten T\u00f6chter giebet;", "tokens": ["Die", "Kay\u00b7ser", "S\u00f6h\u00b7ne", "nennt", ",", "und", "F\u00fcrs\u00b7ten", "T\u00f6ch\u00b7ter", "gie\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "KON", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die klug befiehlt, und z\u00e4rtlich liebet.", "tokens": ["Die", "klug", "be\u00b7fiehlt", ",", "und", "z\u00e4rt\u00b7lich", "lie\u00b7bet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "GoTT, ", "tokens": ["GoTT", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Wie Seine grossen Eigenschafften", "tokens": ["Wie", "Sei\u00b7ne", "gros\u00b7sen", "Ei\u00b7gen\u00b7schaff\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "in eigner Kraft und Macht starck, wahrhafft, ewig, treu,", "tokens": ["in", "eig\u00b7ner", "Kraft", "und", "Macht", "starck", ",", "wahr\u00b7hafft", ",", "e\u00b7wig", ",", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "PTKVZ", "$,", "VVFIN", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "unnennbarlich zusammen haften.", "tokens": ["un\u00b7nenn\u00b7bar\u00b7lich", "zu\u00b7sam\u00b7men", "haf\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Wie festgestellt Sein Vorsatz ist;", "tokens": ["Wie", "fest\u00b7ge\u00b7stellt", "Sein", "Vor\u00b7satz", "ist", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie Seine Weissheit Menschen f\u00fchret;", "tokens": ["Wie", "Sei\u00b7ne", "Weiss\u00b7heit", "Men\u00b7schen", "f\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "die H\u00f6chsten F\u00fcrsten setzt, und K\u00f6nige regieret;", "tokens": ["die", "H\u00f6chs\u00b7ten", "F\u00fcrs\u00b7ten", "setzt", ",", "und", "K\u00f6\u00b7ni\u00b7ge", "re\u00b7gie\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie wenig Er Sein Wort vergisst:", "tokens": ["Wie", "we\u00b7nig", "Er", "Sein", "Wort", "ver\u00b7gisst", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So kr\u00e4ftig, so gewiss, so reich wird er den Seegen", "tokens": ["So", "kr\u00e4f\u00b7tig", ",", "so", "ge\u00b7wiss", ",", "so", "reich", "wird", "er", "den", "See\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "auf ", "tokens": ["auf"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}}}}}