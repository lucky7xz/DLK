{"textgrid.poem.47782": {"metadata": {"author": {"name": "Daumer, Georg Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "[sing', o lieblicher S\u00e4ngermund]", "genre": "verse", "period": "N.A.", "pub_year": 1837, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sing', o lieblicher S\u00e4ngermund,", "tokens": ["Sing'", ",", "o", "lieb\u00b7li\u00b7cher", "S\u00e4n\u00b7ger\u00b7mund", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Stets von neuem und ende nicht!", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Spend' uns herrlicher Reime Fund", "tokens": ["Spend'", "uns", "herr\u00b7li\u00b7cher", "Rei\u00b7me", "Fund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Stets von neuem und ende nicht! \u2013", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.2": {"line.1": {"text": "In holdseligem Minnespiel", "tokens": ["In", "hold\u00b7se\u00b7li\u00b7gem", "Min\u00b7ne\u00b7spiel"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00dcb', o Sch\u00fcler Hafisens, dich,", "tokens": ["\u00dcb'", ",", "o", "Sch\u00fc\u00b7ler", "Ha\u00b7fi\u00b7sens", ",", "dich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "FM", "NN", "NE", "$,", "PPER", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Weil nur also das Herz gesund,", "tokens": ["Weil", "nur", "al\u00b7so", "das", "Herz", "ge\u00b7sund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Stets von neuem und ende nicht! \u2013", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.3": {"line.1": {"text": "Sieh, o Schenke, die Becher leer;", "tokens": ["Sieh", ",", "o", "Schen\u00b7ke", ",", "die", "Be\u00b7cher", "leer", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "NN", "$,", "ART", "NN", "ADJD", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Bring' uns, um zu bekr\u00e4ftigen", "tokens": ["Bring'", "uns", ",", "um", "zu", "be\u00b7kr\u00e4f\u00b7ti\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PPER", "$,", "KOUI", "PTKZU", "VVINF"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Mit dem Weine den edlen Bund,", "tokens": ["Mit", "dem", "Wei\u00b7ne", "den", "ed\u00b7len", "Bund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Stets von neuem und ende nicht! \u2013", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.4": {"line.1": {"text": "Da\u00df ich theuer und werth dir sei,", "tokens": ["Da\u00df", "ich", "theu\u00b7er", "und", "werth", "dir", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "KON", "ADJD", "PPER", "VAFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Sag' es, Liebste, denn nimmermehr", "tokens": ["Sag'", "es", ",", "Liebs\u00b7te", ",", "denn", "nim\u00b7mer\u00b7mehr"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "KON", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Ward mir s\u00fc\u00dfere M\u00e4hre kund,", "tokens": ["Ward", "mir", "s\u00fc\u00b7\u00dfe\u00b7re", "M\u00e4h\u00b7re", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Stets von neuem und ende nicht! \u2013", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.5": {"line.1": {"text": "Ras' und tobe, du schwarzes Herz,", "tokens": ["Ras'", "und", "to\u00b7be", ",", "du", "schwar\u00b7zes", "Herz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Wenn es also gef\u00e4llig ist,", "tokens": ["Wenn", "es", "al\u00b7so", "ge\u00b7f\u00e4l\u00b7lig", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Unvern\u00fcnftig und ohne Grund", "tokens": ["Un\u00b7ver\u00b7n\u00fcnf\u00b7tig", "und", "oh\u00b7ne", "Grund"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "APPR", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Stets von neuem und ende nicht!", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.6": {"line.1": {"text": "Du, o Quelle des Lichts, jedoch", "tokens": ["Du", ",", "o", "Quel\u00b7le", "des", "Lichts", ",", "je\u00b7doch"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "$,", "FM", "NN", "ART", "NN", "$,", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Scheuch', o Sonne, die finstre Nacht,", "tokens": ["Scheuch'", ",", "o", "Son\u00b7ne", ",", "die", "finst\u00b7re", "Nacht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "FM", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Hell durchstrahle das Weltenrund", "tokens": ["Hell", "durch\u00b7strah\u00b7le", "das", "Wel\u00b7ten\u00b7rund"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Stets von neuem und ende nicht!", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.7": {"line.1": {"text": "Sing', o lieblicher S\u00e4ngermund,", "tokens": ["Sing'", ",", "o", "lieb\u00b7li\u00b7cher", "S\u00e4n\u00b7ger\u00b7mund", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Stets von neuem und ende nicht!", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Spend' uns herrlicher Reime Fund", "tokens": ["Spend'", "uns", "herr\u00b7li\u00b7cher", "Rei\u00b7me", "Fund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Stets von neuem und ende nicht! \u2013", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.8": {"line.1": {"text": "In holdseligem Minnespiel", "tokens": ["In", "hold\u00b7se\u00b7li\u00b7gem", "Min\u00b7ne\u00b7spiel"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00dcb', o Sch\u00fcler Hafisens, dich,", "tokens": ["\u00dcb'", ",", "o", "Sch\u00fc\u00b7ler", "Ha\u00b7fi\u00b7sens", ",", "dich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "FM", "NN", "NE", "$,", "PPER", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Weil nur also das Herz gesund,", "tokens": ["Weil", "nur", "al\u00b7so", "das", "Herz", "ge\u00b7sund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Stets von neuem und ende nicht! \u2013", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.9": {"line.1": {"text": "Sieh, o Schenke, die Becher leer;", "tokens": ["Sieh", ",", "o", "Schen\u00b7ke", ",", "die", "Be\u00b7cher", "leer", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "NN", "$,", "ART", "NN", "ADJD", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Bring' uns, um zu bekr\u00e4ftigen", "tokens": ["Bring'", "uns", ",", "um", "zu", "be\u00b7kr\u00e4f\u00b7ti\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PPER", "$,", "KOUI", "PTKZU", "VVINF"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Mit dem Weine den edlen Bund,", "tokens": ["Mit", "dem", "Wei\u00b7ne", "den", "ed\u00b7len", "Bund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Stets von neuem und ende nicht! \u2013", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.10": {"line.1": {"text": "Da\u00df ich theuer und werth dir sei,", "tokens": ["Da\u00df", "ich", "theu\u00b7er", "und", "werth", "dir", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "KON", "ADJD", "PPER", "VAFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Sag' es, Liebste, denn nimmermehr", "tokens": ["Sag'", "es", ",", "Liebs\u00b7te", ",", "denn", "nim\u00b7mer\u00b7mehr"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "KON", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Ward mir s\u00fc\u00dfere M\u00e4hre kund,", "tokens": ["Ward", "mir", "s\u00fc\u00b7\u00dfe\u00b7re", "M\u00e4h\u00b7re", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Stets von neuem und ende nicht! \u2013", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.11": {"line.1": {"text": "Ras' und tobe, du schwarzes Herz,", "tokens": ["Ras'", "und", "to\u00b7be", ",", "du", "schwar\u00b7zes", "Herz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Wenn es also gef\u00e4llig ist,", "tokens": ["Wenn", "es", "al\u00b7so", "ge\u00b7f\u00e4l\u00b7lig", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Unvern\u00fcnftig und ohne Grund", "tokens": ["Un\u00b7ver\u00b7n\u00fcnf\u00b7tig", "und", "oh\u00b7ne", "Grund"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "APPR", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Stets von neuem und ende nicht!", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.12": {"line.1": {"text": "Du, o Quelle des Lichts, jedoch", "tokens": ["Du", ",", "o", "Quel\u00b7le", "des", "Lichts", ",", "je\u00b7doch"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "$,", "FM", "NN", "ART", "NN", "$,", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Scheuch', o Sonne, die finstre Nacht,", "tokens": ["Scheuch'", ",", "o", "Son\u00b7ne", ",", "die", "finst\u00b7re", "Nacht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "FM", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Hell durchstrahle das Weltenrund", "tokens": ["Hell", "durch\u00b7strah\u00b7le", "das", "Wel\u00b7ten\u00b7rund"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Stets von neuem und ende nicht!", "tokens": ["Stets", "von", "neu\u00b7em", "und", "en\u00b7de", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "KON", "NN", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}