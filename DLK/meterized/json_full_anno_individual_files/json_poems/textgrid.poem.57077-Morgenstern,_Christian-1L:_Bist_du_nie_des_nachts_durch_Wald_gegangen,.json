{"textgrid.poem.57077": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Bist du nie des nachts durch Wald gegangen,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bist du nie des nachts durch Wald gegangen,", "tokens": ["Bist", "du", "nie", "des", "nachts", "durch", "Wald", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "wo du deinen eignen Fu\u00df nicht sahst?", "tokens": ["wo", "du", "dei\u00b7nen", "eig\u00b7nen", "Fu\u00df", "nicht", "sahst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "ADJA", "NN", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Doch ein Wissen \u00fcberwand dein Bangen:", "tokens": ["Doch", "ein", "Wis\u00b7sen", "\u00fc\u00b7ber\u00b7wand", "dein", "Ban\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Dich f\u00fchrt der Weg.", "tokens": ["Dich", "f\u00fchrt", "der", "Weg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "H\u00e4lt dich Leid und Tr\u00fcbsal nie umfangen,", "tokens": ["H\u00e4lt", "dich", "Leid", "und", "Tr\u00fcb\u00b7sal", "nie", "um\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "da\u00df du zitterst, welchem Ziel du nahst?", "tokens": ["da\u00df", "du", "zit\u00b7terst", ",", "wel\u00b7chem", "Ziel", "du", "nahst", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Doch ein Wissen \u00fcbermannt dein Bangen:", "tokens": ["Doch", "ein", "Wis\u00b7sen", "\u00fc\u00b7berm\u00b7annt", "dein", "Ban\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Dich f\u00fchrt dein Weg.", "tokens": ["Dich", "f\u00fchrt", "dein", "Weg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Bist du nie des nachts durch Wald gegangen,", "tokens": ["Bist", "du", "nie", "des", "nachts", "durch", "Wald", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "wo du deinen eignen Fu\u00df nicht sahst?", "tokens": ["wo", "du", "dei\u00b7nen", "eig\u00b7nen", "Fu\u00df", "nicht", "sahst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "ADJA", "NN", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Doch ein Wissen \u00fcberwand dein Bangen:", "tokens": ["Doch", "ein", "Wis\u00b7sen", "\u00fc\u00b7ber\u00b7wand", "dein", "Ban\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Dich f\u00fchrt der Weg.", "tokens": ["Dich", "f\u00fchrt", "der", "Weg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "H\u00e4lt dich Leid und Tr\u00fcbsal nie umfangen,", "tokens": ["H\u00e4lt", "dich", "Leid", "und", "Tr\u00fcb\u00b7sal", "nie", "um\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "da\u00df du zitterst, welchem Ziel du nahst?", "tokens": ["da\u00df", "du", "zit\u00b7terst", ",", "wel\u00b7chem", "Ziel", "du", "nahst", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Doch ein Wissen \u00fcbermannt dein Bangen:", "tokens": ["Doch", "ein", "Wis\u00b7sen", "\u00fc\u00b7berm\u00b7annt", "dein", "Ban\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Dich f\u00fchrt dein Weg.", "tokens": ["Dich", "f\u00fchrt", "dein", "Weg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}