{"textgrid.poem.31240": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "1L: Dorillgen/ kleines Ringel-Schwein", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dorillgen/ kleines Ringel-Schwein", "tokens": ["Do\u00b7rill\u00b7gen", "/", "klei\u00b7nes", "Rin\u00b7gel\u00b7Schwein"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$(", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "au\u00df planck polirtem Helffen-Bein/", "tokens": ["au\u00df", "planck", "po\u00b7lir\u00b7tem", "Helf\u00b7fen\u00b7Bein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVIMP", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wie man au\u00df M\u00e4ntschen F\u00e4rckel macht/", "tokens": ["wie", "man", "au\u00df", "M\u00e4nt\u00b7schen", "F\u00e4r\u00b7ckel", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "hat ", "tokens": ["hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+", "measure": "single.up"}}, "stanza.2": {"line.1": {"text": "Mein Spizzen-Mantel au\u00df Braband", "tokens": ["Mein", "Spiz\u00b7zen\u00b7Man\u00b7tel", "au\u00df", "Bra\u00b7band"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ist dir nur allzu wohl-bekandt;", "tokens": ["ist", "dir", "nur", "all\u00b7zu", "wohl\u00b7be\u00b7kandt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "kaum ", "tokens": ["kaum"], "token_info": ["word"], "pos": ["ADV"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "das Zokker-s\u00fcsse Lihbes-Spihl.", "tokens": ["das", "Zok\u00b7ker\u00b7s\u00fcs\u00b7se", "Lih\u00b7bes\u00b7Spihl", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch machstu dich fast zu gemein/", "tokens": ["Doch", "machs\u00b7tu", "dich", "fast", "zu", "ge\u00b7mein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du l\u00e4sst noch andre Sch\u00e4ffer ein.", "tokens": ["du", "l\u00e4sst", "noch", "and\u00b7re", "Sch\u00e4f\u00b7fer", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Beqw\u00e4m gehn unter deinen Rokk", "tokens": ["Be\u00b7qw\u00e4m", "gehn", "un\u00b7ter", "dei\u00b7nen", "Rokk"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "zw\u00f6lff M\u00e4nner und ein Zihgen-Bokk.", "tokens": ["zw\u00f6lff", "M\u00e4n\u00b7ner", "und", "ein", "Zih\u00b7gen\u00b7Bokk", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Dr\u00fcmb huhst ich dir itzt ins Gesicht:", "tokens": ["Dr\u00fcmb", "huhst", "ich", "dir", "itzt", "ins", "Ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+++-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "for Lauch und N\u00e4sseln b\u00fcn ich nicht!", "tokens": ["for", "Lauch", "und", "N\u00e4s\u00b7seln", "b\u00fcn", "ich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn solch ein Maul/ das jeder l\u00e4kkt/", "tokens": ["Denn", "solch", "ein", "Maul", "/", "das", "je\u00b7der", "l\u00e4kkt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ART", "NN", "$(", "PRELS", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "nach nichts al\u00df Coloqwinten schm\u00e4kkt!", "tokens": ["nach", "nichts", "al\u00df", "Co\u00b7lo\u00b7qwin\u00b7ten", "schm\u00e4kkt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "KOKOM", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Dorillgen/ kleines Ringel-Schwein", "tokens": ["Do\u00b7rill\u00b7gen", "/", "klei\u00b7nes", "Rin\u00b7gel\u00b7Schwein"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$(", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "au\u00df planck polirtem Helffen-Bein/", "tokens": ["au\u00df", "planck", "po\u00b7lir\u00b7tem", "Helf\u00b7fen\u00b7Bein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVIMP", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wie man au\u00df M\u00e4ntschen F\u00e4rckel macht/", "tokens": ["wie", "man", "au\u00df", "M\u00e4nt\u00b7schen", "F\u00e4r\u00b7ckel", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "hat ", "tokens": ["hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+", "measure": "single.up"}}, "stanza.6": {"line.1": {"text": "Mein Spizzen-Mantel au\u00df Braband", "tokens": ["Mein", "Spiz\u00b7zen\u00b7Man\u00b7tel", "au\u00df", "Bra\u00b7band"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ist dir nur allzu wohl-bekandt;", "tokens": ["ist", "dir", "nur", "all\u00b7zu", "wohl\u00b7be\u00b7kandt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "kaum ", "tokens": ["kaum"], "token_info": ["word"], "pos": ["ADV"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "das Zokker-s\u00fcsse Lihbes-Spihl.", "tokens": ["das", "Zok\u00b7ker\u00b7s\u00fcs\u00b7se", "Lih\u00b7bes\u00b7Spihl", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Doch machstu dich fast zu gemein/", "tokens": ["Doch", "machs\u00b7tu", "dich", "fast", "zu", "ge\u00b7mein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du l\u00e4sst noch andre Sch\u00e4ffer ein.", "tokens": ["du", "l\u00e4sst", "noch", "and\u00b7re", "Sch\u00e4f\u00b7fer", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Beqw\u00e4m gehn unter deinen Rokk", "tokens": ["Be\u00b7qw\u00e4m", "gehn", "un\u00b7ter", "dei\u00b7nen", "Rokk"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "zw\u00f6lff M\u00e4nner und ein Zihgen-Bokk.", "tokens": ["zw\u00f6lff", "M\u00e4n\u00b7ner", "und", "ein", "Zih\u00b7gen\u00b7Bokk", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Dr\u00fcmb huhst ich dir itzt ins Gesicht:", "tokens": ["Dr\u00fcmb", "huhst", "ich", "dir", "itzt", "ins", "Ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+++-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "for Lauch und N\u00e4sseln b\u00fcn ich nicht!", "tokens": ["for", "Lauch", "und", "N\u00e4s\u00b7seln", "b\u00fcn", "ich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn solch ein Maul/ das jeder l\u00e4kkt/", "tokens": ["Denn", "solch", "ein", "Maul", "/", "das", "je\u00b7der", "l\u00e4kkt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ART", "NN", "$(", "PRELS", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "nach nichts al\u00df Coloqwinten schm\u00e4kkt!", "tokens": ["nach", "nichts", "al\u00df", "Co\u00b7lo\u00b7qwin\u00b7ten", "schm\u00e4kkt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "KOKOM", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}