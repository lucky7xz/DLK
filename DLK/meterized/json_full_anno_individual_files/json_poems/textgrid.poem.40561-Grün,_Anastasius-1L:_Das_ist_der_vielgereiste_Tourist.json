{"textgrid.poem.40561": {"metadata": {"author": {"name": "Gr\u00fcn, Anastasius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Das ist der vielgereiste Tourist", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das ist der vielgereiste Tourist", "tokens": ["Das", "ist", "der", "viel\u00b7ge\u00b7reis\u00b7te", "Tou\u00b7rist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Herr Storch, der heimgekehrte,", "tokens": ["Herr", "Storch", ",", "der", "heim\u00b7ge\u00b7kehr\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mit langen stolzen Schritten mi\u00dft", "tokens": ["Mit", "lan\u00b7gen", "stol\u00b7zen", "Schrit\u00b7ten", "mi\u00dft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Daches First der Werthe.", "tokens": ["Des", "Da\u00b7ches", "First", "der", "Wert\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Er tr\u00e4gt, wie's Wandrerart gebot,", "tokens": ["Er", "tr\u00e4gt", ",", "wie's", "Wand\u00b7re\u00b7rart", "ge\u00b7bot", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein wei\u00dfes Blousenhemde", "tokens": ["Ein", "wei\u00b7\u00dfes", "Blou\u00b7sen\u00b7hem\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nebst hohen Stiefeln von Juchten roth,", "tokens": ["Nebst", "ho\u00b7hen", "Stie\u00b7feln", "von", "Juch\u00b7ten", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und preist die sch\u00f6ne Fremde:", "tokens": ["Und", "preist", "die", "sch\u00f6\u00b7ne", "Frem\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "\u00bbda w\u00e4ren wir wieder, da wohnen wir", "tokens": ["\u00bb", "da", "w\u00e4\u00b7ren", "wir", "wie\u00b7der", ",", "da", "woh\u00b7nen", "wir"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ADV", "$,", "ADV", "VVFIN", "PPER"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Grad' \u00fcber dem Stall der Rinder.", "tokens": ["Grad'", "\u00fc\u00b7ber", "dem", "Stall", "der", "Rin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Prophet in der Heimat, bin ich hier", "tokens": ["Pro\u00b7phet", "in", "der", "Hei\u00b7mat", ",", "bin", "ich", "hier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "$,", "VAFIN", "PPER", "ADV"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Das Spiel der Bauernkinder.", "tokens": ["Das", "Spiel", "der", "Bau\u00b7ern\u00b7kin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "In Rom wohnt' ich auf dem Vatikan,", "tokens": ["In", "Rom", "wohnt'", "ich", "auf", "dem", "Va\u00b7ti\u00b7kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Sah wandeln den Papst im Garten,", "tokens": ["Sah", "wan\u00b7deln", "den", "Papst", "im", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da wuchsen, seht eure K\u00fcrbiss' an,", "tokens": ["Da", "wuch\u00b7sen", ",", "seht", "eu\u00b7re", "K\u00fcr\u00b7biss'", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So gro\u00df der Orangen Arten.", "tokens": ["So", "gro\u00df", "der", "O\u00b7ran\u00b7gen", "Ar\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Vom Rhein war b\u00f6se Post gerad',", "tokens": ["Vom", "Rhein", "war", "b\u00f6\u00b7se", "Post", "ge\u00b7rad'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "VAFIN", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Papst in Sinnen verloren;", "tokens": ["Der", "Papst", "in", "Sin\u00b7nen", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich gab ihm einen guten Rath,", "tokens": ["Ich", "gab", "ihm", "ei\u00b7nen", "gu\u00b7ten", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er mir den Orden vom Sporen.", "tokens": ["Er", "mir", "den", "Or\u00b7den", "vom", "Spo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Auch hatt' er drob mir keinen Verdru\u00df,", "tokens": ["Auch", "hatt'", "er", "drob", "mir", "kei\u00b7nen", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Als ich ihm in einem Sitze", "tokens": ["Als", "ich", "ihm", "in", "ei\u00b7nem", "Sit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vor Durst aussoff den Tiberflu\u00df,", "tokens": ["Vor", "Durst", "aus\u00b7soff", "den", "Ti\u00b7ber\u00b7flu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So gro\u00df ist dort die Hitze.", "tokens": ["So", "gro\u00df", "ist", "dort", "die", "Hit\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Am Aetna schnell vor\u00fcber ging's,", "tokens": ["Am", "A\u00b7et\u00b7na", "schnell", "vor\u00b7\u00fc\u00b7ber", "ging's", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zwei sah ich um Schwefel streiten;", "tokens": ["Zwei", "sah", "ich", "um", "Schwe\u00b7fel", "strei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "VVFIN", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich schaute rechts, ich schaute links,", "tokens": ["Ich", "schau\u00b7te", "rechts", ",", "ich", "schau\u00b7te", "links", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es stank auf beiden Seiten.", "tokens": ["Es", "stank", "auf", "bei\u00b7den", "Sei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Als \u00fcber das blaue Meer ich zog,", "tokens": ["Als", "\u00fc\u00b7ber", "das", "blau\u00b7e", "Meer", "ich", "zog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da flaggten mir alle Schiffe,", "tokens": ["Da", "flagg\u00b7ten", "mir", "al\u00b7le", "Schif\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ihr Donner zum Ehrengru\u00df mir flog", "tokens": ["Ihr", "Don\u00b7ner", "zum", "Eh\u00b7ren\u00b7gru\u00df", "mir", "flog"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "PPER", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Weithin an Gestad' und Riffe.", "tokens": ["Weit\u00b7hin", "an", "Ge\u00b7stad'", "und", "Rif\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "In Syrien fand ich ein irres Heer,", "tokens": ["In", "Sy\u00b7ri\u00b7en", "fand", "ich", "ein", "ir\u00b7res", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Verhungernd, versprengt in der W\u00fcste;", "tokens": ["Ver\u00b7hun\u00b7gernd", ",", "ver\u00b7sprengt", "in", "der", "W\u00fcs\u00b7te", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Ich flog vor ihm durch des Sandes Meer", "tokens": ["Ich", "flog", "vor", "ihm", "durch", "des", "San\u00b7des", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Als F\u00fchrer zu Mizraims K\u00fcste.", "tokens": ["Als", "F\u00fch\u00b7rer", "zu", "Miz\u00b7ra\u00b7ims", "K\u00fcs\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NE", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.10": {"line.1": {"text": "Da lag der Feldherr todeskrank,", "tokens": ["Da", "lag", "der", "Feld\u00b7herr", "to\u00b7des\u00b7krank", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Ende mocht' es eilen;", "tokens": ["Zu", "En\u00b7de", "mocht'", "es", "ei\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des Vetters Ibis Kunst sei Dank,", "tokens": ["Des", "Vet\u00b7ters", "I\u00b7bis", "Kunst", "sei", "Dank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die mich gelehrt, ihn zu heilen.", "tokens": ["Die", "mich", "ge\u00b7lehrt", ",", "ihn", "zu", "hei\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.11": {"line.1": {"text": "Mit wei\u00dfem Bart der alte Pascha", "tokens": ["Mit", "wei\u00b7\u00dfem", "Bart", "der", "al\u00b7te", "Pa\u00b7scha"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Zum Gro\u00dffeldscher mich ernannte,", "tokens": ["Zum", "Gro\u00df\u00b7feld\u00b7scher", "mich", "er\u00b7nann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Gab mir zu Lehn das Nilland da", "tokens": ["Gab", "mir", "zu", "Lehn", "das", "Nil\u00b7land", "da"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "NN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und was drin kroch, schwamm, rannte.", "tokens": ["Und", "was", "drin", "kroch", ",", "schwamm", ",", "rann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.12": {"line.1": {"text": "Auf Pyramiden, bei f\u00fcrstlicher Kost,", "tokens": ["Auf", "Py\u00b7ra\u00b7mi\u00b7den", ",", "bei", "f\u00fcrst\u00b7li\u00b7cher", "Kost", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Durft' ich in Herrlichkeit thronen;", "tokens": ["Durft'", "ich", "in", "Herr\u00b7lich\u00b7keit", "thro\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Mir huldigten V\u00f6lker aus S\u00fcd und Ost,", "tokens": ["Mir", "hul\u00b7dig\u00b7ten", "V\u00f6l\u00b7ker", "aus", "S\u00fcd", "und", "Ost", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Wie G\u00f6ttern der Pharaonen.\u00ab", "tokens": ["Wie", "G\u00f6t\u00b7tern", "der", "Pha\u00b7ra\u00b7o\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NN", "ART", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Den Reisebericht indessen erkl\u00e4rt", "tokens": ["Den", "Rei\u00b7se\u00b7be\u00b7richt", "in\u00b7des\u00b7sen", "er\u00b7kl\u00e4rt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVPP"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Frau Storchin den Nachbarinnen:", "tokens": ["Frau", "Stor\u00b7chin", "den", "Nach\u00b7ba\u00b7rin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbam Nil hat er ein W\u00fcrmlein verzehrt,", "tokens": ["\u00bb", "am", "Nil", "hat", "er", "ein", "W\u00fcrm\u00b7lein", "ver\u00b7zehrt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Den Tiber \u2013 sah er rinnen.\u00ab", "tokens": ["Den", "Ti\u00b7ber", "\u2013", "sah", "er", "rin\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NE", "$(", "VVFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Das ist der vielgereiste Tourist", "tokens": ["Das", "ist", "der", "viel\u00b7ge\u00b7reis\u00b7te", "Tou\u00b7rist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Herr Storch, der heimgekehrte,", "tokens": ["Herr", "Storch", ",", "der", "heim\u00b7ge\u00b7kehr\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mit langen stolzen Schritten mi\u00dft", "tokens": ["Mit", "lan\u00b7gen", "stol\u00b7zen", "Schrit\u00b7ten", "mi\u00dft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Daches First der Werthe.", "tokens": ["Des", "Da\u00b7ches", "First", "der", "Wert\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Er tr\u00e4gt, wie's Wandrerart gebot,", "tokens": ["Er", "tr\u00e4gt", ",", "wie's", "Wand\u00b7re\u00b7rart", "ge\u00b7bot", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein wei\u00dfes Blousenhemde", "tokens": ["Ein", "wei\u00b7\u00dfes", "Blou\u00b7sen\u00b7hem\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nebst hohen Stiefeln von Juchten roth,", "tokens": ["Nebst", "ho\u00b7hen", "Stie\u00b7feln", "von", "Juch\u00b7ten", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und preist die sch\u00f6ne Fremde:", "tokens": ["Und", "preist", "die", "sch\u00f6\u00b7ne", "Frem\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "\u00bbda w\u00e4ren wir wieder, da wohnen wir", "tokens": ["\u00bb", "da", "w\u00e4\u00b7ren", "wir", "wie\u00b7der", ",", "da", "woh\u00b7nen", "wir"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ADV", "$,", "ADV", "VVFIN", "PPER"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Grad' \u00fcber dem Stall der Rinder.", "tokens": ["Grad'", "\u00fc\u00b7ber", "dem", "Stall", "der", "Rin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Prophet in der Heimat, bin ich hier", "tokens": ["Pro\u00b7phet", "in", "der", "Hei\u00b7mat", ",", "bin", "ich", "hier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "$,", "VAFIN", "PPER", "ADV"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Das Spiel der Bauernkinder.", "tokens": ["Das", "Spiel", "der", "Bau\u00b7ern\u00b7kin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "In Rom wohnt' ich auf dem Vatikan,", "tokens": ["In", "Rom", "wohnt'", "ich", "auf", "dem", "Va\u00b7ti\u00b7kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Sah wandeln den Papst im Garten,", "tokens": ["Sah", "wan\u00b7deln", "den", "Papst", "im", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da wuchsen, seht eure K\u00fcrbiss' an,", "tokens": ["Da", "wuch\u00b7sen", ",", "seht", "eu\u00b7re", "K\u00fcr\u00b7biss'", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So gro\u00df der Orangen Arten.", "tokens": ["So", "gro\u00df", "der", "O\u00b7ran\u00b7gen", "Ar\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.18": {"line.1": {"text": "Vom Rhein war b\u00f6se Post gerad',", "tokens": ["Vom", "Rhein", "war", "b\u00f6\u00b7se", "Post", "ge\u00b7rad'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "VAFIN", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Papst in Sinnen verloren;", "tokens": ["Der", "Papst", "in", "Sin\u00b7nen", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich gab ihm einen guten Rath,", "tokens": ["Ich", "gab", "ihm", "ei\u00b7nen", "gu\u00b7ten", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er mir den Orden vom Sporen.", "tokens": ["Er", "mir", "den", "Or\u00b7den", "vom", "Spo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Auch hatt' er drob mir keinen Verdru\u00df,", "tokens": ["Auch", "hatt'", "er", "drob", "mir", "kei\u00b7nen", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Als ich ihm in einem Sitze", "tokens": ["Als", "ich", "ihm", "in", "ei\u00b7nem", "Sit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vor Durst aussoff den Tiberflu\u00df,", "tokens": ["Vor", "Durst", "aus\u00b7soff", "den", "Ti\u00b7ber\u00b7flu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So gro\u00df ist dort die Hitze.", "tokens": ["So", "gro\u00df", "ist", "dort", "die", "Hit\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Am Aetna schnell vor\u00fcber ging's,", "tokens": ["Am", "A\u00b7et\u00b7na", "schnell", "vor\u00b7\u00fc\u00b7ber", "ging's", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zwei sah ich um Schwefel streiten;", "tokens": ["Zwei", "sah", "ich", "um", "Schwe\u00b7fel", "strei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "VVFIN", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich schaute rechts, ich schaute links,", "tokens": ["Ich", "schau\u00b7te", "rechts", ",", "ich", "schau\u00b7te", "links", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es stank auf beiden Seiten.", "tokens": ["Es", "stank", "auf", "bei\u00b7den", "Sei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Als \u00fcber das blaue Meer ich zog,", "tokens": ["Als", "\u00fc\u00b7ber", "das", "blau\u00b7e", "Meer", "ich", "zog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da flaggten mir alle Schiffe,", "tokens": ["Da", "flagg\u00b7ten", "mir", "al\u00b7le", "Schif\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ihr Donner zum Ehrengru\u00df mir flog", "tokens": ["Ihr", "Don\u00b7ner", "zum", "Eh\u00b7ren\u00b7gru\u00df", "mir", "flog"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "PPER", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Weithin an Gestad' und Riffe.", "tokens": ["Weit\u00b7hin", "an", "Ge\u00b7stad'", "und", "Rif\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "In Syrien fand ich ein irres Heer,", "tokens": ["In", "Sy\u00b7ri\u00b7en", "fand", "ich", "ein", "ir\u00b7res", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Verhungernd, versprengt in der W\u00fcste;", "tokens": ["Ver\u00b7hun\u00b7gernd", ",", "ver\u00b7sprengt", "in", "der", "W\u00fcs\u00b7te", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Ich flog vor ihm durch des Sandes Meer", "tokens": ["Ich", "flog", "vor", "ihm", "durch", "des", "San\u00b7des", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Als F\u00fchrer zu Mizraims K\u00fcste.", "tokens": ["Als", "F\u00fch\u00b7rer", "zu", "Miz\u00b7ra\u00b7ims", "K\u00fcs\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NE", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.23": {"line.1": {"text": "Da lag der Feldherr todeskrank,", "tokens": ["Da", "lag", "der", "Feld\u00b7herr", "to\u00b7des\u00b7krank", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Ende mocht' es eilen;", "tokens": ["Zu", "En\u00b7de", "mocht'", "es", "ei\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des Vetters Ibis Kunst sei Dank,", "tokens": ["Des", "Vet\u00b7ters", "I\u00b7bis", "Kunst", "sei", "Dank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die mich gelehrt, ihn zu heilen.", "tokens": ["Die", "mich", "ge\u00b7lehrt", ",", "ihn", "zu", "hei\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.24": {"line.1": {"text": "Mit wei\u00dfem Bart der alte Pascha", "tokens": ["Mit", "wei\u00b7\u00dfem", "Bart", "der", "al\u00b7te", "Pa\u00b7scha"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Zum Gro\u00dffeldscher mich ernannte,", "tokens": ["Zum", "Gro\u00df\u00b7feld\u00b7scher", "mich", "er\u00b7nann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Gab mir zu Lehn das Nilland da", "tokens": ["Gab", "mir", "zu", "Lehn", "das", "Nil\u00b7land", "da"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "NN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und was drin kroch, schwamm, rannte.", "tokens": ["Und", "was", "drin", "kroch", ",", "schwamm", ",", "rann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.25": {"line.1": {"text": "Auf Pyramiden, bei f\u00fcrstlicher Kost,", "tokens": ["Auf", "Py\u00b7ra\u00b7mi\u00b7den", ",", "bei", "f\u00fcrst\u00b7li\u00b7cher", "Kost", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Durft' ich in Herrlichkeit thronen;", "tokens": ["Durft'", "ich", "in", "Herr\u00b7lich\u00b7keit", "thro\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Mir huldigten V\u00f6lker aus S\u00fcd und Ost,", "tokens": ["Mir", "hul\u00b7dig\u00b7ten", "V\u00f6l\u00b7ker", "aus", "S\u00fcd", "und", "Ost", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Wie G\u00f6ttern der Pharaonen.\u00ab", "tokens": ["Wie", "G\u00f6t\u00b7tern", "der", "Pha\u00b7ra\u00b7o\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NN", "ART", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.26": {"line.1": {"text": "Den Reisebericht indessen erkl\u00e4rt", "tokens": ["Den", "Rei\u00b7se\u00b7be\u00b7richt", "in\u00b7des\u00b7sen", "er\u00b7kl\u00e4rt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVPP"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Frau Storchin den Nachbarinnen:", "tokens": ["Frau", "Stor\u00b7chin", "den", "Nach\u00b7ba\u00b7rin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbam Nil hat er ein W\u00fcrmlein verzehrt,", "tokens": ["\u00bb", "am", "Nil", "hat", "er", "ein", "W\u00fcrm\u00b7lein", "ver\u00b7zehrt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Den Tiber \u2013 sah er rinnen.\u00ab", "tokens": ["Den", "Ti\u00b7ber", "\u2013", "sah", "er", "rin\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NE", "$(", "VVFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}