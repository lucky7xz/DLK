{"dta.poem.5906": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Von den Elementen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1730", "urn": "urn:nbn:de:kobv:b4-20087-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Cartesius nun setzt, verbessert, und erfindet", "tokens": ["Car\u00b7te\u00b7sius", "nun", "setzt", ",", "ver\u00b7bes\u00b7sert", ",", "und", "er\u00b7fin\u00b7det"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "ADV", "VVFIN", "$,", "VVPP", "$,", "KON", "VVFIN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Jm gl\u00fccklichsten Entwurf von der Philosophie,", "tokens": ["Jm", "gl\u00fcck\u00b7lichs\u00b7ten", "Ent\u00b7wurf", "von", "der", "Phi\u00b7lo\u00b7so\u00b7phie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da er die Wahrheit selbst mit neuer Ordnung bindet,", "tokens": ["Da", "er", "die", "Wahr\u00b7heit", "selbst", "mit", "neu\u00b7er", "Ord\u00b7nung", "bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein Lehr-Geb\u00e4u, worinn man mit geringrer M\u00fch", "tokens": ["Ein", "Lehr\u00b7Ge\u00b7b\u00e4u", ",", "wo\u00b7rinn", "man", "mit", "ge\u00b7ring\u00b7rer", "M\u00fch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "PIS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mehr Sch\u00f6nheit, Deutlichkeit und Ordnung mercket;", "tokens": ["Mehr", "Sch\u00f6n\u00b7heit", ",", "Deut\u00b7lich\u00b7keit", "und", "Ord\u00b7nung", "mer\u00b7cket", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df es die Lehr-Art selbst erleichtert und best\u00e4rcket.", "tokens": ["Da\u00df", "es", "die", "Lehr\u00b7Art", "selbst", "er\u00b7leich\u00b7tert", "und", "be\u00b7st\u00e4r\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Zu Anfangs setzet er: Es dehne sich und breite,", "tokens": ["Zu", "An\u00b7fangs", "set\u00b7zet", "er", ":", "Es", "deh\u00b7ne", "sich", "und", "brei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "PRF", "KON", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ohn einz\u2019ges Leer, das ", "tokens": ["Ohn", "einz'\u00b7ges", "Leer", ",", "das"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "An allen Orten aus. Hier seh\u2019", "tokens": ["An", "al\u00b7len", "Or\u00b7ten", "aus", ".", "Hier", "seh'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "$.", "ADV", "VVFIN"], "meter": "-+-+--++", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und merck ich die Materie,", "tokens": ["Und", "merck", "ich", "die", "Ma\u00b7te\u00b7rie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Die ungeformt, vereint, in allen Theilen gleich,", "tokens": ["Die", "un\u00b7ge\u00b7formt", ",", "ver\u00b7eint", ",", "in", "al\u00b7len", "Thei\u00b7len", "gleich", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "VVPP", "$,", "APPR", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Was ausgedehnetes, das ohn Beschaffenheit.", "tokens": ["Was", "aus\u00b7ge\u00b7deh\u00b7ne\u00b7tes", ",", "das", "ohn", "Be\u00b7schaf\u00b7fen\u00b7heit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "$,", "PRELS", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Er giebet Jhr annoch kein\u2019 Eigenschafft von Gluht,", "tokens": ["Er", "gie\u00b7bet", "Ihr", "an\u00b7noch", "kein'", "Ei\u00b7gen\u00b7schafft", "von", "Gluht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "Von Erde, Lufft und Fluht:", "tokens": ["Von", "Er\u00b7de", ",", "Lufft", "und", "Fluht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Er setzet noch nicht gleich in Wiedrigkeit und Streit", "tokens": ["Er", "set\u00b7zet", "noch", "nicht", "gleich", "in", "Wied\u00b7rig\u00b7keit", "und", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die Weichheit mit der H\u00e4rtigkeit,", "tokens": ["Die", "Weich\u00b7heit", "mit", "der", "H\u00e4r\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Die Hitze mit dem Frost, Na\u00df mit der Trockenheit.", "tokens": ["Die", "Hit\u00b7ze", "mit", "dem", "Frost", ",", "Na\u00df", "mit", "der", "Tro\u00b7cken\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Es ist des Naso Chaos nicht.", "tokens": ["Es", "ist", "des", "Na\u00b7so", "Chaos", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NE", "PTKNEG", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Er giebet uns blo\u00df diesen Unterricht,", "tokens": ["Er", "gie\u00b7bet", "uns", "blo\u00df", "die\u00b7sen", "Un\u00b7ter\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und macht uns anders nichts davon bekannt,", "tokens": ["Und", "macht", "uns", "an\u00b7ders", "nichts", "da\u00b7von", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PIS", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Als da\u00df es etwas sey, so ausgespannt,", "tokens": ["Als", "da\u00df", "es", "et\u00b7was", "sey", ",", "so", "aus\u00b7ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "VAFIN", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Das allenthalben gleich und fest,", "tokens": ["Das", "al\u00b7len\u00b7thal\u00b7ben", "gleich", "und", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Das sich bewegen kan, und das sich biegen l\u00e4sst.", "tokens": ["Das", "sich", "be\u00b7we\u00b7gen", "kan", ",", "und", "das", "sich", "bie\u00b7gen", "l\u00e4sst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "VVINF", "VMFIN", "$,", "KON", "PRELS", "PRF", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}