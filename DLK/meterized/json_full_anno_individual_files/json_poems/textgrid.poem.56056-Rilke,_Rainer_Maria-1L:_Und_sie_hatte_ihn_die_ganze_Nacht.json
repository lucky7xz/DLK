{"textgrid.poem.56056": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "1L: Und sie hatte ihn die ganze Nacht", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und sie hatte ihn die ganze Nacht", "tokens": ["Und", "sie", "hat\u00b7te", "ihn", "die", "gan\u00b7ze", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "angerufen, hingekniet, die schwache", "tokens": ["an\u00b7ge\u00b7ru\u00b7fen", ",", "hin\u00b7ge\u00b7kniet", ",", "die", "schwa\u00b7che"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["VVPP", "$,", "VVFIN", "$,", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "wache Jungfrau: Siehe, dieser Drache,", "tokens": ["wa\u00b7che", "Jung\u00b7frau", ":", "Sie\u00b7he", ",", "die\u00b7ser", "Dra\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "VVIMP", "$,", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "und ich wei\u00df es nicht, warum er wacht.", "tokens": ["und", "ich", "wei\u00df", "es", "nicht", ",", "wa\u00b7rum", "er", "wacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Und da brach er aus dem Morgengraun", "tokens": ["Und", "da", "brach", "er", "aus", "dem", "Mor\u00b7gen\u00b7graun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "auf dem Falben, strahlend Helm und Haubert,", "tokens": ["auf", "dem", "Fal\u00b7ben", ",", "strah\u00b7lend", "Helm", "und", "Hau\u00b7bert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "und er sah sie, traurig und verzaubert", "tokens": ["und", "er", "sah", "sie", ",", "trau\u00b7rig", "und", "ver\u00b7zau\u00b7bert"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "ADJD", "KON", "VVFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "aus dem Knieen aufw\u00e4rtsschaun", "tokens": ["aus", "dem", "Kni\u00b7e\u00b7en", "auf\u00b7w\u00e4rts\u00b7schaun"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.3": {"line.1": {"text": "zu dem Glanze, der er war.", "tokens": ["zu", "dem", "Glan\u00b7ze", ",", "der", "er", "war", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und er sprengte gl\u00e4nzend l\u00e4ngs der L\u00e4nder", "tokens": ["Und", "er", "spreng\u00b7te", "gl\u00e4n\u00b7zend", "l\u00e4ngs", "der", "L\u00e4n\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "abw\u00e4rts mit erhobnem Doppelh\u00e4nder", "tokens": ["ab\u00b7w\u00e4rts", "mit", "er\u00b7hob\u00b7nem", "Dop\u00b7pel\u00b7h\u00e4n\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "in die offene Gefahr,", "tokens": ["in", "die", "of\u00b7fe\u00b7ne", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+---+", "measure": "unknown.measure.tri"}}, "stanza.4": {"line.1": {"text": "viel zu furchtbar, aber doch erfleht.", "tokens": ["viel", "zu", "furcht\u00b7bar", ",", "a\u00b7ber", "doch", "er\u00b7fleht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "$,", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und sie kniete knieender, die H\u00e4nde", "tokens": ["Und", "sie", "knie\u00b7te", "kni\u00b7e\u00b7en\u00b7der", ",", "die", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "$,", "ART", "NN"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "fester faltend, da\u00df er sie best\u00e4nde;", "tokens": ["fes\u00b7ter", "fal\u00b7tend", ",", "da\u00df", "er", "sie", "be\u00b7st\u00e4n\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "denn sie wu\u00dfte nicht, da\u00df Der besteht,", "tokens": ["denn", "sie", "wu\u00df\u00b7te", "nicht", ",", "da\u00df", "Der", "be\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "den ihr Herz, ihr reines und bereites,", "tokens": ["den", "ihr", "Herz", ",", "ihr", "rei\u00b7nes", "und", "be\u00b7rei\u00b7tes", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "KON", "ADJA", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "aus dem Licht des g\u00f6ttlichen Geleites", "tokens": ["aus", "dem", "Licht", "des", "g\u00f6tt\u00b7li\u00b7chen", "Ge\u00b7lei\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "niederrei\u00dft. Zuseiten seines Streites", "tokens": ["nie\u00b7der\u00b7rei\u00dft", ".", "Zu\u00b7sei\u00b7ten", "sei\u00b7nes", "Strei\u00b7tes"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$.", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "stand, wie T\u00fcrme stehen, ihr Gebet.", "tokens": ["stand", ",", "wie", "T\u00fcr\u00b7me", "ste\u00b7hen", ",", "ihr", "Ge\u00b7bet", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "NN", "VVFIN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Und sie hatte ihn die ganze Nacht", "tokens": ["Und", "sie", "hat\u00b7te", "ihn", "die", "gan\u00b7ze", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "angerufen, hingekniet, die schwache", "tokens": ["an\u00b7ge\u00b7ru\u00b7fen", ",", "hin\u00b7ge\u00b7kniet", ",", "die", "schwa\u00b7che"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["VVPP", "$,", "VVFIN", "$,", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "wache Jungfrau: Siehe, dieser Drache,", "tokens": ["wa\u00b7che", "Jung\u00b7frau", ":", "Sie\u00b7he", ",", "die\u00b7ser", "Dra\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "VVIMP", "$,", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "und ich wei\u00df es nicht, warum er wacht.", "tokens": ["und", "ich", "wei\u00df", "es", "nicht", ",", "wa\u00b7rum", "er", "wacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Und da brach er aus dem Morgengraun", "tokens": ["Und", "da", "brach", "er", "aus", "dem", "Mor\u00b7gen\u00b7graun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "auf dem Falben, strahlend Helm und Haubert,", "tokens": ["auf", "dem", "Fal\u00b7ben", ",", "strah\u00b7lend", "Helm", "und", "Hau\u00b7bert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "und er sah sie, traurig und verzaubert", "tokens": ["und", "er", "sah", "sie", ",", "trau\u00b7rig", "und", "ver\u00b7zau\u00b7bert"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "ADJD", "KON", "VVFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "aus dem Knieen aufw\u00e4rtsschaun", "tokens": ["aus", "dem", "Kni\u00b7e\u00b7en", "auf\u00b7w\u00e4rts\u00b7schaun"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.8": {"line.1": {"text": "zu dem Glanze, der er war.", "tokens": ["zu", "dem", "Glan\u00b7ze", ",", "der", "er", "war", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und er sprengte gl\u00e4nzend l\u00e4ngs der L\u00e4nder", "tokens": ["Und", "er", "spreng\u00b7te", "gl\u00e4n\u00b7zend", "l\u00e4ngs", "der", "L\u00e4n\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "abw\u00e4rts mit erhobnem Doppelh\u00e4nder", "tokens": ["ab\u00b7w\u00e4rts", "mit", "er\u00b7hob\u00b7nem", "Dop\u00b7pel\u00b7h\u00e4n\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "in die offene Gefahr,", "tokens": ["in", "die", "of\u00b7fe\u00b7ne", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+---+", "measure": "unknown.measure.tri"}}, "stanza.9": {"line.1": {"text": "viel zu furchtbar, aber doch erfleht.", "tokens": ["viel", "zu", "furcht\u00b7bar", ",", "a\u00b7ber", "doch", "er\u00b7fleht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "$,", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und sie kniete knieender, die H\u00e4nde", "tokens": ["Und", "sie", "knie\u00b7te", "kni\u00b7e\u00b7en\u00b7der", ",", "die", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "$,", "ART", "NN"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "fester faltend, da\u00df er sie best\u00e4nde;", "tokens": ["fes\u00b7ter", "fal\u00b7tend", ",", "da\u00df", "er", "sie", "be\u00b7st\u00e4n\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "denn sie wu\u00dfte nicht, da\u00df Der besteht,", "tokens": ["denn", "sie", "wu\u00df\u00b7te", "nicht", ",", "da\u00df", "Der", "be\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "den ihr Herz, ihr reines und bereites,", "tokens": ["den", "ihr", "Herz", ",", "ihr", "rei\u00b7nes", "und", "be\u00b7rei\u00b7tes", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "KON", "ADJA", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "aus dem Licht des g\u00f6ttlichen Geleites", "tokens": ["aus", "dem", "Licht", "des", "g\u00f6tt\u00b7li\u00b7chen", "Ge\u00b7lei\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "niederrei\u00dft. Zuseiten seines Streites", "tokens": ["nie\u00b7der\u00b7rei\u00dft", ".", "Zu\u00b7sei\u00b7ten", "sei\u00b7nes", "Strei\u00b7tes"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$.", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "stand, wie T\u00fcrme stehen, ihr Gebet.", "tokens": ["stand", ",", "wie", "T\u00fcr\u00b7me", "ste\u00b7hen", ",", "ihr", "Ge\u00b7bet", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "NN", "VVFIN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}}}}