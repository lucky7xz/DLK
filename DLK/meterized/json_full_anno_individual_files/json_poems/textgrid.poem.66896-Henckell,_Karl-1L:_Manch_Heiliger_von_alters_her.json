{"textgrid.poem.66896": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "1L: Manch Heiliger von alters her", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Manch Heiliger von alters her", "tokens": ["Manch", "Hei\u00b7li\u00b7ger", "von", "al\u00b7ters", "her"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ADV", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stand bei der Menschheit hoch in Ehr.", "tokens": ["Stand", "bei", "der", "Menschheit", "hoch", "in", "Ehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Der eine, weil er Kranke heilte,", "tokens": ["Der", "ei\u00b7ne", ",", "weil", "er", "Kran\u00b7ke", "heil\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der andre, weil er Heiden keilte", "tokens": ["Der", "and\u00b7re", ",", "weil", "er", "Hei\u00b7den", "keil\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "$,", "KOUS", "PPER", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr die katholische Verbindung,", "tokens": ["F\u00fcr", "die", "ka\u00b7tho\u00b7li\u00b7sche", "Ver\u00b7bin\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der dritte wegen Mitempfindung", "tokens": ["Der", "drit\u00b7te", "we\u00b7gen", "Mi\u00b7temp\u00b7fin\u00b7dung"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "F\u00fcr alle V\u00f6gel auf dem Feld,", "tokens": ["F\u00fcr", "al\u00b7le", "V\u00f6\u00b7gel", "auf", "dem", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und sogenannte \u00e4u\u00dfre G\u00fcter,", "tokens": ["Und", "so\u00b7ge\u00b7nann\u00b7te", "\u00e4u\u00df\u00b7re", "G\u00fc\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.2": {"line.1": {"text": "Der Heilige, den ich erk\u00fcre,", "tokens": ["Der", "Hei\u00b7li\u00b7ge", ",", "den", "ich", "er\u00b7k\u00fc\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat g\u00e4nzlich andere All\u00fcre,", "tokens": ["Hat", "g\u00e4nz\u00b7lich", "an\u00b7de\u00b7re", "Al\u00b7l\u00fc\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er ist aus einem Material", "tokens": ["Er", "ist", "aus", "ei\u00b7nem", "Ma\u00b7te\u00b7ri\u00b7al"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "So schleierhaft wie schenial,", "tokens": ["So", "schlei\u00b7er\u00b7haft", "wie", "sche\u00b7ni\u00b7al", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn er besteht nur aus der Sohle", "tokens": ["Denn", "er", "be\u00b7steht", "nur", "aus", "der", "Soh\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und sonst aus nichts als Aureole.", "tokens": ["Und", "sonst", "aus", "nichts", "als", "Au\u00b7re\u00b7o\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIS", "KOKOM", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Sohle freilich macht daf\u00fcr", "tokens": ["Die", "Soh\u00b7le", "frei\u00b7lich", "macht", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So gro\u00df wie eine Kirchent\u00fcr,", "tokens": ["So", "gro\u00df", "wie", "ei\u00b7ne", "Kir\u00b7chen\u00b7t\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und tritt der Heilige herein,", "tokens": ["Und", "tritt", "der", "Hei\u00b7li\u00b7ge", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "M\u00f6cht' alles gleich: \u00bbDer Herrgott!\u00ab schrein.", "tokens": ["M\u00f6cht'", "al\u00b7les", "gleich", ":", "\u00bb", "Der", "Herr\u00b7gott", "!", "\u00ab", "schrein", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "$.", "$(", "ART", "NN", "$.", "$(", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wo das Gespr\u00e4ch in vollem Brausen,", "tokens": ["Wo", "das", "Ge\u00b7spr\u00e4ch", "in", "vol\u00b7lem", "Brau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Entsteht die tiefste aller Pausen,", "tokens": ["Ent\u00b7steht", "die", "tiefs\u00b7te", "al\u00b7ler", "Pau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Man f\u00e4llt vor Ehrfurcht von dem Platz \u2013", "tokens": ["Man", "f\u00e4llt", "vor", "Ehr\u00b7furcht", "von", "dem", "Platz", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Das macht der hohe Untersatz.", "tokens": ["Das", "macht", "der", "ho\u00b7he", "Un\u00b7ter\u00b7satz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Die Sohle ist ein hohles Ding,", "tokens": ["Die", "Soh\u00b7le", "ist", "ein", "hoh\u00b7les", "Ding", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Kautschuk mit Luft wie 'n Rettungsring,", "tokens": ["Kaut\u00b7schuk", "mit", "Luft", "wie", "'n", "Ret\u00b7tungs\u00b7ring", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KOKOM", "ART", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.17": {"text": "Doch eine Schelle pingpingping", "tokens": ["Doch", "ei\u00b7ne", "Schel\u00b7le", "ping\u00b7ping\u00b7ping"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Bet\u00f6rt selbst einen Sonderling,", "tokens": ["Be\u00b7t\u00f6rt", "selbst", "ei\u00b7nen", "Son\u00b7der\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Der sonst sich schwer l\u00e4\u00dft imponieren", "tokens": ["Der", "sonst", "sich", "schwer", "l\u00e4\u00dft", "im\u00b7po\u00b7nie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PRF", "ADJD", "VVFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Von annoncierten gro\u00dfen Tieren.", "tokens": ["Von", "an\u00b7non\u00b7cier\u00b7ten", "gro\u00b7\u00dfen", "Tie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Doch nach dem unteren Symbole", "tokens": ["Doch", "nach", "dem", "un\u00b7te\u00b7ren", "Sym\u00b7bo\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Wirkt erst die obre Aureole", "tokens": ["Wirkt", "erst", "die", "ob\u00b7re", "Au\u00b7re\u00b7o\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Ganz unbeschreiblich mit dem Kranz", "tokens": ["Ganz", "un\u00b7be\u00b7schreib\u00b7lich", "mit", "dem", "Kranz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Von Flimmerflammerflummerglanz.", "tokens": ["Von", "Flim\u00b7mer\u00b7flam\u00b7mer\u00b7flum\u00b7mer\u00b7glanz", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Da dreht sich statt dem Oberleibe", "tokens": ["Da", "dreht", "sich", "statt", "dem", "O\u00b7berl\u00b7ei\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Nur eine Riesenblendescheibe,", "tokens": ["Nur", "ei\u00b7ne", "Rie\u00b7sen\u00b7blen\u00b7de\u00b7schei\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Davor die Sonne sich verbirgt", "tokens": ["Da\u00b7vor", "die", "Son\u00b7ne", "sich", "ver\u00b7birgt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "PRF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Und ihre Scham herunterw\u00fcrgt.", "tokens": ["Und", "ih\u00b7re", "Scham", "her\u00b7un\u00b7ter\u00b7w\u00fcrgt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Und solcher \u00dcbersonnenschimmer", "tokens": ["Und", "sol\u00b7cher", "\u00dc\u00b7ber\u00b7son\u00b7nen\u00b7schim\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Kommt nur von Talmiglas und -Glimmer,", "tokens": ["Kommt", "nur", "von", "Tal\u00b7mi\u00b7glas", "und", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Dahinter sich wie ein Prolet", "tokens": ["Da\u00b7hin\u00b7ter", "sich", "wie", "ein", "Pro\u00b7let"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PRF", "KOKOM", "ART", "NN"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.32": {"text": "Ein ganz gemeines Talglicht dreht.", "tokens": ["Ein", "ganz", "ge\u00b7mei\u00b7nes", "Talg\u00b7licht", "dreht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wo nun der Heilige erscheint,", "tokens": ["Wo", "nun", "der", "Hei\u00b7li\u00b7ge", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da ist man nahezu versteint.", "tokens": ["Da", "ist", "man", "na\u00b7he\u00b7zu", "ver\u00b7steint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer sonst die Nase hochgetragen,", "tokens": ["Wer", "sonst", "die", "Na\u00b7se", "hoch\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wagt kaum die Augen aufzuschlagen,", "tokens": ["Wagt", "kaum", "die", "Au\u00b7gen", "auf\u00b7zu\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und wer sonst kein verlegner Lurch,", "tokens": ["Und", "wer", "sonst", "kein", "ver\u00b7leg\u00b7ner", "Lurch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der ist vertattert durch und durch.", "tokens": ["Der", "ist", "ver\u00b7tat\u00b7tert", "durch", "und", "durch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "APPR", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Kniee knicken, da\u00df es knackt,", "tokens": ["Die", "Kni\u00b7ee", "kni\u00b7cken", ",", "da\u00df", "es", "knackt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die Wirbel biegen sich im Takt,", "tokens": ["Die", "Wir\u00b7bel", "bie\u00b7gen", "sich", "im", "Takt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und auf dem Gipfelpunkt des Glanzes", "tokens": ["Und", "auf", "dem", "Gip\u00b7fel\u00b7punkt", "des", "Glan\u00b7zes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Beginnt nach Art des Eiertanzes", "tokens": ["Be\u00b7ginnt", "nach", "Art", "des", "Ei\u00b7er\u00b7tan\u00b7zes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Ein wunderlicher Ehrenstu\u00df \u2013", "tokens": ["Ein", "wun\u00b7der\u00b7li\u00b7cher", "Eh\u00b7ren\u00b7stu\u00df", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Der Kotau macht sodann den Schlu\u00df.", "tokens": ["Der", "Ko\u00b7tau", "macht", "so\u00b7dann", "den", "Schlu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wer diesen Heiligen nun ben\u00fctzt,", "tokens": ["Wer", "die\u00b7sen", "Hei\u00b7li\u00b7gen", "nun", "be\u00b7n\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da\u00df er besonders ihn besch\u00fctzt,", "tokens": ["Da\u00df", "er", "be\u00b7son\u00b7ders", "ihn", "be\u00b7sch\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der l\u00e4\u00dft um sich die Welt sich drehen,", "tokens": ["Der", "l\u00e4\u00dft", "um", "sich", "die", "Welt", "sich", "dre\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PRF", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil alle nach dem Heiligen sehen,", "tokens": ["Weil", "al\u00b7le", "nach", "dem", "Hei\u00b7li\u00b7gen", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Der als ein magisch Transparent", "tokens": ["Der", "als", "ein", "ma\u00b7gisch", "Trans\u00b7pa\u00b7rent"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "KOUS", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor seinem Schutzbefohlnen brennt.", "tokens": ["Vor", "sei\u00b7nem", "Schutz\u00b7be\u00b7fohl\u00b7nen", "brennt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vom Hausknecht an bis zu den Spitzen", "tokens": ["Vom", "Haus\u00b7knecht", "an", "bis", "zu", "den", "Spit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "F\u00e4ngt's an vor Hochachtung zu spritzen,", "tokens": ["F\u00e4ngt's", "an", "vor", "Hoch\u00b7ach\u00b7tung", "zu", "sprit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.9": {"text": "Man glotzt geblendet auf das Licht", "tokens": ["Man", "glotzt", "ge\u00b7blen\u00b7det", "auf", "das", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und sieht den \u2013 Talg vor Nimbus nicht.", "tokens": ["Und", "sieht", "den", "\u2013", "Talg", "vor", "Nim\u00b7bus", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "$(", "NN", "APPR", "NE", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Sankt ", "tokens": ["Sankt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Des Heiligen von Notreklame,", "tokens": ["Des", "Hei\u00b7li\u00b7gen", "von", "Not\u00b7re\u00b7kla\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das in den b\u00f6hmischen W\u00e4ldern liegt,", "tokens": ["Das", "in", "den", "b\u00f6h\u00b7mi\u00b7schen", "W\u00e4l\u00b7dern", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wo man es nie zu sehen kriegt.", "tokens": ["Wo", "man", "es", "nie", "zu", "se\u00b7hen", "kriegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer mit ihm auftritt, mag geboren", "tokens": ["Wer", "mit", "ihm", "auf\u00b7tritt", ",", "mag", "ge\u00b7bo\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "APPR", "PPER", "VVFIN", "$,", "VMFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als Schuster sein, er ist erkoren,", "tokens": ["Als", "Schus\u00b7ter", "sein", ",", "er", "ist", "er\u00b7ko\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAINF", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df jede Festung sich ergibt,", "tokens": ["Da\u00df", "je\u00b7de", "Fes\u00b7tung", "sich", "er\u00b7gibt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In die er seine Plempe schiebt.", "tokens": ["In", "die", "er", "sei\u00b7ne", "Plem\u00b7pe", "schiebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ist er ein Ludewig der Gosse,", "tokens": ["Ist", "er", "ein", "Lu\u00b7de\u00b7wig", "der", "Gos\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Er wird vermittelst Rudolf Mosse,", "tokens": ["Er", "wird", "ver\u00b7mit\u00b7telst", "Ru\u00b7dolf", "Mos\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Vielleicht auch Haasenstein und Vogler,", "tokens": ["Viel\u00b7leicht", "auch", "Haa\u00b7sen\u00b7stein", "und", "Vog\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Zun\u00e4chst ein s\u00fc\u00dfer, frecher Mogler,", "tokens": ["Zu\u00b7n\u00e4chst", "ein", "s\u00fc\u00b7\u00dfer", ",", "fre\u00b7cher", "Mog\u00b7ler", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Denn unser Heiliger bringt Heil", "tokens": ["Denn", "un\u00b7ser", "Hei\u00b7li\u00b7ger", "bringt", "Heil"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Auch durch den Inseratenteil.", "tokens": ["Auch", "durch", "den", "In\u00b7se\u00b7ra\u00b7ten\u00b7teil", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Dann thront er bald im \u00bbGrand Hotelle\u00ab", "tokens": ["Dann", "thront", "er", "bald", "im", "\u00bb", "Grand", "Ho\u00b7tel\u00b7le", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "$(", "NN", "NN", "$("], "meter": "-+-+-++--", "measure": "unknown.measure.tetra"}, "line.16": {"text": "Beim \u00bbSouper\u00ab an der ersten Stelle,", "tokens": ["Beim", "\u00bb", "Sou\u00b7per", "\u00ab", "an", "der", "ers\u00b7ten", "Stel\u00b7le", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "$(", "NN", "$(", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "S\u00e4mtliche Schneider sind verr\u00fcckt,", "tokens": ["S\u00e4mt\u00b7li\u00b7che", "Schnei\u00b7der", "sind", "ver\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.18": {"text": "Bald ist's beim Marschall ihm gegl\u00fcckt", "tokens": ["Bald", "ist's", "beim", "Mar\u00b7schall", "ihm", "ge\u00b7gl\u00fcckt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Just durch die fixste Kammerzofe,", "tokens": ["Just", "durch", "die", "fixs\u00b7te", "Kam\u00b7mer\u00b7zo\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Und schlie\u00dflich h\u00e4lt er \u2013 an \u2013 zu \u2013 Hofe.", "tokens": ["Und", "schlie\u00df\u00b7lich", "h\u00e4lt", "er", "\u2013", "an", "\u2013", "zu", "\u2013", "Ho\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "$(", "APPR", "$(", "PTKZU", "$(", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch von dem ordin\u00e4ren Lucki", "tokens": ["Doch", "von", "dem", "or\u00b7di\u00b7n\u00e4\u00b7ren", "Lu\u00b7cki"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Ganz abgesehn, der Doljorucki", "tokens": ["Ganz", "ab\u00b7ge\u00b7sehn", ",", "der", "Dol\u00b7jo\u00b7ruc\u00b7ki"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "VVPP", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und F\u00fcrst Kanaljewitsch sich nennt \u2013", "tokens": ["Und", "F\u00fcrst", "Ka\u00b7nal\u00b7je\u00b7witsch", "sich", "nennt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Heilige mit Transparent", "tokens": ["Der", "Hei\u00b7li\u00b7ge", "mit", "Trans\u00b7pa\u00b7rent"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Macht selbst ganz unbescholtne M\u00e4nner", "tokens": ["Macht", "selbst", "ganz", "un\u00b7be\u00b7scholt\u00b7ne", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu einer Sensation f\u00fcr Kenner.", "tokens": ["Zu", "ei\u00b7ner", "Sen\u00b7sa\u00b7ti\u00b7on", "f\u00fcr", "Ken\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Dem \u00bbim Detail\u00ab noch nachzusp\u00fcren,", "tokens": ["Dem", "\u00bb", "im", "De\u00b7tail", "\u00ab", "noch", "nach\u00b7zu\u00b7sp\u00fc\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "$(", "APPRART", "NN", "$(", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das w\u00fcrde hier \u00bbzu weit mich f\u00fchren\u00ab,", "tokens": ["Das", "w\u00fcr\u00b7de", "hier", "\u00bb", "zu", "weit", "mich", "f\u00fch\u00b7ren", "\u00ab", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ADV", "$(", "PTKA", "ADJD", "PPER", "VVINF", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die Kunst ist kurz, die Elle lang,", "tokens": ["Die", "Kunst", "ist", "kurz", ",", "die", "El\u00b7le", "lang", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wer zuviel schreibt, kriegt Blutandrang.", "tokens": ["Wer", "zu\u00b7viel", "schreibt", ",", "kriegt", "Blu\u00b7tan\u00b7drang", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "$,", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Genug \u2013 man darf Herr Schulze hei\u00dfen,", "tokens": ["Ge\u00b7nug", "\u2013", "man", "darf", "Herr", "Schul\u00b7ze", "hei\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "PIS", "VMFIN", "NN", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Hat Nimbus er, kann er drauf \u2013 pfeifen", "tokens": ["Hat", "Nim\u00b7bus", "er", ",", "kann", "er", "drauf", "\u2013", "pfei\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "NE", "PPER", "$,", "VMFIN", "PPER", "PAV", "$(", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "Und wird, wenn es Sankt N. gef\u00e4llt,", "tokens": ["Und", "wird", ",", "wenn", "es", "Sankt", "N.", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "abbreviation", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "KOUS", "PPER", "VVFIN", "NE", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Rasch Aufsichtsrat der ganzen Welt.", "tokens": ["Rasch", "Auf\u00b7sichts\u00b7rat", "der", "gan\u00b7zen", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Hast einen Zirkus du von Fl\u00f6hen,", "tokens": ["Hast", "ei\u00b7nen", "Zir\u00b7kus", "du", "von", "Fl\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "La\u00df dich nur omin\u00f6s \u00bberh\u00f6hen\u00ab,", "tokens": ["La\u00df", "dich", "nur", "o\u00b7mi\u00b7n\u00f6s", "\u00bb", "er\u00b7h\u00f6\u00b7hen", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADJD", "$(", "VVINF", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und bald ziehst du an einem Haar", "tokens": ["Und", "bald", "ziehst", "du", "an", "ei\u00b7nem", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.18": {"text": "Die hohe Professorenschar", "tokens": ["Die", "ho\u00b7he", "Pro\u00b7fes\u00b7so\u00b7ren\u00b7schar"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Mitsamt den Frauen und den T\u00f6chten,", "tokens": ["Mit\u00b7samt", "den", "Frau\u00b7en", "und", "den", "T\u00f6ch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Die sich dressieren lassen m\u00f6chten.", "tokens": ["Die", "sich", "dres\u00b7sie\u00b7ren", "las\u00b7sen", "m\u00f6ch\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVINF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Bist du ein Schornalist, so nimm", "tokens": ["Bist", "du", "ein", "Schor\u00b7na\u00b7list", ",", "so", "nimm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "ADV", "VVIMP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Den Majestatikus und schwimm", "tokens": ["Den", "Ma\u00b7jes\u00b7ta\u00b7ti\u00b7kus", "und", "schwimm"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Im Glanz der \u00f6ffentlichen Meinung \u2013", "tokens": ["Im", "Glanz", "der", "\u00f6f\u00b7fent\u00b7li\u00b7chen", "Mei\u00b7nung", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Gen Himmel w\u00e4chst die Schmockerscheinung.", "tokens": ["Gen", "Him\u00b7mel", "w\u00e4chst", "die", "Schmo\u00b7cker\u00b7schei\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Ein sogenannter Dichter aber,", "tokens": ["Ein", "so\u00b7ge\u00b7nann\u00b7ter", "Dich\u00b7ter", "a\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.26": {"text": "Als welchen sticht des Ruhmes Haber,", "tokens": ["Als", "wel\u00b7chen", "sticht", "des", "Ruh\u00b7mes", "Ha\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAT", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Er lasse bei dem Heiligen sich", "tokens": ["Er", "las\u00b7se", "bei", "dem", "Hei\u00b7li\u00b7gen", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PRF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Versichern prompt. Hat er den Strich,", "tokens": ["Ver\u00b7si\u00b7chern", "prompt", ".", "Hat", "er", "den", "Strich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.29": {"text": "Dann um ", "tokens": ["Dann", "um"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.30": {"text": "Der Nimbus macht den Dichtersmann.", "tokens": ["Der", "Nim\u00b7bus", "macht", "den", "Dich\u00b7ters\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Enorm wirkt hier die hohe Sohle", "tokens": ["En\u00b7orm", "wirkt", "hier", "die", "ho\u00b7he", "Soh\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Der allerdunkelsten Symbole,", "tokens": ["Der", "al\u00b7ler\u00b7dun\u00b7kels\u00b7ten", "Sym\u00b7bo\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.33": {"text": "Gemischt aus Schall und blauem Dunst,", "tokens": ["Ge\u00b7mischt", "aus", "Schall", "und", "blau\u00b7em", "Dunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Apartem Brei, besondrer Brunst.", "tokens": ["A\u00b7par\u00b7tem", "Brei", ",", "be\u00b7sond\u00b7rer", "Brunst", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Der Nimbus adelt einen blo\u00dfen", "tokens": ["Der", "Nim\u00b7bus", "a\u00b7delt", "ei\u00b7nen", "blo\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Nonsensplusultra gleich zum gro\u00dfen", "tokens": ["Non\u00b7sen\u00b7splu\u00b7sul\u00b7tra", "gleich", "zum", "gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADV", "APPRART", "ADJA"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.37": {"text": "Gedanken \u2013 \u00bbTiefsinn!\u00ab raunt der Snob,", "tokens": ["Ge\u00b7dan\u00b7ken", "\u2013", "\u00bb", "Tief\u00b7sinn", "!", "\u00ab", "raunt", "der", "Snob", ","], "token_info": ["word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "$(", "NN", "$.", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Und hurrehurrehopphopphopp", "tokens": ["Und", "hur\u00b7re\u00b7hur\u00b7re\u00b7hop\u00b7phop\u00b7phopp"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Schreit das Ger\u00fccht den seltnen Kleister", "tokens": ["Schreit", "das", "Ge\u00b7r\u00fccht", "den", "selt\u00b7nen", "Kleis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.40": {"text": "Zum Kunstwerk aus, den Matz zum Meister.", "tokens": ["Zum", "Kunst\u00b7werk", "aus", ",", "den", "Matz", "zum", "Meis\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$,", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "So geht der Heilige Nimbus um,", "tokens": ["So", "geht", "der", "Hei\u00b7li\u00b7ge", "Nim\u00b7bus", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er kennt, er kennt sein Publikum.", "tokens": ["Er", "kennt", ",", "er", "kennt", "sein", "Pub\u00b7li\u00b7kum", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er ist \u2013 samt Sohle, Schein und Schelle \u2013", "tokens": ["Er", "ist", "\u2013", "samt", "Soh\u00b7le", ",", "Schein", "und", "Schel\u00b7le", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "APPR", "NN", "$,", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von Haus aus Tapeziergeselle", "tokens": ["Von", "Haus", "aus", "Ta\u00b7pe\u00b7zier\u00b7ge\u00b7sel\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und hat \u2013 das sei ihm nicht verdacht! \u2013", "tokens": ["Und", "hat", "\u2013", "das", "sei", "ihm", "nicht", "ver\u00b7dacht", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "$(", "PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es sehr weit auf der Welt gebracht.", "tokens": ["Es", "sehr", "weit", "auf", "der", "Welt", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Manch Heiliger von alters her", "tokens": ["Manch", "Hei\u00b7li\u00b7ger", "von", "al\u00b7ters", "her"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ADV", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stand bei der Menschheit hoch in Ehr.", "tokens": ["Stand", "bei", "der", "Menschheit", "hoch", "in", "Ehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Der eine, weil er Kranke heilte,", "tokens": ["Der", "ei\u00b7ne", ",", "weil", "er", "Kran\u00b7ke", "heil\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der andre, weil er Heiden keilte", "tokens": ["Der", "and\u00b7re", ",", "weil", "er", "Hei\u00b7den", "keil\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "$,", "KOUS", "PPER", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr die katholische Verbindung,", "tokens": ["F\u00fcr", "die", "ka\u00b7tho\u00b7li\u00b7sche", "Ver\u00b7bin\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der dritte wegen Mitempfindung", "tokens": ["Der", "drit\u00b7te", "we\u00b7gen", "Mi\u00b7temp\u00b7fin\u00b7dung"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "F\u00fcr alle V\u00f6gel auf dem Feld,", "tokens": ["F\u00fcr", "al\u00b7le", "V\u00f6\u00b7gel", "auf", "dem", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und sogenannte \u00e4u\u00dfre G\u00fcter,", "tokens": ["Und", "so\u00b7ge\u00b7nann\u00b7te", "\u00e4u\u00df\u00b7re", "G\u00fc\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.9": {"line.1": {"text": "Der Heilige, den ich erk\u00fcre,", "tokens": ["Der", "Hei\u00b7li\u00b7ge", ",", "den", "ich", "er\u00b7k\u00fc\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat g\u00e4nzlich andere All\u00fcre,", "tokens": ["Hat", "g\u00e4nz\u00b7lich", "an\u00b7de\u00b7re", "Al\u00b7l\u00fc\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er ist aus einem Material", "tokens": ["Er", "ist", "aus", "ei\u00b7nem", "Ma\u00b7te\u00b7ri\u00b7al"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "So schleierhaft wie schenial,", "tokens": ["So", "schlei\u00b7er\u00b7haft", "wie", "sche\u00b7ni\u00b7al", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn er besteht nur aus der Sohle", "tokens": ["Denn", "er", "be\u00b7steht", "nur", "aus", "der", "Soh\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und sonst aus nichts als Aureole.", "tokens": ["Und", "sonst", "aus", "nichts", "als", "Au\u00b7re\u00b7o\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIS", "KOKOM", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Sohle freilich macht daf\u00fcr", "tokens": ["Die", "Soh\u00b7le", "frei\u00b7lich", "macht", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So gro\u00df wie eine Kirchent\u00fcr,", "tokens": ["So", "gro\u00df", "wie", "ei\u00b7ne", "Kir\u00b7chen\u00b7t\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und tritt der Heilige herein,", "tokens": ["Und", "tritt", "der", "Hei\u00b7li\u00b7ge", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "M\u00f6cht' alles gleich: \u00bbDer Herrgott!\u00ab schrein.", "tokens": ["M\u00f6cht'", "al\u00b7les", "gleich", ":", "\u00bb", "Der", "Herr\u00b7gott", "!", "\u00ab", "schrein", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "$.", "$(", "ART", "NN", "$.", "$(", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wo das Gespr\u00e4ch in vollem Brausen,", "tokens": ["Wo", "das", "Ge\u00b7spr\u00e4ch", "in", "vol\u00b7lem", "Brau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Entsteht die tiefste aller Pausen,", "tokens": ["Ent\u00b7steht", "die", "tiefs\u00b7te", "al\u00b7ler", "Pau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Man f\u00e4llt vor Ehrfurcht von dem Platz \u2013", "tokens": ["Man", "f\u00e4llt", "vor", "Ehr\u00b7furcht", "von", "dem", "Platz", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Das macht der hohe Untersatz.", "tokens": ["Das", "macht", "der", "ho\u00b7he", "Un\u00b7ter\u00b7satz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Die Sohle ist ein hohles Ding,", "tokens": ["Die", "Soh\u00b7le", "ist", "ein", "hoh\u00b7les", "Ding", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Kautschuk mit Luft wie 'n Rettungsring,", "tokens": ["Kaut\u00b7schuk", "mit", "Luft", "wie", "'n", "Ret\u00b7tungs\u00b7ring", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KOKOM", "ART", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.17": {"text": "Doch eine Schelle pingpingping", "tokens": ["Doch", "ei\u00b7ne", "Schel\u00b7le", "ping\u00b7ping\u00b7ping"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Bet\u00f6rt selbst einen Sonderling,", "tokens": ["Be\u00b7t\u00f6rt", "selbst", "ei\u00b7nen", "Son\u00b7der\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Der sonst sich schwer l\u00e4\u00dft imponieren", "tokens": ["Der", "sonst", "sich", "schwer", "l\u00e4\u00dft", "im\u00b7po\u00b7nie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PRF", "ADJD", "VVFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Von annoncierten gro\u00dfen Tieren.", "tokens": ["Von", "an\u00b7non\u00b7cier\u00b7ten", "gro\u00b7\u00dfen", "Tie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Doch nach dem unteren Symbole", "tokens": ["Doch", "nach", "dem", "un\u00b7te\u00b7ren", "Sym\u00b7bo\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Wirkt erst die obre Aureole", "tokens": ["Wirkt", "erst", "die", "ob\u00b7re", "Au\u00b7re\u00b7o\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Ganz unbeschreiblich mit dem Kranz", "tokens": ["Ganz", "un\u00b7be\u00b7schreib\u00b7lich", "mit", "dem", "Kranz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Von Flimmerflammerflummerglanz.", "tokens": ["Von", "Flim\u00b7mer\u00b7flam\u00b7mer\u00b7flum\u00b7mer\u00b7glanz", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Da dreht sich statt dem Oberleibe", "tokens": ["Da", "dreht", "sich", "statt", "dem", "O\u00b7berl\u00b7ei\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Nur eine Riesenblendescheibe,", "tokens": ["Nur", "ei\u00b7ne", "Rie\u00b7sen\u00b7blen\u00b7de\u00b7schei\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Davor die Sonne sich verbirgt", "tokens": ["Da\u00b7vor", "die", "Son\u00b7ne", "sich", "ver\u00b7birgt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "PRF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Und ihre Scham herunterw\u00fcrgt.", "tokens": ["Und", "ih\u00b7re", "Scham", "her\u00b7un\u00b7ter\u00b7w\u00fcrgt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Und solcher \u00dcbersonnenschimmer", "tokens": ["Und", "sol\u00b7cher", "\u00dc\u00b7ber\u00b7son\u00b7nen\u00b7schim\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Kommt nur von Talmiglas und -Glimmer,", "tokens": ["Kommt", "nur", "von", "Tal\u00b7mi\u00b7glas", "und", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Dahinter sich wie ein Prolet", "tokens": ["Da\u00b7hin\u00b7ter", "sich", "wie", "ein", "Pro\u00b7let"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PRF", "KOKOM", "ART", "NN"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.32": {"text": "Ein ganz gemeines Talglicht dreht.", "tokens": ["Ein", "ganz", "ge\u00b7mei\u00b7nes", "Talg\u00b7licht", "dreht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Wo nun der Heilige erscheint,", "tokens": ["Wo", "nun", "der", "Hei\u00b7li\u00b7ge", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da ist man nahezu versteint.", "tokens": ["Da", "ist", "man", "na\u00b7he\u00b7zu", "ver\u00b7steint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer sonst die Nase hochgetragen,", "tokens": ["Wer", "sonst", "die", "Na\u00b7se", "hoch\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wagt kaum die Augen aufzuschlagen,", "tokens": ["Wagt", "kaum", "die", "Au\u00b7gen", "auf\u00b7zu\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und wer sonst kein verlegner Lurch,", "tokens": ["Und", "wer", "sonst", "kein", "ver\u00b7leg\u00b7ner", "Lurch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der ist vertattert durch und durch.", "tokens": ["Der", "ist", "ver\u00b7tat\u00b7tert", "durch", "und", "durch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "APPR", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Kniee knicken, da\u00df es knackt,", "tokens": ["Die", "Kni\u00b7ee", "kni\u00b7cken", ",", "da\u00df", "es", "knackt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die Wirbel biegen sich im Takt,", "tokens": ["Die", "Wir\u00b7bel", "bie\u00b7gen", "sich", "im", "Takt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und auf dem Gipfelpunkt des Glanzes", "tokens": ["Und", "auf", "dem", "Gip\u00b7fel\u00b7punkt", "des", "Glan\u00b7zes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Beginnt nach Art des Eiertanzes", "tokens": ["Be\u00b7ginnt", "nach", "Art", "des", "Ei\u00b7er\u00b7tan\u00b7zes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Ein wunderlicher Ehrenstu\u00df \u2013", "tokens": ["Ein", "wun\u00b7der\u00b7li\u00b7cher", "Eh\u00b7ren\u00b7stu\u00df", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Der Kotau macht sodann den Schlu\u00df.", "tokens": ["Der", "Ko\u00b7tau", "macht", "so\u00b7dann", "den", "Schlu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Wer diesen Heiligen nun ben\u00fctzt,", "tokens": ["Wer", "die\u00b7sen", "Hei\u00b7li\u00b7gen", "nun", "be\u00b7n\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da\u00df er besonders ihn besch\u00fctzt,", "tokens": ["Da\u00df", "er", "be\u00b7son\u00b7ders", "ihn", "be\u00b7sch\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der l\u00e4\u00dft um sich die Welt sich drehen,", "tokens": ["Der", "l\u00e4\u00dft", "um", "sich", "die", "Welt", "sich", "dre\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PRF", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil alle nach dem Heiligen sehen,", "tokens": ["Weil", "al\u00b7le", "nach", "dem", "Hei\u00b7li\u00b7gen", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Der als ein magisch Transparent", "tokens": ["Der", "als", "ein", "ma\u00b7gisch", "Trans\u00b7pa\u00b7rent"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "KOUS", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor seinem Schutzbefohlnen brennt.", "tokens": ["Vor", "sei\u00b7nem", "Schutz\u00b7be\u00b7fohl\u00b7nen", "brennt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vom Hausknecht an bis zu den Spitzen", "tokens": ["Vom", "Haus\u00b7knecht", "an", "bis", "zu", "den", "Spit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "F\u00e4ngt's an vor Hochachtung zu spritzen,", "tokens": ["F\u00e4ngt's", "an", "vor", "Hoch\u00b7ach\u00b7tung", "zu", "sprit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.9": {"text": "Man glotzt geblendet auf das Licht", "tokens": ["Man", "glotzt", "ge\u00b7blen\u00b7det", "auf", "das", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und sieht den \u2013 Talg vor Nimbus nicht.", "tokens": ["Und", "sieht", "den", "\u2013", "Talg", "vor", "Nim\u00b7bus", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "$(", "NN", "APPR", "NE", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Sankt ", "tokens": ["Sankt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Des Heiligen von Notreklame,", "tokens": ["Des", "Hei\u00b7li\u00b7gen", "von", "Not\u00b7re\u00b7kla\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das in den b\u00f6hmischen W\u00e4ldern liegt,", "tokens": ["Das", "in", "den", "b\u00f6h\u00b7mi\u00b7schen", "W\u00e4l\u00b7dern", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wo man es nie zu sehen kriegt.", "tokens": ["Wo", "man", "es", "nie", "zu", "se\u00b7hen", "kriegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer mit ihm auftritt, mag geboren", "tokens": ["Wer", "mit", "ihm", "auf\u00b7tritt", ",", "mag", "ge\u00b7bo\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "APPR", "PPER", "VVFIN", "$,", "VMFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als Schuster sein, er ist erkoren,", "tokens": ["Als", "Schus\u00b7ter", "sein", ",", "er", "ist", "er\u00b7ko\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAINF", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df jede Festung sich ergibt,", "tokens": ["Da\u00df", "je\u00b7de", "Fes\u00b7tung", "sich", "er\u00b7gibt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In die er seine Plempe schiebt.", "tokens": ["In", "die", "er", "sei\u00b7ne", "Plem\u00b7pe", "schiebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ist er ein Ludewig der Gosse,", "tokens": ["Ist", "er", "ein", "Lu\u00b7de\u00b7wig", "der", "Gos\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Er wird vermittelst Rudolf Mosse,", "tokens": ["Er", "wird", "ver\u00b7mit\u00b7telst", "Ru\u00b7dolf", "Mos\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Vielleicht auch Haasenstein und Vogler,", "tokens": ["Viel\u00b7leicht", "auch", "Haa\u00b7sen\u00b7stein", "und", "Vog\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Zun\u00e4chst ein s\u00fc\u00dfer, frecher Mogler,", "tokens": ["Zu\u00b7n\u00e4chst", "ein", "s\u00fc\u00b7\u00dfer", ",", "fre\u00b7cher", "Mog\u00b7ler", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Denn unser Heiliger bringt Heil", "tokens": ["Denn", "un\u00b7ser", "Hei\u00b7li\u00b7ger", "bringt", "Heil"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Auch durch den Inseratenteil.", "tokens": ["Auch", "durch", "den", "In\u00b7se\u00b7ra\u00b7ten\u00b7teil", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Dann thront er bald im \u00bbGrand Hotelle\u00ab", "tokens": ["Dann", "thront", "er", "bald", "im", "\u00bb", "Grand", "Ho\u00b7tel\u00b7le", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "$(", "NN", "NN", "$("], "meter": "-+-+-++--", "measure": "unknown.measure.tetra"}, "line.16": {"text": "Beim \u00bbSouper\u00ab an der ersten Stelle,", "tokens": ["Beim", "\u00bb", "Sou\u00b7per", "\u00ab", "an", "der", "ers\u00b7ten", "Stel\u00b7le", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "$(", "NN", "$(", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "S\u00e4mtliche Schneider sind verr\u00fcckt,", "tokens": ["S\u00e4mt\u00b7li\u00b7che", "Schnei\u00b7der", "sind", "ver\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.18": {"text": "Bald ist's beim Marschall ihm gegl\u00fcckt", "tokens": ["Bald", "ist's", "beim", "Mar\u00b7schall", "ihm", "ge\u00b7gl\u00fcckt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Just durch die fixste Kammerzofe,", "tokens": ["Just", "durch", "die", "fixs\u00b7te", "Kam\u00b7mer\u00b7zo\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Und schlie\u00dflich h\u00e4lt er \u2013 an \u2013 zu \u2013 Hofe.", "tokens": ["Und", "schlie\u00df\u00b7lich", "h\u00e4lt", "er", "\u2013", "an", "\u2013", "zu", "\u2013", "Ho\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "$(", "APPR", "$(", "PTKZU", "$(", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Doch von dem ordin\u00e4ren Lucki", "tokens": ["Doch", "von", "dem", "or\u00b7di\u00b7n\u00e4\u00b7ren", "Lu\u00b7cki"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Ganz abgesehn, der Doljorucki", "tokens": ["Ganz", "ab\u00b7ge\u00b7sehn", ",", "der", "Dol\u00b7jo\u00b7ruc\u00b7ki"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "VVPP", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und F\u00fcrst Kanaljewitsch sich nennt \u2013", "tokens": ["Und", "F\u00fcrst", "Ka\u00b7nal\u00b7je\u00b7witsch", "sich", "nennt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Heilige mit Transparent", "tokens": ["Der", "Hei\u00b7li\u00b7ge", "mit", "Trans\u00b7pa\u00b7rent"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Macht selbst ganz unbescholtne M\u00e4nner", "tokens": ["Macht", "selbst", "ganz", "un\u00b7be\u00b7scholt\u00b7ne", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu einer Sensation f\u00fcr Kenner.", "tokens": ["Zu", "ei\u00b7ner", "Sen\u00b7sa\u00b7ti\u00b7on", "f\u00fcr", "Ken\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Dem \u00bbim Detail\u00ab noch nachzusp\u00fcren,", "tokens": ["Dem", "\u00bb", "im", "De\u00b7tail", "\u00ab", "noch", "nach\u00b7zu\u00b7sp\u00fc\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "$(", "APPRART", "NN", "$(", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das w\u00fcrde hier \u00bbzu weit mich f\u00fchren\u00ab,", "tokens": ["Das", "w\u00fcr\u00b7de", "hier", "\u00bb", "zu", "weit", "mich", "f\u00fch\u00b7ren", "\u00ab", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ADV", "$(", "PTKA", "ADJD", "PPER", "VVINF", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die Kunst ist kurz, die Elle lang,", "tokens": ["Die", "Kunst", "ist", "kurz", ",", "die", "El\u00b7le", "lang", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wer zuviel schreibt, kriegt Blutandrang.", "tokens": ["Wer", "zu\u00b7viel", "schreibt", ",", "kriegt", "Blu\u00b7tan\u00b7drang", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "$,", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Genug \u2013 man darf Herr Schulze hei\u00dfen,", "tokens": ["Ge\u00b7nug", "\u2013", "man", "darf", "Herr", "Schul\u00b7ze", "hei\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "PIS", "VMFIN", "NN", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Hat Nimbus er, kann er drauf \u2013 pfeifen", "tokens": ["Hat", "Nim\u00b7bus", "er", ",", "kann", "er", "drauf", "\u2013", "pfei\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "NE", "PPER", "$,", "VMFIN", "PPER", "PAV", "$(", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "Und wird, wenn es Sankt N. gef\u00e4llt,", "tokens": ["Und", "wird", ",", "wenn", "es", "Sankt", "N.", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "abbreviation", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "KOUS", "PPER", "VVFIN", "NE", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Rasch Aufsichtsrat der ganzen Welt.", "tokens": ["Rasch", "Auf\u00b7sichts\u00b7rat", "der", "gan\u00b7zen", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Hast einen Zirkus du von Fl\u00f6hen,", "tokens": ["Hast", "ei\u00b7nen", "Zir\u00b7kus", "du", "von", "Fl\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "La\u00df dich nur omin\u00f6s \u00bberh\u00f6hen\u00ab,", "tokens": ["La\u00df", "dich", "nur", "o\u00b7mi\u00b7n\u00f6s", "\u00bb", "er\u00b7h\u00f6\u00b7hen", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADJD", "$(", "VVINF", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und bald ziehst du an einem Haar", "tokens": ["Und", "bald", "ziehst", "du", "an", "ei\u00b7nem", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.18": {"text": "Die hohe Professorenschar", "tokens": ["Die", "ho\u00b7he", "Pro\u00b7fes\u00b7so\u00b7ren\u00b7schar"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Mitsamt den Frauen und den T\u00f6chten,", "tokens": ["Mit\u00b7samt", "den", "Frau\u00b7en", "und", "den", "T\u00f6ch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Die sich dressieren lassen m\u00f6chten.", "tokens": ["Die", "sich", "dres\u00b7sie\u00b7ren", "las\u00b7sen", "m\u00f6ch\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVINF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Bist du ein Schornalist, so nimm", "tokens": ["Bist", "du", "ein", "Schor\u00b7na\u00b7list", ",", "so", "nimm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "ADV", "VVIMP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Den Majestatikus und schwimm", "tokens": ["Den", "Ma\u00b7jes\u00b7ta\u00b7ti\u00b7kus", "und", "schwimm"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Im Glanz der \u00f6ffentlichen Meinung \u2013", "tokens": ["Im", "Glanz", "der", "\u00f6f\u00b7fent\u00b7li\u00b7chen", "Mei\u00b7nung", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Gen Himmel w\u00e4chst die Schmockerscheinung.", "tokens": ["Gen", "Him\u00b7mel", "w\u00e4chst", "die", "Schmo\u00b7cker\u00b7schei\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Ein sogenannter Dichter aber,", "tokens": ["Ein", "so\u00b7ge\u00b7nann\u00b7ter", "Dich\u00b7ter", "a\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.26": {"text": "Als welchen sticht des Ruhmes Haber,", "tokens": ["Als", "wel\u00b7chen", "sticht", "des", "Ruh\u00b7mes", "Ha\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAT", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Er lasse bei dem Heiligen sich", "tokens": ["Er", "las\u00b7se", "bei", "dem", "Hei\u00b7li\u00b7gen", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PRF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Versichern prompt. Hat er den Strich,", "tokens": ["Ver\u00b7si\u00b7chern", "prompt", ".", "Hat", "er", "den", "Strich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.29": {"text": "Dann um ", "tokens": ["Dann", "um"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.30": {"text": "Der Nimbus macht den Dichtersmann.", "tokens": ["Der", "Nim\u00b7bus", "macht", "den", "Dich\u00b7ters\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Enorm wirkt hier die hohe Sohle", "tokens": ["En\u00b7orm", "wirkt", "hier", "die", "ho\u00b7he", "Soh\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Der allerdunkelsten Symbole,", "tokens": ["Der", "al\u00b7ler\u00b7dun\u00b7kels\u00b7ten", "Sym\u00b7bo\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.33": {"text": "Gemischt aus Schall und blauem Dunst,", "tokens": ["Ge\u00b7mischt", "aus", "Schall", "und", "blau\u00b7em", "Dunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Apartem Brei, besondrer Brunst.", "tokens": ["A\u00b7par\u00b7tem", "Brei", ",", "be\u00b7sond\u00b7rer", "Brunst", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Der Nimbus adelt einen blo\u00dfen", "tokens": ["Der", "Nim\u00b7bus", "a\u00b7delt", "ei\u00b7nen", "blo\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Nonsensplusultra gleich zum gro\u00dfen", "tokens": ["Non\u00b7sen\u00b7splu\u00b7sul\u00b7tra", "gleich", "zum", "gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADV", "APPRART", "ADJA"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.37": {"text": "Gedanken \u2013 \u00bbTiefsinn!\u00ab raunt der Snob,", "tokens": ["Ge\u00b7dan\u00b7ken", "\u2013", "\u00bb", "Tief\u00b7sinn", "!", "\u00ab", "raunt", "der", "Snob", ","], "token_info": ["word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "$(", "NN", "$.", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Und hurrehurrehopphopphopp", "tokens": ["Und", "hur\u00b7re\u00b7hur\u00b7re\u00b7hop\u00b7phop\u00b7phopp"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Schreit das Ger\u00fccht den seltnen Kleister", "tokens": ["Schreit", "das", "Ge\u00b7r\u00fccht", "den", "selt\u00b7nen", "Kleis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.40": {"text": "Zum Kunstwerk aus, den Matz zum Meister.", "tokens": ["Zum", "Kunst\u00b7werk", "aus", ",", "den", "Matz", "zum", "Meis\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$,", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "So geht der Heilige Nimbus um,", "tokens": ["So", "geht", "der", "Hei\u00b7li\u00b7ge", "Nim\u00b7bus", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er kennt, er kennt sein Publikum.", "tokens": ["Er", "kennt", ",", "er", "kennt", "sein", "Pub\u00b7li\u00b7kum", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er ist \u2013 samt Sohle, Schein und Schelle \u2013", "tokens": ["Er", "ist", "\u2013", "samt", "Soh\u00b7le", ",", "Schein", "und", "Schel\u00b7le", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "APPR", "NN", "$,", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von Haus aus Tapeziergeselle", "tokens": ["Von", "Haus", "aus", "Ta\u00b7pe\u00b7zier\u00b7ge\u00b7sel\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und hat \u2013 das sei ihm nicht verdacht! \u2013", "tokens": ["Und", "hat", "\u2013", "das", "sei", "ihm", "nicht", "ver\u00b7dacht", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "$(", "PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es sehr weit auf der Welt gebracht.", "tokens": ["Es", "sehr", "weit", "auf", "der", "Welt", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}