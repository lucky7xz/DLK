{"dta.poem.20429": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Uber die thorheit der menschen/ aus  \n dem frantz\u00f6sischen des ber\u00fchmten poeten  \n  Boileau.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "In aller thiere heer/ die in den l\u00fcfften schweben/", "tokens": ["In", "al\u00b7ler", "thie\u00b7re", "heer", "/", "die", "in", "den", "l\u00fcff\u00b7ten", "schwe\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$(", "ART", "APPR", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In wasser wohnhafft sind/ und auff der erden leben/", "tokens": ["In", "was\u00b7ser", "wohn\u00b7hafft", "sind", "/", "und", "auff", "der", "er\u00b7den", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "$(", "KON", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von Japan bi\u00df nach Rom/ von Peru bi\u00df Pari\u00df/", "tokens": ["Von", "Ja\u00b7pan", "bi\u00df", "nach", "Rom", "/", "von", "Pe\u00b7ru", "bi\u00df", "Pa\u00b7ri\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "APPR", "NE", "$(", "APPR", "NE", "APPR", "NE", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Ist wohl das n\u00e4rrschte thier der mensch/ und das gewi\u00df.", "tokens": ["Ist", "wohl", "das", "n\u00e4rrschte", "thier", "der", "mensch", "/", "und", "das", "ge\u00b7wi\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "ART", "NN", "$(", "KON", "PDS", "ADV", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Was? sagest du hierauff/ ein kriechend ungezieffer/", "tokens": ["Was", "?", "sa\u00b7gest", "du", "hier\u00b7auff", "/", "ein", "krie\u00b7chend", "un\u00b7ge\u00b7zief\u00b7fer", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "VVFIN", "PPER", "PAV", "$(", "ART", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein rind/ das wiederk\u00e4ut/ und was noch etwa tieffer/", "tokens": ["Ein", "rind", "/", "das", "wie\u00b7der\u00b7k\u00e4ut", "/", "und", "was", "noch", "et\u00b7wa", "tief\u00b7fer", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PDS", "VVFIN", "$(", "KON", "PWS", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein wurm/ der kaum halb lebt/ der bunt gemachte specht/", "tokens": ["Ein", "wurm", "/", "der", "kaum", "halb", "lebt", "/", "der", "bunt", "ge\u00b7mach\u00b7te", "specht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADV", "ADJD", "VVFIN", "$(", "ART", "ADJD", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sind die von besserm geist/ als nicht der mensch? gantz recht.", "tokens": ["Sind", "die", "von", "bes\u00b7serm", "geist", "/", "als", "nicht", "der", "mensch", "?", "gantz", "recht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ART", "APPR", "ADJA", "NN", "$(", "KOUS", "PTKNEG", "ART", "NN", "$.", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die rede wundert dich/ herr doctor/ und nicht wenig;", "tokens": ["Die", "re\u00b7de", "wun\u00b7dert", "dich", "/", "herr", "doc\u00b7tor", "/", "und", "nicht", "we\u00b7nig", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "PPER", "$(", "FM.la", "FM.la", "$(", "KON", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der mensch ist der natur erkohrnes haupt und k\u00f6nig/", "tokens": ["Der", "mensch", "ist", "der", "na\u00b7tur", "er\u00b7kohr\u00b7nes", "haupt", "und", "k\u00f6\u00b7nig", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ADJA", "NN", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Feld/ wiesen/ holtz und thier sind nur vor ihn gemacht/", "tokens": ["Feld", "/", "wie\u00b7sen", "/", "holtz", "und", "thier", "sind", "nur", "vor", "ihn", "ge\u00b7macht", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVPP", "$(", "ADJD", "KON", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und er allein/ sprichst du/ ist zur vernunfft gebracht.", "tokens": ["Und", "er", "al\u00b7lein", "/", "sprichst", "du", "/", "ist", "zur", "ver\u00b7nunfft", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "$(", "VVFIN", "PPER", "$(", "VAFIN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-++-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Ja wohl der wei\u00dfheit sitz mu\u00df stets bey ihm beharren/", "tokens": ["Ja", "wohl", "der", "wei\u00df\u00b7heit", "sitz", "mu\u00df", "stets", "bey", "ihm", "be\u00b7har\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "NN", "NE", "VMFIN", "ADV", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Doch davor halt ich ihn auch vor den gr\u00f6sten narren.", "tokens": ["Doch", "da\u00b7vor", "halt", "ich", "ihn", "auch", "vor", "den", "gr\u00f6s\u00b7ten", "nar\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der vortrag dienet schon/ sagst du/ zur sticheley/", "tokens": ["Der", "vor\u00b7trag", "die\u00b7net", "schon", "/", "sagst", "du", "/", "zur", "sti\u00b7che\u00b7ley", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$(", "VVFIN", "PPER", "$(", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Auff da\u00df der gerne lacht/ damit belustigt sey;", "tokens": ["Auff", "da\u00df", "der", "ger\u00b7ne", "lacht", "/", "da\u00b7mit", "be\u00b7lus\u00b7tigt", "sey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "ADV", "VVFIN", "$(", "PAV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Allein bewei\u00df es auch/ wie sichs geb\u00fchrt/ zu dienen/", "tokens": ["Al\u00b7lein", "be\u00b7wei\u00df", "es", "auch", "/", "wie", "sichs", "ge\u00b7b\u00fchrt", "/", "zu", "die\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "PWAV", "PIS", "VVPP", "$(", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Drum setz dich auff die banck/ ich bin vor dir erschienen/", "tokens": ["Drum", "setz", "dich", "auff", "die", "banck", "/", "ich", "bin", "vor", "dir", "er\u00b7schie\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "PPER", "VAFIN", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Lehr mich/ was klugheit sey/ der seelen gleiche krafft/", "tokens": ["Lehr", "mich", "/", "was", "klug\u00b7heit", "sey", "/", "der", "see\u00b7len", "glei\u00b7che", "krafft", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$(", "PWS", "ADJD", "VAFIN", "$(", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Die kein verh\u00e4ngni\u00df schw\u00e4cht/ da keine neigung hafft.", "tokens": ["Die", "kein", "ver\u00b7h\u00e4ng\u00b7ni\u00df", "schw\u00e4cht", "/", "da", "kei\u00b7ne", "nei\u00b7gung", "hafft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$(", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Sie fust in ihren schlu\u00df mit viel gepa\u00dftern schritten/", "tokens": ["Sie", "fust", "in", "ih\u00b7ren", "schlu\u00df", "mit", "viel", "ge\u00b7pa\u00df\u00b7tern", "schrit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "PIAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Als kaum ein rathhaus-bret vom doctor hat erlitten.", "tokens": ["Als", "kaum", "ein", "ra\u00b7th\u00b7haus\u00b7bret", "vom", "doc\u00b7tor", "hat", "er\u00b7lit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPRART", "NE", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.23": {"text": "Nach dieser gleichen krafft/ von der man klugheit bricht/", "tokens": ["Nach", "die\u00b7ser", "glei\u00b7chen", "krafft", "/", "von", "der", "man", "klug\u00b7heit", "bricht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$(", "APPR", "PRELS", "PIS", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Hat iemand/ als der mensch/ sich schlechter eingericht?", "tokens": ["Hat", "ie\u00b7mand", "/", "als", "der", "mensch", "/", "sich", "schlech\u00b7ter", "ein\u00b7ge\u00b7richt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$(", "KOUS", "ART", "NN", "$(", "PRF", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die amei\u00df/ h\u00f6re doch! pflegt alle jahr zu lauffen/", "tokens": ["Die", "am\u00b7ei\u00df", "/", "h\u00f6\u00b7re", "doch", "!", "pflegt", "al\u00b7le", "jahr", "zu", "lauf\u00b7fen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "VVFIN", "ADV", "$.", "VVFIN", "PIAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und bringt der Ceres schatz in magazin zu hauffen;", "tokens": ["Und", "bringt", "der", "Ce\u00b7res", "schatz", "in", "ma\u00b7ga\u00b7zin", "zu", "hauf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NE", "ADJD", "APPR", "NE", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wenn denn der scharffe nord die k\u00e4lte wiederbringt/", "tokens": ["Wenn", "denn", "der", "scharf\u00b7fe", "nord", "die", "k\u00e4l\u00b7te", "wie\u00b7der\u00b7bringt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und mit der nebel-netz die fr\u00f6ligkeit bezwingt/", "tokens": ["Und", "mit", "der", "ne\u00b7bel\u00b7netz", "die", "fr\u00f6\u00b7lig\u00b7keit", "be\u00b7zwingt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.29": {"text": "Steckt dieses kluge thier in seinen dunckeln wesen/", "tokens": ["Steckt", "die\u00b7ses", "klu\u00b7ge", "thier", "in", "sei\u00b7nen", "dun\u00b7ckeln", "we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und zehrt des winters auff/ was sommers eingelesen.", "tokens": ["Und", "zehrt", "des", "win\u00b7ters", "auff", "/", "was", "som\u00b7mers", "ein\u00b7ge\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "$(", "PWS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Gantz recht/ der mensch allein ist zum verstand erkohren/", "tokens": ["Gantz", "recht", "/", "der", "mensch", "al\u00b7lein", "ist", "zum", "ver\u00b7stand", "er\u00b7koh\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ART", "NN", "ADV", "VAFIN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Doch darum halt ich ihn auch f\u00fcr den gr\u00f6sten thoren.", "tokens": ["Doch", "da\u00b7rum", "halt", "ich", "ihn", "auch", "f\u00fcr", "den", "gr\u00f6s\u00b7ten", "tho\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Man siehet es auch nicht aus unbest\u00e4ndigkeit/", "tokens": ["Man", "sie\u00b7het", "es", "auch", "nicht", "aus", "un\u00b7be\u00b7st\u00e4n\u00b7dig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "PTKNEG", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Im sommer etwa faul/ voll flei\u00df zur winters-zeit/", "tokens": ["Im", "som\u00b7mer", "et\u00b7wa", "faul", "/", "voll", "flei\u00df", "zur", "win\u00b7ter\u00b7szeit", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADJD", "$(", "ADJD", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Noch in der weissen flur dem harten jenner pochen/", "tokens": ["Noch", "in", "der", "weis\u00b7sen", "flur", "dem", "har\u00b7ten", "jen\u00b7ner", "po\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "PDAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und wenn der widder k\u00f6mmt verscharret und verkrochen.", "tokens": ["Und", "wenn", "der", "wid\u00b7der", "k\u00f6mmt", "ver\u00b7schar\u00b7ret", "und", "ver\u00b7kro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "VVFIN", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Allein der mensch h\u00e4lt nicht in seinem n\u00e4rrschen lauff/", "tokens": ["Al\u00b7lein", "der", "mensch", "h\u00e4lt", "nicht", "in", "sei\u00b7nem", "n\u00e4rr\u00b7schen", "lauff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Er h\u00fcpfft ohn unterla\u00df bald nunter/ bald herauff.", "tokens": ["Er", "h\u00fcpfft", "ohn", "un\u00b7ter\u00b7la\u00df", "bald", "nun\u00b7ter", "/", "bald", "her\u00b7auff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "VVIMP", "ADV", "ADV", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Sein hertz f\u00fchrt tausend angst/ und kan sich nicht entscheiden/", "tokens": ["Sein", "hertz", "f\u00fchrt", "tau\u00b7send", "angst", "/", "und", "kan", "sich", "nicht", "ent\u00b7schei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "VVPP", "$(", "KON", "VMFIN", "PRF", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Indem es auch nicht wei\u00df/ was suchen sey/ was meiden;", "tokens": ["In\u00b7dem", "es", "auch", "nicht", "wei\u00df", "/", "was", "su\u00b7chen", "sey", "/", "was", "mei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "VVFIN", "$(", "PWS", "VVINF", "VAFIN", "$(", "PWS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Das/ was er heute scheut/ w\u00fcnscht er den andern tag.", "tokens": ["Das", "/", "was", "er", "heu\u00b7te", "scheut", "/", "w\u00fcnscht", "er", "den", "an\u00b7dern", "tag", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "PWS", "PPER", "ADV", "VVFIN", "$(", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Ich solte diese freyn/ der ich nicht h\u00f6rner mag;", "tokens": ["Ich", "sol\u00b7te", "die\u00b7se", "freyn", "/", "der", "ich", "nicht", "h\u00f6r\u00b7ner", "mag", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PDAT", "NN", "$(", "PRELS", "PPER", "PTKNEG", "ADJD", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Ich solte voll bestand den gr\u00f6sten schimpff nicht achten/", "tokens": ["Ich", "sol\u00b7te", "voll", "be\u00b7stand", "den", "gr\u00f6s\u00b7ten", "schimpff", "nicht", "ach\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "VVFIN", "ART", "ADJA", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Bey Bussys heiligen mir einen platz zu pachten/", "tokens": ["Bey", "Bus\u00b7sys", "hei\u00b7li\u00b7gen", "mir", "ei\u00b7nen", "platz", "zu", "pach\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Gnug narren ausser mir sind in der leute mund;", "tokens": ["Gnug", "nar\u00b7ren", "aus\u00b7ser", "mir", "sind", "in", "der", "leu\u00b7te", "mund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "VAFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "So gabe sich nur nechst ein guter schlucker kund/", "tokens": ["So", "ga\u00b7be", "sich", "nur", "nechst", "ein", "gu\u00b7ter", "schlu\u00b7cker", "kund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "ADV", "ART", "ADJA", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Der vierzehn tage drauff doch in der schlingen hienge/", "tokens": ["Der", "vier\u00b7zehn", "ta\u00b7ge", "drauff", "doch", "in", "der", "schlin\u00b7gen", "hien\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "PAV", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Und in der guten schaar den ehren-tag begienge;", "tokens": ["Und", "in", "der", "gu\u00b7ten", "schaar", "den", "eh\u00b7ren\u00b7tag", "be\u00b7gien\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Wiewohl er g\u00e4ntzlich meynt/ GOtt hab nur ihn bedacht/", "tokens": ["Wie\u00b7wohl", "er", "g\u00e4ntz\u00b7lich", "meynt", "/", "Gott", "hab", "nur", "ihn", "be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN", "$(", "NN", "VAFIN", "ADV", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Und ihm ein treues weib aus seiner ribbe bracht.", "tokens": ["Und", "ihm", "ein", "treu\u00b7es", "weib", "aus", "sei\u00b7ner", "rib\u00b7be", "bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "So sieht ein menschen-kind/ er geht zum schwartz-vom weissen/", "tokens": ["So", "sieht", "ein", "men\u00b7schen\u00b7kind", "/", "er", "geht", "zum", "schwartz\u00b7vom", "weis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "PPER", "VVFIN", "APPRART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Und was er fr\u00fch gebaut/ will er des nachts zerreissen/", "tokens": ["Und", "was", "er", "fr\u00fch", "ge\u00b7baut", "/", "will", "er", "des", "nachts", "zer\u00b7reis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADJD", "VVPP", "$(", "VMFIN", "PPER", "ART", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Sich macht er \u00fcberlast/ dem anderen verdru\u00df/", "tokens": ["Sich", "macht", "er", "\u00fc\u00b7berl\u00b7ast", "/", "dem", "an\u00b7de\u00b7ren", "ver\u00b7dru\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "PPER", "ADV", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Und wechselt wie die tracht den vorgefa\u00dften schlu\u00df.", "tokens": ["Und", "wech\u00b7selt", "wie", "die", "tracht", "den", "vor\u00b7ge\u00b7fa\u00df\u00b7ten", "schlu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Es dreht ihn halbe lufft/ er f\u00e4llt nur von ber\u00fchren/", "tokens": ["Es", "dreht", "ihn", "hal\u00b7be", "lufft", "/", "er", "f\u00e4llt", "nur", "von", "be\u00b7r\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJA", "NN", "$(", "PPER", "VVFIN", "ADV", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Bald heute will er schwerdt/ bald morgen kutt anf\u00fchren;", "tokens": ["Bald", "heu\u00b7te", "will", "er", "schwerdt", "/", "bald", "mor\u00b7gen", "kutt", "an\u00b7f\u00fch\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "ADJD", "$(", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Indessen wiegt er sich in eigner schmeicheley/", "tokens": ["In\u00b7des\u00b7sen", "wiegt", "er", "sich", "in", "eig\u00b7ner", "schmei\u00b7che\u00b7ley", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Und stellt sich kr\u00e4fftig vor/ was vor ein held er sey.", "tokens": ["Und", "stellt", "sich", "kr\u00e4ff\u00b7tig", "vor", "/", "was", "vor", "ein", "held", "er", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "PTKVZ", "$(", "PWS", "APPR", "ART", "VVFIN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Wie er bey der natur als grund und pfeiler stehe/", "tokens": ["Wie", "er", "bey", "der", "na\u00b7tur", "als", "grund", "und", "pfei\u00b7ler", "ste\u00b7he", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "KOUS", "NN", "KON", "NN", "VVFIN", "$("], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.60": {"text": "Das zehnde himmels-rath sich einig vor ihm drehe/", "tokens": ["Das", "zehn\u00b7de", "him\u00b7mels\u00b7rath", "sich", "ei\u00b7nig", "vor", "ihm", "dre\u00b7he", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "ADJD", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Von allen was nur lebt/ meynt er/ ich bin der mann/", "tokens": ["Von", "al\u00b7len", "was", "nur", "lebt", "/", "meynt", "er", "/", "ich", "bin", "der", "mann", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PWS", "ADV", "VVFIN", "$(", "VVFIN", "PPER", "$(", "PPER", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Wer leugnets denn/ sagstu? Ich/ mein freund/ weil ich kan.", "tokens": ["Wer", "leug\u00b7nets", "denn", "/", "sags\u00b7tu", "?", "Ich", "/", "mein", "freund", "/", "weil", "ich", "kan", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "$(", "VVFIN", "$.", "PPER", "$(", "PPOSAT", "NN", "$(", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Hier untersuch ich nicht/ wie sich ein b\u00e4r erweiset/", "tokens": ["Hier", "un\u00b7ter\u00b7such", "ich", "nicht", "/", "wie", "sich", "ein", "b\u00e4r", "er\u00b7wei\u00b7set", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$(", "PWAV", "PRF", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Wie freundlich er uns thut/ wenn ihn der hunger reisset/", "tokens": ["Wie", "freund\u00b7lich", "er", "uns", "thut", "/", "wenn", "ihn", "der", "hun\u00b7ger", "reis\u00b7set", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PPER", "VVFIN", "$(", "KOUS", "PPER", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Er tr\u00e4gt vor b\u00fcttel/ knecht und keinen hencker scheu.", "tokens": ["Er", "tr\u00e4gt", "vor", "b\u00fct\u00b7tel", "/", "knecht", "und", "kei\u00b7nen", "hen\u00b7cker", "scheu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "$(", "VVFIN", "KON", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Raubt auch ein wolff so sehr/ als wie wir wilden leute?", "tokens": ["Raubt", "auch", "ein", "wolff", "so", "sehr", "/", "als", "wie", "wir", "wil\u00b7den", "leu\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "ADV", "$(", "KOUS", "KOKOM", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Zieht er den wolff wohl ab/ und macht das fleisch zur beute?", "tokens": ["Zieht", "er", "den", "wolff", "wohl", "ab", "/", "und", "macht", "das", "fleisch", "zur", "beu\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "PTKVZ", "$(", "KON", "VVFIN", "ART", "NN", "APPRART", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Kein krieger denckt auff krieg auch in der gr\u00f6sten wuth/", "tokens": ["Kein", "krie\u00b7ger", "denckt", "auff", "krieg", "auch", "in", "der", "gr\u00f6s\u00b7ten", "wuth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "NN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Und macht Hircanien zu einen taffel-gut.", "tokens": ["Und", "macht", "Hir\u00b7ca\u00b7ni\u00b7en", "zu", "ei\u00b7nen", "taf\u00b7fel\u00b7gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Sieht man im holtze krieg von b\u00e4ren gegen b\u00e4ren?", "tokens": ["Sieht", "man", "im", "holt\u00b7ze", "krieg", "von", "b\u00e4\u00b7ren", "ge\u00b7gen", "b\u00e4\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPRART", "ADJA", "NN", "APPR", "ADJA", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Mu\u00df sich der geyer auch vor seines gleichen wehren?", "tokens": ["Mu\u00df", "sich", "der", "ge\u00b7yer", "auch", "vor", "sei\u00b7nes", "glei\u00b7chen", "weh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ART", "ADJA", "ADV", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.72": {"text": "H\u00f6rt man aus Africa da\u00df sich aus ha\u00df und groll", "tokens": ["H\u00f6rt", "man", "aus", "A\u00b7fri\u00b7ca", "da\u00df", "sich", "aus", "ha\u00df", "und", "groll"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPR", "NE", "KOUS", "PRF", "APPR", "VVIMP", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Ins l\u00f6wens republic ein krieg entspinnen soll?", "tokens": ["Ins", "l\u00f6\u00b7wens", "re\u00b7pub\u00b7lic", "ein", "krieg", "ent\u00b7spin\u00b7nen", "soll", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Da\u00df l\u00f6we gegen l\u00f6w/ ein freund auff seines gleichen/", "tokens": ["Da\u00df", "l\u00f6\u00b7we", "ge\u00b7gen", "l\u00f6w", "/", "ein", "freund", "auff", "sei\u00b7nes", "glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPR", "NE", "$(", "ART", "NN", "APPR", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Auff des tyrannen wort sich so voll grimm erzeigen?", "tokens": ["Auff", "des", "ty\u00b7ran\u00b7nen", "wort", "sich", "so", "voll", "grimm", "er\u00b7zei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PRF", "ADV", "ADJD", "ADJD", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.76": {"text": "Das allergrimmste thier/ das die natur gebiert/", "tokens": ["Das", "al\u00b7ler\u00b7grimms\u00b7te", "thier", "/", "das", "die", "na\u00b7tur", "ge\u00b7biert", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PRELS", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Tr\u00e4gt vor dem andern scheu/ wenn es sein bildni\u00df f\u00fchrt;", "tokens": ["Tr\u00e4gt", "vor", "dem", "an\u00b7dern", "scheu", "/", "wenn", "es", "sein", "bild\u00b7ni\u00df", "f\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "ADJD", "$(", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "L\u00e4st bey ihm seine wuth und seine wildheit fahren/", "tokens": ["L\u00e4st", "bey", "ihm", "sei\u00b7ne", "wuth", "und", "sei\u00b7ne", "wild\u00b7heit", "fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Und kan sich ohne zanck und streit mit ihm gebahren.", "tokens": ["Und", "kan", "sich", "oh\u00b7ne", "zanck", "und", "streit", "mit", "ihm", "ge\u00b7bah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "APPR", "NN", "KON", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Ob schon der adler-heer von einem felde ist/", "tokens": ["Ob", "schon", "der", "ad\u00b7ler\u00b7heer", "von", "ei\u00b7nem", "fel\u00b7de", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Citirt er andre wohl auff eine s\u00e4chsche frist?", "tokens": ["Ci\u00b7tirt", "er", "and\u00b7re", "wohl", "auff", "ei\u00b7ne", "s\u00e4ch\u00b7sche", "frist", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PIS", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Und wenn der fuchs dem huhn auch den proce\u00df will machen/", "tokens": ["Und", "wenn", "der", "fuchs", "dem", "huhn", "auch", "den", "pro\u00b7ce\u00df", "will", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "NN", "ADV", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Wird wohl der andre fuchs ein advocat der sachen?", "tokens": ["Wird", "wohl", "der", "and\u00b7re", "fuchs", "ein", "ad\u00b7vo\u00b7cat", "der", "sa\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "ART", "NE", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Wenn hat denn in der brunst das unvergn\u00fcgte reh", "tokens": ["Wenn", "hat", "denn", "in", "der", "brunst", "das", "un\u00b7ver\u00b7gn\u00fcg\u00b7te", "reh"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Den schwachen hirsch verklagt/ da\u00df er vor rechte steh?", "tokens": ["Den", "schwa\u00b7chen", "hirsch", "ver\u00b7klagt", "/", "da\u00df", "er", "vor", "rech\u00b7te", "steh", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$(", "KOUS", "PPER", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Niemahl/ schliest hier da\u00df recht/ den beyschlaff anzusagen/", "tokens": ["Nie\u00b7mahl", "/", "schliest", "hier", "da\u00df", "recht", "/", "den", "bey\u00b7schlaff", "an\u00b7zu\u00b7sa\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "VVFIN", "ADV", "KOUS", "ADJD", "$(", "ART", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Und l\u00e4st di\u00df garst\u2019ge wort in seinem urtheil tragen.", "tokens": ["Und", "l\u00e4st", "di\u00df", "gar\u00b7st'\u00b7ge", "wort", "in", "sei\u00b7nem", "ur\u00b7theil", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "VVFIN", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.88": {"text": "Sie fordert kein termin/ sie suppliciren nicht/", "tokens": ["Sie", "for\u00b7dert", "kein", "ter\u00b7min", "/", "sie", "sup\u00b7pli\u00b7ci\u00b7ren", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$(", "PPER", "VVFIN", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Und kennen weder rath/ noch amt/ noch hoffgericht;", "tokens": ["Und", "ken\u00b7nen", "we\u00b7der", "rath", "/", "noch", "amt", "/", "noch", "hoff\u00b7ge\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVINF", "KON", "NN", "$(", "ADV", "NN", "$(", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Sie leben unter sich in ruhigen vernehmen/", "tokens": ["Sie", "le\u00b7ben", "un\u00b7ter", "sich", "in", "ru\u00b7hi\u00b7gen", "ver\u00b7neh\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PRF", "APPR", "ADJA", "VVINF", "$("], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.91": {"text": "Die einfalt ist ihr recht/ wovor sie sich nicht sch\u00e4men.", "tokens": ["Die", "ein\u00b7falt", "ist", "ihr", "recht", "/", "wo\u00b7vor", "sie", "sich", "nicht", "sch\u00e4\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD", "$(", "PWAV", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Der mensch/ der mensch allein/ der nur nach narrheit fragt/", "tokens": ["Der", "mensch", "/", "der", "mensch", "al\u00b7lein", "/", "der", "nur", "nach", "nar\u00b7rheit", "fragt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "ADV", "$(", "ART", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Macht ehr und ruhm daraus/ da\u00df er sich selber plagt;", "tokens": ["Macht", "ehr", "und", "ruhm", "da\u00b7raus", "/", "da\u00df", "er", "sich", "sel\u00b7ber", "plagt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "PAV", "$(", "KOUS", "PPER", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Di\u00df war noch nicht genug/ da\u00df er aus h\u00f6llschen triebe/", "tokens": ["Di\u00df", "war", "noch", "nicht", "ge\u00b7nug", "/", "da\u00df", "er", "aus", "h\u00f6ll\u00b7schen", "trie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PTKNEG", "ADV", "$(", "KOUS", "PPER", "APPR", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Das lange eisen schliff/ und den salpeter riebe.", "tokens": ["Das", "lan\u00b7ge", "ei\u00b7sen", "schliff", "/", "und", "den", "sal\u00b7pe\u00b7ter", "rie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Nein/ da\u00df doch ja sein thun der gantzen erde schadt/", "tokens": ["Nein", "/", "da\u00df", "doch", "ja", "sein", "thun", "der", "gant\u00b7zen", "er\u00b7de", "schadt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "KOUS", "ADV", "ADV", "VAINF", "VVFIN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Schmiert er so lange drauff bi\u00df er Pandecten hat/", "tokens": ["Schmiert", "er", "so", "lan\u00b7ge", "drauff", "bi\u00df", "er", "Pan\u00b7dec\u00b7ten", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "PAV", "KOUS", "PPER", "NN", "VAFIN", "$("], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.98": {"text": "Die \u00fcberstrich er noch mit den erleuchten glossen/", "tokens": ["Die", "\u00fc\u00b7bers\u00b7trich", "er", "noch", "mit", "den", "er\u00b7leuch\u00b7ten", "glos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.99": {"text": "Und warff das reine recht in seine narrenpossen.", "tokens": ["Und", "warff", "das", "rei\u00b7ne", "recht", "in", "sei\u00b7ne", "nar\u00b7ren\u00b7pos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Er f\u00fchrte/ da\u00df auch wir ja gut getroffen seyn/", "tokens": ["Er", "f\u00fchr\u00b7te", "/", "da\u00df", "auch", "wir", "ja", "gut", "ge\u00b7trof\u00b7fen", "seyn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "ADV", "PPER", "ADV", "ADJD", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Der zungen-drescher heer in unsern l\u00e4ndern ein.", "tokens": ["Der", "zun\u00b7gen\u00b7dre\u00b7scher", "heer", "in", "un\u00b7sern", "l\u00e4n\u00b7dern", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Ein wenig glimpfflicher/ sagst du/ was n\u00fctzt das schm\u00e4hlen?", "tokens": ["Ein", "we\u00b7nig", "glimpf\u00b7fli\u00b7cher", "/", "sagst", "du", "/", "was", "n\u00fctzt", "das", "schm\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "$(", "VVFIN", "PPER", "$(", "PWS", "VVFIN", "PDS", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.103": {"text": "Die menschen irren zwar/ es kan ja wohl nicht fehlen/", "tokens": ["Die", "men\u00b7schen", "ir\u00b7ren", "zwar", "/", "es", "kan", "ja", "wohl", "nicht", "feh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$(", "PPER", "VMFIN", "ADV", "ADV", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Und haben wir das meer bald sturm/ bald ebb und flut/", "tokens": ["Und", "ha\u00b7ben", "wir", "das", "meer", "bald", "sturm", "/", "bald", "ebb", "und", "flut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "ADV", "ADJD", "$(", "ADV", "ADJD", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Doch macht auch alles di\u00df ein eintzge tugend gut.", "tokens": ["Doch", "macht", "auch", "al\u00b7les", "di\u00df", "ein", "eintz\u00b7ge", "tu\u00b7gend", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIS", "PDS", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Ist nicht ein mensch der mann/ der mit so k\u00fchnen wissen", "tokens": ["Ist", "nicht", "ein", "mensch", "der", "mann", "/", "der", "mit", "so", "k\u00fch\u00b7nen", "wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "ART", "NN", "$(", "ART", "APPR", "ADV", "ADJA", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "In einem zirckel-krey\u00df den himmel hat gerissen/", "tokens": ["In", "ei\u00b7nem", "zir\u00b7ckel\u00b7krey\u00df", "den", "him\u00b7mel", "hat", "ge\u00b7ris\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Der durch die weite kunst das/ was nur ist/ enth\u00e4lt/", "tokens": ["Der", "durch", "die", "wei\u00b7te", "kunst", "das", "/", "was", "nur", "ist", "/", "ent\u00b7h\u00e4lt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "ART", "$(", "PWS", "ADV", "VAFIN", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Der die natur erforscht/ von ihr das urtheil f\u00e4llt.", "tokens": ["Der", "die", "na\u00b7tur", "er\u00b7forscht", "/", "von", "ihr", "das", "ur\u00b7theil", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$(", "APPR", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Die universit\u00e4t gilt nicht bey denen thieren/", "tokens": ["Die", "u\u00b7niv\u00b7er\u00b7si\u00b7t\u00e4t", "gilt", "nicht", "bey", "de\u00b7nen", "thie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "APPR", "PRELS", "NN", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.111": {"text": "Wo k\u00f6nnen sie mir wohl vier facult\u00e4ten zieren?", "tokens": ["Wo", "k\u00f6n\u00b7nen", "sie", "mir", "wohl", "vier", "fa\u00b7cul\u00b7t\u00e4\u00b7ten", "zie\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PPER", "ADV", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Sind sie im recht gelehrt und in der medicin?", "tokens": ["Sind", "sie", "im", "recht", "ge\u00b7lehrt", "und", "in", "der", "me\u00b7di\u00b7cin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "ADJD", "VVPP", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Legt man ihn scharlach an/ de\u00dfgleichen hermelin?", "tokens": ["Legt", "man", "ihn", "schar\u00b7lach", "an", "/", "de\u00df\u00b7glei\u00b7chen", "her\u00b7me\u00b7lin", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "VVFIN", "PTKVZ", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Nein/ nein! das hat wohl nie bey ihn ein artzt gestifftet/", "tokens": ["Nein", "/", "nein", "!", "das", "hat", "wohl", "nie", "bey", "ihn", "ein", "artzt", "ge\u00b7stiff\u00b7tet", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "PTKANT", "$.", "PDS", "VAFIN", "ADV", "ADV", "APPR", "PPER", "ART", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Und durch die t\u00f6dtungs-kunst den gantzen wald vergifftet.", "tokens": ["Und", "durch", "die", "t\u00f6d\u00b7tungs\u00b7kunst", "den", "gant\u00b7zen", "wald", "ver\u00b7giff\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Nie hat sich unter ihn ein doctor heisch gemacht/", "tokens": ["Nie", "hat", "sich", "un\u00b7ter", "ihn", "ein", "doc\u00b7tor", "heisch", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "APPR", "PPER", "ART", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Und einen l\u00e4pschen schlu\u00df mit auff die banck gebracht.", "tokens": ["Und", "ei\u00b7nen", "l\u00e4p\u00b7schen", "schlu\u00df", "mit", "auff", "die", "banck", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Hier schweig ich/ ob der geist di\u00df/ was er wei\u00df auch wisse/", "tokens": ["Hier", "schweig", "ich", "/", "ob", "der", "geist", "di\u00df", "/", "was", "er", "wei\u00df", "auch", "wis\u00b7se", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "KOUS", "ART", "NN", "PDS", "$(", "PWS", "PPER", "VVFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Ja ob er gar nichts wei\u00df/ es sind nur hindernisse.", "tokens": ["Ja", "ob", "er", "gar", "nichts", "wei\u00df", "/", "es", "sind", "nur", "hin\u00b7der\u00b7nis\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "PPER", "ADV", "PIS", "VVFIN", "$(", "PPER", "VAFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Du rede nunmehr selbst/ ob itzge zeit verg\u00f6nnt/", "tokens": ["Du", "re\u00b7de", "nun\u00b7mehr", "selbst", "/", "ob", "itz\u00b7ge", "zeit", "ver\u00b7g\u00f6nnt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$(", "KOUS", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Da\u00df man nach tugenden rechtschaffne leute nennt?", "tokens": ["Da\u00df", "man", "nach", "tu\u00b7gen\u00b7den", "recht\u00b7schaff\u00b7ne", "leu\u00b7te", "nennt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Wilstu was grosses seyn/ lie\u00df sich ein vater h\u00f6ren/", "tokens": ["Wils\u00b7tu", "was", "gros\u00b7ses", "seyn", "/", "lie\u00df", "sich", "ein", "va\u00b7ter", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADJA", "VAINF", "$(", "VVFIN", "PRF", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Und gab dem glatten sohn nur nechst die sch\u00f6nen lehren:", "tokens": ["Und", "gab", "dem", "glat\u00b7ten", "sohn", "nur", "nechst", "die", "sch\u00f6\u00b7nen", "leh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ADV", "ADV", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Nimm mir den rechten ort/ la\u00df alle b\u00fccher stehn/", "tokens": ["Nimm", "mir", "den", "rech\u00b7ten", "ort", "/", "la\u00df", "al\u00b7le", "b\u00fc\u00b7cher", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "$(", "VVIMP", "PIAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Wenn zwantzig einen giebt/ was macht zweyhundert zehn.", "tokens": ["Wenn", "zwant\u00b7zig", "ei\u00b7nen", "giebt", "/", "was", "macht", "zwey\u00b7hun\u00b7dert", "zehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "PIS", "VVFIN", "$(", "PWS", "VVFIN", "CARD", "CARD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Wie in Numidien sich auch der l\u00f6w entzieht/", "tokens": ["Wie", "in", "Nu\u00b7mi\u00b7di\u00b7en", "sich", "auch", "der", "l\u00f6w", "ent\u00b7zieht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NE", "PRF", "ADV", "ART", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Und nicht entdeckt zu seyn/ nach mord und raube flieht/", "tokens": ["Und", "nicht", "ent\u00b7deckt", "zu", "seyn", "/", "nach", "mord", "und", "rau\u00b7be", "flieht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "VVPP", "PTKZU", "VAINF", "$(", "APPR", "NE", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Das eingebildte haupt/ das ihm mu\u00df satzung lehren/", "tokens": ["Das", "ein\u00b7ge\u00b7bild\u00b7te", "haupt", "/", "das", "ihm", "mu\u00df", "sat\u00b7zung", "leh\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PRELS", "PPER", "VMFIN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Was mu\u00df er/ als ihr herr/ nicht selbst vor herren ehren.", "tokens": ["Was", "mu\u00df", "er", "/", "als", "ihr", "herr", "/", "nicht", "selbst", "vor", "her\u00b7ren", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "$(", "KOUS", "PPOSAT", "NN", "$(", "PTKNEG", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Die ehrsucht/ lieb und geitz/ und was dem zorn gef\u00e4llt/", "tokens": ["Die", "ehr\u00b7sucht", "/", "lieb", "und", "geitz", "/", "und", "was", "dem", "zorn", "ge\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADJD", "KON", "VVIMP", "$(", "KON", "PWS", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Ist seines geistes stock/ der ihn gefangen h\u00e4lt.", "tokens": ["Ist", "sei\u00b7nes", "geis\u00b7tes", "stock", "/", "der", "ihn", "ge\u00b7fan\u00b7gen", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "$(", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Kaum hat der schwere schlaff zu dr\u00fccken angefangen/", "tokens": ["Kaum", "hat", "der", "schwe\u00b7re", "schlaff", "zu", "dr\u00fc\u00b7cken", "an\u00b7ge\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "ADJD", "PTKZU", "VVINF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Steh auff/ spricht schon der geitz/ bistu noch nicht gegangen?", "tokens": ["Steh", "auff", "/", "spricht", "schon", "der", "geitz", "/", "bis\u00b7tu", "noch", "nicht", "ge\u00b7gan\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "$(", "VVFIN", "ADV", "ART", "NN", "$(", "ADV", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Ey la\u00df mich doch. Steh auff! ein wenig bittest du/", "tokens": ["Ey", "la\u00df", "mich", "doch", ".", "Steh", "auff", "!", "ein", "we\u00b7nig", "bit\u00b7test", "du", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVIMP", "PPER", "ADV", "$.", "VVFIN", "PTKVZ", "$.", "ART", "PIS", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Der tag sperrt schon das thor/ dein laden ist noch zu;", "tokens": ["Der", "tag", "sperrt", "schon", "das", "thor", "/", "dein", "la\u00b7den", "ist", "noch", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "$(", "PPOSAT", "ADJA", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Was hinderts? hebe dich. Wilt du der letzte bleiben/", "tokens": ["Was", "hin\u00b7derts", "?", "he\u00b7be", "dich", ".", "Wilt", "du", "der", "letz\u00b7te", "blei\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$.", "VVFIN", "PPER", "$.", "VMFIN", "PPER", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Das grosse Meer der welt zum ende durchzutreiben/", "tokens": ["Das", "gros\u00b7se", "Meer", "der", "welt", "zum", "en\u00b7de", "durch\u00b7zu\u00b7trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Wo Japan porcellan und ambra zu uns schickt/", "tokens": ["Wo", "Ja\u00b7pan", "por\u00b7cel\u00b7lan", "und", "am\u00b7bra", "zu", "uns", "schickt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "KON", "NE", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.139": {"text": "Und Goa ingwer gr\u00e4bt/ und pfeffer-k\u00f6rner pflickt.", "tokens": ["Und", "Goa", "ing\u00b7wer", "gr\u00e4bt", "/", "und", "pfef\u00b7fer\u00b7k\u00f6r\u00b7ner", "pflickt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADJD", "VVFIN", "$(", "KON", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.140": {"text": "Ich hab ja gut genug/ das kan ich schon entbehren/", "tokens": ["Ich", "hab", "ja", "gut", "ge\u00b7nug", "/", "das", "kan", "ich", "schon", "ent\u00b7beh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADV", "$(", "PDS", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Man hat niemahl zu viel/ sich dessen zu gewehren/", "tokens": ["Man", "hat", "nie\u00b7mahl", "zu", "viel", "/", "sich", "des\u00b7sen", "zu", "ge\u00b7weh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "PTKA", "PIS", "$(", "PRF", "PDS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "Spar man kein laster nicht/ kein meineyd halt uns ein/", "tokens": ["Spar", "man", "kein", "las\u00b7ter", "nicht", "/", "kein", "mei\u00b7neyd", "halt", "uns", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "PIAT", "NN", "PTKNEG", "$(", "PIAT", "PIS", "VVFIN", "PPER", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Man stehe hunger aus/ das bette sey ein stein/", "tokens": ["Man", "ste\u00b7he", "hun\u00b7ger", "aus", "/", "das", "bet\u00b7te", "sey", "ein", "stein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADJD", "PTKVZ", "$(", "PDS", "VVFIN", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "W\u00e4r unser schatz noch mehr als Galet auffgerieben/", "tokens": ["W\u00e4r", "un\u00b7ser", "schatz", "noch", "mehr", "als", "Ga\u00b7let", "auff\u00b7ge\u00b7rie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "PIAT", "KOKOM", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Soll man selbst diener seyn/ und keinen hausrath lieben.", "tokens": ["Soll", "man", "selbst", "die\u00b7ner", "seyn", "/", "und", "kei\u00b7nen", "haus\u00b7rath", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "ADJD", "VAINF", "$(", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Da\u00df man den weitzen spaart/ schmeckt uns wohl haber-brod/", "tokens": ["Da\u00df", "man", "den", "weit\u00b7zen", "spaart", "/", "schmeckt", "uns", "wohl", "ha\u00b7ber\u00b7brod", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "ADJA", "NN", "$(", "VVFIN", "PPER", "ADV", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Ein heller ist zu viel auch vor die todes-noth.", "tokens": ["Ein", "hel\u00b7ler", "ist", "zu", "viel", "auch", "vor", "die", "to\u00b7des\u00b7noth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "PTKA", "PIS", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "Was nutzt denn nun der geitz? Weist du noch nicht die f\u00e4lle?", "tokens": ["Was", "nutzt", "denn", "nun", "der", "geitz", "?", "Weist", "du", "noch", "nicht", "die", "f\u00e4l\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "ART", "NN", "$.", "VAFIN", "PPER", "ADV", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Der erbe labt sich ja zuletzt an deiner stelle;", "tokens": ["Der", "er\u00b7be", "labt", "sich", "ja", "zu\u00b7letzt", "an", "dei\u00b7ner", "stel\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "ADV", "ADV", "APPR", "PPOSAT", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Er legt die sch\u00e4tze an/ die dir nichts nutze sind/", "tokens": ["Er", "legt", "die", "sch\u00e4t\u00b7ze", "an", "/", "die", "dir", "nichts", "nut\u00b7ze", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "VVFIN", "PTKVZ", "$(", "PRELS", "PPER", "PIS", "VVFIN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Und putzt die gassen aus mit seinem hausgesind.", "tokens": ["Und", "putzt", "die", "gas\u00b7sen", "aus", "mit", "sei\u00b7nem", "haus\u00b7ge\u00b7sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.152": {"text": "Ey was! mach einmahl aus/ das schiff f\u00e4ngt an zu fliehen/", "tokens": ["Ey", "was", "!", "mach", "ein\u00b7mahl", "aus", "/", "das", "schiff", "f\u00e4ngt", "an", "zu", "flie\u00b7hen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWS", "$.", "VVFIN", "ADV", "PTKVZ", "$(", "PDS", "VVFIN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Und ist das geld zu schwach den starcken held zu ziehen;", "tokens": ["Und", "ist", "das", "geld", "zu", "schwach", "den", "star\u00b7cken", "held", "zu", "zie\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PTKZU", "VVFIN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "So setzt der ehrgeitz an mit seiner gantzen brut:", "tokens": ["So", "setzt", "der", "ehr\u00b7geitz", "an", "mit", "sei\u00b7ner", "gant\u00b7zen", "brut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Und eh er sichs versieht/ gebraucht er volle wuth.", "tokens": ["Und", "eh", "er", "sichs", "ver\u00b7sieht", "/", "ge\u00b7braucht", "er", "vol\u00b7le", "wuth", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIS", "VVFIN", "$(", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "L\u00e4st sich ihm halb verruckt in tausend jammer dringen/", "tokens": ["L\u00e4st", "sich", "ihm", "halb", "ver\u00b7ruckt", "in", "tau\u00b7send", "jam\u00b7mer", "drin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPER", "ADJD", "VVPP", "APPR", "CARD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "Und auff des C\u00e4sars pfand nach noth und \u00e4ngsten zwingen:", "tokens": ["Und", "auff", "des", "C\u00e4\u00b7sars", "pfand", "nach", "noth", "und", "\u00e4ngs\u00b7ten", "zwin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "APPR", "NN", "KON", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Wenn er nun in dem sturm das ehren-bette dr\u00fcckt/", "tokens": ["Wenn", "er", "nun", "in", "dem", "sturm", "das", "eh\u00b7ren\u00b7bet\u00b7te", "dr\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "ART", "ADJA", "VVFIN", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.159": {"text": "So wird die n\u00e4rrsche that der zeitung eingeflickt.", "tokens": ["So", "wird", "die", "n\u00e4rr\u00b7sche", "that", "der", "zei\u00b7tung", "ein\u00b7ge\u00b7flickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "VVFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Sacht an! spricht einer drauff; hier kanstu dich nur melden/", "tokens": ["Sacht", "an", "!", "spricht", "ei\u00b7ner", "drauff", ";", "hier", "kans\u00b7tu", "dich", "nur", "mel\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$.", "VVFIN", "PIS", "PTKVZ", "$.", "ADV", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Das/ was du laster nennst/ ist ja ein werck der helden:", "tokens": ["Das", "/", "was", "du", "las\u00b7ter", "nennst", "/", "ist", "ja", "ein", "werck", "der", "hel\u00b7den", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "PWS", "PPER", "ADJD", "VVFIN", "$(", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "War Alexander n\u00e4rrsch/ wie deine meynung spricht?", "tokens": ["War", "A\u00b7lex\u00b7an\u00b7der", "n\u00e4rrsch", "/", "wie", "dei\u00b7ne", "mey\u00b7nung", "spricht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ADJD", "$(", "KOKOM", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "Der schwindels\u00fcchtge mann/ der Asien vernicht?", "tokens": ["Der", "schwin\u00b7del\u00b7s\u00fccht\u00b7ge", "mann", "/", "der", "A\u00b7sien", "ver\u00b7nicht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.164": {"text": "Das unbesonne thier/ das stets im blute w\u00fchlte/", "tokens": ["Das", "un\u00b7be\u00b7son\u00b7ne", "thier", "/", "das", "stets", "im", "blu\u00b7te", "w\u00fchl\u00b7te", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PDS", "ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Als herre von der welt sich doch zu enge f\u00fchlte/", "tokens": ["Als", "her\u00b7re", "von", "der", "welt", "sich", "doch", "zu", "en\u00b7ge", "f\u00fchl\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "PRF", "ADV", "APPR", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "Er gieng voll raserey als erb-printz aus dem land;", "tokens": ["Er", "gieng", "voll", "ra\u00b7se\u00b7rey", "als", "er\u00b7bprintz", "aus", "dem", "land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ADJD", "KOKOM", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.167": {"text": "Worinne man ihm schon/ wie klug er sey/ erkandt.", "tokens": ["Wo\u00b7rin\u00b7ne", "man", "ihm", "schon", "/", "wie", "klug", "er", "sey", "/", "er\u00b7kandt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "$(", "PWAV", "ADJD", "PPER", "VAFIN", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "So lieff er th\u00f6richt fort/ und wolte g\u00f6ttern gleichen/", "tokens": ["So", "lieff", "er", "th\u00f6\u00b7richt", "fort", "/", "und", "wol\u00b7te", "g\u00f6t\u00b7tern", "glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$(", "KON", "VMFIN", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Und konte wie ein dieb kaum glut nicht heerd erreichen;", "tokens": ["Und", "kon\u00b7te", "wie", "ein", "dieb", "kaum", "glut", "nicht", "heerd", "er\u00b7rei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "KOKOM", "ART", "NN", "ADV", "NN", "PTKNEG", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.170": {"text": "Wohin er sich gekehrt/ hat er den krieg gebracht/", "tokens": ["Wo\u00b7hin", "er", "sich", "ge\u00b7kehrt", "/", "hat", "er", "den", "krieg", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVPP", "$(", "VAFIN", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Und fast die gantze welt mit narrheit voll gemacht.", "tokens": ["Und", "fast", "die", "gant\u00b7ze", "welt", "mit", "nar\u00b7rheit", "voll", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "APPR", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "O! wie w\u00e4rs gut gewest/ da\u00df es bey seinem leben", "tokens": ["O", "!", "wie", "w\u00e4rs", "gut", "ge\u00b7west", "/", "da\u00df", "es", "bey", "sei\u00b7nem", "le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "PWAV", "VAFIN", "ADJD", "VVPP", "$(", "KOUS", "PPER", "APPR", "PPOSAT", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "In Macedonien doch h\u00e4tt ein toll-hau\u00df geben/", "tokens": ["In", "Ma\u00b7ce\u00b7do\u00b7ni\u00b7en", "doch", "h\u00e4tt", "ein", "toll\u00b7hau\u00df", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "VAFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Wo ihn bey rechter zeit ein vormund eingesperrt/", "tokens": ["Wo", "ihn", "bey", "rech\u00b7ter", "zeit", "ein", "vor\u00b7mund", "ein\u00b7ge\u00b7sperrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN", "ART", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Und auff der freunde wort das wilde thier gekerrt.", "tokens": ["Und", "auff", "der", "freun\u00b7de", "wort", "das", "wil\u00b7de", "thier", "ge\u00b7kerrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Damit wir aber nicht hiedurch vom zwecke gehen/", "tokens": ["Da\u00b7mit", "wir", "a\u00b7ber", "nicht", "hie\u00b7durch", "vom", "zwe\u00b7cke", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "PAV", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Noch ieder neigung art/ wie Senaut thut/ besehen/", "tokens": ["Noch", "ie\u00b7der", "nei\u00b7gung", "art", "/", "wie", "Sen\u00b7aut", "thut", "/", "be\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "NN", "$(", "KOKOM", "NN", "VVFIN", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Und schliessen dieses werck in classen oder titl/", "tokens": ["Und", "schlies\u00b7sen", "die\u00b7ses", "werck", "in", "clas\u00b7sen", "o\u00b7der", "titl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "NN", "APPR", "NE", "KON", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "In versen/ predigen und reimen durch capitl.", "tokens": ["In", "ver\u00b7sen", "/", "pre\u00b7di\u00b7gen", "und", "rei\u00b7men", "durch", "ca\u00b7pitl", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVINF", "$(", "VVFIN", "KON", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "So la\u00df mir C\u00f6ffeteau und Schambre davon h\u00f6ren/", "tokens": ["So", "la\u00df", "mir", "C\u00f6f\u00b7fe\u00b7te\u00b7au", "und", "Schamb\u00b7re", "da\u00b7von", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "NE", "KON", "NN", "PAV", "VVINF", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.181": {"text": "Ich will den sch\u00f6nsten ort an unsern menschen lehren:", "tokens": ["Ich", "will", "den", "sch\u00f6ns\u00b7ten", "ort", "an", "un\u00b7sern", "men\u00b7schen", "leh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Er lebt nur/ saget man/ in einer festen stadt/", "tokens": ["Er", "lebt", "nur", "/", "sa\u00b7get", "man", "/", "in", "ei\u00b7ner", "fes\u00b7ten", "stadt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "VVFIN", "PIS", "$(", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.183": {"text": "Und zeigt was er vor thun/ und guten sitten hat.", "tokens": ["Und", "zeigt", "was", "er", "vor", "thun", "/", "und", "gu\u00b7ten", "sit\u00b7ten", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWS", "PPER", "APPR", "VVINF", "$(", "KON", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "Er setzt sich k\u00f6nige/ und kan sich f\u00fcrsten geben/", "tokens": ["Er", "setzt", "sich", "k\u00f6\u00b7ni\u00b7ge", "/", "und", "kan", "sich", "f\u00fcrs\u00b7ten", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJA", "$(", "KON", "VMFIN", "PRF", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Pflegt nach der policey und nach dem recht zu leben;", "tokens": ["Pflegt", "nach", "der", "po\u00b7li\u00b7cey", "und", "nach", "dem", "recht", "zu", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "ART", "NN", "KON", "APPR", "ART", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Ja wohl/ doch ohne recht/ und ohne policey.", "tokens": ["Ja", "wohl", "/", "doch", "oh\u00b7ne", "recht", "/", "und", "oh\u00b7ne", "po\u00b7li\u00b7cey", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$(", "ADV", "APPR", "ADJD", "$(", "KON", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "So recht/ du hast die kunst/ und was man nur mu\u00df wissen/", "tokens": ["So", "recht", "/", "du", "hast", "die", "kunst", "/", "und", "was", "man", "nur", "mu\u00df", "wis\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "PPER", "VAFIN", "ART", "NN", "$(", "KON", "PWS", "PIS", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.188": {"text": "Was wird vor ehre/ gut und reichthum auff dich fliessen!", "tokens": ["Was", "wird", "vor", "eh\u00b7re", "/", "gut", "und", "reicht\u00b7hum", "auff", "dich", "flies\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "VVFIN", "$(", "ADJD", "KON", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "Ub dich mein liebes kind in dieser wissenschafft/", "tokens": ["Ub", "dich", "mein", "lie\u00b7bes", "kind", "in", "die\u00b7ser", "wis\u00b7sen\u00b7schafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPOSAT", "ADJA", "NN", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "Ein gutes rechen-buch hat mehr als Plato krafft.", "tokens": ["Ein", "gu\u00b7tes", "re\u00b7chen\u00b7buch", "hat", "mehr", "als", "Pla\u00b7to", "krafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PIAT", "KOKOM", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "Erfahre dir das land/ das die gewerbe nehret/", "tokens": ["Er\u00b7fah\u00b7re", "dir", "das", "land", "/", "das", "die", "ge\u00b7wer\u00b7be", "neh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$(", "PRELS", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.192": {"text": "Wie viel dem k\u00f6nige durchs jahr vom saltz geh\u00f6ret;", "tokens": ["Wie", "viel", "dem", "k\u00f6\u00b7ni\u00b7ge", "durchs", "jahr", "vom", "saltz", "ge\u00b7h\u00f6\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "APPRART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "Verh\u00e4rte geist und sinn/ sey barbar und Corsar/", "tokens": ["Ver\u00b7h\u00e4r\u00b7te", "geist", "und", "sinn", "/", "sey", "bar\u00b7bar", "und", "Cor\u00b7sar", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "KON", "NN", "$(", "VAFIN", "ADJD", "KON", "NE", "$("], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.194": {"text": "Meineidig/ ungerecht/ verwegen/ ohne wahr.", "tokens": ["Mei\u00b7nei\u00b7dig", "/", "un\u00b7ge\u00b7recht", "/", "ver\u00b7we\u00b7gen", "/", "oh\u00b7ne", "wahr", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$(", "ADJD", "$(", "VVINF", "$(", "APPR", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Sey ja der gro\u00dfmuth nicht/ als wie ein kind beflissen/", "tokens": ["Sey", "ja", "der", "gro\u00df\u00b7muth", "nicht", "/", "als", "wie", "ein", "kind", "be\u00b7flis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PTKNEG", "$(", "KOUS", "KOKOM", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Geh/ meste dich/ mein sohn/ mit armer leute bissen.", "tokens": ["Geh", "/", "mes\u00b7te", "dich", "/", "mein", "sohn", "/", "mit", "ar\u00b7mer", "leu\u00b7te", "bis\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "VVFIN", "PPER", "$(", "PPOSAT", "NN", "$(", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.197": {"text": "Ber\u00fccke/ wo du kanst/ accise/ steuer/ scho\u00df/", "tokens": ["Be\u00b7r\u00fc\u00b7cke", "/", "wo", "du", "kanst", "/", "ac\u00b7ci\u00b7se", "/", "steu\u00b7er", "/", "scho\u00df", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "PWAV", "PPER", "VMFIN", "$(", "XY", "$(", "ADJD", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.198": {"text": "Mach dich durch grausamkeit auff alle weise gro\u00df.", "tokens": ["Mach", "dich", "durch", "grau\u00b7sam\u00b7keit", "auff", "al\u00b7le", "wei\u00b7se", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "APPR", "PIS", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.199": {"text": "Du wirst alsbalde sehn/ wie Medici/ Poeten/", "tokens": ["Du", "wirst", "als\u00b7bal\u00b7de", "sehn", "/", "wie", "Me\u00b7di\u00b7ci", "/", "Po\u00b7et\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "VVINF", "$(", "KOKOM", "NE", "$(", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Juristen/ Prediger/ Astronomi/ Propheten", "tokens": ["Ju\u00b7ris\u00b7ten", "/", "Pre\u00b7di\u00b7ger", "/", "Ast\u00b7ro\u00b7no\u00b7mi", "/", "Pro\u00b7phe\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$(", "NN", "$(", "NE", "$(", "NN"], "meter": "+--+--+-++-+-", "measure": "dactylic.di.plus"}, "line.201": {"text": "Die helden runter thun/ und dich daf\u00fcr erh\u00f6hn;", "tokens": ["Die", "hel\u00b7den", "run\u00b7ter", "thun", "/", "und", "dich", "da\u00b7f\u00fcr", "er\u00b7h\u00f6hn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$(", "KON", "PRF", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Dein titul wird voran in allen b\u00fcchern stehn.", "tokens": ["Dein", "ti\u00b7tul", "wird", "vo\u00b7ran", "in", "al\u00b7len", "b\u00fc\u00b7chern", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.203": {"text": "Sie werden selbsten dir latein und griechisch zeigen/", "tokens": ["Sie", "wer\u00b7den", "selbs\u00b7ten", "dir", "la\u00b7tein", "und", "grie\u00b7chisch", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "PTKVZ", "KON", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.204": {"text": "Da\u00df du in ihrer kunst den gipffel kanst ersteigen;", "tokens": ["Da\u00df", "du", "in", "ih\u00b7rer", "kunst", "den", "gipf\u00b7fel", "kanst", "er\u00b7stei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.205": {"text": "Der reich\u2019 ist/ was er will/ in gr\u00f6ster tumheit klug/", "tokens": ["Der", "reich'", "ist", "/", "was", "er", "will", "/", "in", "gr\u00f6s\u00b7ter", "tum\u00b7heit", "klug", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$(", "PWS", "PPER", "VMFIN", "$(", "APPR", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.206": {"text": "Und hat im leeren kopff doch wissenschafft genug/", "tokens": ["Und", "hat", "im", "lee\u00b7ren", "kopff", "doch", "wis\u00b7sen\u00b7schafft", "ge\u00b7nug", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "ADJA", "NN", "ADV", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.207": {"text": "Er hat geschickligkeit/ erk\u00e4nntni\u00df/ k\u00fcnste/ lehre/", "tokens": ["Er", "hat", "ge\u00b7schick\u00b7lig\u00b7keit", "/", "er\u00b7k\u00e4nnt\u00b7ni\u00df", "/", "k\u00fcns\u00b7te", "/", "leh\u00b7re", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "VVFIN", "$(", "VVFIN", "$(", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.208": {"text": "Erfahrung/ hertze/ blut/ krafft/ adel/ ahnen/ ehre.", "tokens": ["Er\u00b7fah\u00b7rung", "/", "hert\u00b7ze", "/", "blut", "/", "krafft", "/", "a\u00b7del", "/", "ah\u00b7nen", "/", "eh\u00b7re", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "$(", "NN", "$(", "NN", "$(", "NE", "$(", "VVINF", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "Die grossen lieben ihn/ die sch\u00f6nen sind ihm hold/", "tokens": ["Die", "gros\u00b7sen", "lie\u00b7ben", "ihn", "/", "die", "sch\u00f6\u00b7nen", "sind", "ihm", "hold", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "$(", "ART", "ADJA", "VAFIN", "PPER", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.210": {"text": "Denn die den kerl gleich hast/ verehret doch sein gold.", "tokens": ["Denn", "die", "den", "kerl", "gleich", "hast", "/", "ver\u00b7eh\u00b7ret", "doch", "sein", "gold", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "ADV", "VAFIN", "$(", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.211": {"text": "Geld kan der he\u00dfligkeit die gr\u00f6ste schmincke machen/", "tokens": ["Geld", "kan", "der", "he\u00df\u00b7lig\u00b7keit", "die", "gr\u00f6s\u00b7te", "schmin\u00b7cke", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.212": {"text": "Was aber/ mu\u00df man nicht der armen klugheit lachen?", "tokens": ["Was", "a\u00b7ber", "/", "mu\u00df", "man", "nicht", "der", "ar\u00b7men", "klug\u00b7heit", "la\u00b7chen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$(", "VMFIN", "PIS", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.213": {"text": "So lehrte seinem sohn ein geld erfahrner mann/", "tokens": ["So", "lehr\u00b7te", "sei\u00b7nem", "sohn", "ein", "geld", "er\u00b7fahr\u00b7ner", "mann", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.214": {"text": "Wie er auff leichter bahn zum reichthum kommen kan.", "tokens": ["Wie", "er", "auff", "leich\u00b7ter", "bahn", "zum", "reicht\u00b7hum", "kom\u00b7men", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.215": {"text": "Und mancher findet sie/ der nicht mehr kunst getrieben/", "tokens": ["Und", "man\u00b7cher", "fin\u00b7det", "sie", "/", "der", "nicht", "mehr", "kunst", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "$(", "ART", "PTKNEG", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.216": {"text": "Als: f\u00fcnff und vier macht neun/ und zwey davon bleibt sieben", "tokens": ["Als", ":", "f\u00fcnff", "und", "vier", "macht", "neun", "/", "und", "zwey", "da\u00b7von", "bleibt", "sie\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$.", "CARD", "KON", "CARD", "VVFIN", "CARD", "$(", "KON", "CARD", "PAV", "VVFIN", "CARD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Herr Doctor geh\u2019 nun hin/ und schwitz in heilger schrifft/", "tokens": ["Herr", "Doc\u00b7tor", "geh'", "nun", "hin", "/", "und", "schwitz", "in", "heil\u00b7ger", "schrifft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "ADV", "PTKVZ", "$(", "KON", "ADJD", "APPR", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.218": {"text": "Zeig was sich vor gefahr in diesem meere trifft.", "tokens": ["Zeig", "was", "sich", "vor", "ge\u00b7fahr", "in", "die\u00b7sem", "mee\u00b7re", "trifft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRELS", "PRF", "APPR", "NN", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.219": {"text": "Durchbrich/ so viel du kanst/ der bibel heilges schrecken/", "tokens": ["Durch\u00b7brich", "/", "so", "viel", "du", "kanst", "/", "der", "bi\u00b7bel", "heil\u00b7ges", "schre\u00b7cken", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "ADV", "ADV", "PPER", "VMFIN", "$(", "ART", "NN", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.220": {"text": "La\u00df Luthern und Calvin in einen mischmasch stecken/", "tokens": ["La\u00df", "Lu\u00b7thern", "und", "Cal\u00b7vin", "in", "ei\u00b7nen", "mischmasch", "ste\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "KON", "NE", "APPR", "ART", "ADJD", "VVINF", "$("], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.221": {"text": "Entscheide noch itzund der alten zanck und streit/", "tokens": ["Ent\u00b7schei\u00b7de", "noch", "it\u00b7zund", "der", "al\u00b7ten", "zanck", "und", "streit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "Erkl\u00e4r das j\u00fcdenthum/ gelehrte dunckelheit.", "tokens": ["Er\u00b7kl\u00e4r", "das", "j\u00fc\u00b7den\u00b7thum", "/", "ge\u00b7lehr\u00b7te", "dun\u00b7ckel\u00b7heit", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.223": {"text": "Im alter la\u00df di\u00df werck in schwartzes leder binden/", "tokens": ["Im", "al\u00b7ter", "la\u00df", "di\u00df", "werck", "in", "schwart\u00b7zes", "le\u00b7der", "bin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVIMP", "PDS", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Schreibs einem knicker zu/ so reich du ihn kanst finden/", "tokens": ["Schreibs", "ei\u00b7nem", "kni\u00b7cker", "zu", "/", "so", "reich", "du", "ihn", "kanst", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PTKZU", "$(", "ADV", "ADJD", "PPER", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.225": {"text": "Der lobt die gute that/ der h\u00e4lt sich ritterlich/", "tokens": ["Der", "lobt", "die", "gu\u00b7te", "that", "/", "der", "h\u00e4lt", "sich", "rit\u00b7ter\u00b7lich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "VVFIN", "$(", "ART", "VVFIN", "PRF", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "Und zahlt dir deine m\u00fch/ mit: Ich bedancke mich.", "tokens": ["Und", "zahlt", "dir", "dei\u00b7ne", "m\u00fch", "/", "mit", ":", "Ich", "be\u00b7dan\u00b7cke", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "ADJD", "$(", "PTKVZ", "$.", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Will nun dein geist statt des nach be\u00dfrer ehre sehen/", "tokens": ["Will", "nun", "dein", "geist", "statt", "des", "nach", "be\u00df\u00b7rer", "eh\u00b7re", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "NN", "APPR", "ART", "APPR", "ADJA", "VVFIN", "VVINF", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.228": {"text": "So la\u00df catheder/ buch und hohe schule stehen/", "tokens": ["So", "la\u00df", "cat\u00b7he\u00b7der", "/", "buch", "und", "ho\u00b7he", "schu\u00b7le", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "NE", "$(", "NN", "KON", "ADJA", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.229": {"text": "Nimm ein gewerbe vor/ setz dich auff bessern fu\u00df/", "tokens": ["Nimm", "ein", "ge\u00b7wer\u00b7be", "vor", "/", "setz", "dich", "auff", "bes\u00b7sern", "fu\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "APPR", "$(", "VVIMP", "PPER", "APPR", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.230": {"text": "Halt eine wechsel-banck/ sey ein Notarius.", "tokens": ["Halt", "ei\u00b7ne", "wech\u00b7sel\u00b7banck", "/", "sey", "ein", "No\u00b7ta\u00b7rius", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "$(", "VAFIN", "ART", "NN", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.231": {"text": "Glaub mit mir/ la\u00df den streit/ la\u00df Scot und Thomas sprechen/", "tokens": ["Glaub", "mit", "mir", "/", "la\u00df", "den", "streit", "/", "la\u00df", "Scot", "und", "Tho\u00b7mas", "spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$(", "VVIMP", "ART", "NN", "$(", "VVIMP", "NE", "KON", "NE", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.232": {"text": "Da\u00df auch den doctor selbst die gr\u00f6sten narren stechen.", "tokens": ["Da\u00df", "auch", "den", "doc\u00b7tor", "selbst", "die", "gr\u00f6s\u00b7ten", "nar\u00b7ren", "ste\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.233": {"text": "Ein doctor/ f\u00e4ngstu an/ poete redt von euch/", "tokens": ["Ein", "doc\u00b7tor", "/", "f\u00e4ngs\u00b7tu", "an", "/", "po\u00b7e\u00b7te", "redt", "von", "euch", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$(", "VVFIN", "PTKVZ", "$(", "VVFIN", "VVFIN", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.234": {"text": "H\u00e4lt eure Musen ein/ der war zu grob der streich.", "tokens": ["H\u00e4lt", "eu\u00b7re", "Mu\u00b7sen", "ein", "/", "der", "war", "zu", "grob", "der", "streich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "$(", "ART", "VAFIN", "PTKA", "ADJD", "ART", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Doch/ eh die zeit vergeht/ nicht l\u00e4nger schertz zu f\u00fchren/", "tokens": ["Doch", "/", "eh", "die", "zeit", "ver\u00b7geht", "/", "nicht", "l\u00e4n\u00b7ger", "schertz", "zu", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "KOUS", "ART", "NN", "VVFIN", "$(", "PTKNEG", "ADJD", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.236": {"text": "Sagst/ ist der mensch nicht klug? da\u00df wir den zweck ber\u00fchren;", "tokens": ["Sagst", "/", "ist", "der", "mensch", "nicht", "klug", "?", "da\u00df", "wir", "den", "zweck", "be\u00b7r\u00fch\u00b7ren", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VAFIN", "ART", "NN", "PTKNEG", "ADJD", "$.", "KOUS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Ist nicht vernunfft sein licht/ sein stern/ wornach er f\u00e4hrt/", "tokens": ["Ist", "nicht", "ver\u00b7nunfft", "sein", "licht", "/", "sein", "stern", "/", "wor\u00b7nach", "er", "f\u00e4hrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "VVFIN", "PPOSAT", "NN", "$(", "PPOSAT", "VVINF", "$(", "PWAV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.238": {"text": "Ja: doch/ was halff sie ihm/ und wenn sie ihm auch lehrt.", "tokens": ["Ja", ":", "doch", "/", "was", "halff", "sie", "ihm", "/", "und", "wenn", "sie", "ihm", "auch", "lehrt", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ADV", "$(", "PWS", "VVFIN", "PPER", "PPER", "$(", "KON", "KOUS", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.239": {"text": "Wenn er den winden traut/ sich drauff zu schiffe setzet/", "tokens": ["Wenn", "er", "den", "win\u00b7den", "traut", "/", "sich", "drauff", "zu", "schif\u00b7fe", "set\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "VVFIN", "$(", "PRF", "PAV", "PTKZU", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.240": {"text": "An iede klippe st\u00f6st/ und sich daran verletzet.", "tokens": ["An", "ie\u00b7de", "klip\u00b7pe", "st\u00f6st", "/", "und", "sich", "da\u00b7ran", "ver\u00b7let\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$(", "KON", "PRF", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.241": {"text": "Was hilfft es jenem dort/ wenn sie ihm pflegt zu schreyn/", "tokens": ["Was", "hilfft", "es", "je\u00b7nem", "dort", "/", "wenn", "sie", "ihm", "pflegt", "zu", "schreyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PDAT", "ADV", "$(", "KOUS", "PPER", "PPER", "VVFIN", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.242": {"text": "Schreib nicht mehr: la\u00df dich doch von deiner wuth befreyn.", "tokens": ["Schreib", "nicht", "mehr", ":", "la\u00df", "dich", "doch", "von", "dei\u00b7ner", "wuth", "be\u00b7freyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "$.", "VVIMP", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.243": {"text": "Da der vergebne rath ihn nur dahin kan treiben/", "tokens": ["Da", "der", "ver\u00b7geb\u00b7ne", "rath", "ihn", "nur", "da\u00b7hin", "kan", "trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPER", "ADV", "PAV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.244": {"text": "Da\u00df er mit gr\u00f6\u00dfrer wuth mu\u00df lauter reime schreiben.", "tokens": ["Da\u00df", "er", "mit", "gr\u00f6\u00df\u00b7rer", "wuth", "mu\u00df", "lau\u00b7ter", "rei\u00b7me", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "VMFIN", "PIAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.245": {"text": "Wenn er die mi\u00dfgeburt mit plerren her erzehlt/", "tokens": ["Wenn", "er", "die", "mi\u00df\u00b7ge\u00b7burt", "mit", "pler\u00b7ren", "her", "er\u00b7zehlt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NN", "APZR", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.246": {"text": "Geht freund und nachbar durch/ damit er sie nicht qv\u00e4lt.", "tokens": ["Geht", "freund", "und", "nach\u00b7bar", "durch", "/", "da\u00b7mit", "er", "sie", "nicht", "qv\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "APPR", "$(", "KOUS", "PPER", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.247": {"text": "Denn so der arge geist ihn so zu treiben pfleget/", "tokens": ["Denn", "so", "der", "ar\u00b7ge", "geist", "ihn", "so", "zu", "trei\u00b7ben", "pfle\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.248": {"text": "Wird alles/ auch die magd/ zu schneller flucht beweget;", "tokens": ["Wird", "al\u00b7les", "/", "auch", "die", "magd", "/", "zu", "schnel\u00b7ler", "flucht", "be\u00b7we\u00b7get", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$(", "ADV", "ART", "NN", "$(", "PTKA", "ADJD", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.249": {"text": "Dem esel wenigstens hat die natur gelehrt/", "tokens": ["Dem", "e\u00b7sel", "we\u00b7nigs\u00b7tens", "hat", "die", "na\u00b7tur", "ge\u00b7lehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.250": {"text": "Da\u00df er di\u00df was er soll ohn allen streit gewehrt.", "tokens": ["Da\u00df", "er", "di\u00df", "was", "er", "soll", "ohn", "al\u00b7len", "streit", "ge\u00b7wehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "PRELS", "PPER", "VMFIN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.251": {"text": "Er pflegt den d\u00fcstern hals auch nicht zum thon zu zwingen/", "tokens": ["Er", "pflegt", "den", "d\u00fcs\u00b7tern", "hals", "auch", "nicht", "zum", "thon", "zu", "zwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "VVFIN", "ADV", "ADV", "PTKNEG", "APPRART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.252": {"text": "Und mit der v\u00f6gel chor dort um den krantz zu singen.", "tokens": ["Und", "mit", "der", "v\u00f6\u00b7gel", "chor", "dort", "um", "den", "krantz", "zu", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NE", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.253": {"text": "Es treibt ihn kein verstand/ und wei\u00df doch seine bahn/", "tokens": ["Es", "treibt", "ihn", "kein", "ver\u00b7stand", "/", "und", "wei\u00df", "doch", "sei\u00b7ne", "bahn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "$(", "KON", "VVFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.254": {"text": "Der mensch nur/ der voll licht/ sicht nichts mit klugheit an;", "tokens": ["Der", "mensch", "nur", "/", "der", "voll", "licht", "/", "sicht", "nichts", "mit", "klug\u00b7heit", "an", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "ART", "ADJD", "NN", "$(", "VVFIN", "PIS", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.255": {"text": "Er thut mir/ was er will/ auch nicht bey rechten zeiten/", "tokens": ["Er", "thut", "mir", "/", "was", "er", "will", "/", "auch", "nicht", "bey", "rech\u00b7ten", "zei\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PWS", "PPER", "VMFIN", "$(", "ADV", "PTKNEG", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.256": {"text": "Und alles/ was er thut/ sind schwach- und dunckelheiten.", "tokens": ["Und", "al\u00b7les", "/", "was", "er", "thut", "/", "sind", "schwach", "und", "dun\u00b7ckel\u00b7hei\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$(", "PWS", "PPER", "VVFIN", "$(", "VAFIN", "TRUNC", "KON", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.257": {"text": "Es ist ihm alles recht/ und alles ein verdru\u00df/", "tokens": ["Es", "ist", "ihm", "al\u00b7les", "recht", "/", "und", "al\u00b7les", "ein", "ver\u00b7dru\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "ADJD", "$(", "KON", "PIS", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.258": {"text": "Und wei\u00df nicht wenn man lust/ und trauren hegen mu\u00df.", "tokens": ["Und", "wei\u00df", "nicht", "wenn", "man", "lust", "/", "und", "trau\u00b7ren", "he\u00b7gen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "KOUS", "PIS", "VVFIN", "$(", "KON", "VVINF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.259": {"text": "Er lebt in tag hinein/ liebt/ hasset/ heilt/ verletzet/", "tokens": ["Er", "lebt", "in", "tag", "hin\u00b7ein", "/", "liebt", "/", "has\u00b7set", "/", "heilt", "/", "ver\u00b7let\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$(", "VVFIN", "$(", "VVFIN", "$(", "VVFIN", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.260": {"text": "Mehrt/ mindert/ sucht/ flieht/ zehrt/ verwaltet und ergetzet/", "tokens": ["Mehrt", "/", "min\u00b7dert", "/", "sucht", "/", "flieht", "/", "zehrt", "/", "ver\u00b7wal\u00b7tet", "und", "er\u00b7get\u00b7zet", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVPP", "$(", "VVFIN", "$(", "VVFIN", "$(", "VVFIN", "$(", "VVPP", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.261": {"text": "Find man bey l\u00f6w und b\u00e4r/ wie sichs bey ihm verh\u00e4lt/", "tokens": ["Find", "man", "bey", "l\u00f6w", "und", "b\u00e4r", "/", "wie", "sichs", "bey", "ihm", "ver\u00b7h\u00e4lt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "NE", "KON", "ADJD", "$(", "PWAV", "PIS", "APPR", "PPER", "VVFIN", "$("], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.262": {"text": "Da\u00df sie der schwarm betr\u00fcbt/ den sie sich vorgestellt;", "tokens": ["Da\u00df", "sie", "der", "schwarm", "be\u00b7tr\u00fcbt", "/", "den", "sie", "sich", "vor\u00b7ge\u00b7stellt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJD", "VVPP", "$(", "ART", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.263": {"text": "Da\u00df sie bey dutzenden vor schw\u00e4chrer zahl erschrecken/", "tokens": ["Da\u00df", "sie", "bey", "dut\u00b7zen\u00b7den", "vor", "schw\u00e4ch\u00b7rer", "zahl", "er\u00b7schre\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.264": {"text": "Des rabens stein und fluch ihm k\u00f6nne furcht erwecken.", "tokens": ["Des", "ra\u00b7bens", "stein", "und", "fluch", "ihm", "k\u00f6n\u00b7ne", "furcht", "er\u00b7we\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "KON", "VVIMP", "PPER", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.265": {"text": "Wenn hat wohl ie der mensch ein thier so n\u00e4rrsch erblickt?", "tokens": ["Wenn", "hat", "wohl", "ie", "der", "mensch", "ein", "thier", "so", "n\u00e4rrsch", "er\u00b7blickt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ADV", "ADV", "ART", "NN", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.266": {"text": "Wenn hats ihn angebett und sich vor ihn geb\u00fcckt/", "tokens": ["Wenn", "hats", "ihn", "an\u00b7ge\u00b7bett", "und", "sich", "vor", "ihn", "ge\u00b7b\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "VVPP", "KON", "PRF", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.267": {"text": "Als wie vor einen Gott der wind und jahres-zeiten/", "tokens": ["Als", "wie", "vor", "ei\u00b7nen", "Gott", "der", "wind", "und", "jah\u00b7res\u00b7zei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "APPR", "ART", "NN", "ART", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.268": {"text": "Da\u00df er ihm sonnenschein und regen soll bereiten?", "tokens": ["Da\u00df", "er", "ihm", "son\u00b7nen\u00b7schein", "und", "re\u00b7gen", "soll", "be\u00b7rei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "KON", "ADJA", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.269": {"text": "Nein! aber hundert mahl sieht es den klugen thorn", "tokens": ["Nein", "!", "a\u00b7ber", "hun\u00b7dert", "mahl", "sieht", "es", "den", "klu\u00b7gen", "thorn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "ADV", "CARD", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.270": {"text": "Vor seiner arbeit knien/ die er zum Gott erkohrn;", "tokens": ["Vor", "sei\u00b7ner", "ar\u00b7beit", "kni\u00b7en", "/", "die", "er", "zum", "Gott", "er\u00b7kohrn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$(", "PRELS", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.271": {"text": "Wie sich in Malabar die menschen voller schrecken/", "tokens": ["Wie", "sich", "in", "Ma\u00b7la\u00b7bar", "die", "men\u00b7schen", "vol\u00b7ler", "schre\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "APPR", "NN", "ART", "ADJA", "ADJA", "VVINF", "$("], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.272": {"text": "Vor eines affen bild/ und seinen altar strecken:", "tokens": ["Vor", "ei\u00b7nes", "af\u00b7fen", "bild", "/", "und", "sei\u00b7nen", "al\u00b7tar", "stre\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.273": {"text": "Und wenn ums Nilus strand das volck recht beten will/", "tokens": ["Und", "wenn", "ums", "Ni\u00b7lus", "strand", "das", "volck", "recht", "be\u00b7ten", "will", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NE", "NE", "VVFIN", "ART", "NN", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.274": {"text": "Es glut und weyrauch nimmt/ und ehrt das Crocodill.", "tokens": ["Es", "glut", "und", "wey\u00b7rauch", "nimmt", "/", "und", "ehrt", "das", "Cro\u00b7co\u00b7dill", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "VVFIN", "$(", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.275": {"text": "Wie sagst du/ so verhast/ mit crocodill und affen/", "tokens": ["Wie", "sagst", "du", "/", "so", "ver\u00b7hast", "/", "mit", "cro\u00b7co\u00b7dill", "und", "af\u00b7fen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$(", "ADV", "ADJD", "$(", "APPR", "NE", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.276": {"text": "Was kan Egyptens Gott allhier vor nutzen schaffen?", "tokens": ["Was", "kan", "E\u00b7gyp\u00b7tens", "Gott", "all\u00b7hier", "vor", "nut\u00b7zen", "schaf\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "NE", "NN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.277": {"text": "Beweist dein eitler schlu\u00df/ da\u00df jenes menschen kind/", "tokens": ["Be\u00b7weist", "dein", "eit\u00b7ler", "schlu\u00df", "/", "da\u00df", "je\u00b7nes", "men\u00b7schen", "kind", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$(", "KOUS", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.278": {"text": "Ja gar der doctor selbst/ noch unter eseln sind?", "tokens": ["Ja", "gar", "der", "doc\u00b7tor", "selbst", "/", "noch", "un\u00b7ter", "e\u00b7seln", "sind", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "NN", "ADV", "$(", "ADV", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.279": {"text": "Ein esel! der ein spiel von allen was sich reget/", "tokens": ["Ein", "e\u00b7sel", "!", "der", "ein", "spiel", "von", "al\u00b7len", "was", "sich", "re\u00b7get", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "ART", "VVFIN", "APPR", "PIAT", "PRELS", "PRF", "VVFIN", "$("], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.280": {"text": "Das allertummste vieh/ das tausend spott ertr\u00e4get/", "tokens": ["Das", "al\u00b7ler\u00b7tumms\u00b7te", "vieh", "/", "das", "tau\u00b7send", "spott", "er\u00b7tr\u00e4\u00b7get", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "FM", "$(", "ART", "CARD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.281": {"text": "Und dessen name nur die gr\u00f6ste schm\u00e4h-schrifft bringt/", "tokens": ["Und", "des\u00b7sen", "na\u00b7me", "nur", "die", "gr\u00f6s\u00b7te", "schm\u00e4h\u00b7schrifft", "bringt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.282": {"text": "Ja/ ja! was hat er denn/ das dich zu lachen zwingt?", "tokens": ["Ja", "/", "ja", "!", "was", "hat", "er", "denn", "/", "das", "dich", "zu", "la\u00b7chen", "zwingt", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "PTKANT", "$.", "PWS", "VAFIN", "PPER", "ADV", "$(", "PRELS", "PPER", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.283": {"text": "Wir spotten \u00fcber ihn/ ach k\u00f6nt er einmahl lallen/", "tokens": ["Wir", "spot\u00b7ten", "\u00fc\u00b7ber", "ihn", "/", "ach", "k\u00f6nt", "er", "ein\u00b7mahl", "lal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$(", "ADV", "VVFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.284": {"text": "Wie ihm doch unser thun/ mein doctor/ mag gefallen/", "tokens": ["Wie", "ihm", "doch", "un\u00b7ser", "thun", "/", "mein", "doc\u00b7tor", "/", "mag", "ge\u00b7fal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PPOSAT", "VVINF", "$(", "PPOSAT", "NN", "$(", "VMFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.285": {"text": "Wenn ihm des himmels-schlu\u00df den menschen zu erbaun/", "tokens": ["Wenn", "ihm", "des", "him\u00b7mels\u00b7schlu\u00df", "den", "men\u00b7schen", "zu", "er\u00b7baun", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.286": {"text": "Vern\u00fcnfftger worte brauch nur wolte anvertraun;", "tokens": ["Ver\u00b7n\u00fcnfft\u00b7ger", "wor\u00b7te", "brauch", "nur", "wol\u00b7te", "an\u00b7ver\u00b7traun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.287": {"text": "Da\u00df er zu sagen w\u00fcst/ das was er itzt mu\u00df dencken/", "tokens": ["Da\u00df", "er", "zu", "sa\u00b7gen", "w\u00fcst", "/", "das", "was", "er", "itzt", "mu\u00df", "den\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKZU", "VVINF", "VVFIN", "$(", "PDS", "PRELS", "PPER", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.288": {"text": "Mein doctor/ in vertraun/ wie solt er uns nicht kr\u00e4ncken.", "tokens": ["Mein", "doc\u00b7tor", "/", "in", "ver\u00b7traun", "/", "wie", "solt", "er", "uns", "nicht", "kr\u00e4n\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "APPR", "VVINF", "$(", "PWAV", "VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.289": {"text": "Wie schleust er doch bey sich/ indem er in der stadt/", "tokens": ["Wie", "schleust", "er", "doch", "bey", "sich", "/", "in\u00b7dem", "er", "in", "der", "stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "APPR", "PRF", "$(", "KOUS", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+++-+-+-+", "measure": "unknown.measure.septa"}, "line.290": {"text": "Auff den gedrangen marck den sack zu tragen hat.", "tokens": ["Auff", "den", "ge\u00b7dran\u00b7gen", "marck", "den", "sack", "zu", "tra\u00b7gen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.291": {"text": "Und sieht den menschen da mit einem schlechten kleide/", "tokens": ["Und", "sieht", "den", "men\u00b7schen", "da", "mit", "ei\u00b7nem", "schlech\u00b7ten", "klei\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.292": {"text": "Gr\u00fcn/ gelbe/ j\u00e4mmerlich/ verg\u00fcldt/ in sammt und seide;", "tokens": ["Gr\u00fcn", "/", "gel\u00b7be", "/", "j\u00e4m\u00b7mer\u00b7lich", "/", "ver\u00b7g\u00fcldt", "/", "in", "sammt", "und", "sei\u00b7de", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJA", "$(", "ADJD", "$(", "VVPP", "$(", "APPR", "VVFIN", "KON", "VVFIN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.293": {"text": "Was denckt er? wenn er sieht/ da\u00df dort ein Rabulist", "tokens": ["Was", "denckt", "er", "?", "wenn", "er", "sieht", "/", "da\u00df", "dort", "ein", "Ra\u00b7bu\u00b7list"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$.", "KOUS", "PPER", "VVFIN", "$(", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.294": {"text": "Mit mantel und pappier/ wie er beladen ist.", "tokens": ["Mit", "man\u00b7tel", "und", "pap\u00b7pier", "/", "wie", "er", "be\u00b7la\u00b7den", "ist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "PWAV", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+--++-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.295": {"text": "Wenn der Pedanten zunfft vor einen sammten kragen/", "tokens": ["Wenn", "der", "Pe\u00b7dan\u00b7ten", "zunfft", "vor", "ei\u00b7nen", "samm\u00b7ten", "kra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.296": {"text": "Dem der Pedell verfolgt/ den hut in h\u00e4nden tragen.", "tokens": ["Dem", "der", "Pe\u00b7dell", "ver\u00b7folgt", "/", "den", "hut", "in", "h\u00e4n\u00b7den", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVPP", "$(", "ART", "NN", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.297": {"text": "Wenn er gerichte sieht/ da\u00df man mit grosser pracht", "tokens": ["Wenn", "er", "ge\u00b7rich\u00b7te", "sieht", "/", "da\u00df", "man", "mit", "gros\u00b7ser", "pracht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJA", "VVFIN", "$(", "KOUS", "PIS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.298": {"text": "Dem auffgezognen dieb ein l\u00fcfftig ende macht.", "tokens": ["Dem", "auff\u00b7ge\u00b7zog\u00b7nen", "dieb", "ein", "l\u00fcff\u00b7tig", "en\u00b7de", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.299": {"text": "Dafern er ungefehr auffs rath-hau\u00df solte kommen/", "tokens": ["Da\u00b7fern", "er", "un\u00b7ge\u00b7fehr", "auffs", "ra\u00b7th\u00b7hau\u00df", "sol\u00b7te", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPRART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.300": {"text": "Und h\u00e4tte da den schwall/ den zanck und streit vernommen/", "tokens": ["Und", "h\u00e4t\u00b7te", "da", "den", "schwall", "/", "den", "zanck", "und", "streit", "ver\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "$(", "ART", "NN", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.301": {"text": "Wie einer dort versetzt/ der andre appellirt/", "tokens": ["Wie", "ei\u00b7ner", "dort", "ver\u00b7setzt", "/", "der", "and\u00b7re", "ap\u00b7pel\u00b7lirt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADV", "VVPP", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.302": {"text": "Der dritte klagbar wird/ der vierdte protestirt.", "tokens": ["Der", "drit\u00b7te", "klag\u00b7bar", "wird", "/", "der", "vierd\u00b7te", "pro\u00b7tes\u00b7tirt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "VAFIN", "$(", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.303": {"text": "Wenn er das volck betracht/ der advocatens menge/", "tokens": ["Wenn", "er", "das", "volck", "be\u00b7tracht", "/", "der", "ad\u00b7vo\u00b7ca\u00b7tens", "men\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.304": {"text": "Den richter/ frohn und knecht/ was denckt er im getr\u00e4nge?", "tokens": ["Den", "rich\u00b7ter", "/", "frohn", "und", "knecht", "/", "was", "denckt", "er", "im", "ge\u00b7tr\u00e4n\u00b7ge", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADJD", "KON", "VVFIN", "$(", "PWS", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.305": {"text": "Ach h\u00e4tte noch di\u00df thier/ wie zu Esopens zeit", "tokens": ["Ach", "h\u00e4t\u00b7te", "noch", "di\u00df", "thier", "/", "wie", "zu", "E\u00b7so\u00b7pens", "zeit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "VAFIN", "ADV", "PDS", "NN", "$(", "KOKOM", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.306": {"text": "Das gl\u00fccklich unmensch ist annoch beredsamkeit.", "tokens": ["Das", "gl\u00fcck\u00b7lich", "un\u00b7mensch", "ist", "an\u00b7noch", "be\u00b7red\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "ADJD", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.307": {"text": "Denn weil es \u00fcberall/ die welt voll narren findet/", "tokens": ["Denn", "weil", "es", "\u00fc\u00b7be\u00b7rall", "/", "die", "welt", "voll", "nar\u00b7ren", "fin\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "$(", "ART", "NN", "ADJD", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.308": {"text": "So sagt es wohl gewi\u00df/ da es kein neid entz\u00fcndet/", "tokens": ["So", "sagt", "es", "wohl", "ge\u00b7wi\u00df", "/", "da", "es", "kein", "neid", "ent\u00b7z\u00fcn\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "$(", "KOUS", "PPER", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.309": {"text": "Und sich mit disteln labt bey auffgelegter m\u00fch/", "tokens": ["Und", "sich", "mit", "dis\u00b7teln", "labt", "bey", "auff\u00b7ge\u00b7leg\u00b7ter", "m\u00fch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "NN", "VVFIN", "APPR", "ADJA", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.310": {"text": "F\u00fcrwahr der mensch ist nur als wie ein tummes vieh.", "tokens": ["F\u00fcr\u00b7wahr", "der", "mensch", "ist", "nur", "als", "wie", "ein", "tum\u00b7mes", "vieh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VAFIN", "ADV", "KOUS", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}