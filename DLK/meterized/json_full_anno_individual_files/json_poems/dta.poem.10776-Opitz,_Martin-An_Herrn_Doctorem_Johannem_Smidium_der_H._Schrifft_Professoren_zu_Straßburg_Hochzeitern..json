{"dta.poem.10776": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "An Herrn   Doctorem Johannem Smidium  \n  der H. Schrifft   Professoren   zu Stra\u00dfburg/  \n Hochzeitern.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Wann wir durchsuchen offt Historische Geschichten/", "tokens": ["Wann", "wir", "durch\u00b7su\u00b7chen", "offt", "His\u00b7to\u00b7ri\u00b7sche", "Ge\u00b7schich\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vnd vnser Sinnen Flamm auff alte Schreiber richten/", "tokens": ["Vnd", "vn\u00b7ser", "Sin\u00b7nen", "Flamm", "auff", "al\u00b7te", "Schrei\u00b7ber", "rich\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NE", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So finden wir/ wie hoch manch Edler K\u00fcner Held", "tokens": ["So", "fin\u00b7den", "wir", "/", "wie", "hoch", "manch", "Ed\u00b7ler", "K\u00fc\u00b7ner", "Held"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$(", "PWAV", "ADJD", "PIAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sein Namen in die H\u00f6h mit hohem flei\u00df gestelt/", "tokens": ["Sein", "Na\u00b7men", "in", "die", "H\u00f6h", "mit", "ho\u00b7hem", "flei\u00df", "ge\u00b7stelt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Vnd seiner armen Krafft so weit durchbrechen lassen/", "tokens": ["Vnd", "sei\u00b7ner", "ar\u00b7men", "Krafft", "so", "weit", "durch\u00b7bre\u00b7chen", "las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Auff da\u00df sein Scepter sey ein Herr der gantzen Welt/", "tokens": ["Auff", "da\u00df", "sein", "Scep\u00b7ter", "sey", "ein", "Herr", "der", "gant\u00b7zen", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPOSAT", "NN", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Vnd er hiemit verbleib der st\u00e4rckeste Kriegsheld.", "tokens": ["Vnd", "er", "hie\u00b7mit", "ver\u00b7bleib", "der", "st\u00e4r\u00b7ckes\u00b7te", "Kriegs\u00b7held", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PAV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was der hochweise F\u00fcrst ", "tokens": ["Was", "der", "hoch\u00b7wei\u00b7se", "F\u00fcrst"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Der Vngerechtigkeit mit starckem Zaum vmbfangen/", "tokens": ["Der", "Vn\u00b7ge\u00b7rech\u00b7tig\u00b7keit", "mit", "star\u00b7ckem", "Zaum", "vmb\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Vnd so die Billigkeit geharnischt au\u00dfger\u00fcst/", "tokens": ["Vnd", "so", "die", "Bil\u00b7lig\u00b7keit", "ge\u00b7har\u00b7nischt", "au\u00df\u00b7ge\u00b7r\u00fcst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df er derstattlichste Gesetz-vollbringer ist.", "tokens": ["Da\u00df", "er", "der\u00b7statt\u00b7lichs\u00b7te", "Ge\u00b7setz\u00b7voll\u00b7brin\u00b7ger", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wie der ", "tokens": ["Wie", "der"], "token_info": ["word", "word"], "pos": ["PWAV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.14": {"text": "Vornembst hat wollen in den Leib de\u00df Menschen stellen/", "tokens": ["Vor\u00b7nembst", "hat", "wol\u00b7len", "in", "den", "Leib", "de\u00df", "Men\u00b7schen", "stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VMFIN", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Da\u00df er der Kranckheit feind ein new Gesundheitlegt/", "tokens": ["Da\u00df", "er", "der", "Kran\u00b7ck\u00b7heit", "feind", "ein", "new", "Ge\u00b7sund\u00b7heit\u00b7legt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "ART", "ADJD", "VVPP", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Vnd so dar von das Lob de\u00df besten Artztes tregt.", "tokens": ["Vnd", "so", "dar", "von", "das", "Lob", "de\u00df", "bes\u00b7ten", "Artz\u00b7tes", "tregt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.18": {"text": "Gedruckt in die Natur/ dieselbe zugewinnen/", "tokens": ["Ge\u00b7druckt", "in", "die", "Na\u00b7tur", "/", "die\u00b7sel\u00b7be", "zu\u00b7ge\u00b7win\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "$(", "PDAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Vnd allen jhren Grund zusetzen in den Tag/", "tokens": ["Vnd", "al\u00b7len", "jhren", "Grund", "zu\u00b7set\u00b7zen", "in", "den", "Tag", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PPOSAT", "NN", "VVIZU", "APPR", "ART", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Da\u00df er also der best ", "tokens": ["Da\u00df", "er", "al\u00b7so", "der", "best"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.21": {"text": "Wie de\u00df ", "tokens": ["Wie", "de\u00df"], "token_info": ["word", "word"], "pos": ["PWAV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.22": {"text": "Vnd durch de\u00df Himmels feld/ durch Erd vnd Meer gedrungen/", "tokens": ["Vnd", "durch", "de\u00df", "Him\u00b7mels", "feld", "/", "durch", "Erd", "vnd", "Meer", "ge\u00b7drun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "$(", "APPR", "NN", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Vnd so ein sch\u00f6n gedicht zusammen auffgebawt/", "tokens": ["Vnd", "so", "ein", "sch\u00f6n", "ge\u00b7dicht", "zu\u00b7sam\u00b7men", "auff\u00b7ge\u00b7bawt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJD", "VVPP", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Da\u00df man allein jhn f\u00fcr Poeten F\u00fcrst anschawt.", "tokens": ["Da\u00df", "man", "al\u00b7lein", "jhn", "f\u00fcr", "Po\u00b7et\u00b7en", "F\u00fcrst", "an\u00b7schawt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PPER", "APPR", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Wie de\u00df ", "tokens": ["Wie", "de\u00df"], "token_info": ["word", "word"], "pos": ["PWAV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.26": {"text": "Als ein new Sch\u00f6pffer/ new Natur/ hat d\u00f6rffen machen/", "tokens": ["Als", "ein", "new", "Sch\u00f6pf\u00b7fer", "/", "new", "Na\u00b7tur", "/", "hat", "d\u00f6rf\u00b7fen", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$(", "ADJD", "NN", "$(", "VAFIN", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Vnd de\u00df Gem\u00fchtes art so abgemahlt im schein/", "tokens": ["Vnd", "de\u00df", "Ge\u00b7m\u00fch\u00b7tes", "art", "so", "ab\u00b7ge\u00b7mahlt", "im", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ADV", "VVPP", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Da\u00df er m\u00f6cht alle zeit der beste Mahler sein.", "tokens": ["Da\u00df", "er", "m\u00f6cht", "al\u00b7le", "zeit", "der", "bes\u00b7te", "Mah\u00b7ler", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "PIAT", "NN", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.30": {"text": "Gelernet/ vnd sein Zung so starcke Wort erfunden/", "tokens": ["Ge\u00b7ler\u00b7net", "/", "vnd", "sein", "Zung", "so", "star\u00b7cke", "Wort", "er\u00b7fun\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "KON", "PPOSAT", "NN", "ADV", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Da\u00df er ohn Schlag/ ohn Stich so vil obsiegt/", "tokens": ["Da\u00df", "er", "ohn", "Schlag", "/", "ohn", "Stich", "so", "vil", "ob\u00b7siegt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "$(", "APPR", "NN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Vnd also auch den Ruhm de\u00df besten Redners kriegt.", "tokens": ["Vnd", "al\u00b7so", "auch", "den", "Ruhm", "de\u00df", "bes\u00b7ten", "Red\u00b7ners", "kriegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Dergleichen M\u00e4nner flei\u00df man k\u00f6nte vil erzehlen/", "tokens": ["Derg\u00b7lei\u00b7chen", "M\u00e4n\u00b7ner", "flei\u00df", "man", "k\u00f6n\u00b7te", "vil", "er\u00b7zeh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "VVFIN", "PIS", "VMFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Wie einem di\u00df geliebt/ dem andern das zuwehlen/", "tokens": ["Wie", "ei\u00b7nem", "di\u00df", "ge\u00b7liebt", "/", "dem", "an\u00b7dern", "das", "zu\u00b7weh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "PDS", "VVPP", "$(", "ART", "ADJA", "PDS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Da\u00df er seins Namens Lob bi\u00df an die Stern erheb/", "tokens": ["Da\u00df", "er", "seins", "Na\u00b7mens", "Lob", "bi\u00df", "an", "die", "Stern", "er\u00b7heb", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "CARD", "NN", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Vnd bi\u00df ans End der Welt doch ohne Leben leb.", "tokens": ["Vnd", "bi\u00df", "ans", "End", "der", "Welt", "doch", "oh\u00b7ne", "Le\u00b7ben", "leb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Doch noch dergleichen that ich habe nicht vernommen/", "tokens": ["Doch", "noch", "derg\u00b7lei\u00b7chen", "that", "ich", "ha\u00b7be", "nicht", "ver\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIS", "VVFIN", "PPER", "VAFIN", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Da\u00df einer auff ein Schlacht zweyfachen Sieg bekommen/", "tokens": ["Da\u00df", "ei\u00b7ner", "auff", "ein", "Schlacht", "zwey\u00b7fa\u00b7chen", "Sieg", "be\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "ART", "NN", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Wie man Herr Bre\u00fctigam di\u00df von euch sagen kan/", "tokens": ["Wie", "man", "Herr", "Bre\u00fc\u00b7ti\u00b7gam", "di\u00df", "von", "euch", "sa\u00b7gen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "NN", "NE", "PDS", "APPR", "PPER", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Da\u00df jhr seyt einen Tag ein Doctor vnd Ehman.", "tokens": ["Da\u00df", "jhr", "seyt", "ei\u00b7nen", "Tag", "ein", "Doc\u00b7tor", "vnd", "Eh\u00b7man", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.41": {"text": "Ob ", "tokens": ["Ob"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.42": {"text": "Doch kan man jhn nicht mehr als einen Kriegsheld nennen.", "tokens": ["Doch", "kan", "man", "jhn", "nicht", "mehr", "als", "ei\u00b7nen", "Kriegs\u00b7held", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "PPER", "PTKNEG", "ADV", "KOKOM", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.43": {"text": "Ob gleich ", "tokens": ["Ob", "gleich"], "token_info": ["word", "word"], "pos": ["KOUS", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.44": {"text": "Jedoch er nun nicht mehr als ein Gsezsetzer bleibt.", "tokens": ["Je\u00b7doch", "er", "nun", "nicht", "mehr", "als", "ein", "Gsez\u00b7set\u00b7zer", "bleibt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "PTKNEG", "ADV", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.45": {"text": "Ob gleich ", "tokens": ["Ob", "gleich"], "token_info": ["word", "word"], "pos": ["KOUS", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.46": {"text": "So h\u00f6rt er doch nicht mehr als eines Artztes Namen/", "tokens": ["So", "h\u00f6rt", "er", "doch", "nicht", "mehr", "als", "ei\u00b7nes", "Artz\u00b7tes", "Na\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "KOUS", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Ob ", "tokens": ["Ob"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.48": {"text": "So wird er doch nichts mehr als ein ", "tokens": ["So", "wird", "er", "doch", "nichts", "mehr", "als", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PIS", "PIS", "KOKOM", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "Ob gleich ", "tokens": ["Ob", "gleich"], "token_info": ["word", "word"], "pos": ["KOUS", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.50": {"text": "Doch jhme man nichts mehr als eim Poeten glaubet/", "tokens": ["Doch", "jh\u00b7me", "man", "nichts", "mehr", "als", "eim", "Po\u00b7et\u00b7en", "glau\u00b7bet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIS", "PIS", "PIS", "KOKOM", "ART", "NN", "VVFIN", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.51": {"text": "Ob gleich ", "tokens": ["Ob", "gleich"], "token_info": ["word", "word"], "pos": ["KOUS", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.52": {"text": "So ist es doch nichts mehr/ als eitel Mahlers pracht.", "tokens": ["So", "ist", "es", "doch", "nichts", "mehr", "/", "als", "ei\u00b7tel", "Mah\u00b7lers", "pracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PIS", "ADV", "$(", "KOUS", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ob ", "tokens": ["Ob"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.54": {"text": "Doch wird man jhn nicht mehr als f\u00fcr ein Redner rechen/", "tokens": ["Doch", "wird", "man", "jhn", "nicht", "mehr", "als", "f\u00fcr", "ein", "Red\u00b7ner", "re\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "PPER", "PTKNEG", "ADV", "KOKOM", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Doch jhr Herr Breutigam geht ein in diese Zeit/", "tokens": ["Doch", "jhr", "Herr", "Breu\u00b7ti\u00b7gam", "geht", "ein", "in", "die\u00b7se", "Zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NE", "VVFIN", "ART", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Da\u00df jhr auff einen Tag Ehman vnd ", "tokens": ["Da\u00df", "jhr", "auff", "ei\u00b7nen", "Tag", "Eh\u00b7man", "vnd"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "NE", "KON"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.57": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.58": {"text": "Vnd alle Ketzerey mit starcker Stimm au\u00dfreutten/", "tokens": ["Vnd", "al\u00b7le", "Ket\u00b7ze\u00b7rey", "mit", "star\u00b7cker", "Stimm", "au\u00df\u00b7reut\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Ein Ehman/ der erwerb ein solches Kriegsgeschlecht/", "tokens": ["Ein", "Eh\u00b7man", "/", "der", "er\u00b7werb", "ein", "sol\u00b7ches", "Kriegs\u00b7ge\u00b7schlecht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "VVFIN", "ART", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Das nach de\u00df Vaters art f\u00fcr Gottes warheit fecht.", "tokens": ["Das", "nach", "de\u00df", "Va\u00b7ters", "art", "f\u00fcr", "Got\u00b7tes", "war\u00b7heit", "fecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "NN", "APPR", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.62": {"text": "Vnd auch das/ was sey recht/ was vnrecht sey/ erkl\u00e4re:", "tokens": ["Vnd", "auch", "das", "/", "was", "sey", "recht", "/", "was", "vn\u00b7recht", "sey", "/", "er\u00b7kl\u00e4\u00b7re", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ART", "$(", "PWS", "VAFIN", "ADJD", "$(", "PWS", "NN", "VAFIN", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Ein Ehman/ dessen Hau\u00df ein solchen Stammen trag/", "tokens": ["Ein", "Eh\u00b7man", "/", "des\u00b7sen", "Hau\u00df", "ein", "sol\u00b7chen", "Stam\u00b7men", "trag", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELAT", "NN", "ART", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Der bring die Billigkeit/ das Vngerecht verjag.", "tokens": ["Der", "bring", "die", "Bil\u00b7lig\u00b7keit", "/", "das", "Vn\u00b7ge\u00b7recht", "ver\u00b7jag", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "$(", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.66": {"text": "Zwar nicht de\u00df Leibes schad/ sondern der Seelen benlen:", "tokens": ["Zwar", "nicht", "de\u00df", "Lei\u00b7bes", "schad", "/", "son\u00b7dern", "der", "See\u00b7len", "ben\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "ADJD", "$(", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.67": {"text": "Ein Ehman/ dessen Tisch vmbwachse solches Kraut/", "tokens": ["Ein", "Eh\u00b7man", "/", "des\u00b7sen", "Tisch", "vmb\u00b7wach\u00b7se", "sol\u00b7ches", "Kraut", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELAT", "NN", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Das theils der Seelen schmertz/ theils heyl de\u00df Leibes haut.", "tokens": ["Das", "theils", "der", "See\u00b7len", "schmertz", "/", "theils", "heyl", "de\u00df", "Lei\u00b7bes", "haut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "ADJD", "$(", "ADV", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.70": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.71": {"text": "Ein Ehman/ dessen st\u00e4rck bring solche ", "tokens": ["Ein", "Eh\u00b7man", "/", "des\u00b7sen", "st\u00e4rck", "bring", "sol\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PRELAT", "NN", "VVFIN", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.72": {"text": "Die auch erforschen k\u00f6n\u0303 den abgrund der Natur.", "tokens": ["Die", "auch", "er\u00b7for\u00b7schen", "k\u00f6\u00f1", "den", "ab\u00b7grund", "der", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVINF", "VMFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.74": {"text": "In sch\u00f6ne rundigkeit mit Versen k\u00f6nne richten:", "tokens": ["In", "sch\u00f6\u00b7ne", "run\u00b7dig\u00b7keit", "mit", "Ver\u00b7sen", "k\u00f6n\u00b7ne", "rich\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Ein Ehman/ vmb den her solch Saam gestrewet werd/", "tokens": ["Ein", "Eh\u00b7man", "/", "vmb", "den", "her", "solch", "Saam", "ge\u00b7stre\u00b7wet", "werd", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "APPR", "ART", "APZR", "PIAT", "NN", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Darau\u00df erwachsen soll ein new Poeten Herd.", "tokens": ["Dar\u00b7au\u00df", "er\u00b7wach\u00b7sen", "soll", "ein", "new", "Po\u00b7et\u00b7en", "Herd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVINF", "VMFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.78": {"text": "Vnd der Dreyfaltigkeit abbilden helle Stralen:", "tokens": ["Vnd", "der", "Drey\u00b7fal\u00b7tig\u00b7keit", "ab\u00b7bil\u00b7den", "hel\u00b7le", "Stra\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.79": {"text": "Ein Ehman/ der sein Hau\u00df voll hab der Zweygelein/", "tokens": ["Ein", "Eh\u00b7man", "/", "der", "sein", "Hau\u00df", "voll", "hab", "der", "Zwey\u00b7ge\u00b7lein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "PPOSAT", "NN", "ADJD", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "In den de\u00df Vaters kunst gantz abgemahlt erschein.", "tokens": ["In", "den", "de\u00df", "Va\u00b7ters", "kunst", "gantz", "ab\u00b7ge\u00b7mahlt", "er\u00b7schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "VMFIN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.82": {"text": "Vnd seine kunst bekand durch sch\u00f6ne Red k\u00f6n\u0303 machen:", "tokens": ["Vnd", "sei\u00b7ne", "kunst", "be\u00b7kand", "durch", "sch\u00f6\u00b7ne", "Red", "k\u00f6\u00f1", "ma\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Ein Ehman/ den vmbring ein solches. V\u00f6lckelein/", "tokens": ["Ein", "Eh\u00b7man", "/", "den", "vm\u00b7bring", "ein", "sol\u00b7ches", ".", "V\u00f6l\u00b7cke\u00b7lein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "VVFIN", "ART", "PIAT", "$.", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Das V\u00e4terlicher sprach k\u00f6nn ein Nachfolger sein.", "tokens": ["Das", "V\u00e4\u00b7ter\u00b7li\u00b7cher", "sprach", "k\u00f6nn", "ein", "Nach\u00b7fol\u00b7ger", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VMFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Drumb sollen jetzo nun die Helden alle stehen/", "tokens": ["Drumb", "sol\u00b7len", "jet\u00b7zo", "nun", "die", "Hel\u00b7den", "al\u00b7le", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "ADV", "ADV", "ART", "NN", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Vnd/ wie jhn jhres Lob entnommen werde/ sehen/", "tokens": ["Vnd", "/", "wie", "jhn", "jhres", "Lob", "ent\u00b7nom\u00b7men", "wer\u00b7de", "/", "se\u00b7hen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$(", "PWAV", "PPER", "PPOSAT", "NN", "VVINF", "VAFIN", "$(", "VVINF", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.87": {"text": "Wo nicht Herr Br\u00e4utigam euch jhr zustand betr\u00fcbt", "tokens": ["Wo", "nicht", "Herr", "Br\u00e4u\u00b7ti\u00b7gam", "euch", "jhr", "zu\u00b7stand", "be\u00b7tr\u00fcbt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PTKNEG", "NN", "NE", "PPER", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Vnd jhr de\u00dfhalben ein theil ewrer Ehr auffschiebt.", "tokens": ["Vnd", "jhr", "de\u00df\u00b7hal\u00b7ben", "ein", "theil", "ew\u00b7rer", "Ehr", "auff\u00b7schiebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PAV", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Denn keinem ist so vil in einem Tag ergangen/", "tokens": ["Denn", "kei\u00b7nem", "ist", "so", "vil", "in", "ei\u00b7nem", "Tag", "er\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Da\u00df jhn zweyfacher Sieg/ zweyfache Ehr vmbfangen/", "tokens": ["Da\u00df", "jhn", "zwey\u00b7fac\u00b7her", "Sieg", "/", "zwey\u00b7fa\u00b7che", "Ehr", "vmb\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "$(", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Drumb theylt jhr ewer Ehr/ das so geschehen kan:", "tokens": ["Drumb", "theylt", "jhr", "e\u00b7wer", "Ehr", "/", "das", "so", "ge\u00b7sche\u00b7hen", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPOSAT", "NN", "$(", "PDS", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Seyd ", "tokens": ["Seyd"], "token_info": ["word"], "pos": ["VAIMP"], "meter": "+", "measure": "single.up"}}}}}