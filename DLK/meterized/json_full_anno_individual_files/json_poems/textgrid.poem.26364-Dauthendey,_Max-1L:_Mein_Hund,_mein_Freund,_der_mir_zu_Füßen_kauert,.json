{"textgrid.poem.26364": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mein Hund, mein Freund, der mir zu F\u00fc\u00dfen kauert,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Hund, mein Freund, der mir zu F\u00fc\u00dfen kauert,", "tokens": ["Mein", "Hund", ",", "mein", "Freund", ",", "der", "mir", "zu", "F\u00fc\u00b7\u00dfen", "kau\u00b7ert", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "St\u00f6\u00dft mit der Schnauze an mein Knie. Er fragt:", "tokens": ["St\u00f6\u00dft", "mit", "der", "Schnau\u00b7ze", "an", "mein", "Knie", ".", "Er", "fragt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "\u00bbherr, sprich, warum dein Menschenblut erschauert!", "tokens": ["\u00bb", "herr", ",", "sprich", ",", "wa\u00b7rum", "dein", "Men\u00b7schen\u00b7blut", "er\u00b7schau\u00b7ert", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "ADJD", "$,", "PWAV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Stille um dich stundenlang schon klagt,", "tokens": ["Die", "Stil\u00b7le", "um", "dich", "stun\u00b7den\u00b7lang", "schon", "klagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sie rief mir zu: Dein Herr, er trauert.\u00ab", "tokens": ["Sie", "rief", "mir", "zu", ":", "Dein", "Herr", ",", "er", "trau\u00b7ert", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Da so mein Hund im morgendlichen Raum", "tokens": ["Da", "so", "mein", "Hund", "im", "mor\u00b7gend\u00b7li\u00b7chen", "Raum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mich weckte, war ich lange wach gewesen,", "tokens": ["Mich", "weck\u00b7te", ",", "war", "ich", "lan\u00b7ge", "wach", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VAFIN", "PPER", "ADV", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Seit langem wach, und war doch tief im Traum.", "tokens": ["Seit", "lan\u00b7gem", "wach", ",", "und", "war", "doch", "tief", "im", "Traum", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "PTKVZ", "$,", "KON", "VAFIN", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mir war, ich hatte tagelang gelesen,", "tokens": ["Mir", "war", ",", "ich", "hat\u00b7te", "ta\u00b7ge\u00b7lang", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Nein, Jahre \u2013 oder nur Sekunden kaum.", "tokens": ["Nein", ",", "Jah\u00b7re", "\u2013", "o\u00b7der", "nur", "Se\u00b7kun\u00b7den", "kaum", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$(", "KON", "ADV", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ich las in einem Buch, des Zeilen flossen", "tokens": ["Ich", "las", "in", "ei\u00b7nem", "Buch", ",", "des", "Zei\u00b7len", "flos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf jedem Blatt wie Welleng\u00e4nge fort.", "tokens": ["Auf", "je\u00b7dem", "Blatt", "wie", "Wel\u00b7len\u00b7g\u00e4n\u00b7ge", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KOKOM", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bald hell, bald dunkel, und zugleich zu gro\u00dfen", "tokens": ["Bald", "hell", ",", "bald", "dun\u00b7kel", ",", "und", "zu\u00b7gleich", "zu", "gro\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "KON", "ADV", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gestalten wuchsen Silben an und Wort,", "tokens": ["Ge\u00b7stal\u00b7ten", "wuch\u00b7sen", "Sil\u00b7ben", "an", "und", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "PTKVZ", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Raketen \u00e4hnlich, die die Nacht durchschossen.", "tokens": ["Ra\u00b7ke\u00b7ten", "\u00e4hn\u00b7lich", ",", "die", "die", "Nacht", "durch\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "PRELS", "ART", "NN", "VVPP", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.4": {"line.1": {"text": "Die Worte wurden reich ein Ozean.", "tokens": ["Die", "Wor\u00b7te", "wur\u00b7den", "reich", "ein", "O\u00b7ze\u00b7an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie wogten vor mir unterm Mondschein weiter,", "tokens": ["Sie", "wog\u00b7ten", "vor", "mir", "un\u00b7term", "Mond\u00b7schein", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und ein Wort kam als Schiffskolo\u00df heran.", "tokens": ["Und", "ein", "Wort", "kam", "als", "Schiffs\u00b7ko\u00b7lo\u00df", "he\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "KOUS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich las und glitt dem Mondlicht nach, das heiter", "tokens": ["Ich", "las", "und", "glitt", "dem", "Mond\u00b7licht", "nach", ",", "das", "hei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Auf weiten Wellen tastend tanzen kann.", "tokens": ["Auf", "wei\u00b7ten", "Wel\u00b7len", "tas\u00b7tend", "tan\u00b7zen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Doch dann erschreckte mich ein ungeheures Wesen.", "tokens": ["Doch", "dann", "er\u00b7schreck\u00b7te", "mich", "ein", "un\u00b7ge\u00b7heu\u00b7res", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es kam zu mir aus fernen Zeilen nah, \u2013", "tokens": ["Es", "kam", "zu", "mir", "aus", "fer\u00b7nen", "Zei\u00b7len", "nah", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "ADJA", "NN", "ADJD", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Wort, von dem ich in den B\u00fcchern mal gelesen,", "tokens": ["Ein", "Wort", ",", "von", "dem", "ich", "in", "den", "B\u00fc\u00b7chern", "mal", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "PPER", "APPR", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch dessen K\u00f6rper ich noch nie vor Augen sah.", "tokens": ["Doch", "des\u00b7sen", "K\u00f6r\u00b7per", "ich", "noch", "nie", "vor", "Au\u00b7gen", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "PPER", "ADV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und atemlos ist dann mein Traum gewesen.", "tokens": ["Und", "a\u00b7tem\u00b7los", "ist", "dann", "mein", "Traum", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ADV", "PPOSAT", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "\u00bbeisberg\u00ab, \u2013 das Wort ging noch im Zimmer um,", "tokens": ["\u00bb", "eis\u00b7berg", "\u00ab", ",", "\u2013", "das", "Wort", "ging", "noch", "im", "Zim\u00b7mer", "um", ","], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$(", "$,", "$(", "ART", "NN", "VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Noch jetzt, da ich das H\u00fcndlein winseln h\u00f6rte.", "tokens": ["Noch", "jetzt", ",", "da", "ich", "das", "H\u00fcnd\u00b7lein", "win\u00b7seln", "h\u00f6r\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In meinen Ohren aber war ein wild Gesumm", "tokens": ["In", "mei\u00b7nen", "Oh\u00b7ren", "a\u00b7ber", "war", "ein", "wild", "Ge\u00b7summ"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VAFIN", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von Menschen und von Schiffsmaschinen, das mich st\u00f6rte.", "tokens": ["Von", "Men\u00b7schen", "und", "von", "Schiffs\u00b7ma\u00b7schi\u00b7nen", ",", "das", "mich", "st\u00f6r\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch vor mir in dem Zimmer stand der Morgen stumm.", "tokens": ["Doch", "vor", "mir", "in", "dem", "Zim\u00b7mer", "stand", "der", "Mor\u00b7gen", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Nicht ruhig aber lag im Land mein altes Zimmer.", "tokens": ["Nicht", "ru\u00b7hig", "a\u00b7ber", "lag", "im", "Land", "mein", "al\u00b7tes", "Zim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ADV", "VVFIN", "APPRART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es wanderte noch mit dem Eisberg fort,", "tokens": ["Es", "wan\u00b7der\u00b7te", "noch", "mit", "dem", "Eis\u00b7berg", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und auch durchs Fenster sah des Eises Schimmer.", "tokens": ["Und", "auch", "durchs", "Fens\u00b7ter", "sah", "des", "Ei\u00b7ses", "Schim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbtitanic\u00ab \u2013 war ein zweites gro\u00dfes Wort,", "tokens": ["\u00bb", "ti\u00b7ta\u00b7nic", "\u00ab", "\u2013", "war", "ein", "zwei\u00b7tes", "gro\u00b7\u00dfes", "Wort", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$(", "$(", "VAFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Das sagten meine Lippen lautlos immer.", "tokens": ["Das", "sag\u00b7ten", "mei\u00b7ne", "Lip\u00b7pen", "laut\u00b7los", "im\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "ADJD", "ADV", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "\u00bbtitanic!\u00ab war ein zweiter gro\u00dfer Schrei.", "tokens": ["\u00bb", "ti\u00b7ta\u00b7nic", "!", "\u00ab", "war", "ein", "zwei\u00b7ter", "gro\u00b7\u00dfer", "Schrei", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$.", "$(", "VAFIN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Es trug ihn wohl nun schon zu hundert Malen", "tokens": ["Es", "trug", "ihn", "wohl", "nun", "schon", "zu", "hun\u00b7dert", "Ma\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADV", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mein Herz aus dieser Nacht zu mir herbei.", "tokens": ["Mein", "Herz", "aus", "die\u00b7ser", "Nacht", "zu", "mir", "her\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PDAT", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich sehe noch die Menschen, jene tausend fahlen,", "tokens": ["Ich", "se\u00b7he", "noch", "die", "Men\u00b7schen", ",", "je\u00b7ne", "tau\u00b7send", "fah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "PDAT", "CARD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die sanken mit dem Wort wie eine Welt aus Blei.", "tokens": ["Die", "san\u00b7ken", "mit", "dem", "Wort", "wie", "ei\u00b7ne", "Welt", "aus", "Blei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "KOKOM", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "\u00bbtitanic!\u00ab schrieen sie. Das Wort, es sollte retten.", "tokens": ["\u00bb", "ti\u00b7ta\u00b7nic", "!", "\u00ab", "schri\u00b7een", "sie", ".", "Das", "Wort", ",", "es", "soll\u00b7te", "ret\u00b7ten", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$.", "$(", "VVFIN", "PPER", "$.", "ART", "NN", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie schleudern's tausendmal dem Eisberg hin", "tokens": ["Sie", "schleu\u00b7dern's", "tau\u00b7send\u00b7mal", "dem", "Eis\u00b7berg", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und fl\u00fcchten fort vom Tanz, aus Spielsaal, Schlaf und Betten.", "tokens": ["Und", "fl\u00fcch\u00b7ten", "fort", "vom", "Tanz", ",", "aus", "Spiel\u00b7saal", ",", "Schlaf", "und", "Bet\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "APPRART", "NN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch ach, das Wort verlor das Leben und den Sinn;", "tokens": ["Doch", "ach", ",", "das", "Wort", "ver\u00b7lor", "das", "Le\u00b7ben", "und", "den", "Sinn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$,", "ART", "NN", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ward allen schwerer als die schwersten Ketten.", "tokens": ["Ward", "al\u00b7len", "schwe\u00b7rer", "als", "die", "schwers\u00b7ten", "Ket\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Wie klang \u00bbTitanic\u00ab erst unfa\u00dfbar gro\u00df!", "tokens": ["Wie", "klang", "\u00bb", "Ti\u00b7ta\u00b7nic", "\u00ab", "erst", "un\u00b7fa\u00df\u00b7bar", "gro\u00df", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$(", "NE", "$(", "ADV", "ADJD", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Un\u00fcberwindlich kam das starke Wort geschwommen,", "tokens": ["Un\u00b7\u00fc\u00b7berw\u00b7ind\u00b7lich", "kam", "das", "star\u00b7ke", "Wort", "ge\u00b7schwom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein unversinkbar Schiff, das aller Stolz geno\u00df.", "tokens": ["Ein", "un\u00b7ver\u00b7sink\u00b7bar", "Schiff", ",", "das", "al\u00b7ler", "Stolz", "ge\u00b7no\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu sp\u00e4t ward seine Maske ihm genommen.", "tokens": ["Zu", "sp\u00e4t", "ward", "sei\u00b7ne", "Mas\u00b7ke", "ihm", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VAFIN", "PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es war der Tod, verkappt, der hin zur Tiefe scho\u00df.", "tokens": ["Es", "war", "der", "Tod", ",", "ver\u00b7kappt", ",", "der", "hin", "zur", "Tie\u00b7fe", "scho\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "VVPP", "$,", "PRELS", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Der Tod, in jenes Riesenwort geh\u00fcllt, der bleiche,", "tokens": ["Der", "Tod", ",", "in", "je\u00b7nes", "Rie\u00b7sen\u00b7wort", "ge\u00b7h\u00fcllt", ",", "der", "blei\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PDAT", "NN", "VVPP", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat Tausend angelockt, die auf das Wort vertraut.", "tokens": ["Hat", "Tau\u00b7send", "an\u00b7ge\u00b7lockt", ",", "die", "auf", "das", "Wort", "ver\u00b7traut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "VVPP", "$,", "PRELS", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Toren trug er hin zu seinem Reiche,", "tokens": ["Die", "To\u00b7ren", "trug", "er", "hin", "zu", "sei\u00b7nem", "Rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die blind zum Wort \u00bbTitanic\u00ab aufgeschaut.", "tokens": ["Die", "blind", "zum", "Wort", "\u00bb", "Ti\u00b7ta\u00b7nic", "\u00ab", "auf\u00b7ge\u00b7schaut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "APPRART", "NN", "$(", "NE", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der Tod, er lenkte selbst des Steuerrades Speiche.", "tokens": ["Der", "Tod", ",", "er", "lenk\u00b7te", "selbst", "des", "Steu\u00b7er\u00b7ra\u00b7des", "Spei\u00b7che", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Der Tod, er stellt den Kurs zum Eisberg ein.", "tokens": ["Der", "Tod", ",", "er", "stellt", "den", "Kurs", "zum", "Eis\u00b7berg", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Eisberg, der Titan bei den Titanen,", "tokens": ["Der", "Eis\u00b7berg", ",", "der", "Ti\u00b7tan", "bei", "den", "Ti\u00b7ta\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-++-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Er soll des Schiffstitanen Henker sein.", "tokens": ["Er", "soll", "des", "Schiffs\u00b7ti\u00b7ta\u00b7nen", "Hen\u00b7ker", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Es wollte keiner hier des gro\u00dfen Wortes Schw\u00e4che ahnen,", "tokens": ["Es", "woll\u00b7te", "kei\u00b7ner", "hier", "des", "gro\u00b7\u00dfen", "Wor\u00b7tes", "Schw\u00e4\u00b7che", "ah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "ADV", "ART", "ADJA", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.5": {"text": "Es wiegte Stolz an Bord die tausend Ahnungslosen ein.", "tokens": ["Es", "wieg\u00b7te", "Stolz", "an", "Bord", "die", "tau\u00b7send", "Ah\u00b7nungs\u00b7lo\u00b7sen", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "ART", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.13": {"line.1": {"text": "Ich seh' noch festlich aus der Nacht den Schiffsrumpf ragen.", "tokens": ["Ich", "seh'", "noch", "fest\u00b7lich", "aus", "der", "Nacht", "den", "Schiffs\u00b7rumpf", "ra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie Reihen goldener Monde sind die Scheiben", "tokens": ["Wie", "Rei\u00b7hen", "gol\u00b7de\u00b7ner", "Mon\u00b7de", "sind", "die", "Schei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "ADJA", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der Fensterluken leuchtend an den Rumpf geschlagen,", "tokens": ["Der", "Fens\u00b7ter\u00b7lu\u00b7ken", "leuch\u00b7tend", "an", "den", "Rumpf", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ungeheure Wirbel schweren Rauches treiben", "tokens": ["Und", "un\u00b7ge\u00b7heu\u00b7re", "Wir\u00b7bel", "schwe\u00b7ren", "Rau\u00b7ches", "trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Aus den Vulkanen, die den Schiffsleib tragen.", "tokens": ["Aus", "den", "Vul\u00b7ka\u00b7nen", ",", "die", "den", "Schiffs\u00b7leib", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Es ist ein pr\u00e4chtig Bild in jenem Buch, das zu mir spricht,", "tokens": ["Es", "ist", "ein", "pr\u00e4ch\u00b7tig", "Bild", "in", "je\u00b7nem", "Buch", ",", "das", "zu", "mir", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "NN", "APPR", "PDAT", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Und dessen Zeilen weiter fort zerflie\u00dfen.", "tokens": ["Und", "des\u00b7sen", "Zei\u00b7len", "wei\u00b7ter", "fort", "zer\u00b7flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "ADV", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dann leuchtet fern auf wie Magnesiumlicht", "tokens": ["Dann", "leuch\u00b7tet", "fern", "auf", "wie", "Mag\u00b7ne\u00b7si\u00b7um\u00b7licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "PTKVZ", "KOKOM", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Zur Nacht die Helle jenes Eisbergriesen.", "tokens": ["Zur", "Nacht", "die", "Hel\u00b7le", "je\u00b7nes", "Eis\u00b7berg\u00b7rie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie mahnt wie an ein \u00fcbersinnliches Gesicht.", "tokens": ["Sie", "mahnt", "wie", "an", "ein", "\u00fc\u00b7ber\u00b7sinn\u00b7li\u00b7ches", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Und w\u00e4re nicht Triumph Schiffsherr gewesen,", "tokens": ["Und", "w\u00e4\u00b7re", "nicht", "Tri\u00b7umph", "Schiffs\u00b7herr", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "NN", "NN", "VAPP", "$,"], "meter": "-+--+-++-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "So w\u00e4re nie das Schreckliche geschehn;", "tokens": ["So", "w\u00e4\u00b7re", "nie", "das", "Schreck\u00b7li\u00b7che", "ge\u00b7schehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auch dieses konnte ich aus jenem Buche lesen.", "tokens": ["Auch", "die\u00b7ses", "konn\u00b7te", "ich", "aus", "je\u00b7nem", "Bu\u00b7che", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VMFIN", "PPER", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nie h\u00e4tte ich des Schiffes Untergang gesehn,", "tokens": ["Nie", "h\u00e4t\u00b7te", "ich", "des", "Schif\u00b7fes", "Un\u00b7ter\u00b7gang", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn Demut mitgefahren w\u00e4re, sie, die von weisem Wesen.", "tokens": ["Wenn", "De\u00b7mut", "mit\u00b7ge\u00b7fah\u00b7ren", "w\u00e4\u00b7re", ",", "sie", ",", "die", "von", "wei\u00b7sem", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "VAFIN", "$,", "PPER", "$,", "PRELS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.16": {"line.1": {"text": "So landete der Schall nur von dem Wort", "tokens": ["So", "lan\u00b7de\u00b7te", "der", "Schall", "nur", "von", "dem", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbtitanic\u00ab \u00fcberm Meer im Neuyork-Hafen.", "tokens": ["\u00bb", "ti\u00b7ta\u00b7nic", "\u00ab", "\u00fc\u00b7berm", "Meer", "im", "Neuyork\u00b7Ha\u00b7fen", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$(", "APPRART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Eistitan, er ri\u00df den Schiffstitanen in die Tiefe fort.", "tokens": ["Der", "Eis\u00b7ti\u00b7tan", ",", "er", "ri\u00df", "den", "Schiffs\u00b7ti\u00b7ta\u00b7nen", "in", "die", "Tie\u00b7fe", "fort", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.4": {"text": "Des Schiffes Anker niemals Land antrafen,", "tokens": ["Des", "Schif\u00b7fes", "An\u00b7ker", "nie\u00b7mals", "Land", "an\u00b7tra\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und nur ein Hilferuf drang zum Bestimmungsort.", "tokens": ["Und", "nur", "ein", "Hil\u00b7fe\u00b7ruf", "drang", "zum", "Be\u00b7stim\u00b7mungs\u00b7ort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Schwer wird es mir, der Bilderreihe nachzugehen,", "tokens": ["Schwer", "wird", "es", "mir", ",", "der", "Bil\u00b7der\u00b7rei\u00b7he", "nach\u00b7zu\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PPER", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die sich im Wirbel jetzt aus langen Zeilen rollt.", "tokens": ["Die", "sich", "im", "Wir\u00b7bel", "jetzt", "aus", "lan\u00b7gen", "Zei\u00b7len", "rollt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPRART", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich m\u00f6chte f\u00fcr die Untergehenden um Gnade flehen.", "tokens": ["Ich", "m\u00f6ch\u00b7te", "f\u00fcr", "die", "Un\u00b7ter\u00b7ge\u00b7hen\u00b7den", "um", "Gna\u00b7de", "fle\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "Ich m\u00f6chte rufen, da\u00df ihr alle retten sollt, \u2013", "tokens": ["Ich", "m\u00f6ch\u00b7te", "ru\u00b7fen", ",", "da\u00df", "ihr", "al\u00b7le", "ret\u00b7ten", "sollt", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "KOUS", "PPER", "PIS", "VVINF", "VMFIN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch gar zu schnell des Buches Schrecknisse sich drehen.", "tokens": ["Doch", "gar", "zu", "schnell", "des", "Bu\u00b7ches", "Schreck\u00b7nis\u00b7se", "sich", "dre\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKA", "ADJD", "ART", "ADJA", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Nachdem das Schiff mit voller Fahrt gerannt", "tokens": ["Nach\u00b7dem", "das", "Schiff", "mit", "vol\u00b7ler", "Fahrt", "ge\u00b7rannt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und ohne Furcht noch Vorsicht mehr zu kennen,", "tokens": ["Und", "oh\u00b7ne", "Furcht", "noch", "Vor\u00b7sicht", "mehr", "zu", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wird jenen \u00dcberm\u00fctigen am Eisberg bald bekannt,", "tokens": ["Wird", "je\u00b7nen", "\u00dc\u00b7berm\u00b7\u00fc\u00b7ti\u00b7gen", "am", "Eis\u00b7berg", "bald", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Da\u00df Toren nur ein Menschenwerk frech unverg\u00e4nglich nennen.", "tokens": ["Da\u00df", "To\u00b7ren", "nur", "ein", "Men\u00b7schen\u00b7werk", "frech", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ART", "NN", "ADJD", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.5": {"text": "Ach, alles Tun der Sterblichen ist an die Sterblichkeit gebannt.", "tokens": ["Ach", ",", "al\u00b7les", "Tun", "der", "Sterb\u00b7li\u00b7chen", "ist", "an", "die", "Sterb\u00b7lich\u00b7keit", "ge\u00b7bannt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PIAT", "NN", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.19": {"line.1": {"text": "Stets in der Ohnmacht mu\u00df das Sterbliche verschwinden,", "tokens": ["Stets", "in", "der", "Ohn\u00b7macht", "mu\u00df", "das", "Sterb\u00b7li\u00b7che", "ver\u00b7schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und unverg\u00e4nglich nenne nie die Menschentat.", "tokens": ["Und", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "nen\u00b7ne", "nie", "die", "Men\u00b7schen\u00b7tat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dem Starken kann sich stets ein St\u00e4rkerer noch finden,", "tokens": ["Dem", "Star\u00b7ken", "kann", "sich", "stets", "ein", "St\u00e4r\u00b7ke\u00b7rer", "noch", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADV", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Triumphierenden meist sein Triumph zertrat.", "tokens": ["Den", "Tri\u00b7um\u00b7phie\u00b7ren\u00b7den", "meist", "sein", "Tri\u00b7umph", "zer\u00b7trat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "An Wortprunk sollst du nicht dein Leben binden. \u2013", "tokens": ["An", "Wort\u00b7prunk", "sollst", "du", "nicht", "dein", "Le\u00b7ben", "bin\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "So hochget\u00fcrmt war dieses Schiff, da\u00df auf dem h\u00f6chsten Deck", "tokens": ["So", "hoch\u00b7ge\u00b7t\u00fcrmt", "war", "die\u00b7ses", "Schiff", ",", "da\u00df", "auf", "dem", "h\u00f6chs\u00b7ten", "Deck"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN", "PDAT", "NN", "$,", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Den Sto\u00df des Eises, der den Rumpf am Grund zerschnitten,", "tokens": ["Den", "Sto\u00df", "des", "Ei\u00b7ses", ",", "der", "den", "Rumpf", "am", "Grund", "zer\u00b7schnit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nicht einer sp\u00fcrt. Und auch die erste Kunde von dem Leck", "tokens": ["Nicht", "ei\u00b7ner", "sp\u00fcrt", ".", "Und", "auch", "die", "ers\u00b7te", "Kun\u00b7de", "von", "dem", "Leck"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "PIS", "VVFIN", "$.", "KON", "ADV", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Wird von den meisten leicht belacht, bestritten.", "tokens": ["Wird", "von", "den", "meis\u00b7ten", "leicht", "be\u00b7lacht", ",", "be\u00b7strit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "VVFIN", "ADJD", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Denn hier an Bord titanenhaft zu sein, das war vereint der Zweck.", "tokens": ["Denn", "hier", "an", "Bord", "ti\u00b7ta\u00b7nen\u00b7haft", "zu", "sein", ",", "das", "war", "ver\u00b7eint", "der", "Zweck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "ADJD", "PTKZU", "VAINF", "$,", "PDS", "VAFIN", "VVPP", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.21": {"line.1": {"text": "Es war des Schiffes allererste Fahrt. Es flog in Eile.", "tokens": ["Es", "war", "des", "Schif\u00b7fes", "al\u00b7le\u00b7rers\u00b7te", "Fahrt", ".", "Es", "flog", "in", "Ei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Man jagte Knoten \u00fcber Knoten ab,", "tokens": ["Man", "jag\u00b7te", "Kno\u00b7ten", "\u00fc\u00b7ber", "Kno\u00b7ten", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und man empfand das Jagen als Kurzweile.", "tokens": ["Und", "man", "emp\u00b7fand", "das", "Ja\u00b7gen", "als", "Kurz\u00b7wei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ART", "NN", "KOUS", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gesichert durch die wasserdichten Schotten vor Tod und Grab,", "tokens": ["Ge\u00b7si\u00b7chert", "durch", "die", "was\u00b7ser\u00b7dich\u00b7ten", "Schot\u00b7ten", "vor", "Tod", "und", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Wich man dem Eis nicht aus, um keine Meile.", "tokens": ["Wich", "man", "dem", "Eis", "nicht", "aus", ",", "um", "kei\u00b7ne", "Mei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "PTKNEG", "PTKVZ", "$,", "KOUI", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Man tanzte noch nach dem Zusammensto\u00df im Saal, der unber\u00fchrt,", "tokens": ["Man", "tanz\u00b7te", "noch", "nach", "dem", "Zu\u00b7sam\u00b7men\u00b7sto\u00df", "im", "Saal", ",", "der", "un\u00b7be\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "ART", "NN", "APPRART", "NN", "$,", "PRELS", "ADJD", "$,"], "meter": "-+-+---+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Und der in seinem Schwebegleichgewicht nicht schwankte.", "tokens": ["Und", "der", "in", "sei\u00b7nem", "Schwe\u00b7be\u00b7gleich\u00b7ge\u00b7wicht", "nicht", "schwank\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man scherzte, denn man wu\u00dfte vom Triumph gef\u00fchrt", "tokens": ["Man", "scherz\u00b7te", ",", "denn", "man", "wu\u00df\u00b7te", "vom", "Tri\u00b7umph", "ge\u00b7f\u00fchrt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "KON", "PIS", "VVFIN", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Schiff. Man spielte, schwatzte, zankte", "tokens": ["Das", "Schiff", ".", "Man", "spiel\u00b7te", ",", "schwatz\u00b7te", ",", "zank\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["ART", "NN", "$.", "PIS", "VVFIN", "$,", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Herzen, die der Tod bereits gek\u00fcrt.", "tokens": ["Mit", "Her\u00b7zen", ",", "die", "der", "Tod", "be\u00b7reits", "ge\u00b7k\u00fcrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Triumph der Technik gl\u00e4nzte in den R\u00e4umen,", "tokens": ["Tri\u00b7umph", "der", "Tech\u00b7nik", "gl\u00e4nz\u00b7te", "in", "den", "R\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Im Sport- und Spiel- und Badesaal,", "tokens": ["Im", "Spor\u00b7t", "und", "Spiel", "und", "Ba\u00b7de\u00b7saal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "TRUNC", "KON", "TRUNC", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und die Musik bei Tafel, bei der Speisen Wahl,", "tokens": ["Und", "die", "Mu\u00b7sik", "bei", "Ta\u00b7fel", ",", "bei", "der", "Spei\u00b7sen", "Wahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie \u00fcbert\u00f6nt des Meeres w\u00fcstes Sch\u00e4umen.", "tokens": ["Sie", "\u00fc\u00b7ber\u00b7t\u00f6nt", "des", "Mee\u00b7res", "w\u00fcs\u00b7tes", "Sch\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Schon sah ich, da\u00df der Schiffsrumpf schwerer ging", "tokens": ["Schon", "sah", "ich", ",", "da\u00df", "der", "Schiffs\u00b7rumpf", "schwe\u00b7rer", "ging"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und Lichterreihen tiefer Fenster schwanden.", "tokens": ["Und", "Lich\u00b7ter\u00b7rei\u00b7hen", "tie\u00b7fer", "Fens\u00b7ter", "schwan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und immer noch drang Lust und der Musik Gesing", "tokens": ["Und", "im\u00b7mer", "noch", "drang", "Lust", "und", "der", "Mu\u00b7sik", "Ge\u00b7sing"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "NN", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von all den Oberdecks, wo Angstger\u00fcchte keinen Eingang fanden,", "tokens": ["Von", "all", "den", "O\u00b7berd\u00b7ecks", ",", "wo", "Angst\u00b7ge\u00b7r\u00fcch\u00b7te", "kei\u00b7nen", "Ein\u00b7gang", "fan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "$,", "PWAV", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.5": {"text": "Weil dort der hellste Lebensglanz die Sterblichen umfing.", "tokens": ["Weil", "dort", "der", "hells\u00b7te", "Le\u00b7bens\u00b7glanz", "die", "Sterb\u00b7li\u00b7chen", "um\u00b7fing", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.25": {"line.1": {"text": "Des Eisbergs Wei\u00dfe leuchtet an den W\u00e4nden", "tokens": ["Des", "Eis\u00b7bergs", "Wei\u00b7\u00dfe", "leuch\u00b7tet", "an", "den", "W\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Schiffes, das im R\u00fcckw\u00e4rtsgehen st\u00f6hnt.", "tokens": ["Des", "Schif\u00b7fes", ",", "das", "im", "R\u00fcck\u00b7w\u00e4rts\u00b7ge\u00b7hen", "st\u00f6hnt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Tod jedoch l\u00e4\u00dft nicht den Schiffsrumpf aus den H\u00e4nden,", "tokens": ["Der", "Tod", "je\u00b7doch", "l\u00e4\u00dft", "nicht", "den", "Schiffs\u00b7rumpf", "aus", "den", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PTKNEG", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und die Maschinenkraft bald nur ged\u00e4mpft noch t\u00f6nt,", "tokens": ["Und", "die", "Ma\u00b7schi\u00b7nen\u00b7kraft", "bald", "nur", "ge\u00b7d\u00e4mpft", "noch", "t\u00f6nt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ADV", "VVPP", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hilflos bei Meeresmeilen und fern von K\u00fcsten und Gel\u00e4nden.", "tokens": ["Hil\u00b7flos", "bei", "Mee\u00b7res\u00b7mei\u00b7len", "und", "fern", "von", "K\u00fcs\u00b7ten", "und", "Ge\u00b7l\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "KON", "ADJD", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.26": {"line.1": {"text": "Das Schiff, das unversinkbar galt und stolz ins Meer hintrat,", "tokens": ["Das", "Schiff", ",", "das", "un\u00b7ver\u00b7sink\u00b7bar", "galt", "und", "stolz", "ins", "Meer", "hin\u00b7trat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "KON", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Vor einem Eishauch sollte es verschwinden!", "tokens": ["Vor", "ei\u00b7nem", "Eis\u00b7hauch", "soll\u00b7te", "es", "ver\u00b7schwin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die blind das Wort \u00bbTitanic\u00ab erst geblendet hat,", "tokens": ["Die", "blind", "das", "Wort", "\u00bb", "Ti\u00b7ta\u00b7nic", "\u00ab", "erst", "ge\u00b7blen\u00b7det", "hat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ART", "NN", "$(", "NE", "$(", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Tausend mu\u00dften rasch den Tod hier finden.", "tokens": ["Die", "Tau\u00b7send", "mu\u00df\u00b7ten", "rasch", "den", "Tod", "hier", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "An ihren Leibern werden weit im Meer die Fische satt.", "tokens": ["An", "ih\u00b7ren", "Lei\u00b7bern", "wer\u00b7den", "weit", "im", "Meer", "die", "Fi\u00b7sche", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ADJD", "APPRART", "NN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.27": {"line.1": {"text": "Zuerst noch \u00fcberflog der Schrei vom sterbenden Titanen Meilen.", "tokens": ["Zu\u00b7erst", "noch", "\u00fc\u00b7berf\u00b7log", "der", "Schrei", "vom", "ster\u00b7ben\u00b7den", "Ti\u00b7ta\u00b7nen", "Mei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.2": {"text": "Das Schiff lag still. Und hilferufend von dem hohen Mast", "tokens": ["Das", "Schiff", "lag", "still", ".", "Und", "hil\u00b7fe\u00b7ru\u00b7fend", "von", "dem", "ho\u00b7hen", "Mast"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "KON", "VVPP", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Zerknattern hin zur K\u00fcste mit dem Funkenspruch die Zeilen", "tokens": ["Zer\u00b7knat\u00b7tern", "hin", "zur", "K\u00fcs\u00b7te", "mit", "dem", "Fun\u00b7ken\u00b7spruch", "die", "Zei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "Und brachten zu den Menschen Schrei um Schrei mit Hast", "tokens": ["Und", "brach\u00b7ten", "zu", "den", "Men\u00b7schen", "Schrei", "um", "Schrei", "mit", "Hast"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "NN", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hin nach Europa und Amerika, die sich in die Titanenschmerzen teilen.", "tokens": ["Hin", "nach", "Eu\u00b7ro\u00b7pa", "und", "A\u00b7me\u00b7ri\u00b7ka", ",", "die", "sich", "in", "die", "Ti\u00b7ta\u00b7nen\u00b7schmer\u00b7zen", "tei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "KON", "NE", "$,", "PRELS", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.28": {"line.1": {"text": "Ein Sarg f\u00fcr Tausende, liegt auf dem gro\u00dfen Meere der Kolo\u00df.", "tokens": ["Ein", "Sarg", "f\u00fcr", "Tau\u00b7sen\u00b7de", ",", "liegt", "auf", "dem", "gro\u00b7\u00dfen", "Mee\u00b7re", "der", "Ko\u00b7lo\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "VVFIN", "APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+--+--+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Und auf ihm wimmelt's jetzt von all den kleinen", "tokens": ["Und", "auf", "ihm", "wim\u00b7melt's", "jetzt", "von", "all", "den", "klei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ADV", "APPR", "PIAT", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Begierdewesen, die der Eisberg aufger\u00fcttelt seit dem Todessto\u00df,", "tokens": ["Be\u00b7gier\u00b7de\u00b7we\u00b7sen", ",", "die", "der", "Eis\u00b7berg", "auf\u00b7ge\u00b7r\u00fct\u00b7telt", "seit", "dem", "To\u00b7des\u00b7sto\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.4": {"text": "Die aber nicht den Tod erkennen m\u00f6gen und die Gefahr verneinen.", "tokens": ["Die", "a\u00b7ber", "nicht", "den", "Tod", "er\u00b7ken\u00b7nen", "m\u00f6\u00b7gen", "und", "die", "Ge\u00b7fahr", "ver\u00b7nei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "ART", "NN", "VVINF", "VMFIN", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+--+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Sie d\u00fcnkten Sch\u00f6pfer sich noch immer und blieben, ach, Gesch\u00f6pfe blo\u00df.", "tokens": ["Sie", "d\u00fcnk\u00b7ten", "Sch\u00f6p\u00b7fer", "sich", "noch", "im\u00b7mer", "und", "blie\u00b7ben", ",", "ach", ",", "Ge\u00b7sch\u00f6p\u00b7fe", "blo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PRF", "ADV", "ADV", "KON", "VVFIN", "$,", "ITJ", "$,", "NN", "ADV", "$."], "meter": "-+-+--++--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.29": {"line.1": {"text": "Tief drinnen eilen durch des Schiffes helle G\u00e4nge", "tokens": ["Tief", "drin\u00b7nen", "ei\u00b7len", "durch", "des", "Schif\u00b7fes", "hel\u00b7le", "G\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "VVFIN", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Stewards, und sie klopfen kurz bei jedem an.", "tokens": ["Die", "Ste\u00b7wards", ",", "und", "sie", "klop\u00b7fen", "kurz", "bei", "je\u00b7dem", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "PPER", "VVFIN", "ADJD", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie klopfen an die tausend T\u00fcren in jenes Schiffes Riesenl\u00e4nge.", "tokens": ["Sie", "klop\u00b7fen", "an", "die", "tau\u00b7send", "T\u00fc\u00b7ren", "in", "je\u00b7nes", "Schif\u00b7fes", "Rie\u00b7sen\u00b7l\u00e4n\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "CARD", "NN", "APPR", "PDAT", "NN", "NN", "$."], "meter": "-+-+-+-+--+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Und an die tausend Herzen auch in jenem Riesenkahn", "tokens": ["Und", "an", "die", "tau\u00b7send", "Her\u00b7zen", "auch", "in", "je\u00b7nem", "Rie\u00b7sen\u00b7kahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "CARD", "NN", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.5": {"text": "T\u00f6nt knapp das Wort \u00bbGefahr\u00ab, dies Wort bel\u00e4chelt von der Menge.", "tokens": ["T\u00f6nt", "knapp", "das", "Wort", "\u00bb", "Ge\u00b7fahr", "\u00ab", ",", "dies", "Wort", "be\u00b7l\u00e4\u00b7chelt", "von", "der", "Men\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$(", "NN", "$(", "$,", "PDS", "NN", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.30": {"line.1": {"text": "Ein wenig Neugier weckt es erst nur hier und dort.", "tokens": ["Ein", "we\u00b7nig", "Neu\u00b7gier", "weckt", "es", "erst", "nur", "hier", "und", "dort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "PPER", "ADV", "ADV", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man witzelt und begleitet sich zu hellen Stufen,", "tokens": ["Man", "wit\u00b7zelt", "und", "be\u00b7glei\u00b7tet", "sich", "zu", "hel\u00b7len", "Stu\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Besteigt den Fahrstuhl und die Treppen, noch in dem Mund das Wort,", "tokens": ["Be\u00b7steigt", "den", "Fahr\u00b7stuhl", "und", "die", "Trep\u00b7pen", ",", "noch", "in", "dem", "Mund", "das", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "ART", "NN", "$,", "ADV", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Das ganz unglaubliche, das aufgetaucht da ungerufen", "tokens": ["Das", "ganz", "un\u00b7glaub\u00b7li\u00b7che", ",", "das", "auf\u00b7ge\u00b7taucht", "da", "un\u00b7ge\u00b7ru\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ADJA", "$,", "PDS", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.5": {"text": "Man h\u00f6rt es abermals und h\u00f6rt es fort und fort:", "tokens": ["Man", "h\u00f6rt", "es", "a\u00b7ber\u00b7mals", "und", "h\u00f6rt", "es", "fort", "und", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Gefahr! \u2013 Man will den Witz leibhaftig miterleben,", "tokens": ["Ge\u00b7fahr", "!", "\u2013", "Man", "will", "den", "Witz", "leib\u00b7haf\u00b7tig", "mi\u00b7ter\u00b7le\u00b7ben", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PIS", "VMFIN", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn nur ein Witzbold denkt hier an Gefahr,", "tokens": ["Denn", "nur", "ein", "Witz\u00b7bold", "denkt", "hier", "an", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo Tausende auf stolzer H\u00f6he des Triumphes schweben.", "tokens": ["Wo", "Tau\u00b7sen\u00b7de", "auf", "stol\u00b7zer", "H\u00f6\u00b7he", "des", "Tri\u00b7um\u00b7phes", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+---+-+-+-+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Denn nirgendwo man sicherer als hier im Schiffe war, \u2013", "tokens": ["Denn", "nir\u00b7gend\u00b7wo", "man", "si\u00b7che\u00b7rer", "als", "hier", "im", "Schif\u00b7fe", "war", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "PIS", "ADJD", "KOKOM", "ADV", "APPRART", "NN", "VAFIN", "$,", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.5": {"text": "Die Ingenieure hatten gestern erst dies Urteil abgegeben.", "tokens": ["Die", "In\u00b7ge\u00b7ni\u00b7eu\u00b7re", "hat\u00b7ten", "ge\u00b7stern", "erst", "dies", "Ur\u00b7teil", "ab\u00b7ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "PDS", "NN", "VVPP", "$."], "meter": "-+--+-+--+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.32": {"line.1": {"text": "Es staut sich noch kein sonderlich Gedr\u00e4ng',", "tokens": ["Es", "staut", "sich", "noch", "kein", "son\u00b7der\u00b7lich", "Ge\u00b7dr\u00e4ng'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PIAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Man bildet Gruppen zwanglos unter Plaudern.", "tokens": ["Man", "bil\u00b7det", "Grup\u00b7pen", "zwang\u00b7los", "un\u00b7ter", "Plau\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Auch dann wird nicht die Luft den Tausend eng,", "tokens": ["Auch", "dann", "wird", "nicht", "die", "Luft", "den", "Tau\u00b7send", "eng", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PTKNEG", "ART", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Als die Maschinen in dem Schiffsraum zaudern.", "tokens": ["Als", "die", "Ma\u00b7schi\u00b7nen", "in", "dem", "Schiffs\u00b7raum", "zau\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dort ordnet eine Dame noch ihr Ohrgeh\u00e4ng',", "tokens": ["Dort", "ord\u00b7net", "ei\u00b7ne", "Da\u00b7me", "noch", "ihr", "Ohr\u00b7ge\u00b7h\u00e4ng'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Und andere vor Spiegeln leicht ihr Haar betasten,", "tokens": ["Und", "an\u00b7de\u00b7re", "vor", "Spie\u00b7geln", "leicht", "ihr", "Haar", "be\u00b7tas\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "ADJD", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das sich ein wenig lockerte beim Tanz,", "tokens": ["Das", "sich", "ein", "we\u00b7nig", "lo\u00b7cker\u00b7te", "beim", "Tanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "ART", "PIS", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Beim Druck der Diademe und der Perlenlasten.", "tokens": ["Beim", "Druck", "der", "Di\u00b7a\u00b7de\u00b7me", "und", "der", "Per\u00b7len\u00b7las\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und an Gefahr glaubt keine unterm Lichterkranz,", "tokens": ["Und", "an", "Ge\u00b7fahr", "glaubt", "kei\u00b7ne", "un\u00b7term", "Lich\u00b7ter\u00b7kranz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "PIAT", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn auch dem Schiff die Atemz\u00fcge rasten.", "tokens": ["Wenn", "auch", "dem", "Schiff", "die", "A\u00b7tem\u00b7z\u00fc\u00b7ge", "ras\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Doch kaum ein St\u00fcndlein sp\u00e4ter sind entstellt", "tokens": ["Doch", "kaum", "ein", "St\u00fcnd\u00b7lein", "sp\u00e4\u00b7ter", "sind", "ent\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "ADJD", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Im gleichen Saal die gleichen Angesichter.", "tokens": ["Im", "glei\u00b7chen", "Saal", "die", "glei\u00b7chen", "An\u00b7ge\u00b7sich\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Noch immer gl\u00e4nzt dieselbe Spiegelwelt.", "tokens": ["Noch", "im\u00b7mer", "gl\u00e4nzt", "die\u00b7sel\u00b7be", "Spie\u00b7gel\u00b7welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die Menschenmenge aber keilt sich \u00e4ngstlich dichter", "tokens": ["Die", "Men\u00b7schen\u00b7men\u00b7ge", "a\u00b7ber", "keilt", "sich", "\u00e4ngst\u00b7lich", "dich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "PRF", "ADJD", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zum Bug, der wie ein Pferd sich hochgestellt ...", "tokens": ["Zum", "Bug", ",", "der", "wie", "ein", "Pferd", "sich", "hoch\u00b7ge\u00b7stellt", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "KOKOM", "ART", "NN", "PRF", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Die letzten Rettungsboote rudern weiter,", "tokens": ["Die", "letz\u00b7ten", "Ret\u00b7tungs\u00b7boo\u00b7te", "ru\u00b7dern", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein jedes nur ein Menschenh\u00e4uflein fa\u00dft.", "tokens": ["Ein", "je\u00b7des", "nur", "ein", "Men\u00b7schen\u00b7h\u00e4uf\u00b7lein", "fa\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Im Wasser aber schreien Hunderte, die gleich wie Reiter", "tokens": ["Im", "Was\u00b7ser", "a\u00b7ber", "schrei\u00b7en", "Hun\u00b7der\u00b7te", ",", "die", "gleich", "wie", "Rei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "ADJA", "NN", "$,", "PRELS", "ADV", "KOKOM", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "Die Wellen anzuspornen scheinen und in Hast", "tokens": ["Die", "Wel\u00b7len", "an\u00b7zu\u00b7spor\u00b7nen", "schei\u00b7nen", "und", "in", "Hast"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVIZU", "VVFIN", "KON", "APPR", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie Korke fliegend schwimmen, denn ein neues Wort w\u00e4chst breiter:", "tokens": ["Wie", "Kor\u00b7ke", "flie\u00b7gend", "schwim\u00b7men", ",", "denn", "ein", "neu\u00b7es", "Wort", "w\u00e4chst", "brei\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "VVINF", "$,", "KON", "ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.36": {"line.1": {"text": "\u00bbder Tod.\u00ab \u2013 Der dunkle Menschenhaufen auf dem Bug,", "tokens": ["\u00bb", "der", "Tod", ".", "\u00ab", "\u2013", "Der", "dunk\u00b7le", "Men\u00b7schen\u00b7hau\u00b7fen", "auf", "dem", "Bug", ","], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$.", "$(", "$(", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Aus dem Pistolensch\u00fcsse fallen, tobt unb\u00e4ndig.", "tokens": ["Aus", "dem", "Pis\u00b7to\u00b7len\u00b7sch\u00fcs\u00b7se", "fal\u00b7len", ",", "tobt", "un\u00b7b\u00e4n\u00b7dig", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Tod steht \u00fcberall jetzt auf, Gefahren gibt's genug.", "tokens": ["Der", "Tod", "steht", "\u00fc\u00b7be\u00b7rall", "jetzt", "auf", ",", "Ge\u00b7fah\u00b7ren", "gibt's", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "PTKVZ", "$,", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Die Elemente und die Menschen, sie werden laut gest\u00e4ndig,", "tokens": ["Die", "E\u00b7le\u00b7men\u00b7te", "und", "die", "Men\u00b7schen", ",", "sie", "wer\u00b7den", "laut", "ge\u00b7st\u00e4n\u00b7dig", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "PPER", "VAFIN", "ADJD", "ADJD", "$,"], "meter": "--+--+-+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Da\u00df Leben stets dem Leben, ach, die Todeswunden schlug.", "tokens": ["Da\u00df", "Le\u00b7ben", "stets", "dem", "Le\u00b7ben", ",", "ach", ",", "die", "To\u00b7des\u00b7wun\u00b7den", "schlug", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ART", "NN", "$,", "ITJ", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.37": {"line.1": {"text": "Sie alle raubten immer, um zu leben.", "tokens": ["Sie", "al\u00b7le", "raub\u00b7ten", "im\u00b7mer", ",", "um", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VVFIN", "ADV", "$,", "KOUI", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dem Tod sind wenig Freunde nur bekannt.", "tokens": ["Dem", "Tod", "sind", "we\u00b7nig", "Freun\u00b7de", "nur", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nur wenig sah ich, die sich friedlich ihm ergeben.", "tokens": ["Nur", "we\u00b7nig", "sah", "ich", ",", "die", "sich", "fried\u00b7lich", "ihm", "er\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPER", "$,", "PRELS", "PRF", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein altes Paar vor mir hat sich ihm l\u00e4chelnd zugewandt,", "tokens": ["Ein", "al\u00b7tes", "Paar", "vor", "mir", "hat", "sich", "ihm", "l\u00e4\u00b7chelnd", "zu\u00b7ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "VAFIN", "PRF", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Ich seh' der beiden Seelen vereint dem Tod entgegenschweben,", "tokens": ["Ich", "seh'", "der", "bei\u00b7den", "See\u00b7len", "ver\u00b7eint", "dem", "Tod", "ent\u00b7ge\u00b7gen\u00b7schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "PIAT", "NN", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.38": {"line.1": {"text": "Man wollt' die Gatten trennen. Doch die Frau", "tokens": ["Man", "wollt'", "die", "Gat\u00b7ten", "tren\u00b7nen", ".", "Doch", "die", "Frau"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ART", "NN", "VVINF", "$.", "KON", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mocht' nicht allein das Rettungsboot besteigen.", "tokens": ["Mocht'", "nicht", "al\u00b7lein", "das", "Ret\u00b7tungs\u00b7boot", "be\u00b7stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein lieblos Leben scheint der Lebensreifen rauh.", "tokens": ["Ein", "lieb\u00b7los", "Le\u00b7ben", "scheint", "der", "Le\u00b7bens\u00b7rei\u00b7fen", "rauh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So teilt sie mutig mit dem Mann das Todesschweigen,", "tokens": ["So", "teilt", "sie", "mu\u00b7tig", "mit", "dem", "Mann", "das", "To\u00b7des\u00b7schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und beide Alten, eng umarmt, sie halten lautlos Totenschau.", "tokens": ["Und", "bei\u00b7de", "Al\u00b7ten", ",", "eng", "um\u00b7armt", ",", "sie", "hal\u00b7ten", "laut\u00b7los", "To\u00b7ten\u00b7schau", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "ADJD", "VVPP", "$,", "PPER", "VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.39": {"line.1": {"text": "Und Segen auch verdienten sich noch viele;", "tokens": ["Und", "Se\u00b7gen", "auch", "ver\u00b7dien\u00b7ten", "sich", "noch", "vie\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "VVFIN", "PRF", "ADV", "PIS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf mancher Todesstunde Lorbeer ruht.", "tokens": ["Auf", "man\u00b7cher", "To\u00b7dess\u00b7tun\u00b7de", "Lor\u00b7beer", "ruht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Manch' Million\u00e4r, der nur des Lebens Spiele", "tokens": ["Man\u00b7ch'", "Mil\u00b7li\u00b7o\u00b7n\u00e4r", ",", "der", "nur", "des", "Le\u00b7bens", "Spie\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "NN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Gekannt, steht ab, zu retten sich sein Blut. \u2013", "tokens": ["Ge\u00b7kannt", ",", "steht", "ab", ",", "zu", "ret\u00b7ten", "sich", "sein", "Blut", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$,", "VVFIN", "PTKVZ", "$,", "PTKZU", "VVINF", "PRF", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Er nimmt die Rettung anderer zum Ziele ...", "tokens": ["Er", "nimmt", "die", "Ret\u00b7tung", "an\u00b7de\u00b7rer", "zum", "Zie\u00b7le", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.40": {"line.1": {"text": "Im Abendkleid, dem lang die Schleppe schleift,", "tokens": ["Im", "A\u00b7bend\u00b7kleid", ",", "dem", "lang", "die", "Schlep\u00b7pe", "schleift", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Stehn Damen fr\u00f6stelnd dichtgedr\u00e4ngt im Dunkel,", "tokens": ["Stehn", "Da\u00b7men", "fr\u00f6s\u00b7telnd", "dicht\u00b7ge\u00b7dr\u00e4ngt", "im", "Dun\u00b7kel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJD", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Den Hals und auch die Br\u00fcste wie bereift", "tokens": ["Den", "Hals", "und", "auch", "die", "Br\u00fcs\u00b7te", "wie", "be\u00b7reift"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADV", "ART", "NN", "KOKOM", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von Verlenprunk und Diamantgefunkel \u2013", "tokens": ["Von", "Ver\u00b7len\u00b7prunk", "und", "Di\u00b7a\u00b7mant\u00b7ge\u00b7fun\u00b7kel", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der Tod auch nach den Edelsteinen greift.", "tokens": ["Der", "Tod", "auch", "nach", "den", "E\u00b7del\u00b7stei\u00b7nen", "greift", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.41": {"line.1": {"text": "Das Licht ist jetzt erloschen in den R\u00e4umen,", "tokens": ["Das", "Licht", "ist", "jetzt", "er\u00b7lo\u00b7schen", "in", "den", "R\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch bringt man Kerzen und beleuchtet schnell.", "tokens": ["Doch", "bringt", "man", "Ker\u00b7zen", "und", "be\u00b7leuch\u00b7tet", "schnell", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "NN", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Wasser steigt, und n\u00e4her t\u00f6nt sein Sch\u00e4umen.", "tokens": ["Das", "Was\u00b7ser", "steigt", ",", "und", "n\u00e4\u00b7her", "t\u00f6nt", "sein", "Sch\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Kerzenschein erstreckt sich flackernd grell", "tokens": ["Der", "Ker\u00b7zen\u00b7schein", "er\u00b7streckt", "sich", "fla\u00b7ckernd", "grell"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADJD", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auf die vom Tod Gezeichneten, die noch vom Leben tr\u00e4umen.", "tokens": ["Auf", "die", "vom", "Tod", "Ge\u00b7zeich\u00b7ne\u00b7ten", ",", "die", "noch", "vom", "Le\u00b7ben", "tr\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPRART", "NN", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.42": {"line.1": {"text": "Der Kapit\u00e4n darf stolz die Hoffnung noch nicht sinken sehn.", "tokens": ["Der", "Ka\u00b7pi\u00b7t\u00e4n", "darf", "stolz", "die", "Hoff\u00b7nung", "noch", "nicht", "sin\u00b7ken", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "ART", "NN", "ADV", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Er mu\u00df des Meerpalastes Untergang verneinen,", "tokens": ["Er", "mu\u00df", "des", "Meer\u00b7pa\u00b7las\u00b7tes", "Un\u00b7ter\u00b7gang", "ver\u00b7nei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Solange knatternd noch die Funkenspr\u00fcche \u00fcbern Ozean gehn,", "tokens": ["So\u00b7lan\u00b7ge", "knat\u00b7ternd", "noch", "die", "Fun\u00b7ken\u00b7spr\u00fc\u00b7che", "\u00fc\u00b7bern", "O\u00b7ze\u00b7an", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+--+", "measure": "iambic.octa.plus.octa.plus.chol"}, "line.4": {"text": "Die sich wie letzte Lebensstrahlen rund um die Todesnot vereinen", "tokens": ["Die", "sich", "wie", "letz\u00b7te", "Le\u00b7bens\u00b7strah\u00b7len", "rund", "um", "die", "To\u00b7des\u00b7not", "ver\u00b7ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "KOKOM", "ADJA", "NN", "ADJD", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Und um zwei M\u00e4nner, die im Telegraphenraum im Wasser stehn.", "tokens": ["Und", "um", "zwei", "M\u00e4n\u00b7ner", ",", "die", "im", "Te\u00b7le\u00b7gra\u00b7phen\u00b7raum", "im", "Was\u00b7ser", "stehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "CARD", "NN", "$,", "PRELS", "APPRART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.43": {"line.1": {"text": "Das Grab nur konnte jene Braven von ihrem Lebensdienst entbinden.", "tokens": ["Das", "Grab", "nur", "konn\u00b7te", "je\u00b7ne", "Bra\u00b7ven", "von", "ih\u00b7rem", "Le\u00b7bens\u00b7dienst", "ent\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VMFIN", "PDAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Des Schiffes F\u00fchlung mit der Welt, sie schwand mit ihnen schwer.", "tokens": ["Des", "Schif\u00b7fes", "F\u00fch\u00b7lung", "mit", "der", "Welt", ",", "sie", "schwand", "mit", "ih\u00b7nen", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "APPR", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Den Rettungsg\u00fcrtel um, so funken sie, bis ihre Kr\u00e4fte schwinden,", "tokens": ["Den", "Ret\u00b7tungs\u00b7g\u00fcr\u00b7tel", "um", ",", "so", "fun\u00b7ken", "sie", ",", "bis", "ih\u00b7re", "Kr\u00e4f\u00b7te", "schwin\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.4": {"text": "Bis sie am Telegraphen abl\u00f6st stumm das Meer", "tokens": ["Bis", "sie", "am", "Te\u00b7le\u00b7gra\u00b7phen", "ab\u00b7l\u00f6st", "stumm", "das", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und sie als letzte Antwort dann den Tod am Apparate finden.", "tokens": ["Und", "sie", "als", "letz\u00b7te", "Ant\u00b7wort", "dann", "den", "Tod", "am", "Ap\u00b7pa\u00b7ra\u00b7te", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "KOUS", "ADJA", "NN", "ADV", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}}, "stanza.44": {"line.1": {"text": "Unheimlich w\u00e4chst das Wasser rund heran,", "tokens": ["Un\u00b7heim\u00b7lich", "w\u00e4chst", "das", "Was\u00b7ser", "rund", "he\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und manchem kehrt zur\u00fcck die ferne Seele,", "tokens": ["Und", "man\u00b7chem", "kehrt", "zu\u00b7r\u00fcck", "die", "fer\u00b7ne", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die hochm\u00fctig er l\u00e4ngst schon abgetan.", "tokens": ["Die", "hoch\u00b7m\u00fc\u00b7tig", "er", "l\u00e4ngst", "schon", "ab\u00b7ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Doch sitzt Gefahr dem Menschen an der Kehle,", "tokens": ["Doch", "sitzt", "Ge\u00b7fahr", "dem", "Men\u00b7schen", "an", "der", "Keh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Springt leicht der Zweifelnde auch in den Glaubenskahn.", "tokens": ["Springt", "leicht", "der", "Zwei\u00b7feln\u00b7de", "auch", "in", "den", "Glau\u00b7bens\u00b7kahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}}, "stanza.45": {"line.1": {"text": "Im Speisesaal, wo noch vor einer Stunde", "tokens": ["Im", "Spei\u00b7se\u00b7saal", ",", "wo", "noch", "vor", "ei\u00b7ner", "Stun\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "PWAV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gar festlich die befrackte Herrenschar", "tokens": ["Gar", "fest\u00b7lich", "die", "be\u00b7frack\u00b7te", "Her\u00b7ren\u00b7schar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den Schaumwein schl\u00fcrfte und das Lachen in der Runde", "tokens": ["Den", "Schaum\u00b7wein", "schl\u00fcrf\u00b7te", "und", "das", "La\u00b7chen", "in", "der", "Run\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KON", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aufdringlich dr\u00f6hnte, blind erhaben der Gefahr, \u2013", "tokens": ["Auf\u00b7dring\u00b7lich", "dr\u00f6hn\u00b7te", ",", "blind", "er\u00b7ha\u00b7ben", "der", "Ge\u00b7fahr", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "$,", "ADJD", "ADJD", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da halten Musikanten noch die Instrumente an dem Munde.", "tokens": ["Da", "hal\u00b7ten", "Mu\u00b7si\u00b7kan\u00b7ten", "noch", "die", "Inst\u00b7ru\u00b7men\u00b7te", "an", "dem", "Mun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}}, "stanza.46": {"line.1": {"text": "Und durch die Not klang \u00fcbers Schiff: \u00bbHin Gott zu dir!\u00ab", "tokens": ["Und", "durch", "die", "Not", "klang", "\u00fc\u00b7bers", "Schiff", ":", "\u00bb", "Hin", "Gott", "zu", "dir", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "APPRART", "NN", "$.", "$(", "NN", "NN", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und manches Auge weinte in dem Prunken", "tokens": ["Und", "man\u00b7ches", "Au\u00b7ge", "wein\u00b7te", "in", "dem", "Prun\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Des Saales, der geschm\u00fcckt mit goldner Zier,", "tokens": ["Des", "Saa\u00b7les", ",", "der", "ge\u00b7schm\u00fcckt", "mit", "gold\u00b7ner", "Zier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wo Violin und Fl\u00f6te jetzt noch t\u00f6netrunken", "tokens": ["Wo", "Vi\u00b7o\u00b7lin", "und", "Fl\u00f6\u00b7te", "jetzt", "noch", "t\u00f6\u00b7ne\u00b7trun\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "KON", "NN", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zum Frieden wiesen, fern der Lebensgier.", "tokens": ["Zum", "Frie\u00b7den", "wie\u00b7sen", ",", "fern", "der", "Le\u00b7bens\u00b7gier", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.47": {"line.1": {"text": "Das Schreien aber, das im Schiff sich r\u00fchrte,", "tokens": ["Das", "Schrei\u00b7en", "a\u00b7ber", ",", "das", "im", "Schiff", "sich", "r\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "APPRART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als krachend nun der Rumpf im Kesselraum zerri\u00df", "tokens": ["Als", "kra\u00b7chend", "nun", "der", "Rumpf", "im", "Kes\u00b7sel\u00b7raum", "zer\u00b7ri\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und Tausende zur Meerestiefe f\u00fchrte,", "tokens": ["Und", "Tau\u00b7sen\u00b7de", "zur", "Mee\u00b7res\u00b7tie\u00b7fe", "f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Schreien sich gar grimmig in mein Herz einbi\u00df,", "tokens": ["Das", "Schrei\u00b7en", "sich", "gar", "grim\u00b7mig", "in", "mein", "Herz", "ein\u00b7bi\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als w\u00e4r's mein eigen Leben, das ich sterbend sp\u00fcrte.", "tokens": ["Als", "w\u00e4r's", "mein", "ei\u00b7gen", "Le\u00b7ben", ",", "das", "ich", "ster\u00b7bend", "sp\u00fcr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Es schrie die Welt auf, die der Mensch gebaut,", "tokens": ["Es", "schrie", "die", "Welt", "auf", ",", "die", "der", "Mensch", "ge\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Es schrie die Sucht auf jener tausend Leben,", "tokens": ["Es", "schrie", "die", "Sucht", "auf", "je\u00b7ner", "tau\u00b7send", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PDAT", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die stolz der Menschen Eitelkeit vertraut.", "tokens": ["Die", "stolz", "der", "Men\u00b7schen", "Ei\u00b7tel\u00b7keit", "ver\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Es schrie die Lust, dem Tod den Tod zu geben,", "tokens": ["Es", "schrie", "die", "Lust", ",", "dem", "Tod", "den", "Tod", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es schrie der Glanz, dem vor dem Dunkel graut.", "tokens": ["Es", "schrie", "der", "Glanz", ",", "dem", "vor", "dem", "Dun\u00b7kel", "graut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.49": {"line.1": {"text": "Es schrien Stimmen, so wie Tiere br\u00fcllen,", "tokens": ["Es", "schri\u00b7en", "Stim\u00b7men", ",", "so", "wie", "Tie\u00b7re", "br\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "ADV", "KOKOM", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn sie der Mensch von ihrer Herde rei\u00dft ...", "tokens": ["Wenn", "sie", "der", "Mensch", "von", "ih\u00b7rer", "Her\u00b7de", "rei\u00dft", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dann sah ich alle Bilder sich verh\u00fcllen,", "tokens": ["Dann", "sah", "ich", "al\u00b7le", "Bil\u00b7der", "sich", "ver\u00b7h\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und eine Hand, die mich ins Leben weist,", "tokens": ["Und", "ei\u00b7ne", "Hand", ",", "die", "mich", "ins", "Le\u00b7ben", "weist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sie mu\u00df des Buches Seiten rasch zerkn\u00fcllen.", "tokens": ["Sie", "mu\u00df", "des", "Bu\u00b7ches", "Sei\u00b7ten", "rasch", "zer\u00b7kn\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.50": {"line.1": {"text": "Getragen von dem eisigsten der Winde,", "tokens": ["Ge\u00b7tra\u00b7gen", "von", "dem", "ei\u00b7sigs\u00b7ten", "der", "Win\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "ART", "NN", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Noch lange ich auf leeren Wassern flog,", "tokens": ["Noch", "lan\u00b7ge", "ich", "auf", "lee\u00b7ren", "Was\u00b7sern", "flog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und nicht sogleich ich wieder heimw\u00e4rts finde.", "tokens": ["Und", "nicht", "sog\u00b7leich", "ich", "wie\u00b7der", "heim\u00b7w\u00e4rts", "fin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein t\u00f6dlich kalter Atem mit mir zog,", "tokens": ["Ein", "t\u00f6d\u00b7lich", "kal\u00b7ter", "A\u00b7tem", "mit", "mir", "zog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Als schmolz das Sterben auch des Eisbergs Rinde.", "tokens": ["Als", "schmolz", "das", "Ster\u00b7ben", "auch", "des", "Eis\u00b7bergs", "Rin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.51": {"line.1": {"text": "Am Eise h\u00e4ngen sich die Toten fest,", "tokens": ["Am", "Ei\u00b7se", "h\u00e4n\u00b7gen", "sich", "die", "To\u00b7ten", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und Haufen Sterbende verr\u00f6cheln st\u00f6hnend.", "tokens": ["Und", "Hau\u00b7fen", "Ster\u00b7ben\u00b7de", "ver\u00b7r\u00f6\u00b7cheln", "st\u00f6h\u00b7nend", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Verschwunden ist des Schiffstitanen Rest.", "tokens": ["Ver\u00b7schwun\u00b7den", "ist", "des", "Schiffs\u00b7ti\u00b7ta\u00b7nen", "Rest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das Wasser rauscht an jener Stelle t\u00f6nend,", "tokens": ["Das", "Was\u00b7ser", "rauscht", "an", "je\u00b7ner", "Stel\u00b7le", "t\u00f6\u00b7nend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und nur der Tod h\u00e4lt noch ein wildes Fest.", "tokens": ["Und", "nur", "der", "Tod", "h\u00e4lt", "noch", "ein", "wil\u00b7des", "Fest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.52": {"line.1": {"text": "Von Zeit zu Zeit, da tauchten Boote auf.", "tokens": ["Von", "Zeit", "zu", "Zeit", ",", "da", "tauch\u00b7ten", "Boo\u00b7te", "auf", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$,", "KOUS", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich sah noch M\u00e4nner sich im Wasser raufen.", "tokens": ["Ich", "sah", "noch", "M\u00e4n\u00b7ner", "sich", "im", "Was\u00b7ser", "rau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Geschm\u00fcckte Frauen steuerten der Boote Lauf,", "tokens": ["Ge\u00b7schm\u00fcck\u00b7te", "Frau\u00b7en", "steu\u00b7er\u00b7ten", "der", "Boo\u00b7te", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich h\u00f6re Schwimmende um mich verschnaufen", "tokens": ["Ich", "h\u00f6\u00b7re", "Schwim\u00b7men\u00b7de", "um", "mich", "ver\u00b7schnau\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dicht bei der Leichen enggedr\u00e4ngtem Hauf ...", "tokens": ["Dicht", "bei", "der", "Lei\u00b7chen", "eng\u00b7ge\u00b7dr\u00e4ng\u00b7tem", "Hauf", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "ADJA", "NN", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.53": {"line.1": {"text": "Der Morgen kam mit seiner leichten R\u00f6te,", "tokens": ["Der", "Mor\u00b7gen", "kam", "mit", "sei\u00b7ner", "leich\u00b7ten", "R\u00f6\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als w\u00fc\u00dft' er nicht, was hier die Nacht gesehn.", "tokens": ["Als", "w\u00fc\u00dft'", "er", "nicht", ",", "was", "hier", "die", "Nacht", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PTKNEG", "$,", "PRELS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Welle aber sprach zur Welle weiter. \u00bbT\u00f6te!", "tokens": ["Die", "Wel\u00b7le", "a\u00b7ber", "sprach", "zur", "Wel\u00b7le", "wei\u00b7ter", ".", "\u00bb", "T\u00f6\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPRART", "NN", "PTKVZ", "$.", "$(", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein Leben soll hier dem Triumph des Todes heut entgehn.\u00ab", "tokens": ["Kein", "Le\u00b7ben", "soll", "hier", "dem", "Tri\u00b7umph", "des", "To\u00b7des", "heut", "ent\u00b7gehn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ADV", "ART", "NN", "ART", "NN", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.5": {"text": "Und da und dort versanken dann die menschenvollen B\u00f6te. \u2013", "tokens": ["Und", "da", "und", "dort", "ver\u00b7san\u00b7ken", "dann", "die", "men\u00b7schen\u00b7vol\u00b7len", "B\u00f6\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "KON", "ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.54": {"line.1": {"text": "Fern rotes bald und gr\u00fcnes Licht im Morgend\u00e4mmern blinkt, \u2013", "tokens": ["Fern", "ro\u00b7tes", "bald", "und", "gr\u00fc\u00b7nes", "Licht", "im", "Mor\u00b7gen\u00b7d\u00e4m\u00b7mern", "blinkt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADJA", "ADV", "KON", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Es sind Laternen eines Dampfers, den zur Nacht gerufen", "tokens": ["Es", "sind", "La\u00b7ter\u00b7nen", "ei\u00b7nes", "Damp\u00b7fers", ",", "den", "zur", "Nacht", "ge\u00b7ru\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.3": {"text": "Durch viele Meilen her der Telegraph. Man winkt.", "tokens": ["Durch", "vie\u00b7le", "Mei\u00b7len", "her", "der", "Te\u00b7le\u00b7gra\u00b7ph", ".", "Man", "winkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APZR", "ART", "NN", "$.", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "In allen Booten aber war es jetzt, als schufen", "tokens": ["In", "al\u00b7len", "Boo\u00b7ten", "a\u00b7ber", "war", "es", "jetzt", ",", "als", "schu\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIAT", "NN", "ADV", "VAFIN", "PPER", "ADV", "$,", "KOUS", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die beiden Lichter neu den Mut, der schon versinkt.", "tokens": ["Die", "bei\u00b7den", "Lich\u00b7ter", "neu", "den", "Mut", ",", "der", "schon", "ver\u00b7sinkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADJD", "ART", "NN", "$,", "PRELS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.55": {"line.1": {"text": "Der Dampfer l\u00e4\u00dft die Treppen zu den Booten nieder.", "tokens": ["Der", "Damp\u00b7fer", "l\u00e4\u00dft", "die", "Trep\u00b7pen", "zu", "den", "Boo\u00b7ten", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man kommt und rettet, wo man retten kann.", "tokens": ["Man", "kommt", "und", "ret\u00b7tet", ",", "wo", "man", "ret\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch die Geretteten erkennen nicht sofort das Leben wieder,", "tokens": ["Doch", "die", "Ge\u00b7ret\u00b7te\u00b7ten", "er\u00b7ken\u00b7nen", "nicht", "so\u00b7fort", "das", "Le\u00b7ben", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKNEG", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.4": {"text": "Und manche zarte Frau, die da im Boot gerudert hatte wie ein Mann,", "tokens": ["Und", "man\u00b7che", "zar\u00b7te", "Frau", ",", "die", "da", "im", "Boot", "ge\u00b7ru\u00b7dert", "hat\u00b7te", "wie", "ein", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "VVPP", "VAFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.5": {"text": "Sieht noch vor sich den Tod durch die ersch\u00f6pft geschlossenen Lider.", "tokens": ["Sieht", "noch", "vor", "sich", "den", "Tod", "durch", "die", "er\u00b7sch\u00f6pft", "ge\u00b7schlos\u00b7se\u00b7nen", "Li\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PRF", "ART", "NN", "APPR", "ART", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}}, "stanza.56": {"line.1": {"text": "Und viele, die man aus den Booten hebt, die schreien wild,", "tokens": ["Und", "vie\u00b7le", ",", "die", "man", "aus", "den", "Boo\u00b7ten", "hebt", ",", "die", "schrei\u00b7en", "wild", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PIS", "APPR", "ART", "NN", "VVFIN", "$,", "PRELS", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Sie wollen nicht vom Grab da unten scheiden.", "tokens": ["Sie", "wol\u00b7len", "nicht", "vom", "Grab", "da", "un\u00b7ten", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "APPRART", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In ihren Augen brennt noch Schreckensbild um Bild,", "tokens": ["In", "ih\u00b7ren", "Au\u00b7gen", "brennt", "noch", "Schre\u00b7ckens\u00b7bild", "um", "Bild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie wollen nicht gerettet sein von ihren Leiden, \u2013", "tokens": ["Sie", "wol\u00b7len", "nicht", "ge\u00b7ret\u00b7tet", "sein", "von", "ih\u00b7ren", "Lei\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVPP", "VAINF", "APPR", "PPOSAT", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es deckte ihre Liebsten zu der ungeheure Meeresschild.", "tokens": ["Es", "deck\u00b7te", "ih\u00b7re", "Liebs\u00b7ten", "zu", "der", "un\u00b7ge\u00b7heu\u00b7re", "Mee\u00b7res\u00b7schild", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.57": {"line.1": {"text": "Und andere, die sich ergeben in das Todeswerben,", "tokens": ["Und", "an\u00b7de\u00b7re", ",", "die", "sich", "er\u00b7ge\u00b7ben", "in", "das", "To\u00b7des\u00b7wer\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PRF", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Die sich schon ihrem Untergang vers\u00f6hnt,", "tokens": ["Die", "sich", "schon", "ih\u00b7rem", "Un\u00b7ter\u00b7gang", "ver\u00b7s\u00f6hnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie sehen in dem Tod nicht mehr Verderben \u2013", "tokens": ["Sie", "se\u00b7hen", "in", "dem", "Tod", "nicht", "mehr", "Ver\u00b7der\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKNEG", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Erl\u00f6sung von dem Dasein, das nur raubt und st\u00f6hnt.", "tokens": ["Er\u00b7l\u00f6\u00b7sung", "von", "dem", "Da\u00b7sein", ",", "das", "nur", "raubt", "und", "st\u00f6hnt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie wollen nie das Leben mehr betreten, \u2013 nur sterben, sterben.", "tokens": ["Sie", "wol\u00b7len", "nie", "das", "Le\u00b7ben", "mehr", "be\u00b7tre\u00b7ten", ",", "\u2013", "nur", "ster\u00b7ben", ",", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "ADV", "VVPP", "$,", "$(", "ADV", "VVINF", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+--+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.58": {"line.1": {"text": "Mit dem Geschmack des bittern Meeres noch im Mund", "tokens": ["Mit", "dem", "Ge\u00b7schmack", "des", "bit\u00b7tern", "Mee\u00b7res", "noch", "im", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und vor mir Leben, das die Hand mir leckte,", "tokens": ["Und", "vor", "mir", "Le\u00b7ben", ",", "das", "die", "Hand", "mir", "leck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "NN", "$,", "PRELS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Erwachte ich. Ans Knie strich mir mein Hund.", "tokens": ["Er\u00b7wach\u00b7te", "ich", ".", "Ans", "Knie", "strich", "mir", "mein", "Hund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "APPRART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Erstaunt ich mich in meinem Zimmerraum entdeckte,", "tokens": ["Er\u00b7staunt", "ich", "mich", "in", "mei\u00b7nem", "Zim\u00b7mer\u00b7raum", "ent\u00b7deck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Im Herzen noch der Schiffswelt Todesstund'.", "tokens": ["Im", "Her\u00b7zen", "noch", "der", "Schiffs\u00b7welt", "To\u00b7desstund'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.59": {"line.1": {"text": "Ich seh' den Hund an, der da vor mir kauert,", "tokens": ["Ich", "seh'", "den", "Hund", "an", ",", "der", "da", "vor", "mir", "kau\u00b7ert", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PRELS", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und der mit seinen Augen stumm mich fragt:", "tokens": ["Und", "der", "mit", "sei\u00b7nen", "Au\u00b7gen", "stumm", "mich", "fragt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "PPOSAT", "NN", "ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbherr, sprich, warum dein Menschenblut erschauert.", "tokens": ["\u00bb", "herr", ",", "sprich", ",", "wa\u00b7rum", "dein", "Men\u00b7schen\u00b7blut", "er\u00b7schau\u00b7ert", "."], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "ADJD", "$,", "PWAV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Stille um dich stundenlang schon klagt,", "tokens": ["Die", "Stil\u00b7le", "um", "dich", "stun\u00b7den\u00b7lang", "schon", "klagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sie rief mir zu: Sieh doch, dein Herr, er trauert.\u00ab \u2013", "tokens": ["Sie", "rief", "mir", "zu", ":", "Sieh", "doch", ",", "dein", "Herr", ",", "er", "trau\u00b7ert", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "NE", "ADV", "$,", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und ich besinne mich, da\u00df ich da n\u00e4chtens las", "tokens": ["Und", "ich", "be\u00b7sin\u00b7ne", "mich", ",", "da\u00df", "ich", "da", "n\u00e4ch\u00b7tens", "las"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Von einem gro\u00dfen Schiff das gro\u00dfe Untergehen,", "tokens": ["Von", "ei\u00b7nem", "gro\u00b7\u00dfen", "Schiff", "das", "gro\u00b7\u00dfe", "Un\u00b7ter\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und da\u00df ich miterlebt Titanenungl\u00fcck und des Todes Ha\u00df.", "tokens": ["Und", "da\u00df", "ich", "mi\u00b7ter\u00b7lebt", "Ti\u00b7ta\u00b7ne\u00b7nun\u00b7gl\u00fcck", "und", "des", "To\u00b7des", "Ha\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "NN", "KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+--+--+-+", "measure": "iambic.septa.relaxed"}, "line.9": {"text": "Beim Leben, das wir gerne triumphieren sehen,", "tokens": ["Beim", "Le\u00b7ben", ",", "das", "wir", "ger\u00b7ne", "tri\u00b7um\u00b7phie\u00b7ren", "se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Todesk\u00e4lte schon im Morgen sa\u00df.", "tokens": ["Die", "To\u00b7des\u00b7k\u00e4l\u00b7te", "schon", "im", "Mor\u00b7gen", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.60": {"line.1": {"text": "Noch jenen Traum im Aug', schau' ich zur Zimmerdiele,", "tokens": ["Noch", "je\u00b7nen", "Traum", "im", "Aug'", ",", "schau'", "ich", "zur", "Zim\u00b7mer\u00b7die\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "APPRART", "NN", "$,", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die wurde wie der Grund vom tiefen Meer.", "tokens": ["Die", "wur\u00b7de", "wie", "der", "Grund", "vom", "tie\u00b7fen", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "KOKOM", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erdr\u00fcckt von Haufen Gold sah ich der Menschen viele.", "tokens": ["Er\u00b7dr\u00fcckt", "von", "Hau\u00b7fen", "Gold", "sah", "ich", "der", "Men\u00b7schen", "vie\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "NN", "VVFIN", "PPER", "ART", "NN", "PIS", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn jener Schiffstitan, er war an Goldlast schwer.", "tokens": ["Denn", "je\u00b7ner", "Schiffs\u00b7ti\u00b7tan", ",", "er", "war", "an", "Gold\u00b7last", "schwer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "$,", "PPER", "VAFIN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u00bbdie Gl\u00fccklichen,\u00ab so seufzte ich, \u00bbsie kamen nun zum goldnen Ziele.\u00ab", "tokens": ["\u00bb", "die", "Gl\u00fcck\u00b7li\u00b7chen", ",", "\u00ab", "so", "seufz\u00b7te", "ich", ",", "\u00bb", "sie", "ka\u00b7men", "nun", "zum", "gold\u00b7nen", "Zie\u00b7le", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "$,", "$(", "ADV", "VVFIN", "PPER", "$,", "$(", "PPER", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}}, "stanza.61": {"line.1": {"text": "Ich sprach es, todeslustig noch, und wurde langsam wach.", "tokens": ["Ich", "sprach", "es", ",", "to\u00b7des\u00b7lus\u00b7tig", "noch", ",", "und", "wur\u00b7de", "lang\u00b7sam", "wach", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ADJD", "ADV", "$,", "KON", "VAFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Vor mir, zerpre\u00dft vom Gold, verschwanden jene Toten.", "tokens": ["Vor", "mir", ",", "zer\u00b7pre\u00dft", "vom", "Gold", ",", "ver\u00b7schwan\u00b7den", "je\u00b7ne", "To\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "VVFIN", "APPRART", "NN", "$,", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und drau\u00dfen stand die Sonne \u00fcberm Nachbardach,", "tokens": ["Und", "drau\u00b7\u00dfen", "stand", "die", "Son\u00b7ne", "\u00fc\u00b7berm", "Nach\u00b7bar\u00b7dach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ihre Strahlen mir ihr Lebenslicht anboten.", "tokens": ["Und", "ih\u00b7re", "Strah\u00b7len", "mir", "ihr", "Le\u00b7bens\u00b7licht", "an\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da griff mein Atem zu. Ich dachte nicht mehr hei\u00df dem Untergange nach.", "tokens": ["Da", "griff", "mein", "A\u00b7tem", "zu", ".", "Ich", "dach\u00b7te", "nicht", "mehr", "hei\u00df", "dem", "Un\u00b7ter\u00b7gan\u00b7ge", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PTKNEG", "ADV", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.62": {"line.1": {"text": "Ich streichelte den Hund, der lebenskr\u00e4ftig bellte,", "tokens": ["Ich", "strei\u00b7chel\u00b7te", "den", "Hund", ",", "der", "le\u00b7bens\u00b7kr\u00e4f\u00b7tig", "bell\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und f\u00fchlte mich von Sterbequalen frei.", "tokens": ["Und", "f\u00fchl\u00b7te", "mich", "von", "Ster\u00b7be\u00b7qua\u00b7len", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Licht, das s\u00fc\u00dfe, das mein Herz erhellte,", "tokens": ["Das", "Licht", ",", "das", "s\u00fc\u00b7\u00dfe", ",", "das", "mein", "Herz", "er\u00b7hell\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Entr\u00fcckte mich dem gro\u00dfen Todesschrei,", "tokens": ["Ent\u00b7r\u00fcck\u00b7te", "mich", "dem", "gro\u00b7\u00dfen", "To\u00b7des\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der fern in der Erinnerung noch gellte.", "tokens": ["Der", "fern", "in", "der", "E\u00b7rin\u00b7ne\u00b7rung", "noch", "gell\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.63": {"line.1": {"text": "Das Schicksalsbuch, darin ich weiterlas,", "tokens": ["Das", "Schick\u00b7sals\u00b7buch", ",", "da\u00b7rin", "ich", "wei\u00b7ter\u00b7las", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Es schlug mir neue Bilder auf und Seiten.", "tokens": ["Es", "schlug", "mir", "neu\u00b7e", "Bil\u00b7der", "auf", "und", "Sei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJA", "NN", "PTKVZ", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch zwischen neuen Zeilen ich es nie verga\u00df,", "tokens": ["Doch", "zwi\u00b7schen", "neu\u00b7en", "Zei\u00b7len", "ich", "es", "nie", "ver\u00b7ga\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Menschen ihrem Tun den Untergang bereiten,", "tokens": ["Da\u00df", "Men\u00b7schen", "ih\u00b7rem", "Tun", "den", "Un\u00b7ter\u00b7gang", "be\u00b7rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn nicht die Demut mit beim Werke sa\u00df.", "tokens": ["Wenn", "nicht", "die", "De\u00b7mut", "mit", "beim", "Wer\u00b7ke", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "APPR", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.64": {"line.1": {"text": "Mein Hund, mein Freund, der mir zu F\u00fc\u00dfen kauert,", "tokens": ["Mein", "Hund", ",", "mein", "Freund", ",", "der", "mir", "zu", "F\u00fc\u00b7\u00dfen", "kau\u00b7ert", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "St\u00f6\u00dft mit der Schnauze an mein Knie. Er fragt:", "tokens": ["St\u00f6\u00dft", "mit", "der", "Schnau\u00b7ze", "an", "mein", "Knie", ".", "Er", "fragt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "\u00bbherr, sprich, warum dein Menschenblut erschauert!", "tokens": ["\u00bb", "herr", ",", "sprich", ",", "wa\u00b7rum", "dein", "Men\u00b7schen\u00b7blut", "er\u00b7schau\u00b7ert", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "ADJD", "$,", "PWAV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Stille um dich stundenlang schon klagt,", "tokens": ["Die", "Stil\u00b7le", "um", "dich", "stun\u00b7den\u00b7lang", "schon", "klagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sie rief mir zu: Dein Herr, er trauert.\u00ab", "tokens": ["Sie", "rief", "mir", "zu", ":", "Dein", "Herr", ",", "er", "trau\u00b7ert", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Da so mein Hund im morgendlichen Raum", "tokens": ["Da", "so", "mein", "Hund", "im", "mor\u00b7gend\u00b7li\u00b7chen", "Raum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mich weckte, war ich lange wach gewesen,", "tokens": ["Mich", "weck\u00b7te", ",", "war", "ich", "lan\u00b7ge", "wach", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VAFIN", "PPER", "ADV", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Seit langem wach, und war doch tief im Traum.", "tokens": ["Seit", "lan\u00b7gem", "wach", ",", "und", "war", "doch", "tief", "im", "Traum", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "PTKVZ", "$,", "KON", "VAFIN", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mir war, ich hatte tagelang gelesen,", "tokens": ["Mir", "war", ",", "ich", "hat\u00b7te", "ta\u00b7ge\u00b7lang", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Nein, Jahre \u2013 oder nur Sekunden kaum.", "tokens": ["Nein", ",", "Jah\u00b7re", "\u2013", "o\u00b7der", "nur", "Se\u00b7kun\u00b7den", "kaum", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$(", "KON", "ADV", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.66": {"line.1": {"text": "Ich las in einem Buch, des Zeilen flossen", "tokens": ["Ich", "las", "in", "ei\u00b7nem", "Buch", ",", "des", "Zei\u00b7len", "flos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf jedem Blatt wie Welleng\u00e4nge fort.", "tokens": ["Auf", "je\u00b7dem", "Blatt", "wie", "Wel\u00b7len\u00b7g\u00e4n\u00b7ge", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KOKOM", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bald hell, bald dunkel, und zugleich zu gro\u00dfen", "tokens": ["Bald", "hell", ",", "bald", "dun\u00b7kel", ",", "und", "zu\u00b7gleich", "zu", "gro\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "KON", "ADV", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gestalten wuchsen Silben an und Wort,", "tokens": ["Ge\u00b7stal\u00b7ten", "wuch\u00b7sen", "Sil\u00b7ben", "an", "und", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "PTKVZ", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Raketen \u00e4hnlich, die die Nacht durchschossen.", "tokens": ["Ra\u00b7ke\u00b7ten", "\u00e4hn\u00b7lich", ",", "die", "die", "Nacht", "durch\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "PRELS", "ART", "NN", "VVPP", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.67": {"line.1": {"text": "Die Worte wurden reich ein Ozean.", "tokens": ["Die", "Wor\u00b7te", "wur\u00b7den", "reich", "ein", "O\u00b7ze\u00b7an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie wogten vor mir unterm Mondschein weiter,", "tokens": ["Sie", "wog\u00b7ten", "vor", "mir", "un\u00b7term", "Mond\u00b7schein", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und ein Wort kam als Schiffskolo\u00df heran.", "tokens": ["Und", "ein", "Wort", "kam", "als", "Schiffs\u00b7ko\u00b7lo\u00df", "he\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "KOUS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich las und glitt dem Mondlicht nach, das heiter", "tokens": ["Ich", "las", "und", "glitt", "dem", "Mond\u00b7licht", "nach", ",", "das", "hei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Auf weiten Wellen tastend tanzen kann.", "tokens": ["Auf", "wei\u00b7ten", "Wel\u00b7len", "tas\u00b7tend", "tan\u00b7zen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.68": {"line.1": {"text": "Doch dann erschreckte mich ein ungeheures Wesen.", "tokens": ["Doch", "dann", "er\u00b7schreck\u00b7te", "mich", "ein", "un\u00b7ge\u00b7heu\u00b7res", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es kam zu mir aus fernen Zeilen nah, \u2013", "tokens": ["Es", "kam", "zu", "mir", "aus", "fer\u00b7nen", "Zei\u00b7len", "nah", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "ADJA", "NN", "ADJD", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Wort, von dem ich in den B\u00fcchern mal gelesen,", "tokens": ["Ein", "Wort", ",", "von", "dem", "ich", "in", "den", "B\u00fc\u00b7chern", "mal", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "PPER", "APPR", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch dessen K\u00f6rper ich noch nie vor Augen sah.", "tokens": ["Doch", "des\u00b7sen", "K\u00f6r\u00b7per", "ich", "noch", "nie", "vor", "Au\u00b7gen", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "PPER", "ADV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und atemlos ist dann mein Traum gewesen.", "tokens": ["Und", "a\u00b7tem\u00b7los", "ist", "dann", "mein", "Traum", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ADV", "PPOSAT", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.69": {"line.1": {"text": "\u00bbeisberg\u00ab, \u2013 das Wort ging noch im Zimmer um,", "tokens": ["\u00bb", "eis\u00b7berg", "\u00ab", ",", "\u2013", "das", "Wort", "ging", "noch", "im", "Zim\u00b7mer", "um", ","], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$(", "$,", "$(", "ART", "NN", "VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Noch jetzt, da ich das H\u00fcndlein winseln h\u00f6rte.", "tokens": ["Noch", "jetzt", ",", "da", "ich", "das", "H\u00fcnd\u00b7lein", "win\u00b7seln", "h\u00f6r\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In meinen Ohren aber war ein wild Gesumm", "tokens": ["In", "mei\u00b7nen", "Oh\u00b7ren", "a\u00b7ber", "war", "ein", "wild", "Ge\u00b7summ"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VAFIN", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von Menschen und von Schiffsmaschinen, das mich st\u00f6rte.", "tokens": ["Von", "Men\u00b7schen", "und", "von", "Schiffs\u00b7ma\u00b7schi\u00b7nen", ",", "das", "mich", "st\u00f6r\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch vor mir in dem Zimmer stand der Morgen stumm.", "tokens": ["Doch", "vor", "mir", "in", "dem", "Zim\u00b7mer", "stand", "der", "Mor\u00b7gen", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.70": {"line.1": {"text": "Nicht ruhig aber lag im Land mein altes Zimmer.", "tokens": ["Nicht", "ru\u00b7hig", "a\u00b7ber", "lag", "im", "Land", "mein", "al\u00b7tes", "Zim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ADV", "VVFIN", "APPRART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es wanderte noch mit dem Eisberg fort,", "tokens": ["Es", "wan\u00b7der\u00b7te", "noch", "mit", "dem", "Eis\u00b7berg", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und auch durchs Fenster sah des Eises Schimmer.", "tokens": ["Und", "auch", "durchs", "Fens\u00b7ter", "sah", "des", "Ei\u00b7ses", "Schim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbtitanic\u00ab \u2013 war ein zweites gro\u00dfes Wort,", "tokens": ["\u00bb", "ti\u00b7ta\u00b7nic", "\u00ab", "\u2013", "war", "ein", "zwei\u00b7tes", "gro\u00b7\u00dfes", "Wort", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$(", "$(", "VAFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Das sagten meine Lippen lautlos immer.", "tokens": ["Das", "sag\u00b7ten", "mei\u00b7ne", "Lip\u00b7pen", "laut\u00b7los", "im\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "ADJD", "ADV", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.71": {"line.1": {"text": "\u00bbtitanic!\u00ab war ein zweiter gro\u00dfer Schrei.", "tokens": ["\u00bb", "ti\u00b7ta\u00b7nic", "!", "\u00ab", "war", "ein", "zwei\u00b7ter", "gro\u00b7\u00dfer", "Schrei", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$.", "$(", "VAFIN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Es trug ihn wohl nun schon zu hundert Malen", "tokens": ["Es", "trug", "ihn", "wohl", "nun", "schon", "zu", "hun\u00b7dert", "Ma\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADV", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mein Herz aus dieser Nacht zu mir herbei.", "tokens": ["Mein", "Herz", "aus", "die\u00b7ser", "Nacht", "zu", "mir", "her\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PDAT", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich sehe noch die Menschen, jene tausend fahlen,", "tokens": ["Ich", "se\u00b7he", "noch", "die", "Men\u00b7schen", ",", "je\u00b7ne", "tau\u00b7send", "fah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "PDAT", "CARD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die sanken mit dem Wort wie eine Welt aus Blei.", "tokens": ["Die", "san\u00b7ken", "mit", "dem", "Wort", "wie", "ei\u00b7ne", "Welt", "aus", "Blei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "KOKOM", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.72": {"line.1": {"text": "\u00bbtitanic!\u00ab schrieen sie. Das Wort, es sollte retten.", "tokens": ["\u00bb", "ti\u00b7ta\u00b7nic", "!", "\u00ab", "schri\u00b7een", "sie", ".", "Das", "Wort", ",", "es", "soll\u00b7te", "ret\u00b7ten", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$.", "$(", "VVFIN", "PPER", "$.", "ART", "NN", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie schleudern's tausendmal dem Eisberg hin", "tokens": ["Sie", "schleu\u00b7dern's", "tau\u00b7send\u00b7mal", "dem", "Eis\u00b7berg", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und fl\u00fcchten fort vom Tanz, aus Spielsaal, Schlaf und Betten.", "tokens": ["Und", "fl\u00fcch\u00b7ten", "fort", "vom", "Tanz", ",", "aus", "Spiel\u00b7saal", ",", "Schlaf", "und", "Bet\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "APPRART", "NN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch ach, das Wort verlor das Leben und den Sinn;", "tokens": ["Doch", "ach", ",", "das", "Wort", "ver\u00b7lor", "das", "Le\u00b7ben", "und", "den", "Sinn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$,", "ART", "NN", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ward allen schwerer als die schwersten Ketten.", "tokens": ["Ward", "al\u00b7len", "schwe\u00b7rer", "als", "die", "schwers\u00b7ten", "Ket\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.73": {"line.1": {"text": "Wie klang \u00bbTitanic\u00ab erst unfa\u00dfbar gro\u00df!", "tokens": ["Wie", "klang", "\u00bb", "Ti\u00b7ta\u00b7nic", "\u00ab", "erst", "un\u00b7fa\u00df\u00b7bar", "gro\u00df", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$(", "NE", "$(", "ADV", "ADJD", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Un\u00fcberwindlich kam das starke Wort geschwommen,", "tokens": ["Un\u00b7\u00fc\u00b7berw\u00b7ind\u00b7lich", "kam", "das", "star\u00b7ke", "Wort", "ge\u00b7schwom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein unversinkbar Schiff, das aller Stolz geno\u00df.", "tokens": ["Ein", "un\u00b7ver\u00b7sink\u00b7bar", "Schiff", ",", "das", "al\u00b7ler", "Stolz", "ge\u00b7no\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu sp\u00e4t ward seine Maske ihm genommen.", "tokens": ["Zu", "sp\u00e4t", "ward", "sei\u00b7ne", "Mas\u00b7ke", "ihm", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VAFIN", "PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es war der Tod, verkappt, der hin zur Tiefe scho\u00df.", "tokens": ["Es", "war", "der", "Tod", ",", "ver\u00b7kappt", ",", "der", "hin", "zur", "Tie\u00b7fe", "scho\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "VVPP", "$,", "PRELS", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.74": {"line.1": {"text": "Der Tod, in jenes Riesenwort geh\u00fcllt, der bleiche,", "tokens": ["Der", "Tod", ",", "in", "je\u00b7nes", "Rie\u00b7sen\u00b7wort", "ge\u00b7h\u00fcllt", ",", "der", "blei\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PDAT", "NN", "VVPP", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat Tausend angelockt, die auf das Wort vertraut.", "tokens": ["Hat", "Tau\u00b7send", "an\u00b7ge\u00b7lockt", ",", "die", "auf", "das", "Wort", "ver\u00b7traut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "VVPP", "$,", "PRELS", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Toren trug er hin zu seinem Reiche,", "tokens": ["Die", "To\u00b7ren", "trug", "er", "hin", "zu", "sei\u00b7nem", "Rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die blind zum Wort \u00bbTitanic\u00ab aufgeschaut.", "tokens": ["Die", "blind", "zum", "Wort", "\u00bb", "Ti\u00b7ta\u00b7nic", "\u00ab", "auf\u00b7ge\u00b7schaut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "APPRART", "NN", "$(", "NE", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der Tod, er lenkte selbst des Steuerrades Speiche.", "tokens": ["Der", "Tod", ",", "er", "lenk\u00b7te", "selbst", "des", "Steu\u00b7er\u00b7ra\u00b7des", "Spei\u00b7che", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.75": {"line.1": {"text": "Der Tod, er stellt den Kurs zum Eisberg ein.", "tokens": ["Der", "Tod", ",", "er", "stellt", "den", "Kurs", "zum", "Eis\u00b7berg", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Eisberg, der Titan bei den Titanen,", "tokens": ["Der", "Eis\u00b7berg", ",", "der", "Ti\u00b7tan", "bei", "den", "Ti\u00b7ta\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-++-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Er soll des Schiffstitanen Henker sein.", "tokens": ["Er", "soll", "des", "Schiffs\u00b7ti\u00b7ta\u00b7nen", "Hen\u00b7ker", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Es wollte keiner hier des gro\u00dfen Wortes Schw\u00e4che ahnen,", "tokens": ["Es", "woll\u00b7te", "kei\u00b7ner", "hier", "des", "gro\u00b7\u00dfen", "Wor\u00b7tes", "Schw\u00e4\u00b7che", "ah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "ADV", "ART", "ADJA", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.5": {"text": "Es wiegte Stolz an Bord die tausend Ahnungslosen ein.", "tokens": ["Es", "wieg\u00b7te", "Stolz", "an", "Bord", "die", "tau\u00b7send", "Ah\u00b7nungs\u00b7lo\u00b7sen", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "ART", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.76": {"line.1": {"text": "Ich seh' noch festlich aus der Nacht den Schiffsrumpf ragen.", "tokens": ["Ich", "seh'", "noch", "fest\u00b7lich", "aus", "der", "Nacht", "den", "Schiffs\u00b7rumpf", "ra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie Reihen goldener Monde sind die Scheiben", "tokens": ["Wie", "Rei\u00b7hen", "gol\u00b7de\u00b7ner", "Mon\u00b7de", "sind", "die", "Schei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "ADJA", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der Fensterluken leuchtend an den Rumpf geschlagen,", "tokens": ["Der", "Fens\u00b7ter\u00b7lu\u00b7ken", "leuch\u00b7tend", "an", "den", "Rumpf", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ungeheure Wirbel schweren Rauches treiben", "tokens": ["Und", "un\u00b7ge\u00b7heu\u00b7re", "Wir\u00b7bel", "schwe\u00b7ren", "Rau\u00b7ches", "trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Aus den Vulkanen, die den Schiffsleib tragen.", "tokens": ["Aus", "den", "Vul\u00b7ka\u00b7nen", ",", "die", "den", "Schiffs\u00b7leib", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.77": {"line.1": {"text": "Es ist ein pr\u00e4chtig Bild in jenem Buch, das zu mir spricht,", "tokens": ["Es", "ist", "ein", "pr\u00e4ch\u00b7tig", "Bild", "in", "je\u00b7nem", "Buch", ",", "das", "zu", "mir", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "NN", "APPR", "PDAT", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Und dessen Zeilen weiter fort zerflie\u00dfen.", "tokens": ["Und", "des\u00b7sen", "Zei\u00b7len", "wei\u00b7ter", "fort", "zer\u00b7flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "ADV", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dann leuchtet fern auf wie Magnesiumlicht", "tokens": ["Dann", "leuch\u00b7tet", "fern", "auf", "wie", "Mag\u00b7ne\u00b7si\u00b7um\u00b7licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "PTKVZ", "KOKOM", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Zur Nacht die Helle jenes Eisbergriesen.", "tokens": ["Zur", "Nacht", "die", "Hel\u00b7le", "je\u00b7nes", "Eis\u00b7berg\u00b7rie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie mahnt wie an ein \u00fcbersinnliches Gesicht.", "tokens": ["Sie", "mahnt", "wie", "an", "ein", "\u00fc\u00b7ber\u00b7sinn\u00b7li\u00b7ches", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.78": {"line.1": {"text": "Und w\u00e4re nicht Triumph Schiffsherr gewesen,", "tokens": ["Und", "w\u00e4\u00b7re", "nicht", "Tri\u00b7umph", "Schiffs\u00b7herr", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "NN", "NN", "VAPP", "$,"], "meter": "-+--+-++-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "So w\u00e4re nie das Schreckliche geschehn;", "tokens": ["So", "w\u00e4\u00b7re", "nie", "das", "Schreck\u00b7li\u00b7che", "ge\u00b7schehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auch dieses konnte ich aus jenem Buche lesen.", "tokens": ["Auch", "die\u00b7ses", "konn\u00b7te", "ich", "aus", "je\u00b7nem", "Bu\u00b7che", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VMFIN", "PPER", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nie h\u00e4tte ich des Schiffes Untergang gesehn,", "tokens": ["Nie", "h\u00e4t\u00b7te", "ich", "des", "Schif\u00b7fes", "Un\u00b7ter\u00b7gang", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn Demut mitgefahren w\u00e4re, sie, die von weisem Wesen.", "tokens": ["Wenn", "De\u00b7mut", "mit\u00b7ge\u00b7fah\u00b7ren", "w\u00e4\u00b7re", ",", "sie", ",", "die", "von", "wei\u00b7sem", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "VAFIN", "$,", "PPER", "$,", "PRELS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.79": {"line.1": {"text": "So landete der Schall nur von dem Wort", "tokens": ["So", "lan\u00b7de\u00b7te", "der", "Schall", "nur", "von", "dem", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbtitanic\u00ab \u00fcberm Meer im Neuyork-Hafen.", "tokens": ["\u00bb", "ti\u00b7ta\u00b7nic", "\u00ab", "\u00fc\u00b7berm", "Meer", "im", "Neuyork\u00b7Ha\u00b7fen", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$(", "APPRART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Eistitan, er ri\u00df den Schiffstitanen in die Tiefe fort.", "tokens": ["Der", "Eis\u00b7ti\u00b7tan", ",", "er", "ri\u00df", "den", "Schiffs\u00b7ti\u00b7ta\u00b7nen", "in", "die", "Tie\u00b7fe", "fort", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.4": {"text": "Des Schiffes Anker niemals Land antrafen,", "tokens": ["Des", "Schif\u00b7fes", "An\u00b7ker", "nie\u00b7mals", "Land", "an\u00b7tra\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und nur ein Hilferuf drang zum Bestimmungsort.", "tokens": ["Und", "nur", "ein", "Hil\u00b7fe\u00b7ruf", "drang", "zum", "Be\u00b7stim\u00b7mungs\u00b7ort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.80": {"line.1": {"text": "Schwer wird es mir, der Bilderreihe nachzugehen,", "tokens": ["Schwer", "wird", "es", "mir", ",", "der", "Bil\u00b7der\u00b7rei\u00b7he", "nach\u00b7zu\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PPER", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die sich im Wirbel jetzt aus langen Zeilen rollt.", "tokens": ["Die", "sich", "im", "Wir\u00b7bel", "jetzt", "aus", "lan\u00b7gen", "Zei\u00b7len", "rollt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPRART", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich m\u00f6chte f\u00fcr die Untergehenden um Gnade flehen.", "tokens": ["Ich", "m\u00f6ch\u00b7te", "f\u00fcr", "die", "Un\u00b7ter\u00b7ge\u00b7hen\u00b7den", "um", "Gna\u00b7de", "fle\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "Ich m\u00f6chte rufen, da\u00df ihr alle retten sollt, \u2013", "tokens": ["Ich", "m\u00f6ch\u00b7te", "ru\u00b7fen", ",", "da\u00df", "ihr", "al\u00b7le", "ret\u00b7ten", "sollt", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "KOUS", "PPER", "PIS", "VVINF", "VMFIN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch gar zu schnell des Buches Schrecknisse sich drehen.", "tokens": ["Doch", "gar", "zu", "schnell", "des", "Bu\u00b7ches", "Schreck\u00b7nis\u00b7se", "sich", "dre\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKA", "ADJD", "ART", "ADJA", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.81": {"line.1": {"text": "Nachdem das Schiff mit voller Fahrt gerannt", "tokens": ["Nach\u00b7dem", "das", "Schiff", "mit", "vol\u00b7ler", "Fahrt", "ge\u00b7rannt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und ohne Furcht noch Vorsicht mehr zu kennen,", "tokens": ["Und", "oh\u00b7ne", "Furcht", "noch", "Vor\u00b7sicht", "mehr", "zu", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wird jenen \u00dcberm\u00fctigen am Eisberg bald bekannt,", "tokens": ["Wird", "je\u00b7nen", "\u00dc\u00b7berm\u00b7\u00fc\u00b7ti\u00b7gen", "am", "Eis\u00b7berg", "bald", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Da\u00df Toren nur ein Menschenwerk frech unverg\u00e4nglich nennen.", "tokens": ["Da\u00df", "To\u00b7ren", "nur", "ein", "Men\u00b7schen\u00b7werk", "frech", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ART", "NN", "ADJD", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.5": {"text": "Ach, alles Tun der Sterblichen ist an die Sterblichkeit gebannt.", "tokens": ["Ach", ",", "al\u00b7les", "Tun", "der", "Sterb\u00b7li\u00b7chen", "ist", "an", "die", "Sterb\u00b7lich\u00b7keit", "ge\u00b7bannt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PIAT", "NN", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.82": {"line.1": {"text": "Stets in der Ohnmacht mu\u00df das Sterbliche verschwinden,", "tokens": ["Stets", "in", "der", "Ohn\u00b7macht", "mu\u00df", "das", "Sterb\u00b7li\u00b7che", "ver\u00b7schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und unverg\u00e4nglich nenne nie die Menschentat.", "tokens": ["Und", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "nen\u00b7ne", "nie", "die", "Men\u00b7schen\u00b7tat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dem Starken kann sich stets ein St\u00e4rkerer noch finden,", "tokens": ["Dem", "Star\u00b7ken", "kann", "sich", "stets", "ein", "St\u00e4r\u00b7ke\u00b7rer", "noch", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADV", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Triumphierenden meist sein Triumph zertrat.", "tokens": ["Den", "Tri\u00b7um\u00b7phie\u00b7ren\u00b7den", "meist", "sein", "Tri\u00b7umph", "zer\u00b7trat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "An Wortprunk sollst du nicht dein Leben binden. \u2013", "tokens": ["An", "Wort\u00b7prunk", "sollst", "du", "nicht", "dein", "Le\u00b7ben", "bin\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.83": {"line.1": {"text": "So hochget\u00fcrmt war dieses Schiff, da\u00df auf dem h\u00f6chsten Deck", "tokens": ["So", "hoch\u00b7ge\u00b7t\u00fcrmt", "war", "die\u00b7ses", "Schiff", ",", "da\u00df", "auf", "dem", "h\u00f6chs\u00b7ten", "Deck"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN", "PDAT", "NN", "$,", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Den Sto\u00df des Eises, der den Rumpf am Grund zerschnitten,", "tokens": ["Den", "Sto\u00df", "des", "Ei\u00b7ses", ",", "der", "den", "Rumpf", "am", "Grund", "zer\u00b7schnit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nicht einer sp\u00fcrt. Und auch die erste Kunde von dem Leck", "tokens": ["Nicht", "ei\u00b7ner", "sp\u00fcrt", ".", "Und", "auch", "die", "ers\u00b7te", "Kun\u00b7de", "von", "dem", "Leck"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "PIS", "VVFIN", "$.", "KON", "ADV", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Wird von den meisten leicht belacht, bestritten.", "tokens": ["Wird", "von", "den", "meis\u00b7ten", "leicht", "be\u00b7lacht", ",", "be\u00b7strit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "VVFIN", "ADJD", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Denn hier an Bord titanenhaft zu sein, das war vereint der Zweck.", "tokens": ["Denn", "hier", "an", "Bord", "ti\u00b7ta\u00b7nen\u00b7haft", "zu", "sein", ",", "das", "war", "ver\u00b7eint", "der", "Zweck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "ADJD", "PTKZU", "VAINF", "$,", "PDS", "VAFIN", "VVPP", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.84": {"line.1": {"text": "Es war des Schiffes allererste Fahrt. Es flog in Eile.", "tokens": ["Es", "war", "des", "Schif\u00b7fes", "al\u00b7le\u00b7rers\u00b7te", "Fahrt", ".", "Es", "flog", "in", "Ei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Man jagte Knoten \u00fcber Knoten ab,", "tokens": ["Man", "jag\u00b7te", "Kno\u00b7ten", "\u00fc\u00b7ber", "Kno\u00b7ten", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und man empfand das Jagen als Kurzweile.", "tokens": ["Und", "man", "emp\u00b7fand", "das", "Ja\u00b7gen", "als", "Kurz\u00b7wei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ART", "NN", "KOUS", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gesichert durch die wasserdichten Schotten vor Tod und Grab,", "tokens": ["Ge\u00b7si\u00b7chert", "durch", "die", "was\u00b7ser\u00b7dich\u00b7ten", "Schot\u00b7ten", "vor", "Tod", "und", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Wich man dem Eis nicht aus, um keine Meile.", "tokens": ["Wich", "man", "dem", "Eis", "nicht", "aus", ",", "um", "kei\u00b7ne", "Mei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "PTKNEG", "PTKVZ", "$,", "KOUI", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.85": {"line.1": {"text": "Man tanzte noch nach dem Zusammensto\u00df im Saal, der unber\u00fchrt,", "tokens": ["Man", "tanz\u00b7te", "noch", "nach", "dem", "Zu\u00b7sam\u00b7men\u00b7sto\u00df", "im", "Saal", ",", "der", "un\u00b7be\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "ART", "NN", "APPRART", "NN", "$,", "PRELS", "ADJD", "$,"], "meter": "-+-+---+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Und der in seinem Schwebegleichgewicht nicht schwankte.", "tokens": ["Und", "der", "in", "sei\u00b7nem", "Schwe\u00b7be\u00b7gleich\u00b7ge\u00b7wicht", "nicht", "schwank\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man scherzte, denn man wu\u00dfte vom Triumph gef\u00fchrt", "tokens": ["Man", "scherz\u00b7te", ",", "denn", "man", "wu\u00df\u00b7te", "vom", "Tri\u00b7umph", "ge\u00b7f\u00fchrt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "KON", "PIS", "VVFIN", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Schiff. Man spielte, schwatzte, zankte", "tokens": ["Das", "Schiff", ".", "Man", "spiel\u00b7te", ",", "schwatz\u00b7te", ",", "zank\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["ART", "NN", "$.", "PIS", "VVFIN", "$,", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Herzen, die der Tod bereits gek\u00fcrt.", "tokens": ["Mit", "Her\u00b7zen", ",", "die", "der", "Tod", "be\u00b7reits", "ge\u00b7k\u00fcrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.86": {"line.1": {"text": "Triumph der Technik gl\u00e4nzte in den R\u00e4umen,", "tokens": ["Tri\u00b7umph", "der", "Tech\u00b7nik", "gl\u00e4nz\u00b7te", "in", "den", "R\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Im Sport- und Spiel- und Badesaal,", "tokens": ["Im", "Spor\u00b7t", "und", "Spiel", "und", "Ba\u00b7de\u00b7saal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "TRUNC", "KON", "TRUNC", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und die Musik bei Tafel, bei der Speisen Wahl,", "tokens": ["Und", "die", "Mu\u00b7sik", "bei", "Ta\u00b7fel", ",", "bei", "der", "Spei\u00b7sen", "Wahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie \u00fcbert\u00f6nt des Meeres w\u00fcstes Sch\u00e4umen.", "tokens": ["Sie", "\u00fc\u00b7ber\u00b7t\u00f6nt", "des", "Mee\u00b7res", "w\u00fcs\u00b7tes", "Sch\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.87": {"line.1": {"text": "Schon sah ich, da\u00df der Schiffsrumpf schwerer ging", "tokens": ["Schon", "sah", "ich", ",", "da\u00df", "der", "Schiffs\u00b7rumpf", "schwe\u00b7rer", "ging"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und Lichterreihen tiefer Fenster schwanden.", "tokens": ["Und", "Lich\u00b7ter\u00b7rei\u00b7hen", "tie\u00b7fer", "Fens\u00b7ter", "schwan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und immer noch drang Lust und der Musik Gesing", "tokens": ["Und", "im\u00b7mer", "noch", "drang", "Lust", "und", "der", "Mu\u00b7sik", "Ge\u00b7sing"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "NN", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von all den Oberdecks, wo Angstger\u00fcchte keinen Eingang fanden,", "tokens": ["Von", "all", "den", "O\u00b7berd\u00b7ecks", ",", "wo", "Angst\u00b7ge\u00b7r\u00fcch\u00b7te", "kei\u00b7nen", "Ein\u00b7gang", "fan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "$,", "PWAV", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.5": {"text": "Weil dort der hellste Lebensglanz die Sterblichen umfing.", "tokens": ["Weil", "dort", "der", "hells\u00b7te", "Le\u00b7bens\u00b7glanz", "die", "Sterb\u00b7li\u00b7chen", "um\u00b7fing", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.88": {"line.1": {"text": "Des Eisbergs Wei\u00dfe leuchtet an den W\u00e4nden", "tokens": ["Des", "Eis\u00b7bergs", "Wei\u00b7\u00dfe", "leuch\u00b7tet", "an", "den", "W\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Schiffes, das im R\u00fcckw\u00e4rtsgehen st\u00f6hnt.", "tokens": ["Des", "Schif\u00b7fes", ",", "das", "im", "R\u00fcck\u00b7w\u00e4rts\u00b7ge\u00b7hen", "st\u00f6hnt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Tod jedoch l\u00e4\u00dft nicht den Schiffsrumpf aus den H\u00e4nden,", "tokens": ["Der", "Tod", "je\u00b7doch", "l\u00e4\u00dft", "nicht", "den", "Schiffs\u00b7rumpf", "aus", "den", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PTKNEG", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und die Maschinenkraft bald nur ged\u00e4mpft noch t\u00f6nt,", "tokens": ["Und", "die", "Ma\u00b7schi\u00b7nen\u00b7kraft", "bald", "nur", "ge\u00b7d\u00e4mpft", "noch", "t\u00f6nt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ADV", "VVPP", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hilflos bei Meeresmeilen und fern von K\u00fcsten und Gel\u00e4nden.", "tokens": ["Hil\u00b7flos", "bei", "Mee\u00b7res\u00b7mei\u00b7len", "und", "fern", "von", "K\u00fcs\u00b7ten", "und", "Ge\u00b7l\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "KON", "ADJD", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.89": {"line.1": {"text": "Das Schiff, das unversinkbar galt und stolz ins Meer hintrat,", "tokens": ["Das", "Schiff", ",", "das", "un\u00b7ver\u00b7sink\u00b7bar", "galt", "und", "stolz", "ins", "Meer", "hin\u00b7trat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "KON", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Vor einem Eishauch sollte es verschwinden!", "tokens": ["Vor", "ei\u00b7nem", "Eis\u00b7hauch", "soll\u00b7te", "es", "ver\u00b7schwin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die blind das Wort \u00bbTitanic\u00ab erst geblendet hat,", "tokens": ["Die", "blind", "das", "Wort", "\u00bb", "Ti\u00b7ta\u00b7nic", "\u00ab", "erst", "ge\u00b7blen\u00b7det", "hat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ART", "NN", "$(", "NE", "$(", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Tausend mu\u00dften rasch den Tod hier finden.", "tokens": ["Die", "Tau\u00b7send", "mu\u00df\u00b7ten", "rasch", "den", "Tod", "hier", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "An ihren Leibern werden weit im Meer die Fische satt.", "tokens": ["An", "ih\u00b7ren", "Lei\u00b7bern", "wer\u00b7den", "weit", "im", "Meer", "die", "Fi\u00b7sche", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ADJD", "APPRART", "NN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.90": {"line.1": {"text": "Zuerst noch \u00fcberflog der Schrei vom sterbenden Titanen Meilen.", "tokens": ["Zu\u00b7erst", "noch", "\u00fc\u00b7berf\u00b7log", "der", "Schrei", "vom", "ster\u00b7ben\u00b7den", "Ti\u00b7ta\u00b7nen", "Mei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.2": {"text": "Das Schiff lag still. Und hilferufend von dem hohen Mast", "tokens": ["Das", "Schiff", "lag", "still", ".", "Und", "hil\u00b7fe\u00b7ru\u00b7fend", "von", "dem", "ho\u00b7hen", "Mast"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "KON", "VVPP", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Zerknattern hin zur K\u00fcste mit dem Funkenspruch die Zeilen", "tokens": ["Zer\u00b7knat\u00b7tern", "hin", "zur", "K\u00fcs\u00b7te", "mit", "dem", "Fun\u00b7ken\u00b7spruch", "die", "Zei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "Und brachten zu den Menschen Schrei um Schrei mit Hast", "tokens": ["Und", "brach\u00b7ten", "zu", "den", "Men\u00b7schen", "Schrei", "um", "Schrei", "mit", "Hast"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "NN", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hin nach Europa und Amerika, die sich in die Titanenschmerzen teilen.", "tokens": ["Hin", "nach", "Eu\u00b7ro\u00b7pa", "und", "A\u00b7me\u00b7ri\u00b7ka", ",", "die", "sich", "in", "die", "Ti\u00b7ta\u00b7nen\u00b7schmer\u00b7zen", "tei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "KON", "NE", "$,", "PRELS", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.91": {"line.1": {"text": "Ein Sarg f\u00fcr Tausende, liegt auf dem gro\u00dfen Meere der Kolo\u00df.", "tokens": ["Ein", "Sarg", "f\u00fcr", "Tau\u00b7sen\u00b7de", ",", "liegt", "auf", "dem", "gro\u00b7\u00dfen", "Mee\u00b7re", "der", "Ko\u00b7lo\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "VVFIN", "APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+--+--+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Und auf ihm wimmelt's jetzt von all den kleinen", "tokens": ["Und", "auf", "ihm", "wim\u00b7melt's", "jetzt", "von", "all", "den", "klei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ADV", "APPR", "PIAT", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Begierdewesen, die der Eisberg aufger\u00fcttelt seit dem Todessto\u00df,", "tokens": ["Be\u00b7gier\u00b7de\u00b7we\u00b7sen", ",", "die", "der", "Eis\u00b7berg", "auf\u00b7ge\u00b7r\u00fct\u00b7telt", "seit", "dem", "To\u00b7des\u00b7sto\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.4": {"text": "Die aber nicht den Tod erkennen m\u00f6gen und die Gefahr verneinen.", "tokens": ["Die", "a\u00b7ber", "nicht", "den", "Tod", "er\u00b7ken\u00b7nen", "m\u00f6\u00b7gen", "und", "die", "Ge\u00b7fahr", "ver\u00b7nei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "ART", "NN", "VVINF", "VMFIN", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+--+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Sie d\u00fcnkten Sch\u00f6pfer sich noch immer und blieben, ach, Gesch\u00f6pfe blo\u00df.", "tokens": ["Sie", "d\u00fcnk\u00b7ten", "Sch\u00f6p\u00b7fer", "sich", "noch", "im\u00b7mer", "und", "blie\u00b7ben", ",", "ach", ",", "Ge\u00b7sch\u00f6p\u00b7fe", "blo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PRF", "ADV", "ADV", "KON", "VVFIN", "$,", "ITJ", "$,", "NN", "ADV", "$."], "meter": "-+-+--++--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.92": {"line.1": {"text": "Tief drinnen eilen durch des Schiffes helle G\u00e4nge", "tokens": ["Tief", "drin\u00b7nen", "ei\u00b7len", "durch", "des", "Schif\u00b7fes", "hel\u00b7le", "G\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "VVFIN", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Stewards, und sie klopfen kurz bei jedem an.", "tokens": ["Die", "Ste\u00b7wards", ",", "und", "sie", "klop\u00b7fen", "kurz", "bei", "je\u00b7dem", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "PPER", "VVFIN", "ADJD", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie klopfen an die tausend T\u00fcren in jenes Schiffes Riesenl\u00e4nge.", "tokens": ["Sie", "klop\u00b7fen", "an", "die", "tau\u00b7send", "T\u00fc\u00b7ren", "in", "je\u00b7nes", "Schif\u00b7fes", "Rie\u00b7sen\u00b7l\u00e4n\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "CARD", "NN", "APPR", "PDAT", "NN", "NN", "$."], "meter": "-+-+-+-+--+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Und an die tausend Herzen auch in jenem Riesenkahn", "tokens": ["Und", "an", "die", "tau\u00b7send", "Her\u00b7zen", "auch", "in", "je\u00b7nem", "Rie\u00b7sen\u00b7kahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "CARD", "NN", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.5": {"text": "T\u00f6nt knapp das Wort \u00bbGefahr\u00ab, dies Wort bel\u00e4chelt von der Menge.", "tokens": ["T\u00f6nt", "knapp", "das", "Wort", "\u00bb", "Ge\u00b7fahr", "\u00ab", ",", "dies", "Wort", "be\u00b7l\u00e4\u00b7chelt", "von", "der", "Men\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$(", "NN", "$(", "$,", "PDS", "NN", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.93": {"line.1": {"text": "Ein wenig Neugier weckt es erst nur hier und dort.", "tokens": ["Ein", "we\u00b7nig", "Neu\u00b7gier", "weckt", "es", "erst", "nur", "hier", "und", "dort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "PPER", "ADV", "ADV", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man witzelt und begleitet sich zu hellen Stufen,", "tokens": ["Man", "wit\u00b7zelt", "und", "be\u00b7glei\u00b7tet", "sich", "zu", "hel\u00b7len", "Stu\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Besteigt den Fahrstuhl und die Treppen, noch in dem Mund das Wort,", "tokens": ["Be\u00b7steigt", "den", "Fahr\u00b7stuhl", "und", "die", "Trep\u00b7pen", ",", "noch", "in", "dem", "Mund", "das", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "ART", "NN", "$,", "ADV", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Das ganz unglaubliche, das aufgetaucht da ungerufen", "tokens": ["Das", "ganz", "un\u00b7glaub\u00b7li\u00b7che", ",", "das", "auf\u00b7ge\u00b7taucht", "da", "un\u00b7ge\u00b7ru\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ADJA", "$,", "PDS", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.5": {"text": "Man h\u00f6rt es abermals und h\u00f6rt es fort und fort:", "tokens": ["Man", "h\u00f6rt", "es", "a\u00b7ber\u00b7mals", "und", "h\u00f6rt", "es", "fort", "und", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.94": {"line.1": {"text": "Gefahr! \u2013 Man will den Witz leibhaftig miterleben,", "tokens": ["Ge\u00b7fahr", "!", "\u2013", "Man", "will", "den", "Witz", "leib\u00b7haf\u00b7tig", "mi\u00b7ter\u00b7le\u00b7ben", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PIS", "VMFIN", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn nur ein Witzbold denkt hier an Gefahr,", "tokens": ["Denn", "nur", "ein", "Witz\u00b7bold", "denkt", "hier", "an", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo Tausende auf stolzer H\u00f6he des Triumphes schweben.", "tokens": ["Wo", "Tau\u00b7sen\u00b7de", "auf", "stol\u00b7zer", "H\u00f6\u00b7he", "des", "Tri\u00b7um\u00b7phes", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+---+-+-+-+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Denn nirgendwo man sicherer als hier im Schiffe war, \u2013", "tokens": ["Denn", "nir\u00b7gend\u00b7wo", "man", "si\u00b7che\u00b7rer", "als", "hier", "im", "Schif\u00b7fe", "war", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "PIS", "ADJD", "KOKOM", "ADV", "APPRART", "NN", "VAFIN", "$,", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.5": {"text": "Die Ingenieure hatten gestern erst dies Urteil abgegeben.", "tokens": ["Die", "In\u00b7ge\u00b7ni\u00b7eu\u00b7re", "hat\u00b7ten", "ge\u00b7stern", "erst", "dies", "Ur\u00b7teil", "ab\u00b7ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "PDS", "NN", "VVPP", "$."], "meter": "-+--+-+--+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.95": {"line.1": {"text": "Es staut sich noch kein sonderlich Gedr\u00e4ng',", "tokens": ["Es", "staut", "sich", "noch", "kein", "son\u00b7der\u00b7lich", "Ge\u00b7dr\u00e4ng'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PIAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Man bildet Gruppen zwanglos unter Plaudern.", "tokens": ["Man", "bil\u00b7det", "Grup\u00b7pen", "zwang\u00b7los", "un\u00b7ter", "Plau\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Auch dann wird nicht die Luft den Tausend eng,", "tokens": ["Auch", "dann", "wird", "nicht", "die", "Luft", "den", "Tau\u00b7send", "eng", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PTKNEG", "ART", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Als die Maschinen in dem Schiffsraum zaudern.", "tokens": ["Als", "die", "Ma\u00b7schi\u00b7nen", "in", "dem", "Schiffs\u00b7raum", "zau\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dort ordnet eine Dame noch ihr Ohrgeh\u00e4ng',", "tokens": ["Dort", "ord\u00b7net", "ei\u00b7ne", "Da\u00b7me", "noch", "ihr", "Ohr\u00b7ge\u00b7h\u00e4ng'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.96": {"line.1": {"text": "Und andere vor Spiegeln leicht ihr Haar betasten,", "tokens": ["Und", "an\u00b7de\u00b7re", "vor", "Spie\u00b7geln", "leicht", "ihr", "Haar", "be\u00b7tas\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "ADJD", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das sich ein wenig lockerte beim Tanz,", "tokens": ["Das", "sich", "ein", "we\u00b7nig", "lo\u00b7cker\u00b7te", "beim", "Tanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "ART", "PIS", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Beim Druck der Diademe und der Perlenlasten.", "tokens": ["Beim", "Druck", "der", "Di\u00b7a\u00b7de\u00b7me", "und", "der", "Per\u00b7len\u00b7las\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und an Gefahr glaubt keine unterm Lichterkranz,", "tokens": ["Und", "an", "Ge\u00b7fahr", "glaubt", "kei\u00b7ne", "un\u00b7term", "Lich\u00b7ter\u00b7kranz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "PIAT", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn auch dem Schiff die Atemz\u00fcge rasten.", "tokens": ["Wenn", "auch", "dem", "Schiff", "die", "A\u00b7tem\u00b7z\u00fc\u00b7ge", "ras\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.97": {"line.1": {"text": "Doch kaum ein St\u00fcndlein sp\u00e4ter sind entstellt", "tokens": ["Doch", "kaum", "ein", "St\u00fcnd\u00b7lein", "sp\u00e4\u00b7ter", "sind", "ent\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "ADJD", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Im gleichen Saal die gleichen Angesichter.", "tokens": ["Im", "glei\u00b7chen", "Saal", "die", "glei\u00b7chen", "An\u00b7ge\u00b7sich\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Noch immer gl\u00e4nzt dieselbe Spiegelwelt.", "tokens": ["Noch", "im\u00b7mer", "gl\u00e4nzt", "die\u00b7sel\u00b7be", "Spie\u00b7gel\u00b7welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die Menschenmenge aber keilt sich \u00e4ngstlich dichter", "tokens": ["Die", "Men\u00b7schen\u00b7men\u00b7ge", "a\u00b7ber", "keilt", "sich", "\u00e4ngst\u00b7lich", "dich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "PRF", "ADJD", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zum Bug, der wie ein Pferd sich hochgestellt ...", "tokens": ["Zum", "Bug", ",", "der", "wie", "ein", "Pferd", "sich", "hoch\u00b7ge\u00b7stellt", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "KOKOM", "ART", "NN", "PRF", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.98": {"line.1": {"text": "Die letzten Rettungsboote rudern weiter,", "tokens": ["Die", "letz\u00b7ten", "Ret\u00b7tungs\u00b7boo\u00b7te", "ru\u00b7dern", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein jedes nur ein Menschenh\u00e4uflein fa\u00dft.", "tokens": ["Ein", "je\u00b7des", "nur", "ein", "Men\u00b7schen\u00b7h\u00e4uf\u00b7lein", "fa\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Im Wasser aber schreien Hunderte, die gleich wie Reiter", "tokens": ["Im", "Was\u00b7ser", "a\u00b7ber", "schrei\u00b7en", "Hun\u00b7der\u00b7te", ",", "die", "gleich", "wie", "Rei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "ADJA", "NN", "$,", "PRELS", "ADV", "KOKOM", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "Die Wellen anzuspornen scheinen und in Hast", "tokens": ["Die", "Wel\u00b7len", "an\u00b7zu\u00b7spor\u00b7nen", "schei\u00b7nen", "und", "in", "Hast"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVIZU", "VVFIN", "KON", "APPR", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie Korke fliegend schwimmen, denn ein neues Wort w\u00e4chst breiter:", "tokens": ["Wie", "Kor\u00b7ke", "flie\u00b7gend", "schwim\u00b7men", ",", "denn", "ein", "neu\u00b7es", "Wort", "w\u00e4chst", "brei\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "VVINF", "$,", "KON", "ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.99": {"line.1": {"text": "\u00bbder Tod.\u00ab \u2013 Der dunkle Menschenhaufen auf dem Bug,", "tokens": ["\u00bb", "der", "Tod", ".", "\u00ab", "\u2013", "Der", "dunk\u00b7le", "Men\u00b7schen\u00b7hau\u00b7fen", "auf", "dem", "Bug", ","], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$.", "$(", "$(", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Aus dem Pistolensch\u00fcsse fallen, tobt unb\u00e4ndig.", "tokens": ["Aus", "dem", "Pis\u00b7to\u00b7len\u00b7sch\u00fcs\u00b7se", "fal\u00b7len", ",", "tobt", "un\u00b7b\u00e4n\u00b7dig", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Tod steht \u00fcberall jetzt auf, Gefahren gibt's genug.", "tokens": ["Der", "Tod", "steht", "\u00fc\u00b7be\u00b7rall", "jetzt", "auf", ",", "Ge\u00b7fah\u00b7ren", "gibt's", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "PTKVZ", "$,", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Die Elemente und die Menschen, sie werden laut gest\u00e4ndig,", "tokens": ["Die", "E\u00b7le\u00b7men\u00b7te", "und", "die", "Men\u00b7schen", ",", "sie", "wer\u00b7den", "laut", "ge\u00b7st\u00e4n\u00b7dig", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "PPER", "VAFIN", "ADJD", "ADJD", "$,"], "meter": "--+--+-+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Da\u00df Leben stets dem Leben, ach, die Todeswunden schlug.", "tokens": ["Da\u00df", "Le\u00b7ben", "stets", "dem", "Le\u00b7ben", ",", "ach", ",", "die", "To\u00b7des\u00b7wun\u00b7den", "schlug", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ART", "NN", "$,", "ITJ", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.100": {"line.1": {"text": "Sie alle raubten immer, um zu leben.", "tokens": ["Sie", "al\u00b7le", "raub\u00b7ten", "im\u00b7mer", ",", "um", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VVFIN", "ADV", "$,", "KOUI", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dem Tod sind wenig Freunde nur bekannt.", "tokens": ["Dem", "Tod", "sind", "we\u00b7nig", "Freun\u00b7de", "nur", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nur wenig sah ich, die sich friedlich ihm ergeben.", "tokens": ["Nur", "we\u00b7nig", "sah", "ich", ",", "die", "sich", "fried\u00b7lich", "ihm", "er\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPER", "$,", "PRELS", "PRF", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein altes Paar vor mir hat sich ihm l\u00e4chelnd zugewandt,", "tokens": ["Ein", "al\u00b7tes", "Paar", "vor", "mir", "hat", "sich", "ihm", "l\u00e4\u00b7chelnd", "zu\u00b7ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "VAFIN", "PRF", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Ich seh' der beiden Seelen vereint dem Tod entgegenschweben,", "tokens": ["Ich", "seh'", "der", "bei\u00b7den", "See\u00b7len", "ver\u00b7eint", "dem", "Tod", "ent\u00b7ge\u00b7gen\u00b7schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "PIAT", "NN", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.101": {"line.1": {"text": "Man wollt' die Gatten trennen. Doch die Frau", "tokens": ["Man", "wollt'", "die", "Gat\u00b7ten", "tren\u00b7nen", ".", "Doch", "die", "Frau"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ART", "NN", "VVINF", "$.", "KON", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mocht' nicht allein das Rettungsboot besteigen.", "tokens": ["Mocht'", "nicht", "al\u00b7lein", "das", "Ret\u00b7tungs\u00b7boot", "be\u00b7stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein lieblos Leben scheint der Lebensreifen rauh.", "tokens": ["Ein", "lieb\u00b7los", "Le\u00b7ben", "scheint", "der", "Le\u00b7bens\u00b7rei\u00b7fen", "rauh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So teilt sie mutig mit dem Mann das Todesschweigen,", "tokens": ["So", "teilt", "sie", "mu\u00b7tig", "mit", "dem", "Mann", "das", "To\u00b7des\u00b7schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und beide Alten, eng umarmt, sie halten lautlos Totenschau.", "tokens": ["Und", "bei\u00b7de", "Al\u00b7ten", ",", "eng", "um\u00b7armt", ",", "sie", "hal\u00b7ten", "laut\u00b7los", "To\u00b7ten\u00b7schau", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "ADJD", "VVPP", "$,", "PPER", "VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.102": {"line.1": {"text": "Und Segen auch verdienten sich noch viele;", "tokens": ["Und", "Se\u00b7gen", "auch", "ver\u00b7dien\u00b7ten", "sich", "noch", "vie\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "VVFIN", "PRF", "ADV", "PIS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf mancher Todesstunde Lorbeer ruht.", "tokens": ["Auf", "man\u00b7cher", "To\u00b7dess\u00b7tun\u00b7de", "Lor\u00b7beer", "ruht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Manch' Million\u00e4r, der nur des Lebens Spiele", "tokens": ["Man\u00b7ch'", "Mil\u00b7li\u00b7o\u00b7n\u00e4r", ",", "der", "nur", "des", "Le\u00b7bens", "Spie\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "NN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Gekannt, steht ab, zu retten sich sein Blut. \u2013", "tokens": ["Ge\u00b7kannt", ",", "steht", "ab", ",", "zu", "ret\u00b7ten", "sich", "sein", "Blut", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$,", "VVFIN", "PTKVZ", "$,", "PTKZU", "VVINF", "PRF", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Er nimmt die Rettung anderer zum Ziele ...", "tokens": ["Er", "nimmt", "die", "Ret\u00b7tung", "an\u00b7de\u00b7rer", "zum", "Zie\u00b7le", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.103": {"line.1": {"text": "Im Abendkleid, dem lang die Schleppe schleift,", "tokens": ["Im", "A\u00b7bend\u00b7kleid", ",", "dem", "lang", "die", "Schlep\u00b7pe", "schleift", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Stehn Damen fr\u00f6stelnd dichtgedr\u00e4ngt im Dunkel,", "tokens": ["Stehn", "Da\u00b7men", "fr\u00f6s\u00b7telnd", "dicht\u00b7ge\u00b7dr\u00e4ngt", "im", "Dun\u00b7kel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJD", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Den Hals und auch die Br\u00fcste wie bereift", "tokens": ["Den", "Hals", "und", "auch", "die", "Br\u00fcs\u00b7te", "wie", "be\u00b7reift"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADV", "ART", "NN", "KOKOM", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von Verlenprunk und Diamantgefunkel \u2013", "tokens": ["Von", "Ver\u00b7len\u00b7prunk", "und", "Di\u00b7a\u00b7mant\u00b7ge\u00b7fun\u00b7kel", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der Tod auch nach den Edelsteinen greift.", "tokens": ["Der", "Tod", "auch", "nach", "den", "E\u00b7del\u00b7stei\u00b7nen", "greift", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.104": {"line.1": {"text": "Das Licht ist jetzt erloschen in den R\u00e4umen,", "tokens": ["Das", "Licht", "ist", "jetzt", "er\u00b7lo\u00b7schen", "in", "den", "R\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch bringt man Kerzen und beleuchtet schnell.", "tokens": ["Doch", "bringt", "man", "Ker\u00b7zen", "und", "be\u00b7leuch\u00b7tet", "schnell", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "NN", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Wasser steigt, und n\u00e4her t\u00f6nt sein Sch\u00e4umen.", "tokens": ["Das", "Was\u00b7ser", "steigt", ",", "und", "n\u00e4\u00b7her", "t\u00f6nt", "sein", "Sch\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Kerzenschein erstreckt sich flackernd grell", "tokens": ["Der", "Ker\u00b7zen\u00b7schein", "er\u00b7streckt", "sich", "fla\u00b7ckernd", "grell"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADJD", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auf die vom Tod Gezeichneten, die noch vom Leben tr\u00e4umen.", "tokens": ["Auf", "die", "vom", "Tod", "Ge\u00b7zeich\u00b7ne\u00b7ten", ",", "die", "noch", "vom", "Le\u00b7ben", "tr\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPRART", "NN", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.105": {"line.1": {"text": "Der Kapit\u00e4n darf stolz die Hoffnung noch nicht sinken sehn.", "tokens": ["Der", "Ka\u00b7pi\u00b7t\u00e4n", "darf", "stolz", "die", "Hoff\u00b7nung", "noch", "nicht", "sin\u00b7ken", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "ART", "NN", "ADV", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Er mu\u00df des Meerpalastes Untergang verneinen,", "tokens": ["Er", "mu\u00df", "des", "Meer\u00b7pa\u00b7las\u00b7tes", "Un\u00b7ter\u00b7gang", "ver\u00b7nei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Solange knatternd noch die Funkenspr\u00fcche \u00fcbern Ozean gehn,", "tokens": ["So\u00b7lan\u00b7ge", "knat\u00b7ternd", "noch", "die", "Fun\u00b7ken\u00b7spr\u00fc\u00b7che", "\u00fc\u00b7bern", "O\u00b7ze\u00b7an", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+--+", "measure": "iambic.octa.plus.octa.plus.chol"}, "line.4": {"text": "Die sich wie letzte Lebensstrahlen rund um die Todesnot vereinen", "tokens": ["Die", "sich", "wie", "letz\u00b7te", "Le\u00b7bens\u00b7strah\u00b7len", "rund", "um", "die", "To\u00b7des\u00b7not", "ver\u00b7ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "KOKOM", "ADJA", "NN", "ADJD", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Und um zwei M\u00e4nner, die im Telegraphenraum im Wasser stehn.", "tokens": ["Und", "um", "zwei", "M\u00e4n\u00b7ner", ",", "die", "im", "Te\u00b7le\u00b7gra\u00b7phen\u00b7raum", "im", "Was\u00b7ser", "stehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "CARD", "NN", "$,", "PRELS", "APPRART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.106": {"line.1": {"text": "Das Grab nur konnte jene Braven von ihrem Lebensdienst entbinden.", "tokens": ["Das", "Grab", "nur", "konn\u00b7te", "je\u00b7ne", "Bra\u00b7ven", "von", "ih\u00b7rem", "Le\u00b7bens\u00b7dienst", "ent\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VMFIN", "PDAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Des Schiffes F\u00fchlung mit der Welt, sie schwand mit ihnen schwer.", "tokens": ["Des", "Schif\u00b7fes", "F\u00fch\u00b7lung", "mit", "der", "Welt", ",", "sie", "schwand", "mit", "ih\u00b7nen", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "APPR", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Den Rettungsg\u00fcrtel um, so funken sie, bis ihre Kr\u00e4fte schwinden,", "tokens": ["Den", "Ret\u00b7tungs\u00b7g\u00fcr\u00b7tel", "um", ",", "so", "fun\u00b7ken", "sie", ",", "bis", "ih\u00b7re", "Kr\u00e4f\u00b7te", "schwin\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.4": {"text": "Bis sie am Telegraphen abl\u00f6st stumm das Meer", "tokens": ["Bis", "sie", "am", "Te\u00b7le\u00b7gra\u00b7phen", "ab\u00b7l\u00f6st", "stumm", "das", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und sie als letzte Antwort dann den Tod am Apparate finden.", "tokens": ["Und", "sie", "als", "letz\u00b7te", "Ant\u00b7wort", "dann", "den", "Tod", "am", "Ap\u00b7pa\u00b7ra\u00b7te", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "KOUS", "ADJA", "NN", "ADV", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}}, "stanza.107": {"line.1": {"text": "Unheimlich w\u00e4chst das Wasser rund heran,", "tokens": ["Un\u00b7heim\u00b7lich", "w\u00e4chst", "das", "Was\u00b7ser", "rund", "he\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und manchem kehrt zur\u00fcck die ferne Seele,", "tokens": ["Und", "man\u00b7chem", "kehrt", "zu\u00b7r\u00fcck", "die", "fer\u00b7ne", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die hochm\u00fctig er l\u00e4ngst schon abgetan.", "tokens": ["Die", "hoch\u00b7m\u00fc\u00b7tig", "er", "l\u00e4ngst", "schon", "ab\u00b7ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Doch sitzt Gefahr dem Menschen an der Kehle,", "tokens": ["Doch", "sitzt", "Ge\u00b7fahr", "dem", "Men\u00b7schen", "an", "der", "Keh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Springt leicht der Zweifelnde auch in den Glaubenskahn.", "tokens": ["Springt", "leicht", "der", "Zwei\u00b7feln\u00b7de", "auch", "in", "den", "Glau\u00b7bens\u00b7kahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}}, "stanza.108": {"line.1": {"text": "Im Speisesaal, wo noch vor einer Stunde", "tokens": ["Im", "Spei\u00b7se\u00b7saal", ",", "wo", "noch", "vor", "ei\u00b7ner", "Stun\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "PWAV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gar festlich die befrackte Herrenschar", "tokens": ["Gar", "fest\u00b7lich", "die", "be\u00b7frack\u00b7te", "Her\u00b7ren\u00b7schar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den Schaumwein schl\u00fcrfte und das Lachen in der Runde", "tokens": ["Den", "Schaum\u00b7wein", "schl\u00fcrf\u00b7te", "und", "das", "La\u00b7chen", "in", "der", "Run\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KON", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aufdringlich dr\u00f6hnte, blind erhaben der Gefahr, \u2013", "tokens": ["Auf\u00b7dring\u00b7lich", "dr\u00f6hn\u00b7te", ",", "blind", "er\u00b7ha\u00b7ben", "der", "Ge\u00b7fahr", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "$,", "ADJD", "ADJD", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da halten Musikanten noch die Instrumente an dem Munde.", "tokens": ["Da", "hal\u00b7ten", "Mu\u00b7si\u00b7kan\u00b7ten", "noch", "die", "Inst\u00b7ru\u00b7men\u00b7te", "an", "dem", "Mun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}}, "stanza.109": {"line.1": {"text": "Und durch die Not klang \u00fcbers Schiff: \u00bbHin Gott zu dir!\u00ab", "tokens": ["Und", "durch", "die", "Not", "klang", "\u00fc\u00b7bers", "Schiff", ":", "\u00bb", "Hin", "Gott", "zu", "dir", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "APPRART", "NN", "$.", "$(", "NN", "NN", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und manches Auge weinte in dem Prunken", "tokens": ["Und", "man\u00b7ches", "Au\u00b7ge", "wein\u00b7te", "in", "dem", "Prun\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Des Saales, der geschm\u00fcckt mit goldner Zier,", "tokens": ["Des", "Saa\u00b7les", ",", "der", "ge\u00b7schm\u00fcckt", "mit", "gold\u00b7ner", "Zier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wo Violin und Fl\u00f6te jetzt noch t\u00f6netrunken", "tokens": ["Wo", "Vi\u00b7o\u00b7lin", "und", "Fl\u00f6\u00b7te", "jetzt", "noch", "t\u00f6\u00b7ne\u00b7trun\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "KON", "NN", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zum Frieden wiesen, fern der Lebensgier.", "tokens": ["Zum", "Frie\u00b7den", "wie\u00b7sen", ",", "fern", "der", "Le\u00b7bens\u00b7gier", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.110": {"line.1": {"text": "Das Schreien aber, das im Schiff sich r\u00fchrte,", "tokens": ["Das", "Schrei\u00b7en", "a\u00b7ber", ",", "das", "im", "Schiff", "sich", "r\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "APPRART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als krachend nun der Rumpf im Kesselraum zerri\u00df", "tokens": ["Als", "kra\u00b7chend", "nun", "der", "Rumpf", "im", "Kes\u00b7sel\u00b7raum", "zer\u00b7ri\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und Tausende zur Meerestiefe f\u00fchrte,", "tokens": ["Und", "Tau\u00b7sen\u00b7de", "zur", "Mee\u00b7res\u00b7tie\u00b7fe", "f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Schreien sich gar grimmig in mein Herz einbi\u00df,", "tokens": ["Das", "Schrei\u00b7en", "sich", "gar", "grim\u00b7mig", "in", "mein", "Herz", "ein\u00b7bi\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als w\u00e4r's mein eigen Leben, das ich sterbend sp\u00fcrte.", "tokens": ["Als", "w\u00e4r's", "mein", "ei\u00b7gen", "Le\u00b7ben", ",", "das", "ich", "ster\u00b7bend", "sp\u00fcr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.111": {"line.1": {"text": "Es schrie die Welt auf, die der Mensch gebaut,", "tokens": ["Es", "schrie", "die", "Welt", "auf", ",", "die", "der", "Mensch", "ge\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Es schrie die Sucht auf jener tausend Leben,", "tokens": ["Es", "schrie", "die", "Sucht", "auf", "je\u00b7ner", "tau\u00b7send", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PDAT", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die stolz der Menschen Eitelkeit vertraut.", "tokens": ["Die", "stolz", "der", "Men\u00b7schen", "Ei\u00b7tel\u00b7keit", "ver\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Es schrie die Lust, dem Tod den Tod zu geben,", "tokens": ["Es", "schrie", "die", "Lust", ",", "dem", "Tod", "den", "Tod", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es schrie der Glanz, dem vor dem Dunkel graut.", "tokens": ["Es", "schrie", "der", "Glanz", ",", "dem", "vor", "dem", "Dun\u00b7kel", "graut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.112": {"line.1": {"text": "Es schrien Stimmen, so wie Tiere br\u00fcllen,", "tokens": ["Es", "schri\u00b7en", "Stim\u00b7men", ",", "so", "wie", "Tie\u00b7re", "br\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "ADV", "KOKOM", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn sie der Mensch von ihrer Herde rei\u00dft ...", "tokens": ["Wenn", "sie", "der", "Mensch", "von", "ih\u00b7rer", "Her\u00b7de", "rei\u00dft", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dann sah ich alle Bilder sich verh\u00fcllen,", "tokens": ["Dann", "sah", "ich", "al\u00b7le", "Bil\u00b7der", "sich", "ver\u00b7h\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und eine Hand, die mich ins Leben weist,", "tokens": ["Und", "ei\u00b7ne", "Hand", ",", "die", "mich", "ins", "Le\u00b7ben", "weist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sie mu\u00df des Buches Seiten rasch zerkn\u00fcllen.", "tokens": ["Sie", "mu\u00df", "des", "Bu\u00b7ches", "Sei\u00b7ten", "rasch", "zer\u00b7kn\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.113": {"line.1": {"text": "Getragen von dem eisigsten der Winde,", "tokens": ["Ge\u00b7tra\u00b7gen", "von", "dem", "ei\u00b7sigs\u00b7ten", "der", "Win\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "ART", "NN", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Noch lange ich auf leeren Wassern flog,", "tokens": ["Noch", "lan\u00b7ge", "ich", "auf", "lee\u00b7ren", "Was\u00b7sern", "flog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und nicht sogleich ich wieder heimw\u00e4rts finde.", "tokens": ["Und", "nicht", "sog\u00b7leich", "ich", "wie\u00b7der", "heim\u00b7w\u00e4rts", "fin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein t\u00f6dlich kalter Atem mit mir zog,", "tokens": ["Ein", "t\u00f6d\u00b7lich", "kal\u00b7ter", "A\u00b7tem", "mit", "mir", "zog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Als schmolz das Sterben auch des Eisbergs Rinde.", "tokens": ["Als", "schmolz", "das", "Ster\u00b7ben", "auch", "des", "Eis\u00b7bergs", "Rin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.114": {"line.1": {"text": "Am Eise h\u00e4ngen sich die Toten fest,", "tokens": ["Am", "Ei\u00b7se", "h\u00e4n\u00b7gen", "sich", "die", "To\u00b7ten", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und Haufen Sterbende verr\u00f6cheln st\u00f6hnend.", "tokens": ["Und", "Hau\u00b7fen", "Ster\u00b7ben\u00b7de", "ver\u00b7r\u00f6\u00b7cheln", "st\u00f6h\u00b7nend", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Verschwunden ist des Schiffstitanen Rest.", "tokens": ["Ver\u00b7schwun\u00b7den", "ist", "des", "Schiffs\u00b7ti\u00b7ta\u00b7nen", "Rest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das Wasser rauscht an jener Stelle t\u00f6nend,", "tokens": ["Das", "Was\u00b7ser", "rauscht", "an", "je\u00b7ner", "Stel\u00b7le", "t\u00f6\u00b7nend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und nur der Tod h\u00e4lt noch ein wildes Fest.", "tokens": ["Und", "nur", "der", "Tod", "h\u00e4lt", "noch", "ein", "wil\u00b7des", "Fest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.115": {"line.1": {"text": "Von Zeit zu Zeit, da tauchten Boote auf.", "tokens": ["Von", "Zeit", "zu", "Zeit", ",", "da", "tauch\u00b7ten", "Boo\u00b7te", "auf", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$,", "KOUS", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich sah noch M\u00e4nner sich im Wasser raufen.", "tokens": ["Ich", "sah", "noch", "M\u00e4n\u00b7ner", "sich", "im", "Was\u00b7ser", "rau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Geschm\u00fcckte Frauen steuerten der Boote Lauf,", "tokens": ["Ge\u00b7schm\u00fcck\u00b7te", "Frau\u00b7en", "steu\u00b7er\u00b7ten", "der", "Boo\u00b7te", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich h\u00f6re Schwimmende um mich verschnaufen", "tokens": ["Ich", "h\u00f6\u00b7re", "Schwim\u00b7men\u00b7de", "um", "mich", "ver\u00b7schnau\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dicht bei der Leichen enggedr\u00e4ngtem Hauf ...", "tokens": ["Dicht", "bei", "der", "Lei\u00b7chen", "eng\u00b7ge\u00b7dr\u00e4ng\u00b7tem", "Hauf", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "ADJA", "NN", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.116": {"line.1": {"text": "Der Morgen kam mit seiner leichten R\u00f6te,", "tokens": ["Der", "Mor\u00b7gen", "kam", "mit", "sei\u00b7ner", "leich\u00b7ten", "R\u00f6\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als w\u00fc\u00dft' er nicht, was hier die Nacht gesehn.", "tokens": ["Als", "w\u00fc\u00dft'", "er", "nicht", ",", "was", "hier", "die", "Nacht", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PTKNEG", "$,", "PRELS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Welle aber sprach zur Welle weiter. \u00bbT\u00f6te!", "tokens": ["Die", "Wel\u00b7le", "a\u00b7ber", "sprach", "zur", "Wel\u00b7le", "wei\u00b7ter", ".", "\u00bb", "T\u00f6\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPRART", "NN", "PTKVZ", "$.", "$(", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein Leben soll hier dem Triumph des Todes heut entgehn.\u00ab", "tokens": ["Kein", "Le\u00b7ben", "soll", "hier", "dem", "Tri\u00b7umph", "des", "To\u00b7des", "heut", "ent\u00b7gehn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ADV", "ART", "NN", "ART", "NN", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.5": {"text": "Und da und dort versanken dann die menschenvollen B\u00f6te. \u2013", "tokens": ["Und", "da", "und", "dort", "ver\u00b7san\u00b7ken", "dann", "die", "men\u00b7schen\u00b7vol\u00b7len", "B\u00f6\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "KON", "ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.117": {"line.1": {"text": "Fern rotes bald und gr\u00fcnes Licht im Morgend\u00e4mmern blinkt, \u2013", "tokens": ["Fern", "ro\u00b7tes", "bald", "und", "gr\u00fc\u00b7nes", "Licht", "im", "Mor\u00b7gen\u00b7d\u00e4m\u00b7mern", "blinkt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADJA", "ADV", "KON", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Es sind Laternen eines Dampfers, den zur Nacht gerufen", "tokens": ["Es", "sind", "La\u00b7ter\u00b7nen", "ei\u00b7nes", "Damp\u00b7fers", ",", "den", "zur", "Nacht", "ge\u00b7ru\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.3": {"text": "Durch viele Meilen her der Telegraph. Man winkt.", "tokens": ["Durch", "vie\u00b7le", "Mei\u00b7len", "her", "der", "Te\u00b7le\u00b7gra\u00b7ph", ".", "Man", "winkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APZR", "ART", "NN", "$.", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "In allen Booten aber war es jetzt, als schufen", "tokens": ["In", "al\u00b7len", "Boo\u00b7ten", "a\u00b7ber", "war", "es", "jetzt", ",", "als", "schu\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIAT", "NN", "ADV", "VAFIN", "PPER", "ADV", "$,", "KOUS", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die beiden Lichter neu den Mut, der schon versinkt.", "tokens": ["Die", "bei\u00b7den", "Lich\u00b7ter", "neu", "den", "Mut", ",", "der", "schon", "ver\u00b7sinkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADJD", "ART", "NN", "$,", "PRELS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.118": {"line.1": {"text": "Der Dampfer l\u00e4\u00dft die Treppen zu den Booten nieder.", "tokens": ["Der", "Damp\u00b7fer", "l\u00e4\u00dft", "die", "Trep\u00b7pen", "zu", "den", "Boo\u00b7ten", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man kommt und rettet, wo man retten kann.", "tokens": ["Man", "kommt", "und", "ret\u00b7tet", ",", "wo", "man", "ret\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch die Geretteten erkennen nicht sofort das Leben wieder,", "tokens": ["Doch", "die", "Ge\u00b7ret\u00b7te\u00b7ten", "er\u00b7ken\u00b7nen", "nicht", "so\u00b7fort", "das", "Le\u00b7ben", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKNEG", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.4": {"text": "Und manche zarte Frau, die da im Boot gerudert hatte wie ein Mann,", "tokens": ["Und", "man\u00b7che", "zar\u00b7te", "Frau", ",", "die", "da", "im", "Boot", "ge\u00b7ru\u00b7dert", "hat\u00b7te", "wie", "ein", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "VVPP", "VAFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.5": {"text": "Sieht noch vor sich den Tod durch die ersch\u00f6pft geschlossenen Lider.", "tokens": ["Sieht", "noch", "vor", "sich", "den", "Tod", "durch", "die", "er\u00b7sch\u00f6pft", "ge\u00b7schlos\u00b7se\u00b7nen", "Li\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PRF", "ART", "NN", "APPR", "ART", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}}, "stanza.119": {"line.1": {"text": "Und viele, die man aus den Booten hebt, die schreien wild,", "tokens": ["Und", "vie\u00b7le", ",", "die", "man", "aus", "den", "Boo\u00b7ten", "hebt", ",", "die", "schrei\u00b7en", "wild", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PIS", "APPR", "ART", "NN", "VVFIN", "$,", "PRELS", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Sie wollen nicht vom Grab da unten scheiden.", "tokens": ["Sie", "wol\u00b7len", "nicht", "vom", "Grab", "da", "un\u00b7ten", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "APPRART", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In ihren Augen brennt noch Schreckensbild um Bild,", "tokens": ["In", "ih\u00b7ren", "Au\u00b7gen", "brennt", "noch", "Schre\u00b7ckens\u00b7bild", "um", "Bild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie wollen nicht gerettet sein von ihren Leiden, \u2013", "tokens": ["Sie", "wol\u00b7len", "nicht", "ge\u00b7ret\u00b7tet", "sein", "von", "ih\u00b7ren", "Lei\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVPP", "VAINF", "APPR", "PPOSAT", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es deckte ihre Liebsten zu der ungeheure Meeresschild.", "tokens": ["Es", "deck\u00b7te", "ih\u00b7re", "Liebs\u00b7ten", "zu", "der", "un\u00b7ge\u00b7heu\u00b7re", "Mee\u00b7res\u00b7schild", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.120": {"line.1": {"text": "Und andere, die sich ergeben in das Todeswerben,", "tokens": ["Und", "an\u00b7de\u00b7re", ",", "die", "sich", "er\u00b7ge\u00b7ben", "in", "das", "To\u00b7des\u00b7wer\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PRF", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Die sich schon ihrem Untergang vers\u00f6hnt,", "tokens": ["Die", "sich", "schon", "ih\u00b7rem", "Un\u00b7ter\u00b7gang", "ver\u00b7s\u00f6hnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie sehen in dem Tod nicht mehr Verderben \u2013", "tokens": ["Sie", "se\u00b7hen", "in", "dem", "Tod", "nicht", "mehr", "Ver\u00b7der\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKNEG", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Erl\u00f6sung von dem Dasein, das nur raubt und st\u00f6hnt.", "tokens": ["Er\u00b7l\u00f6\u00b7sung", "von", "dem", "Da\u00b7sein", ",", "das", "nur", "raubt", "und", "st\u00f6hnt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie wollen nie das Leben mehr betreten, \u2013 nur sterben, sterben.", "tokens": ["Sie", "wol\u00b7len", "nie", "das", "Le\u00b7ben", "mehr", "be\u00b7tre\u00b7ten", ",", "\u2013", "nur", "ster\u00b7ben", ",", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "ADV", "VVPP", "$,", "$(", "ADV", "VVINF", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+--+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.121": {"line.1": {"text": "Mit dem Geschmack des bittern Meeres noch im Mund", "tokens": ["Mit", "dem", "Ge\u00b7schmack", "des", "bit\u00b7tern", "Mee\u00b7res", "noch", "im", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und vor mir Leben, das die Hand mir leckte,", "tokens": ["Und", "vor", "mir", "Le\u00b7ben", ",", "das", "die", "Hand", "mir", "leck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "NN", "$,", "PRELS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Erwachte ich. Ans Knie strich mir mein Hund.", "tokens": ["Er\u00b7wach\u00b7te", "ich", ".", "Ans", "Knie", "strich", "mir", "mein", "Hund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "APPRART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Erstaunt ich mich in meinem Zimmerraum entdeckte,", "tokens": ["Er\u00b7staunt", "ich", "mich", "in", "mei\u00b7nem", "Zim\u00b7mer\u00b7raum", "ent\u00b7deck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Im Herzen noch der Schiffswelt Todesstund'.", "tokens": ["Im", "Her\u00b7zen", "noch", "der", "Schiffs\u00b7welt", "To\u00b7desstund'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.122": {"line.1": {"text": "Ich seh' den Hund an, der da vor mir kauert,", "tokens": ["Ich", "seh'", "den", "Hund", "an", ",", "der", "da", "vor", "mir", "kau\u00b7ert", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PRELS", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und der mit seinen Augen stumm mich fragt:", "tokens": ["Und", "der", "mit", "sei\u00b7nen", "Au\u00b7gen", "stumm", "mich", "fragt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "PPOSAT", "NN", "ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbherr, sprich, warum dein Menschenblut erschauert.", "tokens": ["\u00bb", "herr", ",", "sprich", ",", "wa\u00b7rum", "dein", "Men\u00b7schen\u00b7blut", "er\u00b7schau\u00b7ert", "."], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "ADJD", "$,", "PWAV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Stille um dich stundenlang schon klagt,", "tokens": ["Die", "Stil\u00b7le", "um", "dich", "stun\u00b7den\u00b7lang", "schon", "klagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sie rief mir zu: Sieh doch, dein Herr, er trauert.\u00ab \u2013", "tokens": ["Sie", "rief", "mir", "zu", ":", "Sieh", "doch", ",", "dein", "Herr", ",", "er", "trau\u00b7ert", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "NE", "ADV", "$,", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und ich besinne mich, da\u00df ich da n\u00e4chtens las", "tokens": ["Und", "ich", "be\u00b7sin\u00b7ne", "mich", ",", "da\u00df", "ich", "da", "n\u00e4ch\u00b7tens", "las"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Von einem gro\u00dfen Schiff das gro\u00dfe Untergehen,", "tokens": ["Von", "ei\u00b7nem", "gro\u00b7\u00dfen", "Schiff", "das", "gro\u00b7\u00dfe", "Un\u00b7ter\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und da\u00df ich miterlebt Titanenungl\u00fcck und des Todes Ha\u00df.", "tokens": ["Und", "da\u00df", "ich", "mi\u00b7ter\u00b7lebt", "Ti\u00b7ta\u00b7ne\u00b7nun\u00b7gl\u00fcck", "und", "des", "To\u00b7des", "Ha\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "NN", "KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+--+--+-+", "measure": "iambic.septa.relaxed"}, "line.9": {"text": "Beim Leben, das wir gerne triumphieren sehen,", "tokens": ["Beim", "Le\u00b7ben", ",", "das", "wir", "ger\u00b7ne", "tri\u00b7um\u00b7phie\u00b7ren", "se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Todesk\u00e4lte schon im Morgen sa\u00df.", "tokens": ["Die", "To\u00b7des\u00b7k\u00e4l\u00b7te", "schon", "im", "Mor\u00b7gen", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.123": {"line.1": {"text": "Noch jenen Traum im Aug', schau' ich zur Zimmerdiele,", "tokens": ["Noch", "je\u00b7nen", "Traum", "im", "Aug'", ",", "schau'", "ich", "zur", "Zim\u00b7mer\u00b7die\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "APPRART", "NN", "$,", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die wurde wie der Grund vom tiefen Meer.", "tokens": ["Die", "wur\u00b7de", "wie", "der", "Grund", "vom", "tie\u00b7fen", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "KOKOM", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erdr\u00fcckt von Haufen Gold sah ich der Menschen viele.", "tokens": ["Er\u00b7dr\u00fcckt", "von", "Hau\u00b7fen", "Gold", "sah", "ich", "der", "Men\u00b7schen", "vie\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "NN", "VVFIN", "PPER", "ART", "NN", "PIS", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn jener Schiffstitan, er war an Goldlast schwer.", "tokens": ["Denn", "je\u00b7ner", "Schiffs\u00b7ti\u00b7tan", ",", "er", "war", "an", "Gold\u00b7last", "schwer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "$,", "PPER", "VAFIN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u00bbdie Gl\u00fccklichen,\u00ab so seufzte ich, \u00bbsie kamen nun zum goldnen Ziele.\u00ab", "tokens": ["\u00bb", "die", "Gl\u00fcck\u00b7li\u00b7chen", ",", "\u00ab", "so", "seufz\u00b7te", "ich", ",", "\u00bb", "sie", "ka\u00b7men", "nun", "zum", "gold\u00b7nen", "Zie\u00b7le", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "$,", "$(", "ADV", "VVFIN", "PPER", "$,", "$(", "PPER", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}}, "stanza.124": {"line.1": {"text": "Ich sprach es, todeslustig noch, und wurde langsam wach.", "tokens": ["Ich", "sprach", "es", ",", "to\u00b7des\u00b7lus\u00b7tig", "noch", ",", "und", "wur\u00b7de", "lang\u00b7sam", "wach", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ADJD", "ADV", "$,", "KON", "VAFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Vor mir, zerpre\u00dft vom Gold, verschwanden jene Toten.", "tokens": ["Vor", "mir", ",", "zer\u00b7pre\u00dft", "vom", "Gold", ",", "ver\u00b7schwan\u00b7den", "je\u00b7ne", "To\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "VVFIN", "APPRART", "NN", "$,", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und drau\u00dfen stand die Sonne \u00fcberm Nachbardach,", "tokens": ["Und", "drau\u00b7\u00dfen", "stand", "die", "Son\u00b7ne", "\u00fc\u00b7berm", "Nach\u00b7bar\u00b7dach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ihre Strahlen mir ihr Lebenslicht anboten.", "tokens": ["Und", "ih\u00b7re", "Strah\u00b7len", "mir", "ihr", "Le\u00b7bens\u00b7licht", "an\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da griff mein Atem zu. Ich dachte nicht mehr hei\u00df dem Untergange nach.", "tokens": ["Da", "griff", "mein", "A\u00b7tem", "zu", ".", "Ich", "dach\u00b7te", "nicht", "mehr", "hei\u00df", "dem", "Un\u00b7ter\u00b7gan\u00b7ge", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PTKNEG", "ADV", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.125": {"line.1": {"text": "Ich streichelte den Hund, der lebenskr\u00e4ftig bellte,", "tokens": ["Ich", "strei\u00b7chel\u00b7te", "den", "Hund", ",", "der", "le\u00b7bens\u00b7kr\u00e4f\u00b7tig", "bell\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und f\u00fchlte mich von Sterbequalen frei.", "tokens": ["Und", "f\u00fchl\u00b7te", "mich", "von", "Ster\u00b7be\u00b7qua\u00b7len", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Licht, das s\u00fc\u00dfe, das mein Herz erhellte,", "tokens": ["Das", "Licht", ",", "das", "s\u00fc\u00b7\u00dfe", ",", "das", "mein", "Herz", "er\u00b7hell\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Entr\u00fcckte mich dem gro\u00dfen Todesschrei,", "tokens": ["Ent\u00b7r\u00fcck\u00b7te", "mich", "dem", "gro\u00b7\u00dfen", "To\u00b7des\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der fern in der Erinnerung noch gellte.", "tokens": ["Der", "fern", "in", "der", "E\u00b7rin\u00b7ne\u00b7rung", "noch", "gell\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.126": {"line.1": {"text": "Das Schicksalsbuch, darin ich weiterlas,", "tokens": ["Das", "Schick\u00b7sals\u00b7buch", ",", "da\u00b7rin", "ich", "wei\u00b7ter\u00b7las", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Es schlug mir neue Bilder auf und Seiten.", "tokens": ["Es", "schlug", "mir", "neu\u00b7e", "Bil\u00b7der", "auf", "und", "Sei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJA", "NN", "PTKVZ", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch zwischen neuen Zeilen ich es nie verga\u00df,", "tokens": ["Doch", "zwi\u00b7schen", "neu\u00b7en", "Zei\u00b7len", "ich", "es", "nie", "ver\u00b7ga\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Menschen ihrem Tun den Untergang bereiten,", "tokens": ["Da\u00df", "Men\u00b7schen", "ih\u00b7rem", "Tun", "den", "Un\u00b7ter\u00b7gang", "be\u00b7rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn nicht die Demut mit beim Werke sa\u00df.", "tokens": ["Wenn", "nicht", "die", "De\u00b7mut", "mit", "beim", "Wer\u00b7ke", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "APPR", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}