{"textgrid.poem.34660": {"metadata": {"author": {"name": "Neukirch, Benjamin", "birth": "N.A.", "death": "N.A."}, "title": "Auff Rosetten", "genre": "verse", "period": "N.A.", "pub_year": 1697, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Amor/ willstu/ da\u00df ich sage/", "tokens": ["A\u00b7mor", "/", "will\u00b7stu", "/", "da\u00df", "ich", "sa\u00b7ge", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "VMFIN", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.2": {"text": "Amor/ willstu/ da\u00df ich klage/", "tokens": ["A\u00b7mor", "/", "will\u00b7stu", "/", "da\u00df", "ich", "kla\u00b7ge", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "VMFIN", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was du mir zu viel gethan?", "tokens": ["Was", "du", "mir", "zu", "viel", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "PTKA", "PIS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Du entz\u00fcndest meine liebe/", "tokens": ["Du", "ent\u00b7z\u00fcn\u00b7dest", "mei\u00b7ne", "lie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und doch hilffstu meinem diebe/", "tokens": ["Und", "doch", "hilffs\u00b7tu", "mei\u00b7nem", "die\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und tr\u00e4gst ihm Rosettgen an.", "tokens": ["Und", "tr\u00e4gst", "ihm", "Ro\u00b7sett\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Jenem gl\u00e4ubt sie/ wann er schertzet/", "tokens": ["Je\u00b7nem", "gl\u00e4ubt", "sie", "/", "wann", "er", "schert\u00b7zet", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$(", "PWAV", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mir verwirfft sie/ was mich schmertzet;", "tokens": ["Mir", "ver\u00b7wirfft", "sie", "/", "was", "mich", "schmert\u00b7zet", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Beydes ist zu viel gethan.", "tokens": ["Bey\u00b7des", "ist", "zu", "viel", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PTKA", "PIS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Amor/ hilff ihm doch nicht stehlen/", "tokens": ["A\u00b7mor", "/", "hilff", "ihm", "doch", "nicht", "steh\u00b7len", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NN", "PPER", "ADV", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00df sie/ wen sie will/ erwehlen/", "tokens": ["La\u00df", "sie", "/", "wen", "sie", "will", "/", "er\u00b7weh\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVIMP", "PPER", "$(", "PWS", "PPER", "VMFIN", "$(", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Beut sie nur nicht selber an.", "tokens": ["Beut", "sie", "nur", "nicht", "sel\u00b7ber", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Amor/ willstu/ da\u00df ich sage/", "tokens": ["A\u00b7mor", "/", "will\u00b7stu", "/", "da\u00df", "ich", "sa\u00b7ge", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "VMFIN", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.2": {"text": "Amor/ willstu/ da\u00df ich klage/", "tokens": ["A\u00b7mor", "/", "will\u00b7stu", "/", "da\u00df", "ich", "kla\u00b7ge", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "VMFIN", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was du mir zu viel gethan?", "tokens": ["Was", "du", "mir", "zu", "viel", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "PTKA", "PIS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Du entz\u00fcndest meine liebe/", "tokens": ["Du", "ent\u00b7z\u00fcn\u00b7dest", "mei\u00b7ne", "lie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und doch hilffstu meinem diebe/", "tokens": ["Und", "doch", "hilffs\u00b7tu", "mei\u00b7nem", "die\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und tr\u00e4gst ihm Rosettgen an.", "tokens": ["Und", "tr\u00e4gst", "ihm", "Ro\u00b7sett\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Jenem gl\u00e4ubt sie/ wann er schertzet/", "tokens": ["Je\u00b7nem", "gl\u00e4ubt", "sie", "/", "wann", "er", "schert\u00b7zet", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$(", "PWAV", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mir verwirfft sie/ was mich schmertzet;", "tokens": ["Mir", "ver\u00b7wirfft", "sie", "/", "was", "mich", "schmert\u00b7zet", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Beydes ist zu viel gethan.", "tokens": ["Bey\u00b7des", "ist", "zu", "viel", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PTKA", "PIS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Amor/ hilff ihm doch nicht stehlen/", "tokens": ["A\u00b7mor", "/", "hilff", "ihm", "doch", "nicht", "steh\u00b7len", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NN", "PPER", "ADV", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00df sie/ wen sie will/ erwehlen/", "tokens": ["La\u00df", "sie", "/", "wen", "sie", "will", "/", "er\u00b7weh\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVIMP", "PPER", "$(", "PWS", "PPER", "VMFIN", "$(", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Beut sie nur nicht selber an.", "tokens": ["Beut", "sie", "nur", "nicht", "sel\u00b7ber", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}