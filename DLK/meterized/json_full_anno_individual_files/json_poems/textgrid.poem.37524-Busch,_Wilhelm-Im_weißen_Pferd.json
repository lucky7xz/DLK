{"textgrid.poem.37524": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Im wei\u00dfen Pferd", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer Bildung und Moral besitzt,", "tokens": ["Wer", "Bil\u00b7dung", "und", "Mo\u00b7ral", "be\u00b7sitzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der wird bemerken, da\u00df anitzt", "tokens": ["Der", "wird", "be\u00b7mer\u00b7ken", ",", "da\u00df", "a\u00b7nitzt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "VVINF", "$,", "KOUS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Fast nirgends mehr zu finden sei", "tokens": ["Fast", "nir\u00b7gends", "mehr", "zu", "fin\u00b7den", "sei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIS", "PTKZU", "VVINF", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die sogenannte Lieb und Treu. \u2013", "tokens": ["Die", "so\u00b7ge\u00b7nann\u00b7te", "Lieb", "und", "Treu", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man sieht zuerst mit Angstgef\u00fchlen", "tokens": ["Man", "sieht", "zu\u00b7erst", "mit", "Angst\u00b7ge\u00b7f\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Herunterfallen von den St\u00fchlen", "tokens": ["Her\u00b7un\u00b7ter\u00b7fal\u00b7len", "von", "den", "St\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die angestammten Landesv\u00e4ter \u2013", "tokens": ["Die", "an\u00b7ge\u00b7stamm\u00b7ten", "Lan\u00b7des\u00b7v\u00e4\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sodann, als k\u00fchler Hochverr\u00e4ter,", "tokens": ["So\u00b7dann", ",", "als", "k\u00fch\u00b7ler", "Hoch\u00b7ver\u00b7r\u00e4\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Zieht man die Tabaksdos hervor,", "tokens": ["Zieht", "man", "die", "Ta\u00b7baks\u00b7dos", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Blickt sanft und seelenvoll empor,", "tokens": ["Blickt", "sanft", "und", "see\u00b7len\u00b7voll", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Streckt sich auf weichem Kanapee,", "tokens": ["Streckt", "sich", "auf", "wei\u00b7chem", "Ka\u00b7na\u00b7pee", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Schl\u00fcrft mit Behagen den Kaffee \u2013", "tokens": ["Schl\u00fcrft", "mit", "Be\u00b7ha\u00b7gen", "den", "Kaf\u00b7fee", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.13": {"text": "Und ist man so aufs neu erfrischt,", "tokens": ["Und", "ist", "man", "so", "aufs", "neu", "er\u00b7frischt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "ADV", "APPRART", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Dann denkt man: \u00bbNa, die hat's erwischt!\u00ab", "tokens": ["Dann", "denkt", "man", ":", "\u00bb", "Na", ",", "die", "hat's", "er\u00b7wischt", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$.", "$(", "ITJ", "$,", "PRELS", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "So denkt der b\u00f6se Mensch. \u2013 Jedoch", "tokens": ["So", "denkt", "der", "b\u00f6\u00b7se", "Mensch", ".", "\u2013", "Je\u00b7doch"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "$(", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Es gibt auch gute Menschen noch. \u2013", "tokens": ["Es", "gibt", "auch", "gu\u00b7te", "Men\u00b7schen", "noch", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Zu Milbenau im wei\u00dfen Pferd", "tokens": ["Zu", "Mil\u00b7be\u00b7nau", "im", "wei\u00b7\u00dfen", "Pferd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei Mutter K\u00f6hm, die jeder ehrt,", "tokens": ["Bei", "Mut\u00b7ter", "K\u00f6hm", ",", "die", "je\u00b7der", "ehrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da sitzen, eng vereint und bieder,", "tokens": ["Da", "sit\u00b7zen", ",", "eng", "ver\u00b7eint", "und", "bie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADJD", "VVPP", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch diesen Sonntagabend wieder", "tokens": ["Auch", "die\u00b7sen", "Sonn\u00b7ta\u00b7ga\u00b7bend", "wie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PDAT", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nach altem Brauch im Freundschaftskreise", "tokens": ["Nach", "al\u00b7tem", "Brauch", "im", "Freund\u00b7schafts\u00b7krei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die M\u00e4nner und die M\u00fcmmelgreise. \u2013", "tokens": ["Die", "M\u00e4n\u00b7ner", "und", "die", "M\u00fcm\u00b7mel\u00b7grei\u00b7se", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbet blivt nich so! Et blivt nich so!!\u00ab", "tokens": ["\u00bb", "et", "blivt", "nich", "so", "!", "Et", "blivt", "nich", "so", "!!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "VVFIN", "PTKNEG", "ADV", "$.", "NE", "VVFIN", "PTKNEG", "ADV", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So murmelt jeder hoffnungsfroh. \u2013", "tokens": ["So", "mur\u00b7melt", "je\u00b7der", "hoff\u00b7nungs\u00b7froh", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbet schall nich bliben ans et is!", "tokens": ["\u00bb", "et", "schall", "nich", "bli\u00b7ben", "ans", "et", "is", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PTKNEG", "VVFIN", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Et schall weer weeren anse s\u00fc\u00df!!\u00ab", "tokens": ["Et", "schall", "weer", "wee\u00b7ren", "an\u00b7se", "s\u00fc\u00df", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["FM.en", "FM.en", "FM.en", "FM.en", "FM.en", "FM.en", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbun dat seg eck! Un dat seg eck!\u00ab", "tokens": ["\u00bb", "un", "dat", "seg", "eck", "!", "Un", "dat", "seg", "eck", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "FM", "FM", "FM", "$.", "NE", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So spricht entschieden Schneider B\u00f6ck. \u2013", "tokens": ["So", "spricht", "ent\u00b7schie\u00b7den", "Schnei\u00b7der", "B\u00f6ck", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Hierauf spricht l\u00e4chelnd Krischan Stinkel", "tokens": ["Hier\u00b7auf", "spricht", "l\u00e4\u00b7chelnd", "Krisc\u00b7han", "Stin\u00b7kel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADJD", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und zwinkert mit dem Augenwinkel:", "tokens": ["Und", "zwin\u00b7kert", "mit", "dem", "Au\u00b7gen\u00b7win\u00b7kel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbeck segge man, vor min Pl\u00e4sier,", "tokens": ["\u00bb", "eck", "seg\u00b7ge", "man", ",", "vor", "min", "Pl\u00e4\u00b7sier", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PIS", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gottlof! Wat is de Botter d\u00fcr!!\u00ab", "tokens": ["Gott\u00b7lof", "!", "Wat", "is", "de", "Bot\u00b7ter", "d\u00fcr", "!!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$.", "FM", "FM", "FM", "FM", "FM", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Dagegen ruft der lange Korte", "tokens": ["Da\u00b7ge\u00b7gen", "ruft", "der", "lan\u00b7ge", "Kor\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Zorneseifer diese Worte:", "tokens": ["Mit", "Zor\u00b7nes\u00b7ei\u00b7fer", "die\u00b7se", "Wor\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbkreuzhimmeldausenddonnerw\u00e4r,", "tokens": ["\u00bb", "kreuz\u00b7him\u00b7mel\u00b7dau\u00b7send\u00b7don\u00b7ner\u00b7w\u00e4r", ","], "token_info": ["punct", "word", "punct"], "pos": ["$(", "VVIMP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Uns' olle K\u00f6nig mot weer her!!\u00ab", "tokens": ["Un\u00b7s'", "ol\u00b7le", "K\u00f6\u00b7nig", "mot", "weer", "her", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NE", "ADJD", "PTKVZ", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Jetzt sieht sich B\u00fcrgermeister Mumm", "tokens": ["Jetzt", "sieht", "sich", "B\u00fcr\u00b7ger\u00b7meis\u00b7ter", "Mumm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bedenklich nach der Seite um.", "tokens": ["Be\u00b7denk\u00b7lich", "nach", "der", "Sei\u00b7te", "um", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbpi\u00dft!!\u00ab \u2013 ruft er \u2013 \u00bbRuhig, liebe Leut!", "tokens": ["\u00bb", "pi\u00dft", "!!", "\u00ab", "\u2013", "ruft", "er", "\u2013", "\u00bb", "Ru\u00b7hig", ",", "lie\u00b7be", "Leut", "!"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$.", "$(", "$(", "VVFIN", "PPER", "$(", "$(", "NE", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Seid untertan der Obrigkeit!!\u00ab", "tokens": ["Seid", "un\u00b7ter\u00b7tan", "der", "Ob\u00b7rig\u00b7keit", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAIMP", "ADJD", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbja, aber man bis insoweit!", "tokens": ["\u00bb", "ja", ",", "a\u00b7ber", "man", "bis", "in\u00b7so\u00b7weit", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "KON", "PIS", "APPR", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Seggt unse olle Herr Pastor.\u00ab", "tokens": ["Seggt", "un\u00b7se", "ol\u00b7le", "Herr", "Pas\u00b7tor", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbdat hat he seggt!!!\u00ab \u2013 so t\u00f6nt's im Chor. \u2013", "tokens": ["\u00bb", "dat", "hat", "he", "seggt", "!!!", "\u00ab", "\u2013", "so", "t\u00f6nt's", "im", "Chor", ".", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PAV", "VAFIN", "NE", "VVFIN", "$.", "$(", "$(", "ADV", "VVFIN", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Hierauf, so wird es etwas stille,", "tokens": ["Hier\u00b7auf", ",", "so", "wird", "es", "et\u00b7was", "stil\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und grad kommt Herr Aptheker Pille.", "tokens": ["Und", "grad", "kommt", "Herr", "Ap\u00b7the\u00b7ker", "Pil\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NN", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbihr Leute, da\u00df ich's blo\u00df man sage!", "tokens": ["\u00bb", "ihr", "Leu\u00b7te", ",", "da\u00df", "ich's", "blo\u00df", "man", "sa\u00b7ge", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "KOUS", "PIS", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Denn morgen ist der Tag der Tage,", "tokens": ["Denn", "mor\u00b7gen", "ist", "der", "Tag", "der", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da er geboren, der \u2013 \u2013 ihr wi\u00dft! \u2013 \u2013\u00ab", "tokens": ["Da", "er", "ge\u00b7bo\u00b7ren", ",", "der", "\u2013", "\u2013", "ihr", "wi\u00dft", "!", "\u2013", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$,", "PRELS", "$(", "$(", "PPER", "VVFIN", "$.", "$(", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbja ja, so is't! Ja ja, so is't!!\u00ab", "tokens": ["\u00bb", "ja", "ja", ",", "so", "is't", "!", "Ja", "ja", ",", "so", "is't", "!!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "ADV", "ADJD", "$.", "PTKANT", "PTKANT", "$,", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "\u00bbnun ist Euch allen wohlbekannt", "tokens": ["\u00bb", "nun", "ist", "Euch", "al\u00b7len", "wohl\u00b7be\u00b7kannt"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Busenfreund, den ich erfand,", "tokens": ["Der", "Bu\u00b7sen\u00b7freund", ",", "den", "ich", "er\u00b7fand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der segensreiche Labetrank,", "tokens": ["Der", "se\u00b7gens\u00b7rei\u00b7che", "La\u00b7be\u00b7trank", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der, sei man munter oder krank,", "tokens": ["Der", ",", "sei", "man", "mun\u00b7ter", "o\u00b7der", "krank", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VAFIN", "PIS", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erw\u00e4rmend dringt bei hoch und nieder", "tokens": ["Er\u00b7w\u00e4r\u00b7mend", "dringt", "bei", "hoch", "und", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "VVFIN", "APPR", "ADJD", "KON", "PTKVZ"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch Kopf, Herz, Magen und die Glieder \u2013 \u2013", "tokens": ["Durch", "Kopf", ",", "Herz", ",", "Ma\u00b7gen", "und", "die", "Glie\u00b7der", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "ART", "NN", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wie w\u00e4r es, hochverehrte Freunde,", "tokens": ["Wie", "w\u00e4r", "es", ",", "hoch\u00b7ver\u00b7ehr\u00b7te", "Freun\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn man im Namen der Gemeinde", "tokens": ["Wenn", "man", "im", "Na\u00b7men", "der", "Ge\u00b7mein\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPRART", "NN", "ART", "NN"], "meter": "+--+---+-", "measure": "dactylic.di.plus"}, "line.9": {"text": "Ein Dutzend Flaschen oder so \u2013 \u2013\u00ab", "tokens": ["Ein", "Dut\u00b7zend", "Fla\u00b7schen", "o\u00b7der", "so", "\u2013", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "NN", "KON", "ADV", "$(", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "\u00bbja ja, man to! Ja ja, man to!!\u00ab", "tokens": ["\u00bb", "ja", "ja", ",", "man", "to", "!", "Ja", "ja", ",", "man", "to", "!!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "PIS", "ADV", "$.", "PTKANT", "PTKANT", "$,", "PIS", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "So t\u00f6nt es laut im treuen Kreise", "tokens": ["So", "t\u00f6nt", "es", "laut", "im", "treu\u00b7en", "Krei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Der M\u00e4nner und der M\u00fcmmelgreise.", "tokens": ["Der", "M\u00e4n\u00b7ner", "und", "der", "M\u00fcm\u00b7mel\u00b7grei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und jeder ruft: \u00bbHe, Mutter K\u00f6hmen!", "tokens": ["Und", "je\u00b7der", "ruft", ":", "\u00bb", "He", ",", "Mut\u00b7ter", "K\u00f6h\u00b7men", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$.", "$(", "ITJ", "$,", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Up d\u00fct will wi noch Einen n\u00f6hmen!!\u00ab", "tokens": ["Up", "d\u00fct", "will", "wi", "noch", "Ei\u00b7nen", "n\u00f6h\u00b7men", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "VMFIN", "KOKOM", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Gesagt, getan. \u2013 F\u00fcr Mutter K\u00f6hm", "tokens": ["Ge\u00b7sagt", ",", "ge\u00b7tan", ".", "\u2013", "F\u00fcr", "Mut\u00b7ter", "K\u00f6hm"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "VVPP", "$.", "$(", "APPR", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist dies nat\u00fcrlich angenehm.", "tokens": ["Ist", "dies", "na\u00b7t\u00fcr\u00b7lich", "an\u00b7ge\u00b7nehm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Wer Bildung und Moral besitzt,", "tokens": ["Wer", "Bil\u00b7dung", "und", "Mo\u00b7ral", "be\u00b7sitzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der wird bemerken, da\u00df anitzt", "tokens": ["Der", "wird", "be\u00b7mer\u00b7ken", ",", "da\u00df", "a\u00b7nitzt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "VVINF", "$,", "KOUS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Fast nirgends mehr zu finden sei", "tokens": ["Fast", "nir\u00b7gends", "mehr", "zu", "fin\u00b7den", "sei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIS", "PTKZU", "VVINF", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die sogenannte Lieb und Treu. \u2013", "tokens": ["Die", "so\u00b7ge\u00b7nann\u00b7te", "Lieb", "und", "Treu", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man sieht zuerst mit Angstgef\u00fchlen", "tokens": ["Man", "sieht", "zu\u00b7erst", "mit", "Angst\u00b7ge\u00b7f\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Herunterfallen von den St\u00fchlen", "tokens": ["Her\u00b7un\u00b7ter\u00b7fal\u00b7len", "von", "den", "St\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die angestammten Landesv\u00e4ter \u2013", "tokens": ["Die", "an\u00b7ge\u00b7stamm\u00b7ten", "Lan\u00b7des\u00b7v\u00e4\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sodann, als k\u00fchler Hochverr\u00e4ter,", "tokens": ["So\u00b7dann", ",", "als", "k\u00fch\u00b7ler", "Hoch\u00b7ver\u00b7r\u00e4\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Zieht man die Tabaksdos hervor,", "tokens": ["Zieht", "man", "die", "Ta\u00b7baks\u00b7dos", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Blickt sanft und seelenvoll empor,", "tokens": ["Blickt", "sanft", "und", "see\u00b7len\u00b7voll", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Streckt sich auf weichem Kanapee,", "tokens": ["Streckt", "sich", "auf", "wei\u00b7chem", "Ka\u00b7na\u00b7pee", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Schl\u00fcrft mit Behagen den Kaffee \u2013", "tokens": ["Schl\u00fcrft", "mit", "Be\u00b7ha\u00b7gen", "den", "Kaf\u00b7fee", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.13": {"text": "Und ist man so aufs neu erfrischt,", "tokens": ["Und", "ist", "man", "so", "aufs", "neu", "er\u00b7frischt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "ADV", "APPRART", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Dann denkt man: \u00bbNa, die hat's erwischt!\u00ab", "tokens": ["Dann", "denkt", "man", ":", "\u00bb", "Na", ",", "die", "hat's", "er\u00b7wischt", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$.", "$(", "ITJ", "$,", "PRELS", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "So denkt der b\u00f6se Mensch. \u2013 Jedoch", "tokens": ["So", "denkt", "der", "b\u00f6\u00b7se", "Mensch", ".", "\u2013", "Je\u00b7doch"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "$(", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Es gibt auch gute Menschen noch. \u2013", "tokens": ["Es", "gibt", "auch", "gu\u00b7te", "Men\u00b7schen", "noch", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Zu Milbenau im wei\u00dfen Pferd", "tokens": ["Zu", "Mil\u00b7be\u00b7nau", "im", "wei\u00b7\u00dfen", "Pferd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei Mutter K\u00f6hm, die jeder ehrt,", "tokens": ["Bei", "Mut\u00b7ter", "K\u00f6hm", ",", "die", "je\u00b7der", "ehrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da sitzen, eng vereint und bieder,", "tokens": ["Da", "sit\u00b7zen", ",", "eng", "ver\u00b7eint", "und", "bie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADJD", "VVPP", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch diesen Sonntagabend wieder", "tokens": ["Auch", "die\u00b7sen", "Sonn\u00b7ta\u00b7ga\u00b7bend", "wie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PDAT", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nach altem Brauch im Freundschaftskreise", "tokens": ["Nach", "al\u00b7tem", "Brauch", "im", "Freund\u00b7schafts\u00b7krei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die M\u00e4nner und die M\u00fcmmelgreise. \u2013", "tokens": ["Die", "M\u00e4n\u00b7ner", "und", "die", "M\u00fcm\u00b7mel\u00b7grei\u00b7se", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "\u00bbet blivt nich so! Et blivt nich so!!\u00ab", "tokens": ["\u00bb", "et", "blivt", "nich", "so", "!", "Et", "blivt", "nich", "so", "!!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "VVFIN", "PTKNEG", "ADV", "$.", "NE", "VVFIN", "PTKNEG", "ADV", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So murmelt jeder hoffnungsfroh. \u2013", "tokens": ["So", "mur\u00b7melt", "je\u00b7der", "hoff\u00b7nungs\u00b7froh", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "\u00bbet schall nich bliben ans et is!", "tokens": ["\u00bb", "et", "schall", "nich", "bli\u00b7ben", "ans", "et", "is", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PTKNEG", "VVFIN", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Et schall weer weeren anse s\u00fc\u00df!!\u00ab", "tokens": ["Et", "schall", "weer", "wee\u00b7ren", "an\u00b7se", "s\u00fc\u00df", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["FM.en", "FM.en", "FM.en", "FM.en", "FM.en", "FM.en", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbun dat seg eck! Un dat seg eck!\u00ab", "tokens": ["\u00bb", "un", "dat", "seg", "eck", "!", "Un", "dat", "seg", "eck", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "FM", "FM", "FM", "$.", "NE", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So spricht entschieden Schneider B\u00f6ck. \u2013", "tokens": ["So", "spricht", "ent\u00b7schie\u00b7den", "Schnei\u00b7der", "B\u00f6ck", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Hierauf spricht l\u00e4chelnd Krischan Stinkel", "tokens": ["Hier\u00b7auf", "spricht", "l\u00e4\u00b7chelnd", "Krisc\u00b7han", "Stin\u00b7kel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADJD", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und zwinkert mit dem Augenwinkel:", "tokens": ["Und", "zwin\u00b7kert", "mit", "dem", "Au\u00b7gen\u00b7win\u00b7kel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbeck segge man, vor min Pl\u00e4sier,", "tokens": ["\u00bb", "eck", "seg\u00b7ge", "man", ",", "vor", "min", "Pl\u00e4\u00b7sier", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PIS", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gottlof! Wat is de Botter d\u00fcr!!\u00ab", "tokens": ["Gott\u00b7lof", "!", "Wat", "is", "de", "Bot\u00b7ter", "d\u00fcr", "!!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$.", "FM", "FM", "FM", "FM", "FM", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Dagegen ruft der lange Korte", "tokens": ["Da\u00b7ge\u00b7gen", "ruft", "der", "lan\u00b7ge", "Kor\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Zorneseifer diese Worte:", "tokens": ["Mit", "Zor\u00b7nes\u00b7ei\u00b7fer", "die\u00b7se", "Wor\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbkreuzhimmeldausenddonnerw\u00e4r,", "tokens": ["\u00bb", "kreuz\u00b7him\u00b7mel\u00b7dau\u00b7send\u00b7don\u00b7ner\u00b7w\u00e4r", ","], "token_info": ["punct", "word", "punct"], "pos": ["$(", "VVIMP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Uns' olle K\u00f6nig mot weer her!!\u00ab", "tokens": ["Un\u00b7s'", "ol\u00b7le", "K\u00f6\u00b7nig", "mot", "weer", "her", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NE", "ADJD", "PTKVZ", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.18": {"line.1": {"text": "Jetzt sieht sich B\u00fcrgermeister Mumm", "tokens": ["Jetzt", "sieht", "sich", "B\u00fcr\u00b7ger\u00b7meis\u00b7ter", "Mumm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bedenklich nach der Seite um.", "tokens": ["Be\u00b7denk\u00b7lich", "nach", "der", "Sei\u00b7te", "um", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbpi\u00dft!!\u00ab \u2013 ruft er \u2013 \u00bbRuhig, liebe Leut!", "tokens": ["\u00bb", "pi\u00dft", "!!", "\u00ab", "\u2013", "ruft", "er", "\u2013", "\u00bb", "Ru\u00b7hig", ",", "lie\u00b7be", "Leut", "!"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$.", "$(", "$(", "VVFIN", "PPER", "$(", "$(", "NE", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Seid untertan der Obrigkeit!!\u00ab", "tokens": ["Seid", "un\u00b7ter\u00b7tan", "der", "Ob\u00b7rig\u00b7keit", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAIMP", "ADJD", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "\u00bbja, aber man bis insoweit!", "tokens": ["\u00bb", "ja", ",", "a\u00b7ber", "man", "bis", "in\u00b7so\u00b7weit", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "KON", "PIS", "APPR", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Seggt unse olle Herr Pastor.\u00ab", "tokens": ["Seggt", "un\u00b7se", "ol\u00b7le", "Herr", "Pas\u00b7tor", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbdat hat he seggt!!!\u00ab \u2013 so t\u00f6nt's im Chor. \u2013", "tokens": ["\u00bb", "dat", "hat", "he", "seggt", "!!!", "\u00ab", "\u2013", "so", "t\u00f6nt's", "im", "Chor", ".", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PAV", "VAFIN", "NE", "VVFIN", "$.", "$(", "$(", "ADV", "VVFIN", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Hierauf, so wird es etwas stille,", "tokens": ["Hier\u00b7auf", ",", "so", "wird", "es", "et\u00b7was", "stil\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und grad kommt Herr Aptheker Pille.", "tokens": ["Und", "grad", "kommt", "Herr", "Ap\u00b7the\u00b7ker", "Pil\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NN", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbihr Leute, da\u00df ich's blo\u00df man sage!", "tokens": ["\u00bb", "ihr", "Leu\u00b7te", ",", "da\u00df", "ich's", "blo\u00df", "man", "sa\u00b7ge", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "KOUS", "PIS", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Denn morgen ist der Tag der Tage,", "tokens": ["Denn", "mor\u00b7gen", "ist", "der", "Tag", "der", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da er geboren, der \u2013 \u2013 ihr wi\u00dft! \u2013 \u2013\u00ab", "tokens": ["Da", "er", "ge\u00b7bo\u00b7ren", ",", "der", "\u2013", "\u2013", "ihr", "wi\u00dft", "!", "\u2013", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$,", "PRELS", "$(", "$(", "PPER", "VVFIN", "$.", "$(", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbja ja, so is't! Ja ja, so is't!!\u00ab", "tokens": ["\u00bb", "ja", "ja", ",", "so", "is't", "!", "Ja", "ja", ",", "so", "is't", "!!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "ADV", "ADJD", "$.", "PTKANT", "PTKANT", "$,", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "\u00bbnun ist Euch allen wohlbekannt", "tokens": ["\u00bb", "nun", "ist", "Euch", "al\u00b7len", "wohl\u00b7be\u00b7kannt"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Busenfreund, den ich erfand,", "tokens": ["Der", "Bu\u00b7sen\u00b7freund", ",", "den", "ich", "er\u00b7fand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der segensreiche Labetrank,", "tokens": ["Der", "se\u00b7gens\u00b7rei\u00b7che", "La\u00b7be\u00b7trank", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der, sei man munter oder krank,", "tokens": ["Der", ",", "sei", "man", "mun\u00b7ter", "o\u00b7der", "krank", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VAFIN", "PIS", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erw\u00e4rmend dringt bei hoch und nieder", "tokens": ["Er\u00b7w\u00e4r\u00b7mend", "dringt", "bei", "hoch", "und", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "VVFIN", "APPR", "ADJD", "KON", "PTKVZ"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch Kopf, Herz, Magen und die Glieder \u2013 \u2013", "tokens": ["Durch", "Kopf", ",", "Herz", ",", "Ma\u00b7gen", "und", "die", "Glie\u00b7der", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "ART", "NN", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wie w\u00e4r es, hochverehrte Freunde,", "tokens": ["Wie", "w\u00e4r", "es", ",", "hoch\u00b7ver\u00b7ehr\u00b7te", "Freun\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn man im Namen der Gemeinde", "tokens": ["Wenn", "man", "im", "Na\u00b7men", "der", "Ge\u00b7mein\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPRART", "NN", "ART", "NN"], "meter": "+--+---+-", "measure": "dactylic.di.plus"}, "line.9": {"text": "Ein Dutzend Flaschen oder so \u2013 \u2013\u00ab", "tokens": ["Ein", "Dut\u00b7zend", "Fla\u00b7schen", "o\u00b7der", "so", "\u2013", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "NN", "KON", "ADV", "$(", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "\u00bbja ja, man to! Ja ja, man to!!\u00ab", "tokens": ["\u00bb", "ja", "ja", ",", "man", "to", "!", "Ja", "ja", ",", "man", "to", "!!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "PIS", "ADV", "$.", "PTKANT", "PTKANT", "$,", "PIS", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "So t\u00f6nt es laut im treuen Kreise", "tokens": ["So", "t\u00f6nt", "es", "laut", "im", "treu\u00b7en", "Krei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Der M\u00e4nner und der M\u00fcmmelgreise.", "tokens": ["Der", "M\u00e4n\u00b7ner", "und", "der", "M\u00fcm\u00b7mel\u00b7grei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und jeder ruft: \u00bbHe, Mutter K\u00f6hmen!", "tokens": ["Und", "je\u00b7der", "ruft", ":", "\u00bb", "He", ",", "Mut\u00b7ter", "K\u00f6h\u00b7men", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$.", "$(", "ITJ", "$,", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Up d\u00fct will wi noch Einen n\u00f6hmen!!\u00ab", "tokens": ["Up", "d\u00fct", "will", "wi", "noch", "Ei\u00b7nen", "n\u00f6h\u00b7men", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "VMFIN", "KOKOM", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Gesagt, getan. \u2013 F\u00fcr Mutter K\u00f6hm", "tokens": ["Ge\u00b7sagt", ",", "ge\u00b7tan", ".", "\u2013", "F\u00fcr", "Mut\u00b7ter", "K\u00f6hm"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "VVPP", "$.", "$(", "APPR", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist dies nat\u00fcrlich angenehm.", "tokens": ["Ist", "dies", "na\u00b7t\u00fcr\u00b7lich", "an\u00b7ge\u00b7nehm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}