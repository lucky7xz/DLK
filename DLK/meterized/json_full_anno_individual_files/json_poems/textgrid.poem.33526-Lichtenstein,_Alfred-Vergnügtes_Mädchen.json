{"textgrid.poem.33526": {"metadata": {"author": {"name": "Lichtenstein, Alfred", "birth": "N.A.", "death": "N.A."}, "title": "Vergn\u00fcgtes M\u00e4dchen", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sieh doch, so ein feines Luder!", "tokens": ["Sieh", "doch", ",", "so", "ein", "fei\u00b7nes", "Lu\u00b7der", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Diesmal hatt' ich wirklich Schwein.", "tokens": ["Dies\u00b7mal", "hatt'", "ich", "wirk\u00b7lich", "Schwein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sein Gesicht ist wei\u00df wie Puder \u2013", "tokens": ["Sein", "Ge\u00b7sicht", "ist", "wei\u00df", "wie", "Pu\u00b7der", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KOKOM", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Louis, nimm ihn! La\u00df mich sein ...", "tokens": ["Lou\u00b7is", ",", "nimm", "ihn", "!", "La\u00df", "mich", "sein", "..."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVIMP", "PPER", "$.", "VVIMP", "PPER", "PPOSAT", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wird sich noch ein Bein ausrenken \u2013", "tokens": ["Wird", "sich", "noch", "ein", "Bein", "aus\u00b7ren\u00b7ken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "ART", "NN", "VVIZU", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Oder schl\u00e4gt an einen Pfahl \u2013", "tokens": ["O\u00b7der", "schl\u00e4gt", "an", "ei\u00b7nen", "Pfahl", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hui, der wird sein Lebtag denken", "tokens": ["Hui", ",", "der", "wird", "sein", "Leb\u00b7tag", "den\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["FM", "$,", "PRELS", "VAFIN", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An den heut'gen Karneval.", "tokens": ["An", "den", "heut'\u00b7gen", "Kar\u00b7ne\u00b7val", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Kannst ihn ganz allein behalten ...", "tokens": ["Kannst", "ihn", "ganz", "al\u00b7lein", "be\u00b7hal\u00b7ten", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df dich nur kein Wachmann fa\u00dft \u2013", "tokens": ["Da\u00df", "dich", "nur", "kein", "Wach\u00b7mann", "fa\u00dft", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Geh doch zu der Sau, der alten,", "tokens": ["Geh", "doch", "zu", "der", "Sau", ",", "der", "al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die du ja viel lieber hast.", "tokens": ["Die", "du", "ja", "viel", "lie\u00b7ber", "hast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich find alle Tage einen", "tokens": ["Ich", "find", "al\u00b7le", "Ta\u00b7ge", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ART"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Neuen Freund ... ich brauch dich nicht.", "tokens": ["Neu\u00b7en", "Freund", "...", "ich", "brauch", "dich", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Louis schielt nach meinen Beinen,", "tokens": ["Lou\u00b7is", "schielt", "nach", "mei\u00b7nen", "Bei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schimpft. Und schl\u00e4gt mich ins Gesicht:", "tokens": ["Schimpft", ".", "Und", "schl\u00e4gt", "mich", "ins", "Ge\u00b7sicht", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "\u00bbwirst du gleich ihn bei den F\u00fc\u00dfen", "tokens": ["\u00bb", "wirst", "du", "gleich", "ihn", "bei", "den", "F\u00fc\u00b7\u00dfen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "ADV", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fassen ... Quatsch nicht ... So ... Gradaus.", "tokens": ["Fas\u00b7sen", "...", "Quatsch", "nicht", "...", "So", "...", "Gra\u00b7daus", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "PTKNEG", "$(", "ADV", "$(", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Warte, Schleimst\u00fcck, du sollst's b\u00fc\u00dfen,", "tokens": ["War\u00b7te", ",", "Schleim\u00b7st\u00fcck", ",", "du", "sollst's", "b\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kommst du erst mit mir nach Haus!\u00ab", "tokens": ["Kommst", "du", "erst", "mit", "mir", "nach", "Haus", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PPER", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Mich ergreift ein tolles Fieber.", "tokens": ["Mich", "er\u00b7greift", "ein", "tol\u00b7les", "Fie\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hiii \u2013 ich freu' mich f\u00fcrchterlich.", "tokens": ["Hi\u00b7ii", "\u2013", "ich", "freu'", "mich", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Endlich wieder ist mein lieber", "tokens": ["End\u00b7lich", "wie\u00b7der", "ist", "mein", "lie\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "S\u00fc\u00dfer Schieber geil auf mich.", "tokens": ["S\u00fc\u00b7\u00dfer", "Schie\u00b7ber", "geil", "auf", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Sieh doch, so ein feines Luder!", "tokens": ["Sieh", "doch", ",", "so", "ein", "fei\u00b7nes", "Lu\u00b7der", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Diesmal hatt' ich wirklich Schwein.", "tokens": ["Dies\u00b7mal", "hatt'", "ich", "wirk\u00b7lich", "Schwein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sein Gesicht ist wei\u00df wie Puder \u2013", "tokens": ["Sein", "Ge\u00b7sicht", "ist", "wei\u00df", "wie", "Pu\u00b7der", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KOKOM", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Louis, nimm ihn! La\u00df mich sein ...", "tokens": ["Lou\u00b7is", ",", "nimm", "ihn", "!", "La\u00df", "mich", "sein", "..."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVIMP", "PPER", "$.", "VVIMP", "PPER", "PPOSAT", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wird sich noch ein Bein ausrenken \u2013", "tokens": ["Wird", "sich", "noch", "ein", "Bein", "aus\u00b7ren\u00b7ken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "ART", "NN", "VVIZU", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Oder schl\u00e4gt an einen Pfahl \u2013", "tokens": ["O\u00b7der", "schl\u00e4gt", "an", "ei\u00b7nen", "Pfahl", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hui, der wird sein Lebtag denken", "tokens": ["Hui", ",", "der", "wird", "sein", "Leb\u00b7tag", "den\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["FM", "$,", "PRELS", "VAFIN", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An den heut'gen Karneval.", "tokens": ["An", "den", "heut'\u00b7gen", "Kar\u00b7ne\u00b7val", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Kannst ihn ganz allein behalten ...", "tokens": ["Kannst", "ihn", "ganz", "al\u00b7lein", "be\u00b7hal\u00b7ten", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df dich nur kein Wachmann fa\u00dft \u2013", "tokens": ["Da\u00df", "dich", "nur", "kein", "Wach\u00b7mann", "fa\u00dft", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Geh doch zu der Sau, der alten,", "tokens": ["Geh", "doch", "zu", "der", "Sau", ",", "der", "al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die du ja viel lieber hast.", "tokens": ["Die", "du", "ja", "viel", "lie\u00b7ber", "hast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Ich find alle Tage einen", "tokens": ["Ich", "find", "al\u00b7le", "Ta\u00b7ge", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ART"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Neuen Freund ... ich brauch dich nicht.", "tokens": ["Neu\u00b7en", "Freund", "...", "ich", "brauch", "dich", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Louis schielt nach meinen Beinen,", "tokens": ["Lou\u00b7is", "schielt", "nach", "mei\u00b7nen", "Bei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schimpft. Und schl\u00e4gt mich ins Gesicht:", "tokens": ["Schimpft", ".", "Und", "schl\u00e4gt", "mich", "ins", "Ge\u00b7sicht", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "\u00bbwirst du gleich ihn bei den F\u00fc\u00dfen", "tokens": ["\u00bb", "wirst", "du", "gleich", "ihn", "bei", "den", "F\u00fc\u00b7\u00dfen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "ADV", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fassen ... Quatsch nicht ... So ... Gradaus.", "tokens": ["Fas\u00b7sen", "...", "Quatsch", "nicht", "...", "So", "...", "Gra\u00b7daus", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "PTKNEG", "$(", "ADV", "$(", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Warte, Schleimst\u00fcck, du sollst's b\u00fc\u00dfen,", "tokens": ["War\u00b7te", ",", "Schleim\u00b7st\u00fcck", ",", "du", "sollst's", "b\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kommst du erst mit mir nach Haus!\u00ab", "tokens": ["Kommst", "du", "erst", "mit", "mir", "nach", "Haus", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PPER", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Mich ergreift ein tolles Fieber.", "tokens": ["Mich", "er\u00b7greift", "ein", "tol\u00b7les", "Fie\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hiii \u2013 ich freu' mich f\u00fcrchterlich.", "tokens": ["Hi\u00b7ii", "\u2013", "ich", "freu'", "mich", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Endlich wieder ist mein lieber", "tokens": ["End\u00b7lich", "wie\u00b7der", "ist", "mein", "lie\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "S\u00fc\u00dfer Schieber geil auf mich.", "tokens": ["S\u00fc\u00b7\u00dfer", "Schie\u00b7ber", "geil", "auf", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}