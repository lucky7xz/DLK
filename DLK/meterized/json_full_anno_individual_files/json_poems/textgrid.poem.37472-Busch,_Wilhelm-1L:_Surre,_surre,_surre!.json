{"textgrid.poem.37472": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: Surre, surre, surre!", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.57", "fr:0.42"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Surre, surre, surre!", "tokens": ["Sur\u00b7re", ",", "sur\u00b7re", ",", "sur\u00b7re", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mein gutes R\u00e4dchen schnurre!", "tokens": ["Mein", "gu\u00b7tes", "R\u00e4d\u00b7chen", "schnur\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "F\u00fcr unser kleines K\u00e4tchen", "tokens": ["F\u00fcr", "un\u00b7ser", "klei\u00b7nes", "K\u00e4t\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dreh mir ein feines F\u00e4dchen,", "tokens": ["Dreh", "mir", "ein", "fei\u00b7nes", "F\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So lang von hier bis K\u00f6llen", "tokens": ["So", "lang", "von", "hier", "bis", "K\u00f6l\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wohl mehr als tausend Ellen.", "tokens": ["Wohl", "mehr", "als", "tau\u00b7send", "El\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "KOKOM", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wir wollen es winden", "tokens": ["Wir", "wol\u00b7len", "es", "win\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Und Docken von binden,", "tokens": ["Und", "Do\u00b7cken", "von", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.2": {"line.1": {"text": "Meister Weber es geben,", "tokens": ["Meis\u00b7ter", "We\u00b7ber", "es", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPER", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Soll Leinen uns weben,", "tokens": ["Soll", "Lei\u00b7nen", "uns", "we\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "PPER", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Das breiten wir beide", "tokens": ["Das", "brei\u00b7ten", "wir", "bei\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "PPER", "PIS"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Auf blumige Heide,", "tokens": ["Auf", "blu\u00b7mi\u00b7ge", "Hei\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Auf Anger und Wiesen", "tokens": ["Auf", "An\u00b7ger", "und", "Wie\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Und wollen es sonnen,", "tokens": ["Und", "wol\u00b7len", "es", "son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Benetzen und gie\u00dfen", "tokens": ["Be\u00b7net\u00b7zen", "und", "gie\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Aus B\u00e4chen und Bronnen.", "tokens": ["Aus", "B\u00e4\u00b7chen", "und", "Bron\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.3": {"line.1": {"text": "Ach, komm du lieber Sonnenschein", "tokens": ["Ach", ",", "komm", "du", "lie\u00b7ber", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bleiche unser Leinen rein.", "tokens": ["Und", "blei\u00b7che", "un\u00b7ser", "Lei\u00b7nen", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann kriegt mein Herzenst\u00e4ubchen", "tokens": ["Dann", "kriegt", "mein", "Her\u00b7zen\u00b7st\u00e4ub\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wohl manch ein feines Hemd", "tokens": ["Wohl", "manch", "ein", "fei\u00b7nes", "Hemd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und T\u00fcchlein oder H\u00e4ubchen,", "tokens": ["Und", "T\u00fcch\u00b7lein", "o\u00b7der", "H\u00e4ub\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Bis da\u00df der Freier k\u00f6mmt.", "tokens": ["Bis", "da\u00df", "der", "Frei\u00b7er", "k\u00f6mmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Sch\u00f6n guten Tag, Herr Freiersmann!", "tokens": ["Sch\u00f6n", "gu\u00b7ten", "Tag", ",", "Herr", "Frei\u00b7ers\u00b7mann", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was schaut er so mein K\u00e4tchen an?", "tokens": ["Was", "schaut", "er", "so", "mein", "K\u00e4t\u00b7chen", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das K\u00e4tchen geben wir nicht her,", "tokens": ["Das", "K\u00e4t\u00b7chen", "ge\u00b7ben", "wir", "nicht", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wenn's f\u00fcr tausend Taler w\u00e4r.", "tokens": ["Und", "wenn's", "f\u00fcr", "tau\u00b7send", "Ta\u00b7ler", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "CARD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ei, Mutter, nur nicht gleich geschm\u00e4lt!", "tokens": ["Ei", ",", "Mut\u00b7ter", ",", "nur", "nicht", "gleich", "ge\u00b7schm\u00e4lt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "ADV", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den h\u00fcbschen jungen Knaben,", "tokens": ["Den", "h\u00fcb\u00b7schen", "jun\u00b7gen", "Kna\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Den will und mu\u00df ich haben;", "tokens": ["Den", "will", "und", "mu\u00df", "ich", "ha\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "KON", "VMFIN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den Krauskopf, den Krauskopf", "tokens": ["Den", "Kraus\u00b7kopf", ",", "den", "Kraus\u00b7kopf"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Hab ich mir auserw\u00e4hlt.", "tokens": ["Hab", "ich", "mir", "au\u00b7ser\u00b7w\u00e4hlt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Und willst du denn ein Br\u00e4utchen sein,", "tokens": ["Und", "willst", "du", "denn", "ein", "Br\u00e4ut\u00b7chen", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So geb ich meinen Segen drein.", "tokens": ["So", "geb", "ich", "mei\u00b7nen", "Se\u00b7gen", "drein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So manches Bl\u00fcmlein wachsen mag", "tokens": ["So", "man\u00b7ches", "Bl\u00fcm\u00b7lein", "wach\u00b7sen", "mag"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Ostern bis Michelistag,", "tokens": ["Von", "Os\u00b7tern", "bis", "Mi\u00b7che\u00b7lis\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "So manches K\u00f6rnlein, als man s\u00e4t,", "tokens": ["So", "man\u00b7ches", "K\u00f6rn\u00b7lein", ",", "als", "man", "s\u00e4t", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So mancher Halm in \u00c4hren steht,", "tokens": ["So", "man\u00b7cher", "Halm", "in", "\u00c4h\u00b7ren", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So vielmal Gutes w\u00fcnsch ich dir", "tokens": ["So", "viel\u00b7mal", "Gu\u00b7tes", "w\u00fcnsch", "ich", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "NN", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Aus meines Herzens Grund herf\u00fcr.", "tokens": ["Aus", "mei\u00b7nes", "Her\u00b7zens", "Grund", "her\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und wenn die Pfeifen klingen,", "tokens": ["Und", "wenn", "die", "Pfei\u00b7fen", "klin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dann tanzen wir und springen;", "tokens": ["Dann", "tan\u00b7zen", "wir", "und", "sprin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dann spring ich wohl und tanz ich", "tokens": ["Dann", "spring", "ich", "wohl", "und", "tanz", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Von Danzig bis nach Nanzig \u2013", "tokens": ["Von", "Dan\u00b7zig", "bis", "nach", "Nan\u00b7zig", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "APPR", "NE", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Knipp, knapp!", "tokens": ["Knipp", ",", "knapp", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Da rei\u00dft mein Faden ab!", "tokens": ["Da", "rei\u00dft", "mein", "Fa\u00b7den", "ab", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Surre, surre, surre!", "tokens": ["Sur\u00b7re", ",", "sur\u00b7re", ",", "sur\u00b7re", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mein gutes R\u00e4dchen schnurre!", "tokens": ["Mein", "gu\u00b7tes", "R\u00e4d\u00b7chen", "schnur\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "F\u00fcr unser kleines K\u00e4tchen", "tokens": ["F\u00fcr", "un\u00b7ser", "klei\u00b7nes", "K\u00e4t\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dreh mir ein feines F\u00e4dchen,", "tokens": ["Dreh", "mir", "ein", "fei\u00b7nes", "F\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So lang von hier bis K\u00f6llen", "tokens": ["So", "lang", "von", "hier", "bis", "K\u00f6l\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wohl mehr als tausend Ellen.", "tokens": ["Wohl", "mehr", "als", "tau\u00b7send", "El\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "KOKOM", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wir wollen es winden", "tokens": ["Wir", "wol\u00b7len", "es", "win\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Und Docken von binden,", "tokens": ["Und", "Do\u00b7cken", "von", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.9": {"line.1": {"text": "Meister Weber es geben,", "tokens": ["Meis\u00b7ter", "We\u00b7ber", "es", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPER", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Soll Leinen uns weben,", "tokens": ["Soll", "Lei\u00b7nen", "uns", "we\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "PPER", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Das breiten wir beide", "tokens": ["Das", "brei\u00b7ten", "wir", "bei\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "PPER", "PIS"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Auf blumige Heide,", "tokens": ["Auf", "blu\u00b7mi\u00b7ge", "Hei\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Auf Anger und Wiesen", "tokens": ["Auf", "An\u00b7ger", "und", "Wie\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Und wollen es sonnen,", "tokens": ["Und", "wol\u00b7len", "es", "son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Benetzen und gie\u00dfen", "tokens": ["Be\u00b7net\u00b7zen", "und", "gie\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Aus B\u00e4chen und Bronnen.", "tokens": ["Aus", "B\u00e4\u00b7chen", "und", "Bron\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.10": {"line.1": {"text": "Ach, komm du lieber Sonnenschein", "tokens": ["Ach", ",", "komm", "du", "lie\u00b7ber", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bleiche unser Leinen rein.", "tokens": ["Und", "blei\u00b7che", "un\u00b7ser", "Lei\u00b7nen", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann kriegt mein Herzenst\u00e4ubchen", "tokens": ["Dann", "kriegt", "mein", "Her\u00b7zen\u00b7st\u00e4ub\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wohl manch ein feines Hemd", "tokens": ["Wohl", "manch", "ein", "fei\u00b7nes", "Hemd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und T\u00fcchlein oder H\u00e4ubchen,", "tokens": ["Und", "T\u00fcch\u00b7lein", "o\u00b7der", "H\u00e4ub\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Bis da\u00df der Freier k\u00f6mmt.", "tokens": ["Bis", "da\u00df", "der", "Frei\u00b7er", "k\u00f6mmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Sch\u00f6n guten Tag, Herr Freiersmann!", "tokens": ["Sch\u00f6n", "gu\u00b7ten", "Tag", ",", "Herr", "Frei\u00b7ers\u00b7mann", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was schaut er so mein K\u00e4tchen an?", "tokens": ["Was", "schaut", "er", "so", "mein", "K\u00e4t\u00b7chen", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das K\u00e4tchen geben wir nicht her,", "tokens": ["Das", "K\u00e4t\u00b7chen", "ge\u00b7ben", "wir", "nicht", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wenn's f\u00fcr tausend Taler w\u00e4r.", "tokens": ["Und", "wenn's", "f\u00fcr", "tau\u00b7send", "Ta\u00b7ler", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "CARD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ei, Mutter, nur nicht gleich geschm\u00e4lt!", "tokens": ["Ei", ",", "Mut\u00b7ter", ",", "nur", "nicht", "gleich", "ge\u00b7schm\u00e4lt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "ADV", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den h\u00fcbschen jungen Knaben,", "tokens": ["Den", "h\u00fcb\u00b7schen", "jun\u00b7gen", "Kna\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Den will und mu\u00df ich haben;", "tokens": ["Den", "will", "und", "mu\u00df", "ich", "ha\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "KON", "VMFIN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den Krauskopf, den Krauskopf", "tokens": ["Den", "Kraus\u00b7kopf", ",", "den", "Kraus\u00b7kopf"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Hab ich mir auserw\u00e4hlt.", "tokens": ["Hab", "ich", "mir", "au\u00b7ser\u00b7w\u00e4hlt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Und willst du denn ein Br\u00e4utchen sein,", "tokens": ["Und", "willst", "du", "denn", "ein", "Br\u00e4ut\u00b7chen", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So geb ich meinen Segen drein.", "tokens": ["So", "geb", "ich", "mei\u00b7nen", "Se\u00b7gen", "drein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So manches Bl\u00fcmlein wachsen mag", "tokens": ["So", "man\u00b7ches", "Bl\u00fcm\u00b7lein", "wach\u00b7sen", "mag"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Ostern bis Michelistag,", "tokens": ["Von", "Os\u00b7tern", "bis", "Mi\u00b7che\u00b7lis\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "So manches K\u00f6rnlein, als man s\u00e4t,", "tokens": ["So", "man\u00b7ches", "K\u00f6rn\u00b7lein", ",", "als", "man", "s\u00e4t", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So mancher Halm in \u00c4hren steht,", "tokens": ["So", "man\u00b7cher", "Halm", "in", "\u00c4h\u00b7ren", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So vielmal Gutes w\u00fcnsch ich dir", "tokens": ["So", "viel\u00b7mal", "Gu\u00b7tes", "w\u00fcnsch", "ich", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "NN", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Aus meines Herzens Grund herf\u00fcr.", "tokens": ["Aus", "mei\u00b7nes", "Her\u00b7zens", "Grund", "her\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Und wenn die Pfeifen klingen,", "tokens": ["Und", "wenn", "die", "Pfei\u00b7fen", "klin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dann tanzen wir und springen;", "tokens": ["Dann", "tan\u00b7zen", "wir", "und", "sprin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dann spring ich wohl und tanz ich", "tokens": ["Dann", "spring", "ich", "wohl", "und", "tanz", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Von Danzig bis nach Nanzig \u2013", "tokens": ["Von", "Dan\u00b7zig", "bis", "nach", "Nan\u00b7zig", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "APPR", "NE", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Knipp, knapp!", "tokens": ["Knipp", ",", "knapp", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Da rei\u00dft mein Faden ab!", "tokens": ["Da", "rei\u00dft", "mein", "Fa\u00b7den", "ab", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}