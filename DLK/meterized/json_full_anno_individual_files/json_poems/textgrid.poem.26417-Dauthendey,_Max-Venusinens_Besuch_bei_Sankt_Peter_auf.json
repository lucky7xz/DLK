{"textgrid.poem.26417": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "Venusinens Besuch bei Sankt Peter auf", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mit dem Zw\u00f6lfuhrschusse,", "tokens": ["Mit", "dem", "Zw\u00f6l\u00b7fuhr\u00b7schus\u00b7se", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Bei dem sch\u00f6nsten Wetter,", "tokens": ["Bei", "dem", "sch\u00f6ns\u00b7ten", "Wet\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trat die Venusine", "tokens": ["Trat", "die", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ein bei dem Sankt Peter.", "tokens": ["Ein", "bei", "dem", "Sankt", "Pe\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "VVFIN", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Herrlich sind die Hallen,", "tokens": ["Herr\u00b7lich", "sind", "die", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und der schlimmsten Heidin", "tokens": ["Und", "der", "schlimms\u00b7ten", "Hei\u00b7din"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mu\u00dften sie gefallen.", "tokens": ["Mu\u00df\u00b7ten", "sie", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Manche Marmorflie\u00dfe,", "tokens": ["Man\u00b7che", "Mar\u00b7mor\u00b7flie\u00b7\u00dfe", ","], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Manche von den S\u00e4ulen", "tokens": ["Man\u00b7che", "von", "den", "S\u00e4u\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kannte Venus wieder", "tokens": ["Kann\u00b7te", "Ve\u00b7nus", "wie\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "NN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und verbi\u00df das Heulen.", "tokens": ["Und", "ver\u00b7bi\u00df", "das", "Heu\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Vieles, was da schm\u00fcckte,", "tokens": ["Vie\u00b7les", ",", "was", "da", "schm\u00fcck\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kam von alten Tempeln,", "tokens": ["Kam", "von", "al\u00b7ten", "Tem\u00b7peln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wo man ihr sich b\u00fcckte.", "tokens": ["Wo", "man", "ihr", "sich", "b\u00fcck\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbm\u00f6cht' heut keinen Tempel.\u00ab", "tokens": ["\u00bb", "m\u00f6cht'", "heut", "kei\u00b7nen", "Tem\u00b7pel", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "ADV", "PIAT", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Menschen, wenn auch beten,", "tokens": ["Men\u00b7schen", ",", "wenn", "auch", "be\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Gutes und auch B\u00f6ses", "tokens": ["Gu\u00b7tes", "und", "auch", "B\u00f6\u00b7ses"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sie doch immer t\u00e4ten.", "tokens": ["Sie", "doch", "im\u00b7mer", "t\u00e4\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Aber sch\u00f6ne Hallen,", "tokens": ["A\u00b7ber", "sch\u00f6\u00b7ne", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo man sich erg\u00f6tzet,", "tokens": ["Wo", "man", "sich", "er\u00b7g\u00f6t\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PRF", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Das t\u00e4t mir gefallen!", "tokens": ["Das", "t\u00e4t", "mir", "ge\u00b7fal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.7": {"line.1": {"text": "\u00bbguten Morgen Peter!\u00ab", "tokens": ["\u00bb", "gu\u00b7ten", "Mor\u00b7gen", "Pe\u00b7ter", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "NE", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Zu dem Bronzebilde", "tokens": ["Zu", "dem", "Bron\u00b7ze\u00b7bil\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nickte Venusine.", "tokens": ["Nick\u00b7te", "Ve\u00b7nu\u00b7si\u00b7ne", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Peter dankte milde,", "tokens": ["Pe\u00b7ter", "dank\u00b7te", "mil\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Bat sie Platz zu nehmen", "tokens": ["Bat", "sie", "Platz", "zu", "neh\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Neben ihm im Stuhle,", "tokens": ["Ne\u00b7ben", "ihm", "im", "Stuh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auf dem Unbequemen.", "tokens": ["Auf", "dem", "Un\u00b7be\u00b7que\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "\u00bbsitz hier schon zu lange,\u00ab", "tokens": ["\u00bb", "sitz", "hier", "schon", "zu", "lan\u00b7ge", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "ADV", "ADV", "PTKA", "ADV", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprach der alte Peter;", "tokens": ["Sprach", "der", "al\u00b7te", "Pe\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sprach gleich von Gesch\u00e4ften", "tokens": ["Sprach", "gleich", "von", "Ge\u00b7sch\u00e4f\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Und nicht erst vom Wetter.", "tokens": ["Und", "nicht", "erst", "vom", "Wet\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "APPRART", "NN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.10": {"line.1": {"text": "\u00bbkeiner will mehr glauben,", "tokens": ["\u00bb", "kei\u00b7ner", "will", "mehr", "glau\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nicht an H\u00f6ll' und Himmel,", "tokens": ["Nicht", "an", "H\u00f6ll'", "und", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zeit tut's jedem rauben.", "tokens": ["Zeit", "tut's", "je\u00b7dem", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Sag mir Venusine:", "tokens": ["Sag", "mir", "Ve\u00b7nu\u00b7si\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hast Dich nicht ver\u00e4ndert!", "tokens": ["Hast", "Dich", "nicht", "ver\u00b7\u00e4n\u00b7dert", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auch die Augenlider", "tokens": ["Auch", "die", "Au\u00b7gen\u00b7li\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sind wie stets ber\u00e4ndert.", "tokens": ["Sind", "wie", "stets", "be\u00b7r\u00e4n\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Hast Du wen gefunden,", "tokens": ["Hast", "Du", "wen", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIS", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Der in Rom Dich liebte,", "tokens": ["Der", "in", "Rom", "Dich", "lieb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wenn auch nur f\u00fcr Stunden?\u00ab", "tokens": ["Wenn", "auch", "nur", "f\u00fcr", "Stun\u00b7den", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "ADV", "APPR", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Venusin err\u00f6tet:", "tokens": ["Ve\u00b7nu\u00b7sin", "er\u00b7r\u00f6\u00b7tet", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bblieber Indiskreter,", "tokens": ["\u00bb", "lie\u00b7ber", "In\u00b7dis\u00b7kre\u00b7ter", ","], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "ADV", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alles mu\u00dft Du wissen,", "tokens": ["Al\u00b7les", "mu\u00dft", "Du", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Beichten soll ich Peter?", "tokens": ["Beich\u00b7ten", "soll", "ich", "Pe\u00b7ter", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Selten fand ich Leute,", "tokens": ["Sel\u00b7ten", "fand", "ich", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die ich lieber k\u00fc\u00dfte,", "tokens": ["Die", "ich", "lie\u00b7ber", "k\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Als den Teufel heute.\u00ab", "tokens": ["Als", "den", "Teu\u00b7fel", "heu\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "\u00bbweit soll nicht der Himmel", "tokens": ["\u00bb", "weit", "soll", "nicht", "der", "Him\u00b7mel"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "VMFIN", "PTKNEG", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Von der H\u00f6lle liegen!", "tokens": ["Von", "der", "H\u00f6l\u00b7le", "lie\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Darum, Venusine,", "tokens": ["Da\u00b7rum", ",", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["PAV", "$,", "NE", "$,"], "meter": "-+----", "measure": "dactylic.init"}, "line.4": {"text": "Sollst 'nen Ku\u00df Du kriegen.", "tokens": ["Sollst", "'nen", "Ku\u00df", "Du", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Darf ich mir erlauben?\u00ab", "tokens": ["Darf", "ich", "mir", "er\u00b7lau\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Eh' noch Venus h\u00f6rte,", "tokens": ["Eh'", "noch", "Ve\u00b7nus", "h\u00f6r\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Tat Sankt Peter rauben.", "tokens": ["Tat", "Sankt", "Pe\u00b7ter", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NE", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "Venus lacht und plaudert:", "tokens": ["Ve\u00b7nus", "lacht", "und", "plau\u00b7dert", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbwas ich fragen wollte:", "tokens": ["\u00bb", "was", "ich", "fra\u00b7gen", "woll\u00b7te", ":"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wie geht's Magdalena,", "tokens": ["Wie", "geht's", "Mag\u00b7da\u00b7le\u00b7na", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die bereuen sollte?", "tokens": ["Die", "be\u00b7reu\u00b7en", "soll\u00b7te", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.18": {"line.1": {"text": "Immer wollt ich wissen:", "tokens": ["Im\u00b7mer", "wollt", "ich", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tat sie Deinen Herren", "tokens": ["Tat", "sie", "Dei\u00b7nen", "Her\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Damals niemals k\u00fcssen?\u00ab", "tokens": ["Da\u00b7mals", "nie\u00b7mals", "k\u00fcs\u00b7sen", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "\u00bbgeh, schw\u00e4tz nicht Nusine,", "tokens": ["\u00bb", "geh", ",", "schw\u00e4tz", "nicht", "Nu\u00b7si\u00b7ne", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "VVFIN", "PTKNEG", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lene wollt' schon gerne.", "tokens": ["Le\u00b7ne", "wollt'", "schon", "ger\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADV", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Doch der Herr, verstehe,", "tokens": ["Doch", "der", "Herr", ",", "ver\u00b7ste\u00b7he", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Hielt sich Weiber ferne.\u00ab", "tokens": ["Hielt", "sich", "Wei\u00b7ber", "fer\u00b7ne", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PRF", "NN", "ADJA", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "\u00bbdoch\u00ab, rief Venusine", "tokens": ["\u00bb", "doch", "\u00ab", ",", "rief", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["punct", "word", "punct", "punct", "word", "word"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "NE"], "meter": "-+----", "measure": "dactylic.init"}, "line.2": {"text": "\u00bblazarusens Schwester", "tokens": ["\u00bb", "la\u00b7za\u00b7ru\u00b7sens", "Schwes\u00b7ter"], "token_info": ["punct", "word", "word"], "pos": ["$(", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hegte f\u00fcr ihn Minne!", "tokens": ["Heg\u00b7te", "f\u00fcr", "ihn", "Min\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "K\u00fc\u00dft' er nie Maria,", "tokens": ["K\u00fc\u00dft'", "er", "nie", "Ma\u00b7ria", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NE", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Die kein Kochtopf qu\u00e4lte,", "tokens": ["Die", "kein", "Koch\u00b7topf", "qu\u00e4l\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und von beiden Schwestern", "tokens": ["Und", "von", "bei\u00b7den", "Schwes\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "S' beste sagt man, w\u00e4hlte?", "tokens": ["S'", "bes\u00b7te", "sagt", "man", ",", "w\u00e4hl\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADJA", "VVFIN", "PIS", "$,", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Wenn sie ", "tokens": ["Wenn", "sie"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Wo wohl dann das ", "tokens": ["Wo", "wohl", "dann", "das"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Sie da finden m\u00fc\u00dfte?", "tokens": ["Sie", "da", "fin\u00b7den", "m\u00fc\u00df\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.23": {"line.1": {"text": "Und Pilatus' Gattin?", "tokens": ["Und", "Pi\u00b7la\u00b7tus'", "Gat\u00b7tin", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Nachts sie von ihm tr\u00e4umte.", "tokens": ["Nachts", "sie", "von", "ihm", "tr\u00e4um\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wenn er ", "tokens": ["Wenn", "er"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.24": {"line.1": {"text": "Hat ans Kreuz er m\u00fcssen,", "tokens": ["Hat", "ans", "Kreuz", "er", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "PPER", "VMFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Weil er niemals liebte", "tokens": ["Weil", "er", "nie\u00b7mals", "lieb\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und kein Weib wollt' k\u00fcssen?\u00ab", "tokens": ["Und", "kein", "Weib", "wollt'", "k\u00fcs\u00b7sen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIAT", "NN", "VMFIN", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.25": {"line.1": {"text": "\u00bbdu fragst wie die Heiden,", "tokens": ["\u00bb", "du", "fragst", "wie", "die", "Hei\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Nur ich Dich verstehe,", "tokens": ["Nur", "ich", "Dich", "ver\u00b7ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "War ja selbst mal Einer.\u00ab", "tokens": ["War", "ja", "selbst", "mal", "Ei\u00b7ner", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "PIS", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.26": {"line.1": {"text": "Also plaudert Peter.", "tokens": ["Al\u00b7so", "plau\u00b7dert", "Pe\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lenkt dann das Gespr\u00e4che", "tokens": ["Lenkt", "dann", "das", "Ge\u00b7spr\u00e4\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Endlich jetzt aufs Wetter.", "tokens": ["End\u00b7lich", "jetzt", "aufs", "Wet\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.27": {"line.1": {"text": "\u00bbwar der Himmel freundlich", "tokens": ["\u00bb", "war", "der", "Him\u00b7mel", "freund\u00b7lich"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "ART", "NN", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Auf der Hierherreise?", "tokens": ["Auf", "der", "Hier\u00b7her\u00b7rei\u00b7se", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kamst du mit dem Auto", "tokens": ["Kamst", "du", "mit", "dem", "Au\u00b7to"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Oder D-Zugsweise?", "tokens": ["O\u00b7der", "D\u00b7\u00b7Zugs\u00b7wei\u00b7se", "?"], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.28": {"line.1": {"text": "Sag, wie ist das, sage:", "tokens": ["Sag", ",", "wie", "ist", "das", ",", "sa\u00b7ge", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VAFIN", "PDS", "$,", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schlafen nie die Bahnen?", "tokens": ["Schla\u00b7fen", "nie", "die", "Bah\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "F\u00e4hrt man Nacht und Tage?", "tokens": ["F\u00e4hrt", "man", "Nacht", "und", "Ta\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.29": {"line.1": {"text": "Und noch Eines h\u00f6re:", "tokens": ["Und", "noch", "Ei\u00b7nes", "h\u00f6\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIS", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wei\u00dft Du, die Sibylle,", "tokens": ["Wei\u00dft", "Du", ",", "die", "Si\u00b7byl\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "$,"], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Die einst einem Kaiser", "tokens": ["Die", "einst", "ei\u00b7nem", "Kai\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Heimlich und in Stille", "tokens": ["Heim\u00b7lich", "und", "in", "Stil\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.30": {"line.1": {"text": "Ferne Zukunft sagte,", "tokens": ["Fer\u00b7ne", "Zu\u00b7kunft", "sag\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Diese Zeit wie heute", "tokens": ["Die\u00b7se", "Zeit", "wie", "heu\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "KOKOM", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ihm zu schildern wagte,", "tokens": ["Ihm", "zu", "schil\u00b7dern", "wag\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.31": {"line.1": {"text": "Meinte: wenn die Menschen", "tokens": ["Mein\u00b7te", ":", "wenn", "die", "Men\u00b7schen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$.", "KOUS", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "In die Ferne sprechen,", "tokens": ["In", "die", "Fer\u00b7ne", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Durch die gro\u00dfen Alpen", "tokens": ["Durch", "die", "gro\u00b7\u00dfen", "Al\u00b7pen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+---", "measure": "unknown.measure.di"}, "line.4": {"text": "Gro\u00dfe L\u00f6cher brechen,", "tokens": ["Gro\u00b7\u00dfe", "L\u00f6\u00b7cher", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.32": {"line.1": {"text": "Und dann auf der Erde", "tokens": ["Und", "dann", "auf", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wagen einfach laufen,", "tokens": ["Wa\u00b7gen", "ein\u00b7fach", "lau\u00b7fen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wagen ohne Pferde, \u2013", "tokens": ["Wa\u00b7gen", "oh\u00b7ne", "Pfer\u00b7de", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.33": {"line.1": {"text": "Dann kehrt auch die Wollust", "tokens": ["Dann", "kehrt", "auch", "die", "Wol\u00b7lust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Zum Olympe wieder,", "tokens": ["Zum", "O\u00b7lym\u00b7pe", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und die Kreuze fallen", "tokens": ["Und", "die", "Kreu\u00b7ze", "fal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Von den Kirchen nieder.", "tokens": ["Von", "den", "Kir\u00b7chen", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.34": {"line.1": {"text": "Sag mir\u00ab, zittert Peter,", "tokens": ["Sag", "mir", "\u00ab", ",", "zit\u00b7tert", "Pe\u00b7ter", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "$(", "$,", "VVFIN", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbstehen so die Dinge?", "tokens": ["\u00bb", "ste\u00b7hen", "so", "die", "Din\u00b7ge", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ist es solches Wetter?\u00ab \u2013", "tokens": ["Ist", "es", "sol\u00b7ches", "Wet\u00b7ter", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "$.", "$(", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.35": {"line.1": {"text": "Venusin nicht gerne", "tokens": ["Ve\u00b7nu\u00b7sin", "nicht", "ger\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["NE", "PTKNEG", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Greise bange machte,", "tokens": ["Grei\u00b7se", "ban\u00b7ge", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sprang vom Stuhl herunter,", "tokens": ["Sprang", "vom", "Stuhl", "her\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Guckt' hinauf und lachte.", "tokens": ["Guckt'", "hin\u00b7auf", "und", "lach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "KON", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.36": {"line.1": {"text": "Rief: \u00bbIch m\u00f6cht vergehen!", "tokens": ["Rief", ":", "\u00bb", "Ich", "m\u00f6cht", "ver\u00b7ge\u00b7hen", "!"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Find's so furchtbar komisch,", "tokens": ["Fin\u00b7d's", "so", "furcht\u00b7bar", "ko\u00b7misch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "K\u00fc\u00dft man Deine Zehen!", "tokens": ["K\u00fc\u00dft", "man", "Dei\u00b7ne", "Ze\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.37": {"line.1": {"text": "Kam da just ein M\u00f6nchherr,", "tokens": ["Kam", "da", "just", "ein", "M\u00f6nch\u00b7herr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sah uns beide plaudern,", "tokens": ["Sah", "uns", "bei\u00b7de", "plau\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ist zum Papst gelaufen,", "tokens": ["Ist", "zum", "Papst", "ge\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sagt's ihm unter Schaudern.", "tokens": ["Sagt's", "ihm", "un\u00b7ter", "Schau\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.38": {"line.1": {"text": "Darum will ich gehen,", "tokens": ["Da\u00b7rum", "will", "ich", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Will Dich nicht blamieren.", "tokens": ["Will", "Dich", "nicht", "bla\u00b7mie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Peter, Wiedersehen!\u00ab", "tokens": ["Pe\u00b7ter", ",", "Wie\u00b7der\u00b7se\u00b7hen", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "punct"], "pos": ["NE", "$,", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.39": {"line.1": {"text": "Venus wirft 'ne Ku\u00dfhand,", "tokens": ["Ve\u00b7nus", "wirft", "'ne", "Ku\u00df\u00b7hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lief zur Ledert\u00fcre;", "tokens": ["Lief", "zur", "Le\u00b7der\u00b7t\u00fc\u00b7re", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Dankte laut im Freien,", "tokens": ["Dank\u00b7te", "laut", "im", "Frei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df sie Freiluft sp\u00fcre.", "tokens": ["Da\u00df", "sie", "Frei\u00b7luft", "sp\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.40": {"line.1": {"text": "Sprang mit einem Satze", "tokens": ["Sprang", "mit", "ei\u00b7nem", "Sat\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tief in die Font\u00e4ne", "tokens": ["Tief", "in", "die", "Fon\u00b7t\u00e4\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN"], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Auf dem Petersplatze.", "tokens": ["Auf", "dem", "Pe\u00b7ter\u00b7splat\u00b7ze", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.41": {"line.1": {"text": "Mit dem Zw\u00f6lfuhrschusse,", "tokens": ["Mit", "dem", "Zw\u00f6l\u00b7fuhr\u00b7schus\u00b7se", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Bei dem sch\u00f6nsten Wetter,", "tokens": ["Bei", "dem", "sch\u00f6ns\u00b7ten", "Wet\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trat die Venusine", "tokens": ["Trat", "die", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ein bei dem Sankt Peter.", "tokens": ["Ein", "bei", "dem", "Sankt", "Pe\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "VVFIN", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.42": {"line.1": {"text": "Herrlich sind die Hallen,", "tokens": ["Herr\u00b7lich", "sind", "die", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und der schlimmsten Heidin", "tokens": ["Und", "der", "schlimms\u00b7ten", "Hei\u00b7din"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mu\u00dften sie gefallen.", "tokens": ["Mu\u00df\u00b7ten", "sie", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.43": {"line.1": {"text": "Manche Marmorflie\u00dfe,", "tokens": ["Man\u00b7che", "Mar\u00b7mor\u00b7flie\u00b7\u00dfe", ","], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Manche von den S\u00e4ulen", "tokens": ["Man\u00b7che", "von", "den", "S\u00e4u\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kannte Venus wieder", "tokens": ["Kann\u00b7te", "Ve\u00b7nus", "wie\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "NN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und verbi\u00df das Heulen.", "tokens": ["Und", "ver\u00b7bi\u00df", "das", "Heu\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.44": {"line.1": {"text": "Vieles, was da schm\u00fcckte,", "tokens": ["Vie\u00b7les", ",", "was", "da", "schm\u00fcck\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kam von alten Tempeln,", "tokens": ["Kam", "von", "al\u00b7ten", "Tem\u00b7peln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wo man ihr sich b\u00fcckte.", "tokens": ["Wo", "man", "ihr", "sich", "b\u00fcck\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.45": {"line.1": {"text": "\u00bbm\u00f6cht' heut keinen Tempel.\u00ab", "tokens": ["\u00bb", "m\u00f6cht'", "heut", "kei\u00b7nen", "Tem\u00b7pel", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "ADV", "PIAT", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Menschen, wenn auch beten,", "tokens": ["Men\u00b7schen", ",", "wenn", "auch", "be\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Gutes und auch B\u00f6ses", "tokens": ["Gu\u00b7tes", "und", "auch", "B\u00f6\u00b7ses"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sie doch immer t\u00e4ten.", "tokens": ["Sie", "doch", "im\u00b7mer", "t\u00e4\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.46": {"line.1": {"text": "Aber sch\u00f6ne Hallen,", "tokens": ["A\u00b7ber", "sch\u00f6\u00b7ne", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo man sich erg\u00f6tzet,", "tokens": ["Wo", "man", "sich", "er\u00b7g\u00f6t\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PRF", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Das t\u00e4t mir gefallen!", "tokens": ["Das", "t\u00e4t", "mir", "ge\u00b7fal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.47": {"line.1": {"text": "\u00bbguten Morgen Peter!\u00ab", "tokens": ["\u00bb", "gu\u00b7ten", "Mor\u00b7gen", "Pe\u00b7ter", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "NE", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Zu dem Bronzebilde", "tokens": ["Zu", "dem", "Bron\u00b7ze\u00b7bil\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nickte Venusine.", "tokens": ["Nick\u00b7te", "Ve\u00b7nu\u00b7si\u00b7ne", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Peter dankte milde,", "tokens": ["Pe\u00b7ter", "dank\u00b7te", "mil\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.48": {"line.1": {"text": "Bat sie Platz zu nehmen", "tokens": ["Bat", "sie", "Platz", "zu", "neh\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Neben ihm im Stuhle,", "tokens": ["Ne\u00b7ben", "ihm", "im", "Stuh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auf dem Unbequemen.", "tokens": ["Auf", "dem", "Un\u00b7be\u00b7que\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.49": {"line.1": {"text": "\u00bbsitz hier schon zu lange,\u00ab", "tokens": ["\u00bb", "sitz", "hier", "schon", "zu", "lan\u00b7ge", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "ADV", "ADV", "PTKA", "ADV", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprach der alte Peter;", "tokens": ["Sprach", "der", "al\u00b7te", "Pe\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sprach gleich von Gesch\u00e4ften", "tokens": ["Sprach", "gleich", "von", "Ge\u00b7sch\u00e4f\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Und nicht erst vom Wetter.", "tokens": ["Und", "nicht", "erst", "vom", "Wet\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "APPRART", "NN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.50": {"line.1": {"text": "\u00bbkeiner will mehr glauben,", "tokens": ["\u00bb", "kei\u00b7ner", "will", "mehr", "glau\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nicht an H\u00f6ll' und Himmel,", "tokens": ["Nicht", "an", "H\u00f6ll'", "und", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zeit tut's jedem rauben.", "tokens": ["Zeit", "tut's", "je\u00b7dem", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.51": {"line.1": {"text": "Sag mir Venusine:", "tokens": ["Sag", "mir", "Ve\u00b7nu\u00b7si\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hast Dich nicht ver\u00e4ndert!", "tokens": ["Hast", "Dich", "nicht", "ver\u00b7\u00e4n\u00b7dert", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auch die Augenlider", "tokens": ["Auch", "die", "Au\u00b7gen\u00b7li\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sind wie stets ber\u00e4ndert.", "tokens": ["Sind", "wie", "stets", "be\u00b7r\u00e4n\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.52": {"line.1": {"text": "Hast Du wen gefunden,", "tokens": ["Hast", "Du", "wen", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIS", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Der in Rom Dich liebte,", "tokens": ["Der", "in", "Rom", "Dich", "lieb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wenn auch nur f\u00fcr Stunden?\u00ab", "tokens": ["Wenn", "auch", "nur", "f\u00fcr", "Stun\u00b7den", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "ADV", "APPR", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.53": {"line.1": {"text": "Venusin err\u00f6tet:", "tokens": ["Ve\u00b7nu\u00b7sin", "er\u00b7r\u00f6\u00b7tet", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bblieber Indiskreter,", "tokens": ["\u00bb", "lie\u00b7ber", "In\u00b7dis\u00b7kre\u00b7ter", ","], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "ADV", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alles mu\u00dft Du wissen,", "tokens": ["Al\u00b7les", "mu\u00dft", "Du", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Beichten soll ich Peter?", "tokens": ["Beich\u00b7ten", "soll", "ich", "Pe\u00b7ter", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.54": {"line.1": {"text": "Selten fand ich Leute,", "tokens": ["Sel\u00b7ten", "fand", "ich", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die ich lieber k\u00fc\u00dfte,", "tokens": ["Die", "ich", "lie\u00b7ber", "k\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Als den Teufel heute.\u00ab", "tokens": ["Als", "den", "Teu\u00b7fel", "heu\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.55": {"line.1": {"text": "\u00bbweit soll nicht der Himmel", "tokens": ["\u00bb", "weit", "soll", "nicht", "der", "Him\u00b7mel"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "VMFIN", "PTKNEG", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Von der H\u00f6lle liegen!", "tokens": ["Von", "der", "H\u00f6l\u00b7le", "lie\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Darum, Venusine,", "tokens": ["Da\u00b7rum", ",", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["PAV", "$,", "NE", "$,"], "meter": "-+----", "measure": "dactylic.init"}, "line.4": {"text": "Sollst 'nen Ku\u00df Du kriegen.", "tokens": ["Sollst", "'nen", "Ku\u00df", "Du", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.56": {"line.1": {"text": "Darf ich mir erlauben?\u00ab", "tokens": ["Darf", "ich", "mir", "er\u00b7lau\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Eh' noch Venus h\u00f6rte,", "tokens": ["Eh'", "noch", "Ve\u00b7nus", "h\u00f6r\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Tat Sankt Peter rauben.", "tokens": ["Tat", "Sankt", "Pe\u00b7ter", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NE", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.57": {"line.1": {"text": "Venus lacht und plaudert:", "tokens": ["Ve\u00b7nus", "lacht", "und", "plau\u00b7dert", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbwas ich fragen wollte:", "tokens": ["\u00bb", "was", "ich", "fra\u00b7gen", "woll\u00b7te", ":"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wie geht's Magdalena,", "tokens": ["Wie", "geht's", "Mag\u00b7da\u00b7le\u00b7na", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die bereuen sollte?", "tokens": ["Die", "be\u00b7reu\u00b7en", "soll\u00b7te", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.58": {"line.1": {"text": "Immer wollt ich wissen:", "tokens": ["Im\u00b7mer", "wollt", "ich", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tat sie Deinen Herren", "tokens": ["Tat", "sie", "Dei\u00b7nen", "Her\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Damals niemals k\u00fcssen?\u00ab", "tokens": ["Da\u00b7mals", "nie\u00b7mals", "k\u00fcs\u00b7sen", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.59": {"line.1": {"text": "\u00bbgeh, schw\u00e4tz nicht Nusine,", "tokens": ["\u00bb", "geh", ",", "schw\u00e4tz", "nicht", "Nu\u00b7si\u00b7ne", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "VVFIN", "PTKNEG", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lene wollt' schon gerne.", "tokens": ["Le\u00b7ne", "wollt'", "schon", "ger\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADV", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Doch der Herr, verstehe,", "tokens": ["Doch", "der", "Herr", ",", "ver\u00b7ste\u00b7he", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Hielt sich Weiber ferne.\u00ab", "tokens": ["Hielt", "sich", "Wei\u00b7ber", "fer\u00b7ne", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PRF", "NN", "ADJA", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.60": {"line.1": {"text": "\u00bbdoch\u00ab, rief Venusine", "tokens": ["\u00bb", "doch", "\u00ab", ",", "rief", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["punct", "word", "punct", "punct", "word", "word"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "NE"], "meter": "-+----", "measure": "dactylic.init"}, "line.2": {"text": "\u00bblazarusens Schwester", "tokens": ["\u00bb", "la\u00b7za\u00b7ru\u00b7sens", "Schwes\u00b7ter"], "token_info": ["punct", "word", "word"], "pos": ["$(", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hegte f\u00fcr ihn Minne!", "tokens": ["Heg\u00b7te", "f\u00fcr", "ihn", "Min\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.61": {"line.1": {"text": "K\u00fc\u00dft' er nie Maria,", "tokens": ["K\u00fc\u00dft'", "er", "nie", "Ma\u00b7ria", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NE", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Die kein Kochtopf qu\u00e4lte,", "tokens": ["Die", "kein", "Koch\u00b7topf", "qu\u00e4l\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und von beiden Schwestern", "tokens": ["Und", "von", "bei\u00b7den", "Schwes\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "S' beste sagt man, w\u00e4hlte?", "tokens": ["S'", "bes\u00b7te", "sagt", "man", ",", "w\u00e4hl\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADJA", "VVFIN", "PIS", "$,", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.62": {"line.1": {"text": "Wenn sie ", "tokens": ["Wenn", "sie"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Wo wohl dann das ", "tokens": ["Wo", "wohl", "dann", "das"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Sie da finden m\u00fc\u00dfte?", "tokens": ["Sie", "da", "fin\u00b7den", "m\u00fc\u00df\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.63": {"line.1": {"text": "Und Pilatus' Gattin?", "tokens": ["Und", "Pi\u00b7la\u00b7tus'", "Gat\u00b7tin", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Nachts sie von ihm tr\u00e4umte.", "tokens": ["Nachts", "sie", "von", "ihm", "tr\u00e4um\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wenn er ", "tokens": ["Wenn", "er"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.64": {"line.1": {"text": "Hat ans Kreuz er m\u00fcssen,", "tokens": ["Hat", "ans", "Kreuz", "er", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "PPER", "VMFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Weil er niemals liebte", "tokens": ["Weil", "er", "nie\u00b7mals", "lieb\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und kein Weib wollt' k\u00fcssen?\u00ab", "tokens": ["Und", "kein", "Weib", "wollt'", "k\u00fcs\u00b7sen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIAT", "NN", "VMFIN", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.65": {"line.1": {"text": "\u00bbdu fragst wie die Heiden,", "tokens": ["\u00bb", "du", "fragst", "wie", "die", "Hei\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Nur ich Dich verstehe,", "tokens": ["Nur", "ich", "Dich", "ver\u00b7ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "War ja selbst mal Einer.\u00ab", "tokens": ["War", "ja", "selbst", "mal", "Ei\u00b7ner", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "PIS", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.66": {"line.1": {"text": "Also plaudert Peter.", "tokens": ["Al\u00b7so", "plau\u00b7dert", "Pe\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lenkt dann das Gespr\u00e4che", "tokens": ["Lenkt", "dann", "das", "Ge\u00b7spr\u00e4\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Endlich jetzt aufs Wetter.", "tokens": ["End\u00b7lich", "jetzt", "aufs", "Wet\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.67": {"line.1": {"text": "\u00bbwar der Himmel freundlich", "tokens": ["\u00bb", "war", "der", "Him\u00b7mel", "freund\u00b7lich"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "ART", "NN", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Auf der Hierherreise?", "tokens": ["Auf", "der", "Hier\u00b7her\u00b7rei\u00b7se", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kamst du mit dem Auto", "tokens": ["Kamst", "du", "mit", "dem", "Au\u00b7to"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Oder D-Zugsweise?", "tokens": ["O\u00b7der", "D\u00b7\u00b7Zugs\u00b7wei\u00b7se", "?"], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.68": {"line.1": {"text": "Sag, wie ist das, sage:", "tokens": ["Sag", ",", "wie", "ist", "das", ",", "sa\u00b7ge", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VAFIN", "PDS", "$,", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schlafen nie die Bahnen?", "tokens": ["Schla\u00b7fen", "nie", "die", "Bah\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "F\u00e4hrt man Nacht und Tage?", "tokens": ["F\u00e4hrt", "man", "Nacht", "und", "Ta\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.69": {"line.1": {"text": "Und noch Eines h\u00f6re:", "tokens": ["Und", "noch", "Ei\u00b7nes", "h\u00f6\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIS", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wei\u00dft Du, die Sibylle,", "tokens": ["Wei\u00dft", "Du", ",", "die", "Si\u00b7byl\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "$,"], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Die einst einem Kaiser", "tokens": ["Die", "einst", "ei\u00b7nem", "Kai\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Heimlich und in Stille", "tokens": ["Heim\u00b7lich", "und", "in", "Stil\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.70": {"line.1": {"text": "Ferne Zukunft sagte,", "tokens": ["Fer\u00b7ne", "Zu\u00b7kunft", "sag\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Diese Zeit wie heute", "tokens": ["Die\u00b7se", "Zeit", "wie", "heu\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "KOKOM", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ihm zu schildern wagte,", "tokens": ["Ihm", "zu", "schil\u00b7dern", "wag\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.71": {"line.1": {"text": "Meinte: wenn die Menschen", "tokens": ["Mein\u00b7te", ":", "wenn", "die", "Men\u00b7schen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$.", "KOUS", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "In die Ferne sprechen,", "tokens": ["In", "die", "Fer\u00b7ne", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Durch die gro\u00dfen Alpen", "tokens": ["Durch", "die", "gro\u00b7\u00dfen", "Al\u00b7pen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+---", "measure": "unknown.measure.di"}, "line.4": {"text": "Gro\u00dfe L\u00f6cher brechen,", "tokens": ["Gro\u00b7\u00dfe", "L\u00f6\u00b7cher", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.72": {"line.1": {"text": "Und dann auf der Erde", "tokens": ["Und", "dann", "auf", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wagen einfach laufen,", "tokens": ["Wa\u00b7gen", "ein\u00b7fach", "lau\u00b7fen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wagen ohne Pferde, \u2013", "tokens": ["Wa\u00b7gen", "oh\u00b7ne", "Pfer\u00b7de", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.73": {"line.1": {"text": "Dann kehrt auch die Wollust", "tokens": ["Dann", "kehrt", "auch", "die", "Wol\u00b7lust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Zum Olympe wieder,", "tokens": ["Zum", "O\u00b7lym\u00b7pe", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und die Kreuze fallen", "tokens": ["Und", "die", "Kreu\u00b7ze", "fal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Von den Kirchen nieder.", "tokens": ["Von", "den", "Kir\u00b7chen", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.74": {"line.1": {"text": "Sag mir\u00ab, zittert Peter,", "tokens": ["Sag", "mir", "\u00ab", ",", "zit\u00b7tert", "Pe\u00b7ter", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "$(", "$,", "VVFIN", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbstehen so die Dinge?", "tokens": ["\u00bb", "ste\u00b7hen", "so", "die", "Din\u00b7ge", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ist es solches Wetter?\u00ab \u2013", "tokens": ["Ist", "es", "sol\u00b7ches", "Wet\u00b7ter", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "$.", "$(", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.75": {"line.1": {"text": "Venusin nicht gerne", "tokens": ["Ve\u00b7nu\u00b7sin", "nicht", "ger\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["NE", "PTKNEG", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Greise bange machte,", "tokens": ["Grei\u00b7se", "ban\u00b7ge", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sprang vom Stuhl herunter,", "tokens": ["Sprang", "vom", "Stuhl", "her\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Guckt' hinauf und lachte.", "tokens": ["Guckt'", "hin\u00b7auf", "und", "lach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "KON", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.76": {"line.1": {"text": "Rief: \u00bbIch m\u00f6cht vergehen!", "tokens": ["Rief", ":", "\u00bb", "Ich", "m\u00f6cht", "ver\u00b7ge\u00b7hen", "!"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Find's so furchtbar komisch,", "tokens": ["Fin\u00b7d's", "so", "furcht\u00b7bar", "ko\u00b7misch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "K\u00fc\u00dft man Deine Zehen!", "tokens": ["K\u00fc\u00dft", "man", "Dei\u00b7ne", "Ze\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.77": {"line.1": {"text": "Kam da just ein M\u00f6nchherr,", "tokens": ["Kam", "da", "just", "ein", "M\u00f6nch\u00b7herr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sah uns beide plaudern,", "tokens": ["Sah", "uns", "bei\u00b7de", "plau\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ist zum Papst gelaufen,", "tokens": ["Ist", "zum", "Papst", "ge\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sagt's ihm unter Schaudern.", "tokens": ["Sagt's", "ihm", "un\u00b7ter", "Schau\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.78": {"line.1": {"text": "Darum will ich gehen,", "tokens": ["Da\u00b7rum", "will", "ich", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Will Dich nicht blamieren.", "tokens": ["Will", "Dich", "nicht", "bla\u00b7mie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Peter, Wiedersehen!\u00ab", "tokens": ["Pe\u00b7ter", ",", "Wie\u00b7der\u00b7se\u00b7hen", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "punct"], "pos": ["NE", "$,", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.79": {"line.1": {"text": "Venus wirft 'ne Ku\u00dfhand,", "tokens": ["Ve\u00b7nus", "wirft", "'ne", "Ku\u00df\u00b7hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lief zur Ledert\u00fcre;", "tokens": ["Lief", "zur", "Le\u00b7der\u00b7t\u00fc\u00b7re", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Dankte laut im Freien,", "tokens": ["Dank\u00b7te", "laut", "im", "Frei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df sie Freiluft sp\u00fcre.", "tokens": ["Da\u00df", "sie", "Frei\u00b7luft", "sp\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.80": {"line.1": {"text": "Sprang mit einem Satze", "tokens": ["Sprang", "mit", "ei\u00b7nem", "Sat\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tief in die Font\u00e4ne", "tokens": ["Tief", "in", "die", "Fon\u00b7t\u00e4\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN"], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Auf dem Petersplatze.", "tokens": ["Auf", "dem", "Pe\u00b7ter\u00b7splat\u00b7ze", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}