{"textgrid.poem.39070": {"metadata": {"author": {"name": "Prutz, Robert Eduard", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1844, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Eines ist f\u00fcr mich verloren:", "tokens": ["Ei\u00b7nes", "ist", "f\u00fcr", "mich", "ver\u00b7lo\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eins beklag' ich, eins bedaur' ich,", "tokens": ["Eins", "be\u00b7klag'", "ich", ",", "eins", "be\u00b7daur'", "ich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "PIS", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "dieses n\u00e4mlich, da\u00df ich leider", "tokens": ["die\u00b7ses", "n\u00e4m\u00b7lich", ",", "da\u00df", "ich", "lei\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDAT", "ADV", "$,", "KOUS", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht als T\u00fcrke bin geboren!", "tokens": ["nicht", "als", "T\u00fcr\u00b7ke", "bin", "ge\u00b7bo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOUS", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn vor allem Volk der Erde", "tokens": ["Denn", "vor", "al\u00b7lem", "Volk", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIS", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sind die T\u00fcrken hoch zu preisen,", "tokens": ["sind", "die", "T\u00fcr\u00b7ken", "hoch", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "sie allein die wahren Menschen,", "tokens": ["sie", "al\u00b7lein", "die", "wah\u00b7ren", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "die Zufriedenen, die Weisen.", "tokens": ["die", "Zu\u00b7frie\u00b7de\u00b7nen", ",", "die", "Wei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Hol' der Teufel unsre Bildung!", "tokens": ["Hol'", "der", "Teu\u00b7fel", "uns\u00b7re", "Bil\u00b7dung", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagt, was bringt es mir f\u00fcr Ehre,", "tokens": ["Sagt", ",", "was", "bringt", "es", "mir", "f\u00fcr", "Eh\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "VVFIN", "PPER", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df ich m\u00fchsam mich in Sorgen", "tokens": ["da\u00df", "ich", "m\u00fch\u00b7sam", "mich", "in", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "PRF", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "um mein Vaterland verzehre?", "tokens": ["um", "mein", "Va\u00b7ter\u00b7land", "ver\u00b7zeh\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df die Schmerzen des Jahrhunderts", "tokens": ["Da\u00df", "die", "Schmer\u00b7zen", "des", "Jahr\u00b7hun\u00b7derts"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "mir in meine Seele schneiden,", "tokens": ["mir", "in", "mei\u00b7ne", "See\u00b7le", "schnei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und da\u00df mein Gl\u00fcck mir verg\u00e4llt ist,", "tokens": ["und", "da\u00df", "mein", "Gl\u00fcck", "mir", "ver\u00b7g\u00e4llt", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "weil ich wei\u00df, da\u00df andre leiden?", "tokens": ["weil", "ich", "wei\u00df", ",", "da\u00df", "and\u00b7re", "lei\u00b7den", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Seid ihr etwa darum weiser,", "tokens": ["Seid", "ihr", "et\u00b7wa", "da\u00b7rum", "wei\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "ADV", "PAV", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "weil ihr euch mit Weisheit br\u00fcstet?", "tokens": ["weil", "ihr", "euch", "mit", "Weis\u00b7heit", "br\u00fcs\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sind wir etwa darum freier,", "tokens": ["Sind", "wir", "et\u00b7wa", "da\u00b7rum", "frei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PAV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "weil nach Freiheit uns gel\u00fcstet?", "tokens": ["weil", "nach", "Frei\u00b7heit", "uns", "ge\u00b7l\u00fcs\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein, wir sind sogar noch schlechter,", "tokens": ["Nein", ",", "wir", "sind", "so\u00b7gar", "noch", "schlech\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "dieses d\u00fcnkt mich unbestritten:", "tokens": ["die\u00b7ses", "d\u00fcnkt", "mich", "un\u00b7be\u00b7strit\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn am Fleisch zwar sind die T\u00fcrken,", "tokens": ["Denn", "am", "Fleisch", "zwar", "sind", "die", "T\u00fcr\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "doch am Geist sind wir beschnitten.", "tokens": ["doch", "am", "Geist", "sind", "wir", "be\u00b7schnit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VAFIN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wohl, wenn ich ein T\u00fcrke w\u00e4re,", "tokens": ["Wohl", ",", "wenn", "ich", "ein", "T\u00fcr\u00b7ke", "w\u00e4\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "dann die H\u00e4nde auf dem Bauche,", "tokens": ["dann", "die", "H\u00e4n\u00b7de", "auf", "dem", "Bau\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "s\u00fc\u00dfe Knasterw\u00f6lkchen saugt' ich", "tokens": ["s\u00fc\u00b7\u00dfe", "Knas\u00b7ter\u00b7w\u00f6lk\u00b7chen", "saugt'", "ich"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "aus dem ambraduft'gen Schlauche;", "tokens": ["aus", "dem", "am\u00b7bra\u00b7duft'\u00b7gen", "Schlau\u00b7che", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "neben mir mit nackten H\u00fcften,", "tokens": ["ne\u00b7ben", "mir", "mit", "nack\u00b7ten", "H\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.6": {"text": "eine Sklavin sch\u00fcrt' die Kohlen,", "tokens": ["ei\u00b7ne", "Skla\u00b7vin", "sch\u00fcrt'", "die", "Koh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und die andre, die Tscherkessin,", "tokens": ["und", "die", "and\u00b7re", ",", "die", "Tscher\u00b7kes\u00b7sin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "$,", "ART", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "kraute dienstbar mir die Sohlen.", "tokens": ["krau\u00b7te", "dienst\u00b7bar", "mir", "die", "Soh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Sanft, mit ausgespr\u00fchten Perlen", "tokens": ["Sanft", ",", "mit", "aus\u00b7ge\u00b7spr\u00fch\u00b7ten", "Per\u00b7len"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sollt' ein Springquell mich erfrischen,", "tokens": ["sollt'", "ein", "Spring\u00b7quell", "mich", "er\u00b7fri\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und in sein melodisch Pl\u00e4tschern", "tokens": ["und", "in", "sein", "me\u00b7lo\u00b7disch", "Pl\u00e4t\u00b7schern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "fl\u00f6tend sich die Bulbul mischen:", "tokens": ["fl\u00f6\u00b7tend", "sich", "die", "Bul\u00b7bul", "mi\u00b7schen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00e4hrend ich, in Gottes Frieden,", "tokens": ["W\u00e4h\u00b7rend", "ich", ",", "in", "Got\u00b7tes", "Frie\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "eingemachte Feigen nasche,", "tokens": ["ein\u00b7ge\u00b7mach\u00b7te", "Fei\u00b7gen", "na\u00b7sche", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "oder unter meinem Kaftan", "tokens": ["o\u00b7der", "un\u00b7ter", "mei\u00b7nem", "Kaf\u00b7tan"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "k\u00fc\u00dft' ich die verbotne Flasche.", "tokens": ["k\u00fc\u00dft'", "ich", "die", "ver\u00b7bot\u00b7ne", "Fla\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Sollt' es aber hin und wieder", "tokens": ["Sollt'", "es", "a\u00b7ber", "hin", "und", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "PTKVZ", "KON", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mir an Unterhaltung fehlen,", "tokens": ["mir", "an", "Un\u00b7ter\u00b7hal\u00b7tung", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "schlummert' ich und lie\u00df zum Schlummer", "tokens": ["schlum\u00b7mert'", "ich", "und", "lie\u00df", "zum", "Schlum\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "lust'ge M\u00e4rchen mir erz\u00e4hlen;", "tokens": ["lust'\u00b7ge", "M\u00e4r\u00b7chen", "mir", "er\u00b7z\u00e4h\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "oder einen Christen rief ich,", "tokens": ["o\u00b7der", "ei\u00b7nen", "Chris\u00b7ten", "rief", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "in das Antlitz ihm zu spucken,", "tokens": ["in", "das", "Ant\u00b7litz", "ihm", "zu", "spu\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und nicht mit den Augenwimpern", "tokens": ["und", "nicht", "mit", "den", "Au\u00b7gen\u00b7wim\u00b7pern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "d\u00fcrfte der Giaur mir zucken! \u2013", "tokens": ["d\u00fcrf\u00b7te", "der", "Gi\u00b7aur", "mir", "zu\u00b7cken", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Kriegt' ich selber auch mitunter", "tokens": ["Kriegt'", "ich", "sel\u00b7ber", "auch", "mi\u00b7tun\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ein klein wenig Bastonnade", "tokens": ["ein", "klein", "we\u00b7nig", "Bas\u00b7ton\u00b7na\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "nun, was w\u00e4r' es, recht besehen,", "tokens": ["nun", ",", "was", "w\u00e4r'", "es", ",", "recht", "be\u00b7se\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VAFIN", "PPER", "$,", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "f\u00fcr ein \u00fcberm\u00e4\u00df'ger Schade?", "tokens": ["f\u00fcr", "ein", "\u00fc\u00b7ber\u00b7m\u00e4\u00df'\u00b7ger", "Scha\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hab' ich Sklaven nicht und Weiber,", "tokens": ["Hab'", "ich", "Skla\u00b7ven", "nicht", "und", "Wei\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "PTKNEG", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die an ihren zarten F\u00fc\u00dfen", "tokens": ["die", "an", "ih\u00b7ren", "zar\u00b7ten", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "jeden Streich, den ich empfangen,", "tokens": ["je\u00b7den", "Streich", ",", "den", "ich", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "hundertfach und dr\u00fcber b\u00fc\u00dfen?", "tokens": ["hun\u00b7dert\u00b7fach", "und", "dr\u00fc\u00b7ber", "b\u00fc\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "PAV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Und so fl\u00f6ssen, klar und eben,", "tokens": ["Und", "so", "fl\u00f6s\u00b7sen", ",", "klar", "und", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "$,", "ADJD", "KON", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "unerm\u00fcdlich meine Tage,", "tokens": ["un\u00b7er\u00b7m\u00fcd\u00b7lich", "mei\u00b7ne", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ohne Wunsch und ohne Sorgen,", "tokens": ["oh\u00b7ne", "Wunsch", "und", "oh\u00b7ne", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ohne Leidenschaft und Klage.", "tokens": ["oh\u00b7ne", "Lei\u00b7den\u00b7schaft", "und", "Kla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn was immer, Gut' und B\u00f6ses,", "tokens": ["Denn", "was", "im\u00b7mer", ",", "Gut'", "und", "B\u00f6\u00b7ses", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mir vom Himmel wird beschieden,", "tokens": ["mir", "vom", "Him\u00b7mel", "wird", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "wei\u00df ich doch: Allah il Allah!", "tokens": ["wei\u00df", "ich", "doch", ":", "Al\u00b7lah", "il", "Al\u00b7lah", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$.", "NN", "NE", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "Und so trag' ich es in Frieden.", "tokens": ["Und", "so", "trag'", "ich", "es", "in", "Frie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Stirbt mein Weib, kauf' ich ein andres,", "tokens": ["Stirbt", "mein", "Weib", ",", "kauf'", "ich", "ein", "and\u00b7res", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "ART", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "das noch s\u00fc\u00dfer wei\u00df zu lachen;", "tokens": ["das", "noch", "s\u00fc\u00b7\u00dfer", "wei\u00df", "zu", "la\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "stirbt mein Sohn, wohlan, so werd' ich", "tokens": ["stirbt", "mein", "Sohn", ",", "wo\u00b7hlan", ",", "so", "werd'", "ich"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "PWAV", "$,", "ADV", "VAFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "flugs mir einen neuen machen;", "tokens": ["flugs", "mir", "ei\u00b7nen", "neu\u00b7en", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "ADJA", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "und nun gar die tollen Worte,", "tokens": ["und", "nun", "gar", "die", "tol\u00b7len", "Wor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "welche euch den Frieden st\u00f6ren;", "tokens": ["wel\u00b7che", "euch", "den", "Frie\u00b7den", "st\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Vaterland und Recht und Freiheit,", "tokens": ["Va\u00b7ter\u00b7land", "und", "Recht", "und", "Frei\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "diese werd' ich gar nicht h\u00f6ren.", "tokens": ["die\u00b7se", "werd'", "ich", "gar", "nicht", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Eines ist f\u00fcr mich verloren:", "tokens": ["Ei\u00b7nes", "ist", "f\u00fcr", "mich", "ver\u00b7lo\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eins beklag' ich, eins bedaur' ich,", "tokens": ["Eins", "be\u00b7klag'", "ich", ",", "eins", "be\u00b7daur'", "ich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "PIS", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "dieses n\u00e4mlich, da\u00df ich leider", "tokens": ["die\u00b7ses", "n\u00e4m\u00b7lich", ",", "da\u00df", "ich", "lei\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDAT", "ADV", "$,", "KOUS", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht als T\u00fcrke bin geboren!", "tokens": ["nicht", "als", "T\u00fcr\u00b7ke", "bin", "ge\u00b7bo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOUS", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn vor allem Volk der Erde", "tokens": ["Denn", "vor", "al\u00b7lem", "Volk", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIS", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sind die T\u00fcrken hoch zu preisen,", "tokens": ["sind", "die", "T\u00fcr\u00b7ken", "hoch", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "sie allein die wahren Menschen,", "tokens": ["sie", "al\u00b7lein", "die", "wah\u00b7ren", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "die Zufriedenen, die Weisen.", "tokens": ["die", "Zu\u00b7frie\u00b7de\u00b7nen", ",", "die", "Wei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Hol' der Teufel unsre Bildung!", "tokens": ["Hol'", "der", "Teu\u00b7fel", "uns\u00b7re", "Bil\u00b7dung", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagt, was bringt es mir f\u00fcr Ehre,", "tokens": ["Sagt", ",", "was", "bringt", "es", "mir", "f\u00fcr", "Eh\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "VVFIN", "PPER", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df ich m\u00fchsam mich in Sorgen", "tokens": ["da\u00df", "ich", "m\u00fch\u00b7sam", "mich", "in", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "PRF", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "um mein Vaterland verzehre?", "tokens": ["um", "mein", "Va\u00b7ter\u00b7land", "ver\u00b7zeh\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df die Schmerzen des Jahrhunderts", "tokens": ["Da\u00df", "die", "Schmer\u00b7zen", "des", "Jahr\u00b7hun\u00b7derts"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "mir in meine Seele schneiden,", "tokens": ["mir", "in", "mei\u00b7ne", "See\u00b7le", "schnei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und da\u00df mein Gl\u00fcck mir verg\u00e4llt ist,", "tokens": ["und", "da\u00df", "mein", "Gl\u00fcck", "mir", "ver\u00b7g\u00e4llt", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "weil ich wei\u00df, da\u00df andre leiden?", "tokens": ["weil", "ich", "wei\u00df", ",", "da\u00df", "and\u00b7re", "lei\u00b7den", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Seid ihr etwa darum weiser,", "tokens": ["Seid", "ihr", "et\u00b7wa", "da\u00b7rum", "wei\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "ADV", "PAV", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "weil ihr euch mit Weisheit br\u00fcstet?", "tokens": ["weil", "ihr", "euch", "mit", "Weis\u00b7heit", "br\u00fcs\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sind wir etwa darum freier,", "tokens": ["Sind", "wir", "et\u00b7wa", "da\u00b7rum", "frei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PAV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "weil nach Freiheit uns gel\u00fcstet?", "tokens": ["weil", "nach", "Frei\u00b7heit", "uns", "ge\u00b7l\u00fcs\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein, wir sind sogar noch schlechter,", "tokens": ["Nein", ",", "wir", "sind", "so\u00b7gar", "noch", "schlech\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "dieses d\u00fcnkt mich unbestritten:", "tokens": ["die\u00b7ses", "d\u00fcnkt", "mich", "un\u00b7be\u00b7strit\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn am Fleisch zwar sind die T\u00fcrken,", "tokens": ["Denn", "am", "Fleisch", "zwar", "sind", "die", "T\u00fcr\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "doch am Geist sind wir beschnitten.", "tokens": ["doch", "am", "Geist", "sind", "wir", "be\u00b7schnit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VAFIN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Wohl, wenn ich ein T\u00fcrke w\u00e4re,", "tokens": ["Wohl", ",", "wenn", "ich", "ein", "T\u00fcr\u00b7ke", "w\u00e4\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "dann die H\u00e4nde auf dem Bauche,", "tokens": ["dann", "die", "H\u00e4n\u00b7de", "auf", "dem", "Bau\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "s\u00fc\u00dfe Knasterw\u00f6lkchen saugt' ich", "tokens": ["s\u00fc\u00b7\u00dfe", "Knas\u00b7ter\u00b7w\u00f6lk\u00b7chen", "saugt'", "ich"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "aus dem ambraduft'gen Schlauche;", "tokens": ["aus", "dem", "am\u00b7bra\u00b7duft'\u00b7gen", "Schlau\u00b7che", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "neben mir mit nackten H\u00fcften,", "tokens": ["ne\u00b7ben", "mir", "mit", "nack\u00b7ten", "H\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.6": {"text": "eine Sklavin sch\u00fcrt' die Kohlen,", "tokens": ["ei\u00b7ne", "Skla\u00b7vin", "sch\u00fcrt'", "die", "Koh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und die andre, die Tscherkessin,", "tokens": ["und", "die", "and\u00b7re", ",", "die", "Tscher\u00b7kes\u00b7sin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "$,", "ART", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "kraute dienstbar mir die Sohlen.", "tokens": ["krau\u00b7te", "dienst\u00b7bar", "mir", "die", "Soh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Sanft, mit ausgespr\u00fchten Perlen", "tokens": ["Sanft", ",", "mit", "aus\u00b7ge\u00b7spr\u00fch\u00b7ten", "Per\u00b7len"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sollt' ein Springquell mich erfrischen,", "tokens": ["sollt'", "ein", "Spring\u00b7quell", "mich", "er\u00b7fri\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und in sein melodisch Pl\u00e4tschern", "tokens": ["und", "in", "sein", "me\u00b7lo\u00b7disch", "Pl\u00e4t\u00b7schern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "fl\u00f6tend sich die Bulbul mischen:", "tokens": ["fl\u00f6\u00b7tend", "sich", "die", "Bul\u00b7bul", "mi\u00b7schen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00e4hrend ich, in Gottes Frieden,", "tokens": ["W\u00e4h\u00b7rend", "ich", ",", "in", "Got\u00b7tes", "Frie\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "eingemachte Feigen nasche,", "tokens": ["ein\u00b7ge\u00b7mach\u00b7te", "Fei\u00b7gen", "na\u00b7sche", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "oder unter meinem Kaftan", "tokens": ["o\u00b7der", "un\u00b7ter", "mei\u00b7nem", "Kaf\u00b7tan"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "k\u00fc\u00dft' ich die verbotne Flasche.", "tokens": ["k\u00fc\u00dft'", "ich", "die", "ver\u00b7bot\u00b7ne", "Fla\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Sollt' es aber hin und wieder", "tokens": ["Sollt'", "es", "a\u00b7ber", "hin", "und", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "PTKVZ", "KON", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mir an Unterhaltung fehlen,", "tokens": ["mir", "an", "Un\u00b7ter\u00b7hal\u00b7tung", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "schlummert' ich und lie\u00df zum Schlummer", "tokens": ["schlum\u00b7mert'", "ich", "und", "lie\u00df", "zum", "Schlum\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "lust'ge M\u00e4rchen mir erz\u00e4hlen;", "tokens": ["lust'\u00b7ge", "M\u00e4r\u00b7chen", "mir", "er\u00b7z\u00e4h\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "oder einen Christen rief ich,", "tokens": ["o\u00b7der", "ei\u00b7nen", "Chris\u00b7ten", "rief", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "in das Antlitz ihm zu spucken,", "tokens": ["in", "das", "Ant\u00b7litz", "ihm", "zu", "spu\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und nicht mit den Augenwimpern", "tokens": ["und", "nicht", "mit", "den", "Au\u00b7gen\u00b7wim\u00b7pern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "d\u00fcrfte der Giaur mir zucken! \u2013", "tokens": ["d\u00fcrf\u00b7te", "der", "Gi\u00b7aur", "mir", "zu\u00b7cken", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Kriegt' ich selber auch mitunter", "tokens": ["Kriegt'", "ich", "sel\u00b7ber", "auch", "mi\u00b7tun\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ein klein wenig Bastonnade", "tokens": ["ein", "klein", "we\u00b7nig", "Bas\u00b7ton\u00b7na\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "nun, was w\u00e4r' es, recht besehen,", "tokens": ["nun", ",", "was", "w\u00e4r'", "es", ",", "recht", "be\u00b7se\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VAFIN", "PPER", "$,", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "f\u00fcr ein \u00fcberm\u00e4\u00df'ger Schade?", "tokens": ["f\u00fcr", "ein", "\u00fc\u00b7ber\u00b7m\u00e4\u00df'\u00b7ger", "Scha\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hab' ich Sklaven nicht und Weiber,", "tokens": ["Hab'", "ich", "Skla\u00b7ven", "nicht", "und", "Wei\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "PTKNEG", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die an ihren zarten F\u00fc\u00dfen", "tokens": ["die", "an", "ih\u00b7ren", "zar\u00b7ten", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "jeden Streich, den ich empfangen,", "tokens": ["je\u00b7den", "Streich", ",", "den", "ich", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "hundertfach und dr\u00fcber b\u00fc\u00dfen?", "tokens": ["hun\u00b7dert\u00b7fach", "und", "dr\u00fc\u00b7ber", "b\u00fc\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "PAV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Und so fl\u00f6ssen, klar und eben,", "tokens": ["Und", "so", "fl\u00f6s\u00b7sen", ",", "klar", "und", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "$,", "ADJD", "KON", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "unerm\u00fcdlich meine Tage,", "tokens": ["un\u00b7er\u00b7m\u00fcd\u00b7lich", "mei\u00b7ne", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ohne Wunsch und ohne Sorgen,", "tokens": ["oh\u00b7ne", "Wunsch", "und", "oh\u00b7ne", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ohne Leidenschaft und Klage.", "tokens": ["oh\u00b7ne", "Lei\u00b7den\u00b7schaft", "und", "Kla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn was immer, Gut' und B\u00f6ses,", "tokens": ["Denn", "was", "im\u00b7mer", ",", "Gut'", "und", "B\u00f6\u00b7ses", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mir vom Himmel wird beschieden,", "tokens": ["mir", "vom", "Him\u00b7mel", "wird", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "wei\u00df ich doch: Allah il Allah!", "tokens": ["wei\u00df", "ich", "doch", ":", "Al\u00b7lah", "il", "Al\u00b7lah", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$.", "NN", "NE", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "Und so trag' ich es in Frieden.", "tokens": ["Und", "so", "trag'", "ich", "es", "in", "Frie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Stirbt mein Weib, kauf' ich ein andres,", "tokens": ["Stirbt", "mein", "Weib", ",", "kauf'", "ich", "ein", "and\u00b7res", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "ART", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "das noch s\u00fc\u00dfer wei\u00df zu lachen;", "tokens": ["das", "noch", "s\u00fc\u00b7\u00dfer", "wei\u00df", "zu", "la\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "stirbt mein Sohn, wohlan, so werd' ich", "tokens": ["stirbt", "mein", "Sohn", ",", "wo\u00b7hlan", ",", "so", "werd'", "ich"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "PWAV", "$,", "ADV", "VAFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "flugs mir einen neuen machen;", "tokens": ["flugs", "mir", "ei\u00b7nen", "neu\u00b7en", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "ADJA", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "und nun gar die tollen Worte,", "tokens": ["und", "nun", "gar", "die", "tol\u00b7len", "Wor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "welche euch den Frieden st\u00f6ren;", "tokens": ["wel\u00b7che", "euch", "den", "Frie\u00b7den", "st\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Vaterland und Recht und Freiheit,", "tokens": ["Va\u00b7ter\u00b7land", "und", "Recht", "und", "Frei\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "diese werd' ich gar nicht h\u00f6ren.", "tokens": ["die\u00b7se", "werd'", "ich", "gar", "nicht", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}