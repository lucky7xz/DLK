{"dta.poem.317": {"metadata": {"author": {"name": "Gressel, Johann Georg", "birth": "N.A.", "death": "N.A."}, "title": "An seine  Inclination.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1716", "urn": "urn:nbn:de:kobv:b4-200905199041", "language": ["de:0.99"], "booktitle": "Celander [i. e. Gressel, Johann Georg]: Verliebte-Galante/ Sinn-Vermischte und Grab-Gedichte. Hamburg u. a., 1716."}, "poem": {"stanza.1": {"line.1": {"text": "Nimm Geliebte Hertz und Hand", "tokens": ["Nimm", "Ge\u00b7lieb\u00b7te", "Hertz", "und", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Beydes ist dir zugewandt/", "tokens": ["Bey\u00b7des", "ist", "dir", "zu\u00b7ge\u00b7wandt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Du weist/ da\u00df meine Treu", "tokens": ["Du", "weist", "/", "da\u00df", "mei\u00b7ne", "Treu"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Frey von der Heucheley;", "tokens": ["Frey", "von", "der", "Heu\u00b7che\u00b7ley", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Drum vertausche ohne Schertz", "tokens": ["Drum", "ver\u00b7tau\u00b7sche", "oh\u00b7ne", "Schertz"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wertheste mit mir dein Hertz.", "tokens": ["Wert\u00b7hes\u00b7te", "mit", "mir", "dein", "Hertz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "PPOSAT", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.2": {"line.1": {"text": "Was bedenckest du dich noch", "tokens": ["Was", "be\u00b7den\u00b7ckest", "du", "dich", "noch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PRF", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nimm das leichte Liebes-Joch/", "tokens": ["Nimm", "das", "leich\u00b7te", "Lie\u00b7bes\u00b7Joch", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ertrag es mit Gedult/", "tokens": ["Er\u00b7trag", "es", "mit", "Ge\u00b7dult", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Das Schicksahl hat die Schuld/", "tokens": ["Das", "Schick\u00b7sahl", "hat", "die", "Schuld", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Jetzt will es nicht anders seyn", "tokens": ["Jetzt", "will", "es", "nicht", "an\u00b7ders", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "ADV", "VAINF"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Gib nur deinen Willen drein.", "tokens": ["Gib", "nur", "dei\u00b7nen", "Wil\u00b7len", "drein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ist schon etwas Bitterkeit", "tokens": ["Ist", "schon", "et\u00b7was", "Bit\u00b7ter\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bey der Liebe ausgestreut/", "tokens": ["Bey", "der", "Lie\u00b7be", "aus\u00b7ge\u00b7streut", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "So ist doch keine Lust", "tokens": ["So", "ist", "doch", "kei\u00b7ne", "Lust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Unliebenden bewust;", "tokens": ["Un\u00b7lie\u00b7ben\u00b7den", "be\u00b7wust", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Von der Grillenf\u00e4ngerey", "tokens": ["Von", "der", "Gril\u00b7len\u00b7f\u00e4n\u00b7ge\u00b7rey"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Macht die s\u00fcsse Liebe frey.", "tokens": ["Macht", "die", "s\u00fcs\u00b7se", "Lie\u00b7be", "frey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Amor ist ein kluger Artzt;", "tokens": ["A\u00b7mor", "ist", "ein", "klu\u00b7ger", "Artzt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er macht offtmahls Wei\u00df aus Schwartz/", "tokens": ["Er", "macht", "offt\u00b7mahls", "Wei\u00df", "aus", "Schwartz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "APPR", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Hat man gleich Schwartz auf Wei\u00df;", "tokens": ["Hat", "man", "gleich", "Schwartz", "auf", "Wei\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "NN", "APPR", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Er spahret keinen Flei\u00df/", "tokens": ["Er", "spah\u00b7ret", "kei\u00b7nen", "Flei\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df sich die gefangen sehn", "tokens": ["Da\u00df", "sich", "die", "ge\u00b7fan\u00b7gen", "sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ART", "ADJD", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die ihm aus dem Wege gehn.", "tokens": ["Die", "ihm", "aus", "dem", "We\u00b7ge", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Will man in die W\u00e4lder fliehn", "tokens": ["Will", "man", "in", "die", "W\u00e4l\u00b7der", "fliehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIS", "APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird man ihn doch nach sich ziehn/", "tokens": ["Wird", "man", "ihn", "doch", "nach", "sich", "ziehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PPER", "ADV", "APPR", "PRF", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Wild-Bahn und die Hatz", "tokens": ["Die", "Wild\u00b7Bahn", "und", "die", "Hatz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-++--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Ist recht sein Sammel-Platz/", "tokens": ["Ist", "recht", "sein", "Sam\u00b7mel\u00b7Platz", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da treibet er die J\u00e4gerey/", "tokens": ["Da", "trei\u00b7bet", "er", "die", "J\u00e4\u00b7ge\u00b7rey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vogel f\u00e4ngt er auch dabey.", "tokens": ["Vo\u00b7gel", "f\u00e4ngt", "er", "auch", "da\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Geht man in die Welt hinein", "tokens": ["Geht", "man", "in", "die", "Welt", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "APZR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er wird ein Gef\u00e4hrte seyn/", "tokens": ["Er", "wird", "ein", "Ge\u00b7f\u00e4hr\u00b7te", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VAINF", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Er reiset t\u00e4glich aus/", "tokens": ["Er", "rei\u00b7set", "t\u00e4g\u00b7lich", "aus", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ist nirgends recht zu Haus/", "tokens": ["Ist", "nir\u00b7gends", "recht", "zu", "Haus", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch nennt er wie wol bekannt/", "tokens": ["Doch", "nennt", "er", "wie", "wol", "be\u00b7kannt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "KOKOM", "ADV", "ADJD", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Jeden Ort sein Vater-Land.", "tokens": ["Je\u00b7den", "Ort", "sein", "Va\u00b7ter\u00b7Land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Sencket man sich in die Fluth", "tokens": ["Sen\u00b7cket", "man", "sich", "in", "die", "Fluth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sp\u00fchrt man da auch seine Gluth/", "tokens": ["Sp\u00fchrt", "man", "da", "auch", "sei\u00b7ne", "Gluth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADV", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Wellen Silber-Schaum", "tokens": ["Der", "Wel\u00b7len", "Sil\u00b7ber\u00b7Schaum"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Macht seinen Flammen raum.", "tokens": ["Macht", "sei\u00b7nen", "Flam\u00b7men", "raum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Venus ist da ausgeheckt", "tokens": ["Ve\u00b7nus", "ist", "da", "aus\u00b7ge\u00b7heckt"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ADV", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Als die Muschel sie entdeckt.", "tokens": ["Als", "die", "Mu\u00b7schel", "sie", "ent\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Nun du Engel-gleiches Bild", "tokens": ["Nun", "du", "En\u00b7gel\u00b7glei\u00b7ches", "Bild"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPER", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00e4hle dir das/ was du wilt/", "tokens": ["W\u00e4h\u00b7le", "dir", "das", "/", "was", "du", "wilt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "$(", "PWS", "PPER", "VMFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch traue dem Bericht/", "tokens": ["Doch", "trau\u00b7e", "dem", "Be\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Es hilfft dir alles nicht/", "tokens": ["Es", "hilfft", "dir", "al\u00b7les", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "PTKNEG", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Deiner Sch\u00f6nheit Sonnenschein", "tokens": ["Dei\u00b7ner", "Sch\u00f6n\u00b7heit", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Soll und mu\u00df geliebet seyn.", "tokens": ["Soll", "und", "mu\u00df", "ge\u00b7lie\u00b7bet", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "KON", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "So umarme mich mein Kind/", "tokens": ["So", "um\u00b7ar\u00b7me", "mich", "mein", "Kind", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eil\u2019 und k\u00fcsse mich geschwind", "tokens": ["Eil'", "und", "k\u00fcs\u00b7se", "mich", "ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "PPER", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Leffzen Honig-Seim", "tokens": ["Der", "Leff\u00b7zen", "Ho\u00b7nig\u00b7Seim"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ist gar ein s\u00fcsser Leim/", "tokens": ["Ist", "gar", "ein", "s\u00fcs\u00b7ser", "Leim", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wodurch Hertz an Hertz sich vest", "tokens": ["Wo\u00b7durch", "Hertz", "an", "Hertz", "sich", "vest"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "APPR", "NN", "PRF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Unzertrennlich f\u00fcgen l\u00e4st.", "tokens": ["Un\u00b7zer\u00b7trenn\u00b7lich", "f\u00fc\u00b7gen", "l\u00e4st", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Alabaster scheint dein Hals", "tokens": ["A\u00b7la\u00b7bas\u00b7ter", "scheint", "dein", "Hals"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Br\u00fcste ebenfals/", "tokens": ["Und", "die", "Br\u00fcs\u00b7te", "e\u00b7ben\u00b7fals", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie wallen also sehr", "tokens": ["Sie", "wal\u00b7len", "al\u00b7so", "sehr"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Recht wie ein Perlen-Meer/", "tokens": ["Recht", "wie", "ein", "Per\u00b7len\u00b7Meer", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wenn des Athens sanffter Wind", "tokens": ["Wenn", "des", "A\u00b7thens", "sanff\u00b7ter", "Wind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sie erregt und mich entz\u00fcndt.", "tokens": ["Sie", "er\u00b7regt", "und", "mich", "ent\u00b7z\u00fcndt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Weiter will ich jetzt nicht gehn/", "tokens": ["Wei\u00b7ter", "will", "ich", "jetzt", "nicht", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch recht in die Tieffe sehn/", "tokens": ["Noch", "recht", "in", "die", "Tief\u00b7fe", "sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das ander spahr ich mir", "tokens": ["Das", "an\u00b7der", "spahr", "ich", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADJD", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Auf be\u00dfre Zeiten f\u00fcr.", "tokens": ["Auf", "be\u00df\u00b7re", "Zei\u00b7ten", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Bleib indessen Eingedenck", "tokens": ["Bleib", "in\u00b7des\u00b7sen", "Ein\u00b7ge\u00b7denck"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ich sey dein/ du mein/ Geschenck.", "tokens": ["Ich", "sey", "dein", "/", "du", "mein", "/", "Ge\u00b7schenck", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "$(", "PPER", "PPOSAT", "$(", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}}}}