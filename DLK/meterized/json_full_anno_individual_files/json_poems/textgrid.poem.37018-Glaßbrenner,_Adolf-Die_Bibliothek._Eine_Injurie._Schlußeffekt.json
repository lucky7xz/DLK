{"textgrid.poem.37018": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "Die Bibliothek. Eine Injurie. Schlu\u00dfeffekt", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df mich dieser krasse Bl\u00f6dsinn", "tokens": ["Da\u00df", "mich", "die\u00b7ser", "kras\u00b7se", "Bl\u00f6d\u00b7sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einer heidnischen Sophistik", "tokens": ["Ei\u00b7ner", "heid\u00b7ni\u00b7schen", "So\u00b7phis\u00b7tik"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Innerlichst emp\u00f6rte, werden", "tokens": ["In\u00b7ner\u00b7lichst", "em\u00b7p\u00f6r\u00b7te", ",", "wer\u00b7den"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "$,", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle meine Herrn Collegen,", "tokens": ["Al\u00b7le", "mei\u00b7ne", "Herrn", "Col\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alle wahrhaft frommen Priester", "tokens": ["Al\u00b7le", "wahr\u00b7haft", "from\u00b7men", "Pries\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Meines Vatersternes Erde", "tokens": ["Mei\u00b7nes", "Va\u00b7ters\u00b7ter\u00b7nes", "Er\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wohl begreifen. Und die Deutschen", "tokens": ["Wohl", "be\u00b7grei\u00b7fen", ".", "Und", "die", "Deut\u00b7schen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVINF", "$.", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Unter ihnen auch, da\u00df trotzdem", "tokens": ["Un\u00b7ter", "ih\u00b7nen", "auch", ",", "da\u00df", "trotz\u00b7dem"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "ADV", "$,", "KOUS", "PAV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Ich \u2013 die Macht des Ober-Mufti's", "tokens": ["Ich", "\u2013", "die", "Macht", "des", "O\u00b7ber\u00b7Muf\u00b7ti's"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$(", "ART", "NN", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Und das Kitzliche, Prek\u00e4re", "tokens": ["Und", "das", "Kitz\u00b7li\u00b7che", ",", "Pre\u00b7k\u00e4\u00b7re"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "ART", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Meiner Stellung hier ermessend \u2013", "tokens": ["Mei\u00b7ner", "Stel\u00b7lung", "hier", "er\u00b7mes\u00b7send", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Dieses heft'gen und gerechten", "tokens": ["Die\u00b7ses", "heft'\u00b7gen", "und", "ge\u00b7rech\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "KON", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Zornes Meister blieb und meine", "tokens": ["Zor\u00b7nes", "Meis\u00b7ter", "blieb", "und", "mei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN", "KON", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Oppositionellen F\u00e4uste", "tokens": ["Op\u00b7po\u00b7si\u00b7ti\u00b7o\u00b7nel\u00b7len", "F\u00e4us\u00b7te"], "token_info": ["word", "word"], "pos": ["NN", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.15": {"text": "In der Tasche machte. Da\u00df ich", "tokens": ["In", "der", "Ta\u00b7sche", "mach\u00b7te", ".", "Da\u00df", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "$.", "KOUS", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Raisonnirte nur im Tiefsten", "tokens": ["Rai\u00b7son\u00b7nir\u00b7te", "nur", "im", "Tiefs\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Meines Innern, in Gedanken,", "tokens": ["Mei\u00b7nes", "In\u00b7nern", ",", "in", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Und selbst ", "tokens": ["Und", "selbst"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.19": {"text": "Und pr\u00e4meditirt, bed\u00e4chtig,", "tokens": ["Und", "pr\u00e4\u00b7me\u00b7di\u00b7tirt", ",", "be\u00b7d\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "VVPP", "$,", "ADJD", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.20": {"text": "Jedes unparlamentarisch-", "tokens": ["Je\u00b7des", "un\u00b7par\u00b7la\u00b7men\u00b7ta\u00b7risch"], "token_info": ["word", "word"], "pos": ["PIAT", "TRUNC"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Schroffen Ausdrucks wie: \u00bbBarbarisch!", "tokens": ["Schrof\u00b7fen", "Aus\u00b7drucks", "wie", ":", "\u00bb", "Bar\u00b7ba\u00b7risch", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "NN", "KOKOM", "$.", "$(", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.22": {"text": "Oeffentliche Meinung! Scheu\u00dflich!", "tokens": ["Oef\u00b7fent\u00b7li\u00b7che", "Mei\u00b7nung", "!", "Scheu\u00df\u00b7lich", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJD", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "Sch\u00e4ndlich! Einheit! Niedertr\u00e4chtig!", "tokens": ["Sch\u00e4nd\u00b7lich", "!", "Ein\u00b7heit", "!", "Nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$.", "NN", "$.", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.24": {"text": "Freie Presse! Klein, doch m\u00e4chtig!", "tokens": ["Frei\u00b7e", "Pres\u00b7se", "!", "Klein", ",", "doch", "m\u00e4ch\u00b7tig", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "NE", "$,", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.25": {"text": "Privilegienst\u00fcrmer! Censor!", "tokens": ["Pri\u00b7vi\u00b7le\u00b7giens\u00b7t\u00fcr\u00b7mer", "!", "Cen\u00b7sor", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.26": {"text": "Liberal! Frech! Ordnungsfeindlich!", "tokens": ["Li\u00b7be\u00b7ral", "!", "Frech", "!", "Ord\u00b7nungs\u00b7feind\u00b7lich", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$.", "NN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.27": {"text": "Fortschritts-Wahnsinn! Plebs-Defensor!", "tokens": ["Fort\u00b7schritts\u00b7Wahn\u00b7sinn", "!", "Plebs\u00b7De\u00b7fen\u00b7sor", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.28": {"text": "Deutschkatholisch! Freigemeindlich!", "tokens": ["Deutschka\u00b7tho\u00b7lisch", "!", "Frei\u00b7ge\u00b7meind\u00b7lich", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$.", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.29": {"text": "Literat! Ruh'st\u00f6rer! Jude!", "tokens": ["Li\u00b7te\u00b7rat", "!", "Ruh'\u00b7st\u00f6\u00b7rer", "!", "Ju\u00b7de", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "NN", "$."], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.30": {"text": "Nationalsinn! Bummellude!", "tokens": ["Na\u00b7ti\u00b7o\u00b7nal\u00b7sinn", "!", "Bum\u00b7mel\u00b7lu\u00b7de", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Reactionswuth! Communistisch!", "tokens": ["Re\u00b7ac\u00b7ti\u00b7ons\u00b7wuth", "!", "Com\u00b7mu\u00b7nis\u00b7tisch", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Heuler! W\u00fchler! Schmutz'ges Siel-Thier!", "tokens": ["Heu\u00b7ler", "!", "W\u00fch\u00b7ler", "!", "Schmutz'\u00b7ges", "Siel\u00b7Thier", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.33": {"text": "Menschenrecht! Lump! Antichristlich!\u00ab", "tokens": ["Men\u00b7schen\u00b7recht", "!", "Lump", "!", "An\u00b7ti\u00b7ch\u00b7rist\u00b7lich", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "$.", "NN", "$.", "NE", "$.", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.34": {"text": "Und so weiter ... mich enthielt hier.", "tokens": ["Und", "so", "wei\u00b7ter", "...", "mich", "ent\u00b7hielt", "hier", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$(", "PPER", "VVFIN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Seine Zopfigkeit geruhten", "tokens": ["Sei\u00b7ne", "Zop\u00b7fig\u00b7keit", "ge\u00b7ruh\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich nunmehr vom Ruhesopha", "tokens": ["Sich", "nun\u00b7mehr", "vom", "Ru\u00b7he\u00b7sop\u00b7ha"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "ADV", "APPRART", "NN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Zu erheben und \u2013 durch so viel", "tokens": ["Zu", "er\u00b7he\u00b7ben", "und", "\u2013", "durch", "so", "viel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "KON", "$(", "APPR", "ADV", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Zimmer f\u00fchrend mich, da\u00df drinnen", "tokens": ["Zim\u00b7mer", "f\u00fch\u00b7rend", "mich", ",", "da\u00df", "drin\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVPP", "PPER", "$,", "KOUS", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Tausend Ober-Mufti's mind'stens", "tokens": ["Tau\u00b7send", "O\u00b7ber\u00b7Muf\u00b7ti's", "min\u00b7d'\u00b7stens"], "token_info": ["word", "word", "word"], "pos": ["CARD", "NE", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Platz gehabt \u2013 vor meinem Auge", "tokens": ["Platz", "ge\u00b7habt", "\u2013", "vor", "mei\u00b7nem", "Au\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAPP", "$(", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Des Pallastes der \u00bbEntbehrung\u00ab", "tokens": ["Des", "Pal\u00b7las\u00b7tes", "der", "\u00bb", "Ent\u00b7beh\u00b7rung", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "$(", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Glanz und Luxus zu entfalten.", "tokens": ["Glanz", "und", "Lu\u00b7xus", "zu", "ent\u00b7fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Mehr jedoch als all' die Speise-,", "tokens": ["Mehr", "je\u00b7doch", "als", "all'", "die", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOUS", "PIS", "ART", "TRUNC", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Spiel-, Empfangs-, Rauch-, Wonne-, Bade-,", "tokens": ["Spiel", ",", "Emp\u00b7fangs", ",", "Rauch", ",", "Won\u00b7ne", ",", "Ba\u00b7de", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["TRUNC", "$,", "TRUNC", "$,", "TRUNC", "$,", "TRUNC", "$,", "TRUNC", "$,"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.11": {"text": "Tanz-Appartements und and're", "tokens": ["Tanz\u00b7Ap\u00b7par\u00b7te\u00b7ments", "und", "an\u00b7d'\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "ADJA"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.12": {"text": "Klein're, machte mich erstaunen", "tokens": ["Klein'\u00b7re", ",", "mach\u00b7te", "mich", "er\u00b7stau\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "VVFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Die Bibliothek hier, welche", "tokens": ["Die", "Bib\u00b7lio\u00b7thek", "hier", ",", "wel\u00b7che"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ADV", "$,", "PRELS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Dreizehntausend B\u00e4nde z\u00e4hlte,", "tokens": ["Drei\u00b7zehn\u00b7tau\u00b7send", "B\u00e4n\u00b7de", "z\u00e4hl\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Aber w\u00f6rtlich auch nur ", "tokens": ["A\u00b7ber", "w\u00f6rt\u00b7lich", "auch", "nur"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADV", "ADV"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.16": {"text": "Nur die reichen, goldverzierten,", "tokens": ["Nur", "die", "rei\u00b7chen", ",", "gold\u00b7ver\u00b7zier\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Inhaltslosen Deckelpappen", "tokens": ["In\u00b7halts\u00b7lo\u00b7sen", "De\u00b7ckel\u00b7pap\u00b7pen"], "token_info": ["word", "word"], "pos": ["NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Mit den Titeln aller Werke", "tokens": ["Mit", "den", "Ti\u00b7teln", "al\u00b7ler", "Wer\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Aller Dichter und Gelehrten", "tokens": ["Al\u00b7ler", "Dich\u00b7ter", "und", "Ge\u00b7lehr\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Dieses Sternes, des Verkehrten!", "tokens": ["Die\u00b7ses", "Ster\u00b7nes", ",", "des", "Ver\u00b7kehr\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbwas staunt\u00ab, sprach mein F\u00fchrer, \u00bb\u00fcber", "tokens": ["\u00bb", "was", "staunt", "\u00ab", ",", "sprach", "mein", "F\u00fch\u00b7rer", ",", "\u00bb", "\u00fc\u00b7ber"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "PWS", "VVFIN", "$(", "$,", "VVFIN", "PPOSAT", "NN", "$,", "$(", "APPR"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Diese Staats-Oekonomie Ihr?", "tokens": ["Die\u00b7se", "Staats\u00b7Oe\u00b7ko\u00b7no\u00b7mie", "Ihr", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sie erf\u00fcllt den Zweck vollkommen", "tokens": ["Sie", "er\u00b7f\u00fcllt", "den", "Zweck", "voll\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zier und Catalog zu sein.", "tokens": ["Zier", "und", "Ca\u00b7ta\u00b7log", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Will, was mich nicht oft anlaunet,", "tokens": ["Will", ",", "was", "mich", "nicht", "oft", "an\u00b7lau\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PWS", "PPER", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ich ein Werk der S\u00fcnder lesen,", "tokens": ["Ich", "ein", "Werk", "der", "S\u00fcn\u00b7der", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Die dem Volk das Licht verleihen,", "tokens": ["Die", "dem", "Volk", "das", "Licht", "ver\u00b7lei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Das des Gl\u00fcckes, des Gehorsams", "tokens": ["Das", "des", "Gl\u00fc\u00b7ckes", ",", "des", "Ge\u00b7hor\u00b7sams"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "ART", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Und der Demuth H\u00fctte ansteckt:", "tokens": ["Und", "der", "De\u00b7muth", "H\u00fct\u00b7te", "an\u00b7steckt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VVFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "Sende ich des Werkes Einband", "tokens": ["Sen\u00b7de", "ich", "des", "Wer\u00b7kes", "Ein\u00b7band"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "NN", "NN"], "meter": "+-+-+-++", "measure": "unknown.measure.penta"}, "line.11": {"text": "Nach der Leihbibliothek hin;", "tokens": ["Nach", "der", "Leih\u00b7bib\u00b7lio\u00b7thek", "hin", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "La\u00df' ihn mit dem Buche f\u00fcllen", "tokens": ["La\u00df'", "ihn", "mit", "dem", "Bu\u00b7che", "f\u00fcl\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Den sein Titel heischt und les' es", "tokens": ["Den", "sein", "Ti\u00b7tel", "heischt", "und", "les'", "es"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "KON", "VVIMP", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "F\u00fcr ein Hunderttheil des Preises", "tokens": ["F\u00fcr", "ein", "Hun\u00b7dert\u00b7theil", "des", "Prei\u00b7ses"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Den es selbst mir kosten w\u00fcrde.\u00ab", "tokens": ["Den", "es", "selbst", "mir", "kos\u00b7ten", "w\u00fcr\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPER", "ADV", "PPER", "VVINF", "VAFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbaber ...\u00ab", "tokens": ["\u00bb", "a\u00b7ber", "...", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "ADV", "$(", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "\u00bbund wie ich, so handelt", "tokens": ["\u00bb", "und", "wie", "ich", ",", "so", "han\u00b7delt"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "KON", "PWAV", "PPER", "$,", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alles, was zur fashionablen", "tokens": ["Al\u00b7les", ",", "was", "zur", "fa\u00b7shi\u00b7o\u00b7nab\u00b7len"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "APPRART", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Welt geh\u00f6rt, was wahrhaft vornehm.", "tokens": ["Welt", "ge\u00b7h\u00f6rt", ",", "was", "wahr\u00b7haft", "vor\u00b7nehm", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PRELS", "ADV", "ADJD", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Nur der dumme Plebs sucht, hi, hi!", "tokens": ["Nur", "der", "dum\u00b7me", "Plebs", "sucht", ",", "hi", ",", "hi", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$,", "VVFIN", "$,", "ITJ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Seine Ehre drinn, so weit es,", "tokens": ["Sei\u00b7ne", "Eh\u00b7re", "drinn", ",", "so", "weit", "es", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,", "ADV", "ADJD", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Noth und D\u00fcrftigkeit gestatten,", "tokens": ["Noth", "und", "D\u00fcrf\u00b7tig\u00b7keit", "ge\u00b7stat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Seiner Dichter und Gelehrten", "tokens": ["Sei\u00b7ner", "Dich\u00b7ter", "und", "Ge\u00b7lehr\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Werke zu besitzen eigens,", "tokens": ["Wer\u00b7ke", "zu", "be\u00b7sit\u00b7zen", "ei\u00b7gens", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "ADV", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Hochzuachten und Bed\u00fcrfni\u00df;", "tokens": ["Hoch\u00b7zu\u00b7ach\u00b7ten", "und", "Be\u00b7d\u00fcrf\u00b7ni\u00df", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Gleichen Dank zu zollen Ihm,", "tokens": ["Glei\u00b7chen", "Dank", "zu", "zol\u00b7len", "Ihm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKZU", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Ihm, der, wie der Plebs sich ausdr\u00fcckt:", "tokens": ["Ihm", ",", "der", ",", "wie", "der", "Plebs", "sich", "aus\u00b7dr\u00fcckt", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "$,", "PWAV", "ART", "NN", "PRF", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.13": {"text": "Unsre Seele tr\u00f6stet, lichtet,", "tokens": ["Uns\u00b7re", "See\u00b7le", "tr\u00f6s\u00b7tet", ",", "lich\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Reinigt, aufschwingt, Heil und Wonne", "tokens": ["Rei\u00b7nigt", ",", "auf\u00b7schwingt", ",", "Heil", "und", "Won\u00b7ne"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Ihr erstreitet und bereitet", "tokens": ["Ihr", "er\u00b7strei\u00b7tet", "und", "be\u00b7rei\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVPP", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Und, gleichwie die Gottessonne,", "tokens": ["Und", ",", "gleich\u00b7wie", "die", "Got\u00b7tes\u00b7son\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KON", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.17": {"text": "Segen \u00fcberall verbreitet.", "tokens": ["Se\u00b7gen", "\u00fc\u00b7be\u00b7rall", "ver\u00b7brei\u00b7tet", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ja, er schilt Diejen'gen P\u00f6bel,", "tokens": ["Ja", ",", "er", "schilt", "Die\u00b7jen'\u00b7gen", "P\u00f6\u00b7bel", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die f\u00fcr Hunde, Pferde, Affen,", "tokens": ["Die", "f\u00fcr", "Hun\u00b7de", ",", "Pfer\u00b7de", ",", "Af\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Flitterkram und Schwelgereien", "tokens": ["Flit\u00b7ter\u00b7kram", "und", "Schwel\u00b7ge\u00b7rei\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tausend Mal wohl mehr verprassen", "tokens": ["Tau\u00b7send", "Mal", "wohl", "mehr", "ver\u00b7pras\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als f\u00fcr Dichterwerke j\u00e4hrlich!", "tokens": ["Als", "f\u00fcr", "Dich\u00b7ter\u00b7wer\u00b7ke", "j\u00e4hr\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Tausend Mal mehr f\u00fcr ihr Fressen", "tokens": ["Tau\u00b7send", "Mal", "mehr", "f\u00fcr", "ihr", "Fres\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Als f\u00fcr geist'ge Nahrung zahlen,", "tokens": ["Als", "f\u00fcr", "geist'\u00b7ge", "Nah\u00b7rung", "zah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Die sie borgen statt zu kaufen!", "tokens": ["Die", "sie", "bor\u00b7gen", "statt", "zu", "kau\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Ja, er stellt dabei ein Gleichni\u00df", "tokens": ["Ja", ",", "er", "stellt", "da\u00b7bei", "ein", "Gleich\u00b7ni\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PAV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Auf von angelieh'ner Nahrung,", "tokens": ["Auf", "von", "an\u00b7ge\u00b7lieh'\u00b7ner", "Nah\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Die, genossen kaum, verborgt wird", "tokens": ["Die", ",", "ge\u00b7nos\u00b7sen", "kaum", ",", "ver\u00b7borgt", "wird"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "$,", "VVPP", "ADV", "$,", "VVPP", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Und, pfui! wiederum genossen", "tokens": ["Und", ",", "pfui", "!", "wie\u00b7de\u00b7rum", "ge\u00b7nos\u00b7sen"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "$,", "ITJ", "$.", "ADV", "VVPP"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "Und verborgt wird und genossen", "tokens": ["Und", "ver\u00b7borgt", "wird", "und", "ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVPP", "VAFIN", "KON", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Und so fort, ein Gleichni\u00df, pfui, pfui!", "tokens": ["Und", "so", "fort", ",", "ein", "Gleich\u00b7ni\u00df", ",", "pfui", ",", "pfui", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "$,", "ART", "NN", "$,", "ITJ", "$,", "ITJ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.15": {"text": "So abscheulich, da\u00df kaum ", "tokens": ["So", "ab\u00b7scheu\u00b7lich", ",", "da\u00df", "kaum"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Es app'titlich finden k\u00f6nnten!\u00ab", "tokens": ["Es", "ap\u00b7p'\u00b7tit\u00b7lich", "fin\u00b7den", "k\u00f6nn\u00b7ten", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADJD", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Unter diesen Worten waren", "tokens": ["Un\u00b7ter", "die\u00b7sen", "Wor\u00b7ten", "wa\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Angelangt wir in des Mufti's", "tokens": ["An\u00b7ge\u00b7langt", "wir", "in", "des", "Muf\u00b7ti's"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ob es gleich, von violetter", "tokens": ["Ob", "es", "gleich", ",", "von", "vi\u00b7o\u00b7let\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "$,", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fenster-Draperie ged\u00fcstert,", "tokens": ["Fens\u00b7ter\u00b7Dra\u00b7pe\u00b7rie", "ge\u00b7d\u00fcs\u00b7tert", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weder Pult, Repositorium", "tokens": ["We\u00b7der", "Pult", ",", "Re\u00b7po\u00b7si\u00b7to\u00b7ri\u00b7um"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "NN", "$,", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Noch Papierkorb, Pfeifenriegel", "tokens": ["Noch", "Pa\u00b7pier\u00b7korb", ",", "Pfei\u00b7fen\u00b7rie\u00b7gel"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und dergleichen aufwies, sondern", "tokens": ["Und", "derg\u00b7lei\u00b7chen", "auf\u00b7wies", ",", "son\u00b7dern"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "PIS", "VVFIN", "$,", "KON"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Einen gro\u00dfen Frauenspiegel,", "tokens": ["Ei\u00b7nen", "gro\u00b7\u00dfen", "Frau\u00b7en\u00b7spie\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Schilderein und Nippes-Capricen,", "tokens": ["Schil\u00b7de\u00b7rein", "und", "Nip\u00b7pes\u00b7Ca\u00b7pri\u00b7cen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Die auf keinen hypochondern", "tokens": ["Die", "auf", "kei\u00b7nen", "hy\u00b7po\u00b7chon\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Eigner eben schlie\u00dfen lie\u00dfen,", "tokens": ["Eig\u00b7ner", "e\u00b7ben", "schlie\u00b7\u00dfen", "lie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Und ein seiden Himmelsbette,", "tokens": ["Und", "ein", "sei\u00b7den", "Him\u00b7mels\u00b7bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.13": {"text": "Ueppig breit, nebst Toilette.", "tokens": ["Uep\u00b7pig", "breit", ",", "nebst", "To\u00b7i\u00b7let\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbg\u00f6tter!\u00ab rief ich aus, \u00bbWas seh' ich?\u00ab", "tokens": ["\u00bb", "g\u00f6t\u00b7ter", "!", "\u00ab", "rief", "ich", "aus", ",", "\u00bb", "Was", "seh'", "ich", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$.", "$(", "VVFIN", "PPER", "PTKVZ", "$,", "$(", "PWS", "VVFIN", "PPER", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als ich pl\u00f6tzlich, nah' am Fenster,", "tokens": ["Als", "ich", "pl\u00f6tz\u00b7lich", ",", "nah'", "am", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "$,", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eingerahmt in goldner Leistung,", "tokens": ["Ein\u00b7ge\u00b7rahmt", "in", "gold\u00b7ner", "Leis\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meiner Gattin, meiner reizend-", "tokens": ["Mei\u00b7ner", "Gat\u00b7tin", ",", "mei\u00b7ner", "rei\u00b7zen\u00b7d"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "TRUNC"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Sch\u00f6nen Lilialinda's Brustbild,", "tokens": ["Sch\u00f6\u00b7nen", "Li\u00b7li\u00b7a\u00b7lin\u00b7da's", "Brust\u00b7bild", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Ausgef\u00fchrt sehr gut in Essig,", "tokens": ["Aus\u00b7ge\u00b7f\u00fchrt", "sehr", "gut", "in", "Es\u00b7sig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPR", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Hier gewahr ward. \u00bbG\u00f6tter! Himmel!\u00ab", "tokens": ["Hier", "ge\u00b7wahr", "ward", ".", "\u00bb", "G\u00f6t\u00b7ter", "!", "Him\u00b7mel", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$.", "$(", "NN", "$.", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Aber eh' ich selbst es konnte,", "tokens": ["A\u00b7ber", "eh'", "ich", "selbst", "es", "konn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hatte, zornig-wilden Blickes,", "tokens": ["Hat\u00b7te", ",", "zor\u00b7nig\u00b7wil\u00b7den", "Bli\u00b7ckes", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lumpel-Lampel mich gefa\u00dft schon,", "tokens": ["Lum\u00b7pel\u00b7Lam\u00b7pel", "mich", "ge\u00b7fa\u00dft", "schon", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und zwar grade vor dem Busen", "tokens": ["Und", "zwar", "gra\u00b7de", "vor", "dem", "Bu\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unter welchem, ach, mein liebend", "tokens": ["Un\u00b7ter", "wel\u00b7chem", ",", "ach", ",", "mein", "lie\u00b7bend"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "PWAT", "$,", "ITJ", "$,", "PPOSAT", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Herz so st\u00fcrmisch klopfte:", "tokens": ["Herz", "so", "st\u00fcr\u00b7misch", "klopf\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "\u00bbbube!\u00ab", "tokens": ["\u00bb", "bu\u00b7be", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.8": {"text": "Rief er (Als ich dieses Ausdrucks", "tokens": ["Rief", "er", "(", "Als", "ich", "die\u00b7ses", "Aus\u00b7drucks"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$(", "KOUS", "PPER", "PDAT", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Wegen sp\u00e4ter ", "tokens": ["We\u00b7gen", "sp\u00e4\u00b7ter"], "token_info": ["word", "word"], "pos": ["APPR", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "Ihn belangte und der Richter \u2013 \u2013", "tokens": ["Ihn", "be\u00b7lang\u00b7te", "und", "der", "Rich\u00b7ter", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "KON", "ART", "NN", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "In Erw\u00e4gung, da\u00df zwar \u00bbBube\u00ab", "tokens": ["In", "Er\u00b7w\u00e4\u00b7gung", ",", "da\u00df", "zwar", "\u00bb", "Bu\u00b7be", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUS", "ADV", "$(", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "An und f\u00fcr sich nicht beleid'gend,", "tokens": ["An", "und", "f\u00fcr", "sich", "nicht", "be\u00b7lei\u00b7d'\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KON", "APPR", "PRF", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.13": {"text": "Da er oft sowohl von M\u00e4dchen", "tokens": ["Da", "er", "oft", "so\u00b7wohl", "von", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Wie von Dichtern schelmisch-freundlich", "tokens": ["Wie", "von", "Dich\u00b7tern", "schel\u00b7mischfreund\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPR", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Angewendet w\u00e4r' und w\u00fcrde,", "tokens": ["An\u00b7ge\u00b7wen\u00b7det", "w\u00e4r'", "und", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "KON", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Auch im Kartenspiele eine", "tokens": ["Auch", "im", "Kar\u00b7ten\u00b7spie\u00b7le", "ei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPRART", "NN", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Respectabele Figur sei,", "tokens": ["Res\u00b7pec\u00b7ta\u00b7be\u00b7le", "Fi\u00b7gur", "sei", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.18": {"text": "Welche von dem Sultan (K\u00f6nig)", "tokens": ["Wel\u00b7che", "von", "dem", "Sul\u00b7tan", "(", "K\u00f6\u00b7nig", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAT", "APPR", "ART", "NN", "$(", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Durch die Mittelspersonnage,", "tokens": ["Durch", "die", "Mit\u00b7tel\u00b7sper\u00b7son\u00b7na\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Durch die Dame, nur getrennt sei,", "tokens": ["Durch", "die", "Da\u00b7me", ",", "nur", "ge\u00b7trennt", "sei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Der Herr Ober-Mufti aber", "tokens": ["Der", "Herr", "O\u00b7ber\u00b7Muf\u00b7ti", "a\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Weder M\u00e4dchen sei noch Dichter", "tokens": ["We\u00b7der", "M\u00e4d\u00b7chen", "sei", "noch", "Dich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "ADV", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Noch der Kl\u00e4ger eine Karte; \u2013", "tokens": ["Noch", "der", "Kl\u00e4\u00b7ger", "ei\u00b7ne", "Kar\u00b7te", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.24": {"text": "Und in fernerer Erw\u00e4gung,", "tokens": ["Und", "in", "fer\u00b7ne\u00b7rer", "Er\u00b7w\u00e4\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.25": {"text": "Da\u00df bereits der Kl\u00e4ger faktisch", "tokens": ["Da\u00df", "be\u00b7reits", "der", "Kl\u00e4\u00b7ger", "fak\u00b7tisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.26": {"text": "In den sogenannten besten", "tokens": ["In", "den", "so\u00b7ge\u00b7nann\u00b7ten", "bes\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.27": {"text": "Jahren so weit vorger\u00fccket", "tokens": ["Jah\u00b7ren", "so", "weit", "vor\u00b7ge\u00b7r\u00fc\u00b7cket"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ADJD", "VVFIN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.28": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.29": {"text": "Sehr bedenklich w\u00fcrde, ", "tokens": ["Sehr", "be\u00b7denk\u00b7lich", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.30": {"text": "Des hochzopf'gen Angeklagten", "tokens": ["Des", "hoch\u00b7zopf'\u00b7gen", "An\u00b7ge\u00b7klag\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.31": {"text": "Einwand: Kl\u00e4ger h\u00e4tt' durch seinen", "tokens": ["Ein\u00b7wand", ":", "Kl\u00e4\u00b7ger", "h\u00e4tt'", "durch", "sei\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "NE", "VAFIN", "APPR", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.32": {"text": "Tugendhaften Lebenswandel", "tokens": ["Tu\u00b7gend\u00b7haf\u00b7ten", "Le\u00b7bens\u00b7wan\u00b7del"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.33": {"text": "So vortrefflich conservirt sich,", "tokens": ["So", "vor\u00b7treff\u00b7lich", "con\u00b7ser\u00b7virt", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PRF", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.34": {"text": "Da\u00df er, Kl\u00e4ger, ihn f\u00fcr einen", "tokens": ["Da\u00df", "er", ",", "Kl\u00e4\u00b7ger", ",", "ihn", "f\u00fcr", "ei\u00b7nen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "NN", "$,", "PPER", "APPR", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.35": {"text": "J\u00fcngeling gehalten h\u00e4tte:", "tokens": ["J\u00fcn\u00b7ge\u00b7ling", "ge\u00b7hal\u00b7ten", "h\u00e4t\u00b7te", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.36": {"text": "Platz nicht greifen kann, vielmehro", "tokens": ["Platz", "nicht", "grei\u00b7fen", "kann", ",", "viel\u00b7meh\u00b7ro"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "PTKNEG", "VVINF", "VMFIN", "$,", "ADV"], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}, "line.37": {"text": "(dieser Schreibefehler schlich sich", "tokens": ["(", "die\u00b7ser", "Schrei\u00b7be\u00b7feh\u00b7ler", "schlich", "sich"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "PDAT", "NN", "ADJD", "PRF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.38": {"text": "Beim Mundiren ein) dabei nicht", "tokens": ["Beim", "Mun\u00b7di\u00b7ren", "ein", ")", "da\u00b7bei", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "ART", "$(", "PAV", "PTKNEG"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.39": {"text": "Zu verkennen, doch der Ausdruck", "tokens": ["Zu", "ver\u00b7ken\u00b7nen", ",", "doch", "der", "Aus\u00b7druck"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "ADV", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.40": {"text": "\u00bbbube\u00ab als ", "tokens": ["\u00bb", "bu\u00b7be", "\u00ab", "als"], "token_info": ["punct", "word", "punct", "word"], "pos": ["$(", "NN", "$(", "KOUS"], "meter": "+-+", "measure": "trochaic.di"}, "line.41": {"text": "Nur zu nehmen \u2013 nach dem eilften", "tokens": ["Nur", "zu", "neh\u00b7men", "\u2013", "nach", "dem", "eilf\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PTKZU", "VVINF", "$(", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.42": {"text": "Paragraphen, Titel Sieben", "tokens": ["Pa\u00b7ra\u00b7gra\u00b7phen", ",", "Ti\u00b7tel", "Sie\u00b7ben"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.43": {"text": "Des Neunzehnten Theils des", "tokens": ["Des", "Neun\u00b7zehn\u00b7ten", "Theils", "des"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.44": {"text": "Allgemeinen Sultan-Rechtes:", "tokens": ["All\u00b7ge\u00b7mei\u00b7nen", "Sul\u00b7tan\u00b7Rech\u00b7tes", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.45": {"text": "Zu der Zahlung von Dreihundert", "tokens": ["Zu", "der", "Zah\u00b7lung", "von", "Drei\u00b7hun\u00b7dert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "CARD"], "meter": "--+--++-", "measure": "anapaest.di.plus"}, "line.46": {"text": "Gold'ner Scudi's an den Fiscus", "tokens": ["Gold'\u00b7ner", "Scu\u00b7di's", "an", "den", "Fis\u00b7cus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.47": {"text": "Und der Kosten \u2013 \u2013 condemnirt ihn,", "tokens": ["Und", "der", "Kos\u00b7ten", "\u2013", "\u2013", "con\u00b7dem\u00b7nirt", "ihn", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$(", "$(", "VVFIN", "PPER", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.48": {"text": "Wurde Lumpel-Lampeln auf sein", "tokens": ["Wur\u00b7de", "Lum\u00b7pel\u00b7Lam\u00b7peln", "auf", "sein"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "NN", "APPR", "PPOSAT"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.49": {"text": "Immediat-Gesuch vom Sultan", "tokens": ["Im\u00b7me\u00b7diat\u00b7Ge\u00b7such", "vom", "Sul\u00b7tan"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.50": {"text": "Pumpel-Pampel es verziehen,", "tokens": ["Pum\u00b7pel\u00b7Pam\u00b7pel", "es", "ver\u00b7zie\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.51": {"text": "Da\u00df er ", "tokens": ["Da\u00df", "er"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.52": {"text": "Kosten wurden, (was ich selbst war", "tokens": ["Kos\u00b7ten", "wur\u00b7den", ",", "(", "was", "ich", "selbst", "war"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "$,", "$(", "PWS", "PPER", "ADV", "VAFIN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.53": {"text": "Ueber diese wunderbare", "tokens": ["Ue\u00b7ber", "die\u00b7se", "wun\u00b7der\u00b7ba\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.54": {"text": "Gnade und, wie soll ich sagen:", "tokens": ["Gna\u00b7de", "und", ",", "wie", "soll", "ich", "sa\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "$,", "PWAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "\u00bbbube!\u00ab rief er, meines Schreckens", "tokens": ["\u00bb", "bu\u00b7be", "!", "\u00ab", "rief", "er", ",", "mei\u00b7nes", "Schre\u00b7ckens"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "VVFIN", "$.", "$(", "VVFIN", "PPER", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bl\u00e4sse f\u00fcr die Farbe eines", "tokens": ["Bl\u00e4s\u00b7se", "f\u00fcr", "die", "Far\u00b7be", "ei\u00b7nes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schuldbewu\u00dftseins nehmend, \u00bbBube!", "tokens": ["Schuld\u00b7be\u00b7wu\u00dfts\u00b7eins", "neh\u00b7mend", ",", "\u00bb", "Bu\u00b7be", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "VVPP", "$,", "$(", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lilialinda, Deine Gattin,", "tokens": ["Li\u00b7li\u00b7a\u00b7lin\u00b7da", ",", "Dei\u00b7ne", "Gat\u00b7tin", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Sprich, wo ist sie? Sicher wei\u00dft Du's!", "tokens": ["Sprich", ",", "wo", "ist", "sie", "?", "Si\u00b7cher", "wei\u00dft", "Du's", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PWAV", "VAFIN", "PPER", "$.", "ADV", "VVFIN", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Sicher hast Du diese sch\u00f6nste,", "tokens": ["Si\u00b7cher", "hast", "Du", "die\u00b7se", "sch\u00f6ns\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Diese k\u00f6stlichste von allen", "tokens": ["Die\u00b7se", "k\u00f6st\u00b7lichs\u00b7te", "von", "al\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "APPR", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Blumen meines C\u00f6libates", "tokens": ["Blu\u00b7men", "mei\u00b7nes", "C\u00f6\u00b7li\u00b7ba\u00b7tes"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Frech geraubt mir! Hast zur Flucht sie", "tokens": ["Frech", "ge\u00b7raubt", "mir", "!", "Hast", "zur", "Flucht", "sie"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVPP", "PPER", "$.", "VAFIN", "APPRART", "NN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Ueberredet, vor ihr spiegelnd", "tokens": ["Ue\u00b7ber\u00b7re\u00b7det", ",", "vor", "ihr", "spie\u00b7gelnd"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "APPR", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Als ob pl\u00f6tzlich nun entflammt sei", "tokens": ["Als", "ob", "pl\u00f6tz\u00b7lich", "nun", "ent\u00b7flammt", "sei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "ADJD", "ADV", "VVPP", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Lieb' f\u00fcr sie in Deinem Herzen,", "tokens": ["Lieb'", "f\u00fcr", "sie", "in", "Dei\u00b7nem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Gegenliebe f\u00fcr die Holde,", "tokens": ["Ge\u00b7gen\u00b7lie\u00b7be", "f\u00fcr", "die", "Hol\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Die, \u00e4cht weiblich, unschuldvoll", "tokens": ["Die", ",", "\u00e4cht", "weib\u00b7lich", ",", "un\u00b7schuld\u00b7voll"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "$,", "ADJD", "ADJD", "$,", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Sich zu Deinem ", "tokens": ["Sich", "zu", "Dei\u00b7nem"], "token_info": ["word", "word", "word"], "pos": ["PRF", "APPR", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.16": {"text": "Zur Geliebten angetragen,", "tokens": ["Zur", "Ge\u00b7lieb\u00b7ten", "an\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Und die Du, statt hinzusinken", "tokens": ["Und", "die", "Du", ",", "statt", "hin\u00b7zu\u00b7sin\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "PPER", "$,", "KOUI", "VVIZU"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Gl\u00fcckbet\u00e4ubt zu ihren F\u00fc\u00dfen,", "tokens": ["Gl\u00fcck\u00b7be\u00b7t\u00e4ubt", "zu", "ih\u00b7ren", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Der Du werth nicht bist, vom Schatten", "tokens": ["Der", "Du", "werth", "nicht", "bist", ",", "vom", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PPER", "ADJD", "PTKNEG", "VAFIN", "$,", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Dieser F\u00fc\u00dfe nur zu tr\u00e4umen,", "tokens": ["Die\u00b7ser", "F\u00fc\u00b7\u00dfe", "nur", "zu", "tr\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Grausam Dir antrauen lie\u00dfest!", "tokens": ["Grau\u00b7sam", "Dir", "an\u00b7trau\u00b7en", "lie\u00b7\u00dfest", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Ihre Liebesgluth verlachend", "tokens": ["Ih\u00b7re", "Lie\u00b7bes\u00b7gluth", "ver\u00b7la\u00b7chend"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Und zu Deiner ", "tokens": ["Und", "zu", "Dei\u00b7ner"], "token_info": ["word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.24": {"text": "Frech und schn\u00f6de sie verstie\u00dfest!\u00ab", "tokens": ["Frech", "und", "schn\u00f6\u00b7de", "sie", "ver\u00b7stie\u00b7\u00dfest", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "VVFIN", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Ich betheuerte bei ", "tokens": ["Ich", "be\u00b7theu\u00b7er\u00b7te", "bei"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und den Heideng\u00f6ttern allen,", "tokens": ["Und", "den", "Hei\u00b7den\u00b7g\u00f6t\u00b7tern", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Selbst bei ", "tokens": ["Selbst", "bei"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Und bei ", "tokens": ["Und", "bei"], "token_info": ["word", "word"], "pos": ["KON", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Da\u00df an meiner Gattin, meiner", "tokens": ["Da\u00df", "an", "mei\u00b7ner", "Gat\u00b7tin", ",", "mei\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "$,", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hei\u00dfgeliebten Lilialinda,", "tokens": ["Hei\u00df\u00b7ge\u00b7lieb\u00b7ten", "Li\u00b7li\u00b7a\u00b7lin\u00b7da", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Flucht ich schuldlos, schwor dem Mufti,", "tokens": ["Flucht", "ich", "schuld\u00b7los", ",", "schwor", "dem", "Muf\u00b7ti", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Seit dem Augenblick der Trennung", "tokens": ["Seit", "dem", "Au\u00b7gen\u00b7blick", "der", "Tren\u00b7nung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Sie mit keinem Aug' gesehen,", "tokens": ["Sie", "mit", "kei\u00b7nem", "Aug'", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Sie mit keinem Mund gesprochen", "tokens": ["Sie", "mit", "kei\u00b7nem", "Mund", "ge\u00b7spro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "PIAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Und mit keiner Hand geschrieben", "tokens": ["Und", "mit", "kei\u00b7ner", "Hand", "ge\u00b7schrie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Ihr zu haben, also auch durch", "tokens": ["Ihr", "zu", "ha\u00b7ben", ",", "al\u00b7so", "auch", "durch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "PTKZU", "VAINF", "$,", "ADV", "ADV", "APPR"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.13": {"text": "Dritter Auge, Mund und Hand nicht.", "tokens": ["Drit\u00b7ter", "Au\u00b7ge", ",", "Mund", "und", "Hand", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "KON", "NN", "PTKNEG", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Schwor ihm, da\u00df er selbst es w\u00e4re,", "tokens": ["Schwor", "ihm", ",", "da\u00df", "er", "selbst", "es", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "KOUS", "PPER", "ADV", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Der mir ihre Flucht aus seinem", "tokens": ["Der", "mir", "ih\u00b7re", "Flucht", "aus", "sei\u00b7nem"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PPOSAT", "NN", "APPR", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Harem oder C\u00f6libate,", "tokens": ["Ha\u00b7rem", "o\u00b7der", "C\u00f6\u00b7li\u00b7ba\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Wie er's nenn', zuerst verk\u00fcnde.", "tokens": ["Wie", "er's", "nenn'", ",", "zu\u00b7erst", "ver\u00b7k\u00fcn\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "\u00bbund so,\u00ab endigte erhitzt ich,", "tokens": ["\u00bb", "und", "so", ",", "\u00ab", "en\u00b7dig\u00b7te", "er\u00b7hitzt", "ich", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "$,", "$(", "VVFIN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "\u00bbprallt der \u203aBube,\u2039 der auf meine", "tokens": ["\u00bb", "prallt", "der", "\u203a", "Bu\u00b7be", ",", "\u2039", "der", "auf", "mei\u00b7ne"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "ART", "ADJA", "NN", "$,", "$(", "ART", "APPR", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Schuldlos-starke Brust geworfen,", "tokens": ["Schuld\u00b7los\u00b7star\u00b7ke", "Brust", "ge\u00b7wor\u00b7fen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Auf den Werfenden zur\u00fcck nun,", "tokens": ["Auf", "den", "Wer\u00b7fen\u00b7den", "zu\u00b7r\u00fcck", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "ADV", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.22": {"text": "Der, wiewohl schon alter S\u00fcnder,", "tokens": ["Der", ",", "wie\u00b7wohl", "schon", "al\u00b7ter", "S\u00fcn\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Nicht einmal solch alter S\u00fcnder", "tokens": ["Nicht", "ein\u00b7mal", "solch", "al\u00b7ter", "S\u00fcn\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.24": {"text": "Einz'gen Vorzug sonst vor jungen", "tokens": ["Einz'\u00b7gen", "Vor\u00b7zug", "sonst", "vor", "jun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADV", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.25": {"text": "S\u00fcndern zeigte: Selbstbeherrschung!\u00ab", "tokens": ["S\u00fcn\u00b7dern", "zeig\u00b7te", ":", "Selbst\u00b7be\u00b7herr\u00b7schung", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "$.", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Rasend, mit giergl\u00fchnden Augen,", "tokens": ["Ra\u00b7send", ",", "mit", "gier\u00b7gl\u00fchn\u00b7den", "Au\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie das Lamm, wenn's Appetit hat,", "tokens": ["Wie", "das", "Lamm", ",", "wenn's", "Ap\u00b7pe\u00b7tit", "hat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "KOUS", "NN", "VAFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Auf den frommen Tiger losspringt,", "tokens": ["Auf", "den", "from\u00b7men", "Ti\u00b7ger", "los\u00b7springt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "St\u00fcrzte sich des G\u00f6tzenpriesters", "tokens": ["St\u00fcrz\u00b7te", "sich", "des", "G\u00f6t\u00b7zen\u00b7pries\u00b7ters"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zopfheit in Person auf mich und", "tokens": ["Zopf\u00b7heit", "in", "Per\u00b7son", "auf", "mich", "und"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "APPR", "PPER", "KON"], "meter": "+--+-++-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Zeigten deutlich dero Absicht,", "tokens": ["Zeig\u00b7ten", "deut\u00b7lich", "de\u00b7ro", "Ab\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PRELAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Das mir zu ertheilen, was man,", "tokens": ["Das", "mir", "zu", "er\u00b7thei\u00b7len", ",", "was", "man", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "PPER", "PTKZU", "VVINF", "$,", "PRELS", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Angewendet bei Personen,", "tokens": ["An\u00b7ge\u00b7wen\u00b7det", "bei", "Per\u00b7so\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Denen jeder ganz vern\u00fcnft'ge", "tokens": ["De\u00b7nen", "je\u00b7der", "ganz", "ver\u00b7n\u00fcnft'\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "PIS", "ADV", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Menschenfreund noch dreimal mehr w\u00fcnscht:", "tokens": ["Men\u00b7schen\u00b7freund", "noch", "drei\u00b7mal", "mehr", "w\u00fcnscht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.11": {"text": "Ausflu\u00df des Verr\u00fccktseins hei\u00dfet.", "tokens": ["Aus\u00b7flu\u00df", "des", "Ver\u00b7r\u00fcck\u00b7tseins", "hei\u00b7\u00dfet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Ich jedoch, nicht faul, ich ri\u00df ihn", "tokens": ["Ich", "je\u00b7doch", ",", "nicht", "faul", ",", "ich", "ri\u00df", "ihn"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "$,", "PTKNEG", "ADJD", "$,", "PPER", "VVFIN", "PPER"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "St\u00fcrmisch an mein Herze, pre\u00dfte", "tokens": ["St\u00fcr\u00b7misch", "an", "mein", "Her\u00b7ze", ",", "pre\u00df\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADJD", "APPR", "PPOSAT", "VVFIN", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Ihn inbr\u00fcnstiglich und klopfte,", "tokens": ["Ihn", "in\u00b7br\u00fcns\u00b7tig\u00b7lich", "und", "klopf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Ihn beruh'gend, ihm den R\u00fccken.", "tokens": ["Ihn", "be\u00b7ruh'\u00b7gend", ",", "ihm", "den", "R\u00fc\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Dann ergriff ich seine H\u00e4nde,", "tokens": ["Dann", "er\u00b7griff", "ich", "sei\u00b7ne", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hielt sie fest und sicher, blickte", "tokens": ["Hielt", "sie", "fest", "und", "si\u00b7cher", ",", "blick\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "ADJD", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fest und sicher ihm in's Auge,", "tokens": ["Fest", "und", "si\u00b7cher", "ihm", "in's", "Au\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nahm all meine Kraft zusammen", "tokens": ["Nahm", "all", "mei\u00b7ne", "Kraft", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und die angebor'ne Hoheit,", "tokens": ["Und", "die", "an\u00b7ge\u00b7bor'\u00b7ne", "Ho\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und sprach mit dem ganzen Adel,", "tokens": ["Und", "sprach", "mit", "dem", "gan\u00b7zen", "A\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Der mir zu Gebot steht, also:", "tokens": ["Der", "mir", "zu", "Ge\u00b7bot", "steht", ",", "al\u00b7so", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$,", "ADV", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "\u00bbwei\u00dft Du, Mufti, ", "tokens": ["\u00bb", "wei\u00dft", "Du", ",", "Muf\u00b7ti", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Wei\u00dft Du, Knirps, auf wen Du wolltest,", "tokens": ["Wei\u00dft", "Du", ",", "Knirps", ",", "auf", "wen", "Du", "woll\u00b7test", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "APPR", "PWS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Ich bin nicht nur ", "tokens": ["Ich", "bin", "nicht", "nur"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Ich, Ernst Heiter, Erst und Einz'ger,", "tokens": ["Ich", ",", "Ernst", "Hei\u00b7ter", ",", "Erst", "und", "Einz'\u00b7ger", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NE", "NE", "$,", "ADV", "KON", "NN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Bin erhaben \u00fcber Vieles!", "tokens": ["Bin", "er\u00b7ha\u00b7ben", "\u00fc\u00b7ber", "Vie\u00b7les", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bin ein F\u00fcrst, mit dem die Kaiser", "tokens": ["Bin", "ein", "F\u00fcrst", ",", "mit", "dem", "die", "Kai\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "APPR", "PRELS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "China's, Ru\u00dflands und Marokko's.", "tokens": ["China's", ",", "Ru\u00df\u00b7lands", "und", "Ma\u00b7rok\u00b7ko'", "s."], "token_info": ["word", "punct", "word", "word", "word", "abbreviation"], "pos": ["NE", "$,", "NE", "KON", "NE", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Nimmermehr sich messen werden!", "tokens": ["Nim\u00b7mer\u00b7mehr", "sich", "mes\u00b7sen", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Zwischen diesem, dem Verkehrten", "tokens": ["Zwi\u00b7schen", "die\u00b7sem", ",", "dem", "Ver\u00b7kehr\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "PDAT", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Weltchen und dem hochvern\u00fcnft'gen", "tokens": ["Welt\u00b7chen", "und", "dem", "hoch\u00b7ver\u00b7n\u00fcnft'\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Sterne Erde hab' ich Schl\u00f6sser", "tokens": ["Ster\u00b7ne", "Er\u00b7de", "hab'", "ich", "Schl\u00f6s\u00b7ser"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "VAFIN", "PPER", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Eine Unzahl und viel pr\u00e4cht'ger", "tokens": ["Ei\u00b7ne", "Un\u00b7zahl", "und", "viel", "pr\u00e4cht'\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Als Du, Mufti, Dir kannst denken!", "tokens": ["Als", "Du", ",", "Muf\u00b7ti", ",", "Dir", "kannst", "den\u00b7ken", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "NN", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Das Gebiet, das sch\u00f6ne, reiche", "tokens": ["Das", "Ge\u00b7biet", ",", "das", "sch\u00f6\u00b7ne", ",", "rei\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Deutscher Zunge ist das meine!", "tokens": ["Deut\u00b7scher", "Zun\u00b7ge", "ist", "das", "mei\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PDS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Und im Reiche der Humoren,", "tokens": ["Und", "im", "Rei\u00b7che", "der", "Hu\u00b7mo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NE", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Wie in jenem zaubervollen,", "tokens": ["Wie", "in", "je\u00b7nem", "zau\u00b7ber\u00b7vol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Himmlischen, de\u00df Blum' und Fr\u00fcchte", "tokens": ["Himm\u00b7li\u00b7schen", ",", "de\u00df", "Blum'", "und", "Fr\u00fcch\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Man vom heiligen Parnassus", "tokens": ["Man", "vom", "hei\u00b7li\u00b7gen", "Par\u00b7nas\u00b7sus"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "APPRART", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.18": {"text": "Ueberschaut, bin ich, Ernst Heiter,", "tokens": ["Ue\u00b7ber\u00b7schaut", ",", "bin", "ich", ",", "Ernst", "Hei\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "VAFIN", "PPER", "$,", "NE", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Wenn auch oft nicht Selbstbeherrscher,", "tokens": ["Wenn", "auch", "oft", "nicht", "Selbst\u00b7be\u00b7herr\u00b7scher", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PTKNEG", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Doch so m\u00e4chtig und gebietend,", "tokens": ["Doch", "so", "m\u00e4ch\u00b7tig", "und", "ge\u00b7bie\u00b7tend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "KON", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Da\u00df, gleichwie der Gott der G\u00f6tter", "tokens": ["Da\u00df", ",", "gleich\u00b7wie", "der", "Gott", "der", "G\u00f6t\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Und mit ihm Dich, alle Mufti's", "tokens": ["Und", "mit", "ihm", "Dich", ",", "al\u00b7le", "Muf\u00b7ti's"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "PPER", "PPER", "$,", "PIAT", "NN"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.23": {"text": "Und die andern Creaturen", "tokens": ["Und", "die", "an\u00b7dern", "Crea\u00b7tu\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.24": {"text": "In dem n\u00e4chsten Augenblick schon", "tokens": ["In", "dem", "n\u00e4chs\u00b7ten", "Au\u00b7gen\u00b7blick", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ADV"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.25": {"text": "St\u00fcrzen und vernichten k\u00f6nnte!", "tokens": ["St\u00fcr\u00b7zen", "und", "ver\u00b7nich\u00b7ten", "k\u00f6nn\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.26": {"text": "Au\u00dferdem bin ich noch Doctor", "tokens": ["Au\u00b7\u00dfer\u00b7dem", "bin", "ich", "noch", "Doc\u00b7tor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.27": {"text": "Der Weltnarrheit und ", "tokens": ["Der", "Welt\u00b7nar\u00b7rheit", "und"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "KON"], "meter": "-+-+-", "measure": "iambic.di"}, "line.28": {"text": "Die das arme, vielbetrog'ne", "tokens": ["Die", "das", "ar\u00b7me", ",", "viel\u00b7be\u00b7tro\u00b7g'\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "ART", "ADJA", "$,", "ADJA"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.29": {"text": "Menschenthum sich will erstreiten!", "tokens": ["Men\u00b7schen\u00b7thum", "sich", "will", "er\u00b7strei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.30": {"text": "Bin an Spree, Rhein, Main und Elbe", "tokens": ["Bin", "an", "Spree", ",", "Rhein", ",", "Main", "und", "El\u00b7be"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "APPR", "NE", "$,", "NE", "$,", "NE", "KON", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.31": {"text": "Mannigfacher Lustvereine", "tokens": ["Man\u00b7nig\u00b7fa\u00b7cher", "Lust\u00b7ver\u00b7ei\u00b7ne"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.32": {"text": "Shakespearweiser Narren Mitglied,", "tokens": ["Sha\u00b7ke\u00b7spe\u00b7ar\u00b7wei\u00b7ser", "Nar\u00b7ren", "Mit\u00b7glied", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.33": {"text": "Pr\u00e4sident, Doktor und Ritter!", "tokens": ["Pr\u00e4\u00b7si\u00b7dent", ",", "Dok\u00b7tor", "und", "Rit\u00b7ter", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.34": {"text": "Bin auch Ritter des erhab'nen", "tokens": ["Bin", "auch", "Rit\u00b7ter", "des", "er\u00b7hab'\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.35": {"text": "Goldenen Champagnerkorkes", "tokens": ["Gol\u00b7de\u00b7nen", "Cham\u00b7pag\u00b7ner\u00b7kor\u00b7kes"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.36": {"text": "Erster Klass' mit Lorbeerbl\u00e4ttern,", "tokens": ["Ers\u00b7ter", "Klass'", "mit", "Lor\u00b7beer\u00b7bl\u00e4t\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.37": {"text": "Wie des sch\u00f6nen Kreuzstern-Ordens", "tokens": ["Wie", "des", "sch\u00f6\u00b7nen", "Kreuz\u00b7stern\u00b7Or\u00b7dens"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.38": {"text": "F\u00fcr wahrhaftige Verdienste", "tokens": ["F\u00fcr", "wahr\u00b7haf\u00b7ti\u00b7ge", "Ver\u00b7diens\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.39": {"text": "Mit der Schleife \u2013 und noch and'rer", "tokens": ["Mit", "der", "Schlei\u00b7fe", "\u2013", "und", "noch", "an\u00b7d'\u00b7rer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$(", "KON", "ADV", "ADJA"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.40": {"text": "Irisbunter (falls dies Wort nicht", "tokens": ["I\u00b7ris\u00b7bun\u00b7ter", "(", "falls", "dies", "Wort", "nicht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$(", "KOUS", "PDS", "NN", "PTKNEG"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.41": {"text": "Tautologisch) Narren-Orden!", "tokens": ["Tau\u00b7to\u00b7lo\u00b7gisch", ")", "Nar\u00b7ren\u00b7Or\u00b7den", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.42": {"text": "Ferner, staune! bin Prophet ich,", "tokens": ["Fer\u00b7ner", ",", "stau\u00b7ne", "!", "bin", "Pro\u00b7phet", "ich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "$.", "VAFIN", "NN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.43": {"text": "Denn ich habe, Dank den G\u00f6ttern!", "tokens": ["Denn", "ich", "ha\u00b7be", ",", "Dank", "den", "G\u00f6t\u00b7tern", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "$,", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.44": {"text": "Wenn der gro\u00dfen L\u00fcge ich die", "tokens": ["Wenn", "der", "gro\u00b7\u00dfen", "L\u00fc\u00b7ge", "ich", "die"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPER", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.45": {"text": "Wahrheit sagte, ", "tokens": ["Wahr\u00b7heit", "sag\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.14": {"line.1": {"text": "Ferner bin ich Oberpriester", "tokens": ["Fer\u00b7ner", "bin", "ich", "O\u00b7ber\u00b7pries\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In Hafisens Freudenkirche", "tokens": ["In", "Ha\u00b7fi\u00b7sens", "Freu\u00b7den\u00b7kir\u00b7che"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Objectiver Weltanschauung!", "tokens": ["Ob\u00b7jec\u00b7ti\u00b7ver", "Welt\u00b7an\u00b7schau\u00b7ung", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und zuletzt: ich bin, was alle", "tokens": ["Und", "zu\u00b7letzt", ":", "ich", "bin", ",", "was", "al\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "$.", "PPER", "VAFIN", "$,", "PRELS", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Diese Hoheit, Ehr' und W\u00fcrden", "tokens": ["Die\u00b7se", "Ho\u00b7heit", ",", "Ehr'", "und", "W\u00fcr\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ich bin, und im h\u00f6hern Sinne", "tokens": ["Ich", "bin", ",", "und", "im", "h\u00f6\u00b7hern", "Sin\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KON", "APPRART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Als man sich im Rausch der Liebe", "tokens": ["Als", "man", "sich", "im", "Rausch", "der", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PRF", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und des Weines hei\u00dft und preist:", "tokens": ["Und", "des", "Wei\u00b7nes", "hei\u00dft", "und", "preist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Ich bin selig! Bin ein Geist!\u00ab", "tokens": ["Ich", "bin", "se\u00b7lig", "!", "Bin", "ein", "Geist", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$.", "VAFIN", "ART", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Diese Worte, wie gesagt schon,", "tokens": ["Die\u00b7se", "Wor\u00b7te", ",", "wie", "ge\u00b7sagt", "schon", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "PWAV", "VVPP", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit der angebor'nen Hoheit", "tokens": ["Mit", "der", "an\u00b7ge\u00b7bor'\u00b7nen", "Ho\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Meines Wesens, mit der W\u00e4rme", "tokens": ["Mei\u00b7nes", "We\u00b7sens", ",", "mit", "der", "W\u00e4r\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des Bewu\u00dftseins eigner Gr\u00f6\u00dfe", "tokens": ["Des", "Be\u00b7wu\u00dfts\u00b7eins", "eig\u00b7ner", "Gr\u00f6\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ausgesprochen, effektuirten", "tokens": ["Aus\u00b7ge\u00b7spro\u00b7chen", ",", "ef\u00b7fek\u00b7tu\u00b7ir\u00b7ten"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "ADJA"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Mehr noch als gehofft ich hatte.", "tokens": ["Mehr", "noch", "als", "ge\u00b7hofft", "ich", "hat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOKOM", "VVFIN", "PPER", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Reuig warf der G\u00f6tzenpriester", "tokens": ["Reu\u00b7ig", "warf", "der", "G\u00f6t\u00b7zen\u00b7pries\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Sich auf seine H\u00e4nde nieder;", "tokens": ["Sich", "auf", "sei\u00b7ne", "H\u00e4n\u00b7de", "nie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Richtete als Quadrupede", "tokens": ["Rich\u00b7te\u00b7te", "als", "Quad\u00b7ru\u00b7pe\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["NE", "KOUS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Auf zu mir sein Haupt und blickte", "tokens": ["Auf", "zu", "mir", "sein", "Haupt", "und", "blick\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "PPER", "PPOSAT", "NN", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Mich mit h\u00fcndisch-stummer-dummer", "tokens": ["Mich", "mit", "h\u00fcn\u00b7dischstum\u00b7mer\u00b7dum\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Demuth und Verehrung an.", "tokens": ["De\u00b7muth", "und", "Ver\u00b7eh\u00b7rung", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Und auch ich that, wie sich's schickte,", "tokens": ["Und", "auch", "ich", "that", ",", "wie", "sich's", "schick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ohn' ihm mein Gesicht zu zeigen,", "tokens": ["Ohn'", "ihm", "mein", "Ge\u00b7sicht", "zu", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Artig mich vor ihm verneigen.", "tokens": ["Ar\u00b7tig", "mich", "vor", "ihm", "ver\u00b7nei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "APPR", "PPER", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Doch, erw\u00e4gend, da\u00df in Scenen", "tokens": ["Doch", ",", "er\u00b7w\u00e4\u00b7gend", ",", "da\u00df", "in", "Sce\u00b7nen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "VVPP", "$,", "KOUS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Solcher Art ein Schlu\u00dfeffekt ganz", "tokens": ["Sol\u00b7cher", "Art", "ein", "Schlu\u00df\u00b7ef\u00b7fekt", "ganz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "ART", "NN", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Unumg\u00e4nglich n\u00f6thig, rief ich", "tokens": ["Un\u00b7um\u00b7g\u00e4ng\u00b7lich", "n\u00f6\u00b7thig", ",", "rief", "ich"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJD", "ADJD", "$,", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "(leider ohne Inspicient-", "tokens": ["(", "lei\u00b7der", "oh\u00b7ne", "In\u00b7spi\u00b7cient"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "ADV", "APPR", "TRUNC"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "geblas'ne Colofoniumblitze!)", "tokens": ["ge\u00b7blas'\u00b7ne", "Co\u00b7lo\u00b7fo\u00b7ni\u00b7um\u00b7blit\u00b7ze", "!", ")"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Einen f\u00fcrchterlichen Fluch aus,", "tokens": ["Ei\u00b7nen", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Fluch", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Der von gleicher f\u00fcrchterlicher", "tokens": ["Der", "von", "glei\u00b7cher", "f\u00fcrch\u00b7ter\u00b7li\u00b7cher"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Wirkung wie die Fl\u00fcche alle", "tokens": ["Wir\u00b7kung", "wie", "die", "Fl\u00fc\u00b7che", "al\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ART", "NN", "PIAT"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Im Theater und im Leben;", "tokens": ["Im", "The\u00b7a\u00b7ter", "und", "im", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Rief ich, wenn auch dem Gebr\u00fclle", "tokens": ["Rief", "ich", ",", "wenn", "auch", "dem", "Ge\u00b7br\u00fcl\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.14": {"text": "Unserer Coulissenhelden", "tokens": ["Un\u00b7se\u00b7rer", "Cou\u00b7lis\u00b7sen\u00b7hel\u00b7den"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Und dem des vom Speer Minervens", "tokens": ["Und", "dem", "des", "vom", "Speer", "Mi\u00b7ner\u00b7vens"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ART", "APPRART", "NN", "NN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.16": {"text": "In dem Unterleib verletzten", "tokens": ["In", "dem", "Un\u00b7ter\u00b7leib", "ver\u00b7letz\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Mars gen\u00fcber: ", "tokens": ["Mars", "ge\u00b7n\u00fc\u00b7ber", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "APPR", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.18": {"text": "Doch mit donnerndem Organe", "tokens": ["Doch", "mit", "don\u00b7nern\u00b7dem", "Or\u00b7ga\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Folgendes Fluch-Ultimatum:", "tokens": ["Fol\u00b7gen\u00b7des", "Fluch\u00b7Ul\u00b7ti\u00b7ma\u00b7tum", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.17": {"line.1": {"text": "\u00bbh\u00f6re, Mufti, wie das Fatum,", "tokens": ["\u00bb", "h\u00f6\u00b7re", ",", "Muf\u00b7ti", ",", "wie", "das", "Fa\u00b7tum", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "NN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das untr\u00fcgliche, Dich richtet:", "tokens": ["Das", "un\u00b7tr\u00fcg\u00b7li\u00b7che", ",", "Dich", "rich\u00b7tet", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PPER", "VVFIN", "$."], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Bist auf Tausend Jahr vernichtet,", "tokens": ["Bist", "auf", "Tau\u00b7send", "Jahr", "ver\u00b7nich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "CARD", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Legst Du jemals wieder Hand an", "tokens": ["Legst", "Du", "je\u00b7mals", "wie\u00b7der", "Hand", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "NN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sel'ge Geister!\u00ab", "tokens": ["Sel'\u00b7ge", "Geis\u00b7ter", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.18": {"line.1": {"text": "Und verschwand dann.", "tokens": ["Und", "ver\u00b7schwand", "dann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.19": {"line.1": {"text": "Da\u00df mich dieser krasse Bl\u00f6dsinn", "tokens": ["Da\u00df", "mich", "die\u00b7ser", "kras\u00b7se", "Bl\u00f6d\u00b7sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einer heidnischen Sophistik", "tokens": ["Ei\u00b7ner", "heid\u00b7ni\u00b7schen", "So\u00b7phis\u00b7tik"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Innerlichst emp\u00f6rte, werden", "tokens": ["In\u00b7ner\u00b7lichst", "em\u00b7p\u00f6r\u00b7te", ",", "wer\u00b7den"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "$,", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle meine Herrn Collegen,", "tokens": ["Al\u00b7le", "mei\u00b7ne", "Herrn", "Col\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alle wahrhaft frommen Priester", "tokens": ["Al\u00b7le", "wahr\u00b7haft", "from\u00b7men", "Pries\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Meines Vatersternes Erde", "tokens": ["Mei\u00b7nes", "Va\u00b7ters\u00b7ter\u00b7nes", "Er\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wohl begreifen. Und die Deutschen", "tokens": ["Wohl", "be\u00b7grei\u00b7fen", ".", "Und", "die", "Deut\u00b7schen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVINF", "$.", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Unter ihnen auch, da\u00df trotzdem", "tokens": ["Un\u00b7ter", "ih\u00b7nen", "auch", ",", "da\u00df", "trotz\u00b7dem"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "ADV", "$,", "KOUS", "PAV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Ich \u2013 die Macht des Ober-Mufti's", "tokens": ["Ich", "\u2013", "die", "Macht", "des", "O\u00b7ber\u00b7Muf\u00b7ti's"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$(", "ART", "NN", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Und das Kitzliche, Prek\u00e4re", "tokens": ["Und", "das", "Kitz\u00b7li\u00b7che", ",", "Pre\u00b7k\u00e4\u00b7re"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "ART", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Meiner Stellung hier ermessend \u2013", "tokens": ["Mei\u00b7ner", "Stel\u00b7lung", "hier", "er\u00b7mes\u00b7send", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Dieses heft'gen und gerechten", "tokens": ["Die\u00b7ses", "heft'\u00b7gen", "und", "ge\u00b7rech\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "KON", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Zornes Meister blieb und meine", "tokens": ["Zor\u00b7nes", "Meis\u00b7ter", "blieb", "und", "mei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN", "KON", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Oppositionellen F\u00e4uste", "tokens": ["Op\u00b7po\u00b7si\u00b7ti\u00b7o\u00b7nel\u00b7len", "F\u00e4us\u00b7te"], "token_info": ["word", "word"], "pos": ["NN", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.15": {"text": "In der Tasche machte. Da\u00df ich", "tokens": ["In", "der", "Ta\u00b7sche", "mach\u00b7te", ".", "Da\u00df", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "$.", "KOUS", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Raisonnirte nur im Tiefsten", "tokens": ["Rai\u00b7son\u00b7nir\u00b7te", "nur", "im", "Tiefs\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Meines Innern, in Gedanken,", "tokens": ["Mei\u00b7nes", "In\u00b7nern", ",", "in", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Und selbst ", "tokens": ["Und", "selbst"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.19": {"text": "Und pr\u00e4meditirt, bed\u00e4chtig,", "tokens": ["Und", "pr\u00e4\u00b7me\u00b7di\u00b7tirt", ",", "be\u00b7d\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "VVPP", "$,", "ADJD", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.20": {"text": "Jedes unparlamentarisch-", "tokens": ["Je\u00b7des", "un\u00b7par\u00b7la\u00b7men\u00b7ta\u00b7risch"], "token_info": ["word", "word"], "pos": ["PIAT", "TRUNC"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Schroffen Ausdrucks wie: \u00bbBarbarisch!", "tokens": ["Schrof\u00b7fen", "Aus\u00b7drucks", "wie", ":", "\u00bb", "Bar\u00b7ba\u00b7risch", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "NN", "KOKOM", "$.", "$(", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.22": {"text": "Oeffentliche Meinung! Scheu\u00dflich!", "tokens": ["Oef\u00b7fent\u00b7li\u00b7che", "Mei\u00b7nung", "!", "Scheu\u00df\u00b7lich", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJD", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "Sch\u00e4ndlich! Einheit! Niedertr\u00e4chtig!", "tokens": ["Sch\u00e4nd\u00b7lich", "!", "Ein\u00b7heit", "!", "Nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$.", "NN", "$.", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.24": {"text": "Freie Presse! Klein, doch m\u00e4chtig!", "tokens": ["Frei\u00b7e", "Pres\u00b7se", "!", "Klein", ",", "doch", "m\u00e4ch\u00b7tig", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "NE", "$,", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.25": {"text": "Privilegienst\u00fcrmer! Censor!", "tokens": ["Pri\u00b7vi\u00b7le\u00b7giens\u00b7t\u00fcr\u00b7mer", "!", "Cen\u00b7sor", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.26": {"text": "Liberal! Frech! Ordnungsfeindlich!", "tokens": ["Li\u00b7be\u00b7ral", "!", "Frech", "!", "Ord\u00b7nungs\u00b7feind\u00b7lich", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$.", "NN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.27": {"text": "Fortschritts-Wahnsinn! Plebs-Defensor!", "tokens": ["Fort\u00b7schritts\u00b7Wahn\u00b7sinn", "!", "Plebs\u00b7De\u00b7fen\u00b7sor", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.28": {"text": "Deutschkatholisch! Freigemeindlich!", "tokens": ["Deutschka\u00b7tho\u00b7lisch", "!", "Frei\u00b7ge\u00b7meind\u00b7lich", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$.", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.29": {"text": "Literat! Ruh'st\u00f6rer! Jude!", "tokens": ["Li\u00b7te\u00b7rat", "!", "Ruh'\u00b7st\u00f6\u00b7rer", "!", "Ju\u00b7de", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "NN", "$."], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.30": {"text": "Nationalsinn! Bummellude!", "tokens": ["Na\u00b7ti\u00b7o\u00b7nal\u00b7sinn", "!", "Bum\u00b7mel\u00b7lu\u00b7de", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Reactionswuth! Communistisch!", "tokens": ["Re\u00b7ac\u00b7ti\u00b7ons\u00b7wuth", "!", "Com\u00b7mu\u00b7nis\u00b7tisch", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Heuler! W\u00fchler! Schmutz'ges Siel-Thier!", "tokens": ["Heu\u00b7ler", "!", "W\u00fch\u00b7ler", "!", "Schmutz'\u00b7ges", "Siel\u00b7Thier", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.33": {"text": "Menschenrecht! Lump! Antichristlich!\u00ab", "tokens": ["Men\u00b7schen\u00b7recht", "!", "Lump", "!", "An\u00b7ti\u00b7ch\u00b7rist\u00b7lich", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "$.", "NN", "$.", "NE", "$.", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.34": {"text": "Und so weiter ... mich enthielt hier.", "tokens": ["Und", "so", "wei\u00b7ter", "...", "mich", "ent\u00b7hielt", "hier", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$(", "PPER", "VVFIN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Seine Zopfigkeit geruhten", "tokens": ["Sei\u00b7ne", "Zop\u00b7fig\u00b7keit", "ge\u00b7ruh\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich nunmehr vom Ruhesopha", "tokens": ["Sich", "nun\u00b7mehr", "vom", "Ru\u00b7he\u00b7sop\u00b7ha"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "ADV", "APPRART", "NN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Zu erheben und \u2013 durch so viel", "tokens": ["Zu", "er\u00b7he\u00b7ben", "und", "\u2013", "durch", "so", "viel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "KON", "$(", "APPR", "ADV", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Zimmer f\u00fchrend mich, da\u00df drinnen", "tokens": ["Zim\u00b7mer", "f\u00fch\u00b7rend", "mich", ",", "da\u00df", "drin\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVPP", "PPER", "$,", "KOUS", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Tausend Ober-Mufti's mind'stens", "tokens": ["Tau\u00b7send", "O\u00b7ber\u00b7Muf\u00b7ti's", "min\u00b7d'\u00b7stens"], "token_info": ["word", "word", "word"], "pos": ["CARD", "NE", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Platz gehabt \u2013 vor meinem Auge", "tokens": ["Platz", "ge\u00b7habt", "\u2013", "vor", "mei\u00b7nem", "Au\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAPP", "$(", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Des Pallastes der \u00bbEntbehrung\u00ab", "tokens": ["Des", "Pal\u00b7las\u00b7tes", "der", "\u00bb", "Ent\u00b7beh\u00b7rung", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "$(", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Glanz und Luxus zu entfalten.", "tokens": ["Glanz", "und", "Lu\u00b7xus", "zu", "ent\u00b7fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Mehr jedoch als all' die Speise-,", "tokens": ["Mehr", "je\u00b7doch", "als", "all'", "die", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOUS", "PIS", "ART", "TRUNC", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Spiel-, Empfangs-, Rauch-, Wonne-, Bade-,", "tokens": ["Spiel", ",", "Emp\u00b7fangs", ",", "Rauch", ",", "Won\u00b7ne", ",", "Ba\u00b7de", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["TRUNC", "$,", "TRUNC", "$,", "TRUNC", "$,", "TRUNC", "$,", "TRUNC", "$,"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.11": {"text": "Tanz-Appartements und and're", "tokens": ["Tanz\u00b7Ap\u00b7par\u00b7te\u00b7ments", "und", "an\u00b7d'\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "ADJA"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.12": {"text": "Klein're, machte mich erstaunen", "tokens": ["Klein'\u00b7re", ",", "mach\u00b7te", "mich", "er\u00b7stau\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "VVFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Die Bibliothek hier, welche", "tokens": ["Die", "Bib\u00b7lio\u00b7thek", "hier", ",", "wel\u00b7che"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ADV", "$,", "PRELS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Dreizehntausend B\u00e4nde z\u00e4hlte,", "tokens": ["Drei\u00b7zehn\u00b7tau\u00b7send", "B\u00e4n\u00b7de", "z\u00e4hl\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Aber w\u00f6rtlich auch nur ", "tokens": ["A\u00b7ber", "w\u00f6rt\u00b7lich", "auch", "nur"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADV", "ADV"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.16": {"text": "Nur die reichen, goldverzierten,", "tokens": ["Nur", "die", "rei\u00b7chen", ",", "gold\u00b7ver\u00b7zier\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Inhaltslosen Deckelpappen", "tokens": ["In\u00b7halts\u00b7lo\u00b7sen", "De\u00b7ckel\u00b7pap\u00b7pen"], "token_info": ["word", "word"], "pos": ["NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Mit den Titeln aller Werke", "tokens": ["Mit", "den", "Ti\u00b7teln", "al\u00b7ler", "Wer\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Aller Dichter und Gelehrten", "tokens": ["Al\u00b7ler", "Dich\u00b7ter", "und", "Ge\u00b7lehr\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Dieses Sternes, des Verkehrten!", "tokens": ["Die\u00b7ses", "Ster\u00b7nes", ",", "des", "Ver\u00b7kehr\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "\u00bbwas staunt\u00ab, sprach mein F\u00fchrer, \u00bb\u00fcber", "tokens": ["\u00bb", "was", "staunt", "\u00ab", ",", "sprach", "mein", "F\u00fch\u00b7rer", ",", "\u00bb", "\u00fc\u00b7ber"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "PWS", "VVFIN", "$(", "$,", "VVFIN", "PPOSAT", "NN", "$,", "$(", "APPR"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Diese Staats-Oekonomie Ihr?", "tokens": ["Die\u00b7se", "Staats\u00b7Oe\u00b7ko\u00b7no\u00b7mie", "Ihr", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sie erf\u00fcllt den Zweck vollkommen", "tokens": ["Sie", "er\u00b7f\u00fcllt", "den", "Zweck", "voll\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zier und Catalog zu sein.", "tokens": ["Zier", "und", "Ca\u00b7ta\u00b7log", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Will, was mich nicht oft anlaunet,", "tokens": ["Will", ",", "was", "mich", "nicht", "oft", "an\u00b7lau\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PWS", "PPER", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ich ein Werk der S\u00fcnder lesen,", "tokens": ["Ich", "ein", "Werk", "der", "S\u00fcn\u00b7der", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Die dem Volk das Licht verleihen,", "tokens": ["Die", "dem", "Volk", "das", "Licht", "ver\u00b7lei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Das des Gl\u00fcckes, des Gehorsams", "tokens": ["Das", "des", "Gl\u00fc\u00b7ckes", ",", "des", "Ge\u00b7hor\u00b7sams"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "ART", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Und der Demuth H\u00fctte ansteckt:", "tokens": ["Und", "der", "De\u00b7muth", "H\u00fct\u00b7te", "an\u00b7steckt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VVFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "Sende ich des Werkes Einband", "tokens": ["Sen\u00b7de", "ich", "des", "Wer\u00b7kes", "Ein\u00b7band"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "NN", "NN"], "meter": "+-+-+-++", "measure": "unknown.measure.penta"}, "line.11": {"text": "Nach der Leihbibliothek hin;", "tokens": ["Nach", "der", "Leih\u00b7bib\u00b7lio\u00b7thek", "hin", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "La\u00df' ihn mit dem Buche f\u00fcllen", "tokens": ["La\u00df'", "ihn", "mit", "dem", "Bu\u00b7che", "f\u00fcl\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Den sein Titel heischt und les' es", "tokens": ["Den", "sein", "Ti\u00b7tel", "heischt", "und", "les'", "es"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "KON", "VVIMP", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "F\u00fcr ein Hunderttheil des Preises", "tokens": ["F\u00fcr", "ein", "Hun\u00b7dert\u00b7theil", "des", "Prei\u00b7ses"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Den es selbst mir kosten w\u00fcrde.\u00ab", "tokens": ["Den", "es", "selbst", "mir", "kos\u00b7ten", "w\u00fcr\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPER", "ADV", "PPER", "VVINF", "VAFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "\u00bbaber ...\u00ab", "tokens": ["\u00bb", "a\u00b7ber", "...", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "ADV", "$(", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "\u00bbund wie ich, so handelt", "tokens": ["\u00bb", "und", "wie", "ich", ",", "so", "han\u00b7delt"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "KON", "PWAV", "PPER", "$,", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alles, was zur fashionablen", "tokens": ["Al\u00b7les", ",", "was", "zur", "fa\u00b7shi\u00b7o\u00b7nab\u00b7len"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "APPRART", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Welt geh\u00f6rt, was wahrhaft vornehm.", "tokens": ["Welt", "ge\u00b7h\u00f6rt", ",", "was", "wahr\u00b7haft", "vor\u00b7nehm", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PRELS", "ADV", "ADJD", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Nur der dumme Plebs sucht, hi, hi!", "tokens": ["Nur", "der", "dum\u00b7me", "Plebs", "sucht", ",", "hi", ",", "hi", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$,", "VVFIN", "$,", "ITJ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Seine Ehre drinn, so weit es,", "tokens": ["Sei\u00b7ne", "Eh\u00b7re", "drinn", ",", "so", "weit", "es", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,", "ADV", "ADJD", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Noth und D\u00fcrftigkeit gestatten,", "tokens": ["Noth", "und", "D\u00fcrf\u00b7tig\u00b7keit", "ge\u00b7stat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Seiner Dichter und Gelehrten", "tokens": ["Sei\u00b7ner", "Dich\u00b7ter", "und", "Ge\u00b7lehr\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Werke zu besitzen eigens,", "tokens": ["Wer\u00b7ke", "zu", "be\u00b7sit\u00b7zen", "ei\u00b7gens", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "ADV", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Hochzuachten und Bed\u00fcrfni\u00df;", "tokens": ["Hoch\u00b7zu\u00b7ach\u00b7ten", "und", "Be\u00b7d\u00fcrf\u00b7ni\u00df", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Gleichen Dank zu zollen Ihm,", "tokens": ["Glei\u00b7chen", "Dank", "zu", "zol\u00b7len", "Ihm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKZU", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Ihm, der, wie der Plebs sich ausdr\u00fcckt:", "tokens": ["Ihm", ",", "der", ",", "wie", "der", "Plebs", "sich", "aus\u00b7dr\u00fcckt", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "$,", "PWAV", "ART", "NN", "PRF", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.13": {"text": "Unsre Seele tr\u00f6stet, lichtet,", "tokens": ["Uns\u00b7re", "See\u00b7le", "tr\u00f6s\u00b7tet", ",", "lich\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Reinigt, aufschwingt, Heil und Wonne", "tokens": ["Rei\u00b7nigt", ",", "auf\u00b7schwingt", ",", "Heil", "und", "Won\u00b7ne"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Ihr erstreitet und bereitet", "tokens": ["Ihr", "er\u00b7strei\u00b7tet", "und", "be\u00b7rei\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVPP", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Und, gleichwie die Gottessonne,", "tokens": ["Und", ",", "gleich\u00b7wie", "die", "Got\u00b7tes\u00b7son\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KON", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.17": {"text": "Segen \u00fcberall verbreitet.", "tokens": ["Se\u00b7gen", "\u00fc\u00b7be\u00b7rall", "ver\u00b7brei\u00b7tet", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Ja, er schilt Diejen'gen P\u00f6bel,", "tokens": ["Ja", ",", "er", "schilt", "Die\u00b7jen'\u00b7gen", "P\u00f6\u00b7bel", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die f\u00fcr Hunde, Pferde, Affen,", "tokens": ["Die", "f\u00fcr", "Hun\u00b7de", ",", "Pfer\u00b7de", ",", "Af\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Flitterkram und Schwelgereien", "tokens": ["Flit\u00b7ter\u00b7kram", "und", "Schwel\u00b7ge\u00b7rei\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tausend Mal wohl mehr verprassen", "tokens": ["Tau\u00b7send", "Mal", "wohl", "mehr", "ver\u00b7pras\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als f\u00fcr Dichterwerke j\u00e4hrlich!", "tokens": ["Als", "f\u00fcr", "Dich\u00b7ter\u00b7wer\u00b7ke", "j\u00e4hr\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Tausend Mal mehr f\u00fcr ihr Fressen", "tokens": ["Tau\u00b7send", "Mal", "mehr", "f\u00fcr", "ihr", "Fres\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Als f\u00fcr geist'ge Nahrung zahlen,", "tokens": ["Als", "f\u00fcr", "geist'\u00b7ge", "Nah\u00b7rung", "zah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Die sie borgen statt zu kaufen!", "tokens": ["Die", "sie", "bor\u00b7gen", "statt", "zu", "kau\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Ja, er stellt dabei ein Gleichni\u00df", "tokens": ["Ja", ",", "er", "stellt", "da\u00b7bei", "ein", "Gleich\u00b7ni\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PAV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Auf von angelieh'ner Nahrung,", "tokens": ["Auf", "von", "an\u00b7ge\u00b7lieh'\u00b7ner", "Nah\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Die, genossen kaum, verborgt wird", "tokens": ["Die", ",", "ge\u00b7nos\u00b7sen", "kaum", ",", "ver\u00b7borgt", "wird"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "$,", "VVPP", "ADV", "$,", "VVPP", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Und, pfui! wiederum genossen", "tokens": ["Und", ",", "pfui", "!", "wie\u00b7de\u00b7rum", "ge\u00b7nos\u00b7sen"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "$,", "ITJ", "$.", "ADV", "VVPP"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "Und verborgt wird und genossen", "tokens": ["Und", "ver\u00b7borgt", "wird", "und", "ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVPP", "VAFIN", "KON", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Und so fort, ein Gleichni\u00df, pfui, pfui!", "tokens": ["Und", "so", "fort", ",", "ein", "Gleich\u00b7ni\u00df", ",", "pfui", ",", "pfui", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "$,", "ART", "NN", "$,", "ITJ", "$,", "ITJ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.15": {"text": "So abscheulich, da\u00df kaum ", "tokens": ["So", "ab\u00b7scheu\u00b7lich", ",", "da\u00df", "kaum"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Es app'titlich finden k\u00f6nnten!\u00ab", "tokens": ["Es", "ap\u00b7p'\u00b7tit\u00b7lich", "fin\u00b7den", "k\u00f6nn\u00b7ten", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADJD", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Unter diesen Worten waren", "tokens": ["Un\u00b7ter", "die\u00b7sen", "Wor\u00b7ten", "wa\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Angelangt wir in des Mufti's", "tokens": ["An\u00b7ge\u00b7langt", "wir", "in", "des", "Muf\u00b7ti's"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ob es gleich, von violetter", "tokens": ["Ob", "es", "gleich", ",", "von", "vi\u00b7o\u00b7let\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "$,", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fenster-Draperie ged\u00fcstert,", "tokens": ["Fens\u00b7ter\u00b7Dra\u00b7pe\u00b7rie", "ge\u00b7d\u00fcs\u00b7tert", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weder Pult, Repositorium", "tokens": ["We\u00b7der", "Pult", ",", "Re\u00b7po\u00b7si\u00b7to\u00b7ri\u00b7um"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "NN", "$,", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Noch Papierkorb, Pfeifenriegel", "tokens": ["Noch", "Pa\u00b7pier\u00b7korb", ",", "Pfei\u00b7fen\u00b7rie\u00b7gel"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und dergleichen aufwies, sondern", "tokens": ["Und", "derg\u00b7lei\u00b7chen", "auf\u00b7wies", ",", "son\u00b7dern"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "PIS", "VVFIN", "$,", "KON"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Einen gro\u00dfen Frauenspiegel,", "tokens": ["Ei\u00b7nen", "gro\u00b7\u00dfen", "Frau\u00b7en\u00b7spie\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Schilderein und Nippes-Capricen,", "tokens": ["Schil\u00b7de\u00b7rein", "und", "Nip\u00b7pes\u00b7Ca\u00b7pri\u00b7cen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Die auf keinen hypochondern", "tokens": ["Die", "auf", "kei\u00b7nen", "hy\u00b7po\u00b7chon\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Eigner eben schlie\u00dfen lie\u00dfen,", "tokens": ["Eig\u00b7ner", "e\u00b7ben", "schlie\u00b7\u00dfen", "lie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Und ein seiden Himmelsbette,", "tokens": ["Und", "ein", "sei\u00b7den", "Him\u00b7mels\u00b7bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.13": {"text": "Ueppig breit, nebst Toilette.", "tokens": ["Uep\u00b7pig", "breit", ",", "nebst", "To\u00b7i\u00b7let\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "\u00bbg\u00f6tter!\u00ab rief ich aus, \u00bbWas seh' ich?\u00ab", "tokens": ["\u00bb", "g\u00f6t\u00b7ter", "!", "\u00ab", "rief", "ich", "aus", ",", "\u00bb", "Was", "seh'", "ich", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$.", "$(", "VVFIN", "PPER", "PTKVZ", "$,", "$(", "PWS", "VVFIN", "PPER", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als ich pl\u00f6tzlich, nah' am Fenster,", "tokens": ["Als", "ich", "pl\u00f6tz\u00b7lich", ",", "nah'", "am", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "$,", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eingerahmt in goldner Leistung,", "tokens": ["Ein\u00b7ge\u00b7rahmt", "in", "gold\u00b7ner", "Leis\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meiner Gattin, meiner reizend-", "tokens": ["Mei\u00b7ner", "Gat\u00b7tin", ",", "mei\u00b7ner", "rei\u00b7zen\u00b7d"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "TRUNC"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Sch\u00f6nen Lilialinda's Brustbild,", "tokens": ["Sch\u00f6\u00b7nen", "Li\u00b7li\u00b7a\u00b7lin\u00b7da's", "Brust\u00b7bild", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Ausgef\u00fchrt sehr gut in Essig,", "tokens": ["Aus\u00b7ge\u00b7f\u00fchrt", "sehr", "gut", "in", "Es\u00b7sig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPR", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Hier gewahr ward. \u00bbG\u00f6tter! Himmel!\u00ab", "tokens": ["Hier", "ge\u00b7wahr", "ward", ".", "\u00bb", "G\u00f6t\u00b7ter", "!", "Him\u00b7mel", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$.", "$(", "NN", "$.", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Aber eh' ich selbst es konnte,", "tokens": ["A\u00b7ber", "eh'", "ich", "selbst", "es", "konn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hatte, zornig-wilden Blickes,", "tokens": ["Hat\u00b7te", ",", "zor\u00b7nig\u00b7wil\u00b7den", "Bli\u00b7ckes", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lumpel-Lampel mich gefa\u00dft schon,", "tokens": ["Lum\u00b7pel\u00b7Lam\u00b7pel", "mich", "ge\u00b7fa\u00dft", "schon", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und zwar grade vor dem Busen", "tokens": ["Und", "zwar", "gra\u00b7de", "vor", "dem", "Bu\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unter welchem, ach, mein liebend", "tokens": ["Un\u00b7ter", "wel\u00b7chem", ",", "ach", ",", "mein", "lie\u00b7bend"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "PWAT", "$,", "ITJ", "$,", "PPOSAT", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Herz so st\u00fcrmisch klopfte:", "tokens": ["Herz", "so", "st\u00fcr\u00b7misch", "klopf\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "\u00bbbube!\u00ab", "tokens": ["\u00bb", "bu\u00b7be", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.8": {"text": "Rief er (Als ich dieses Ausdrucks", "tokens": ["Rief", "er", "(", "Als", "ich", "die\u00b7ses", "Aus\u00b7drucks"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$(", "KOUS", "PPER", "PDAT", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Wegen sp\u00e4ter ", "tokens": ["We\u00b7gen", "sp\u00e4\u00b7ter"], "token_info": ["word", "word"], "pos": ["APPR", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "Ihn belangte und der Richter \u2013 \u2013", "tokens": ["Ihn", "be\u00b7lang\u00b7te", "und", "der", "Rich\u00b7ter", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "KON", "ART", "NN", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "In Erw\u00e4gung, da\u00df zwar \u00bbBube\u00ab", "tokens": ["In", "Er\u00b7w\u00e4\u00b7gung", ",", "da\u00df", "zwar", "\u00bb", "Bu\u00b7be", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUS", "ADV", "$(", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "An und f\u00fcr sich nicht beleid'gend,", "tokens": ["An", "und", "f\u00fcr", "sich", "nicht", "be\u00b7lei\u00b7d'\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KON", "APPR", "PRF", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.13": {"text": "Da er oft sowohl von M\u00e4dchen", "tokens": ["Da", "er", "oft", "so\u00b7wohl", "von", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Wie von Dichtern schelmisch-freundlich", "tokens": ["Wie", "von", "Dich\u00b7tern", "schel\u00b7mischfreund\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPR", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Angewendet w\u00e4r' und w\u00fcrde,", "tokens": ["An\u00b7ge\u00b7wen\u00b7det", "w\u00e4r'", "und", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "KON", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Auch im Kartenspiele eine", "tokens": ["Auch", "im", "Kar\u00b7ten\u00b7spie\u00b7le", "ei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPRART", "NN", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Respectabele Figur sei,", "tokens": ["Res\u00b7pec\u00b7ta\u00b7be\u00b7le", "Fi\u00b7gur", "sei", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.18": {"text": "Welche von dem Sultan (K\u00f6nig)", "tokens": ["Wel\u00b7che", "von", "dem", "Sul\u00b7tan", "(", "K\u00f6\u00b7nig", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAT", "APPR", "ART", "NN", "$(", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Durch die Mittelspersonnage,", "tokens": ["Durch", "die", "Mit\u00b7tel\u00b7sper\u00b7son\u00b7na\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Durch die Dame, nur getrennt sei,", "tokens": ["Durch", "die", "Da\u00b7me", ",", "nur", "ge\u00b7trennt", "sei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Der Herr Ober-Mufti aber", "tokens": ["Der", "Herr", "O\u00b7ber\u00b7Muf\u00b7ti", "a\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Weder M\u00e4dchen sei noch Dichter", "tokens": ["We\u00b7der", "M\u00e4d\u00b7chen", "sei", "noch", "Dich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "ADV", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Noch der Kl\u00e4ger eine Karte; \u2013", "tokens": ["Noch", "der", "Kl\u00e4\u00b7ger", "ei\u00b7ne", "Kar\u00b7te", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.24": {"text": "Und in fernerer Erw\u00e4gung,", "tokens": ["Und", "in", "fer\u00b7ne\u00b7rer", "Er\u00b7w\u00e4\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.25": {"text": "Da\u00df bereits der Kl\u00e4ger faktisch", "tokens": ["Da\u00df", "be\u00b7reits", "der", "Kl\u00e4\u00b7ger", "fak\u00b7tisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.26": {"text": "In den sogenannten besten", "tokens": ["In", "den", "so\u00b7ge\u00b7nann\u00b7ten", "bes\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.27": {"text": "Jahren so weit vorger\u00fccket", "tokens": ["Jah\u00b7ren", "so", "weit", "vor\u00b7ge\u00b7r\u00fc\u00b7cket"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ADJD", "VVFIN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.28": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.29": {"text": "Sehr bedenklich w\u00fcrde, ", "tokens": ["Sehr", "be\u00b7denk\u00b7lich", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.30": {"text": "Des hochzopf'gen Angeklagten", "tokens": ["Des", "hoch\u00b7zopf'\u00b7gen", "An\u00b7ge\u00b7klag\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.31": {"text": "Einwand: Kl\u00e4ger h\u00e4tt' durch seinen", "tokens": ["Ein\u00b7wand", ":", "Kl\u00e4\u00b7ger", "h\u00e4tt'", "durch", "sei\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "NE", "VAFIN", "APPR", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.32": {"text": "Tugendhaften Lebenswandel", "tokens": ["Tu\u00b7gend\u00b7haf\u00b7ten", "Le\u00b7bens\u00b7wan\u00b7del"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.33": {"text": "So vortrefflich conservirt sich,", "tokens": ["So", "vor\u00b7treff\u00b7lich", "con\u00b7ser\u00b7virt", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PRF", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.34": {"text": "Da\u00df er, Kl\u00e4ger, ihn f\u00fcr einen", "tokens": ["Da\u00df", "er", ",", "Kl\u00e4\u00b7ger", ",", "ihn", "f\u00fcr", "ei\u00b7nen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "NN", "$,", "PPER", "APPR", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.35": {"text": "J\u00fcngeling gehalten h\u00e4tte:", "tokens": ["J\u00fcn\u00b7ge\u00b7ling", "ge\u00b7hal\u00b7ten", "h\u00e4t\u00b7te", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.36": {"text": "Platz nicht greifen kann, vielmehro", "tokens": ["Platz", "nicht", "grei\u00b7fen", "kann", ",", "viel\u00b7meh\u00b7ro"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "PTKNEG", "VVINF", "VMFIN", "$,", "ADV"], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}, "line.37": {"text": "(dieser Schreibefehler schlich sich", "tokens": ["(", "die\u00b7ser", "Schrei\u00b7be\u00b7feh\u00b7ler", "schlich", "sich"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "PDAT", "NN", "ADJD", "PRF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.38": {"text": "Beim Mundiren ein) dabei nicht", "tokens": ["Beim", "Mun\u00b7di\u00b7ren", "ein", ")", "da\u00b7bei", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "ART", "$(", "PAV", "PTKNEG"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.39": {"text": "Zu verkennen, doch der Ausdruck", "tokens": ["Zu", "ver\u00b7ken\u00b7nen", ",", "doch", "der", "Aus\u00b7druck"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "ADV", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.40": {"text": "\u00bbbube\u00ab als ", "tokens": ["\u00bb", "bu\u00b7be", "\u00ab", "als"], "token_info": ["punct", "word", "punct", "word"], "pos": ["$(", "NN", "$(", "KOUS"], "meter": "+-+", "measure": "trochaic.di"}, "line.41": {"text": "Nur zu nehmen \u2013 nach dem eilften", "tokens": ["Nur", "zu", "neh\u00b7men", "\u2013", "nach", "dem", "eilf\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PTKZU", "VVINF", "$(", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.42": {"text": "Paragraphen, Titel Sieben", "tokens": ["Pa\u00b7ra\u00b7gra\u00b7phen", ",", "Ti\u00b7tel", "Sie\u00b7ben"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.43": {"text": "Des Neunzehnten Theils des", "tokens": ["Des", "Neun\u00b7zehn\u00b7ten", "Theils", "des"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.44": {"text": "Allgemeinen Sultan-Rechtes:", "tokens": ["All\u00b7ge\u00b7mei\u00b7nen", "Sul\u00b7tan\u00b7Rech\u00b7tes", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.45": {"text": "Zu der Zahlung von Dreihundert", "tokens": ["Zu", "der", "Zah\u00b7lung", "von", "Drei\u00b7hun\u00b7dert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "CARD"], "meter": "--+--++-", "measure": "anapaest.di.plus"}, "line.46": {"text": "Gold'ner Scudi's an den Fiscus", "tokens": ["Gold'\u00b7ner", "Scu\u00b7di's", "an", "den", "Fis\u00b7cus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.47": {"text": "Und der Kosten \u2013 \u2013 condemnirt ihn,", "tokens": ["Und", "der", "Kos\u00b7ten", "\u2013", "\u2013", "con\u00b7dem\u00b7nirt", "ihn", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$(", "$(", "VVFIN", "PPER", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.48": {"text": "Wurde Lumpel-Lampeln auf sein", "tokens": ["Wur\u00b7de", "Lum\u00b7pel\u00b7Lam\u00b7peln", "auf", "sein"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "NN", "APPR", "PPOSAT"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.49": {"text": "Immediat-Gesuch vom Sultan", "tokens": ["Im\u00b7me\u00b7diat\u00b7Ge\u00b7such", "vom", "Sul\u00b7tan"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.50": {"text": "Pumpel-Pampel es verziehen,", "tokens": ["Pum\u00b7pel\u00b7Pam\u00b7pel", "es", "ver\u00b7zie\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.51": {"text": "Da\u00df er ", "tokens": ["Da\u00df", "er"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.52": {"text": "Kosten wurden, (was ich selbst war", "tokens": ["Kos\u00b7ten", "wur\u00b7den", ",", "(", "was", "ich", "selbst", "war"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "$,", "$(", "PWS", "PPER", "ADV", "VAFIN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.53": {"text": "Ueber diese wunderbare", "tokens": ["Ue\u00b7ber", "die\u00b7se", "wun\u00b7der\u00b7ba\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.54": {"text": "Gnade und, wie soll ich sagen:", "tokens": ["Gna\u00b7de", "und", ",", "wie", "soll", "ich", "sa\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "$,", "PWAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "\u00bbbube!\u00ab rief er, meines Schreckens", "tokens": ["\u00bb", "bu\u00b7be", "!", "\u00ab", "rief", "er", ",", "mei\u00b7nes", "Schre\u00b7ckens"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "VVFIN", "$.", "$(", "VVFIN", "PPER", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bl\u00e4sse f\u00fcr die Farbe eines", "tokens": ["Bl\u00e4s\u00b7se", "f\u00fcr", "die", "Far\u00b7be", "ei\u00b7nes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schuldbewu\u00dftseins nehmend, \u00bbBube!", "tokens": ["Schuld\u00b7be\u00b7wu\u00dfts\u00b7eins", "neh\u00b7mend", ",", "\u00bb", "Bu\u00b7be", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "VVPP", "$,", "$(", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lilialinda, Deine Gattin,", "tokens": ["Li\u00b7li\u00b7a\u00b7lin\u00b7da", ",", "Dei\u00b7ne", "Gat\u00b7tin", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Sprich, wo ist sie? Sicher wei\u00dft Du's!", "tokens": ["Sprich", ",", "wo", "ist", "sie", "?", "Si\u00b7cher", "wei\u00dft", "Du's", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PWAV", "VAFIN", "PPER", "$.", "ADV", "VVFIN", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Sicher hast Du diese sch\u00f6nste,", "tokens": ["Si\u00b7cher", "hast", "Du", "die\u00b7se", "sch\u00f6ns\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Diese k\u00f6stlichste von allen", "tokens": ["Die\u00b7se", "k\u00f6st\u00b7lichs\u00b7te", "von", "al\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "APPR", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Blumen meines C\u00f6libates", "tokens": ["Blu\u00b7men", "mei\u00b7nes", "C\u00f6\u00b7li\u00b7ba\u00b7tes"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Frech geraubt mir! Hast zur Flucht sie", "tokens": ["Frech", "ge\u00b7raubt", "mir", "!", "Hast", "zur", "Flucht", "sie"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVPP", "PPER", "$.", "VAFIN", "APPRART", "NN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Ueberredet, vor ihr spiegelnd", "tokens": ["Ue\u00b7ber\u00b7re\u00b7det", ",", "vor", "ihr", "spie\u00b7gelnd"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "APPR", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Als ob pl\u00f6tzlich nun entflammt sei", "tokens": ["Als", "ob", "pl\u00f6tz\u00b7lich", "nun", "ent\u00b7flammt", "sei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "ADJD", "ADV", "VVPP", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Lieb' f\u00fcr sie in Deinem Herzen,", "tokens": ["Lieb'", "f\u00fcr", "sie", "in", "Dei\u00b7nem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Gegenliebe f\u00fcr die Holde,", "tokens": ["Ge\u00b7gen\u00b7lie\u00b7be", "f\u00fcr", "die", "Hol\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Die, \u00e4cht weiblich, unschuldvoll", "tokens": ["Die", ",", "\u00e4cht", "weib\u00b7lich", ",", "un\u00b7schuld\u00b7voll"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "$,", "ADJD", "ADJD", "$,", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Sich zu Deinem ", "tokens": ["Sich", "zu", "Dei\u00b7nem"], "token_info": ["word", "word", "word"], "pos": ["PRF", "APPR", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.16": {"text": "Zur Geliebten angetragen,", "tokens": ["Zur", "Ge\u00b7lieb\u00b7ten", "an\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Und die Du, statt hinzusinken", "tokens": ["Und", "die", "Du", ",", "statt", "hin\u00b7zu\u00b7sin\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "PPER", "$,", "KOUI", "VVIZU"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Gl\u00fcckbet\u00e4ubt zu ihren F\u00fc\u00dfen,", "tokens": ["Gl\u00fcck\u00b7be\u00b7t\u00e4ubt", "zu", "ih\u00b7ren", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Der Du werth nicht bist, vom Schatten", "tokens": ["Der", "Du", "werth", "nicht", "bist", ",", "vom", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PPER", "ADJD", "PTKNEG", "VAFIN", "$,", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Dieser F\u00fc\u00dfe nur zu tr\u00e4umen,", "tokens": ["Die\u00b7ser", "F\u00fc\u00b7\u00dfe", "nur", "zu", "tr\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Grausam Dir antrauen lie\u00dfest!", "tokens": ["Grau\u00b7sam", "Dir", "an\u00b7trau\u00b7en", "lie\u00b7\u00dfest", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Ihre Liebesgluth verlachend", "tokens": ["Ih\u00b7re", "Lie\u00b7bes\u00b7gluth", "ver\u00b7la\u00b7chend"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Und zu Deiner ", "tokens": ["Und", "zu", "Dei\u00b7ner"], "token_info": ["word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.24": {"text": "Frech und schn\u00f6de sie verstie\u00dfest!\u00ab", "tokens": ["Frech", "und", "schn\u00f6\u00b7de", "sie", "ver\u00b7stie\u00b7\u00dfest", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "VVFIN", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Ich betheuerte bei ", "tokens": ["Ich", "be\u00b7theu\u00b7er\u00b7te", "bei"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und den Heideng\u00f6ttern allen,", "tokens": ["Und", "den", "Hei\u00b7den\u00b7g\u00f6t\u00b7tern", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Selbst bei ", "tokens": ["Selbst", "bei"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Und bei ", "tokens": ["Und", "bei"], "token_info": ["word", "word"], "pos": ["KON", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Da\u00df an meiner Gattin, meiner", "tokens": ["Da\u00df", "an", "mei\u00b7ner", "Gat\u00b7tin", ",", "mei\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "$,", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hei\u00dfgeliebten Lilialinda,", "tokens": ["Hei\u00df\u00b7ge\u00b7lieb\u00b7ten", "Li\u00b7li\u00b7a\u00b7lin\u00b7da", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Flucht ich schuldlos, schwor dem Mufti,", "tokens": ["Flucht", "ich", "schuld\u00b7los", ",", "schwor", "dem", "Muf\u00b7ti", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Seit dem Augenblick der Trennung", "tokens": ["Seit", "dem", "Au\u00b7gen\u00b7blick", "der", "Tren\u00b7nung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Sie mit keinem Aug' gesehen,", "tokens": ["Sie", "mit", "kei\u00b7nem", "Aug'", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Sie mit keinem Mund gesprochen", "tokens": ["Sie", "mit", "kei\u00b7nem", "Mund", "ge\u00b7spro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "PIAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Und mit keiner Hand geschrieben", "tokens": ["Und", "mit", "kei\u00b7ner", "Hand", "ge\u00b7schrie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Ihr zu haben, also auch durch", "tokens": ["Ihr", "zu", "ha\u00b7ben", ",", "al\u00b7so", "auch", "durch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "PTKZU", "VAINF", "$,", "ADV", "ADV", "APPR"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.13": {"text": "Dritter Auge, Mund und Hand nicht.", "tokens": ["Drit\u00b7ter", "Au\u00b7ge", ",", "Mund", "und", "Hand", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "KON", "NN", "PTKNEG", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Schwor ihm, da\u00df er selbst es w\u00e4re,", "tokens": ["Schwor", "ihm", ",", "da\u00df", "er", "selbst", "es", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "KOUS", "PPER", "ADV", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Der mir ihre Flucht aus seinem", "tokens": ["Der", "mir", "ih\u00b7re", "Flucht", "aus", "sei\u00b7nem"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PPOSAT", "NN", "APPR", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Harem oder C\u00f6libate,", "tokens": ["Ha\u00b7rem", "o\u00b7der", "C\u00f6\u00b7li\u00b7ba\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Wie er's nenn', zuerst verk\u00fcnde.", "tokens": ["Wie", "er's", "nenn'", ",", "zu\u00b7erst", "ver\u00b7k\u00fcn\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "\u00bbund so,\u00ab endigte erhitzt ich,", "tokens": ["\u00bb", "und", "so", ",", "\u00ab", "en\u00b7dig\u00b7te", "er\u00b7hitzt", "ich", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "$,", "$(", "VVFIN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "\u00bbprallt der \u203aBube,\u2039 der auf meine", "tokens": ["\u00bb", "prallt", "der", "\u203a", "Bu\u00b7be", ",", "\u2039", "der", "auf", "mei\u00b7ne"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "ART", "ADJA", "NN", "$,", "$(", "ART", "APPR", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Schuldlos-starke Brust geworfen,", "tokens": ["Schuld\u00b7los\u00b7star\u00b7ke", "Brust", "ge\u00b7wor\u00b7fen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Auf den Werfenden zur\u00fcck nun,", "tokens": ["Auf", "den", "Wer\u00b7fen\u00b7den", "zu\u00b7r\u00fcck", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "ADV", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.22": {"text": "Der, wiewohl schon alter S\u00fcnder,", "tokens": ["Der", ",", "wie\u00b7wohl", "schon", "al\u00b7ter", "S\u00fcn\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Nicht einmal solch alter S\u00fcnder", "tokens": ["Nicht", "ein\u00b7mal", "solch", "al\u00b7ter", "S\u00fcn\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.24": {"text": "Einz'gen Vorzug sonst vor jungen", "tokens": ["Einz'\u00b7gen", "Vor\u00b7zug", "sonst", "vor", "jun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADV", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.25": {"text": "S\u00fcndern zeigte: Selbstbeherrschung!\u00ab", "tokens": ["S\u00fcn\u00b7dern", "zeig\u00b7te", ":", "Selbst\u00b7be\u00b7herr\u00b7schung", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "$.", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Rasend, mit giergl\u00fchnden Augen,", "tokens": ["Ra\u00b7send", ",", "mit", "gier\u00b7gl\u00fchn\u00b7den", "Au\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie das Lamm, wenn's Appetit hat,", "tokens": ["Wie", "das", "Lamm", ",", "wenn's", "Ap\u00b7pe\u00b7tit", "hat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "KOUS", "NN", "VAFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Auf den frommen Tiger losspringt,", "tokens": ["Auf", "den", "from\u00b7men", "Ti\u00b7ger", "los\u00b7springt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "St\u00fcrzte sich des G\u00f6tzenpriesters", "tokens": ["St\u00fcrz\u00b7te", "sich", "des", "G\u00f6t\u00b7zen\u00b7pries\u00b7ters"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zopfheit in Person auf mich und", "tokens": ["Zopf\u00b7heit", "in", "Per\u00b7son", "auf", "mich", "und"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "APPR", "PPER", "KON"], "meter": "+--+-++-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Zeigten deutlich dero Absicht,", "tokens": ["Zeig\u00b7ten", "deut\u00b7lich", "de\u00b7ro", "Ab\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PRELAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Das mir zu ertheilen, was man,", "tokens": ["Das", "mir", "zu", "er\u00b7thei\u00b7len", ",", "was", "man", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "PPER", "PTKZU", "VVINF", "$,", "PRELS", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Angewendet bei Personen,", "tokens": ["An\u00b7ge\u00b7wen\u00b7det", "bei", "Per\u00b7so\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Denen jeder ganz vern\u00fcnft'ge", "tokens": ["De\u00b7nen", "je\u00b7der", "ganz", "ver\u00b7n\u00fcnft'\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "PIS", "ADV", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Menschenfreund noch dreimal mehr w\u00fcnscht:", "tokens": ["Men\u00b7schen\u00b7freund", "noch", "drei\u00b7mal", "mehr", "w\u00fcnscht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.11": {"text": "Ausflu\u00df des Verr\u00fccktseins hei\u00dfet.", "tokens": ["Aus\u00b7flu\u00df", "des", "Ver\u00b7r\u00fcck\u00b7tseins", "hei\u00b7\u00dfet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Ich jedoch, nicht faul, ich ri\u00df ihn", "tokens": ["Ich", "je\u00b7doch", ",", "nicht", "faul", ",", "ich", "ri\u00df", "ihn"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "$,", "PTKNEG", "ADJD", "$,", "PPER", "VVFIN", "PPER"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "St\u00fcrmisch an mein Herze, pre\u00dfte", "tokens": ["St\u00fcr\u00b7misch", "an", "mein", "Her\u00b7ze", ",", "pre\u00df\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADJD", "APPR", "PPOSAT", "VVFIN", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Ihn inbr\u00fcnstiglich und klopfte,", "tokens": ["Ihn", "in\u00b7br\u00fcns\u00b7tig\u00b7lich", "und", "klopf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Ihn beruh'gend, ihm den R\u00fccken.", "tokens": ["Ihn", "be\u00b7ruh'\u00b7gend", ",", "ihm", "den", "R\u00fc\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Dann ergriff ich seine H\u00e4nde,", "tokens": ["Dann", "er\u00b7griff", "ich", "sei\u00b7ne", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hielt sie fest und sicher, blickte", "tokens": ["Hielt", "sie", "fest", "und", "si\u00b7cher", ",", "blick\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "ADJD", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fest und sicher ihm in's Auge,", "tokens": ["Fest", "und", "si\u00b7cher", "ihm", "in's", "Au\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nahm all meine Kraft zusammen", "tokens": ["Nahm", "all", "mei\u00b7ne", "Kraft", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und die angebor'ne Hoheit,", "tokens": ["Und", "die", "an\u00b7ge\u00b7bor'\u00b7ne", "Ho\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und sprach mit dem ganzen Adel,", "tokens": ["Und", "sprach", "mit", "dem", "gan\u00b7zen", "A\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Der mir zu Gebot steht, also:", "tokens": ["Der", "mir", "zu", "Ge\u00b7bot", "steht", ",", "al\u00b7so", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$,", "ADV", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "\u00bbwei\u00dft Du, Mufti, ", "tokens": ["\u00bb", "wei\u00dft", "Du", ",", "Muf\u00b7ti", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Wei\u00dft Du, Knirps, auf wen Du wolltest,", "tokens": ["Wei\u00dft", "Du", ",", "Knirps", ",", "auf", "wen", "Du", "woll\u00b7test", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "APPR", "PWS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Ich bin nicht nur ", "tokens": ["Ich", "bin", "nicht", "nur"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Ich, Ernst Heiter, Erst und Einz'ger,", "tokens": ["Ich", ",", "Ernst", "Hei\u00b7ter", ",", "Erst", "und", "Einz'\u00b7ger", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NE", "NE", "$,", "ADV", "KON", "NN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Bin erhaben \u00fcber Vieles!", "tokens": ["Bin", "er\u00b7ha\u00b7ben", "\u00fc\u00b7ber", "Vie\u00b7les", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bin ein F\u00fcrst, mit dem die Kaiser", "tokens": ["Bin", "ein", "F\u00fcrst", ",", "mit", "dem", "die", "Kai\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "APPR", "PRELS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "China's, Ru\u00dflands und Marokko's.", "tokens": ["China's", ",", "Ru\u00df\u00b7lands", "und", "Ma\u00b7rok\u00b7ko'", "s."], "token_info": ["word", "punct", "word", "word", "word", "abbreviation"], "pos": ["NE", "$,", "NE", "KON", "NE", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Nimmermehr sich messen werden!", "tokens": ["Nim\u00b7mer\u00b7mehr", "sich", "mes\u00b7sen", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Zwischen diesem, dem Verkehrten", "tokens": ["Zwi\u00b7schen", "die\u00b7sem", ",", "dem", "Ver\u00b7kehr\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "PDAT", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Weltchen und dem hochvern\u00fcnft'gen", "tokens": ["Welt\u00b7chen", "und", "dem", "hoch\u00b7ver\u00b7n\u00fcnft'\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Sterne Erde hab' ich Schl\u00f6sser", "tokens": ["Ster\u00b7ne", "Er\u00b7de", "hab'", "ich", "Schl\u00f6s\u00b7ser"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "VAFIN", "PPER", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Eine Unzahl und viel pr\u00e4cht'ger", "tokens": ["Ei\u00b7ne", "Un\u00b7zahl", "und", "viel", "pr\u00e4cht'\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Als Du, Mufti, Dir kannst denken!", "tokens": ["Als", "Du", ",", "Muf\u00b7ti", ",", "Dir", "kannst", "den\u00b7ken", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "NN", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Das Gebiet, das sch\u00f6ne, reiche", "tokens": ["Das", "Ge\u00b7biet", ",", "das", "sch\u00f6\u00b7ne", ",", "rei\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Deutscher Zunge ist das meine!", "tokens": ["Deut\u00b7scher", "Zun\u00b7ge", "ist", "das", "mei\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PDS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Und im Reiche der Humoren,", "tokens": ["Und", "im", "Rei\u00b7che", "der", "Hu\u00b7mo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NE", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Wie in jenem zaubervollen,", "tokens": ["Wie", "in", "je\u00b7nem", "zau\u00b7ber\u00b7vol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Himmlischen, de\u00df Blum' und Fr\u00fcchte", "tokens": ["Himm\u00b7li\u00b7schen", ",", "de\u00df", "Blum'", "und", "Fr\u00fcch\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Man vom heiligen Parnassus", "tokens": ["Man", "vom", "hei\u00b7li\u00b7gen", "Par\u00b7nas\u00b7sus"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "APPRART", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.18": {"text": "Ueberschaut, bin ich, Ernst Heiter,", "tokens": ["Ue\u00b7ber\u00b7schaut", ",", "bin", "ich", ",", "Ernst", "Hei\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "VAFIN", "PPER", "$,", "NE", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Wenn auch oft nicht Selbstbeherrscher,", "tokens": ["Wenn", "auch", "oft", "nicht", "Selbst\u00b7be\u00b7herr\u00b7scher", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PTKNEG", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Doch so m\u00e4chtig und gebietend,", "tokens": ["Doch", "so", "m\u00e4ch\u00b7tig", "und", "ge\u00b7bie\u00b7tend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "KON", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Da\u00df, gleichwie der Gott der G\u00f6tter", "tokens": ["Da\u00df", ",", "gleich\u00b7wie", "der", "Gott", "der", "G\u00f6t\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Und mit ihm Dich, alle Mufti's", "tokens": ["Und", "mit", "ihm", "Dich", ",", "al\u00b7le", "Muf\u00b7ti's"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "PPER", "PPER", "$,", "PIAT", "NN"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.23": {"text": "Und die andern Creaturen", "tokens": ["Und", "die", "an\u00b7dern", "Crea\u00b7tu\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.24": {"text": "In dem n\u00e4chsten Augenblick schon", "tokens": ["In", "dem", "n\u00e4chs\u00b7ten", "Au\u00b7gen\u00b7blick", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ADV"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.25": {"text": "St\u00fcrzen und vernichten k\u00f6nnte!", "tokens": ["St\u00fcr\u00b7zen", "und", "ver\u00b7nich\u00b7ten", "k\u00f6nn\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.26": {"text": "Au\u00dferdem bin ich noch Doctor", "tokens": ["Au\u00b7\u00dfer\u00b7dem", "bin", "ich", "noch", "Doc\u00b7tor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.27": {"text": "Der Weltnarrheit und ", "tokens": ["Der", "Welt\u00b7nar\u00b7rheit", "und"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "KON"], "meter": "-+-+-", "measure": "iambic.di"}, "line.28": {"text": "Die das arme, vielbetrog'ne", "tokens": ["Die", "das", "ar\u00b7me", ",", "viel\u00b7be\u00b7tro\u00b7g'\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "ART", "ADJA", "$,", "ADJA"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.29": {"text": "Menschenthum sich will erstreiten!", "tokens": ["Men\u00b7schen\u00b7thum", "sich", "will", "er\u00b7strei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.30": {"text": "Bin an Spree, Rhein, Main und Elbe", "tokens": ["Bin", "an", "Spree", ",", "Rhein", ",", "Main", "und", "El\u00b7be"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "APPR", "NE", "$,", "NE", "$,", "NE", "KON", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.31": {"text": "Mannigfacher Lustvereine", "tokens": ["Man\u00b7nig\u00b7fa\u00b7cher", "Lust\u00b7ver\u00b7ei\u00b7ne"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.32": {"text": "Shakespearweiser Narren Mitglied,", "tokens": ["Sha\u00b7ke\u00b7spe\u00b7ar\u00b7wei\u00b7ser", "Nar\u00b7ren", "Mit\u00b7glied", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.33": {"text": "Pr\u00e4sident, Doktor und Ritter!", "tokens": ["Pr\u00e4\u00b7si\u00b7dent", ",", "Dok\u00b7tor", "und", "Rit\u00b7ter", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.34": {"text": "Bin auch Ritter des erhab'nen", "tokens": ["Bin", "auch", "Rit\u00b7ter", "des", "er\u00b7hab'\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.35": {"text": "Goldenen Champagnerkorkes", "tokens": ["Gol\u00b7de\u00b7nen", "Cham\u00b7pag\u00b7ner\u00b7kor\u00b7kes"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.36": {"text": "Erster Klass' mit Lorbeerbl\u00e4ttern,", "tokens": ["Ers\u00b7ter", "Klass'", "mit", "Lor\u00b7beer\u00b7bl\u00e4t\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.37": {"text": "Wie des sch\u00f6nen Kreuzstern-Ordens", "tokens": ["Wie", "des", "sch\u00f6\u00b7nen", "Kreuz\u00b7stern\u00b7Or\u00b7dens"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.38": {"text": "F\u00fcr wahrhaftige Verdienste", "tokens": ["F\u00fcr", "wahr\u00b7haf\u00b7ti\u00b7ge", "Ver\u00b7diens\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.39": {"text": "Mit der Schleife \u2013 und noch and'rer", "tokens": ["Mit", "der", "Schlei\u00b7fe", "\u2013", "und", "noch", "an\u00b7d'\u00b7rer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$(", "KON", "ADV", "ADJA"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.40": {"text": "Irisbunter (falls dies Wort nicht", "tokens": ["I\u00b7ris\u00b7bun\u00b7ter", "(", "falls", "dies", "Wort", "nicht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$(", "KOUS", "PDS", "NN", "PTKNEG"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.41": {"text": "Tautologisch) Narren-Orden!", "tokens": ["Tau\u00b7to\u00b7lo\u00b7gisch", ")", "Nar\u00b7ren\u00b7Or\u00b7den", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.42": {"text": "Ferner, staune! bin Prophet ich,", "tokens": ["Fer\u00b7ner", ",", "stau\u00b7ne", "!", "bin", "Pro\u00b7phet", "ich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "$.", "VAFIN", "NN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.43": {"text": "Denn ich habe, Dank den G\u00f6ttern!", "tokens": ["Denn", "ich", "ha\u00b7be", ",", "Dank", "den", "G\u00f6t\u00b7tern", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "$,", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.44": {"text": "Wenn der gro\u00dfen L\u00fcge ich die", "tokens": ["Wenn", "der", "gro\u00b7\u00dfen", "L\u00fc\u00b7ge", "ich", "die"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPER", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.45": {"text": "Wahrheit sagte, ", "tokens": ["Wahr\u00b7heit", "sag\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.32": {"line.1": {"text": "Ferner bin ich Oberpriester", "tokens": ["Fer\u00b7ner", "bin", "ich", "O\u00b7ber\u00b7pries\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In Hafisens Freudenkirche", "tokens": ["In", "Ha\u00b7fi\u00b7sens", "Freu\u00b7den\u00b7kir\u00b7che"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Objectiver Weltanschauung!", "tokens": ["Ob\u00b7jec\u00b7ti\u00b7ver", "Welt\u00b7an\u00b7schau\u00b7ung", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und zuletzt: ich bin, was alle", "tokens": ["Und", "zu\u00b7letzt", ":", "ich", "bin", ",", "was", "al\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "$.", "PPER", "VAFIN", "$,", "PRELS", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Diese Hoheit, Ehr' und W\u00fcrden", "tokens": ["Die\u00b7se", "Ho\u00b7heit", ",", "Ehr'", "und", "W\u00fcr\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ich bin, und im h\u00f6hern Sinne", "tokens": ["Ich", "bin", ",", "und", "im", "h\u00f6\u00b7hern", "Sin\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KON", "APPRART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Als man sich im Rausch der Liebe", "tokens": ["Als", "man", "sich", "im", "Rausch", "der", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PRF", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und des Weines hei\u00dft und preist:", "tokens": ["Und", "des", "Wei\u00b7nes", "hei\u00dft", "und", "preist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Ich bin selig! Bin ein Geist!\u00ab", "tokens": ["Ich", "bin", "se\u00b7lig", "!", "Bin", "ein", "Geist", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$.", "VAFIN", "ART", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.33": {"line.1": {"text": "Diese Worte, wie gesagt schon,", "tokens": ["Die\u00b7se", "Wor\u00b7te", ",", "wie", "ge\u00b7sagt", "schon", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "PWAV", "VVPP", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit der angebor'nen Hoheit", "tokens": ["Mit", "der", "an\u00b7ge\u00b7bor'\u00b7nen", "Ho\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Meines Wesens, mit der W\u00e4rme", "tokens": ["Mei\u00b7nes", "We\u00b7sens", ",", "mit", "der", "W\u00e4r\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des Bewu\u00dftseins eigner Gr\u00f6\u00dfe", "tokens": ["Des", "Be\u00b7wu\u00dfts\u00b7eins", "eig\u00b7ner", "Gr\u00f6\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ausgesprochen, effektuirten", "tokens": ["Aus\u00b7ge\u00b7spro\u00b7chen", ",", "ef\u00b7fek\u00b7tu\u00b7ir\u00b7ten"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "ADJA"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Mehr noch als gehofft ich hatte.", "tokens": ["Mehr", "noch", "als", "ge\u00b7hofft", "ich", "hat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOKOM", "VVFIN", "PPER", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Reuig warf der G\u00f6tzenpriester", "tokens": ["Reu\u00b7ig", "warf", "der", "G\u00f6t\u00b7zen\u00b7pries\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Sich auf seine H\u00e4nde nieder;", "tokens": ["Sich", "auf", "sei\u00b7ne", "H\u00e4n\u00b7de", "nie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Richtete als Quadrupede", "tokens": ["Rich\u00b7te\u00b7te", "als", "Quad\u00b7ru\u00b7pe\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["NE", "KOUS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Auf zu mir sein Haupt und blickte", "tokens": ["Auf", "zu", "mir", "sein", "Haupt", "und", "blick\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "PPER", "PPOSAT", "NN", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Mich mit h\u00fcndisch-stummer-dummer", "tokens": ["Mich", "mit", "h\u00fcn\u00b7dischstum\u00b7mer\u00b7dum\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Demuth und Verehrung an.", "tokens": ["De\u00b7muth", "und", "Ver\u00b7eh\u00b7rung", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.34": {"line.1": {"text": "Und auch ich that, wie sich's schickte,", "tokens": ["Und", "auch", "ich", "that", ",", "wie", "sich's", "schick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ohn' ihm mein Gesicht zu zeigen,", "tokens": ["Ohn'", "ihm", "mein", "Ge\u00b7sicht", "zu", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Artig mich vor ihm verneigen.", "tokens": ["Ar\u00b7tig", "mich", "vor", "ihm", "ver\u00b7nei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "APPR", "PPER", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Doch, erw\u00e4gend, da\u00df in Scenen", "tokens": ["Doch", ",", "er\u00b7w\u00e4\u00b7gend", ",", "da\u00df", "in", "Sce\u00b7nen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "VVPP", "$,", "KOUS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Solcher Art ein Schlu\u00dfeffekt ganz", "tokens": ["Sol\u00b7cher", "Art", "ein", "Schlu\u00df\u00b7ef\u00b7fekt", "ganz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "ART", "NN", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Unumg\u00e4nglich n\u00f6thig, rief ich", "tokens": ["Un\u00b7um\u00b7g\u00e4ng\u00b7lich", "n\u00f6\u00b7thig", ",", "rief", "ich"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJD", "ADJD", "$,", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "(leider ohne Inspicient-", "tokens": ["(", "lei\u00b7der", "oh\u00b7ne", "In\u00b7spi\u00b7cient"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "ADV", "APPR", "TRUNC"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "geblas'ne Colofoniumblitze!)", "tokens": ["ge\u00b7blas'\u00b7ne", "Co\u00b7lo\u00b7fo\u00b7ni\u00b7um\u00b7blit\u00b7ze", "!", ")"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Einen f\u00fcrchterlichen Fluch aus,", "tokens": ["Ei\u00b7nen", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Fluch", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Der von gleicher f\u00fcrchterlicher", "tokens": ["Der", "von", "glei\u00b7cher", "f\u00fcrch\u00b7ter\u00b7li\u00b7cher"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Wirkung wie die Fl\u00fcche alle", "tokens": ["Wir\u00b7kung", "wie", "die", "Fl\u00fc\u00b7che", "al\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ART", "NN", "PIAT"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Im Theater und im Leben;", "tokens": ["Im", "The\u00b7a\u00b7ter", "und", "im", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Rief ich, wenn auch dem Gebr\u00fclle", "tokens": ["Rief", "ich", ",", "wenn", "auch", "dem", "Ge\u00b7br\u00fcl\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.14": {"text": "Unserer Coulissenhelden", "tokens": ["Un\u00b7se\u00b7rer", "Cou\u00b7lis\u00b7sen\u00b7hel\u00b7den"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Und dem des vom Speer Minervens", "tokens": ["Und", "dem", "des", "vom", "Speer", "Mi\u00b7ner\u00b7vens"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ART", "APPRART", "NN", "NN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.16": {"text": "In dem Unterleib verletzten", "tokens": ["In", "dem", "Un\u00b7ter\u00b7leib", "ver\u00b7letz\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Mars gen\u00fcber: ", "tokens": ["Mars", "ge\u00b7n\u00fc\u00b7ber", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "APPR", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.18": {"text": "Doch mit donnerndem Organe", "tokens": ["Doch", "mit", "don\u00b7nern\u00b7dem", "Or\u00b7ga\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Folgendes Fluch-Ultimatum:", "tokens": ["Fol\u00b7gen\u00b7des", "Fluch\u00b7Ul\u00b7ti\u00b7ma\u00b7tum", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.35": {"line.1": {"text": "\u00bbh\u00f6re, Mufti, wie das Fatum,", "tokens": ["\u00bb", "h\u00f6\u00b7re", ",", "Muf\u00b7ti", ",", "wie", "das", "Fa\u00b7tum", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "NN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das untr\u00fcgliche, Dich richtet:", "tokens": ["Das", "un\u00b7tr\u00fcg\u00b7li\u00b7che", ",", "Dich", "rich\u00b7tet", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PPER", "VVFIN", "$."], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Bist auf Tausend Jahr vernichtet,", "tokens": ["Bist", "auf", "Tau\u00b7send", "Jahr", "ver\u00b7nich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "CARD", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Legst Du jemals wieder Hand an", "tokens": ["Legst", "Du", "je\u00b7mals", "wie\u00b7der", "Hand", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "NN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sel'ge Geister!\u00ab", "tokens": ["Sel'\u00b7ge", "Geis\u00b7ter", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.36": {"line.1": {"text": "Und verschwand dann.", "tokens": ["Und", "ver\u00b7schwand", "dann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$."], "meter": "+-+-", "measure": "trochaic.di"}}}}}