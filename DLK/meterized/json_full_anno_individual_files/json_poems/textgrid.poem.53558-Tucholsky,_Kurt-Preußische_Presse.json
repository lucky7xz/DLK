{"textgrid.poem.53558": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Preu\u00dfische Presse", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Niemand hat eine so gro\u00dfe Fresse", "tokens": ["Nie\u00b7mand", "hat", "ei\u00b7ne", "so", "gro\u00b7\u00dfe", "Fres\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ART", "ADV", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "wie die preu\u00dfische Presse.", "tokens": ["wie", "die", "preu\u00b7\u00dfi\u00b7sche", "Pres\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Und ehe wir wieder mit bunten Aurikeln", "tokens": ["Und", "e\u00b7he", "wir", "wie\u00b7der", "mit", "bun\u00b7ten", "Au\u00b7ri\u00b7keln"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "die Harfe umschlingen", "tokens": ["die", "Har\u00b7fe", "um\u00b7schlin\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "und leise singen \u2013", "tokens": ["und", "lei\u00b7se", "sin\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "la\u00dft uns ein bi\u00dfchen leitartikeln.", "tokens": ["la\u00dft", "uns", "ein", "bi\u00df\u00b7chen", "leit\u00b7ar\u00b7ti\u00b7keln", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "PIS", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Vor dem Kriege waren sie da,", "tokens": ["Vor", "dem", "Krie\u00b7ge", "wa\u00b7ren", "sie", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "schrieen t\u00e4glich zweimal Hurra,", "tokens": ["schri\u00b7een", "t\u00e4g\u00b7lich", "zwei\u00b7mal", "Hur\u00b7ra", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "rasselten mit dem glorreichen S\u00e4bel,", "tokens": ["ras\u00b7sel\u00b7ten", "mit", "dem", "glor\u00b7rei\u00b7chen", "S\u00e4\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "schimpften auf Auer und schimpften auf Bebel,", "tokens": ["schimpf\u00b7ten", "auf", "Au\u00b7er", "und", "schimpf\u00b7ten", "auf", "Be\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "beteten Gott an und die Offiziere,", "tokens": ["be\u00b7te\u00b7ten", "Gott", "an", "und", "die", "Of\u00b7fi\u00b7zie\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKVZ", "KON", "ART", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "und rollten sich abends in Rudeln zum Biere.", "tokens": ["und", "roll\u00b7ten", "sich", "a\u00b7bends", "in", "Ru\u00b7deln", "zum", "Bie\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.3": {"line.1": {"text": "Soweit war das sch\u00f6n und gut.", "tokens": ["So\u00b7weit", "war", "das", "sch\u00f6n", "und", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Aber Vierzehn, da schwoll ihr Mut!", "tokens": ["A\u00b7ber", "Vier\u00b7zehn", ",", "da", "schwoll", "ihr", "Mut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "$,", "KOUS", "ADJD", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Endlich war ihre Zeit gekommen,", "tokens": ["End\u00b7lich", "war", "ih\u00b7re", "Zeit", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "auf die sie so viel Vorschu\u00df genommen,", "tokens": ["auf", "die", "sie", "so", "viel", "Vor\u00b7schu\u00df", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "von der Bernhardi immer geschrieben \u2013", "tokens": ["von", "der", "Bern\u00b7har\u00b7di", "im\u00b7mer", "ge\u00b7schrie\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "ADV", "VVPP", "$("], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.6": {"text": "nun hatten sie uns hineingetrieben.", "tokens": ["nun", "hat\u00b7ten", "sie", "uns", "hin\u00b7ein\u00b7ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und von ihren Freunden, den Offizieren,", "tokens": ["Und", "von", "ih\u00b7ren", "Freun\u00b7den", ",", "den", "Of\u00b7fi\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.8": {"text": "lie\u00dfen sich alle reklamieren,", "tokens": ["lie\u00b7\u00dfen", "sich", "al\u00b7le", "re\u00b7kla\u00b7mie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIS", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "und schrieben daf\u00fcr die h\u00fcbschesten Sachen:", "tokens": ["und", "schrie\u00b7ben", "da\u00b7f\u00fcr", "die", "h\u00fcb\u00b7sches\u00b7ten", "Sa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Wie weit da hinten die M\u00f6rser krachen,", "tokens": ["Wie", "weit", "da", "hin\u00b7ten", "die", "M\u00f6r\u00b7ser", "kra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "wie die braven, lieben, ordentlichen, guten", "tokens": ["wie", "die", "bra\u00b7ven", ",", "lie\u00b7ben", ",", "or\u00b7dent\u00b7li\u00b7chen", ",", "gu\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "ART", "ADJA", "$,", "VVFIN", "$,", "ADJA", "$,", "ADJA"], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Feldgrauen gar so gerne verbluten,", "tokens": ["Feld\u00b7grau\u00b7en", "gar", "so", "ger\u00b7ne", "ver\u00b7blu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "wie sogar manchmal die Herren Obersten schwitzen,", "tokens": ["wie", "so\u00b7gar", "manch\u00b7mal", "die", "Her\u00b7ren", "O\u00b7bers\u00b7ten", "schwit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.14": {"text": "wenn sie beim Trinken im Stabsquartier sitzen,", "tokens": ["wenn", "sie", "beim", "Trin\u00b7ken", "im", "Stabs\u00b7quar\u00b7tier", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "und wie so freundlich und loyal", "tokens": ["und", "wie", "so", "freund\u00b7lich", "und", "lo\u00b7yal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADV", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "zu ihnen gesprochen der Herr General.", "tokens": ["zu", "ih\u00b7nen", "ge\u00b7spro\u00b7chen", "der", "Herr", "Ge\u00b7ne\u00b7ral", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "ART", "NN", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.17": {"text": "Und so ging das ein, zwei, drei, vier lange Jahre \u2013 \u2013 \u2013", "tokens": ["Und", "so", "ging", "das", "ein", ",", "zwei", ",", "drei", ",", "vier", "lan\u00b7ge", "Jah\u00b7re", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PDS", "PTKVZ", "$,", "CARD", "$,", "CARD", "$,", "CARD", "ADJA", "NN", "$(", "$(", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.4": {"line.1": {"text": "Aber auch diese wunderbare", "tokens": ["A\u00b7ber", "auch", "die\u00b7se", "wun\u00b7der\u00b7ba\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "PDAT", "ADJA"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "gro\u00dfe und erhabene Zeit", "tokens": ["gro\u00b7\u00dfe", "und", "er\u00b7ha\u00b7be\u00b7ne", "Zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "KON", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "schien uns allen zu gro\u00df und weit . . .", "tokens": ["schien", "uns", "al\u00b7len", "zu", "gro\u00df", "und", "weit", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "PTKA", "ADJD", "KON", "ADJD", "$.", "$.", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Und pl\u00f6tzlich wurde die Zeit wieder klein \u2013", "tokens": ["Und", "pl\u00f6tz\u00b7lich", "wur\u00b7de", "die", "Zeit", "wie\u00b7der", "klein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "ADV", "ADJD", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ludendorff fiel mit allem herein", "tokens": ["Lu\u00b7den\u00b7dorff", "fiel", "mit", "al\u00b7lem", "her\u00b7ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "PIS", "PTKVZ"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "und besuchte pl\u00f6tzlich und eiligst Schweden.", "tokens": ["und", "be\u00b7such\u00b7te", "pl\u00f6tz\u00b7lich", "und", "ei\u00b7ligst", "Schwe\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "KON", "VVFIN", "NE", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.7": {"text": "(\u00fcbrigens, dar\u00fcber ist nichts zu reden:", "tokens": ["(", "\u00fcb\u00b7ri\u00b7gens", ",", "da\u00b7r\u00fc\u00b7ber", "ist", "nichts", "zu", "re\u00b7den", ":"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "PAV", "VAFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "+---+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Er tat das nur aus Gesundheitsr\u00fccksichten.", "tokens": ["Er", "tat", "das", "nur", "aus", "Ge\u00b7sund\u00b7heits\u00b7r\u00fcck\u00b7sich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "ADV", "APPR", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Denn als hier zu Hause die tollen Geschichten", "tokens": ["Denn", "als", "hier", "zu", "Hau\u00b7se", "die", "tol\u00b7len", "Ge\u00b7schich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "APPR", "NN", "ART", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.10": {"text": "sich wieder beruhigt und gelegt,", "tokens": ["sich", "wie\u00b7der", "be\u00b7ru\u00b7higt", "und", "ge\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVPP", "KON", "VVPP", "$,"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.11": {"text": "kam er gleich wieder angefegt;", "tokens": ["kam", "er", "gleich", "wie\u00b7der", "an\u00b7ge\u00b7fegt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "und jetzt sitzt er an einem Geschreibe dran", "tokens": ["und", "jetzt", "sitzt", "er", "an", "ei\u00b7nem", "Ge\u00b7schrei\u00b7be", "dran"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PAV"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.13": {"text": "und wird zur Belohnung ein reicher Mann.)", "tokens": ["und", "wird", "zur", "Be\u00b7loh\u00b7nung", "ein", "rei\u00b7cher", "Mann", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "ART", "ADJD", "NN", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "Aber die Presse!", "tokens": ["A\u00b7ber", "die", "Pres\u00b7se", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Da\u00df ich die nicht vergesse!", "tokens": ["Da\u00df", "ich", "die", "nicht", "ver\u00b7ges\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir dachten doch nun, jetzt seis mit ihr aus!", "tokens": ["Wir", "dach\u00b7ten", "doch", "nun", ",", "jetzt", "seis", "mit", "ihr", "aus", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,", "ADV", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das \u00fcberlebe sie nicht, dies Gebraus.", "tokens": ["Das", "\u00fc\u00b7berl\u00b7e\u00b7be", "sie", "nicht", ",", "dies", "Ge\u00b7braus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "$,", "PDS", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Denn nun liegt es doch klar am Tage:", "tokens": ["Denn", "nun", "liegt", "es", "doch", "klar", "am", "Ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "F\u00fcr wen ert\u00f6nte die Totenklage?", "tokens": ["F\u00fcr", "wen", "er\u00b7t\u00f6n\u00b7te", "die", "To\u00b7ten\u00b7kla\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Wer hat die Mannschaft aufs Blut geschunden?", "tokens": ["Wer", "hat", "die", "Mann\u00b7schaft", "aufs", "Blut", "ge\u00b7schun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Wer bereicherte sich noch an Todwunden?", "tokens": ["Wer", "be\u00b7rei\u00b7cher\u00b7te", "sich", "noch", "an", "Tod\u00b7wun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "ADV", "APPR", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Wer klaute in viereinhalb langen Jahren", "tokens": ["Wer", "klau\u00b7te", "in", "vier\u00b7ein\u00b7halb", "lan\u00b7gen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "APPR", "CARD", "ADJA", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Kantinenfonds, Marketenderwaren?", "tokens": ["Kan\u00b7ti\u00b7nen\u00b7fonds", ",", "Mar\u00b7ke\u00b7ten\u00b7der\u00b7wa\u00b7ren", "?"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Wem verdanken wir diese Niederlage?", "tokens": ["Wem", "ver\u00b7dan\u00b7ken", "wir", "die\u00b7se", "Nie\u00b7der\u00b7la\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.12": {"text": "Nun, dachten wir, liegt es klar am Tage . . .", "tokens": ["Nun", ",", "dach\u00b7ten", "wir", ",", "liegt", "es", "klar", "am", "Ta\u00b7ge", ".", ".", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$.", "$.", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Weit gefehlt!", "tokens": ["Weit", "ge\u00b7fehlt", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Sie haben sich gar nicht lange gequ\u00e4lt", "tokens": ["Sie", "ha\u00b7ben", "sich", "gar", "nicht", "lan\u00b7ge", "ge\u00b7qu\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "PTKNEG", "ADV", "VVPP"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "und spotten schon heute voller Hohn", "tokens": ["und", "spot\u00b7ten", "schon", "heu\u00b7te", "vol\u00b7ler", "Hohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "auf die Revolution!", "tokens": ["auf", "die", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und wenn wir in Verhandlungen traten,", "tokens": ["Und", "wenn", "wir", "in", "Ver\u00b7hand\u00b7lun\u00b7gen", "tra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "so geschah das nur wegen der lumpigen Soldaten,", "tokens": ["so", "ge\u00b7schah", "das", "nur", "we\u00b7gen", "der", "lum\u00b7pi\u00b7gen", "Sol\u00b7da\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDS", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+--+++-+-", "measure": "anapaest.tri.plus"}, "line.7": {"text": "diesen hundsgemeinen Halunken,", "tokens": ["die\u00b7sen", "hunds\u00b7ge\u00b7mei\u00b7nen", "Ha\u00b7lun\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "und \u00fcberhaupt: deshalb sei alles gesunken . . .", "tokens": ["und", "\u00fc\u00b7ber\u00b7haupt", ":", "des\u00b7halb", "sei", "al\u00b7les", "ge\u00b7sun\u00b7ken", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "$.", "PAV", "VAFIN", "PIS", "VVPP", "$.", "$.", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Die Kerls sind an allem, allem schuld \u2013 \u2013 \u2013", "tokens": ["Die", "Kerls", "sind", "an", "al\u00b7lem", ",", "al\u00b7lem", "schuld", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PIS", "$,", "PIS", "ADJD", "$(", "$(", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Deutschland! hast du eine Lammsgeduld!", "tokens": ["Deutschland", "!", "hast", "du", "ei\u00b7ne", "Lamms\u00b7ge\u00b7duld", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "L\u00e4\u00dft dir heute nach diesem allen", "tokens": ["L\u00e4\u00dft", "dir", "heu\u00b7te", "nach", "die\u00b7sem", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PDAT", "PIAT"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Frechheit von Metzgergesellen gefallen?", "tokens": ["Frech\u00b7heit", "von", "Metz\u00b7ger\u00b7ge\u00b7sel\u00b7len", "ge\u00b7fal\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Lern ihre eiserne Energie!", "tokens": ["Lern", "ih\u00b7re", "ei\u00b7ser\u00b7ne", "E\u00b7ner\u00b7gie", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die vergessen nie.", "tokens": ["Die", "ver\u00b7ges\u00b7sen", "nie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Die setzen ihren verdammten Willen", "tokens": ["Die", "set\u00b7zen", "ih\u00b7ren", "ver\u00b7damm\u00b7ten", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "durch \u2013 im lauten und im stillen", "tokens": ["durch", "\u2013", "im", "lau\u00b7ten", "und", "im", "stil\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "$(", "APPRART", "ADJA", "KON", "APPRART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Kampf, und sie denken nur an sich.", "tokens": ["Kampf", ",", "und", "sie", "den\u00b7ken", "nur", "an", "sich", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "PPER", "VVFIN", "ADV", "APPR", "PRF", "$."], "meter": "+--+-++-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Deutschland! wach auf und besinne dich!", "tokens": ["Deutschland", "!", "wach", "auf", "und", "be\u00b7sin\u00b7ne", "dich", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADJD", "PTKVZ", "KON", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Nur einen Feind hast du deines Geschlechts!", "tokens": ["Nur", "ei\u00b7nen", "Feind", "hast", "du", "dei\u00b7nes", "Ge\u00b7schlechts", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Feind steht rechts!", "tokens": ["Der", "Feind", "steht", "rechts", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Niemand hat eine so gro\u00dfe Fresse", "tokens": ["Nie\u00b7mand", "hat", "ei\u00b7ne", "so", "gro\u00b7\u00dfe", "Fres\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ART", "ADV", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "wie die preu\u00dfische Presse.", "tokens": ["wie", "die", "preu\u00b7\u00dfi\u00b7sche", "Pres\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Und ehe wir wieder mit bunten Aurikeln", "tokens": ["Und", "e\u00b7he", "wir", "wie\u00b7der", "mit", "bun\u00b7ten", "Au\u00b7ri\u00b7keln"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "die Harfe umschlingen", "tokens": ["die", "Har\u00b7fe", "um\u00b7schlin\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "und leise singen \u2013", "tokens": ["und", "lei\u00b7se", "sin\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "la\u00dft uns ein bi\u00dfchen leitartikeln.", "tokens": ["la\u00dft", "uns", "ein", "bi\u00df\u00b7chen", "leit\u00b7ar\u00b7ti\u00b7keln", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "PIS", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.10": {"line.1": {"text": "Vor dem Kriege waren sie da,", "tokens": ["Vor", "dem", "Krie\u00b7ge", "wa\u00b7ren", "sie", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "schrieen t\u00e4glich zweimal Hurra,", "tokens": ["schri\u00b7een", "t\u00e4g\u00b7lich", "zwei\u00b7mal", "Hur\u00b7ra", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "rasselten mit dem glorreichen S\u00e4bel,", "tokens": ["ras\u00b7sel\u00b7ten", "mit", "dem", "glor\u00b7rei\u00b7chen", "S\u00e4\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "schimpften auf Auer und schimpften auf Bebel,", "tokens": ["schimpf\u00b7ten", "auf", "Au\u00b7er", "und", "schimpf\u00b7ten", "auf", "Be\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "beteten Gott an und die Offiziere,", "tokens": ["be\u00b7te\u00b7ten", "Gott", "an", "und", "die", "Of\u00b7fi\u00b7zie\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKVZ", "KON", "ART", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "und rollten sich abends in Rudeln zum Biere.", "tokens": ["und", "roll\u00b7ten", "sich", "a\u00b7bends", "in", "Ru\u00b7deln", "zum", "Bie\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.11": {"line.1": {"text": "Soweit war das sch\u00f6n und gut.", "tokens": ["So\u00b7weit", "war", "das", "sch\u00f6n", "und", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Aber Vierzehn, da schwoll ihr Mut!", "tokens": ["A\u00b7ber", "Vier\u00b7zehn", ",", "da", "schwoll", "ihr", "Mut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "$,", "KOUS", "ADJD", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Endlich war ihre Zeit gekommen,", "tokens": ["End\u00b7lich", "war", "ih\u00b7re", "Zeit", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "auf die sie so viel Vorschu\u00df genommen,", "tokens": ["auf", "die", "sie", "so", "viel", "Vor\u00b7schu\u00df", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "von der Bernhardi immer geschrieben \u2013", "tokens": ["von", "der", "Bern\u00b7har\u00b7di", "im\u00b7mer", "ge\u00b7schrie\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "ADV", "VVPP", "$("], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.6": {"text": "nun hatten sie uns hineingetrieben.", "tokens": ["nun", "hat\u00b7ten", "sie", "uns", "hin\u00b7ein\u00b7ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und von ihren Freunden, den Offizieren,", "tokens": ["Und", "von", "ih\u00b7ren", "Freun\u00b7den", ",", "den", "Of\u00b7fi\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.8": {"text": "lie\u00dfen sich alle reklamieren,", "tokens": ["lie\u00b7\u00dfen", "sich", "al\u00b7le", "re\u00b7kla\u00b7mie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIS", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "und schrieben daf\u00fcr die h\u00fcbschesten Sachen:", "tokens": ["und", "schrie\u00b7ben", "da\u00b7f\u00fcr", "die", "h\u00fcb\u00b7sches\u00b7ten", "Sa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Wie weit da hinten die M\u00f6rser krachen,", "tokens": ["Wie", "weit", "da", "hin\u00b7ten", "die", "M\u00f6r\u00b7ser", "kra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "wie die braven, lieben, ordentlichen, guten", "tokens": ["wie", "die", "bra\u00b7ven", ",", "lie\u00b7ben", ",", "or\u00b7dent\u00b7li\u00b7chen", ",", "gu\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "ART", "ADJA", "$,", "VVFIN", "$,", "ADJA", "$,", "ADJA"], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Feldgrauen gar so gerne verbluten,", "tokens": ["Feld\u00b7grau\u00b7en", "gar", "so", "ger\u00b7ne", "ver\u00b7blu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "wie sogar manchmal die Herren Obersten schwitzen,", "tokens": ["wie", "so\u00b7gar", "manch\u00b7mal", "die", "Her\u00b7ren", "O\u00b7bers\u00b7ten", "schwit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.14": {"text": "wenn sie beim Trinken im Stabsquartier sitzen,", "tokens": ["wenn", "sie", "beim", "Trin\u00b7ken", "im", "Stabs\u00b7quar\u00b7tier", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "und wie so freundlich und loyal", "tokens": ["und", "wie", "so", "freund\u00b7lich", "und", "lo\u00b7yal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADV", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "zu ihnen gesprochen der Herr General.", "tokens": ["zu", "ih\u00b7nen", "ge\u00b7spro\u00b7chen", "der", "Herr", "Ge\u00b7ne\u00b7ral", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "ART", "NN", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.17": {"text": "Und so ging das ein, zwei, drei, vier lange Jahre \u2013 \u2013 \u2013", "tokens": ["Und", "so", "ging", "das", "ein", ",", "zwei", ",", "drei", ",", "vier", "lan\u00b7ge", "Jah\u00b7re", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PDS", "PTKVZ", "$,", "CARD", "$,", "CARD", "$,", "CARD", "ADJA", "NN", "$(", "$(", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.12": {"line.1": {"text": "Aber auch diese wunderbare", "tokens": ["A\u00b7ber", "auch", "die\u00b7se", "wun\u00b7der\u00b7ba\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "PDAT", "ADJA"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "gro\u00dfe und erhabene Zeit", "tokens": ["gro\u00b7\u00dfe", "und", "er\u00b7ha\u00b7be\u00b7ne", "Zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "KON", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "schien uns allen zu gro\u00df und weit . . .", "tokens": ["schien", "uns", "al\u00b7len", "zu", "gro\u00df", "und", "weit", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "PTKA", "ADJD", "KON", "ADJD", "$.", "$.", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Und pl\u00f6tzlich wurde die Zeit wieder klein \u2013", "tokens": ["Und", "pl\u00f6tz\u00b7lich", "wur\u00b7de", "die", "Zeit", "wie\u00b7der", "klein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "ADV", "ADJD", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ludendorff fiel mit allem herein", "tokens": ["Lu\u00b7den\u00b7dorff", "fiel", "mit", "al\u00b7lem", "her\u00b7ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "PIS", "PTKVZ"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "und besuchte pl\u00f6tzlich und eiligst Schweden.", "tokens": ["und", "be\u00b7such\u00b7te", "pl\u00f6tz\u00b7lich", "und", "ei\u00b7ligst", "Schwe\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "KON", "VVFIN", "NE", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.7": {"text": "(\u00fcbrigens, dar\u00fcber ist nichts zu reden:", "tokens": ["(", "\u00fcb\u00b7ri\u00b7gens", ",", "da\u00b7r\u00fc\u00b7ber", "ist", "nichts", "zu", "re\u00b7den", ":"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "PAV", "VAFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "+---+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Er tat das nur aus Gesundheitsr\u00fccksichten.", "tokens": ["Er", "tat", "das", "nur", "aus", "Ge\u00b7sund\u00b7heits\u00b7r\u00fcck\u00b7sich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "ADV", "APPR", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Denn als hier zu Hause die tollen Geschichten", "tokens": ["Denn", "als", "hier", "zu", "Hau\u00b7se", "die", "tol\u00b7len", "Ge\u00b7schich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "APPR", "NN", "ART", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.10": {"text": "sich wieder beruhigt und gelegt,", "tokens": ["sich", "wie\u00b7der", "be\u00b7ru\u00b7higt", "und", "ge\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVPP", "KON", "VVPP", "$,"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.11": {"text": "kam er gleich wieder angefegt;", "tokens": ["kam", "er", "gleich", "wie\u00b7der", "an\u00b7ge\u00b7fegt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "und jetzt sitzt er an einem Geschreibe dran", "tokens": ["und", "jetzt", "sitzt", "er", "an", "ei\u00b7nem", "Ge\u00b7schrei\u00b7be", "dran"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PAV"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.13": {"text": "und wird zur Belohnung ein reicher Mann.)", "tokens": ["und", "wird", "zur", "Be\u00b7loh\u00b7nung", "ein", "rei\u00b7cher", "Mann", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "ART", "ADJD", "NN", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.13": {"line.1": {"text": "Aber die Presse!", "tokens": ["A\u00b7ber", "die", "Pres\u00b7se", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Da\u00df ich die nicht vergesse!", "tokens": ["Da\u00df", "ich", "die", "nicht", "ver\u00b7ges\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir dachten doch nun, jetzt seis mit ihr aus!", "tokens": ["Wir", "dach\u00b7ten", "doch", "nun", ",", "jetzt", "seis", "mit", "ihr", "aus", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,", "ADV", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das \u00fcberlebe sie nicht, dies Gebraus.", "tokens": ["Das", "\u00fc\u00b7berl\u00b7e\u00b7be", "sie", "nicht", ",", "dies", "Ge\u00b7braus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "$,", "PDS", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Denn nun liegt es doch klar am Tage:", "tokens": ["Denn", "nun", "liegt", "es", "doch", "klar", "am", "Ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "F\u00fcr wen ert\u00f6nte die Totenklage?", "tokens": ["F\u00fcr", "wen", "er\u00b7t\u00f6n\u00b7te", "die", "To\u00b7ten\u00b7kla\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Wer hat die Mannschaft aufs Blut geschunden?", "tokens": ["Wer", "hat", "die", "Mann\u00b7schaft", "aufs", "Blut", "ge\u00b7schun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Wer bereicherte sich noch an Todwunden?", "tokens": ["Wer", "be\u00b7rei\u00b7cher\u00b7te", "sich", "noch", "an", "Tod\u00b7wun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "ADV", "APPR", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Wer klaute in viereinhalb langen Jahren", "tokens": ["Wer", "klau\u00b7te", "in", "vier\u00b7ein\u00b7halb", "lan\u00b7gen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "APPR", "CARD", "ADJA", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Kantinenfonds, Marketenderwaren?", "tokens": ["Kan\u00b7ti\u00b7nen\u00b7fonds", ",", "Mar\u00b7ke\u00b7ten\u00b7der\u00b7wa\u00b7ren", "?"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Wem verdanken wir diese Niederlage?", "tokens": ["Wem", "ver\u00b7dan\u00b7ken", "wir", "die\u00b7se", "Nie\u00b7der\u00b7la\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.12": {"text": "Nun, dachten wir, liegt es klar am Tage . . .", "tokens": ["Nun", ",", "dach\u00b7ten", "wir", ",", "liegt", "es", "klar", "am", "Ta\u00b7ge", ".", ".", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$.", "$.", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Weit gefehlt!", "tokens": ["Weit", "ge\u00b7fehlt", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Sie haben sich gar nicht lange gequ\u00e4lt", "tokens": ["Sie", "ha\u00b7ben", "sich", "gar", "nicht", "lan\u00b7ge", "ge\u00b7qu\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "PTKNEG", "ADV", "VVPP"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "und spotten schon heute voller Hohn", "tokens": ["und", "spot\u00b7ten", "schon", "heu\u00b7te", "vol\u00b7ler", "Hohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "auf die Revolution!", "tokens": ["auf", "die", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und wenn wir in Verhandlungen traten,", "tokens": ["Und", "wenn", "wir", "in", "Ver\u00b7hand\u00b7lun\u00b7gen", "tra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "so geschah das nur wegen der lumpigen Soldaten,", "tokens": ["so", "ge\u00b7schah", "das", "nur", "we\u00b7gen", "der", "lum\u00b7pi\u00b7gen", "Sol\u00b7da\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDS", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+--+++-+-", "measure": "anapaest.tri.plus"}, "line.7": {"text": "diesen hundsgemeinen Halunken,", "tokens": ["die\u00b7sen", "hunds\u00b7ge\u00b7mei\u00b7nen", "Ha\u00b7lun\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "und \u00fcberhaupt: deshalb sei alles gesunken . . .", "tokens": ["und", "\u00fc\u00b7ber\u00b7haupt", ":", "des\u00b7halb", "sei", "al\u00b7les", "ge\u00b7sun\u00b7ken", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "$.", "PAV", "VAFIN", "PIS", "VVPP", "$.", "$.", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Die Kerls sind an allem, allem schuld \u2013 \u2013 \u2013", "tokens": ["Die", "Kerls", "sind", "an", "al\u00b7lem", ",", "al\u00b7lem", "schuld", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PIS", "$,", "PIS", "ADJD", "$(", "$(", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Deutschland! hast du eine Lammsgeduld!", "tokens": ["Deutschland", "!", "hast", "du", "ei\u00b7ne", "Lamms\u00b7ge\u00b7duld", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "L\u00e4\u00dft dir heute nach diesem allen", "tokens": ["L\u00e4\u00dft", "dir", "heu\u00b7te", "nach", "die\u00b7sem", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PDAT", "PIAT"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Frechheit von Metzgergesellen gefallen?", "tokens": ["Frech\u00b7heit", "von", "Metz\u00b7ger\u00b7ge\u00b7sel\u00b7len", "ge\u00b7fal\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Lern ihre eiserne Energie!", "tokens": ["Lern", "ih\u00b7re", "ei\u00b7ser\u00b7ne", "E\u00b7ner\u00b7gie", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die vergessen nie.", "tokens": ["Die", "ver\u00b7ges\u00b7sen", "nie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Die setzen ihren verdammten Willen", "tokens": ["Die", "set\u00b7zen", "ih\u00b7ren", "ver\u00b7damm\u00b7ten", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "durch \u2013 im lauten und im stillen", "tokens": ["durch", "\u2013", "im", "lau\u00b7ten", "und", "im", "stil\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "$(", "APPRART", "ADJA", "KON", "APPRART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Kampf, und sie denken nur an sich.", "tokens": ["Kampf", ",", "und", "sie", "den\u00b7ken", "nur", "an", "sich", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "PPER", "VVFIN", "ADV", "APPR", "PRF", "$."], "meter": "+--+-++-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Deutschland! wach auf und besinne dich!", "tokens": ["Deutschland", "!", "wach", "auf", "und", "be\u00b7sin\u00b7ne", "dich", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADJD", "PTKVZ", "KON", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Nur einen Feind hast du deines Geschlechts!", "tokens": ["Nur", "ei\u00b7nen", "Feind", "hast", "du", "dei\u00b7nes", "Ge\u00b7schlechts", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Feind steht rechts!", "tokens": ["Der", "Feind", "steht", "rechts", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}