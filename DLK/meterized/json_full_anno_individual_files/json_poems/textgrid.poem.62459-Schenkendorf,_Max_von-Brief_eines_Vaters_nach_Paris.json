{"textgrid.poem.62459": {"metadata": {"author": {"name": "Schenkendorf, Max von", "birth": "N.A.", "death": "N.A."}, "title": "Brief eines Vaters nach Paris", "genre": "verse", "period": "N.A.", "pub_year": 1800, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "H\u00f6re mich, du Sohn der Eichen,", "tokens": ["H\u00f6\u00b7re", "mich", ",", "du", "Sohn", "der", "Ei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deines Landes Stolz und Hort,", "tokens": ["Dei\u00b7nes", "Lan\u00b7des", "Stolz", "und", "Hort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bis in Babels Mauern reichen", "tokens": ["Bis", "in", "Ba\u00b7bels", "Mau\u00b7ern", "rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "NE", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Soll das ernste deutsche Wort.", "tokens": ["Soll", "das", "erns\u00b7te", "deut\u00b7sche", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Freiheitsheld, ich mu\u00df dich schelten,", "tokens": ["Frei\u00b7heits\u00b7held", ",", "ich", "mu\u00df", "dich", "schel\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dich verblendet falsches Licht,", "tokens": ["Dich", "ver\u00b7blen\u00b7det", "fal\u00b7sches", "Licht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Freundlichkeit und Gro\u00dfmuth gelten", "tokens": ["Freund\u00b7lich\u00b7keit", "und", "Gro\u00df\u00b7muth", "gel\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht im g\u00f6ttlichen Gericht.", "tokens": ["Nicht", "im", "g\u00f6tt\u00b7li\u00b7chen", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Schau', die Alte, die wir hassen,", "tokens": ["Schau'", ",", "die", "Al\u00b7te", ",", "die", "wir", "has\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welcher flucht die halbe Welt,", "tokens": ["Wel\u00b7cher", "flucht", "die", "hal\u00b7be", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lauert noch in allen Gassen,", "tokens": ["Lau\u00b7ert", "noch", "in", "al\u00b7len", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat auch dir das Netz gestellt.", "tokens": ["Hat", "auch", "dir", "das", "Netz", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "In den Staub war sie gefallen,", "tokens": ["In", "den", "Staub", "war", "sie", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber ihr erschlugt sie nicht,", "tokens": ["A\u00b7ber", "ihr", "er\u00b7schlugt", "sie", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und aus ihren Leichenhallen", "tokens": ["Und", "aus", "ih\u00b7ren", "Lei\u00b7chen\u00b7hal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dringet noch ein schwer Gericht.", "tokens": ["Drin\u00b7get", "noch", "ein", "schwer", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Trunken von der Heil'gen Blute,", "tokens": ["Trun\u00b7ken", "von", "der", "Heil'\u00b7gen", "Blu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An den Ecken, auf dem Stein", "tokens": ["An", "den", "E\u00b7cken", ",", "auf", "dem", "Stein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ladet sie im Uebermuthe", "tokens": ["La\u00b7det", "sie", "im", "Ue\u00b7ber\u00b7mu\u00b7the"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jeden frech zur Buhlschaft ein.", "tokens": ["Je\u00b7den", "frech", "zur", "Buhl\u00b7schaft", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wer die Buhlschaft je getrieben,", "tokens": ["Wer", "die", "Buhl\u00b7schaft", "je", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer aus ihrem Becher trank,", "tokens": ["Wer", "aus", "ih\u00b7rem", "Be\u00b7cher", "trank", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kann das deutsche Land nicht lieben,", "tokens": ["Kann", "das", "deut\u00b7sche", "Land", "nicht", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist an Ehr' und Tugend krank.", "tokens": ["Ist", "an", "Ehr'", "und", "Tu\u00b7gend", "krank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "KON", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Honigs\u00fc\u00df ist ihre Rede", "tokens": ["Ho\u00b7ni\u00b7gs\u00fc\u00df", "ist", "ih\u00b7re", "Re\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und gef\u00e4rbt ihr Angesicht,", "tokens": ["Und", "ge\u00b7f\u00e4rbt", "ihr", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber biet' ihr offne Fehde,", "tokens": ["A\u00b7ber", "biet'", "ihr", "off\u00b7ne", "Feh\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Spuk betr\u00fcgt dich nicht.", "tokens": ["Und", "der", "Spuk", "be\u00b7tr\u00fcgt", "dich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Sohn, die deutschen B\u00e4ume rauschen,", "tokens": ["Sohn", ",", "die", "deut\u00b7schen", "B\u00e4u\u00b7me", "rau\u00b7schen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die V\u00e4ter blicken her,", "tokens": ["Und", "die", "V\u00e4\u00b7ter", "bli\u00b7cken", "her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die deutschen M\u00e4dchen lauschen", "tokens": ["Und", "die", "deut\u00b7schen", "M\u00e4d\u00b7chen", "lau\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf die neuste Heldenm\u00e4r'.", "tokens": ["Auf", "die", "neus\u00b7te", "Hel\u00b7den\u00b7m\u00e4r'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Was nicht rein ist, mu\u00df nun sterben,", "tokens": ["Was", "nicht", "rein", "ist", ",", "mu\u00df", "nun", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "ADJD", "VAFIN", "$,", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ewig strahlt das h\u00f6chste Gut,", "tokens": ["E\u00b7wig", "strahlt", "das", "h\u00f6chs\u00b7te", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wahre du den freien Erben", "tokens": ["Wah\u00b7re", "du", "den", "frei\u00b7en", "Er\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fromm und rein dein deutsches Blut.", "tokens": ["Fromm", "und", "rein", "dein", "deut\u00b7sches", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "H\u00f6re mich, du Sohn der Eichen,", "tokens": ["H\u00f6\u00b7re", "mich", ",", "du", "Sohn", "der", "Ei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deines Landes Stolz und Hort,", "tokens": ["Dei\u00b7nes", "Lan\u00b7des", "Stolz", "und", "Hort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bis in Babels Mauern reichen", "tokens": ["Bis", "in", "Ba\u00b7bels", "Mau\u00b7ern", "rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "NE", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Soll das ernste deutsche Wort.", "tokens": ["Soll", "das", "erns\u00b7te", "deut\u00b7sche", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Freiheitsheld, ich mu\u00df dich schelten,", "tokens": ["Frei\u00b7heits\u00b7held", ",", "ich", "mu\u00df", "dich", "schel\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dich verblendet falsches Licht,", "tokens": ["Dich", "ver\u00b7blen\u00b7det", "fal\u00b7sches", "Licht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Freundlichkeit und Gro\u00dfmuth gelten", "tokens": ["Freund\u00b7lich\u00b7keit", "und", "Gro\u00df\u00b7muth", "gel\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht im g\u00f6ttlichen Gericht.", "tokens": ["Nicht", "im", "g\u00f6tt\u00b7li\u00b7chen", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Schau', die Alte, die wir hassen,", "tokens": ["Schau'", ",", "die", "Al\u00b7te", ",", "die", "wir", "has\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welcher flucht die halbe Welt,", "tokens": ["Wel\u00b7cher", "flucht", "die", "hal\u00b7be", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lauert noch in allen Gassen,", "tokens": ["Lau\u00b7ert", "noch", "in", "al\u00b7len", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat auch dir das Netz gestellt.", "tokens": ["Hat", "auch", "dir", "das", "Netz", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "In den Staub war sie gefallen,", "tokens": ["In", "den", "Staub", "war", "sie", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber ihr erschlugt sie nicht,", "tokens": ["A\u00b7ber", "ihr", "er\u00b7schlugt", "sie", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und aus ihren Leichenhallen", "tokens": ["Und", "aus", "ih\u00b7ren", "Lei\u00b7chen\u00b7hal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dringet noch ein schwer Gericht.", "tokens": ["Drin\u00b7get", "noch", "ein", "schwer", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Trunken von der Heil'gen Blute,", "tokens": ["Trun\u00b7ken", "von", "der", "Heil'\u00b7gen", "Blu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An den Ecken, auf dem Stein", "tokens": ["An", "den", "E\u00b7cken", ",", "auf", "dem", "Stein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ladet sie im Uebermuthe", "tokens": ["La\u00b7det", "sie", "im", "Ue\u00b7ber\u00b7mu\u00b7the"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jeden frech zur Buhlschaft ein.", "tokens": ["Je\u00b7den", "frech", "zur", "Buhl\u00b7schaft", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Wer die Buhlschaft je getrieben,", "tokens": ["Wer", "die", "Buhl\u00b7schaft", "je", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer aus ihrem Becher trank,", "tokens": ["Wer", "aus", "ih\u00b7rem", "Be\u00b7cher", "trank", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kann das deutsche Land nicht lieben,", "tokens": ["Kann", "das", "deut\u00b7sche", "Land", "nicht", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist an Ehr' und Tugend krank.", "tokens": ["Ist", "an", "Ehr'", "und", "Tu\u00b7gend", "krank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "KON", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Honigs\u00fc\u00df ist ihre Rede", "tokens": ["Ho\u00b7ni\u00b7gs\u00fc\u00df", "ist", "ih\u00b7re", "Re\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und gef\u00e4rbt ihr Angesicht,", "tokens": ["Und", "ge\u00b7f\u00e4rbt", "ihr", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber biet' ihr offne Fehde,", "tokens": ["A\u00b7ber", "biet'", "ihr", "off\u00b7ne", "Feh\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Spuk betr\u00fcgt dich nicht.", "tokens": ["Und", "der", "Spuk", "be\u00b7tr\u00fcgt", "dich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Sohn, die deutschen B\u00e4ume rauschen,", "tokens": ["Sohn", ",", "die", "deut\u00b7schen", "B\u00e4u\u00b7me", "rau\u00b7schen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die V\u00e4ter blicken her,", "tokens": ["Und", "die", "V\u00e4\u00b7ter", "bli\u00b7cken", "her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die deutschen M\u00e4dchen lauschen", "tokens": ["Und", "die", "deut\u00b7schen", "M\u00e4d\u00b7chen", "lau\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf die neuste Heldenm\u00e4r'.", "tokens": ["Auf", "die", "neus\u00b7te", "Hel\u00b7den\u00b7m\u00e4r'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Was nicht rein ist, mu\u00df nun sterben,", "tokens": ["Was", "nicht", "rein", "ist", ",", "mu\u00df", "nun", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "ADJD", "VAFIN", "$,", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ewig strahlt das h\u00f6chste Gut,", "tokens": ["E\u00b7wig", "strahlt", "das", "h\u00f6chs\u00b7te", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wahre du den freien Erben", "tokens": ["Wah\u00b7re", "du", "den", "frei\u00b7en", "Er\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fromm und rein dein deutsches Blut.", "tokens": ["Fromm", "und", "rein", "dein", "deut\u00b7sches", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}