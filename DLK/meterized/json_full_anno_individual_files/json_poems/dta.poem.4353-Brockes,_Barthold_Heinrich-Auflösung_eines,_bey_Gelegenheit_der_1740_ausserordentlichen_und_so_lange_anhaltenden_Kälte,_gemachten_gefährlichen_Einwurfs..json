{"dta.poem.4353": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Aufl\u00f6sung  \n eines,  \n  bey Gelegenheit  \n der 1740 ausserordentlichen und so lange anhaltenden  \n  K\u00e4lte,  \n gemachten gef\u00e4hrlichen Einwurfs.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ach Gott! wo bleibt der Schmuck der Erden!", "tokens": ["Ach", "Gott", "!", "wo", "bleibt", "der", "Schmuck", "der", "Er\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "PWAV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nachdem sowohl April, als May,", "tokens": ["Nach\u00b7dem", "so\u00b7wohl", "Ap\u00b7ril", ",", "als", "May", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "KON", "NN", "$,", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ohn\u2019 alle ", "tokens": ["Ohn'", "al\u00b7le"], "token_info": ["word", "word"], "pos": ["APPR", "PIAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Soll es denn auch nicht ", "tokens": ["Soll", "es", "denn", "auch", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "PTKNEG"], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Man sieht die W\u00e4lder noch entlaubet,", "tokens": ["Man", "sieht", "die", "W\u00e4l\u00b7der", "noch", "ent\u00b7lau\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Feld noch seines Schmucks beraubet,", "tokens": ["Das", "Feld", "noch", "sei\u00b7nes", "Schmucks", "be\u00b7rau\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den Wiesen fehlt ihr bunter Flor,", "tokens": ["Den", "Wie\u00b7sen", "fehlt", "ihr", "bun\u00b7ter", "Flor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es will fast gar kein Gras hervor.", "tokens": ["Es", "will", "fast", "gar", "kein", "Gras", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Es bleckt das Schaaf, die Rinder br\u00fcllen,", "tokens": ["Es", "bleckt", "das", "Schaaf", ",", "die", "Rin\u00b7der", "br\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie k\u00f6nnen nicht den Hunger stillen,", "tokens": ["Sie", "k\u00f6n\u00b7nen", "nicht", "den", "Hun\u00b7ger", "stil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie reissen manchen d\u00fcrren Straus", "tokens": ["Sie", "reis\u00b7sen", "man\u00b7chen", "d\u00fcr\u00b7ren", "Straus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Wurzeln aus dem Grund heraus.", "tokens": ["Mit", "Wur\u00b7zeln", "aus", "dem", "Grund", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Statt da\u00df sich sonst die schlanken Zungen,", "tokens": ["Statt", "da\u00df", "sich", "sonst", "die", "schlan\u00b7ken", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PRF", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Jm Bi\u00df, um langes Gras geschlungen;", "tokens": ["Jm", "Bi\u00df", ",", "um", "lan\u00b7ges", "Gras", "ge\u00b7schlun\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUI", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So nagt itzt, da das Feld noch blo\u00df,", "tokens": ["So", "nagt", "itzt", ",", "da", "das", "Feld", "noch", "blo\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "KOUS", "ART", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jhr d\u00fcrrer Zahn nur welkes Moo\u00df.", "tokens": ["Ihr", "d\u00fcr\u00b7rer", "Zahn", "nur", "wel\u00b7kes", "Moo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ist denn der rauhe Wind aus Norden", "tokens": ["Ist", "denn", "der", "rau\u00b7he", "Wind", "aus", "Nor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Allein der Winde K\u00f6nig worden?", "tokens": ["Al\u00b7lein", "der", "Win\u00b7de", "K\u00f6\u00b7nig", "wor\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie ruhen all\u2019; er bl\u00e4set nur,", "tokens": ["Sie", "ru\u00b7hen", "all'", ";", "er", "bl\u00e4\u00b7set", "nur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$.", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und st\u00f6hrt die Ordnung der Natur.", "tokens": ["Und", "st\u00f6hrt", "die", "Ord\u00b7nung", "der", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Jm tr\u00fcben Nebel eingeh\u00fcllet,", "tokens": ["Jm", "tr\u00fc\u00b7ben", "Ne\u00b7bel", "ein\u00b7ge\u00b7h\u00fcl\u00b7let", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der unsern ganzen Luft-Kreis f\u00fcllet,", "tokens": ["Der", "un\u00b7sern", "gan\u00b7zen", "Luft\u00b7Kreis", "f\u00fcl\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zeigt die betr\u00fcbte K\u00e4lte sich,", "tokens": ["Zeigt", "die", "be\u00b7tr\u00fcb\u00b7te", "K\u00e4l\u00b7te", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In grauer Farbe, sichtbarlich.", "tokens": ["In", "grau\u00b7er", "Far\u00b7be", ",", "sicht\u00b7bar\u00b7lich", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wie Wolken stets das Licht vermindern,", "tokens": ["Wie", "Wol\u00b7ken", "stets", "das", "Licht", "ver\u00b7min\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So sieht man diese K\u00e4lte hindern,", "tokens": ["So", "sieht", "man", "die\u00b7se", "K\u00e4l\u00b7te", "hin\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df uns der Sonnen rege Kraft", "tokens": ["Da\u00df", "uns", "der", "Son\u00b7nen", "re\u00b7ge", "Kraft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die holde W\u00e4rme nicht verschafft.", "tokens": ["Die", "hol\u00b7de", "W\u00e4r\u00b7me", "nicht", "ver\u00b7schafft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Es scheint, ob woll\u2019 in unsern L\u00e4ndern", "tokens": ["Es", "scheint", ",", "ob", "woll'", "in", "un\u00b7sern", "L\u00e4n\u00b7dern"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Zeiten Wechsel sich ver\u00e4ndern,", "tokens": ["Der", "Zei\u00b7ten", "Wech\u00b7sel", "sich", "ver\u00b7\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es wird, was niemahls noch erh\u00f6rt,", "tokens": ["Es", "wird", ",", "was", "nie\u00b7mahls", "noch", "er\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ordnung der Natur verkehrt.", "tokens": ["Die", "Ord\u00b7nung", "der", "Na\u00b7tur", "ver\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Hier war es, wo der Bluhmen Gl\u00e4nzen", "tokens": ["Hier", "war", "es", ",", "wo", "der", "Bluh\u00b7men", "Gl\u00e4n\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PWAV", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durchs Auge mich zum Sch\u00f6pfer zog;", "tokens": ["Durchs", "Au\u00b7ge", "mich", "zum", "Sch\u00f6p\u00b7fer", "zog", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hier, wo ich sonst den bunten Lenzen,", "tokens": ["Hier", ",", "wo", "ich", "sonst", "den", "bun\u00b7ten", "Len\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu unsers Sch\u00f6pfers Ehr\u2019, erwog;", "tokens": ["Zu", "un\u00b7sers", "Sch\u00f6p\u00b7fers", "Ehr'", ",", "er\u00b7wog", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Hier war es, wo von ihrer Pracht", "tokens": ["Hier", "war", "es", ",", "wo", "von", "ih\u00b7rer", "Pracht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PWAV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fast allenthalben aufgebracht,", "tokens": ["Fast", "al\u00b7len\u00b7thal\u00b7ben", "auf\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich, ihrer Quell\u2019 zu Ehren, sang;", "tokens": ["Ich", ",", "ih\u00b7rer", "Quell'", "zu", "Eh\u00b7ren", ",", "sang", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "APPR", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier, wo mein fr\u00fches Lied erklang;", "tokens": ["Hier", ",", "wo", "mein", "fr\u00fc\u00b7hes", "Lied", "er\u00b7klang", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Hier war es, wo auch meine Luft,", "tokens": ["Hier", "war", "es", ",", "wo", "auch", "mei\u00b7ne", "Luft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PWAV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey eurer sch\u00f6nen Bl\u00fchte, bl\u00fchte;", "tokens": ["Bey", "eu\u00b7rer", "sch\u00f6\u00b7nen", "Bl\u00fch\u00b7te", ",", "bl\u00fch\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hier, wo ich, mit ger\u00fchrter Brust,", "tokens": ["Hier", ",", "wo", "ich", ",", "mit", "ge\u00b7r\u00fchr\u00b7ter", "Brust", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein, durch des Sch\u00f6pfers grosse G\u00fcte,", "tokens": ["Mein", ",", "durch", "des", "Sch\u00f6p\u00b7fers", "gros\u00b7se", "G\u00fc\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$,", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ganz angef\u00fclletes Gem\u00fchte", "tokens": ["Ganz", "an\u00b7ge\u00b7f\u00fcl\u00b7le\u00b7tes", "Ge\u00b7m\u00fch\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Erfreut zu zeigen mich bem\u00fchte.", "tokens": ["Er\u00b7freut", "zu", "zei\u00b7gen", "mich", "be\u00b7m\u00fch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Die\u00df war mein trauriger Gesang, den ich, wie sich kein", "tokens": ["Die\u00df", "war", "mein", "trau\u00b7ri\u00b7ger", "Ge\u00b7sang", ",", "den", "ich", ",", "wie", "sich", "kein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "PPER", "$,", "PWAV", "PRF", "PIAT"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Fr\u00fchling wies,", "tokens": ["Fr\u00fch\u00b7ling", "wies", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Noch gestern, unter d\u00fcrren B\u00e4umen, auf \u00f6den Feldern,", "tokens": ["Noch", "ge\u00b7stern", ",", "un\u00b7ter", "d\u00fcr\u00b7ren", "B\u00e4u\u00b7men", ",", "auf", "\u00f6\u00b7den", "Fel\u00b7dern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "---+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "schallen lie\u00df.", "tokens": ["schal\u00b7len", "lie\u00df", "."], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Als heute f\u00fcg ich ihm annoch, da noch das Wetter einerley,", "tokens": ["Als", "heu\u00b7te", "f\u00fcg", "ich", "ihm", "an\u00b7noch", ",", "da", "noch", "das", "Wet\u00b7ter", "ei\u00b7ner\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$,", "KOUS", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.6": {"text": "Mit eben so betr\u00fcbtem Sinn, die folgende Gedanken bey:", "tokens": ["Mit", "e\u00b7ben", "so", "be\u00b7tr\u00fcb\u00b7tem", "Sinn", ",", "die", "fol\u00b7gen\u00b7de", "Ge\u00b7dan\u00b7ken", "bey", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.13": {"line.1": {"text": "Die Bluhmen- Bl\u00e4tter- Kr\u00e4uter- Vieh- und Menschen-", "tokens": ["Die", "Bluh\u00b7men", "Bl\u00e4t\u00b7ter", "Kr\u00e4u\u00b7ter", "Vieh", "und", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "TRUNC", "TRUNC", "TRUNC", "TRUNC", "KON", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "m\u00f6rderische K\u00e4lte", "tokens": ["m\u00f6r\u00b7de\u00b7ri\u00b7sche", "K\u00e4l\u00b7te"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hat, leider! noch nicht ausgeras\u2019t. Der May, der uns die", "tokens": ["Hat", ",", "lei\u00b7der", "!", "noch", "nicht", "aus\u00b7ge\u00b7ras'", "t.", "Der", "May", ",", "der", "uns", "die"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "abbreviation", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "$,", "ADV", "$.", "ADV", "PTKNEG", "NE", "NE", "ART", "NN", "$,", "PRELS", "PPER", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Felder gr\u00fcn,", "tokens": ["Fel\u00b7der", "gr\u00fcn", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Den Wald belaubt, die G\u00e4rten bunt, in jedem Jahr vor", "tokens": ["Den", "Wald", "be\u00b7laubt", ",", "die", "G\u00e4r\u00b7ten", "bunt", ",", "in", "je\u00b7dem", "Jahr", "vor"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$,", "ART", "NN", "ADJD", "$,", "APPR", "PIAT", "NN", "APPR"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Augen stellte,", "tokens": ["Au\u00b7gen", "stell\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Scheint in des kalten Jenners Tracht zu kommen, und sich", "tokens": ["Scheint", "in", "des", "kal\u00b7ten", "Jen\u00b7ners", "Tracht", "zu", "kom\u00b7men", ",", "und", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "NN", "PTKZU", "VVINF", "$,", "KON", "PRF"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "wegzuziehn,", "tokens": ["weg\u00b7zu\u00b7ziehn", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Eilt \u00fcber Bl\u00e4tter-lose Wipfel, begleitet von dem rauhen", "tokens": ["Eilt", "\u00fc\u00b7ber", "Bl\u00e4t\u00b7ter\u00b7lo\u00b7se", "Wip\u00b7fel", ",", "be\u00b7glei\u00b7tet", "von", "dem", "rau\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "NN", "$,", "VVPP", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "Nord,", "tokens": ["Nord", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+", "measure": "single.up"}, "line.11": {"text": "Und \u00fcber schmutzig-welke Felder, entstellt, betr\u00fcbt und", "tokens": ["Und", "\u00fc\u00b7ber", "schmut\u00b7zig\u00b7wel\u00b7ke", "Fel\u00b7der", ",", "ent\u00b7stellt", ",", "be\u00b7tr\u00fcbt", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "$,", "VVFIN", "$,", "VVPP", "KON"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "gr\u00e4mlich, fort.", "tokens": ["gr\u00e4m\u00b7lich", ",", "fort", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "PTKVZ", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Ach! rief ich: Hier, wo ich vor dem, mit Lust, zu eben die-", "tokens": ["Ach", "!", "rief", "ich", ":", "Hier", ",", "wo", "ich", "vor", "dem", ",", "mit", "Lust", ",", "zu", "e\u00b7ben", "die"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "$.", "ADV", "$,", "PWAV", "PPER", "APPR", "ART", "$,", "APPR", "NN", "$,", "APPR", "ADV", "TRUNC"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "ser Zeit,", "tokens": ["ser", "Zeit", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.15": {"text": "In vorigen vergangnen Jahren, im holden Gr\u00fcnen, allbe-", "tokens": ["In", "vo\u00b7ri\u00b7gen", "ver\u00b7gang\u00b7nen", "Jah\u00b7ren", ",", "im", "hol\u00b7den", "Gr\u00fc\u00b7nen", ",", "all\u00b7be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "$,", "TRUNC"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.16": {"text": "reit,", "tokens": ["reit", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+", "measure": "single.up"}}, "stanza.14": {"line.1": {"text": "Mein, durch die Anmuht der Natur, erregt- und ange-", "tokens": ["Mein", ",", "durch", "die", "An\u00b7muht", "der", "Na\u00b7tur", ",", "er\u00b7reg\u00b7t", "und", "an\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "$,", "APPR", "ART", "NN", "ART", "NN", "$,", "TRUNC", "KON", "TRUNC"], "meter": "-+-+---+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "stimmtes Singen,", "tokens": ["stimm\u00b7tes", "Sin\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Dem Sch\u00f6pfer der Natur zum Ruhm, vergn\u00fcgte Lieder", "tokens": ["Dem", "Sch\u00f6p\u00b7fer", "der", "Na\u00b7tur", "zum", "Ruhm", ",", "ver\u00b7gn\u00fcg\u00b7te", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "APPRART", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "lie\u00df erklingen,", "tokens": ["lie\u00df", "er\u00b7klin\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Erblickt itzt, stumm, f\u00fcr Gram und Sorgen, durchs Auge,", "tokens": ["Er\u00b7blickt", "itzt", ",", "stumm", ",", "f\u00fcr", "Gram", "und", "Sor\u00b7gen", ",", "durchs", "Au\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "ADJD", "$,", "APPR", "NN", "KON", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "mein betr\u00fcbter Geist,", "tokens": ["mein", "be\u00b7tr\u00fcb\u00b7ter", "Geist", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Wie sich von dem, was sonst im Fr\u00fchling die Erde schm\u00fccket,", "tokens": ["Wie", "sich", "von", "dem", ",", "was", "sonst", "im", "Fr\u00fch\u00b7ling", "die", "Er\u00b7de", "schm\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "APPR", "ART", "$,", "PRELS", "ADV", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "nichts fast weist.", "tokens": ["nichts", "fast", "weist", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Welch Anblick, da ich die Verwirrung der Jahres-Zeiten", "tokens": ["Welch", "An\u00b7blick", ",", "da", "ich", "die", "Ver\u00b7wir\u00b7rung", "der", "Jah\u00b7res\u00b7Zei\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "KOUS", "PPER", "ART", "NN", "ART", "NN"], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}, "line.10": {"text": "\u00fcberlegte,", "tokens": ["\u00fc\u00b7ber\u00b7leg\u00b7te", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.11": {"text": "Mich selber mit Verwirrung f\u00fcllte, und so zu denken mich", "tokens": ["Mich", "sel\u00b7ber", "mit", "Ver\u00b7wir\u00b7rung", "f\u00fcll\u00b7te", ",", "und", "so", "zu", "den\u00b7ken", "mich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "NN", "VVFIN", "$,", "KON", "ADV", "PTKZU", "VVINF", "PPER"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "bewegte:", "tokens": ["be\u00b7weg\u00b7te", ":"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.15": {"line.1": {"text": "K\u00e4m\u2019 auf den Frost kein Fr\u00fchling wieder, h\u00f6rt\u2019 einst der", "tokens": ["K\u00e4m'", "auf", "den", "Frost", "kein", "Fr\u00fch\u00b7ling", "wie\u00b7der", ",", "h\u00f6rt'", "einst", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN", "PIAT", "NN", "ADV", "$,", "VVFIN", "ADV", "ART"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Zeiten Wechsel-Lauf,", "tokens": ["Zei\u00b7ten", "Wech\u00b7sel\u00b7Lauf", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "In seiner unverr\u00fcckten Ordnung, die nimmermehr gefehlet,", "tokens": ["In", "sei\u00b7ner", "un\u00b7ver\u00b7r\u00fcck\u00b7ten", "Ord\u00b7nung", ",", "die", "nim\u00b7mer\u00b7mehr", "ge\u00b7feh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "auf;", "tokens": ["auf", ";"], "token_info": ["word", "punct"], "pos": ["PTKVZ", "$."], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Verl\u00f6hr mein irdisches Vergn\u00fcgen in GOtt, sich nicht alleine", "tokens": ["Ver\u00b7l\u00f6hr", "mein", "ir\u00b7di\u00b7sches", "Ver\u00b7gn\u00fc\u00b7gen", "in", "Gott", ",", "sich", "nicht", "al\u00b7lei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "APPR", "NN", "$,", "PRF", "PTKNEG", "ADV"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.6": {"text": "nur;", "tokens": ["nur", ";"], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Es w\u00fcrde der so feste Grund der festen Ordnung der Natur,", "tokens": ["Es", "w\u00fcr\u00b7de", "der", "so", "fes\u00b7te", "Grund", "der", "fes\u00b7ten", "Ord\u00b7nung", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADV", "ADJA", "NN", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.8": {"text": "Von einer weisen Macht gest\u00fctzt, in allen menschlichen Ge-", "tokens": ["Von", "ei\u00b7ner", "wei\u00b7sen", "Macht", "ge\u00b7st\u00fctzt", ",", "in", "al\u00b7len", "menschli\u00b7chen", "Ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.9": {"text": "danken,", "tokens": ["dan\u00b7ken", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Zum Schaden, der unwiederbringlich, nebst Zuversicht und", "tokens": ["Zum", "Scha\u00b7den", ",", "der", "un\u00b7wie\u00b7der\u00b7bring\u00b7lich", ",", "nebst", "Zu\u00b7ver\u00b7sicht", "und"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "PRELS", "ADJD", "$,", "APPR", "NN", "KON"], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}, "line.11": {"text": "Hoffnung, wanken.", "tokens": ["Hoff\u00b7nung", ",", "wan\u00b7ken", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.16": {"line.1": {"text": "Es w\u00fcrd\u2019 ein blindes Ungefehr sich suchen auf den Thron", "tokens": ["Es", "w\u00fcrd'", "ein", "blin\u00b7des", "Un\u00b7ge\u00b7fehr", "sich", "su\u00b7chen", "auf", "den", "Thron"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "PRF", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "zu schwingen,", "tokens": ["zu", "schwin\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Und sich bem\u00fchen wenigstens zur Ungewi\u00dfheit uns zu brin-", "tokens": ["Und", "sich", "be\u00b7m\u00fc\u00b7hen", "we\u00b7nigs\u00b7tens", "zur", "Un\u00b7ge\u00b7wi\u00df\u00b7heit", "uns", "zu", "brin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PRF", "VVFIN", "ADV", "APPRART", "NN", "PPER", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.4": {"text": "gen.", "tokens": ["gen", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Wobey Du, GOtt! zwar nichts verl\u00f6hrst, als ewig und", "tokens": ["Wo\u00b7bey", "Du", ",", "Gott", "!", "zwar", "nichts", "ver\u00b7l\u00f6hrst", ",", "als", "e\u00b7wig", "und"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "NN", "$.", "ADV", "PIS", "VVFIN", "$,", "KOUS", "ADJD", "KON"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "unwandelbar,", "tokens": ["un\u00b7wan\u00b7del\u00b7bar", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Der ist, und ewig bleiben wird das, was Er ist und ewig", "tokens": ["Der", "ist", ",", "und", "e\u00b7wig", "blei\u00b7ben", "wird", "das", ",", "was", "Er", "ist", "und", "e\u00b7wig"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "$,", "KON", "ADJD", "VVINF", "VAFIN", "PDS", "$,", "PRELS", "PPER", "VAFIN", "KON", "ADJD"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.8": {"text": "war.", "tokens": ["war", "."], "token_info": ["word", "punct"], "pos": ["VAFIN", "$."], "meter": "-", "measure": "single.down"}}, "stanza.17": {"line.1": {"text": "Allein, welch ein geschminkter Zweifel w\u00fcrd\u2019 unsre Kum-", "tokens": ["Al\u00b7lein", ",", "welch", "ein", "ge\u00b7schmink\u00b7ter", "Zwei\u00b7fel", "w\u00fcrd'", "uns\u00b7re", "Kum"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAT", "ART", "ADJA", "NN", "VAFIN", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "mer-reiche Seelen,", "tokens": ["mer\u00b7rei\u00b7che", "See\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Durch der Natur gest\u00f6rte Ordnung und ganz verr\u00fcckten", "tokens": ["Durch", "der", "Na\u00b7tur", "ge\u00b7st\u00f6r\u00b7te", "Ord\u00b7nung", "und", "ganz", "ver\u00b7r\u00fcck\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "KON", "ADV", "ADJA"], "meter": "+--+-+-+--+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Lauf, nicht qu\u00e4len!", "tokens": ["Lauf", ",", "nicht", "qu\u00e4\u00b7len", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PTKNEG", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Wie w\u00fcrd\u2019, in ihrem groben Jrrthum, die stolze Schaar", "tokens": ["Wie", "w\u00fcrd'", ",", "in", "ih\u00b7rem", "gro\u00b7ben", "Jrr\u00b7thum", ",", "die", "stol\u00b7ze", "Schaar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "der Atheisten", "tokens": ["der", "A\u00b7theis\u00b7ten"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "--+-", "measure": "anapaest.init"}, "line.7": {"text": "Sich dieses nicht zu Nutze machen, und sich ganz unertr\u00e4g-", "tokens": ["Sich", "die\u00b7ses", "nicht", "zu", "Nut\u00b7ze", "ma\u00b7chen", ",", "und", "sich", "ganz", "un\u00b7er\u00b7tr\u00e4g"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "PDS", "PTKNEG", "PTKZU", "VVFIN", "VVINF", "$,", "KON", "PRF", "ADV", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "lich br\u00fcsten!", "tokens": ["lich", "br\u00fcs\u00b7ten", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "\u201cwas sagt ihr? (w\u00fcrd\u2019 er freventlich von unsers Glau-", "tokens": ["\u201c", "was", "sagt", "ihr", "?", "(", "w\u00fcrd'", "er", "fre\u00b7vent\u00b7lich", "von", "un\u00b7sers", "Glau"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$.", "$(", "VAFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "bens Grunde sprechen,", "tokens": ["bens", "Grun\u00b7de", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "\u201eder auf die Ordnung der Natur sich fu\u00dft und stutzt)", "tokens": ["\u201e", "der", "auf", "die", "Ord\u00b7nung", "der", "Na\u00b7tur", "sich", "fu\u00dft", "und", "stutzt", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "APPR", "ART", "NN", "ART", "NN", "PRF", "ADJD", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Was sagt ihr nun?", "tokens": ["Was", "sagt", "ihr", "nun", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "\u201ekann eine Gottheit, die nicht irrt, ihr einst gegebnes", "tokens": ["\u201e", "kann", "ei\u00b7ne", "Got\u00b7theit", ",", "die", "nicht", "irrt", ",", "ihr", "einst", "ge\u00b7geb\u00b7nes"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "VMFIN", "ART", "NN", "$,", "PRELS", "PTKNEG", "VVFIN", "$,", "PPER", "ADV", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wort wohl brechen?", "tokens": ["Wort", "wohl", "bre\u00b7chen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.15": {"text": "\u201eselbst was die Regel der Natur, ja was selbst eure", "tokens": ["\u201e", "selbst", "was", "die", "Re\u00b7gel", "der", "Na\u00b7tur", ",", "ja", "was", "selbst", "eu\u00b7re"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "PWS", "ART", "NN", "ART", "NN", "$,", "ADV", "PWS", "ADV", "PPOSAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Bibel spricht:", "tokens": ["Bi\u00b7bel", "spricht", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.17": {"text": "\u201edem Winter soll der Fr\u00fchling folgen, bestehet und", "tokens": ["\u201e", "dem", "Win\u00b7ter", "soll", "der", "Fr\u00fch\u00b7ling", "fol\u00b7gen", ",", "be\u00b7ste\u00b7het", "und"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "ART", "NN", "VMFIN", "ART", "NN", "VVINF", "$,", "VVFIN", "KON"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "geschicht ja nicht.", "tokens": ["ge\u00b7schicht", "ja", "nicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "ADV", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.19": {"text": "\u201eeinfolglich f\u00e4llet alles weg, worauf ihr alles das", "tokens": ["\u201e", "ein\u00b7folg\u00b7lich", "f\u00e4l\u00b7let", "al\u00b7les", "weg", ",", "wo\u00b7rauf", "ihr", "al\u00b7les", "das"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "VVFIN", "PIS", "PTKVZ", "$,", "PWAV", "PPER", "PIS", "ART"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.20": {"text": "gebauet,", "tokens": ["ge\u00b7bau\u00b7et", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.21": {"text": "\u201eda man, bey aufgehabner Ordnung, auch ferner keine", "tokens": ["\u201e", "da", "man", ",", "bey", "auf\u00b7ge\u00b7hab\u00b7ner", "Ord\u00b7nung", ",", "auch", "fer\u00b7ner", "kei\u00b7ne"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "KOUS", "PIS", "$,", "APPR", "ADJA", "NN", "$,", "ADV", "ADV", "PIAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Gottheit schauet,", "tokens": ["Got\u00b7theit", "schau\u00b7et", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.23": {"text": "\u201edie blo\u00df die Ordnung euch gezeigt, und euch zu glau-", "tokens": ["\u201e", "die", "blo\u00df", "die", "Ord\u00b7nung", "euch", "ge\u00b7zeigt", ",", "und", "euch", "zu", "glau"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADV", "ART", "NN", "PPER", "VVPP", "$,", "KON", "PPER", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "ben reizt. Allein,", "tokens": ["ben", "reizt", ".", "Al\u00b7lein", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VVPP", "VVFIN", "$.", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.25": {"text": "Halt! rief ich, wie ich mich besann, verwegner Atheist, halt", "tokens": ["Halt", "!", "rief", "ich", ",", "wie", "ich", "mich", "be\u00b7sann", ",", "ver\u00b7weg\u00b7ner", "A\u00b7theist", ",", "halt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["VVIMP", "$.", "VVFIN", "PPER", "$,", "PWAV", "PPER", "PRF", "VVFIN", "$,", "ADJA", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.26": {"text": "ein!", "tokens": ["ein", "!"], "token_info": ["word", "punct"], "pos": ["PTKVZ", "$."], "meter": "-", "measure": "single.down"}, "line.27": {"text": "Auch du, mein Geist! besinne dich; leg Hand und Finger auf", "tokens": ["Auch", "du", ",", "mein", "Geist", "!", "be\u00b7sin\u00b7ne", "dich", ";", "leg", "Hand", "und", "Fin\u00b7ger", "auf"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "$.", "NE", "NN", "KON", "NN", "APPR"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.28": {"text": "den Mund.", "tokens": ["den", "Mund", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.29": {"text": "Es hat der Atheisten Bosheit, auch deine Schwachheit,", "tokens": ["Es", "hat", "der", "A\u00b7theis\u00b7ten", "Bos\u00b7heit", ",", "auch", "dei\u00b7ne", "Schwach\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.30": {"text": "keinen Grund.", "tokens": ["kei\u00b7nen", "Grund", "."], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.18": {"line.1": {"text": "Ist ein umschr\u00e4nkter Menschen-Geist, so wie er ist, mit", "tokens": ["Ist", "ein", "um\u00b7schr\u00e4nk\u00b7ter", "Men\u00b7schen\u00b7Geist", ",", "so", "wie", "er", "ist", ",", "mit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,", "ADV", "KOKOM", "PPER", "VAFIN", "$,", "APPR"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Recht so k\u00fchn", "tokens": ["Recht", "so", "k\u00fchn"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADV", "ADJD"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Zu fassen, ob nicht die Ver\u00e4ndrung in der Natur zu etwas", "tokens": ["Zu", "fas\u00b7sen", ",", "ob", "nicht", "die", "Ver\u00b7\u00e4n\u00b7drung", "in", "der", "Na\u00b7tur", "zu", "et\u00b7was"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "KOUS", "PTKNEG", "ART", "NN", "APPR", "ART", "NN", "APPR", "PIS"], "meter": "-+-+-+-+-++-+-+-", "measure": "unknown.measure.octa.plus"}, "line.4": {"text": "dien',", "tokens": ["dien'", ","], "token_info": ["word", "punct"], "pos": ["PDS", "$,"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "So wir, aus Schwachheit, nicht begreifen? Zudem, so kann", "tokens": ["So", "wir", ",", "aus", "Schwach\u00b7heit", ",", "nicht", "be\u00b7grei\u00b7fen", "?", "Zu\u00b7dem", ",", "so", "kann"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "PPER", "$,", "APPR", "NN", "$,", "PTKNEG", "VVINF", "$.", "PAV", "$,", "ADV", "VMFIN"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "es ja geschehn,", "tokens": ["es", "ja", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Da\u00df wir schon Morgen alle Pracht des sch\u00f6nen Fr\u00fchlings", "tokens": ["Da\u00df", "wir", "schon", "Mor\u00b7gen", "al\u00b7le", "Pracht", "des", "sch\u00f6\u00b7nen", "Fr\u00fch\u00b7lings"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "NN", "PIAT", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "wieder sehn.", "tokens": ["wie\u00b7der", "sehn", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Die Knospen sind ja schon geschwollen, des Grases Spitzen", "tokens": ["Die", "Knos\u00b7pen", "sind", "ja", "schon", "ge\u00b7schwol\u00b7len", ",", "des", "Gra\u00b7ses", "Spit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$,", "ART", "ADJA", "NN"], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}, "line.10": {"text": "zeigen sich,", "tokens": ["zei\u00b7gen", "sich", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,"], "meter": "+--", "measure": "dactylic.init"}, "line.11": {"text": "Und warten nur auf etwas W\u00e4rme. Hat gleich der Winter", "tokens": ["Und", "war\u00b7ten", "nur", "auf", "et\u00b7was", "W\u00e4r\u00b7me", ".", "Hat", "gleich", "der", "Win\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PIAT", "NN", "$.", "VAFIN", "ADV", "ART", "NN"], "meter": "-+---+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "grimmiglich,", "tokens": ["grim\u00b7mig\u00b7lich", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Und mehr, als je geschehn, geras\u2019t; so siehet man doch offen-", "tokens": ["Und", "mehr", ",", "als", "je", "ge\u00b7schehn", ",", "ge\u00b7ras't", ";", "so", "sie\u00b7het", "man", "doch", "of\u00b7fen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUS", "ADV", "VVPP", "$,", "VVPP", "$.", "ADV", "VVFIN", "PIS", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.14": {"text": "bar,", "tokens": ["bar", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+", "measure": "single.up"}, "line.15": {"text": "Der Saamen ist doch nicht erfroren. Man wird noch \u00fcber-", "tokens": ["Der", "Saa\u00b7men", "ist", "doch", "nicht", "er\u00b7fro\u00b7ren", ".", "Man", "wird", "noch", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "VVINF", "$.", "PIS", "VAFIN", "ADV", "TRUNC"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "dem gewahr,", "tokens": ["dem", "ge\u00b7wahr", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.17": {"text": "Da\u00df auch der Rocken unversehrt, wie stark der Frost gew\u00fctet,", "tokens": ["Da\u00df", "auch", "der", "Ro\u00b7cken", "un\u00b7ver\u00b7sehrt", ",", "wie", "stark", "der", "Frost", "ge\u00b7w\u00fc\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "$,", "PWAV", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.18": {"text": "blieben.", "tokens": ["blie\u00b7ben", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.19": {"text": "Man sieht ihn, auch bey kalter Luft, die gr\u00fcnen Spitzen", "tokens": ["Man", "sieht", "ihn", ",", "auch", "bey", "kal\u00b7ter", "Luft", ",", "die", "gr\u00fc\u00b7nen", "Spit\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "$,", "ADV", "APPR", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "aufwerts schieben.", "tokens": ["auf\u00b7werts", "schie\u00b7ben", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.19": {"line.1": {"text": "Ja, wenn es gleich noch schlimmer w\u00e4re; gesetzt,", "tokens": ["Ja", ",", "wenn", "es", "gleich", "noch", "schlim\u00b7mer", "w\u00e4\u00b7re", ";", "ge\u00b7setzt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$.", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "das \u00fcberbliebne Vieh", "tokens": ["das", "\u00fc\u00b7berb\u00b7lieb\u00b7ne", "Vieh"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "St\u00fcrb\u2019 alles, ja die Menschen selber: so w\u00fcrde dieses", "tokens": ["St\u00fcrb'", "al\u00b7les", ",", "ja", "die", "Men\u00b7schen", "sel\u00b7ber", ":", "so", "w\u00fcr\u00b7de", "die\u00b7ses"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PIS", "$,", "ADV", "ART", "NN", "ADV", "$.", "ADV", "VAFIN", "PDAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Elend nie", "tokens": ["E\u00b7lend", "nie"], "token_info": ["word", "word"], "pos": ["NN", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Den ganzen Erd-Kreis doch betreffen. Ja, wenn auch", "tokens": ["Den", "gan\u00b7zen", "Erd\u00b7Kreis", "doch", "be\u00b7tref\u00b7fen", ".", "Ja", ",", "wenn", "auch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "$.", "PTKANT", "$,", "KOUS", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "dieses m\u00f6glich w\u00e4re;", "tokens": ["die\u00b7ses", "m\u00f6g\u00b7lich", "w\u00e4\u00b7re", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJD", "VAFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "So folget doch noch lange nicht der Schlu\u00df der ungl\u00fcckselgen", "tokens": ["So", "fol\u00b7get", "doch", "noch", "lan\u00b7ge", "nicht", "der", "Schlu\u00df", "der", "un\u00b7gl\u00fcck\u00b7sel\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ADV", "PTKNEG", "ART", "NN", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.8": {"text": "Lehre:", "tokens": ["Leh\u00b7re", ":"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "Es sey kein GOtt. Die Millionen von so viel andern Erden", "tokens": ["Es", "sey", "kein", "Gott", ".", "Die", "Mil\u00b7lion\u00b7en", "von", "so", "viel", "an\u00b7dern", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$.", "ART", "NN", "APPR", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.10": {"text": "blieben,", "tokens": ["blie\u00b7ben", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.11": {"text": "Und zeigten, nach wie vor, die Proben von einer Gottheit,", "tokens": ["Und", "zeig\u00b7ten", ",", "nach", "wie", "vor", ",", "die", "Pro\u00b7ben", "von", "ei\u00b7ner", "Got\u00b7theit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPR", "KOKOM", "APPR", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+---+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Macht und Lieben.", "tokens": ["Macht", "und", "Lie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.20": {"line.1": {"text": "Obgleich die S\u00fcndfluht unsre Erde ganz umgekehret und", "tokens": ["Ob\u00b7gleich", "die", "S\u00fcnd\u00b7fluht", "uns\u00b7re", "Er\u00b7de", "ganz", "um\u00b7ge\u00b7keh\u00b7ret", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN", "ADV", "VVPP", "KON"], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "verst\u00f6rt;", "tokens": ["ver\u00b7st\u00f6rt", ";"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "So hat dennoch der Gottheit Wesen dadurch bey keinem", "tokens": ["So", "hat", "den\u00b7noch", "der", "Got\u00b7theit", "We\u00b7sen", "da\u00b7durch", "bey", "kei\u00b7nem"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "NN", "PAV", "APPR", "PIAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "aufgeh\u00f6rt.", "tokens": ["auf\u00b7ge\u00b7h\u00f6rt", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.21": {"line.1": {"text": "Sprich nicht, bey solcher Aenderung der weisen Ordnung-", "tokens": ["Sprich", "nicht", ",", "bey", "sol\u00b7cher", "A\u00b7en\u00b7de\u00b7rung", "der", "wei\u00b7sen", "Ord\u00b7nung"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PTKNEG", "$,", "APPR", "PIAT", "NN", "ART", "ADJA", "TRUNC"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "gen, wo bliebe,", "tokens": ["gen", ",", "wo", "blie\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWAV", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Nebst Seinem einst gesprochnen Wort, absonderlich des", "tokens": ["Nebst", "Sei\u00b7nem", "einst", "ge\u00b7sproch\u00b7nen", "Wort", ",", "ab\u00b7son\u00b7der\u00b7lich", "des"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPOSAT", "ADV", "ADJA", "NN", "$,", "ADJD", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sch\u00f6pfers Liebe?", "tokens": ["Sch\u00f6p\u00b7fers", "Lie\u00b7be", "?"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Denn h\u00f6r\u2019: Ist wohl des Sch\u00f6pfers Lieben nach unserm", "tokens": ["Denn", "h\u00f6r'", ":", "Ist", "wohl", "des", "Sch\u00f6p\u00b7fers", "Lie\u00b7ben", "nach", "un\u00b7serm"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "VAFIN", "ADV", "ART", "NN", "ADJA", "APPR", "PPOSAT"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Lieben abzumessen?", "tokens": ["Lie\u00b7ben", "ab\u00b7zu\u00b7mes\u00b7sen", "?"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "VVIZU", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Gott liebt in Absicht auf das Ganze, die\u00df mu\u00df die Mensch-", "tokens": ["Gott", "liebt", "in", "Ab\u00b7sicht", "auf", "das", "Gan\u00b7ze", ",", "die\u00df", "mu\u00df", "die", "Men\u00b7sch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$,", "PDS", "VMFIN", "ART", "TRUNC"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "heit nicht vergessen,", "tokens": ["heit", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Ein jeder wird dennoch geliebt, ob man es \u00f6fters selbst nicht", "tokens": ["Ein", "je\u00b7der", "wird", "den\u00b7noch", "ge\u00b7liebt", ",", "ob", "man", "es", "\u00f6f\u00b7ters", "selbst", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VAFIN", "ADV", "VVPP", "$,", "KOUS", "PIS", "PPER", "ADV", "ADV", "PTKNEG"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.10": {"text": "sp\u00fchrt;", "tokens": ["sp\u00fchrt", ";"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-", "measure": "single.down"}, "line.11": {"text": "Indem die Gottheit alle Ding\u2019 zu einem guten Ende f\u00fchrt,", "tokens": ["In\u00b7dem", "die", "Got\u00b7theit", "al\u00b7le", "Ding'", "zu", "ei\u00b7nem", "gu\u00b7ten", "En\u00b7de", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIAT", "NN", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.12": {"text": "Kann unser Witz es gleich nicht fassen. Mich deucht, du", "tokens": ["Kann", "un\u00b7ser", "Witz", "es", "gleich", "nicht", "fas\u00b7sen", ".", "Mich", "deucht", ",", "du"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["VMFIN", "PPOSAT", "NN", "PPER", "ADV", "PTKNEG", "VVINF", "$.", "PPER", "VVFIN", "$,", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "wirfst mir ferner ein:", "tokens": ["wirfst", "mir", "fer\u00b7ner", "ein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "Wenn auch die Menschen wo zu strafen, und billig heimzusu-", "tokens": ["Wenn", "auch", "die", "Men\u00b7schen", "wo", "zu", "stra\u00b7fen", ",", "und", "bil\u00b7lig", "heim\u00b7zu\u00b7su"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "PWAV", "PTKZU", "VVINF", "$,", "KON", "ADJD", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.15": {"text": "chen seyn,", "tokens": ["chen", "seyn", ","], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAINF", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.16": {"text": "Was kann das arme Vieh daf\u00fcr, da\u00df es so elend leiden", "tokens": ["Was", "kann", "das", "ar\u00b7me", "Vieh", "da\u00b7f\u00fcr", ",", "da\u00df", "es", "so", "e\u00b7lend", "lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "ART", "ADJA", "NN", "PAV", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.17": {"text": "mu\u00df?", "tokens": ["mu\u00df", "?"], "token_info": ["word", "punct"], "pos": ["VMFIN", "$."], "meter": "+", "measure": "single.up"}, "line.18": {"text": "Auch hierinn, ob du es kaum glaubst, fehlt doch dein \u00fcber-", "tokens": ["Auch", "hie\u00b7rinn", ",", "ob", "du", "es", "kaum", "glaubst", ",", "fehlt", "doch", "dein", "\u00fc\u00b7ber"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "ADV", "PPOSAT", "TRUNC"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "eilter Schlu\u00df.", "tokens": ["eil\u00b7ter", "Schlu\u00df", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.20": {"text": "Mu\u00df denn das Vieh nicht einmahl sterben? Und h\u00e4tten viele", "tokens": ["Mu\u00df", "denn", "das", "Vieh", "nicht", "ein\u00b7mahl", "ster\u00b7ben", "?", "Und", "h\u00e4t\u00b7ten", "vie\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "NN", "PTKNEG", "ADV", "VVINF", "$.", "KON", "VAFIN", "PIAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "nicht mehr Plagen", "tokens": ["nicht", "mehr", "Pla\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "PIAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.22": {"text": "Bey einem l\u00e4ngern Leben noch erleiden m\u00fcssen und er-", "tokens": ["Bey", "ei\u00b7nem", "l\u00e4n\u00b7gern", "Le\u00b7ben", "noch", "er\u00b7lei\u00b7den", "m\u00fcs\u00b7sen", "und", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ADV", "VVINF", "VMFIN", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.23": {"text": "tragen?", "tokens": ["tra\u00b7gen", "?"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.24": {"text": "Nach noch viel tausend Geissel-Schl\u00e4gen, von Alter lahm,", "tokens": ["Nach", "noch", "viel", "tau\u00b7send", "Geis\u00b7sel\u00b7Schl\u00e4\u00b7gen", ",", "von", "Al\u00b7ter", "lahm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "CARD", "NN", "$,", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "h\u00e4tt' es sich strecken,", "tokens": ["h\u00e4tt'", "es", "sich", "stre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "VVFIN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.26": {"text": "Jm kalten Winter ausgejagt, von Hunger ausgezehrt, ver-", "tokens": ["Jm", "kal\u00b7ten", "Win\u00b7ter", "aus\u00b7ge\u00b7jagt", ",", "von", "Hun\u00b7ger", "aus\u00b7ge\u00b7zehrt", ",", "ver"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "$,", "APPR", "NN", "VVPP", "$,", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.27": {"text": "recken,", "tokens": ["re\u00b7cken", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}}}}}