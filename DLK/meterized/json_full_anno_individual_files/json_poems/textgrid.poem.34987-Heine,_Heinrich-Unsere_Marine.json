{"textgrid.poem.34987": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Unsere Marine", "genre": "verse", "period": "N.A.", "pub_year": 1844, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir tr\u00e4umten von einer Flotte j\u00fcngst,", "tokens": ["Wir", "tr\u00e4um\u00b7ten", "von", "ei\u00b7ner", "Flot\u00b7te", "j\u00fcngst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und segelten schon vergn\u00fcglich", "tokens": ["Und", "se\u00b7gel\u00b7ten", "schon", "ver\u00b7gn\u00fcg\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hinaus aufs balkenlose Meer,", "tokens": ["Hin\u00b7aus", "aufs", "bal\u00b7ken\u00b7lo\u00b7se", "Meer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Wind war ganz vorz\u00fcglich.", "tokens": ["Der", "Wind", "war", "ganz", "vor\u00b7z\u00fcg\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wir hatten unsern Fregatten schon", "tokens": ["Wir", "hat\u00b7ten", "un\u00b7sern", "Fre\u00b7gat\u00b7ten", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die stolzesten Namen gegeben,", "tokens": ["Die", "stol\u00b7zes\u00b7ten", "Na\u00b7men", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Prutz hie\u00df die eine, die andre hie\u00df", "tokens": ["Prutz", "hie\u00df", "die", "ei\u00b7ne", ",", "die", "and\u00b7re", "hie\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ART", "$,", "PRELS", "PIS", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hoffmann von Fallersleben.", "tokens": ["Hoff\u00b7mann", "von", "Fal\u00b7lers\u00b7le\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.3": {"line.1": {"text": "Da schwamm der Kutter Freiligrath,", "tokens": ["Da", "schwamm", "der", "Kut\u00b7ter", "Frei\u00b7li\u00b7gra\u00b7th", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.2": {"text": "Darauf als Puppe die B\u00fcste", "tokens": ["Da\u00b7rauf", "als", "Pup\u00b7pe", "die", "B\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "KOUS", "NN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Des Mohrenk\u00f6nigs, die wie ein Mond", "tokens": ["Des", "Moh\u00b7ren\u00b7k\u00f6\u00b7nigs", ",", "die", "wie", "ein", "Mond"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "KOKOM", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "(versteht sich ein schwarzer) gr\u00fc\u00dfte.", "tokens": ["(", "ver\u00b7steht", "sich", "ein", "schwar\u00b7zer", ")", "gr\u00fc\u00df\u00b7te", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "PRF", "ART", "ADJA", "$(", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Da kamen geschwommen ein Gustav Schwab,", "tokens": ["Da", "ka\u00b7men", "ge\u00b7schwom\u00b7men", "ein", "Gus\u00b7tav", "Schwab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVPP", "ART", "NE", "NE", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Ein Pfizer, ein K\u00f6lle, ein Mayer;", "tokens": ["Ein", "Pfi\u00b7zer", ",", "ein", "K\u00f6l\u00b7le", ",", "ein", "Ma\u00b7yer", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Auf jedem stand ein Schwabengesicht", "tokens": ["Auf", "je\u00b7dem", "stand", "ein", "Schwa\u00b7ben\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "VVFIN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit einer h\u00f6lzernen Leier.", "tokens": ["Mit", "ei\u00b7ner", "h\u00f6l\u00b7zer\u00b7nen", "Lei\u00b7er", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Da schwamm die Birch-Pfeiffer, eine Brigg,", "tokens": ["Da", "schwamm", "die", "Birch\u00b7Pfeif\u00b7fer", ",", "ei\u00b7ne", "Brigg", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie trug am Fockmast das Wappen", "tokens": ["Sie", "trug", "am", "Fock\u00b7mast", "das", "Wap\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der deutschen Admiralit\u00e4t", "tokens": ["Der", "deut\u00b7schen", "Ad\u00b7mi\u00b7ra\u00b7li\u00b7t\u00e4t"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf schwarzrotgoldnem Lappen.", "tokens": ["Auf", "schwarz\u00b7rot\u00b7gold\u00b7nem", "Lap\u00b7pen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Wir kletterten keck an Bugspriet und Rahn", "tokens": ["Wir", "klet\u00b7ter\u00b7ten", "keck", "an", "Bug\u00b7spriet", "und", "Rahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NE", "KON", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und trugen uns wie Matrosen,", "tokens": ["Und", "tru\u00b7gen", "uns", "wie", "Mat\u00b7ro\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "KOKOM", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die Jacke kurz, der Hut beteert,", "tokens": ["Die", "Ja\u00b7cke", "kurz", ",", "der", "Hut", "be\u00b7teert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und weite Schifferhosen.", "tokens": ["Und", "wei\u00b7te", "Schif\u00b7fer\u00b7ho\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Gar mancher, der fr\u00fcher nur Tee geno\u00df", "tokens": ["Gar", "man\u00b7cher", ",", "der", "fr\u00fc\u00b7her", "nur", "Tee", "ge\u00b7no\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "$,", "PRELS", "ADJD", "ADV", "NN", "VVFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Als wohlerzogener Eh'mann,", "tokens": ["Als", "woh\u00b7ler\u00b7zo\u00b7ge\u00b7ner", "Eh'\u00b7mann", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der soff jetzt Rum und kaute Tabak,", "tokens": ["Der", "soff", "jetzt", "Rum", "und", "kau\u00b7te", "Ta\u00b7bak", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "NE", "KON", "VVFIN", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und fluchte wie ein Seemann.", "tokens": ["Und", "fluch\u00b7te", "wie", "ein", "See\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Seekrank ist mancher geworden sogar,", "tokens": ["See\u00b7krank", "ist", "man\u00b7cher", "ge\u00b7wor\u00b7den", "so\u00b7gar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIAT", "VAPP", "ADV", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Und auf dem Fallersleben,", "tokens": ["Und", "auf", "dem", "Fal\u00b7lers\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dem alten Brander, hat mancher sich", "tokens": ["Dem", "al\u00b7ten", "Bran\u00b7der", ",", "hat", "man\u00b7cher", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VAFIN", "PIAT", "PRF"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gem\u00fctlich \u00fcbergeben.", "tokens": ["Ge\u00b7m\u00fct\u00b7lich", "\u00fc\u00b7ber\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wir tr\u00e4umten so sch\u00f6n, wir hatten fast", "tokens": ["Wir", "tr\u00e4um\u00b7ten", "so", "sch\u00f6n", ",", "wir", "hat\u00b7ten", "fast"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "PPER", "VAFIN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Schon eine Seeschlacht gewonnen \u2013", "tokens": ["Schon", "ei\u00b7ne", "See\u00b7schlacht", "ge\u00b7won\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch als die Morgensonne kam,", "tokens": ["Doch", "als", "die", "Mor\u00b7gen\u00b7son\u00b7ne", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist Traum und Flotte zerronnen.", "tokens": ["Ist", "Traum", "und", "Flot\u00b7te", "zer\u00b7ron\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Wir lagen noch immer im heimischen Bett", "tokens": ["Wir", "la\u00b7gen", "noch", "im\u00b7mer", "im", "hei\u00b7mi\u00b7schen", "Bett"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Mit ausgestreckten Knochen.", "tokens": ["Mit", "aus\u00b7ge\u00b7streck\u00b7ten", "Kno\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir rieben uns aus den Augen den Schlaf,", "tokens": ["Wir", "rie\u00b7ben", "uns", "aus", "den", "Au\u00b7gen", "den", "Schlaf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und haben g\u00e4hnend gesprochen:", "tokens": ["Und", "ha\u00b7ben", "g\u00e4h\u00b7nend", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "\u00bbdie Welt ist rund. Was n\u00fctzt es am End',", "tokens": ["\u00bb", "die", "Welt", "ist", "rund", ".", "Was", "n\u00fctzt", "es", "am", "End'", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "$.", "PWS", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Zu schaukeln auf m\u00fc\u00dfiger Welle!", "tokens": ["Zu", "schau\u00b7keln", "auf", "m\u00fc\u00b7\u00dfi\u00b7ger", "Wel\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Der Weltumsegler kommt zuletzt", "tokens": ["Der", "Welt\u00b7um\u00b7seg\u00b7ler", "kommt", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur\u00fcck auf dieselbe Stelle.\u00ab", "tokens": ["Zu\u00b7r\u00fcck", "auf", "die\u00b7sel\u00b7be", "Stel\u00b7le", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Wir tr\u00e4umten von einer Flotte j\u00fcngst,", "tokens": ["Wir", "tr\u00e4um\u00b7ten", "von", "ei\u00b7ner", "Flot\u00b7te", "j\u00fcngst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und segelten schon vergn\u00fcglich", "tokens": ["Und", "se\u00b7gel\u00b7ten", "schon", "ver\u00b7gn\u00fcg\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hinaus aufs balkenlose Meer,", "tokens": ["Hin\u00b7aus", "aufs", "bal\u00b7ken\u00b7lo\u00b7se", "Meer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Wind war ganz vorz\u00fcglich.", "tokens": ["Der", "Wind", "war", "ganz", "vor\u00b7z\u00fcg\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Wir hatten unsern Fregatten schon", "tokens": ["Wir", "hat\u00b7ten", "un\u00b7sern", "Fre\u00b7gat\u00b7ten", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die stolzesten Namen gegeben,", "tokens": ["Die", "stol\u00b7zes\u00b7ten", "Na\u00b7men", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Prutz hie\u00df die eine, die andre hie\u00df", "tokens": ["Prutz", "hie\u00df", "die", "ei\u00b7ne", ",", "die", "and\u00b7re", "hie\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ART", "$,", "PRELS", "PIS", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hoffmann von Fallersleben.", "tokens": ["Hoff\u00b7mann", "von", "Fal\u00b7lers\u00b7le\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.14": {"line.1": {"text": "Da schwamm der Kutter Freiligrath,", "tokens": ["Da", "schwamm", "der", "Kut\u00b7ter", "Frei\u00b7li\u00b7gra\u00b7th", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.2": {"text": "Darauf als Puppe die B\u00fcste", "tokens": ["Da\u00b7rauf", "als", "Pup\u00b7pe", "die", "B\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "KOUS", "NN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Des Mohrenk\u00f6nigs, die wie ein Mond", "tokens": ["Des", "Moh\u00b7ren\u00b7k\u00f6\u00b7nigs", ",", "die", "wie", "ein", "Mond"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "KOKOM", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "(versteht sich ein schwarzer) gr\u00fc\u00dfte.", "tokens": ["(", "ver\u00b7steht", "sich", "ein", "schwar\u00b7zer", ")", "gr\u00fc\u00df\u00b7te", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "PRF", "ART", "ADJA", "$(", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Da kamen geschwommen ein Gustav Schwab,", "tokens": ["Da", "ka\u00b7men", "ge\u00b7schwom\u00b7men", "ein", "Gus\u00b7tav", "Schwab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVPP", "ART", "NE", "NE", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Ein Pfizer, ein K\u00f6lle, ein Mayer;", "tokens": ["Ein", "Pfi\u00b7zer", ",", "ein", "K\u00f6l\u00b7le", ",", "ein", "Ma\u00b7yer", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Auf jedem stand ein Schwabengesicht", "tokens": ["Auf", "je\u00b7dem", "stand", "ein", "Schwa\u00b7ben\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "VVFIN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit einer h\u00f6lzernen Leier.", "tokens": ["Mit", "ei\u00b7ner", "h\u00f6l\u00b7zer\u00b7nen", "Lei\u00b7er", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Da schwamm die Birch-Pfeiffer, eine Brigg,", "tokens": ["Da", "schwamm", "die", "Birch\u00b7Pfeif\u00b7fer", ",", "ei\u00b7ne", "Brigg", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie trug am Fockmast das Wappen", "tokens": ["Sie", "trug", "am", "Fock\u00b7mast", "das", "Wap\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der deutschen Admiralit\u00e4t", "tokens": ["Der", "deut\u00b7schen", "Ad\u00b7mi\u00b7ra\u00b7li\u00b7t\u00e4t"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf schwarzrotgoldnem Lappen.", "tokens": ["Auf", "schwarz\u00b7rot\u00b7gold\u00b7nem", "Lap\u00b7pen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Wir kletterten keck an Bugspriet und Rahn", "tokens": ["Wir", "klet\u00b7ter\u00b7ten", "keck", "an", "Bug\u00b7spriet", "und", "Rahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NE", "KON", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und trugen uns wie Matrosen,", "tokens": ["Und", "tru\u00b7gen", "uns", "wie", "Mat\u00b7ro\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "KOKOM", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die Jacke kurz, der Hut beteert,", "tokens": ["Die", "Ja\u00b7cke", "kurz", ",", "der", "Hut", "be\u00b7teert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und weite Schifferhosen.", "tokens": ["Und", "wei\u00b7te", "Schif\u00b7fer\u00b7ho\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Gar mancher, der fr\u00fcher nur Tee geno\u00df", "tokens": ["Gar", "man\u00b7cher", ",", "der", "fr\u00fc\u00b7her", "nur", "Tee", "ge\u00b7no\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "$,", "PRELS", "ADJD", "ADV", "NN", "VVFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Als wohlerzogener Eh'mann,", "tokens": ["Als", "woh\u00b7ler\u00b7zo\u00b7ge\u00b7ner", "Eh'\u00b7mann", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der soff jetzt Rum und kaute Tabak,", "tokens": ["Der", "soff", "jetzt", "Rum", "und", "kau\u00b7te", "Ta\u00b7bak", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "NE", "KON", "VVFIN", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und fluchte wie ein Seemann.", "tokens": ["Und", "fluch\u00b7te", "wie", "ein", "See\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Seekrank ist mancher geworden sogar,", "tokens": ["See\u00b7krank", "ist", "man\u00b7cher", "ge\u00b7wor\u00b7den", "so\u00b7gar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIAT", "VAPP", "ADV", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Und auf dem Fallersleben,", "tokens": ["Und", "auf", "dem", "Fal\u00b7lers\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dem alten Brander, hat mancher sich", "tokens": ["Dem", "al\u00b7ten", "Bran\u00b7der", ",", "hat", "man\u00b7cher", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VAFIN", "PIAT", "PRF"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gem\u00fctlich \u00fcbergeben.", "tokens": ["Ge\u00b7m\u00fct\u00b7lich", "\u00fc\u00b7ber\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Wir tr\u00e4umten so sch\u00f6n, wir hatten fast", "tokens": ["Wir", "tr\u00e4um\u00b7ten", "so", "sch\u00f6n", ",", "wir", "hat\u00b7ten", "fast"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "PPER", "VAFIN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Schon eine Seeschlacht gewonnen \u2013", "tokens": ["Schon", "ei\u00b7ne", "See\u00b7schlacht", "ge\u00b7won\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch als die Morgensonne kam,", "tokens": ["Doch", "als", "die", "Mor\u00b7gen\u00b7son\u00b7ne", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist Traum und Flotte zerronnen.", "tokens": ["Ist", "Traum", "und", "Flot\u00b7te", "zer\u00b7ron\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Wir lagen noch immer im heimischen Bett", "tokens": ["Wir", "la\u00b7gen", "noch", "im\u00b7mer", "im", "hei\u00b7mi\u00b7schen", "Bett"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Mit ausgestreckten Knochen.", "tokens": ["Mit", "aus\u00b7ge\u00b7streck\u00b7ten", "Kno\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir rieben uns aus den Augen den Schlaf,", "tokens": ["Wir", "rie\u00b7ben", "uns", "aus", "den", "Au\u00b7gen", "den", "Schlaf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und haben g\u00e4hnend gesprochen:", "tokens": ["Und", "ha\u00b7ben", "g\u00e4h\u00b7nend", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "\u00bbdie Welt ist rund. Was n\u00fctzt es am End',", "tokens": ["\u00bb", "die", "Welt", "ist", "rund", ".", "Was", "n\u00fctzt", "es", "am", "End'", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "$.", "PWS", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Zu schaukeln auf m\u00fc\u00dfiger Welle!", "tokens": ["Zu", "schau\u00b7keln", "auf", "m\u00fc\u00b7\u00dfi\u00b7ger", "Wel\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Der Weltumsegler kommt zuletzt", "tokens": ["Der", "Welt\u00b7um\u00b7seg\u00b7ler", "kommt", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur\u00fcck auf dieselbe Stelle.\u00ab", "tokens": ["Zu\u00b7r\u00fcck", "auf", "die\u00b7sel\u00b7be", "Stel\u00b7le", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}