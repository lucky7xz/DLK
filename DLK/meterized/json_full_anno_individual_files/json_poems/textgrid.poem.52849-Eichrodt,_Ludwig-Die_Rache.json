{"textgrid.poem.52849": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Die Rache", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Umgebracht in seinem Bette,", "tokens": ["Um\u00b7ge\u00b7bracht", "in", "sei\u00b7nem", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liegt der Ritter Seidelbrecht,", "tokens": ["Liegt", "der", "Rit\u00b7ter", "Sei\u00b7del\u00b7brecht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Liegt in seinem bleichen Fette,", "tokens": ["Liegt", "in", "sei\u00b7nem", "blei\u00b7chen", "Fet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und daneben steht sein Knecht,", "tokens": ["Und", "da\u00b7ne\u00b7ben", "steht", "sein", "Knecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Steht sein Weib, das abgefeimte,", "tokens": ["Steht", "sein", "Weib", ",", "das", "ab\u00b7ge\u00b7feim\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das von jeher Bosheit sch\u00e4umte.", "tokens": ["Das", "von", "je\u00b7her", "Bos\u00b7heit", "sch\u00e4um\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Und es spricht der Knecht des Hauses,", "tokens": ["Und", "es", "spricht", "der", "Knecht", "des", "Hau\u00b7ses", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wischend die bespritzte Hand", "tokens": ["Wi\u00b7schend", "die", "be\u00b7spritz\u00b7te", "Hand"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "An dem Aermel seines Flauses,", "tokens": ["An", "dem", "A\u00b7er\u00b7mel", "sei\u00b7nes", "Flau\u00b7ses", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Zum verruchten Weib gewandt:", "tokens": ["Zum", "ver\u00b7ruch\u00b7ten", "Weib", "ge\u00b7wandt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieser ist des Todes worden,", "tokens": ["Die\u00b7ser", "ist", "des", "To\u00b7des", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Soll ich auch den ", "tokens": ["Soll", "ich", "auch", "den"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "ART"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Und erwidernd spricht die Arge:", "tokens": ["Und", "er\u00b7wi\u00b7dernd", "spricht", "die", "Ar\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sch\u00f6ner Josef, sei so gut!", "tokens": ["Sch\u00f6\u00b7ner", "Jo\u00b7sef", ",", "sei", "so", "gut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Thu mir den Gefallen, karge", "tokens": ["Thu", "mir", "den", "Ge\u00b7fal\u00b7len", ",", "kar\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "- Nimmer mit Tyrannenblut!", "tokens": ["Nim\u00b7mer", "mit", "Ty\u00b7ran\u00b7nen\u00b7blut", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "APPR", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Willst Du Gift, willst Du ein D\u00f6lchlein,", "tokens": ["Willst", "Du", "Gift", ",", "willst", "Du", "ein", "D\u00f6lch\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "$,", "VMFIN", "PPER", "ART", "NN", "$,"], "meter": "+-++-+-+", "measure": "unknown.measure.penta"}, "line.6": {"text": "Oder w\u00fcrgen wir das M\u00f6lchlein?", "tokens": ["O\u00b7der", "w\u00fcr\u00b7gen", "wir", "das", "M\u00f6lch\u00b7lein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.4": {"line.1": {"text": "Ach, sie haben kein Gewissen,", "tokens": ["Ach", ",", "sie", "ha\u00b7ben", "kein", "Ge\u00b7wis\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, der Kleine mu\u00df daran,", "tokens": ["Ach", ",", "der", "Klei\u00b7ne", "mu\u00df", "da\u00b7ran", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "ADJA", "VMFIN", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus dem Bett wird er gerissen,", "tokens": ["Aus", "dem", "Bett", "wird", "er", "ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mit Wohllust abgethan.", "tokens": ["Und", "mit", "Wohl\u00b7lust", "ab\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sieh, das geht geschmiert wie Butter,", "tokens": ["Sieh", ",", "das", "geht", "ge\u00b7schmiert", "wie", "But\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PDS", "VVFIN", "VVPP", "KOKOM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Lispelet die Rabenmutter.", "tokens": ["Lis\u00b7pe\u00b7let", "die", "Ra\u00b7ben\u00b7mut\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "----+-+-", "measure": "unknown.measure.di"}}, "stanza.5": {"line.1": {"text": "Horch, da raspelt's in dem Bette,", "tokens": ["Horch", ",", "da", "ras\u00b7pelt's", "in", "dem", "Bet\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "NE", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da erhebt sich's ", "tokens": ["Da", "er\u00b7hebt", "sich's"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "NE"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Und als ob es Leben h\u00e4tte,", "tokens": ["Und", "als", "ob", "es", "Le\u00b7ben", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOKOM", "KOUS", "PPER", "NN", "VAFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wandelt es zum Pfeifenbrett;", "tokens": ["Wan\u00b7delt", "es", "zum", "Pfei\u00b7fen\u00b7brett", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Stopft sich mit verdrehten Augen", "tokens": ["Stopft", "sich", "mit", "ver\u00b7dreh\u00b7ten", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen Kopf und thut ihn rauchen.", "tokens": ["Ei\u00b7nen", "Kopf", "und", "thut", "ihn", "rau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Gr\u00e4\u00dflich, gr\u00e4\u00dflich, ", "tokens": ["Gr\u00e4\u00df\u00b7lich", ",", "gr\u00e4\u00df\u00b7lich", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Gr\u00e4\u00dflich, das ist ein Gespenst!", "tokens": ["Gr\u00e4\u00df\u00b7lich", ",", "das", "ist", "ein", "Ge\u00b7spenst", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Josef, Josef, wird unp\u00e4\u00dflich,", "tokens": ["Jo\u00b7sef", ",", "Jo\u00b7sef", ",", "wird", "un\u00b7p\u00e4\u00df\u00b7lich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Eulagunde blickt entmenscht:", "tokens": ["Eu\u00b7la\u00b7gun\u00b7de", "blickt", "ent\u00b7menscht", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Beide wagen nicht zu sprechen -", "tokens": ["Bei\u00b7de", "wa\u00b7gen", "nicht", "zu", "spre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So thut Seidelbrecht sich r\u00e4chen.", "tokens": ["So", "thut", "Sei\u00b7del\u00b7brecht", "sich", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "PRF", "VVINF", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.7": {"line.1": {"text": "Eine lange, lange Stunde", "tokens": ["Ei\u00b7ne", "lan\u00b7ge", ",", "lan\u00b7ge", "Stun\u00b7de"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schleicht dahin und Keines weicht,", "tokens": ["Schleicht", "da\u00b7hin", "und", "Kei\u00b7nes", "weicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "KON", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Uebel wird es Eulagunde,", "tokens": ["Ue\u00b7bel", "wird", "es", "Eu\u00b7la\u00b7gun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Josef zum Phantom erbleicht:", "tokens": ["Jo\u00b7sef", "zum", "Phan\u00b7tom", "er\u00b7bleicht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Seidelbrecht, der Todtensteife,", "tokens": ["Sei\u00b7del\u00b7brecht", ",", "der", "Tod\u00b7ten\u00b7stei\u00b7fe", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stopft sich eine zweite Pfeife.", "tokens": ["Stopft", "sich", "ei\u00b7ne", "zwei\u00b7te", "Pfei\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "H\u00f6ret nimmer auf zu rauchen,", "tokens": ["H\u00f6\u00b7ret", "nim\u00b7mer", "auf", "zu", "rau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stieret auf das Herz des Weibs", "tokens": ["Stie\u00b7ret", "auf", "das", "Herz", "des", "Weibs"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem linken seiner Augen,", "tokens": ["Mit", "dem", "lin\u00b7ken", "sei\u00b7ner", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schauerlichen Zeitvertreibs;", "tokens": ["Schau\u00b7er\u00b7li\u00b7chen", "Zeit\u00b7ver\u00b7treibs", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mit dem rechten schielt erbittert", "tokens": ["Mit", "dem", "rech\u00b7ten", "schielt", "er\u00b7bit\u00b7tert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "VVFIN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Er auf Josef, der da zittert.", "tokens": ["Er", "auf", "Jo\u00b7sef", ",", "der", "da", "zit\u00b7tert", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Und zum andern Male klopfet", "tokens": ["Und", "zum", "an\u00b7dern", "Ma\u00b7le", "klop\u00b7fet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aus die Pfeife Seidelbrecht", "tokens": ["Aus", "die", "Pfei\u00b7fe", "Sei\u00b7del\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zum dritten Male stopfet", "tokens": ["Und", "zum", "drit\u00b7ten", "Ma\u00b7le", "stop\u00b7fet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Er die Pfeife mundgerecht.", "tokens": ["Er", "die", "Pfei\u00b7fe", "mund\u00b7ge\u00b7recht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Siebenmal und nochmal sieben", "tokens": ["Sie\u00b7ben\u00b7mal", "und", "noch\u00b7mal", "sie\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "ADV", "CARD"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Mal wird dieser Spuck betrieben.", "tokens": ["Mal", "wird", "die\u00b7ser", "Spuck", "be\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PDAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Eben schlug die zw\u00f6lfte Stunde", "tokens": ["E\u00b7ben", "schlug", "die", "zw\u00f6lf\u00b7te", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dumpfig, wie ein Uhu surrt,", "tokens": ["Dump\u00b7fig", ",", "wie", "ein", "U\u00b7hu", "surrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Angeraucht ist Eulagunde,", "tokens": ["An\u00b7ge\u00b7raucht", "ist", "Eu\u00b7la\u00b7gun\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Josef \u00e4rmlich eingeschnurrt;", "tokens": ["Jo\u00b7sef", "\u00e4rm\u00b7lich", "ein\u00b7ge\u00b7schnurrt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schon, mit ganz verdorbnem Teinte,", "tokens": ["Schon", ",", "mit", "ganz", "ver\u00b7dorb\u00b7nem", "Tein\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stehn sie da wie Postamente.", "tokens": ["Stehn", "sie", "da", "wie", "Pos\u00b7ta\u00b7men\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KOKOM", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Dann, unm\u00f6glich da\u00df man's glaube,", "tokens": ["Dann", ",", "un\u00b7m\u00f6g\u00b7lich", "da\u00df", "man's", "glau\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJD", "KOUS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unerbittlich, stumm, gerecht,", "tokens": ["Un\u00b7er\u00b7bitt\u00b7lich", ",", "stumm", ",", "ge\u00b7recht", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Br\u00f6ckelt er zu schn\u00f6dem Staube", "tokens": ["Br\u00f6\u00b7ckelt", "er", "zu", "schn\u00f6\u00b7dem", "Stau\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seine Gattin, seinen Knecht;", "tokens": ["Sei\u00b7ne", "Gat\u00b7tin", ",", "sei\u00b7nen", "Knecht", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Stopft damit, wer will's begreifen?", "tokens": ["Stopft", "da\u00b7mit", ",", "wer", "will's", "be\u00b7grei\u00b7fen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "$,", "PWS", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Siebenmal dreihundert Pfeifen.", "tokens": ["Sie\u00b7ben\u00b7mal", "drei\u00b7hun\u00b7dert", "Pfei\u00b7fen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.12": {"line.1": {"text": "Rauchet krampfhaft, rauchet sch\u00e4ndlich,", "tokens": ["Rau\u00b7chet", "krampf\u00b7haft", ",", "rau\u00b7chet", "sch\u00e4nd\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bis der Hund zur Sonne bellt,", "tokens": ["Bis", "der", "Hund", "zur", "Son\u00b7ne", "bellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Raucht und rauchet, bis er endlich", "tokens": ["Raucht", "und", "rau\u00b7chet", ",", "bis", "er", "end\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "$,", "KOUS", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Selbst in Staub und Asche f\u00e4llt.", "tokens": ["Selbst", "in", "Staub", "und", "A\u00b7sche", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wage Keiner, da\u00df er lache -", "tokens": ["Wa\u00b7ge", "Kei\u00b7ner", ",", "da\u00df", "er", "la\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PIS", "$,", "KOUS", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das war eines ", "tokens": ["Das", "war", "ei\u00b7nes"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "ART"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.13": {"line.1": {"text": "Umgebracht in seinem Bette,", "tokens": ["Um\u00b7ge\u00b7bracht", "in", "sei\u00b7nem", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liegt der Ritter Seidelbrecht,", "tokens": ["Liegt", "der", "Rit\u00b7ter", "Sei\u00b7del\u00b7brecht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Liegt in seinem bleichen Fette,", "tokens": ["Liegt", "in", "sei\u00b7nem", "blei\u00b7chen", "Fet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und daneben steht sein Knecht,", "tokens": ["Und", "da\u00b7ne\u00b7ben", "steht", "sein", "Knecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Steht sein Weib, das abgefeimte,", "tokens": ["Steht", "sein", "Weib", ",", "das", "ab\u00b7ge\u00b7feim\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das von jeher Bosheit sch\u00e4umte.", "tokens": ["Das", "von", "je\u00b7her", "Bos\u00b7heit", "sch\u00e4um\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Und es spricht der Knecht des Hauses,", "tokens": ["Und", "es", "spricht", "der", "Knecht", "des", "Hau\u00b7ses", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wischend die bespritzte Hand", "tokens": ["Wi\u00b7schend", "die", "be\u00b7spritz\u00b7te", "Hand"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "An dem Aermel seines Flauses,", "tokens": ["An", "dem", "A\u00b7er\u00b7mel", "sei\u00b7nes", "Flau\u00b7ses", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Zum verruchten Weib gewandt:", "tokens": ["Zum", "ver\u00b7ruch\u00b7ten", "Weib", "ge\u00b7wandt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieser ist des Todes worden,", "tokens": ["Die\u00b7ser", "ist", "des", "To\u00b7des", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Soll ich auch den ", "tokens": ["Soll", "ich", "auch", "den"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "ART"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.15": {"line.1": {"text": "Und erwidernd spricht die Arge:", "tokens": ["Und", "er\u00b7wi\u00b7dernd", "spricht", "die", "Ar\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sch\u00f6ner Josef, sei so gut!", "tokens": ["Sch\u00f6\u00b7ner", "Jo\u00b7sef", ",", "sei", "so", "gut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Thu mir den Gefallen, karge", "tokens": ["Thu", "mir", "den", "Ge\u00b7fal\u00b7len", ",", "kar\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "- Nimmer mit Tyrannenblut!", "tokens": ["Nim\u00b7mer", "mit", "Ty\u00b7ran\u00b7nen\u00b7blut", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "APPR", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Willst Du Gift, willst Du ein D\u00f6lchlein,", "tokens": ["Willst", "Du", "Gift", ",", "willst", "Du", "ein", "D\u00f6lch\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "$,", "VMFIN", "PPER", "ART", "NN", "$,"], "meter": "+-++-+-+", "measure": "unknown.measure.penta"}, "line.6": {"text": "Oder w\u00fcrgen wir das M\u00f6lchlein?", "tokens": ["O\u00b7der", "w\u00fcr\u00b7gen", "wir", "das", "M\u00f6lch\u00b7lein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.16": {"line.1": {"text": "Ach, sie haben kein Gewissen,", "tokens": ["Ach", ",", "sie", "ha\u00b7ben", "kein", "Ge\u00b7wis\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, der Kleine mu\u00df daran,", "tokens": ["Ach", ",", "der", "Klei\u00b7ne", "mu\u00df", "da\u00b7ran", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "ADJA", "VMFIN", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus dem Bett wird er gerissen,", "tokens": ["Aus", "dem", "Bett", "wird", "er", "ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mit Wohllust abgethan.", "tokens": ["Und", "mit", "Wohl\u00b7lust", "ab\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sieh, das geht geschmiert wie Butter,", "tokens": ["Sieh", ",", "das", "geht", "ge\u00b7schmiert", "wie", "But\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PDS", "VVFIN", "VVPP", "KOKOM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Lispelet die Rabenmutter.", "tokens": ["Lis\u00b7pe\u00b7let", "die", "Ra\u00b7ben\u00b7mut\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "----+-+-", "measure": "unknown.measure.di"}}, "stanza.17": {"line.1": {"text": "Horch, da raspelt's in dem Bette,", "tokens": ["Horch", ",", "da", "ras\u00b7pelt's", "in", "dem", "Bet\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "NE", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da erhebt sich's ", "tokens": ["Da", "er\u00b7hebt", "sich's"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "NE"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Und als ob es Leben h\u00e4tte,", "tokens": ["Und", "als", "ob", "es", "Le\u00b7ben", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOKOM", "KOUS", "PPER", "NN", "VAFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wandelt es zum Pfeifenbrett;", "tokens": ["Wan\u00b7delt", "es", "zum", "Pfei\u00b7fen\u00b7brett", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Stopft sich mit verdrehten Augen", "tokens": ["Stopft", "sich", "mit", "ver\u00b7dreh\u00b7ten", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen Kopf und thut ihn rauchen.", "tokens": ["Ei\u00b7nen", "Kopf", "und", "thut", "ihn", "rau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Gr\u00e4\u00dflich, gr\u00e4\u00dflich, ", "tokens": ["Gr\u00e4\u00df\u00b7lich", ",", "gr\u00e4\u00df\u00b7lich", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Gr\u00e4\u00dflich, das ist ein Gespenst!", "tokens": ["Gr\u00e4\u00df\u00b7lich", ",", "das", "ist", "ein", "Ge\u00b7spenst", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Josef, Josef, wird unp\u00e4\u00dflich,", "tokens": ["Jo\u00b7sef", ",", "Jo\u00b7sef", ",", "wird", "un\u00b7p\u00e4\u00df\u00b7lich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Eulagunde blickt entmenscht:", "tokens": ["Eu\u00b7la\u00b7gun\u00b7de", "blickt", "ent\u00b7menscht", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Beide wagen nicht zu sprechen -", "tokens": ["Bei\u00b7de", "wa\u00b7gen", "nicht", "zu", "spre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So thut Seidelbrecht sich r\u00e4chen.", "tokens": ["So", "thut", "Sei\u00b7del\u00b7brecht", "sich", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "PRF", "VVINF", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.19": {"line.1": {"text": "Eine lange, lange Stunde", "tokens": ["Ei\u00b7ne", "lan\u00b7ge", ",", "lan\u00b7ge", "Stun\u00b7de"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schleicht dahin und Keines weicht,", "tokens": ["Schleicht", "da\u00b7hin", "und", "Kei\u00b7nes", "weicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "KON", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Uebel wird es Eulagunde,", "tokens": ["Ue\u00b7bel", "wird", "es", "Eu\u00b7la\u00b7gun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Josef zum Phantom erbleicht:", "tokens": ["Jo\u00b7sef", "zum", "Phan\u00b7tom", "er\u00b7bleicht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Seidelbrecht, der Todtensteife,", "tokens": ["Sei\u00b7del\u00b7brecht", ",", "der", "Tod\u00b7ten\u00b7stei\u00b7fe", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stopft sich eine zweite Pfeife.", "tokens": ["Stopft", "sich", "ei\u00b7ne", "zwei\u00b7te", "Pfei\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "H\u00f6ret nimmer auf zu rauchen,", "tokens": ["H\u00f6\u00b7ret", "nim\u00b7mer", "auf", "zu", "rau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stieret auf das Herz des Weibs", "tokens": ["Stie\u00b7ret", "auf", "das", "Herz", "des", "Weibs"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem linken seiner Augen,", "tokens": ["Mit", "dem", "lin\u00b7ken", "sei\u00b7ner", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schauerlichen Zeitvertreibs;", "tokens": ["Schau\u00b7er\u00b7li\u00b7chen", "Zeit\u00b7ver\u00b7treibs", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mit dem rechten schielt erbittert", "tokens": ["Mit", "dem", "rech\u00b7ten", "schielt", "er\u00b7bit\u00b7tert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "VVFIN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Er auf Josef, der da zittert.", "tokens": ["Er", "auf", "Jo\u00b7sef", ",", "der", "da", "zit\u00b7tert", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Und zum andern Male klopfet", "tokens": ["Und", "zum", "an\u00b7dern", "Ma\u00b7le", "klop\u00b7fet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aus die Pfeife Seidelbrecht", "tokens": ["Aus", "die", "Pfei\u00b7fe", "Sei\u00b7del\u00b7brecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zum dritten Male stopfet", "tokens": ["Und", "zum", "drit\u00b7ten", "Ma\u00b7le", "stop\u00b7fet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Er die Pfeife mundgerecht.", "tokens": ["Er", "die", "Pfei\u00b7fe", "mund\u00b7ge\u00b7recht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Siebenmal und nochmal sieben", "tokens": ["Sie\u00b7ben\u00b7mal", "und", "noch\u00b7mal", "sie\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "ADV", "CARD"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Mal wird dieser Spuck betrieben.", "tokens": ["Mal", "wird", "die\u00b7ser", "Spuck", "be\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PDAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Eben schlug die zw\u00f6lfte Stunde", "tokens": ["E\u00b7ben", "schlug", "die", "zw\u00f6lf\u00b7te", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dumpfig, wie ein Uhu surrt,", "tokens": ["Dump\u00b7fig", ",", "wie", "ein", "U\u00b7hu", "surrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Angeraucht ist Eulagunde,", "tokens": ["An\u00b7ge\u00b7raucht", "ist", "Eu\u00b7la\u00b7gun\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Josef \u00e4rmlich eingeschnurrt;", "tokens": ["Jo\u00b7sef", "\u00e4rm\u00b7lich", "ein\u00b7ge\u00b7schnurrt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schon, mit ganz verdorbnem Teinte,", "tokens": ["Schon", ",", "mit", "ganz", "ver\u00b7dorb\u00b7nem", "Tein\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stehn sie da wie Postamente.", "tokens": ["Stehn", "sie", "da", "wie", "Pos\u00b7ta\u00b7men\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KOKOM", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Dann, unm\u00f6glich da\u00df man's glaube,", "tokens": ["Dann", ",", "un\u00b7m\u00f6g\u00b7lich", "da\u00df", "man's", "glau\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJD", "KOUS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unerbittlich, stumm, gerecht,", "tokens": ["Un\u00b7er\u00b7bitt\u00b7lich", ",", "stumm", ",", "ge\u00b7recht", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Br\u00f6ckelt er zu schn\u00f6dem Staube", "tokens": ["Br\u00f6\u00b7ckelt", "er", "zu", "schn\u00f6\u00b7dem", "Stau\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seine Gattin, seinen Knecht;", "tokens": ["Sei\u00b7ne", "Gat\u00b7tin", ",", "sei\u00b7nen", "Knecht", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Stopft damit, wer will's begreifen?", "tokens": ["Stopft", "da\u00b7mit", ",", "wer", "will's", "be\u00b7grei\u00b7fen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "$,", "PWS", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Siebenmal dreihundert Pfeifen.", "tokens": ["Sie\u00b7ben\u00b7mal", "drei\u00b7hun\u00b7dert", "Pfei\u00b7fen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.24": {"line.1": {"text": "Rauchet krampfhaft, rauchet sch\u00e4ndlich,", "tokens": ["Rau\u00b7chet", "krampf\u00b7haft", ",", "rau\u00b7chet", "sch\u00e4nd\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bis der Hund zur Sonne bellt,", "tokens": ["Bis", "der", "Hund", "zur", "Son\u00b7ne", "bellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Raucht und rauchet, bis er endlich", "tokens": ["Raucht", "und", "rau\u00b7chet", ",", "bis", "er", "end\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "$,", "KOUS", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Selbst in Staub und Asche f\u00e4llt.", "tokens": ["Selbst", "in", "Staub", "und", "A\u00b7sche", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wage Keiner, da\u00df er lache -", "tokens": ["Wa\u00b7ge", "Kei\u00b7ner", ",", "da\u00df", "er", "la\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PIS", "$,", "KOUS", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das war eines ", "tokens": ["Das", "war", "ei\u00b7nes"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "ART"], "meter": "+-+-", "measure": "trochaic.di"}}}}}