{"dta.poem.18207": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "Den Franzosenfressern.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1886", "urn": "urn:nbn:de:kobv:b4-200905192665", "language": ["de:0.99"], "booktitle": "Holz, Arno: Das Buch der Zeit. Lieder eines Modernen. Z\u00fcrich, 1886."}, "poem": {"stanza.1": {"line.1": {"text": "Und schwarz-wei\u00df-roth sind meine Verse,", "tokens": ["Und", "schwa\u00b7rz\u00b7wei\u00df\u00b7roth", "sind", "mei\u00b7ne", "Ver\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Denn treu dem Volk bis in den Tod", "tokens": ["Denn", "treu", "dem", "Volk", "bis", "in", "den", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "ART", "NN", "APPR", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schw\u00f6r ich auf Werther, Faust und Lerse.", "tokens": ["Schw\u00f6r", "ich", "auf", "Wert\u00b7her", ",", "Faust", "und", "Ler\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NE", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Manch goldbeschlagnes Auerhorn", "tokens": ["Manch", "gold\u00b7be\u00b7schlag\u00b7nes", "Au\u00b7er\u00b7horn"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hab ich aufs Deutschthum schon getrunken", "tokens": ["Hab", "ich", "aufs", "Deutscht\u00b7hum", "schon", "ge\u00b7trun\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPRART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und bin als Kerl von Schrot und Korn", "tokens": ["Und", "bin", "als", "Kerl", "von", "Schrot", "und", "Korn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "KOKOM", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Noch niemals untern Tisch gesunken.", "tokens": ["Noch", "nie\u00b7mals", "un\u00b7tern", "Tisch", "ge\u00b7sun\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Doch trotzdem ruf ich: ", "tokens": ["Doch", "trotz\u00b7dem", "ruf", "ich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Hony soit, qui mal y pense!", "tokens": ["Ho\u00b7ny", "soit", ",", "qui", "mal", "y", "pen\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "FM", "FM", "FM", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "O, nicht stets f\u00fcr sich selbst geschw\u00e4rmt!", "tokens": ["O", ",", "nicht", "stets", "f\u00fcr", "sich", "selbst", "ge\u00b7schw\u00e4rmt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PTKNEG", "ADV", "APPR", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus tausend Schriften l\u00e4\u00dft sich's lesen:", "tokens": ["Aus", "tau\u00b7send", "Schrif\u00b7ten", "l\u00e4\u00dft", "sich's", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Gluth, die ", "tokens": ["Die", "Gluth", ",", "die"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PRELS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Sie loht auch jenseits der Vogesen.", "tokens": ["Sie", "loht", "auch", "jen\u00b7seits", "der", "Vo\u00b7ge\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Das Volk der Rousseaus und St. Pierres,", "tokens": ["Das", "Volk", "der", "Rous\u00b7se\u00b7aus", "und", "St.", "Pier\u00b7res", ","], "token_info": ["word", "word", "word", "word", "word", "abbreviation", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "NE", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Man mag's begeifern, mag's beneiden:", "tokens": ["Man", "mag's", "be\u00b7gei\u00b7fern", ",", "mag's", "be\u00b7nei\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVINF", "$,", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Mir ist's so lieb, wie das Homers,", "tokens": ["Mir", "ist's", "so", "lieb", ",", "wie", "das", "Ho\u00b7mers", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "PWAV", "ART", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und kein Phantast soll's mir verleiden!", "tokens": ["Und", "kein", "Phan\u00b7tast", "soll's", "mir", "ver\u00b7lei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Drum ruf ich lautauf: ", "tokens": ["Drum", "ruf", "ich", "laut\u00b7auf", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.10": {"text": "Hony soit, qui mal y pense!", "tokens": ["Ho\u00b7ny", "soit", ",", "qui", "mal", "y", "pen\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "FM", "FM", "FM", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.3": {"line.1": {"text": "O wer, als einst wie nie zuvor", "tokens": ["O", "wer", ",", "als", "einst", "wie", "nie", "zu\u00b7vor"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "PWS", "$,", "KOUS", "ADV", "KOKOM", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Welt ein Haupt voll Blut und Wunden,", "tokens": ["Die", "Welt", "ein", "Haupt", "voll", "Blut", "und", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sang ihr das \u201eLied im h\u00f6hern Chor\u201c,", "tokens": ["Sang", "ihr", "das", "\u201e", "Lied", "im", "h\u00f6\u00b7hern", "Chor", "\u201c", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "$(", "NN", "APPRART", "ADJA", "NN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Daran wir heute noch gesunden?", "tokens": ["Da\u00b7ran", "wir", "heu\u00b7te", "noch", "ge\u00b7sun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Rouget de L'Isle war's, der Franzos,", "tokens": ["Rou\u00b7get", "de", "L'\u00b7Is\u00b7le", "wa\u00b7r's", ",", "der", "Fran\u00b7zos", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "VAFIN", "$,", "ART", "NN", "$,"], "meter": "+---+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Die Seine rauscht's und die Garonne,", "tokens": ["Die", "Sei\u00b7ne", "rauscht's", "und", "die", "Ga\u00b7ron\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und aus der Knechtschaft dunklem Schoo\u00df", "tokens": ["Und", "aus", "der", "Knecht\u00b7schaft", "dunk\u00b7lem", "Schoo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Rang sich die Freiheit in die Sonne.", "tokens": ["Rang", "sich", "die", "Frei\u00b7heit", "in", "die", "Son\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Drum juble, Seele: ", "tokens": ["Drum", "jub\u00b7le", ",", "See\u00b7le", ":"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "Hony soit, qui mal pense!", "tokens": ["Ho\u00b7ny", "soit", ",", "qui", "mal", "pen\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "FM", "FM", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.4": {"line.1": {"text": "Wohl wei\u00df ich's, kra\u00df war jene Zeit", "tokens": ["Wohl", "wei\u00df", "ich's", ",", "kra\u00df", "war", "je\u00b7ne", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "$,", "ADJD", "VAFIN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ward von Tag zu Tag noch krasser,", "tokens": ["Und", "ward", "von", "Tag", "zu", "Tag", "noch", "kras\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "APPR", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch jede gro\u00dfe Wahrheit schreit", "tokens": ["Doch", "je\u00b7de", "gro\u00b7\u00dfe", "Wahr\u00b7heit", "schreit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach Blut und nicht nach Zuckerwasser!", "tokens": ["Nach", "Blut", "und", "nicht", "nach", "Zu\u00b7cker\u00b7was\u00b7ser", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wem sie ihr Herz geoffenbart,", "tokens": ["Wem", "sie", "ihr", "Herz", "ge\u00b7of\u00b7fen\u00b7bart", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der schrickt zusammen und bewundert's;", "tokens": ["Der", "schrickt", "zu\u00b7sam\u00b7men", "und", "be\u00b7wun\u00b7dert's", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "O, jener Schwur im Ballhaus ward", "tokens": ["O", ",", "je\u00b7ner", "Schwur", "im", "Ball\u00b7haus", "ward"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PDS", "VVFIN", "APPRART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zur ersten Gro\u00dfthat des Jahrhunderts!", "tokens": ["Zur", "ers\u00b7ten", "Gro\u00df\u00b7that", "des", "Jahr\u00b7hun\u00b7derts", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Drum juble Seele: ", "tokens": ["Drum", "jub\u00b7le", "See\u00b7le", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "Hony soit, qui mal y pense!", "tokens": ["Ho\u00b7ny", "soit", ",", "qui", "mal", "y", "pen\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "FM", "FM", "FM", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.5": {"line.1": {"text": "Wohl steht noch heut, Gewehr bei Fu\u00df,", "tokens": ["Wohl", "steht", "noch", "heut", ",", "Ge\u00b7wehr", "bei", "Fu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Cerberus an jeder Grenze,", "tokens": ["Ein", "Cer\u00b7be\u00b7rus", "an", "je\u00b7der", "Gren\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch schon umweht's mich wie ein Gru\u00df", "tokens": ["Doch", "schon", "um\u00b7weht's", "mich", "wie", "ein", "Gru\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus ferner Zukunft fernem Lenze.", "tokens": ["Aus", "fer\u00b7ner", "Zu\u00b7kunft", "fer\u00b7nem", "Len\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dann schl\u00e4gt kein Tambour mehr Allarm,", "tokens": ["Dann", "schl\u00e4gt", "kein", "Tam\u00b7bour", "mehr", "Al\u00b7larm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dann steht die Welt voll goldner Halme", "tokens": ["Dann", "steht", "die", "Welt", "voll", "gold\u00b7ner", "Hal\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und Frankreich ringt dann Arm in Arm", "tokens": ["Und", "Fran\u00b7kreich", "ringt", "dann", "Arm", "in", "Arm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "ADV", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mit Deutschland um dieselbe Palme.", "tokens": ["Mit", "Deutschland", "um", "die\u00b7sel\u00b7be", "Pal\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Drum juble, juble: ", "tokens": ["Drum", "jub\u00b7le", ",", "jub\u00b7le", ":"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "Hony soit, qui mal y pense!", "tokens": ["Ho\u00b7ny", "soit", ",", "qui", "mal", "y", "pen\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "FM", "FM", "FM", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Doch ihr ... verh\u00f6hnt mich immer nur,", "tokens": ["Doch", "ihr", "...", "ver\u00b7h\u00f6hnt", "mich", "im\u00b7mer", "nur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "$(", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr biedern Knopflochpatrioten;", "tokens": ["Ihr", "bie\u00b7dern", "Kno\u00b7pfloch\u00b7pat\u00b7ri\u00b7o\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich wei\u00df, ihr schw\u00e4rmt nur f\u00fcr Dressur,", "tokens": ["Ich", "wei\u00df", ",", "ihr", "schw\u00e4rmt", "nur", "f\u00fcr", "Dres\u00b7sur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr Kalbsfilet und Schweinepoten.", "tokens": ["F\u00fcr", "Kalbs\u00b7fi\u00b7let", "und", "Schwei\u00b7ne\u00b7po\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr sammelt Lumpen, sammelt Geld", "tokens": ["Ihr", "sam\u00b7melt", "Lum\u00b7pen", ",", "sam\u00b7melt", "Geld"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "$,", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und tr\u00e4umt von l\u00e4ngst verschollnen Tagen:", "tokens": ["Und", "tr\u00e4umt", "von", "l\u00e4ngst", "ver\u00b7scholl\u00b7nen", "Ta\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was k\u00fcmmert's euch, wenn durch die Welt", "tokens": ["Was", "k\u00fcm\u00b7mert's", "euch", ",", "wenn", "durch", "die", "Welt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Zukunft Nachtigallen schlagen?", "tokens": ["Der", "Zu\u00b7kunft", "Nach\u00b7ti\u00b7gal\u00b7len", "schla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Ich aber rufe: ", "tokens": ["Ich", "a\u00b7ber", "ru\u00b7fe", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "Hony soit, qui mal y pense!", "tokens": ["Ho\u00b7ny", "soit", ",", "qui", "mal", "y", "pen\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "FM", "FM", "FM", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}}}}