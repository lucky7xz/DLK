{"dta.poem.19600": {"metadata": {"author": {"name": "Meyer, Conrad Ferdinand", "birth": "N.A.", "death": "N.A."}, "title": "La Blanche Nef.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1882", "urn": "urn:nbn:de:kobv:b4-200905193933", "language": ["de:0.99"], "booktitle": "Meyer, Conrad Ferdinand: Gedichte. Leipzig, 1882."}, "poem": {"stanza.1": {"line.1": {"text": "\u201eherr K\u00f6nig, ich bin Steffens Kind,", "tokens": ["\u201e", "herr", "K\u00f6\u00b7nig", ",", "ich", "bin", "Stef\u00b7fens", "Kind", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "PPER", "VAFIN", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der den Erobrer einst gef\u00fchrt!", "tokens": ["Der", "den", "E\u00b7rob\u00b7rer", "einst", "ge\u00b7f\u00fchrt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist ein Lehn, da\u00df ", "tokens": ["Es", "ist", "ein", "Lehn", ",", "da\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "KOUS"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Voraus den schnellsten Seglern fliegt", "tokens": ["Vo\u00b7raus", "den", "schnells\u00b7ten", "Seg\u00b7lern", "fliegt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Boot, La Blanche Nef genannt,", "tokens": ["Mein", "Boot", ",", "La", "Blan\u00b7che", "Nef", "ge\u00b7nannt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NE", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es wei\u00df wo sichre Tiefe liegt,", "tokens": ["Es", "wei\u00df", "wo", "sich\u00b7re", "Tie\u00b7fe", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWAV", "VVFIN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es furcht das Meer, es kennt den Strand!\u201c", "tokens": ["Es", "furcht", "das", "Meer", ",", "es", "kennt", "den", "Strand", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "\u2014 \u201eNicht mich, doch meinen besten Hort,", "tokens": ["\u201e", "Nicht", "mich", ",", "doch", "mei\u00b7nen", "bes\u00b7ten", "Hort", ","], "token_info": ["punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "PTKNEG", "PPER", "$,", "KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vier K\u00f6nigskinder, f\u00fchrest du \u2014", "tokens": ["Vier", "K\u00f6\u00b7nigs\u00b7kin\u00b7der", ",", "f\u00fch\u00b7rest", "du"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie knospen, weil mein Leben dorrt \u2014", "tokens": ["Sie", "knos\u00b7pen", ",", "weil", "mein", "Le\u00b7ben", "dorrt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die junge Normandie dazu!", "tokens": ["Die", "jun\u00b7ge", "Nor\u00b7man\u00b7die", "da\u00b7zu", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Gelobe mir dein himmlisch Theil,", "tokens": ["Ge\u00b7lo\u00b7be", "mir", "dein", "himm\u00b7lisch", "Theil", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gelobe mir dein m\u00e4nnlich Wort:", "tokens": ["Ge\u00b7lo\u00b7be", "mir", "dein", "m\u00e4nn\u00b7lich", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du bringst an Leib und Seele heil", "tokens": ["Du", "bringst", "an", "Leib", "und", "See\u00b7le", "heil"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Kinder mir nach England dort!\u201c", "tokens": ["Die", "Kin\u00b7der", "mir", "nach", "En\u00b7gland", "dort", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "NE", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "\u2014 \u201eIch schw\u00f6re Dir mein himmlisch Theil,", "tokens": ["\u201e", "Ich", "schw\u00f6\u00b7re", "Dir", "mein", "himm\u00b7lisch", "Theil", ","], "token_info": ["punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "PPER", "VVFIN", "PPER", "PPOSAT", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich schw\u00f6re Dir mein m\u00e4nnlich Wort:", "tokens": ["Ich", "schw\u00f6\u00b7re", "Dir", "mein", "m\u00e4nn\u00b7lich", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "An Leib und Seele bring' ich heil", "tokens": ["An", "Leib", "und", "See\u00b7le", "bring'", "ich", "heil"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Kinder Dir nach England dort!\u201c", "tokens": ["Die", "Kin\u00b7der", "Dir", "nach", "En\u00b7gland", "dort", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "NE", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Des Schiffers geller Pfiff erscholl,", "tokens": ["Des", "Schif\u00b7fers", "gel\u00b7ler", "Pfiff", "er\u00b7scholl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In See das Boot des K\u00f6nigs stach \u2014", "tokens": ["In", "See", "das", "Boot", "des", "K\u00f6\u00b7nigs", "stach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Korb von frischen Blumen voll,", "tokens": ["Ein", "Korb", "von", "fri\u00b7schen", "Blu\u00b7men", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Glitt Blanche Nef, la Belle, nach.", "tokens": ["Glitt", "Blan\u00b7che", "Nef", ",", "la", "Bel\u00b7le", ",", "nach", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,", "FM", "FM", "$,", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "So leicht beschwingt wie nie zuvor,", "tokens": ["So", "leicht", "be\u00b7schwingt", "wie", "nie", "zu\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "KOKOM", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durchfurchte Blanche Nef die See", "tokens": ["Durch\u00b7furch\u00b7te", "Blan\u00b7che", "Nef", "die", "See"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "NE", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit ihrem kr\u00e4ft'gen Knabenflor", "tokens": ["Mit", "ih\u00b7rem", "kr\u00e4ft'\u00b7gen", "Kna\u00b7ben\u00b7flor"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und M\u00e4gdlein schlank wie Hirsch und Reh.", "tokens": ["Und", "M\u00e4gd\u00b7lein", "schlank", "wie", "Hirsch", "und", "Reh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "KOKOM", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Die K\u00f6nigskinder hell und zart", "tokens": ["Die", "K\u00f6\u00b7nigs\u00b7kin\u00b7der", "hell", "und", "zart"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erh\u00f6ht inmitten sa\u00dfen sie,", "tokens": ["Er\u00b7h\u00f6ht", "in\u00b7mit\u00b7ten", "sa\u00b7\u00dfen", "sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ringsum gepaart in Zucht und Art", "tokens": ["Ring\u00b7sum", "ge\u00b7paart", "in", "Zucht", "und", "Art"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "APPR", "NN", "KON", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Das Edelblut der Normandie.", "tokens": ["Das", "E\u00b7del\u00b7blut", "der", "Nor\u00b7man\u00b7die", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Vier helle Stimmen sangen sch\u00f6n", "tokens": ["Vier", "hel\u00b7le", "Stim\u00b7men", "san\u00b7gen", "sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADJA", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hundertstimmig scholl der Chor,", "tokens": ["Und", "hun\u00b7derts\u00b7tim\u00b7mig", "scholl", "der", "Chor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es zog das junge Lustget\u00f6n", "tokens": ["Es", "zog", "das", "jun\u00b7ge", "Lust\u00b7ge\u00b7t\u00f6n"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Nixen aus der Fluth empor.", "tokens": ["Die", "Ni\u00b7xen", "aus", "der", "Fluth", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "\u2014 \u201eIch warne junge Herrlichkeit", "tokens": ["\u201e", "Ich", "war\u00b7ne", "jun\u00b7ge", "Herr\u00b7lich\u00b7keit"], "token_info": ["punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "$(", "PPER", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und dich, norm\u00e4nnisch Edelblut,", "tokens": ["Und", "dich", ",", "nor\u00b7m\u00e4n\u00b7nisch", "E\u00b7del\u00b7blut", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Singen schafft der Nixe Leid,", "tokens": ["Das", "Sin\u00b7gen", "schafft", "der", "Ni\u00b7xe", "Leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem freudelosen Kind der Flut!\u201c", "tokens": ["Dem", "freu\u00b7de\u00b7lo\u00b7sen", "Kind", "der", "Flut", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "\u2014 \u201eUnd schaffen dem Gez\u00fccht wir Leid", "tokens": ["\u201e", "Und", "schaf\u00b7fen", "dem", "Ge\u00b7z\u00fccht", "wir", "Leid"], "token_info": ["punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "$(", "KON", "VVFIN", "ART", "NN", "PPER", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und qu\u00e4len wir das Halbgeschlecht", "tokens": ["Und", "qu\u00e4\u00b7len", "wir", "das", "Halb\u00b7ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und reizen wir der Nixe Neid,", "tokens": ["Und", "rei\u00b7zen", "wir", "der", "Ni\u00b7xe", "Neid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das, Steffen, ist uns eben recht!\u201c", "tokens": ["Das", ",", "Stef\u00b7fen", ",", "ist", "uns", "e\u00b7ben", "recht", "!", "\u201c"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "$,", "NN", "$,", "VAFIN", "PPER", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Gemach verlosch das Abendrot,", "tokens": ["Ge\u00b7mach", "ver\u00b7losch", "das", "A\u00b7ben\u00b7drot", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Tages Gluten schliefen ein,", "tokens": ["Des", "Ta\u00b7ges", "Glu\u00b7ten", "schlie\u00b7fen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ausbreitet' \u00fcber Meer und Boot", "tokens": ["Aus\u00b7brei\u00b7tet'", "\u00fc\u00b7ber", "Meer", "und", "Boot"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Mond den bleichen Geisterschein.", "tokens": ["Der", "Mond", "den", "blei\u00b7chen", "Geis\u00b7ter\u00b7schein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Die See ist wunderlich erregt.", "tokens": ["Die", "See", "ist", "wun\u00b7der\u00b7lich", "er\u00b7regt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was wandert um des Kieles Lauf?", "tokens": ["Was", "wan\u00b7dert", "um", "des", "Kie\u00b7les", "Lauf", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von Armen wird die Flut bewegt,", "tokens": ["Von", "Ar\u00b7men", "wird", "die", "Flut", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Begl\u00e4nzte Nacken tauchen auf.", "tokens": ["Be\u00b7gl\u00e4nz\u00b7te", "Na\u00b7cken", "tau\u00b7chen", "auf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Der Steffen ernst am Steuer stand:", "tokens": ["Der", "Stef\u00b7fen", "ernst", "am", "Steu\u00b7er", "stand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edas Meer ist klar, doch droht Gefahr ...\u201c", "tokens": ["\u201e", "das", "Meer", "ist", "klar", ",", "doch", "droht", "Ge\u00b7fahr", "...", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "$,", "ADV", "VVFIN", "NN", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er deutet mit gestreckter Hand:", "tokens": ["Er", "deu\u00b7tet", "mit", "ge\u00b7streck\u00b7ter", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eda naht sie schon, die Nixenschaar!\u201c", "tokens": ["\u201e", "da", "naht", "sie", "schon", ",", "die", "Ni\u00b7xen\u00b7schaar", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "$,", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Umklammert h\u00e4lt den schr\u00e4gen Mast", "tokens": ["Um\u00b7klam\u00b7mert", "h\u00e4lt", "den", "schr\u00e4\u00b7gen", "Mast"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVPP", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein blanker Leib als Schiffsfigur,", "tokens": ["Ein", "blan\u00b7ker", "Leib", "als", "Schiffs\u00b7fi\u00b7gur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df Blanche Nef, von Graun erfa\u00dft,", "tokens": ["Da\u00df", "Blan\u00b7che", "Nef", ",", "von", "Graun", "er\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In wilder Flucht von dannen fuhr.", "tokens": ["In", "wil\u00b7der", "Flucht", "von", "dan\u00b7nen", "fuhr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "\u2014 \u201eIch warne junge Herrlichkeit,", "tokens": ["\u201e", "Ich", "war\u00b7ne", "jun\u00b7ge", "Herr\u00b7lich\u00b7keit", ","], "token_info": ["punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Verge\u00dft die Nachtgebete nicht!\u201c", "tokens": ["Ver\u00b7ge\u00dft", "die", "Nacht\u00b7ge\u00b7be\u00b7te", "nicht", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u2014 \u201eEi Steffen, Kind der alten Zeit,", "tokens": ["\u201e", "Ei", "Stef\u00b7fen", ",", "Kind", "der", "al\u00b7ten", "Zeit", ","], "token_info": ["punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "NN", "NN", "$,", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "S\u00fc\u00df herzt es sich im Mondenlicht\u201c ...", "tokens": ["S\u00fc\u00df", "herzt", "es", "sich", "im", "Mon\u00b7den\u00b7licht", "\u201c", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "PPER", "PRF", "APPRART", "NN", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Es klimmt und \u00fcberklimmt das Bord,", "tokens": ["Es", "klimmt", "und", "\u00fc\u00b7ber\u00b7klimmt", "das", "Bord", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es l\u00e4\u00dft sich nieder aus den Taun,", "tokens": ["Es", "l\u00e4\u00dft", "sich", "nie\u00b7der", "aus", "den", "Taun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es kichert wie ein freches Wort,", "tokens": ["Es", "ki\u00b7chert", "wie", "ein", "fre\u00b7ches", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es schaudert wie ein l\u00fcstern Graun ...", "tokens": ["Es", "schau\u00b7dert", "wie", "ein", "l\u00fcs\u00b7tern", "Graun", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Es reizt, es qu\u00e4lt, es schl\u00fcpft, es schmiegt", "tokens": ["Es", "reizt", ",", "es", "qu\u00e4lt", ",", "es", "schl\u00fcpft", ",", "es", "schmiegt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich zwischen Edelknecht und Maid,", "tokens": ["Sich", "zwi\u00b7schen", "E\u00b7del\u00b7knecht", "und", "Maid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bis sich das Paar in Armen liegt", "tokens": ["Bis", "sich", "das", "Paar", "in", "Ar\u00b7men", "liegt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRF", "ART", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu fr\u00fcher Lust, zu Tod und Leid ...", "tokens": ["Zu", "fr\u00fc\u00b7her", "Lust", ",", "zu", "Tod", "und", "Leid", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "NN", "$,", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Dem Steffen steigt das Haar. Er starrt", "tokens": ["Dem", "Stef\u00b7fen", "steigt", "das", "Haar", ".", "Er", "starrt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf ein gespenstig Bacchanal:", "tokens": ["Auf", "ein", "ge\u00b7spens\u00b7tig", "Bac\u00b7cha\u00b7nal", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die K\u00f6nigskinder hell und zart", "tokens": ["Die", "K\u00f6\u00b7nigs\u00b7kin\u00b7der", "hell", "und", "zart"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verbl\u00fchen all im Mondenstrahl.", "tokens": ["Ver\u00b7bl\u00fc\u00b7hen", "all", "im", "Mon\u00b7dens\u00b7trahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "\u201everloren geht mein himmlisch Theil,", "tokens": ["\u201e", "ver\u00b7lo\u00b7ren", "geht", "mein", "himm\u00b7lisch", "Theil", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "VVFIN", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gebrochen ist mein m\u00e4nnlich Wort:", "tokens": ["Ge\u00b7bro\u00b7chen", "ist", "mein", "m\u00e4nn\u00b7lich", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht bring' an Leib und Seele heil", "tokens": ["Nicht", "bring'", "an", "Leib", "und", "See\u00b7le", "heil"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVFIN", "APPR", "NN", "KON", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Kinder ich nach England dort!", "tokens": ["Die", "Kin\u00b7der", "ich", "nach", "En\u00b7gland", "dort", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "NE", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Geh nieder, Blanche Nef! Es ragt", "tokens": ["Geh", "nie\u00b7der", ",", "Blan\u00b7che", "Nef", "!", "Es", "ragt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "PTKVZ", "$,", "ADJA", "NN", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Links unterm Wasser hier ein Riff ...\u201c", "tokens": ["Links", "un\u00b7term", "Was\u00b7ser", "hier", "ein", "Riff", "...", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPRART", "NN", "ADV", "ART", "NN", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er dreht das Steuer stracks und jagt", "tokens": ["Er", "dreht", "das", "Steu\u00b7er", "stracks", "und", "jagt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Klippe zu das S\u00fcndenschiff.", "tokens": ["Der", "Klip\u00b7pe", "zu", "das", "S\u00fcn\u00b7den\u00b7schiff", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Der K\u00f6nig lauscht zur\u00fcck: \u201eDas scholl", "tokens": ["Der", "K\u00f6\u00b7nig", "lauscht", "zu\u00b7r\u00fcck", ":", "\u201e", "Das", "scholl"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "$(", "PDS", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Sterbeschrei!\u201c Klar ist der Sund.", "tokens": ["Wie", "Ster\u00b7be\u00b7schrei", "!", "\u201c", "Klar", "ist", "der", "Sund", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$.", "$(", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Ein Korb von welken Blumen voll,", "tokens": ["Ein", "Korb", "von", "wel\u00b7ken", "Blu\u00b7men", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PWAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sinkt Blanche Nef zum Meeresgrund.", "tokens": ["Sinkt", "Blan\u00b7che", "Nef", "zum", "Mee\u00b7res\u00b7grund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}