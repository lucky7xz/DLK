{"dta.poem.20534": {"metadata": {"author": {"name": "Scheyb, Franz Christoph von", "birth": "N.A.", "death": "N.A."}, "title": "O D E.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1746", "urn": "urn:nbn:de:kobv:b4-20536-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wacht auf! ermuntert euch! verla\u00dft die d\u00fcstern H\u00f6hlen", "tokens": ["Wacht", "auf", "!", "er\u00b7mun\u00b7tert", "euch", "!", "ver\u00b7la\u00dft", "die", "d\u00fcs\u00b7tern", "H\u00f6h\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$.", "VVFIN", "PPER", "$.", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Jhr F\u00fcrsten, derer Ruhm zu keiner Zeit vergeht!", "tokens": ["Ihr", "F\u00fcrs\u00b7ten", ",", "de\u00b7rer", "Ruhm", "zu", "kei\u00b7ner", "Zeit", "ver\u00b7geht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PDS", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Steigt aus dem Schutt empor! wir wollen euch", "tokens": ["Steigt", "aus", "dem", "Schutt", "em\u00b7por", "!", "wir", "wol\u00b7len", "euch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$.", "PPER", "VMFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wie weit ", "tokens": ["Wie", "weit"], "token_info": ["word", "word"], "pos": ["PWAV", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Wie weit ", "tokens": ["Wie", "weit"], "token_info": ["word", "word"], "pos": ["PWAV", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Den Rang, der euch geb\u00fchrt, bereits hat \u00fcberstiegen.", "tokens": ["Den", "Rang", ",", "der", "euch", "ge\u00b7b\u00fchrt", ",", "be\u00b7reits", "hat", "\u00fc\u00b7bers\u00b7tie\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Jhr, die ihr manches Land bezwungen und beschirmet;", "tokens": ["Ihr", ",", "die", "ihr", "man\u00b7ches", "Land", "be\u00b7zwun\u00b7gen", "und", "be\u00b7schir\u00b7met", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "PIAT", "NN", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem Waffen- Strohm des Feinds mit Starckmuth vorgeschantzt:", "tokens": ["Dem", "Waf\u00b7fen", "Strohm", "des", "Feinds", "mit", "Starck\u00b7muth", "vor\u00b7ge\u00b7schantzt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "NN", "ART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jhr, derer Schwert und Muth auf keinen Wall gest\u00fcrmet,", "tokens": ["Ihr", ",", "de\u00b7rer", "Schwert", "und", "Muth", "auf", "kei\u00b7nen", "Wall", "ge\u00b7st\u00fcr\u00b7met", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PDS", "NN", "KON", "NN", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo nicht die tapfre Faust den Sieges-Fahn gepflantzt:", "tokens": ["Wo", "nicht", "die", "tapf\u00b7re", "Faust", "den", "Sie\u00b7ges\u00b7Fahn", "ge\u00b7pflantzt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ART", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Seht den Zusammenhang der Staats- und Kriegs-Gesch\u00e4fte!", "tokens": ["Seht", "den", "Zu\u00b7sam\u00b7men\u00b7hang", "der", "Staats", "und", "Kriegs\u00b7Ge\u00b7sch\u00e4f\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "TRUNC", "KON", "NN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.6": {"text": "Sagt! \u00fcbertrifft er nicht die Wirckung eurer Kr\u00e4ffte?", "tokens": ["Sagt", "!", "\u00fc\u00b7bert\u00b7rifft", "er", "nicht", "die", "Wir\u00b7ckung", "eu\u00b7rer", "Kr\u00e4ff\u00b7te", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wer ist von euch, der jung; doch Alten gleich gek\u00e4mpffet;", "tokens": ["Wer", "ist", "von", "euch", ",", "der", "jung", ";", "doch", "Al\u00b7ten", "gleich", "ge\u00b7k\u00e4mpf\u00b7fet", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "PPER", "$,", "PRELS", "ADJD", "$.", "ADV", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der aller Hilff entbl\u00f6\u00dft den Sieger selbst erschreckt?", "tokens": ["Der", "al\u00b7ler", "Hilff", "ent\u00b7bl\u00f6\u00dft", "den", "Sie\u00b7ger", "selbst", "er\u00b7schreckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer ist der ohne Macht, die gr\u00f6ste Macht ged\u00e4mpfet,", "tokens": ["Wer", "ist", "der", "oh\u00b7ne", "Macht", ",", "die", "gr\u00f6s\u00b7te", "Macht", "ge\u00b7d\u00e4mp\u00b7fet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "APPR", "NN", "$,", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und fast am Untergang die Lorber aufgesteckt?", "tokens": ["Und", "fast", "am", "Un\u00b7ter\u00b7gang", "die", "Lor\u00b7ber", "auf\u00b7ge\u00b7steckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Werfft den erstaunten Blick auf diese Zier der Frauen!", "tokens": ["Werfft", "den", "er\u00b7staun\u00b7ten", "Blick", "auf", "die\u00b7se", "Zier", "der", "Frau\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie l\u00e4\u00dft dies Wunder euch in ihren Thaten schauen.", "tokens": ["Sie", "l\u00e4\u00dft", "dies", "Wun\u00b7der", "euch", "in", "ih\u00b7ren", "Tha\u00b7ten", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "NN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Der Helden Prei\u00df und F\u00fcrst; der F\u00fcrsten Haupt erbleichet;", "tokens": ["Der", "Hel\u00b7den", "Prei\u00df", "und", "F\u00fcrst", ";", "der", "F\u00fcrs\u00b7ten", "Haupt", "er\u00b7blei\u00b7chet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$.", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Grund des Throns erbebt; des Stammens Pracht verdirbt;", "tokens": ["Der", "Grund", "des", "Throns", "er\u00b7bebt", ";", "des", "Stam\u00b7mens", "Pracht", "ver\u00b7dirbt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$.", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des Staates Sa\u00fcle f\u00e4llt; der L\u00e4nder Schutz entweichet;", "tokens": ["Des", "Staa\u00b7tes", "Sa\u00fc\u00b7le", "f\u00e4llt", ";", "der", "L\u00e4n\u00b7der", "Schutz", "ent\u00b7wei\u00b7chet", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ja! Kayser, K\u00f6nig, F\u00fcrst und Held, und Vater stirbt!", "tokens": ["Ja", "!", "Kay\u00b7ser", ",", "K\u00f6\u00b7nig", ",", "F\u00fcrst", "und", "Held", ",", "und", "Va\u00b7ter", "stirbt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was h\u00e4ttet, F\u00fcrsten! ihr in eurem Rath entschlossen,", "tokens": ["Was", "h\u00e4t\u00b7tet", ",", "F\u00fcrs\u00b7ten", "!", "ihr", "in", "eu\u00b7rem", "Rath", "ent\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "NN", "$.", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wann euch dergleichen Sturtz und Fall w\u00e4r zugestossen?", "tokens": ["Wann", "euch", "derg\u00b7lei\u00b7chen", "Sturtz", "und", "Fall", "w\u00e4r", "zu\u00b7ges\u00b7tos\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PIS", "NN", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Der n\u00e4chst erfolgte Tag entdecke Feur und Flutten;", "tokens": ["Der", "n\u00e4chst", "er\u00b7folg\u00b7te", "Tag", "ent\u00b7de\u00b7cke", "Feur", "und", "Flut\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "NN", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein ungef\u00fcrchter Freund raub eurer V\u00f6lcker Ruh:", "tokens": ["Ein", "un\u00b7ge\u00b7f\u00fcrch\u00b7ter", "Freund", "raub", "eu\u00b7rer", "V\u00f6l\u00b7cker", "Ruh", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es eile Schaarenwei\u00df, und wider das Vermuthen", "tokens": ["Es", "ei\u00b7le", "Schaa\u00b7ren\u00b7wei\u00df", ",", "und", "wi\u00b7der", "das", "Ver\u00b7mu\u00b7then"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "$,", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein zweyfach-doppelt Heer auf eure Mauren zu:", "tokens": ["Ein", "zweyfach\u00b7dop\u00b7pelt", "Heer", "auf", "eu\u00b7re", "Mau\u00b7ren", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Sagt! w\u00fcrde bey dem Sturm, bey solchen Ungewittern", "tokens": ["Sagt", "!", "w\u00fcr\u00b7de", "bey", "dem", "Sturm", ",", "bey", "sol\u00b7chen", "Un\u00b7ge\u00b7wit\u00b7tern"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$.", "VAFIN", "APPR", "ART", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nicht auch der Tapferste des Helden-Ordens zittern?", "tokens": ["Nicht", "auch", "der", "Tap\u00b7fers\u00b7te", "des", "Hel\u00b7den\u00b7Or\u00b7dens", "zit\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Theresia verh\u00fcllt bey ihres Vaters Bahre", "tokens": ["The\u00b7re\u00b7sia", "ver\u00b7h\u00fcllt", "bey", "ih\u00b7res", "Va\u00b7ters", "Bah\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Den h\u00f6chst-gerechten Schmertz in ihren Trauer-Flor:", "tokens": ["Den", "h\u00f6chst\u00b7ge\u00b7rech\u00b7ten", "Schmertz", "in", "ih\u00b7ren", "Trau\u00b7e\u00b7rFlor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie wei\u00df nicht, was dem Thron, dem Zepter wiederfahre:", "tokens": ["Sie", "wei\u00df", "nicht", ",", "was", "dem", "Thron", ",", "dem", "Zep\u00b7ter", "wie\u00b7der\u00b7fah\u00b7re", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PRELS", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Feinde Zorn und Macht dringt schon bi\u00df an das Thor.", "tokens": ["Der", "Fein\u00b7de", "Zorn", "und", "Macht", "dringt", "schon", "bi\u00df", "an", "das", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Indem sie Trost, und Rath sieht in den Sarg verschliessen,", "tokens": ["In\u00b7dem", "sie", "Trost", ",", "und", "Rath", "sieht", "in", "den", "Sarg", "ver\u00b7schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "$,", "KON", "NN", "VVFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Glim\u0303t in dem Vaterland schon Brand und Blut-Vergiessen.", "tokens": ["Glim\u0303t", "in", "dem", "Va\u00b7ter\u00b7land", "schon", "Brand", "und", "Blut\u00b7Ver\u00b7gies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Sje rei\u00dft den Schleyer auf, sieht, da\u00df die Fahnen fliegen;", "tokens": ["Sje", "rei\u00dft", "den", "Schle\u00b7yer", "auf", ",", "sieht", ",", "da\u00df", "die", "Fah\u00b7nen", "flie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PTKVZ", "$,", "VVFIN", "$,", "KOUS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erschrickt, fa\u00dft Hertz und rufft: verf\u00e4lschter Freundschafts-Eyd!", "tokens": ["Er\u00b7schrickt", ",", "fa\u00dft", "Hertz", "und", "rufft", ":", "ver\u00b7f\u00e4lschter", "Freund\u00b7schafts\u00b7Eyd", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "NN", "KON", "VVFIN", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der mich besch\u00fctzen soll, fangt an mich zu bekriegen!", "tokens": ["Der", "mich", "be\u00b7sch\u00fct\u00b7zen", "soll", ",", "fangt", "an", "mich", "zu", "be\u00b7krie\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "$,", "VVFIN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So ist dann unter Fried und Krieg kein Unterscheid?", "tokens": ["So", "ist", "dann", "un\u00b7ter", "Fried", "und", "Krieg", "kein", "Un\u00b7ter\u00b7scheid", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "NN", "KON", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie schreyt Vertrauens-voll zu GOtt: HErr! la\u00df auf Erden", "tokens": ["Sie", "schreyt", "Ver\u00b7trau\u00b7ens\u00b7voll", "zu", "Gott", ":", "Herr", "!", "la\u00df", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "$.", "NN", "$.", "VVIMP", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mein Erb-Recht so erkannt, als dort im Himmel, werden!", "tokens": ["Mein", "Er\u00b7bRecht", "so", "er\u00b7kannt", ",", "als", "dort", "im", "Him\u00b7mel", ",", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "$,", "KOUS", "ADV", "APPRART", "NN", "$,", "VAINF", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.8": {"line.1": {"text": "Zur Rettung wollte sie nach ihrer Krone langen:", "tokens": ["Zur", "Ret\u00b7tung", "woll\u00b7te", "sie", "nach", "ih\u00b7rer", "Kro\u00b7ne", "lan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie griff auch allbereit das sch\u00f6nste Kleinod an,", "tokens": ["Sie", "griff", "auch", "all\u00b7be\u00b7reit", "das", "sch\u00f6ns\u00b7te", "Klei\u00b7nod", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und sprach: Das geb ich her, die Perl sollt ihr empfangen;", "tokens": ["Und", "sprach", ":", "Das", "geb", "ich", "her", ",", "die", "Perl", "sollt", "ihr", "emp\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PDS", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN", "VMFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wann ich daf\u00fcr den Werth des Friedens haben kan!", "tokens": ["Wann", "ich", "da\u00b7f\u00fcr", "den", "Werth", "des", "Frie\u00b7dens", "ha\u00b7ben", "kan", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PAV", "ART", "NN", "ART", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Umsonst, war der Bescheyd: Der gantze Schmuck der Krone", "tokens": ["Um\u00b7sonst", ",", "war", "der", "Be\u00b7scheyd", ":", "Der", "gant\u00b7ze", "Schmuck", "der", "Kro\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "VAFIN", "ART", "NN", "$.", "ART", "ADJA", "NN", "ART", "NN"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Ist schon f\u00fcr den bestim\u0303t, der deinen Thron bewohne.", "tokens": ["Ist", "schon", "f\u00fcr", "den", "be\u00b7stim\u0303t", ",", "der", "dei\u00b7nen", "Thron", "be\u00b7woh\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "ART", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Der Staat ersch\u00fctterte; der Thron fieng an zu wancken;", "tokens": ["Der", "Staat", "er\u00b7sch\u00fct\u00b7ter\u00b7te", ";", "der", "Thron", "fi\u00b7eng", "an", "zu", "wan\u00b7cken", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie gieng, bestieg ihn doch, und trotzte die Gefahr.", "tokens": ["Sie", "gieng", ",", "be\u00b7stieg", "ihn", "doch", ",", "und", "trotz\u00b7te", "die", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "$,", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Standhaftigkeit und Muth hielt sie bey dem Gedancken,", "tokens": ["Stand\u00b7haf\u00b7tig\u00b7keit", "und", "Muth", "hielt", "sie", "bey", "dem", "Ge\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der Anfangs f\u00fcrchterlich, am Ende nutzbar war.", "tokens": ["Der", "An\u00b7fangs", "f\u00fcrch\u00b7ter\u00b7lich", ",", "am", "En\u00b7de", "nutz\u00b7bar", "war", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "APPRART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Je mehr der Feinde Zorn, Gewalt, und Macht erfunden;", "tokens": ["Je", "mehr", "der", "Fein\u00b7de", "Zorn", ",", "Ge\u00b7walt", ",", "und", "Macht", "er\u00b7fun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "$,", "NN", "$,", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Je weniger war sie von jemand \u00fcberwunden.", "tokens": ["Je", "we\u00b7ni\u00b7ger", "war", "sie", "von", "je\u00b7mand", "\u00fc\u00b7berw\u00b7un\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "APPR", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Was Carls des Grossen Rath, und Vorsicht angefangen,", "tokens": ["Was", "Carls", "des", "Gros\u00b7sen", "Rath", ",", "und", "Vor\u00b7sicht", "an\u00b7ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "ART", "ADJA", "NN", "$,", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das bracht ihr Geist, zu Trotz des Widerstands, zum End.", "tokens": ["Das", "bracht", "ihr", "Geist", ",", "zu", "Trotz", "des", "Wi\u00b7der\u00b7stands", ",", "zum", "End", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,", "APPR", "APPR", "ART", "NN", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was Herrschkunst, Wei\u00dfheit, Muth und St\u00e4rcke kan erlangen,", "tokens": ["Was", "Herrschkunst", ",", "Wei\u00df\u00b7heit", ",", "Muth", "und", "St\u00e4r\u00b7cke", "kan", "er\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Ward ihr durch Feur und Schwert und Schrecken zugewendt.", "tokens": ["Ward", "ihr", "durch", "Feur", "und", "Schwert", "und", "Schre\u00b7cken", "zu\u00b7ge\u00b7wendt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "KON", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So klein man sie gemacht, so viel ward sie vergr\u00f6ssert:", "tokens": ["So", "klein", "man", "sie", "ge\u00b7macht", ",", "so", "viel", "ward", "sie", "ver\u00b7gr\u00f6s\u00b7sert", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PIS", "PPER", "VVPP", "$,", "ADV", "ADV", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das Feur hat ihrer Kron ererbtes Gold verbessert.", "tokens": ["Das", "Feur", "hat", "ih\u00b7rer", "Kron", "er\u00b7erb\u00b7tes", "Gold", "ver\u00b7bes\u00b7sert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Flei\u00df, Wachsamkeit, Vernunft, Witz, Hoheit des Verstandes,", "tokens": ["Flei\u00df", ",", "Wach\u00b7sam\u00b7keit", ",", "Ver\u00b7nunft", ",", "Witz", ",", "Ho\u00b7heit", "des", "Ver\u00b7stan\u00b7des", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hertz, M\u00fche, Geist und Muth hat ihr den Ruhm erlangt,", "tokens": ["Hertz", ",", "M\u00fc\u00b7he", ",", "Geist", "und", "Muth", "hat", "ihr", "den", "Ruhm", "er\u00b7langt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df sie als Retterin des frohen Vaterlandes", "tokens": ["Da\u00df", "sie", "als", "Ret\u00b7te\u00b7rin", "des", "fro\u00b7hen", "Va\u00b7ter\u00b7lan\u00b7des"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "KOUS", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht bey den Freunden nur, auch bey den Feinden prangt.", "tokens": ["Nicht", "bey", "den", "Freun\u00b7den", "nur", ",", "auch", "bey", "den", "Fein\u00b7den", "prangt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "ADV", "$,", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jm Sieg und im Verlust, in Freuden und Beschwerden", "tokens": ["Jm", "Sieg", "und", "im", "Ver\u00b7lust", ",", "in", "Freu\u00b7den", "und", "Be\u00b7schwer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hat sie die Tugenden zu R\u00e4then und Gef\u00e4rten.", "tokens": ["Hat", "sie", "die", "Tu\u00b7gen\u00b7den", "zu", "R\u00e4\u00b7then", "und", "Ge\u00b7f\u00e4r\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Sje wei\u00df im h\u00e4rtsten Fall, den besten Schlu\u00df zu w\u00e4hlen;", "tokens": ["Sje", "wei\u00df", "im", "h\u00e4rts\u00b7ten", "Fall", ",", "den", "bes\u00b7ten", "Schlu\u00df", "zu", "w\u00e4h\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie siegt, doch ohne Stoltz; sie k\u00e4mpft, doch ohne Rach:", "tokens": ["Sie", "siegt", ",", "doch", "oh\u00b7ne", "Stoltz", ";", "sie", "k\u00e4mpft", ",", "doch", "oh\u00b7ne", "Rach", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "APPR", "NN", "$.", "PPER", "VVFIN", "$,", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jhr Endzweck ist das Recht; ihr Streit, sich GOtt befehlen:", "tokens": ["Ihr", "End\u00b7zweck", "ist", "das", "Recht", ";", "ihr", "Streit", ",", "sich", "Gott", "be\u00b7feh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$.", "PPOSAT", "NN", "$,", "PRF", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jhr Hertz strebt jenen nicht, nur diesen beyden nach.", "tokens": ["Ihr", "Hertz", "strebt", "je\u00b7nen", "nicht", ",", "nur", "die\u00b7sen", "bey\u00b7den", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PDS", "PTKNEG", "$,", "ADV", "PDAT", "PIAT", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jhr Helden m\u00fc\u00dft von ihr die Helden-Tugend lernen:", "tokens": ["Ihr", "Hel\u00b7den", "m\u00fc\u00dft", "von", "ihr", "die", "Hel\u00b7den\u00b7Tu\u00b7gend", "ler\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wann ihr die Schaalen seyd, so gleichet sie den Kernen.", "tokens": ["Wann", "ihr", "die", "Schaa\u00b7len", "seyd", ",", "so", "glei\u00b7chet", "sie", "den", "Ker\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VAFIN", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Wje? was? es \u00f6ffnet sich den Augen ein Gesichte;", "tokens": ["Wie", "?", "was", "?", "es", "\u00f6ff\u00b7net", "sich", "den", "Au\u00b7gen", "ein", "Ge\u00b7sich\u00b7te", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWS", "$.", "PPER", "VVFIN", "PRF", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein Lorber-reiches Haupt steigt aus der Gruft empor:", "tokens": ["Ein", "Lor\u00b7ber\u00b7rei\u00b7ches", "Haupt", "steigt", "aus", "der", "Gruft", "em\u00b7por", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ja! seht, wie sich der Held, mit Ernst zu reden, richte;", "tokens": ["Ja", "!", "seht", ",", "wie", "sich", "der", "Held", ",", "mit", "Ernst", "zu", "re\u00b7den", ",", "rich\u00b7te", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "$.", "VVFIN", "$,", "PWAV", "PRF", "ART", "NN", "$,", "APPR", "NE", "PTKZU", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vielleicht tr\u00e4gt er das Wort statt aller Helden vor:", "tokens": ["Viel\u00b7leicht", "tr\u00e4gt", "er", "das", "Wort", "statt", "al\u00b7ler", "Hel\u00b7den", "vor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er regt den F\u00fcrsten-Stab; was wird es wohl bedeuten?", "tokens": ["Er", "regt", "den", "F\u00fcrs\u00b7ten\u00b7Stab", ";", "was", "wird", "es", "wohl", "be\u00b7deu\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "PWS", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich hoffe nicht, da\u00df er wird meinen Satz bestreiten?", "tokens": ["Ich", "hof\u00b7fe", "nicht", ",", "da\u00df", "er", "wird", "mei\u00b7nen", "Satz", "be\u00b7strei\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "VAFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Vernehmt! ich h\u00f6re schon, wie seine Worte th\u00f6nen:", "tokens": ["Ver\u00b7nehmt", "!", "ich", "h\u00f6\u00b7re", "schon", ",", "wie", "sei\u00b7ne", "Wor\u00b7te", "th\u00f6\u00b7nen", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPER", "VVFIN", "ADV", "$,", "PWAV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Halt ein! es ist zu viel, was man uns vorgebracht:", "tokens": ["Halt", "ein", "!", "es", "ist", "zu", "viel", ",", "was", "man", "uns", "vor\u00b7ge\u00b7bracht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$.", "PPER", "VAFIN", "PTKA", "PIS", "$,", "PRELS", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Will man vielleicht damit nur unsre Thaten h\u00f6hnen?", "tokens": ["Will", "man", "viel\u00b7leicht", "da\u00b7mit", "nur", "uns\u00b7re", "Tha\u00b7ten", "h\u00f6h\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "PAV", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wir wissen auch, sagt er, was einen Helden macht.", "tokens": ["Wir", "wis\u00b7sen", "auch", ",", "sagt", "er", ",", "was", "ei\u00b7nen", "Hel\u00b7den", "macht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "VVFIN", "PPER", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Durch Dichter werden oft aus Hirn-Geburten Helden:", "tokens": ["Durch", "Dich\u00b7ter", "wer\u00b7den", "oft", "aus", "Hirn\u00b7Ge\u00b7bur\u00b7ten", "Hel\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ADV", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was, wann sie gar mit Recht wahrhafte Thaten melden?", "tokens": ["Was", ",", "wann", "sie", "gar", "mit", "Recht", "wahr\u00b7haf\u00b7te", "Tha\u00b7ten", "mel\u00b7den", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "PWAV", "PPER", "ADV", "APPR", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "And wer beredet uns, da\u00df K\u00f6nigliche Schw\u00fcre,", "tokens": ["And", "wer", "be\u00b7re\u00b7det", "uns", ",", "da\u00df", "K\u00f6\u00b7nig\u00b7li\u00b7che", "Schw\u00fc\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "$,", "KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein GOtt-geweyhtes Wort auf einmahl ohne Frucht?", "tokens": ["Ein", "Got\u00b7tge\u00b7wey\u00b7htes", "Wort", "auf", "ein\u00b7mahl", "oh\u00b7ne", "Frucht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df man die K\u00f6niginn alldort zum Opfer f\u00fchre,", "tokens": ["Da\u00df", "man", "die", "K\u00f6\u00b7ni\u00b7ginn", "all\u00b7dort", "zum", "Op\u00b7fer", "f\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo Sie Gewehr und Hilff und Zuflucht hat gesucht?", "tokens": ["Wo", "Sie", "Ge\u00b7wehr", "und", "Hilff", "und", "Zu\u00b7flucht", "hat", "ge\u00b7sucht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "KON", "NN", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Himmel h\u00e4tt gewi\u00df .... Jedoch hier mu\u00df ich schweigen;", "tokens": ["Der", "Him\u00b7mel", "h\u00e4tt", "ge\u00b7wi\u00df", "....", "Je\u00b7doch", "hier", "mu\u00df", "ich", "schwei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$.", "ADV", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es w\u00e4r Vermessenheit, sein Urtheil anzuzeigen.", "tokens": ["Es", "w\u00e4r", "Ver\u00b7mes\u00b7sen\u00b7heit", ",", "sein", "Ur\u00b7theil", "an\u00b7zu\u00b7zei\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Wann alles, was du sagst, sich in der That bef\u00fcnde,", "tokens": ["Wann", "al\u00b7les", ",", "was", "du", "sagst", ",", "sich", "in", "der", "That", "be\u00b7f\u00fcn\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was hie\u00df man endlich Recht, Treu, Glauben, Fried und Krieg?", "tokens": ["Was", "hie\u00df", "man", "end\u00b7lich", "Recht", ",", "Treu", ",", "Glau\u00b7ben", ",", "Fried", "und", "Krieg", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ADV", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sag, ob der Erden Rund nicht im Verderben st\u00fcnde?", "tokens": ["Sag", ",", "ob", "der", "Er\u00b7den", "Rund", "nicht", "im", "Ver\u00b7der\u00b7ben", "st\u00fcn\u00b7de", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ART", "NN", "ADJD", "PTKNEG", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Recht nicht, die Gewalt erlangte Rang und Sieg.", "tokens": ["Das", "Recht", "nicht", ",", "die", "Ge\u00b7walt", "er\u00b7lang\u00b7te", "Rang", "und", "Sieg", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "$,", "ART", "NN", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was w\u00e4r an einem Pflug, an einem Helden-Degen,", "tokens": ["Was", "w\u00e4r", "an", "ei\u00b7nem", "Pflug", ",", "an", "ei\u00b7nem", "Hel\u00b7den\u00b7De\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "An Ordnung und Gesatz; an Ehr und Ruhm gelegen?", "tokens": ["An", "Ord\u00b7nung", "und", "Ge\u00b7satz", ";", "an", "Ehr", "und", "Ruhm", "ge\u00b7le\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$.", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.17": {"line.1": {"text": "Amsonst erw\u00e4hnest du so viele Wichtigkeiten;", "tokens": ["Am\u00b7sonst", "er\u00b7w\u00e4h\u00b7nest", "du", "so", "vie\u00b7le", "Wich\u00b7tig\u00b7kei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "W\u00e4r der geringste Theil von der Erzehlung wahr;", "tokens": ["W\u00e4r", "der", "ge\u00b7rings\u00b7te", "Theil", "von", "der", "Er\u00b7zeh\u00b7lung", "wahr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So schw\u00fcng ", "tokens": ["So", "schw\u00fcng"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Der Anfall, und der Schutz ist viel zu wunderbar.", "tokens": ["Der", "An\u00b7fall", ",", "und", "der", "Schutz", "ist", "viel", "zu", "wun\u00b7der\u00b7bar", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du suchst nur, uns den Ruhm, den Helden-Lohn, zu rauben:", "tokens": ["Du", "suchst", "nur", ",", "uns", "den", "Ruhm", ",", "den", "Hel\u00b7den\u00b7Lohn", ",", "zu", "rau\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "ART", "NN", "$,", "ART", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Geh, sag es wem du wilst! wir k\u00f6nnen es nicht glauben.", "tokens": ["Geh", ",", "sag", "es", "wem", "du", "wilst", "!", "wir", "k\u00f6n\u00b7nen", "es", "nicht", "glau\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "PWS", "PPER", "VMFIN", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Wje? dieses ist die Sprach und Antwort unsrer Ahnen?", "tokens": ["Wie", "?", "die\u00b7ses", "ist", "die", "Sprach", "und", "Ant\u00b7wort", "uns\u00b7rer", "Ah\u00b7nen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PDS", "VAFIN", "ART", "NN", "KON", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie messen dem Bericht so wenig Glauben bey?", "tokens": ["Sie", "mes\u00b7sen", "dem", "Be\u00b7richt", "so", "we\u00b7nig", "Glau\u00b7ben", "bey", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie neigten sonst gewi\u00df mit Ehrfurcht ihre Fahnen,", "tokens": ["Sie", "neig\u00b7ten", "sonst", "ge\u00b7wi\u00df", "mit", "Ehr\u00b7furcht", "ih\u00b7re", "Fah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und nennten den Gesang nicht eine Schmeicheley.", "tokens": ["Und", "nenn\u00b7ten", "den", "Ge\u00b7sang", "nicht", "ei\u00b7ne", "Schmei\u00b7che\u00b7ley", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Entweder f\u00fcrchten sie, ", "tokens": ["Ent\u00b7we\u00b7der", "f\u00fcrch\u00b7ten", "sie", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Was? oder eyfern sie, da\u00df ihre Thaten besser?", "tokens": ["Was", "?", "o\u00b7der", "ey\u00b7fern", "sie", ",", "da\u00df", "ih\u00b7re", "Tha\u00b7ten", "bes\u00b7ser", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "KON", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Nein: die Unm\u00f6glichkeit macht, da\u00df sie dieses meinen:", "tokens": ["Nein", ":", "die", "Un\u00b7m\u00f6g\u00b7lich\u00b7keit", "macht", ",", "da\u00df", "sie", "die\u00b7ses", "mei\u00b7nen", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "PDS", "VVFIN", "$."], "meter": "-+-+-+++-+-+-", "measure": "unknown.measure.septa"}, "line.2": {"text": "Neyd, Ha\u00df, Verrath und List; Zorn, Mi\u00dfgunst, Rach und Groll", "tokens": ["Neyd", ",", "Ha\u00df", ",", "Ver\u00b7rath", "und", "List", ";", "Zorn", ",", "Mi\u00df\u00b7gunst", ",", "Rach", "und", "Groll"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$.", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In Waffen einig sehn, das will nicht m\u00f6glich scheinen:", "tokens": ["In", "Waf\u00b7fen", "ei\u00b7nig", "sehn", ",", "das", "will", "nicht", "m\u00f6g\u00b7lich", "schei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVINF", "$,", "PDS", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil die Vereinigung sich selbst zernichten soll.", "tokens": ["Weil", "die", "Ver\u00b7ei\u00b7ni\u00b7gung", "sich", "selbst", "zer\u00b7nich\u00b7ten", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie messen diese That nach dem, was folgen k\u00f6nnte:", "tokens": ["Sie", "mes\u00b7sen", "die\u00b7se", "That", "nach", "dem", ",", "was", "fol\u00b7gen", "k\u00f6nn\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "APPR", "ART", "$,", "PWS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df man das Recht nur dem, der furchtbar ist, verg\u00f6nnte.", "tokens": ["Da\u00df", "man", "das", "Recht", "nur", "dem", ",", "der", "furcht\u00b7bar", "ist", ",", "ver\u00b7g\u00f6nn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADV", "ART", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Kein Wunder; frage man, die gegenw\u00e4rtig waren:", "tokens": ["Kein", "Wun\u00b7der", ";", "fra\u00b7ge", "man", ",", "die", "ge\u00b7gen\u00b7w\u00e4r\u00b7tig", "wa\u00b7ren", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$.", "VVFIN", "PIS", "$,", "PRELS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was sie, da dieser Sturm die Welt ergriff, gedacht?", "tokens": ["Was", "sie", ",", "da", "die\u00b7ser", "Sturm", "die", "Welt", "er\u00b7griff", ",", "ge\u00b7dacht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "$,", "KOUS", "PDAT", "NN", "ART", "NN", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hat nicht das Aug erstarrt, das Ohr entsetzt erfahren,", "tokens": ["Hat", "nicht", "das", "Aug", "er\u00b7starrt", ",", "das", "Ohr", "ent\u00b7setzt", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "VVPP", "$,", "ART", "NN", "VVPP", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie dieses Kronen-Hau\u00df ersch\u00fcttert und gekracht?", "tokens": ["Wie", "die\u00b7ses", "Kro\u00b7nen\u00b7Hau\u00df", "er\u00b7sch\u00fct\u00b7tert", "und", "ge\u00b7kracht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NN", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man h\u00f6rte, wie von West und Nord der Donner rollte;", "tokens": ["Man", "h\u00f6r\u00b7te", ",", "wie", "von", "West", "und", "Nord", "der", "Don\u00b7ner", "roll\u00b7te", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PWAV", "APPR", "NE", "KON", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer hoffte, da\u00df der Thron dem Sturtz entkommen sollte?", "tokens": ["Wer", "hoff\u00b7te", ",", "da\u00df", "der", "Thron", "dem", "Sturtz", "ent\u00b7kom\u00b7men", "soll\u00b7te", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Doch ist Theresia, der man uns fast beraubte;", "tokens": ["Doch", "ist", "The\u00b7re\u00b7sia", ",", "der", "man", "uns", "fast", "be\u00b7raub\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NE", "$,", "PRELS", "PIS", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Die man von ihrem Recht, von ihrem Eigenthum,", "tokens": ["Die", "man", "von", "ih\u00b7rem", "Recht", ",", "von", "ih\u00b7rem", "Ei\u00b7gen\u00b7thum", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des Vaters Kron entbl\u00f6\u00dft, vom Thron gest\u00fcrtzet glaubte;", "tokens": ["Des", "Va\u00b7ters", "Kron", "ent\u00b7bl\u00f6\u00dft", ",", "vom", "Thron", "ge\u00b7st\u00fcrt\u00b7zet", "glaub\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "APPRART", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die dreyfach-bl\u00fchende gekr\u00f6nte Purpur Bluhm", "tokens": ["Die", "dreyfach\u00b7bl\u00fc\u00b7hen\u00b7de", "ge\u00b7kr\u00f6n\u00b7te", "Pur\u00b7pur", "Bluhm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Die Bluhme, welche man schon vor entlaubt geachtet,", "tokens": ["Die", "Bluh\u00b7me", ",", "wel\u00b7che", "man", "schon", "vor", "ent\u00b7laubt", "ge\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "ADV", "APPR", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird nun im sch\u00f6nsten Flor des h\u00f6chsten Schmucks betrachtet.", "tokens": ["Wird", "nun", "im", "sch\u00f6ns\u00b7ten", "Flor", "des", "h\u00f6chs\u00b7ten", "Schmucks", "be\u00b7trach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Wann alter Helden Sinn nicht glaubet, was geschehen;", "tokens": ["Wann", "al\u00b7ter", "Hel\u00b7den", "Sinn", "nicht", "glau\u00b7bet", ",", "was", "ge\u00b7sche\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "NN", "PTKNEG", "VVFIN", "$,", "PWS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In der Erzehlung nichts, als eitlen Schimmer sieht:", "tokens": ["In", "der", "Er\u00b7zeh\u00b7lung", "nichts", ",", "als", "eit\u00b7len", "Schim\u00b7mer", "sieht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIS", "$,", "KOUS", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ja, wann wir selbst erstaunt, verwirrt, entz\u00fccket stehen;", "tokens": ["Ja", ",", "wann", "wir", "selbst", "er\u00b7staunt", ",", "ver\u00b7wirrt", ",", "ent\u00b7z\u00fc\u00b7cket", "ste\u00b7hen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PWAV", "PPER", "ADV", "ADJD", "$,", "ADJD", "$,", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da, der sie st\u00fcrtzen wollt, erschrocken stutzt und flieht:", "tokens": ["Da", ",", "der", "sie", "st\u00fcrt\u00b7zen", "wollt", ",", "er\u00b7schro\u00b7cken", "stutzt", "und", "flieht", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$,", "VVFIN", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was wird die sp\u00e4te Welt zu dieser Nachricht sagen?", "tokens": ["Was", "wird", "die", "sp\u00e4\u00b7te", "Welt", "zu", "die\u00b7ser", "Nach\u00b7richt", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird sie so viel darnach, als dort die Vorwelt fragen?", "tokens": ["Wird", "sie", "so", "viel", "dar\u00b7nach", ",", "als", "dort", "die", "Vor\u00b7welt", "fra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PAV", "$,", "KOUS", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Nein: der Erfolg des Wercks wird ihren Augen zeigen,", "tokens": ["Nein", ":", "der", "Er\u00b7folg", "des", "Wercks", "wird", "ih\u00b7ren", "Au\u00b7gen", "zei\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ART", "NN", "ART", "NN", "VAFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df dieser Ruhm-Gesang kein Bild der Dichter sey;", "tokens": ["Da\u00df", "die\u00b7ser", "Ruhm\u00b7Ge\u00b7sang", "kein", "Bild", "der", "Dich\u00b7ter", "sey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "PIAT", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man sieht die Pflantzen schon, wie Ceder-Ba\u00fcme, steigen.", "tokens": ["Man", "sieht", "die", "Pflant\u00b7zen", "schon", ",", "wie", "Ce\u00b7der\u00b7Ba\u00fc\u00b7me", ",", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "$,", "PWAV", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Selbst die ", "tokens": ["Selbst", "die"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Sie kommt erregt, erfreut von ihren Ehren-B\u00fchnen,", "tokens": ["Sie", "kommt", "er\u00b7regt", ",", "er\u00b7freut", "von", "ih\u00b7ren", "Eh\u00b7ren\u00b7B\u00fch\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "$,", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und sieht den Helden-Stamm in ihren Auen gr\u00fcnen.", "tokens": ["Und", "sieht", "den", "Hel\u00b7den\u00b7Stamm", "in", "ih\u00b7ren", "Au\u00b7en", "gr\u00fc\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Sje rufft: Betrachte man den Kronen-reichen Sprossen", "tokens": ["Sje", "rufft", ":", "Be\u00b7trach\u00b7te", "man", "den", "Kro\u00b7nen\u00b7rei\u00b7chen", "Spros\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$.", "VVFIN", "PIS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "An diesem F\u00fcrsten-Baum, der einst zu ", "tokens": ["An", "die\u00b7sem", "F\u00fcrs\u00b7ten\u00b7Baum", ",", "der", "einst", "zu"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "ADV", "APPR"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Er schien zwar welck, jedoch er ist frisch vorgeschossen:", "tokens": ["Er", "schien", "zwar", "welck", ",", "je\u00b7doch", "er", "ist", "frisch", "vor\u00b7ge\u00b7schos\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,", "ADV", "PPER", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Freud und mein Entschlu\u00df sey allen Welten kund!", "tokens": ["Die", "Freud", "und", "mein", "Ent\u00b7schlu\u00df", "sey", "al\u00b7len", "Wel\u00b7ten", "kund", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPOSAT", "NN", "VAFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich schwere dem, der auch vielleicht nicht wurde sterben;", "tokens": ["Ich", "schwe\u00b7re", "dem", ",", "der", "auch", "viel\u00b7leicht", "nicht", "wur\u00b7de", "ster\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "$,", "PRELS", "ADV", "ADV", "PTKNEG", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ber\u00fchrt er diesen Ast; Rach, Untergang, Verderben.", "tokens": ["Be\u00b7r\u00fchrt", "er", "die\u00b7sen", "Ast", ";", "Rach", ",", "Un\u00b7ter\u00b7gang", ",", "Ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "PDAT", "NN", "$.", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Sje sieht noch einen Zweig, der sich mit dem verbindet:", "tokens": ["Sje", "sieht", "noch", "ei\u00b7nen", "Zweig", ",", "der", "sich", "mit", "dem", "ver\u00b7bin\u00b7det", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "NN", "$,", "PRELS", "PRF", "APPR", "ART", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Frolockt noch mehr und spricht: ", "tokens": ["Fro\u00b7lockt", "noch", "mehr", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kein Baum ist, welcher den an Fr\u00fcchten \u00fcberwindet!", "tokens": ["Kein", "Baum", "ist", ",", "wel\u00b7cher", "den", "an", "Fr\u00fcch\u00b7ten", "\u00fc\u00b7berw\u00b7in\u00b7det", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$,", "PRELS", "ART", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dies Paar ist seine Kron, Ehr, Ansehn, Pracht und Zucht!", "tokens": ["Dies", "Paar", "ist", "sei\u00b7ne", "Kron", ",", "Ehr", ",", "An\u00b7sehn", ",", "Pracht", "und", "Zucht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "PPOSAT", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der ist, von dem die Welt die gr\u00f6sten Helden hatte:", "tokens": ["Der", "ist", ",", "von", "dem", "die", "Welt", "die", "gr\u00f6s\u00b7ten", "Hel\u00b7den", "hat\u00b7te", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "APPR", "PRELS", "ART", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von dem ich k\u00fcnftighin sie noch zu ziehn, gestatte.", "tokens": ["Von", "dem", "ich", "k\u00fcnf\u00b7tig\u00b7hin", "sie", "noch", "zu", "ziehn", ",", "ge\u00b7stat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Wjll selbst Unsterblichkeit, da\u00df man den Baum bewahre;", "tokens": ["Wjll", "selbst", "U\u00b7nsterb\u00b7lich\u00b7keit", ",", "da\u00df", "man", "den", "Baum", "be\u00b7wah\u00b7re", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "NN", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Er\u00f6ffnet sie der Welt den hohen Schutz-Befehl;", "tokens": ["Er\u00b7\u00f6ff\u00b7net", "sie", "der", "Welt", "den", "ho\u00b7hen", "Schutz\u00b7Be\u00b7fehl", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So wird auch in dem Lauf der allersp\u00e4tsten Jahre", "tokens": ["So", "wird", "auch", "in", "dem", "Lauf", "der", "al\u00b7ler\u00b7sp\u00e4ts\u00b7ten", "Jah\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ber\u00fchmt, bewundert seyn, was ich davon erzehl.", "tokens": ["Be\u00b7r\u00fchmt", ",", "be\u00b7wun\u00b7dert", "seyn", ",", "was", "ich", "da\u00b7von", "er\u00b7zehl", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "VAINF", "$,", "PWS", "PPER", "PAV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und recht: der Zweifel ist umsonst und unvonn\u00f6then:", "tokens": ["Und", "recht", ":", "der", "Zwei\u00b7fel", "ist", "um\u00b7sonst", "und", "un\u00b7von\u00b7n\u00f6\u00b7then", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "ART", "NN", "VAFIN", "ADV", "KON", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wir haben zum Bewei\u00df des Stammens Majest\u00e4ten.", "tokens": ["Wir", "ha\u00b7ben", "zum", "Be\u00b7wei\u00df", "des", "Stam\u00b7mens", "Ma\u00b7jes\u00b7t\u00e4\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Die Nach-Welt wird sie sehn und sagen: diese Fr\u00fcchte", "tokens": ["Die", "Nach\u00b7Welt", "wird", "sie", "sehn", "und", "sa\u00b7gen", ":", "die\u00b7se", "Fr\u00fcch\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVINF", "KON", "VVINF", "$.", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo kommen sie dann her? Wer ist der F\u00fcrst, der Held?", "tokens": ["Wo", "kom\u00b7men", "sie", "dann", "her", "?", "Wer", "ist", "der", "F\u00fcrst", ",", "der", "Held", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "PWS", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er herrscht, er kriegt, er siegt: es ist kein blind Ger\u00fcchte!", "tokens": ["Er", "herrscht", ",", "er", "kriegt", ",", "er", "siegt", ":", "es", "ist", "kein", "blind", "Ge\u00b7r\u00fcch\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "PPER", "VAFIN", "PIAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er stammet von dem Baum, von dem man uns gemeldt:", "tokens": ["Er", "stam\u00b7met", "von", "dem", "Baum", ",", "von", "dem", "man", "uns", "ge\u00b7meldt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "APPR", "PRELS", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So kan man \u00fcberzeugt der Sache Wahrheit mercken:", "tokens": ["So", "kan", "man", "\u00fc\u00b7berz\u00b7eugt", "der", "Sa\u00b7che", "Wahr\u00b7heit", "mer\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "VVFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was einst ", "tokens": ["Was", "einst"], "token_info": ["word", "word"], "pos": ["PWS", "ADV"], "meter": "-+", "measure": "iambic.single"}}, "stanza.28": {"line.1": {"text": "Die Wercke seynd so gro\u00df, als keine Zeit erfahren:", "tokens": ["Die", "Wer\u00b7cke", "seynd", "so", "gro\u00df", ",", "als", "kei\u00b7ne", "Zeit", "er\u00b7fah\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$,", "KOUS", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie seynd wahrhaftig nicht von Dichtern aufgef\u00fchrt.", "tokens": ["Sie", "seynd", "wahr\u00b7haf\u00b7tig", "nicht", "von", "Dich\u00b7tern", "auf\u00b7ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "PTKNEG", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Derselben Ursprung ist in jenen Helden-Jahren,", "tokens": ["Der\u00b7sel\u00b7ben", "Ur\u00b7sprung", "ist", "in", "je\u00b7nen", "Hel\u00b7den\u00b7Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die dort ", "tokens": ["Die", "dort"], "token_info": ["word", "word"], "pos": ["ART", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "In seiner Majest\u00e4t erblickt man solche Zeichen,", "tokens": ["In", "sei\u00b7ner", "Ma\u00b7jes\u00b7t\u00e4t", "er\u00b7blickt", "man", "sol\u00b7che", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PIS", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die dieser K\u00f6niginn, von der man redet, gleichen.", "tokens": ["Die", "die\u00b7ser", "K\u00f6\u00b7ni\u00b7ginn", ",", "von", "der", "man", "re\u00b7det", ",", "glei\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PDAT", "NN", "$,", "APPR", "PRELS", "PIS", "VVFIN", "$,", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Der Baum hat, wie man sagt, zwar einen Streich empfunden;", "tokens": ["Der", "Baum", "hat", ",", "wie", "man", "sagt", ",", "zwar", "ei\u00b7nen", "Streich", "emp\u00b7fun\u00b7den", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PWAV", "PIS", "VVFIN", "$,", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es gehet ihm die Zier des gr\u00f6sten Sprossens ab:", "tokens": ["Es", "ge\u00b7het", "ihm", "die", "Zier", "des", "gr\u00f6s\u00b7ten", "Spros\u00b7sens", "ab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hingegen haben sich statt dessen zwey verbunden;", "tokens": ["Hin\u00b7ge\u00b7gen", "ha\u00b7ben", "sich", "statt", "des\u00b7sen", "zwey", "ver\u00b7bun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "APPR", "PDS", "CARD", "VVPP", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Wovon ", "tokens": ["Wo\u00b7von"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "So bringt ja der Verlust den Fr\u00fcchten kein Verderben:", "tokens": ["So", "bringt", "ja", "der", "Ver\u00b7lust", "den", "Fr\u00fcch\u00b7ten", "kein", "Ver\u00b7der\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier starb das Haupt, doch lebt die Folge seiner Erben.", "tokens": ["Hier", "starb", "das", "Haupt", ",", "doch", "lebt", "die", "Fol\u00b7ge", "sei\u00b7ner", "Er\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Gott theilt die Kronen aus: Er wiedmet sie den H\u00e4usern,", "tokens": ["Gott", "theilt", "die", "Kro\u00b7nen", "aus", ":", "Er", "wied\u00b7met", "sie", "den", "H\u00e4u\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Gro\u00dfmuth, Fr\u00f6mmigkeit und wahre Wei\u00dfheit schm\u00fcckt.", "tokens": ["Die", "Gro\u00df\u00b7muth", ",", "Fr\u00f6m\u00b7mig\u00b7keit", "und", "wah\u00b7re", "Wei\u00df\u00b7heit", "schm\u00fcckt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum prangen diese zwey mit K\u00f6nigen und Kaysern:", "tokens": ["Drum", "pran\u00b7gen", "die\u00b7se", "zwey", "mit", "K\u00f6\u00b7ni\u00b7gen", "und", "Kay\u00b7sern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PDAT", "CARD", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Drum blieb ", "tokens": ["Drum", "blieb"], "token_info": ["word", "word"], "pos": ["PAV", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Wo Tugend, GOtt und Recht um Kron und Zepter fechten,", "tokens": ["Wo", "Tu\u00b7gend", ",", "Gott", "und", "Recht", "um", "Kron", "und", "Zep\u00b7ter", "fech\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "NN", "KON", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kan man den Sieges-Krantz leicht um die Scheitel flechten.", "tokens": ["Kan", "man", "den", "Sie\u00b7ges\u00b7Krantz", "leicht", "um", "die", "Schei\u00b7tel", "flech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ART", "NN", "ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+--+-++--+-+-", "measure": "iambic.hexa.invert"}}, "stanza.31": {"line.1": {"text": "So wird der sp\u00e4ten Welt erstaunter Nachklang sprechen:", "tokens": ["So", "wird", "der", "sp\u00e4\u00b7ten", "Welt", "er\u00b7staun\u00b7ter", "Nach\u00b7klang", "spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So wird die Sach erzehlt, geglaubt, gepriesen seyn.", "tokens": ["So", "wird", "die", "Sach", "er\u00b7zehlt", ",", "ge\u00b7glaubt", ",", "ge\u00b7prie\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVFIN", "$,", "VVPP", "$,", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was kan mir also mehr den Vorsatz unterbrechen?", "tokens": ["Was", "kan", "mir", "al\u00b7so", "mehr", "den", "Vor\u00b7satz", "un\u00b7ter\u00b7bre\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es stimmt mit mir, was ist, was war, was seyn wird, ein.", "tokens": ["Es", "stimmt", "mit", "mir", ",", "was", "ist", ",", "was", "war", ",", "was", "seyn", "wird", ",", "ein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "PWS", "VAFIN", "$,", "PWS", "VAFIN", "$,", "PRELS", "VAINF", "VAFIN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auf auf dann Geist und Hertz! entflammet Muth und Sinnen!", "tokens": ["Auf", "auf", "dann", "Geist", "und", "Hertz", "!", "ent\u00b7flam\u00b7met", "Muth", "und", "Sin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ADV", "NN", "KON", "NN", "$.", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Entreisset euch der Furcht! verfolget das Beginnen!", "tokens": ["E\u00b7ntreis\u00b7set", "euch", "der", "Furcht", "!", "ver\u00b7fol\u00b7get", "das", "Be\u00b7gin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Ja, K\u00f6niginn! ich will von zehen Stunden singen,", "tokens": ["Ja", ",", "K\u00f6\u00b7ni\u00b7ginn", "!", "ich", "will", "von", "ze\u00b7hen", "Stun\u00b7den", "sin\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$.", "PPER", "VMFIN", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die deiner Tugenden getreuer Rath gewacht;", "tokens": ["Die", "dei\u00b7ner", "Tu\u00b7gen\u00b7den", "ge\u00b7treu\u00b7er", "Rath", "ge\u00b7wacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als jede sich bem\u00fcht, Bewei\u00dfthum aufzubringen,", "tokens": ["Als", "je\u00b7de", "sich", "be\u00b7m\u00fcht", ",", "Be\u00b7wei\u00df\u00b7thum", "auf\u00b7zu\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "PRF", "VVPP", "$,", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df ihre Wirckung dich das, was du bist, gemacht.", "tokens": ["Da\u00df", "ih\u00b7re", "Wir\u00b7ckung", "dich", "das", ",", "was", "du", "bist", ",", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "PDS", "$,", "PWS", "PPER", "VAFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nicht da\u00df ich dir ein Lob, ein Ehren-Mahl erdichte:", "tokens": ["Nicht", "da\u00df", "ich", "dir", "ein", "Lob", ",", "ein", "Eh\u00b7ren\u00b7Mahl", "er\u00b7dich\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOUS", "PPER", "PPER", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}