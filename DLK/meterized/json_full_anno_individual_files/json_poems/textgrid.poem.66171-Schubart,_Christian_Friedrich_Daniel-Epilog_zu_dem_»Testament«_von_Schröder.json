{"textgrid.poem.66171": {"metadata": {"author": {"name": "Schubart, Christian Friedrich Daniel", "birth": "N.A.", "death": "N.A."}, "title": "Epilog zu dem \u00bbTestament\u00ab von Schr\u00f6der", "genre": "verse", "period": "N.A.", "pub_year": 1789, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Vorhang falle nicht, ihr G\u00f6nner unsers Spiels,", "tokens": ["Der", "Vor\u00b7hang", "fal\u00b7le", "nicht", ",", "ihr", "G\u00f6n\u00b7ner", "un\u00b7sers", "Spiels", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "$,", "PPOSAT", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bis ich im Drange des Gef\u00fchls", "tokens": ["Bis", "ich", "im", "Dran\u00b7ge", "des", "Ge\u00b7f\u00fchls"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "An CARLS gefei'rtem Lebenstage", "tokens": ["An", "CaRLS", "ge\u00b7fei'r\u00b7tem", "Le\u00b7bens\u00b7ta\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zwei Worte noch zu sagen wage.", "tokens": ["Zwei", "Wor\u00b7te", "noch", "zu", "sa\u00b7gen", "wa\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Kein Festtagspomp strahlt um uns her.", "tokens": ["Kein", "Fest\u00b7tags\u00b7pomp", "strahlt", "um", "uns", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "CaRLS Name, uns so gro\u00df und theuer,", "tokens": ["CaRLS", "Na\u00b7me", ",", "uns", "so", "gro\u00df", "und", "theu\u00b7er", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Strahlt nicht in kunstgemaltem Feuer.", "tokens": ["Strahlt", "nicht", "in", "kunst\u00b7ge\u00b7mal\u00b7tem", "Feu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hier brennt es! Hier! \u2013 und das ist mehr.", "tokens": ["Hier", "brennt", "es", "!", "Hier", "!", "\u2013", "und", "das", "ist", "mehr", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "ADV", "$.", "$(", "KON", "PDS", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wenn der Kanonen Donner schweigen,", "tokens": ["Wenn", "der", "Ka\u00b7no\u00b7nen", "Don\u00b7ner", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn der Erleuchtung tausendfacher Strahl", "tokens": ["Wenn", "der", "Er\u00b7leuch\u00b7tung", "tau\u00b7send\u00b7fa\u00b7cher", "Strahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verlischt, so m\u00fcssen \u00fcberall", "tokens": ["Ver\u00b7lischt", ",", "so", "m\u00fcs\u00b7sen", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "VMFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Volkes Herzen lauter zeugen,", "tokens": ["Des", "Vol\u00b7kes", "Her\u00b7zen", "lau\u00b7ter", "zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df Lieb' und Dank und Biedertreu'", "tokens": ["Da\u00df", "Lieb'", "und", "Dank", "und", "Bie\u00b7der\u00b7treu'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mehr als ein Festtagsjubel sei.", "tokens": ["Mehr", "als", "ein", "Fest\u00b7tags\u00b7ju\u00b7bel", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wer blickt herab \u2013 herauf auf unsre B\u00fchne?", "tokens": ["Wer", "blickt", "her\u00b7ab", "\u2013", "her\u00b7auf", "auf", "uns\u00b7re", "B\u00fch\u00b7ne", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "$(", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wo ist der Patriot, dem nicht", "tokens": ["Wo", "ist", "der", "Pat\u00b7ri\u00b7ot", ",", "dem", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "PRELS", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Hochgedanke Carl aus jeder Miene", "tokens": ["Der", "Hoch\u00b7ge\u00b7dan\u00b7ke", "Carl", "aus", "je\u00b7der", "Mie\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie Sonnenglanz aus leichten Wolken bricht?", "tokens": ["Wie", "Son\u00b7nen\u00b7glanz", "aus", "leich\u00b7ten", "Wol\u00b7ken", "bricht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wer denkt nicht heut den milden Strom der Gnade,", "tokens": ["Wer", "denkt", "nicht", "heut", "den", "mil\u00b7den", "Strom", "der", "Gna\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der sich vom Stuhle Carls auf unser Land ergo\u00df \u2013", "tokens": ["Der", "sich", "vom", "Stuh\u00b7le", "Carls", "auf", "un\u00b7ser", "Land", "er\u00b7go\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPRART", "NN", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nicht seine Huld, die mild", "tokens": ["Nicht", "sei\u00b7ne", "Huld", ",", "die", "mild"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PTKNEG", "PPOSAT", "NN", "$,", "PRELS", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Wie Licht auf unsre Pfade,", "tokens": ["Wie", "Licht", "auf", "uns\u00b7re", "Pfa\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Wohlth\u00e4tig auf uns niederflo\u00df?", "tokens": ["Wohlt\u00b7h\u00e4\u00b7tig", "auf", "uns", "nie\u00b7der\u00b7flo\u00df", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sprich du, sein Volk, zu welchem Stande", "tokens": ["Sprich", "du", ",", "sein", "Volk", ",", "zu", "wel\u00b7chem", "Stan\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "$,", "PPOSAT", "NN", "$,", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Hat diese Huld sich nicht herabgeneigt?", "tokens": ["Hat", "die\u00b7se", "Huld", "sich", "nicht", "her\u00b7ab\u00b7ge\u00b7neigt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "PRF", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Der Gro\u00df' und Kleine in dem Lande,", "tokens": ["Der", "Gro\u00df'", "und", "Klei\u00b7ne", "in", "dem", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJA", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Der Arme, wie der Reiche, zeugt. \u2013", "tokens": ["Der", "Ar\u00b7me", ",", "wie", "der", "Rei\u00b7che", ",", "zeugt", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "NE", "$,", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Als j\u00fcngst der Wintergott mit f\u00fcrchterlicher Strenge", "tokens": ["Als", "j\u00fcngst", "der", "Win\u00b7ter\u00b7gott", "mit", "f\u00fcrch\u00b7ter\u00b7li\u00b7cher", "Stren\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Durch Deutschlands Zonen grimmig fuhr,", "tokens": ["Durch", "Deutschlands", "Zo\u00b7nen", "grim\u00b7mig", "fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Da lag sie wie erstarrt, die \u00e4chzende Natur.", "tokens": ["Da", "lag", "sie", "wie", "er\u00b7starrt", ",", "die", "\u00e4ch\u00b7zen\u00b7de", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOKOM", "VVPP", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Es kamen D\u00fcrftige in wimmelndem Gedr\u00e4nge", "tokens": ["Es", "ka\u00b7men", "D\u00fcrf\u00b7ti\u00b7ge", "in", "wim\u00b7meln\u00b7dem", "Ge\u00b7dr\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und schrieen Hilfe! Carl, an Vatermilde reich,", "tokens": ["Und", "schri\u00b7een", "Hil\u00b7fe", "!", "Carl", ",", "an", "Va\u00b7ter\u00b7mil\u00b7de", "reich", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$.", "NE", "$,", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sprach: Kommt, ihr D\u00fcrftigen, erquickt und w\u00e4rmet euch! \u2013", "tokens": ["Sprach", ":", "Kommt", ",", "ihr", "D\u00fcrf\u00b7ti\u00b7gen", ",", "er\u00b7quickt", "und", "w\u00e4r\u00b7met", "euch", "!", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "VVFIN", "$,", "PPOSAT", "NN", "$,", "VVPP", "KON", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Doch Thaten, die zum Himmel aufgeflogen,", "tokens": ["Doch", "Tha\u00b7ten", ",", "die", "zum", "Him\u00b7mel", "auf\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Vom Thatensch\u00e4tzer schon gewogen", "tokens": ["Vom", "Tha\u00b7ten\u00b7sch\u00e4t\u00b7zer", "schon", "ge\u00b7wo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Mit ihres Lohnes Schwergewicht,", "tokens": ["Mit", "ih\u00b7res", "Loh\u00b7nes", "Schwer\u00b7ge\u00b7wicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Entweiht ein menschliches Gedicht.", "tokens": ["Ent\u00b7weiht", "ein", "menschli\u00b7ches", "Ge\u00b7dicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "Ich schweige. Aber Wunsch des Volkes, du hast Fl\u00fcgel,", "tokens": ["Ich", "schwei\u00b7ge", ".", "A\u00b7ber", "Wunsch", "des", "Vol\u00b7kes", ",", "du", "hast", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "KON", "NN", "ART", "NN", "$,", "PPER", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Drum eile \u00fcber Fl\u00fcsse, Thal und H\u00fcgel", "tokens": ["Drum", "ei\u00b7le", "\u00fc\u00b7ber", "Fl\u00fcs\u00b7se", ",", "Thal", "und", "H\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVFIN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dem fernen Landesvater nach,", "tokens": ["Dem", "fer\u00b7nen", "Lan\u00b7des\u00b7va\u00b7ter", "nach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sag' ihm, was der Geist von seinem Volke sprach:", "tokens": ["Und", "sag'", "ihm", ",", "was", "der", "Geist", "von", "sei\u00b7nem", "Vol\u00b7ke", "sprach", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PRELS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bereis', o CARL, die fernsten Lande,", "tokens": ["Be\u00b7reis'", ",", "o", "CaRL", ",", "die", "ferns\u00b7ten", "Lan\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "FM", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Such' V\u00f6lker an des Meeres Strande", "tokens": ["Such'", "V\u00f6l\u00b7ker", "an", "des", "Mee\u00b7res", "Stran\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und pr\u00fcf' als Menschenforscher sie \u2013", "tokens": ["Und", "pr\u00fcf'", "als", "Men\u00b7schen\u00b7for\u00b7scher", "sie", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOUS", "NN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch V\u00f6lker, die mit unserm Glutverlangen,", "tokens": ["Doch", "V\u00f6l\u00b7ker", ",", "die", "mit", "un\u00b7serm", "Glut\u00b7ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Mit unsrer Lieb' und Treu' an ihrem F\u00fcrsten hangen,", "tokens": ["Mit", "uns\u00b7rer", "Lieb'", "und", "Treu'", "an", "ih\u00b7rem", "F\u00fcrs\u00b7ten", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Verzeih', o Carl, die findst du nie! \u2013", "tokens": ["Ver\u00b7zeih'", ",", "o", "Carl", ",", "die", "findst", "du", "nie", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKVZ", "$,", "FM", "NE", "$,", "PRELS", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Der Vorhang falle nicht, ihr G\u00f6nner unsers Spiels,", "tokens": ["Der", "Vor\u00b7hang", "fal\u00b7le", "nicht", ",", "ihr", "G\u00f6n\u00b7ner", "un\u00b7sers", "Spiels", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "$,", "PPOSAT", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bis ich im Drange des Gef\u00fchls", "tokens": ["Bis", "ich", "im", "Dran\u00b7ge", "des", "Ge\u00b7f\u00fchls"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "An CARLS gefei'rtem Lebenstage", "tokens": ["An", "CaRLS", "ge\u00b7fei'r\u00b7tem", "Le\u00b7bens\u00b7ta\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zwei Worte noch zu sagen wage.", "tokens": ["Zwei", "Wor\u00b7te", "noch", "zu", "sa\u00b7gen", "wa\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Kein Festtagspomp strahlt um uns her.", "tokens": ["Kein", "Fest\u00b7tags\u00b7pomp", "strahlt", "um", "uns", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "CaRLS Name, uns so gro\u00df und theuer,", "tokens": ["CaRLS", "Na\u00b7me", ",", "uns", "so", "gro\u00df", "und", "theu\u00b7er", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Strahlt nicht in kunstgemaltem Feuer.", "tokens": ["Strahlt", "nicht", "in", "kunst\u00b7ge\u00b7mal\u00b7tem", "Feu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hier brennt es! Hier! \u2013 und das ist mehr.", "tokens": ["Hier", "brennt", "es", "!", "Hier", "!", "\u2013", "und", "das", "ist", "mehr", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "ADV", "$.", "$(", "KON", "PDS", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wenn der Kanonen Donner schweigen,", "tokens": ["Wenn", "der", "Ka\u00b7no\u00b7nen", "Don\u00b7ner", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn der Erleuchtung tausendfacher Strahl", "tokens": ["Wenn", "der", "Er\u00b7leuch\u00b7tung", "tau\u00b7send\u00b7fa\u00b7cher", "Strahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verlischt, so m\u00fcssen \u00fcberall", "tokens": ["Ver\u00b7lischt", ",", "so", "m\u00fcs\u00b7sen", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "VMFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Volkes Herzen lauter zeugen,", "tokens": ["Des", "Vol\u00b7kes", "Her\u00b7zen", "lau\u00b7ter", "zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df Lieb' und Dank und Biedertreu'", "tokens": ["Da\u00df", "Lieb'", "und", "Dank", "und", "Bie\u00b7der\u00b7treu'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mehr als ein Festtagsjubel sei.", "tokens": ["Mehr", "als", "ein", "Fest\u00b7tags\u00b7ju\u00b7bel", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Wer blickt herab \u2013 herauf auf unsre B\u00fchne?", "tokens": ["Wer", "blickt", "her\u00b7ab", "\u2013", "her\u00b7auf", "auf", "uns\u00b7re", "B\u00fch\u00b7ne", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "$(", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wo ist der Patriot, dem nicht", "tokens": ["Wo", "ist", "der", "Pat\u00b7ri\u00b7ot", ",", "dem", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "PRELS", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Hochgedanke Carl aus jeder Miene", "tokens": ["Der", "Hoch\u00b7ge\u00b7dan\u00b7ke", "Carl", "aus", "je\u00b7der", "Mie\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie Sonnenglanz aus leichten Wolken bricht?", "tokens": ["Wie", "Son\u00b7nen\u00b7glanz", "aus", "leich\u00b7ten", "Wol\u00b7ken", "bricht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wer denkt nicht heut den milden Strom der Gnade,", "tokens": ["Wer", "denkt", "nicht", "heut", "den", "mil\u00b7den", "Strom", "der", "Gna\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der sich vom Stuhle Carls auf unser Land ergo\u00df \u2013", "tokens": ["Der", "sich", "vom", "Stuh\u00b7le", "Carls", "auf", "un\u00b7ser", "Land", "er\u00b7go\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPRART", "NN", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nicht seine Huld, die mild", "tokens": ["Nicht", "sei\u00b7ne", "Huld", ",", "die", "mild"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PTKNEG", "PPOSAT", "NN", "$,", "PRELS", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Wie Licht auf unsre Pfade,", "tokens": ["Wie", "Licht", "auf", "uns\u00b7re", "Pfa\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Wohlth\u00e4tig auf uns niederflo\u00df?", "tokens": ["Wohlt\u00b7h\u00e4\u00b7tig", "auf", "uns", "nie\u00b7der\u00b7flo\u00df", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sprich du, sein Volk, zu welchem Stande", "tokens": ["Sprich", "du", ",", "sein", "Volk", ",", "zu", "wel\u00b7chem", "Stan\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "$,", "PPOSAT", "NN", "$,", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Hat diese Huld sich nicht herabgeneigt?", "tokens": ["Hat", "die\u00b7se", "Huld", "sich", "nicht", "her\u00b7ab\u00b7ge\u00b7neigt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "PRF", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Der Gro\u00df' und Kleine in dem Lande,", "tokens": ["Der", "Gro\u00df'", "und", "Klei\u00b7ne", "in", "dem", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJA", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Der Arme, wie der Reiche, zeugt. \u2013", "tokens": ["Der", "Ar\u00b7me", ",", "wie", "der", "Rei\u00b7che", ",", "zeugt", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "NE", "$,", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Als j\u00fcngst der Wintergott mit f\u00fcrchterlicher Strenge", "tokens": ["Als", "j\u00fcngst", "der", "Win\u00b7ter\u00b7gott", "mit", "f\u00fcrch\u00b7ter\u00b7li\u00b7cher", "Stren\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Durch Deutschlands Zonen grimmig fuhr,", "tokens": ["Durch", "Deutschlands", "Zo\u00b7nen", "grim\u00b7mig", "fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Da lag sie wie erstarrt, die \u00e4chzende Natur.", "tokens": ["Da", "lag", "sie", "wie", "er\u00b7starrt", ",", "die", "\u00e4ch\u00b7zen\u00b7de", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOKOM", "VVPP", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Es kamen D\u00fcrftige in wimmelndem Gedr\u00e4nge", "tokens": ["Es", "ka\u00b7men", "D\u00fcrf\u00b7ti\u00b7ge", "in", "wim\u00b7meln\u00b7dem", "Ge\u00b7dr\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und schrieen Hilfe! Carl, an Vatermilde reich,", "tokens": ["Und", "schri\u00b7een", "Hil\u00b7fe", "!", "Carl", ",", "an", "Va\u00b7ter\u00b7mil\u00b7de", "reich", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$.", "NE", "$,", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sprach: Kommt, ihr D\u00fcrftigen, erquickt und w\u00e4rmet euch! \u2013", "tokens": ["Sprach", ":", "Kommt", ",", "ihr", "D\u00fcrf\u00b7ti\u00b7gen", ",", "er\u00b7quickt", "und", "w\u00e4r\u00b7met", "euch", "!", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "VVFIN", "$,", "PPOSAT", "NN", "$,", "VVPP", "KON", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Doch Thaten, die zum Himmel aufgeflogen,", "tokens": ["Doch", "Tha\u00b7ten", ",", "die", "zum", "Him\u00b7mel", "auf\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Vom Thatensch\u00e4tzer schon gewogen", "tokens": ["Vom", "Tha\u00b7ten\u00b7sch\u00e4t\u00b7zer", "schon", "ge\u00b7wo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Mit ihres Lohnes Schwergewicht,", "tokens": ["Mit", "ih\u00b7res", "Loh\u00b7nes", "Schwer\u00b7ge\u00b7wicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Entweiht ein menschliches Gedicht.", "tokens": ["Ent\u00b7weiht", "ein", "menschli\u00b7ches", "Ge\u00b7dicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.10": {"line.1": {"text": "Ich schweige. Aber Wunsch des Volkes, du hast Fl\u00fcgel,", "tokens": ["Ich", "schwei\u00b7ge", ".", "A\u00b7ber", "Wunsch", "des", "Vol\u00b7kes", ",", "du", "hast", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "KON", "NN", "ART", "NN", "$,", "PPER", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Drum eile \u00fcber Fl\u00fcsse, Thal und H\u00fcgel", "tokens": ["Drum", "ei\u00b7le", "\u00fc\u00b7ber", "Fl\u00fcs\u00b7se", ",", "Thal", "und", "H\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVFIN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dem fernen Landesvater nach,", "tokens": ["Dem", "fer\u00b7nen", "Lan\u00b7des\u00b7va\u00b7ter", "nach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sag' ihm, was der Geist von seinem Volke sprach:", "tokens": ["Und", "sag'", "ihm", ",", "was", "der", "Geist", "von", "sei\u00b7nem", "Vol\u00b7ke", "sprach", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PRELS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bereis', o CARL, die fernsten Lande,", "tokens": ["Be\u00b7reis'", ",", "o", "CaRL", ",", "die", "ferns\u00b7ten", "Lan\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "FM", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Such' V\u00f6lker an des Meeres Strande", "tokens": ["Such'", "V\u00f6l\u00b7ker", "an", "des", "Mee\u00b7res", "Stran\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und pr\u00fcf' als Menschenforscher sie \u2013", "tokens": ["Und", "pr\u00fcf'", "als", "Men\u00b7schen\u00b7for\u00b7scher", "sie", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOUS", "NN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch V\u00f6lker, die mit unserm Glutverlangen,", "tokens": ["Doch", "V\u00f6l\u00b7ker", ",", "die", "mit", "un\u00b7serm", "Glut\u00b7ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Mit unsrer Lieb' und Treu' an ihrem F\u00fcrsten hangen,", "tokens": ["Mit", "uns\u00b7rer", "Lieb'", "und", "Treu'", "an", "ih\u00b7rem", "F\u00fcrs\u00b7ten", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Verzeih', o Carl, die findst du nie! \u2013", "tokens": ["Ver\u00b7zeih'", ",", "o", "Carl", ",", "die", "findst", "du", "nie", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKVZ", "$,", "FM", "NE", "$,", "PRELS", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}