{"textgrid.poem.52069": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "50.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ist was nicht deutsch und nicht verst\u00e4ndlich etwan hier,", "tokens": ["Ist", "was", "nicht", "deutsch", "und", "nicht", "ver\u00b7st\u00e4nd\u00b7lich", "et\u00b7wan", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PWS", "PTKNEG", "ADJD", "KON", "PTKNEG", "ADJD", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein Leser, oder bin ich gar zu derb an Worten,", "tokens": ["Mein", "Le\u00b7ser", ",", "o\u00b7der", "bin", "ich", "gar", "zu", "derb", "an", "Wor\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und treffe deine Stirn und Art an meisten Orten,", "tokens": ["Und", "tref\u00b7fe", "dei\u00b7ne", "Stirn", "und", "Art", "an", "meis\u00b7ten", "Or\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "KON", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wirff alle Schuld auff dich und nicht auff mein Papier.", "tokens": ["Wirff", "al\u00b7le", "Schuld", "auff", "dich", "und", "nicht", "auff", "mein", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "APPR", "PPER", "KON", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Sein Leben giebt mir ja die Schelt Wort an die Hand,", "tokens": ["Sein", "Le\u00b7ben", "giebt", "mir", "ja", "die", "Schelt", "Wort", "an", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und k\u00f6nnt ich von Natur und Art nicht Verse schreiben,", "tokens": ["Und", "k\u00f6nnt", "ich", "von", "Na\u00b7tur", "und", "Art", "nicht", "Ver\u00b7se", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "PTKNEG", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Eifer w\u00fcrde sie dir in die Nasen reiben,", "tokens": ["Der", "Ei\u00b7fer", "w\u00fcr\u00b7de", "sie", "dir", "in", "die", "Na\u00b7sen", "rei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den ich empfind, alsbald ich deine S\u00fcnd' erkannt.", "tokens": ["Den", "ich", "emp\u00b7find", ",", "als\u00b7bald", "ich", "dei\u00b7ne", "S\u00fcnd'", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dich kenn ich nicht, doch treff' ich deine Laster an,", "tokens": ["Dich", "kenn", "ich", "nicht", ",", "doch", "treff'", "ich", "dei\u00b7ne", "Las\u00b7ter", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So bist du mir vielmehr als dir bekannt gewesen,", "tokens": ["So", "bist", "du", "mir", "viel\u00b7mehr", "als", "dir", "be\u00b7kannt", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADV", "KOUS", "PPER", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ob ich dich nicht gesehn, kanst du dich hier schon lesen,", "tokens": ["Ob", "ich", "dich", "nicht", "ge\u00b7sehn", ",", "kanst", "du", "dich", "hier", "schon", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVPP", "$,", "VMFIN", "PPER", "PRF", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zuf\u00f6rderst wer du bist, und dann, was du gethan.", "tokens": ["Zu\u00b7f\u00f6r\u00b7derst", "wer", "du", "bist", ",", "und", "dann", ",", "was", "du", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PPER", "VAFIN", "$,", "KON", "ADV", "$,", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wiltu zum Richter gehn? Halt an, der Tag ist da,", "tokens": ["Wil\u00b7tu", "zum", "Rich\u00b7ter", "gehn", "?", "Halt", "an", ",", "der", "Tag", "ist", "da", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "VVINF", "$.", "NN", "PTKVZ", "$,", "ART", "NN", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dann wo du zornig bist, hat dich, wie ich kan schlie\u00dfen,", "tokens": ["Dann", "wo", "du", "zor\u00b7nig", "bist", ",", "hat", "dich", ",", "wie", "ich", "kan", "schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "PPER", "ADJD", "VAFIN", "$,", "VAFIN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein Argwohn sch\u00f6n verdammt! Durch wen? Durch dein Gewi\u00dfen,", "tokens": ["Dein", "Arg\u00b7wohn", "sch\u00f6n", "ver\u00b7dammt", "!", "Durch", "wen", "?", "Durch", "dein", "Ge\u00b7wi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "VVPP", "$.", "APPR", "PWS", "$.", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Vernein es, wie du wilt, es spricht doch allzeit: Ja.", "tokens": ["Ver\u00b7nein", "es", ",", "wie", "du", "wilt", ",", "es", "spricht", "doch", "all\u00b7zeit", ":", "Ja", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$,", "PPER", "VVFIN", "ADV", "ADV", "$.", "PTKANT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ist was nicht deutsch und nicht verst\u00e4ndlich etwan hier,", "tokens": ["Ist", "was", "nicht", "deutsch", "und", "nicht", "ver\u00b7st\u00e4nd\u00b7lich", "et\u00b7wan", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PWS", "PTKNEG", "ADJD", "KON", "PTKNEG", "ADJD", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein Leser, oder bin ich gar zu derb an Worten,", "tokens": ["Mein", "Le\u00b7ser", ",", "o\u00b7der", "bin", "ich", "gar", "zu", "derb", "an", "Wor\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und treffe deine Stirn und Art an meisten Orten,", "tokens": ["Und", "tref\u00b7fe", "dei\u00b7ne", "Stirn", "und", "Art", "an", "meis\u00b7ten", "Or\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "KON", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wirff alle Schuld auff dich und nicht auff mein Papier.", "tokens": ["Wirff", "al\u00b7le", "Schuld", "auff", "dich", "und", "nicht", "auff", "mein", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "APPR", "PPER", "KON", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Sein Leben giebt mir ja die Schelt Wort an die Hand,", "tokens": ["Sein", "Le\u00b7ben", "giebt", "mir", "ja", "die", "Schelt", "Wort", "an", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und k\u00f6nnt ich von Natur und Art nicht Verse schreiben,", "tokens": ["Und", "k\u00f6nnt", "ich", "von", "Na\u00b7tur", "und", "Art", "nicht", "Ver\u00b7se", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "PTKNEG", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Eifer w\u00fcrde sie dir in die Nasen reiben,", "tokens": ["Der", "Ei\u00b7fer", "w\u00fcr\u00b7de", "sie", "dir", "in", "die", "Na\u00b7sen", "rei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den ich empfind, alsbald ich deine S\u00fcnd' erkannt.", "tokens": ["Den", "ich", "emp\u00b7find", ",", "als\u00b7bald", "ich", "dei\u00b7ne", "S\u00fcnd'", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Dich kenn ich nicht, doch treff' ich deine Laster an,", "tokens": ["Dich", "kenn", "ich", "nicht", ",", "doch", "treff'", "ich", "dei\u00b7ne", "Las\u00b7ter", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So bist du mir vielmehr als dir bekannt gewesen,", "tokens": ["So", "bist", "du", "mir", "viel\u00b7mehr", "als", "dir", "be\u00b7kannt", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADV", "KOUS", "PPER", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ob ich dich nicht gesehn, kanst du dich hier schon lesen,", "tokens": ["Ob", "ich", "dich", "nicht", "ge\u00b7sehn", ",", "kanst", "du", "dich", "hier", "schon", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVPP", "$,", "VMFIN", "PPER", "PRF", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zuf\u00f6rderst wer du bist, und dann, was du gethan.", "tokens": ["Zu\u00b7f\u00f6r\u00b7derst", "wer", "du", "bist", ",", "und", "dann", ",", "was", "du", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PPER", "VAFIN", "$,", "KON", "ADV", "$,", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Wiltu zum Richter gehn? Halt an, der Tag ist da,", "tokens": ["Wil\u00b7tu", "zum", "Rich\u00b7ter", "gehn", "?", "Halt", "an", ",", "der", "Tag", "ist", "da", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "VVINF", "$.", "NN", "PTKVZ", "$,", "ART", "NN", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dann wo du zornig bist, hat dich, wie ich kan schlie\u00dfen,", "tokens": ["Dann", "wo", "du", "zor\u00b7nig", "bist", ",", "hat", "dich", ",", "wie", "ich", "kan", "schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "PPER", "ADJD", "VAFIN", "$,", "VAFIN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein Argwohn sch\u00f6n verdammt! Durch wen? Durch dein Gewi\u00dfen,", "tokens": ["Dein", "Arg\u00b7wohn", "sch\u00f6n", "ver\u00b7dammt", "!", "Durch", "wen", "?", "Durch", "dein", "Ge\u00b7wi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "VVPP", "$.", "APPR", "PWS", "$.", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Vernein es, wie du wilt, es spricht doch allzeit: Ja.", "tokens": ["Ver\u00b7nein", "es", ",", "wie", "du", "wilt", ",", "es", "spricht", "doch", "all\u00b7zeit", ":", "Ja", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$,", "PPER", "VVFIN", "ADV", "ADV", "$.", "PTKANT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}