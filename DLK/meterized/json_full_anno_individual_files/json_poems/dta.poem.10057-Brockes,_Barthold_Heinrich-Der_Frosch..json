{"dta.poem.10057": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Der Frosch.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Nachdem ich j\u00fcngst zur holden Fr\u00fchlings-Zeit,", "tokens": ["Nach\u00b7dem", "ich", "j\u00fcngst", "zur", "hol\u00b7den", "Fr\u00fch\u00b7lings\u00b7Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Auf einer Wiese mich befand,", "tokens": ["Auf", "ei\u00b7ner", "Wie\u00b7se", "mich", "be\u00b7fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nah\u2019 an einem Graben stand,", "tokens": ["Und", "nah'", "an", "ei\u00b7nem", "Gra\u00b7ben", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bewundert\u2019 ich des Wassers Reinigkeit.", "tokens": ["Be\u00b7wun\u00b7dert'", "ich", "des", "Was\u00b7sers", "Rei\u00b7nig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Des tieffen Grabens klar-nunmehr enteis\u2019tes Ra\u00df", "tokens": ["Des", "tief\u00b7fen", "Gra\u00b7bens", "kla\u00b7rnun\u00b7mehr", "ent\u00b7eis'\u00b7tes", "Ra\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Stand rings umher mit Gras und Klee bekr\u00e4ntzet,", "tokens": ["Stand", "rings", "um\u00b7her", "mit", "Gras", "und", "Klee", "be\u00b7kr\u00b7\u00e4nt\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKVZ", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Durch dessen gr\u00fcnen Schein es nicht nur lieblich gl\u00e4ntzet;", "tokens": ["Durch", "des\u00b7sen", "gr\u00fc\u00b7nen", "Schein", "es", "nicht", "nur", "lieb\u00b7lich", "gl\u00e4nt\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "ADJA", "NN", "PPER", "PTKNEG", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Es war durchsichtig, wie ein Glas:", "tokens": ["Es", "war", "durch\u00b7sich\u00b7tig", ",", "wie", "ein", "Glas", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So da\u00df mein Blick in dieses Grabens Tieffe", "tokens": ["So", "da\u00df", "mein", "Blick", "in", "die\u00b7ses", "Gra\u00b7bens", "Tief\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPOSAT", "NN", "APPR", "PDAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Gantz ungehemmet sanck, und, recht als wenn er leer,", "tokens": ["Gantz", "un\u00b7ge\u00b7hem\u00b7met", "san\u00b7ck", ",", "und", ",", "recht", "als", "wenn", "er", "leer", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$,", "KON", "$,", "ADJD", "KOKOM", "KOUS", "PPER", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Und gar kein Wasser drinnen w\u00e4r\u2019,", "tokens": ["Und", "gar", "kein", "Was\u00b7ser", "drin\u00b7nen", "w\u00e4r'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Mit Anmuth hin und wieder lieffe,", "tokens": ["Mit", "An\u00b7muth", "hin", "und", "wie\u00b7der", "lief\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "KON", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Bald bunte glatte Stein\u2019 auf weissem Sand\u2019 entdeckte,", "tokens": ["Bald", "bun\u00b7te", "glat\u00b7te", "Stein'", "auf", "weis\u00b7sem", "Sand'", "ent\u00b7deck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Bald junges Kraut, das hie und da", "tokens": ["Bald", "jun\u00b7ges", "Kraut", ",", "das", "hie", "und", "da"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "$,", "PRELS", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Die zarten Spitzen aufw\u00e4rts streckte,", "tokens": ["Die", "zar\u00b7ten", "Spit\u00b7zen", "auf\u00b7w\u00e4rts", "streck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Nebst gr\u00fcnen Moo\u00df und frischen Binsen sah.", "tokens": ["Nebst", "gr\u00fc\u00b7nen", "Moo\u00df", "und", "fri\u00b7schen", "Bin\u00b7sen", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Indem ich nun dadurch ger\u00fchret, stand,", "tokens": ["In\u00b7dem", "ich", "nun", "da\u00b7durch", "ge\u00b7r\u00fch\u00b7ret", ",", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PAV", "VVPP", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und von der Fr\u00fchlings-Pracht ein inniges Vergn\u00fcgen", "tokens": ["Und", "von", "der", "Fr\u00fch\u00b7lings\u00b7Pracht", "ein", "in\u00b7ni\u00b7ges", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auf dieser glatten Fluth empfand;", "tokens": ["Auf", "die\u00b7ser", "glat\u00b7ten", "Fluth", "emp\u00b7fand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sah ich ein halb geformt, halb Form-los Etwas liegen,", "tokens": ["Sah", "ich", "ein", "halb", "ge\u00b7formt", ",", "halb", "For\u00b7mlos", "Et\u00b7was", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJD", "VVPP", "$,", "ADJD", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das einem grauen Stein, an Farb\u2019 und Bildung, glich.", "tokens": ["Das", "ei\u00b7nem", "grau\u00b7en", "Stein", ",", "an", "Fa\u00b7rb'", "und", "Bil\u00b7dung", ",", "glich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "$,", "APPR", "NN", "KON", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Kaum da\u00df ich ihn mit Ernst und Flei\u00df besehe,", "tokens": ["Kaum", "da\u00df", "ich", "ihn", "mit", "Ernst", "und", "Flei\u00df", "be\u00b7se\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PPER", "APPR", "NE", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "F\u00e4ngt der vermeinte Stein sich an zu regen,", "tokens": ["F\u00e4ngt", "der", "ver\u00b7mein\u00b7te", "Stein", "sich", "an", "zu", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PRF", "APPR", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Begiebt sich allgemach, doch langsam, in die H\u00f6he", "tokens": ["Be\u00b7giebt", "sich", "all\u00b7ge\u00b7mach", ",", "doch", "lang\u00b7sam", ",", "in", "die", "H\u00f6\u00b7he"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "$,", "ADV", "ADJD", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und kommt, mit wenigem Bewegen,", "tokens": ["Und", "kommt", ",", "mit", "we\u00b7ni\u00b7gem", "Be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ein Frosch bis auf des Wassers Fl\u00e4che.", "tokens": ["Ein", "Frosch", "bis", "auf", "des", "Was\u00b7sers", "Fl\u00e4\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Hier schien er, f\u00fcr das helle Licht", "tokens": ["Hier", "schien", "er", ",", "f\u00fcr", "das", "hel\u00b7le", "Licht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und aller Fr\u00fchlings-Pracht, zu stutzen,", "tokens": ["Und", "al\u00b7ler", "Fr\u00fch\u00b7lings\u00b7Pracht", ",", "zu", "stut\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Lag gleichsam gantz erstarrt, und r\u00fchrete sich nicht.", "tokens": ["Lag", "gleich\u00b7sam", "gantz", "er\u00b7starrt", ",", "und", "r\u00fch\u00b7re\u00b7te", "sich", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ADV", "VVPP", "$,", "KON", "VVFIN", "PRF", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch fieng er endlich an sein bl\u00f6d Gesicht", "tokens": ["Doch", "fi\u00b7eng", "er", "end\u00b7lich", "an", "sein", "bl\u00f6d", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Mit seiner kleinen Hand zu wischen und zu putzen,", "tokens": ["Mit", "sei\u00b7ner", "klei\u00b7nen", "Hand", "zu", "wi\u00b7schen", "und", "zu", "put\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Stutzt abermahl, und bliebe, lange Zeit,", "tokens": ["Stutzt", "a\u00b7ber\u00b7mahl", ",", "und", "blie\u00b7be", ",", "lan\u00b7ge", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KON", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Vermuthlich \u00fcberh\u00e4ufft von so viel Herrlichkeit", "tokens": ["Ver\u00b7muth\u00b7lich", "\u00fc\u00b7berh\u00b7\u00e4ufft", "von", "so", "viel", "Herr\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und gantz erstannet f\u00fcr Vergn\u00fcgen,", "tokens": ["Und", "gantz", "er\u00b7stan\u00b7net", "f\u00fcr", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "In seiner ersten Lage liegen.", "tokens": ["In", "sei\u00b7ner", "ers\u00b7ten", "La\u00b7ge", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Zuletzt gab er, mit fr\u00f6hlichem Geschrey,", "tokens": ["Zu\u00b7letzt", "gab", "er", ",", "mit", "fr\u00f6h\u00b7li\u00b7chem", "Ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Wie sehr er durch die Welt, da sie so Wunder-sch\u00f6n,", "tokens": ["Wie", "sehr", "er", "durch", "die", "Welt", ",", "da", "sie", "so", "Wun\u00b7der\u00b7sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "ART", "NN", "$,", "KOUS", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ergetzet und ger\u00fchret sey,", "tokens": ["Er\u00b7get\u00b7zet", "und", "ge\u00b7r\u00fch\u00b7ret", "sey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Mit lautem quacken zu verstehn.", "tokens": ["Mit", "lau\u00b7tem", "qua\u00b7cken", "zu", "ver\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich sahe die\u00df bewundernd an, und sprach:", "tokens": ["Ich", "sa\u00b7he", "die\u00df", "be\u00b7wun\u00b7dernd", "an", ",", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ach! folgten wir auch deinen Beyspiel nach,", "tokens": ["Ach", "!", "folg\u00b7ten", "wir", "auch", "dei\u00b7nen", "Bey\u00b7spiel", "nach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vom Schlaf erwachter Frosch! ach m\u00f6gten wir", "tokens": ["Vom", "Schlaf", "er\u00b7wach\u00b7ter", "Frosch", "!", "ach", "m\u00f6g\u00b7ten", "wir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJA", "NN", "$.", "XY", "VMFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Nach dunckler Winter-Nacht, an allen Fr\u00fchlings-Sch\u00e4tzen,", "tokens": ["Nach", "dunck\u00b7ler", "Win\u00b7ter\u00b7Nacht", ",", "an", "al\u00b7len", "Fr\u00fch\u00b7lings\u00b7Sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "An aller Creaturen Zier,", "tokens": ["An", "al\u00b7ler", "Crea\u00b7tu\u00b7ren", "Zier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "So, wie du thust, uns auch ergetzen!", "tokens": ["So", ",", "wie", "du", "thust", ",", "uns", "auch", "er\u00b7get\u00b7zen", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "VVFIN", "$,", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ach liessen wir doch Dem, Der alles schuff, zu Ehren,", "tokens": ["Ach", "lies\u00b7sen", "wir", "doch", "Dem", ",", "Der", "al\u00b7les", "schuff", ",", "zu", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "ADV", "PDS", "$,", "ART", "PIS", "ADJD", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auch manches frohe Danck-Lied h\u00f6ren!", "tokens": ["Auch", "man\u00b7ches", "fro\u00b7he", "Dan\u00b7ck\u00b7Lied", "h\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "So dacht und w\u00fcnscht ich noch, als auf einmahl", "tokens": ["So", "dacht", "und", "w\u00fcnscht", "ich", "noch", ",", "als", "auf", "ein\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$,", "KOUS", "APPR", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein neues Licht, mit einem schnellen Strahl,", "tokens": ["Ein", "neu\u00b7es", "Licht", ",", "mit", "ei\u00b7nem", "schnel\u00b7len", "Strahl", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mir in die Seele drang. In einer Dunckelheit", "tokens": ["Mir", "in", "die", "See\u00b7le", "drang", ".", "In", "ei\u00b7ner", "Dun\u00b7ckel\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "$.", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In schlammigtem Morast in einer finstern Tieffe", "tokens": ["In", "schlam\u00b7mig\u00b7tem", "Mo\u00b7rast", "in", "ei\u00b7ner", "fins\u00b7tern", "Tief\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Hat, dacht ich bey mir selbst, der Frosch so lange Zeit", "tokens": ["Hat", ",", "dacht", "ich", "bey", "mir", "selbst", ",", "der", "Frosch", "so", "lan\u00b7ge", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "$,", "VVFIN", "PPER", "APPR", "PPER", "ADV", "$,", "ART", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den gantzen Winter durch, gestecket.", "tokens": ["Den", "gant\u00b7zen", "Win\u00b7ter", "durch", ",", "ge\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wird er nicht gleichsam ietzt als aus dem Grab\u2019 erwecket?", "tokens": ["Wird", "er", "nicht", "gleich\u00b7sam", "ietzt", "als", "aus", "dem", "Grab'", "er\u00b7we\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "ADV", "KOKOM", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ja wahrlich, lieber Frosch, es stellt dein Zustand mir", "tokens": ["Ja", "wahr\u00b7lich", ",", "lie\u00b7ber", "Frosch", ",", "es", "stellt", "dein", "Zu\u00b7stand", "mir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "$,", "ADV", "ADJD", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und allen Menschen insgesammt", "tokens": ["Und", "al\u00b7len", "Men\u00b7schen", "ins\u00b7ge\u00b7sammt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ein Wunder-sch\u00f6n Exempel f\u00fcr.", "tokens": ["Ein", "Wun\u00b7der\u00b7sch\u00f6n", "Ex\u00b7em\u00b7pel", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.6": {"line.1": {"text": "Es wird mein Geist von neuen angeflammt,", "tokens": ["Es", "wird", "mein", "Geist", "von", "neu\u00b7en", "an\u00b7ge\u00b7flammt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "APPR", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Indem er hier den Stand der irdschen Welt,", "tokens": ["In\u00b7dem", "er", "hier", "den", "Stand", "der", "ird\u00b7schen", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Jm Gegenhalt mit der, die uns, nach diesem Leben,", "tokens": ["Jm", "Ge\u00b7gen\u00b7halt", "mit", "der", ",", "die", "uns", ",", "nach", "die\u00b7sem", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "$,", "PRELS", "PPER", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Sch\u00f6pfer wird im ewgen Fr\u00fchling geben,", "tokens": ["Der", "Sch\u00f6p\u00b7fer", "wird", "im", "ew\u00b7gen", "Fr\u00fch\u00b7ling", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Nicht anders sich vor Augen stellt,", "tokens": ["Nicht", "an\u00b7ders", "sich", "vor", "Au\u00b7gen", "stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als deinen Winter-Aufenthalt,", "tokens": ["Als", "dei\u00b7nen", "Win\u00b7ter\u00b7Auf\u00b7ent\u00b7halt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wo alles schlackrig, wiedrig, kalt,", "tokens": ["Wo", "al\u00b7les", "schlack\u00b7rig", ",", "wied\u00b7rig", ",", "kalt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Bedeckt mit D\u00e4mmrung bald, bald dicker Finsterni\u00df,", "tokens": ["Be\u00b7deckt", "mit", "D\u00e4mm\u00b7rung", "bald", ",", "bald", "di\u00b7cker", "Fins\u00b7ter\u00b7ni\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADV", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wo alles unstet, ungewi\u00df,", "tokens": ["Wo", "al\u00b7les", "un\u00b7stet", ",", "un\u00b7ge\u00b7wi\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wo der Gewonheit Schlamm die Augen uns verdeckt,", "tokens": ["Wo", "der", "Ge\u00b7won\u00b7heit", "Schlamm", "die", "Au\u00b7gen", "uns", "ver\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und der Gesch\u00f6pfe Pracht f\u00fcr uns versteckt,", "tokens": ["Und", "der", "Ge\u00b7sch\u00f6p\u00b7fe", "Pracht", "f\u00fcr", "uns", "ver\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Wie wird uns nun, wann wir erblassen,", "tokens": ["Wie", "wird", "uns", "nun", ",", "wann", "wir", "er\u00b7blas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und wir den duncklen Grund verlassen,", "tokens": ["Und", "wir", "den", "dunck\u00b7len", "Grund", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn unser Geist (so, wie du durch die Fluth)", "tokens": ["Wenn", "un\u00b7ser", "Geist", "(", "so", ",", "wie", "du", "durch", "die", "Fluth", ")"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$(", "ADV", "$,", "PWAV", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Sich durch die Lufft erhebt, und aufw\u00e4rts steiget;", "tokens": ["Sich", "durch", "die", "Lufft", "er\u00b7hebt", ",", "und", "auf\u00b7w\u00e4rts", "stei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "VVFIN", "$,", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "In jener Erden Fr\u00fchlings-Schein", "tokens": ["In", "je\u00b7ner", "Er\u00b7den", "Fr\u00fch\u00b7lings\u00b7Schein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und seelger Herrlichkeit zu Muth,", "tokens": ["Und", "seel\u00b7ger", "Herr\u00b7lich\u00b7keit", "zu", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie werden wir erquickt, ja gar entz\u00fccket, seyn!", "tokens": ["Wie", "wer\u00b7den", "wir", "er\u00b7quickt", ",", "ja", "gar", "ent\u00b7z\u00fc\u00b7cket", ",", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "VVPP", "$,", "ADV", "ADV", "VVFIN", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wann wir in den gestirnten H\u00f6hen,", "tokens": ["Wann", "wir", "in", "den", "ge\u00b7stirn\u00b7ten", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "In tausendfach vermehrtem Licht,", "tokens": ["In", "tau\u00b7send\u00b7fach", "ver\u00b7mehr\u00b7tem", "Licht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mit gantz verkl\u00e4rtem Blick, und seeligem Gesicht,", "tokens": ["Mit", "gantz", "ver\u00b7kl\u00e4r\u00b7tem", "Blick", ",", "und", "see\u00b7li\u00b7gem", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Viel tausend tausend Welt\u2019, und tausend Sonnen-Heere,", "tokens": ["Viel", "tau\u00b7send", "tau\u00b7send", "Welt'", ",", "und", "tau\u00b7send", "Son\u00b7nen\u00b7Hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "CARD", "NN", "$,", "KON", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "In einem unumschr\u00e4nckt- und lichten Anmuths-Meere,", "tokens": ["In", "ei\u00b7nem", "un\u00b7um\u00b7schr\u00e4n\u00b7ck\u00b7t", "und", "lich\u00b7ten", "An\u00b7muths\u00b7Mee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.13": {"text": "Wie Inseln herrlich schwimmen sehen!", "tokens": ["Wie", "In\u00b7seln", "herr\u00b7lich", "schwim\u00b7men", "se\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wird nicht ein solcher Wunder-Glantz", "tokens": ["Wird", "nicht", "ein", "sol\u00b7cher", "Wun\u00b7der\u00b7Glantz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So dann in nimmer satten Blicken", "tokens": ["So", "dann", "in", "nim\u00b7mer", "sat\u00b7ten", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ADV", "VVFIN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der frohen Seele Wesen gantz", "tokens": ["Der", "fro\u00b7hen", "See\u00b7le", "We\u00b7sen", "gantz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beseeligen, verhimmeln und entz\u00fccken?", "tokens": ["Be\u00b7see\u00b7li\u00b7gen", ",", "ver\u00b7him\u00b7meln", "und", "ent\u00b7z\u00fc\u00b7cken", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Bis da\u00df die Nacht die Welt in Schatten h\u00fcllt,", "tokens": ["Bis", "da\u00df", "die", "Nacht", "die", "Welt", "in", "Schat\u00b7ten", "h\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "War mein recht inniglich hiedurch ger\u00fchrt Gem\u00fcthe", "tokens": ["War", "mein", "recht", "in\u00b7nig\u00b7lich", "hie\u00b7durch", "ge\u00b7r\u00fchrt", "Ge\u00b7m\u00fc\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADJD", "ADJD", "PAV", "VVPP", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit diesen lehrenden Gedancken angef\u00fcllt.", "tokens": ["Mit", "die\u00b7sen", "leh\u00b7ren\u00b7den", "Ge\u00b7dan\u00b7cken", "an\u00b7ge\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So gar, da\u00df mein sanft wallendes Gebl\u00fcte", "tokens": ["So", "gar", ",", "da\u00df", "mein", "sanft", "wal\u00b7len\u00b7des", "Ge\u00b7bl\u00fc\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPOSAT", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Nachdem ich mich ins Bett gelegt,", "tokens": ["Nach\u00b7dem", "ich", "mich", "ins", "Bett", "ge\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die rege Phantasie bewegt,", "tokens": ["Die", "re\u00b7ge", "Phan\u00b7ta\u00b7sie", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und einen Traum erregt,", "tokens": ["Und", "ei\u00b7nen", "Traum", "er\u00b7regt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Der iedennoch so sonderlich,", "tokens": ["Der", "ie\u00b7den\u00b7noch", "so", "son\u00b7der\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df einem wircklichen Gesicht\u2019 er mehr,", "tokens": ["Da\u00df", "ei\u00b7nem", "wir\u00b7ck\u00b7li\u00b7chen", "Ge\u00b7sicht'", "er", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPER", "ADV", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Als einem leichten Traume, glich.", "tokens": ["Als", "ei\u00b7nem", "leich\u00b7ten", "Trau\u00b7me", ",", "glich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Mich deucht, ich l\u00e4ge kranck, mein Lebens-Oel ver-", "tokens": ["Mich", "deucht", ",", "ich", "l\u00e4\u00b7ge", "kranck", ",", "mein", "Le\u00b7bens\u00b7O\u00b7el", "ver"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADJD", "$,", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mein Hauch w\u00fcrd\u2019 schwer und schwach, blieb\u2019 endlich v\u00f6l-", "tokens": ["Mein", "Hauch", "w\u00fcrd'", "schwer", "und", "schwach", ",", "blieb'", "end\u00b7lich", "v\u00f6l"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,", "VVFIN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der rege Geist verlie\u00df sein lang bewohntes Haus,", "tokens": ["Der", "re\u00b7ge", "Geist", "ver\u00b7lie\u00df", "sein", "lang", "be\u00b7wohn\u00b7tes", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kaum da\u00df derselbe sich von seinem C\u00f6rper wandte,", "tokens": ["Kaum", "da\u00df", "der\u00b7sel\u00b7be", "sich", "von", "sei\u00b7nem", "C\u00f6r\u00b7per", "wand\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PDAT", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als er, nach leichter Blasen Art,", "tokens": ["Als", "er", ",", "nach", "leich\u00b7ter", "Bla\u00b7sen", "Art", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die aus dem Grund\u2019 im Wasser aufw\u00e4rts steigen,", "tokens": ["Die", "aus", "dem", "Grund'", "im", "Was\u00b7ser", "auf\u00b7w\u00e4rts", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "APPRART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Mit einer leicht- nud schnellen Fahrt", "tokens": ["Mit", "ei\u00b7ner", "leicht", "nud", "schnel\u00b7len", "Fahrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sich durch die Fluth der Lufft allm\u00e4hlig h\u00f6her zog,", "tokens": ["Sich", "durch", "die", "Fluth", "der", "Lufft", "all\u00b7m\u00e4h\u00b7lig", "h\u00f6\u00b7her", "zog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "ART", "NN", "ADJD", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und im geraden Strich von unten aufw\u00e4rts flog.", "tokens": ["Und", "im", "ge\u00b7ra\u00b7den", "Strich", "von", "un\u00b7ten", "auf\u00b7w\u00e4rts", "flog", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "NN", "APPR", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Wie er nun auf der Lufft bestrahlte Fl\u00e4che kam,", "tokens": ["Wie", "er", "nun", "auf", "der", "Lufft", "be\u00b7strahl\u00b7te", "Fl\u00e4\u00b7che", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Woselbst voll reiner Heiterkeit,", "tokens": ["Wo\u00b7selbst", "voll", "rei\u00b7ner", "Hei\u00b7ter\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von allen D\u00fcfften leer, von allem Dunst befreyt,", "tokens": ["Von", "al\u00b7len", "D\u00fcff\u00b7ten", "leer", ",", "von", "al\u00b7lem", "Dunst", "be\u00b7freyt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADJD", "$,", "APPR", "PIS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Himmels-Lufft erst ihren Anfang nahm,", "tokens": ["Die", "Him\u00b7mels\u00b7Lufft", "erst", "ih\u00b7ren", "An\u00b7fang", "nahm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Fiel ein gantz ander Licht,", "tokens": ["Fiel", "ein", "gantz", "an\u00b7der", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADV", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Als er allhier gewohnt zu sehn, ihm ins Gesicht.", "tokens": ["Als", "er", "all\u00b7hier", "ge\u00b7wohnt", "zu", "sehn", ",", "ihm", "ins", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "PTKZU", "VVINF", "$,", "PPER", "APPRART", "NN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.12": {"line.1": {"text": "Wie ich nun alles die\u00df, fast, doch nicht gantz geblendet\u2019,", "tokens": ["Wie", "ich", "nun", "al\u00b7les", "die\u00df", ",", "fast", ",", "doch", "nicht", "gantz", "ge\u00b7blen\u00b7det'", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PIS", "PDS", "$,", "ADV", "$,", "ADV", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erstarret \u00fcbersehn, fiel mein ger\u00fchrter Blick", "tokens": ["Er\u00b7star\u00b7ret", "\u00fc\u00b7ber\u00b7sehn", ",", "fiel", "mein", "ge\u00b7r\u00fchr\u00b7ter", "Blick"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "VVINF", "$,", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erstaunet auf mich selbst zur\u00fcck,", "tokens": ["Er\u00b7stau\u00b7net", "auf", "mich", "selbst", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich sah mich durch und durch, mir ward mein wahres", "tokens": ["Ich", "sah", "mich", "durch", "und", "durch", ",", "mir", "ward", "mein", "wah\u00b7res"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "KON", "APPR", "$,", "PPER", "VAFIN", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Nun allererst bekannt: als wie in einer Schrift,", "tokens": ["Nun", "al\u00b7le\u00b7rerst", "be\u00b7kannt", ":", "als", "wie", "in", "ei\u00b7ner", "Schrift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$.", "KOUS", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kunnt\u2019 ich im innersten von meiner Seele lesen", "tokens": ["Kunnt'", "ich", "im", "in\u00b7ners\u00b7ten", "von", "mei\u00b7ner", "See\u00b7le", "le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Das, was ich auf der Welt begangen und gestifft,", "tokens": ["Das", ",", "was", "ich", "auf", "der", "Welt", "be\u00b7gan\u00b7gen", "und", "ge\u00b7stifft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "APPR", "ART", "NN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ja gar was ich gedacht. Kein Spiegel stellt so klar", "tokens": ["Ja", "gar", "was", "ich", "ge\u00b7dacht", ".", "Kein", "Spie\u00b7gel", "stellt", "so", "klar"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "PWS", "PPER", "VVPP", "$.", "PIAT", "NN", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die c\u00f6rperliche Vorw\u00fcrff dar,", "tokens": ["Die", "c\u00f6r\u00b7per\u00b7li\u00b7che", "Vor\u00b7w\u00fcrff", "dar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als ich mir von mir selbst ein heller Spiegel war.", "tokens": ["Als", "ich", "mir", "von", "mir", "selbst", "ein", "hel\u00b7ler", "Spie\u00b7gel", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPER", "ADV", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Was man Gewissen heist", "tokens": ["Was", "man", "Ge\u00b7wis\u00b7sen", "heist"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "PIS", "NN", "VVFIN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.12": {"text": "Ers\u00fcllte meinen gantzen Geist.", "tokens": ["Er\u00b7s\u00fcll\u00b7te", "mei\u00b7nen", "gant\u00b7zen", "Geist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ich fand mich gantz entbl\u00f6sst von Wollust, Ehre, Geld,", "tokens": ["Ich", "fand", "mich", "gantz", "ent\u00b7bl\u00f6sst", "von", "Wol\u00b7lust", ",", "Eh\u00b7re", ",", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "VVFIN", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Als eitlen Zielen dieser Welt.", "tokens": ["Als", "eit\u00b7len", "Zie\u00b7len", "die\u00b7ser", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Nur die Ged\u00e4chtni\u00df meiner Thaten,", "tokens": ["Nur", "die", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", "mei\u00b7ner", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "So wohl die b\u00f6s, als welche gut gerathen,", "tokens": ["So", "wohl", "die", "b\u00f6s", ",", "als", "wel\u00b7che", "gut", "ge\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJD", "$,", "KOUS", "PIS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "War blo\u00df allein", "tokens": ["War", "blo\u00df", "al\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.18": {"text": "Mein gantzes Seyn.", "tokens": ["Mein", "gant\u00b7zes", "Seyn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.13": {"line.1": {"text": "Indem ich auf der Lufft, als einem Wasser, schwam,", "tokens": ["In\u00b7dem", "ich", "auf", "der", "Lufft", ",", "als", "ei\u00b7nem", "Was\u00b7ser", ",", "schwam", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "$,", "KOUS", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kam ich mir anfangs vor", "tokens": ["Kam", "ich", "mir", "an\u00b7fangs", "vor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "PPER", "PPER", "ADV", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Fast wie ein Fr\u00fchlings-Frosch, der  in der Winters-Zeit", "tokens": ["Fast", "wie", "ein", "Fr\u00fch\u00b7lings\u00b7Frosch", ",", "der", "in", "der", "Win\u00b7ter\u00b7sZeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jm Sumpff und im Morast gestecket,", "tokens": ["Jm", "Sumpff", "und", "im", "Mo\u00b7rast", "ge\u00b7ste\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der aber, wie der Fr\u00fchling wieder kam,", "tokens": ["Der", "a\u00b7ber", ",", "wie", "der", "Fr\u00fch\u00b7ling", "wie\u00b7der", "kam", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "PWAV", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Nach dicker Nacht, die Sonn im hellen Glantz entdecket,", "tokens": ["Nach", "di\u00b7cker", "Nacht", ",", "die", "Sonn", "im", "hel\u00b7len", "Glantz", "ent\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ART", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Beschmutzt und sonder Schmuck. Doch eine Reinlichkeit", "tokens": ["Be\u00b7schmutzt", "und", "son\u00b7der", "Schmuck", ".", "Doch", "ei\u00b7ne", "Rein\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "KON", "ADJA", "NN", "$.", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Kunnt ich mit innigem erquicken,", "tokens": ["Kunnt", "ich", "mit", "in\u00b7ni\u00b7gem", "er\u00b7qui\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.9": {"text": "Bald hie bald da noch durch den Schmutz erblicken.", "tokens": ["Bald", "hie", "bald", "da", "noch", "durch", "den", "Schmutz", "er\u00b7bli\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Dieselbe Reinlichkeit und heller Schmuck entstunden", "tokens": ["Die\u00b7sel\u00b7be", "Rein\u00b7lich\u00b7keit", "und", "hel\u00b7ler", "Schmuck", "ent\u00b7stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "KON", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Aus mancher Lust, die ich alhier", "tokens": ["Aus", "man\u00b7cher", "Lust", ",", "die", "ich", "al\u00b7hier"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "In der Gesch\u00f6pfe Schmuck und Zier,", "tokens": ["In", "der", "Ge\u00b7sch\u00f6p\u00b7fe", "Schmuck", "und", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "So lang ich auf der Welt, empfunden.", "tokens": ["So", "lang", "ich", "auf", "der", "Welt", ",", "emp\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPR", "ART", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und die den Geist, der sie zu GOttes Ruhm erblickt,", "tokens": ["Und", "die", "den", "Geist", ",", "der", "sie", "zu", "Got\u00b7tes", "Ruhm", "er\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Indem sie nnvermerckt ihm selbst sich eingedr\u00fcckt,", "tokens": ["In\u00b7dem", "sie", "nn\u00b7ver\u00b7merckt", "ihm", "selbst", "sich", "ein\u00b7ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPER", "ADV", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ob sie es gleich alhier nicht einst gemerckt, geschm\u00fcckt.", "tokens": ["Ob", "sie", "es", "gleich", "al\u00b7hier", "nicht", "einst", "ge\u00b7merckt", ",", "ge\u00b7schm\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "PTKNEG", "ADV", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Ich ward hierauf in kurtzer Zeit gewahr,", "tokens": ["Ich", "ward", "hier\u00b7auf", "in", "kurt\u00b7zer", "Zeit", "ge\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df alles schmutzige, vom Wasser aufgel\u00f6st,", "tokens": ["Da\u00df", "al\u00b7les", "schmut\u00b7zi\u00b7ge", ",", "vom", "Was\u00b7ser", "auf\u00b7ge\u00b7l\u00f6st", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sich von mir sonderte, wodurch mein Wesen klar", "tokens": ["Sich", "von", "mir", "son\u00b7der\u00b7te", ",", "wo\u00b7durch", "mein", "We\u00b7sen", "klar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "PPER", "VVFIN", "$,", "PWAV", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und hell, wie alles, ward, ja auch so leicht zugleich,", "tokens": ["Und", "hell", ",", "wie", "al\u00b7les", ",", "ward", ",", "ja", "auch", "so", "leicht", "zu\u00b7gleich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PWAV", "PIS", "$,", "VAFIN", "$,", "ADV", "ADV", "ADV", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df ich mich aus der Fluth, worin viel tausend trieben,", "tokens": ["Da\u00df", "ich", "mich", "aus", "der", "Fluth", ",", "wo\u00b7rin", "viel", "tau\u00b7send", "trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "$,", "PWAV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die in best\u00e4ndiger Gefahr", "tokens": ["Die", "in", "be\u00b7st\u00e4n\u00b7di\u00b7ger", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Noch wieder zu versincken, blieben,", "tokens": ["Noch", "wie\u00b7der", "zu", "ver\u00b7sin\u00b7cken", ",", "blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "PTKZU", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Behend erheben kunnt. Ich trat ins Seelen-Reich,", "tokens": ["Be\u00b7hend", "er\u00b7he\u00b7ben", "kunnt", ".", "Ich", "trat", "ins", "See\u00b7len\u00b7Reich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PTKVZ", "$.", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Durchdrungen und durchstrahlt von einem s\u00fcssen Glantz,", "tokens": ["Durch\u00b7drun\u00b7gen", "und", "durch\u00b7strahlt", "von", "ei\u00b7nem", "s\u00fcs\u00b7sen", "Glantz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Mein Wesen, gantz verkl\u00e4hrt, verherrlichte sich gantz.", "tokens": ["Mein", "We\u00b7sen", ",", "gantz", "ver\u00b7kl\u00e4hrt", ",", "ver\u00b7herr\u00b7lich\u00b7te", "sich", "gantz", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "VVPP", "$,", "VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Unglaublich angenehm war alles, was ich sah,", "tokens": ["Un\u00b7glaub\u00b7lich", "an\u00b7ge\u00b7nehm", "war", "al\u00b7les", ",", "was", "ich", "sah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAFIN", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein ieder Vorwurff gl\u00e4ntzt. Es glimmt in buntem Schein", "tokens": ["Ein", "ie\u00b7der", "Vor\u00b7wurff", "gl\u00e4ntzt", ".", "Es", "glimmt", "in", "bun\u00b7tem", "Schein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Feld, Wiesen, Acker-Feld, Gras, Kr\u00e4uter, Holtz und Stein,", "tokens": ["Feld", ",", "Wie\u00b7sen", ",", "A\u00b7cke\u00b7rFeld", ",", "Gras", ",", "Kr\u00e4u\u00b7ter", ",", "Holtz", "und", "Stein", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.4": {"text": "Ja was noch mehr, viel tausend Creaturen,", "tokens": ["Ja", "was", "noch", "mehr", ",", "viel", "tau\u00b7send", "Crea\u00b7tu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "PWS", "ADV", "ADV", "$,", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die uns hier unbekannt, wovon wir keine Spuren", "tokens": ["Die", "uns", "hier", "un\u00b7be\u00b7kannt", ",", "wo\u00b7von", "wir", "kei\u00b7ne", "Spu\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADJD", "$,", "PWAV", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier auf der Welt gesehn, ward ich daselbst gewahr,", "tokens": ["Hier", "auf", "der", "Welt", "ge\u00b7sehn", ",", "ward", "ich", "da\u00b7selbst", "ge\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$,", "VAFIN", "PPER", "PAV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die unansdr\u00fccklich sch\u00f6n, und welche nicht zu zehlen,", "tokens": ["Die", "un\u00b7ans\u00b7dr\u00fcck\u00b7lich", "sch\u00f6n", ",", "und", "wel\u00b7che", "nicht", "zu", "zeh\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "$,", "KON", "PRELS", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die aber, weil dazu die Nahmen fehlen,", "tokens": ["Die", "a\u00b7ber", ",", "weil", "da\u00b7zu", "die", "Nah\u00b7men", "feh\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "KOUS", "PAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und keine W\u00f6rter ausgefunden,", "tokens": ["Und", "kei\u00b7ne", "W\u00f6r\u00b7ter", "aus\u00b7ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Nicht zu beschreiben sind.", "tokens": ["Nicht", "zu", "be\u00b7schrei\u00b7ben", "sind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Das Gr\u00fcn war wie das Gr\u00fcn an einem Pfanen-Schwantz,", "tokens": ["Das", "Gr\u00fcn", "war", "wie", "das", "Gr\u00fcn", "an", "ei\u00b7nem", "Pfa\u00b7nen\u00b7Schwantz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Vermischt mit Klarheit, Licht und Glantz.", "tokens": ["Ver\u00b7mischt", "mit", "Klar\u00b7heit", ",", "Licht", "und", "Glantz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die Bluhmen funckeln hier und gl\u00fchn,", "tokens": ["Die", "Bluh\u00b7men", "fun\u00b7ckeln", "hier", "und", "gl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Die blauen wie Sapphir, die rothen wie Rubin,", "tokens": ["Die", "blau\u00b7en", "wie", "Sap\u00b7phir", ",", "die", "ro\u00b7then", "wie", "Ru\u00b7bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KOKOM", "NE", "$,", "ART", "ADJA", "KOKOM", "NE", "$,"], "meter": "-+--+--+-++-", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "Und was nur sichtbar, ist durchsichtig, hell und klar.", "tokens": ["Und", "was", "nur", "sicht\u00b7bar", ",", "ist", "durch\u00b7sich\u00b7tig", ",", "hell", "und", "klar", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADJD", "$,", "VAFIN", "ADJD", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Das Licht, das alles hier erf\u00fcllet, ist so licht,", "tokens": ["Das", "Licht", ",", "das", "al\u00b7les", "hier", "er\u00b7f\u00fcl\u00b7let", ",", "ist", "so", "licht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$,", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df es durch jeden Vorwurff bricht,", "tokens": ["Da\u00df", "es", "durch", "je\u00b7den", "Vor\u00b7wurff", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da es so gar den Geist durchdringet.", "tokens": ["Da", "es", "so", "gar", "den", "Geist", "durch\u00b7drin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wodurch in allem, was man sieht,", "tokens": ["Wo\u00b7durch", "in", "al\u00b7lem", ",", "was", "man", "sieht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PIS", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Indem das Licht, wie hier, davon nicht r\u00fcckw\u00e4rts springet,", "tokens": ["In\u00b7dem", "das", "Licht", ",", "wie", "hier", ",", "da\u00b7von", "nicht", "r\u00fcck\u00b7w\u00e4rts", "sprin\u00b7get", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "PWAV", "ADV", "$,", "PAV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein lieblich-froher Glantz und Freuden-Feuer gl\u00fcht.", "tokens": ["Ein", "lieb\u00b7lich\u00b7fro\u00b7her", "Glantz", "und", "Freu\u00b7den\u00b7Feu\u00b7er", "gl\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Ich ward hier durchs Geh\u00f6r entz\u00fcckt mehr, als ge-", "tokens": ["Ich", "ward", "hier", "durchs", "Ge\u00b7h\u00f6r", "ent\u00b7z\u00fcckt", "mehr", ",", "als", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPRART", "NN", "VVFIN", "ADV", "$,", "KOUS", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Weil hier der gantze Kreis der L\u00fcffte musiciret.", "tokens": ["Weil", "hier", "der", "gant\u00b7ze", "Kreis", "der", "L\u00fcff\u00b7te", "mu\u00b7si\u00b7ci\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So ward nicht weniger mein Geist durch einen Schwall", "tokens": ["So", "ward", "nicht", "we\u00b7ni\u00b7ger", "mein", "Geist", "durch", "ei\u00b7nen", "Schwall"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PTKNEG", "ADV", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von ausged\u00fcnsteter ambrirten Krafft,", "tokens": ["Von", "aus\u00b7ge\u00b7d\u00fcns\u00b7te\u00b7ter", "am\u00b7br\u00b7ir\u00b7ten", "Krafft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Aus Pflantzen, woraus \u00fcberall", "tokens": ["Aus", "Pflant\u00b7zen", ",", "wo\u00b7raus", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$,", "PWAV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein edler Balsam-Safft", "tokens": ["Ein", "ed\u00b7ler", "Bal\u00b7sam\u00b7\u00b7S\u00b7afft"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "In Uberflu\u00df und unaufh\u00f6rlich quillet,", "tokens": ["In", "U\u00b7ber\u00b7flu\u00df", "und", "un\u00b7auf\u00b7h\u00f6r\u00b7lich", "quil\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Gelabt, durchdrungen und erf\u00fcllet.", "tokens": ["Ge\u00b7labt", ",", "durch\u00b7drun\u00b7gen", "und", "er\u00b7f\u00fcl\u00b7let", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Ich streckte meine Hand begierig aus,", "tokens": ["Ich", "streck\u00b7te", "mei\u00b7ne", "Hand", "be\u00b7gie\u00b7rig", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein Bl\u00fchmchen abzupfl\u00fccken,", "tokens": ["Ein", "Bl\u00fch\u00b7mchen", "ab\u00b7zu\u00b7pfl\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So recht vor andern sch\u00f6n. Allein", "tokens": ["So", "recht", "vor", "an\u00b7dern", "sch\u00f6n", ".", "Al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADJD", "APPR", "PIS", "ADJD", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie stutzt\u2019 ich, als ich nichts daselbst befand;", "tokens": ["Wie", "stutzt'", "ich", ",", "als", "ich", "nichts", "da\u00b7selbst", "be\u00b7fand", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PIS", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Finger traffen nichts, was f\u00fchlbar war, in ihnen,", "tokens": ["Die", "Fin\u00b7ger", "traf\u00b7fen", "nichts", ",", "was", "f\u00fchl\u00b7bar", "war", ",", "in", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "$,", "PRELS", "ADJD", "VAFIN", "$,", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie sie gegl\u00e4ubet, an, ob sie gleich f\u00fchlbar schienen,", "tokens": ["Wie", "sie", "ge\u00b7gl\u00e4u\u00b7bet", ",", "an", ",", "ob", "sie", "gleich", "f\u00fchl\u00b7bar", "schie\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "$,", "PTKVZ", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Weil sie f\u00fcr c\u00f6rperlich-noch nicht verkl\u00e4rte H\u00e4nde,", "tokens": ["Weil", "sie", "f\u00fcr", "c\u00f6\u00b7rper\u00b7lich\u00b7noch", "nicht", "ver\u00b7kl\u00e4r\u00b7te", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da sie nicht c\u00f6rperlich, nicht f\u00fchlbar seyn.", "tokens": ["Da", "sie", "nicht", "c\u00f6r\u00b7per\u00b7lich", ",", "nicht", "f\u00fchl\u00b7bar", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "$,", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Die\u00df nun noch ferner zu probiren,", "tokens": ["Die\u00df", "nun", "noch", "fer\u00b7ner", "zu", "pro\u00b7bi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Entschlo\u00df ich mich, den harten Stamm", "tokens": ["Ent\u00b7schlo\u00df", "ich", "mich", ",", "den", "har\u00b7ten", "Stamm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von einer Eichen zu ber\u00fchren.", "tokens": ["Von", "ei\u00b7ner", "Ei\u00b7chen", "zu", "be\u00b7r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Allein auch hier war nichts zu fassen.", "tokens": ["Al\u00b7lein", "auch", "hier", "war", "nichts", "zu", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VAFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die gantze Hand ward durch den Baum gelassen,", "tokens": ["Die", "gant\u00b7ze", "Hand", "ward", "durch", "den", "Baum", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Als wie durch leere Lufft. Hier\u00fcber noch weit mehr", "tokens": ["Als", "wie", "durch", "lee\u00b7re", "Lufft", ".", "Hier\u00b7\u00fc\u00b7ber", "noch", "weit", "mehr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "KOKOM", "APPR", "ADJA", "NN", "$.", "PAV", "ADV", "ADJD", "ADV"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Erstannet und best\u00fcrtzt, kam ich von ungefehr", "tokens": ["Er\u00b7stan\u00b7net", "und", "be\u00b7st\u00fcrtzt", ",", "kam", "ich", "von", "un\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVPP", "$,", "VVFIN", "PPER", "APPR", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "An einen Flu\u00df, der einen reinen Spiegel", "tokens": ["An", "ei\u00b7nen", "Flu\u00df", ",", "der", "ei\u00b7nen", "rei\u00b7nen", "Spie\u00b7gel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "An Gl\u00e4tt und Klarheit gleich, der durch beb\u00fcschte H\u00fcgel", "tokens": ["An", "Gl\u00e4tt", "und", "Klar\u00b7heit", "gleich", ",", "der", "durch", "be\u00b7b\u00fcschte", "H\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "ADV", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Und lauter Bluhmen flo\u00df.", "tokens": ["Und", "lau\u00b7ter", "Bluh\u00b7men", "flo\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Das Ufer, wo mein Fu\u00df, f\u00fcr Anmuth, stille stand,", "tokens": ["Das", "U\u00b7fer", ",", "wo", "mein", "Fu\u00df", ",", "f\u00fcr", "An\u00b7muth", ",", "stil\u00b7le", "stand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPOSAT", "NN", "$,", "APPR", "NN", "$,", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Schien ein fast g\u00fcldner Sand:", "tokens": ["Schien", "ein", "fast", "g\u00fcld\u00b7ner", "Sand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Das aber, weil es g\u00e4h, mit mir herunter scho\u00df.", "tokens": ["Das", "a\u00b7ber", ",", "weil", "es", "g\u00e4h", ",", "mit", "mir", "her\u00b7un\u00b7ter", "scho\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,", "APPR", "PPER", "APZR", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ich fiel, f\u00fcr Angst erstarrt, von oben in die Fluth.", "tokens": ["Ich", "fiel", ",", "f\u00fcr", "Angst", "er\u00b7starrt", ",", "von", "o\u00b7ben", "in", "die", "Fluth", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "NN", "VVPP", "$,", "APPR", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ohn\u2019 alle Hoffnung meines Lebens:", "tokens": ["Ohn'", "al\u00b7le", "Hoff\u00b7nung", "mei\u00b7nes", "Le\u00b7bens", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Jedoch, wie wol ward mir zu Muth!", "tokens": ["Je\u00b7doch", ",", "wie", "wol", "ward", "mir", "zu", "Muth", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADV", "VAFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Mein Schrecken war vergebens.", "tokens": ["Mein", "Schre\u00b7cken", "war", "ver\u00b7ge\u00b7bens", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Die Fluth hatt von der Fluth f\u00fcr mich nur die Figur,", "tokens": ["Die", "Fluth", "hatt", "von", "der", "Fluth", "f\u00fcr", "mich", "nur", "die", "Fi\u00b7gur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "APPR", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und ungefehr der Lufft Natur,", "tokens": ["Und", "un\u00b7ge\u00b7fehr", "der", "Lufft", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Die weder netzet noch erstickt.", "tokens": ["Die", "we\u00b7der", "net\u00b7zet", "noch", "er\u00b7stickt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KON", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Ich gieng demnach durch diese trockne Wellen,", "tokens": ["Ich", "gieng", "dem\u00b7nach", "durch", "die\u00b7se", "trock\u00b7ne", "Wel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von ihnen nicht gehemmet noch gedr\u00fcckt,", "tokens": ["Von", "ih\u00b7nen", "nicht", "ge\u00b7hem\u00b7met", "noch", "ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKNEG", "VVFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bi\u00df zu derselben gr\u00fcnen Grentzen,", "tokens": ["Bi\u00df", "zu", "der\u00b7sel\u00b7ben", "gr\u00fc\u00b7nen", "Grent\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo Millionen Bluhmen gl\u00e4ntzen,", "tokens": ["Wo", "Mil\u00b7lion\u00b7en", "Bluh\u00b7men", "gl\u00e4nt\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zum andern Ufer fort: Die allerdicksten Hecken,", "tokens": ["Zum", "an\u00b7dern", "U\u00b7fer", "fort", ":", "Die", "al\u00b7ler\u00b7dicks\u00b7ten", "He\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dergleichen ich auf Erden nie gesehn,", "tokens": ["Derg\u00b7lei\u00b7chen", "ich", "auf", "Er\u00b7den", "nie", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Fand ich daselbst, voll starrer Dornen, stehn:", "tokens": ["Fand", "ich", "da\u00b7selbst", ",", "voll", "star\u00b7rer", "Dor\u00b7nen", ",", "stehn", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "$,", "ADJD", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Die aber mir den Durchgang nicht verwehrten,", "tokens": ["Die", "a\u00b7ber", "mir", "den", "Durch\u00b7gang", "nicht", "ver\u00b7wehr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Noch im geringsten mich versehrten.", "tokens": ["Noch", "im", "ge\u00b7rings\u00b7ten", "mich", "ver\u00b7sehr\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "So bald ich nun mit ungehemmten Gang", "tokens": ["So", "bald", "ich", "nun", "mit", "un\u00b7ge\u00b7hemm\u00b7ten", "Gang"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Durch die verwachsnen Hecken drang;", "tokens": ["Durch", "die", "ver\u00b7wachs\u00b7nen", "He\u00b7cken", "drang", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Befand ich mich auf einem weiten Platz,", "tokens": ["Be\u00b7fand", "ich", "mich", "auf", "ei\u00b7nem", "wei\u00b7ten", "Platz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der gr\u00fcn, wie ein Smaragd, in welchem Bluhmen stunden,", "tokens": ["Der", "gr\u00fcn", ",", "wie", "ein", "Sma\u00b7ragd", ",", "in", "wel\u00b7chem", "Bluh\u00b7men", "stun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "PWAV", "ART", "NN", "$,", "APPR", "PWAT", "NN", "VVINF", "$,"], "meter": "-+-+++-+-+-+-", "measure": "unknown.measure.septa"}, "line.5": {"text": "Die alle, wie ein reicher Schatz", "tokens": ["Die", "al\u00b7le", ",", "wie", "ein", "rei\u00b7cher", "Schatz"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von lieblich spielenden Opalen,", "tokens": ["Von", "lieb\u00b7lich", "spie\u00b7len\u00b7den", "O\u00b7pa\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Mehr Glantz als Farben von sich strahlen.", "tokens": ["Mehr", "Glantz", "als", "Far\u00b7ben", "von", "sich", "strah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KOUS", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ein lieblicher Oranjen Wald", "tokens": ["Ein", "lieb\u00b7li\u00b7cher", "O\u00b7ran\u00b7jen", "Wald"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "War an der rechten Hand ein rechter Aufenthalt", "tokens": ["War", "an", "der", "rech\u00b7ten", "Hand", "ein", "rech\u00b7ter", "Auf\u00b7ent\u00b7halt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von Anmuth, Ruh, Zufriedenheit und Lust.", "tokens": ["Von", "An\u00b7muth", ",", "Ruh", ",", "Zu\u00b7frie\u00b7den\u00b7heit", "und", "Lust", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Hier traff ich, halb entz\u00fcckt, so sch\u00f6ne Menschen an,", "tokens": ["Hier", "traff", "ich", ",", "halb", "ent\u00b7z\u00fcckt", ",", "so", "sch\u00f6\u00b7ne", "Men\u00b7schen", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJD", "VVPP", "$,", "ADV", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df ich, wie sehr mich ihre Sch\u00f6nheit r\u00fchrte,", "tokens": ["Da\u00df", "ich", ",", "wie", "sehr", "mich", "ih\u00b7re", "Sch\u00f6n\u00b7heit", "r\u00fchr\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PWAV", "ADV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wie die Lust so gro\u00df,", "tokens": ["Und", "wie", "die", "Lust", "so", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die ich in ihrem Ansehn blos", "tokens": ["Die", "ich", "in", "ih\u00b7rem", "An\u00b7sehn", "blos"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bey mir versp\u00fchrte,", "tokens": ["Bey", "mir", "ver\u00b7sp\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Unm\u00f6glich recht beschreiben kann.", "tokens": ["Un\u00b7m\u00f6g\u00b7lich", "recht", "be\u00b7schrei\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kurtz, es war ihre Zier", "tokens": ["Kurtz", ",", "es", "war", "ih\u00b7re", "Zier"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PPER", "VAFIN", "PPOSAT", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Recht so wie wir uns hier", "tokens": ["Recht", "so", "wie", "wir", "uns", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "KOKOM", "PPER", "PPER", "ADV"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "Die Engel vorzustellen pflegen,", "tokens": ["Die", "En\u00b7gel", "vor\u00b7zu\u00b7stel\u00b7len", "pfle\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die Schimmer, Glantz und Licht in ihrem Wesen hegen.", "tokens": ["Die", "Schim\u00b7mer", ",", "Glantz", "und", "Licht", "in", "ih\u00b7rem", "We\u00b7sen", "he\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Allein!", "tokens": ["Al\u00b7lein", "!"], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.12": {"text": "Was recht verwunderlich,", "tokens": ["Was", "recht", "ver\u00b7wun\u00b7der\u00b7lich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Es schien kein eintziger f\u00fcr sich,", "tokens": ["Es", "schien", "kein", "eint\u00b7zi\u00b7ger", "f\u00fcr", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "PIS", "APPR", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Hingegen alle blos", "tokens": ["Hin\u00b7ge\u00b7gen", "al\u00b7le", "blos"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PIS", "ADV"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.15": {"text": "Vom Gantzen nur ein Theil zu seyn.", "tokens": ["Vom", "Gant\u00b7zen", "nur", "ein", "Theil", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Es war die Eintracht gro\u00df,", "tokens": ["Es", "war", "die", "Ein\u00b7tracht", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Ja wunderbar und ungemein.", "tokens": ["Ja", "wun\u00b7der\u00b7bar", "und", "un\u00b7ge\u00b7mein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADJD", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Recht wie in einem Krieges-Heer", "tokens": ["Recht", "wie", "in", "ei\u00b7nem", "Krie\u00b7ge\u00b7sHeer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich Regimenter so vereinen,", "tokens": ["Sich", "Re\u00b7gi\u00b7men\u00b7ter", "so", "ver\u00b7ei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df an Bewegung sie nicht anders scheinen,", "tokens": ["Da\u00df", "an", "Be\u00b7we\u00b7gung", "sie", "nicht", "an\u00b7ders", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "PPER", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als wenn es nur ein einzger C\u00f6rper w\u00e4r;", "tokens": ["Als", "wenn", "es", "nur", "ein", "einz\u00b7ger", "C\u00f6r\u00b7per", "w\u00e4r", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So, doch weit inniger annoch vereint,", "tokens": ["So", ",", "doch", "weit", "in\u00b7ni\u00b7ger", "an\u00b7noch", "ver\u00b7eint", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADJD", "ADJD", "ADV", "VVPP", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "War dieses Geister-Heer, da sie ein wircklich Ein,", "tokens": ["War", "die\u00b7ses", "Geis\u00b7ter\u00b7Heer", ",", "da", "sie", "ein", "wir\u00b7ck\u00b7lich", "Ein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "$,", "KOUS", "PPER", "ART", "ADJD", "ART", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Wenn sie sich gleich zertheilen, seyn.", "tokens": ["Wenn", "sie", "sich", "gleich", "zer\u00b7thei\u00b7len", ",", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVINF", "$,", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Es schien, ob herrschte nur ein Wille", "tokens": ["Es", "schien", ",", "ob", "herrschte", "nur", "ein", "Wil\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "In dieser gantzen Schaar. In einer regen Stille", "tokens": ["In", "die\u00b7ser", "gant\u00b7zen", "Schaar", ".", "In", "ei\u00b7ner", "re\u00b7gen", "Stil\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$.", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "War \u00fcberall", "tokens": ["War", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word"], "pos": ["VAFIN", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Ein unausdr\u00fccklich s\u00fcsser Schall,", "tokens": ["Ein", "un\u00b7aus\u00b7dr\u00fcck\u00b7lich", "s\u00fcs\u00b7ser", "Schall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Ein s\u00fc\u00df harmonisches Geth\u00f6n", "tokens": ["Ein", "s\u00fc\u00df", "har\u00b7mo\u00b7ni\u00b7sches", "Ge\u00b7th\u00f6n"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Nicht nur zu h\u00f6ren, auch zu sehn.", "tokens": ["Nicht", "nur", "zu", "h\u00f6\u00b7ren", ",", "auch", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PTKZU", "VVINF", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Die Lust die einer f\u00fchlt\u2019, empfand sogleich ein ieder,", "tokens": ["Die", "Lust", "die", "ei\u00b7ner", "f\u00fchlt'", ",", "emp\u00b7fand", "sog\u00b7leich", "ein", "ie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PIS", "VVFIN", "$,", "VVFIN", "ADV", "ART", "PIAT", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Nicht anders wie bey uns die andern Glieder", "tokens": ["Nicht", "an\u00b7ders", "wie", "bey", "uns", "die", "an\u00b7dern", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "KOKOM", "APPR", "PPER", "ART", "ADJA", "NN"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "An einem C\u00f6rper das zugleich ergetzet,", "tokens": ["An", "ei\u00b7nem", "C\u00f6r\u00b7per", "das", "zu\u00b7gleich", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Was ein Glied in Vergn\u00fcgung setzet.", "tokens": ["Was", "ein", "Glied", "in", "Ver\u00b7gn\u00fc\u00b7gung", "set\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.18": {"text": "Daher war ihnen nichts als eine stete Lust,", "tokens": ["Da\u00b7her", "war", "ih\u00b7nen", "nichts", "als", "ei\u00b7ne", "ste\u00b7te", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PIS", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die allen allgemein, bewust.", "tokens": ["Die", "al\u00b7len", "all\u00b7ge\u00b7mein", ",", "be\u00b7wust", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PIAT", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Es sucht kein eintziger f\u00fcr sich allein", "tokens": ["Es", "sucht", "kein", "eint\u00b7zi\u00b7ger", "f\u00fcr", "sich", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "PIS", "APPR", "PRF", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Begl\u00fcckt zu seyn;", "tokens": ["Be\u00b7gl\u00fcckt", "zu", "seyn", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.22": {"text": "Sie theilten sich auf eine s\u00fcsse Weise,", "tokens": ["Sie", "theil\u00b7ten", "sich", "auf", "ei\u00b7ne", "s\u00fcs\u00b7se", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Dem Sch\u00f6pffer aller Welt zum Preise,", "tokens": ["Dem", "Sch\u00f6pf\u00b7fer", "al\u00b7ler", "Welt", "zum", "Prei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "An iedem Ort, bey iedem Schritt,", "tokens": ["An", "ie\u00b7dem", "Ort", ",", "bey", "ie\u00b7dem", "Schritt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Einander ihre Freude mit.", "tokens": ["Ein\u00b7an\u00b7der", "ih\u00b7re", "Freu\u00b7de", "mit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "So wie auf Erden keine Lust", "tokens": ["So", "wie", "auf", "Er\u00b7den", "kei\u00b7ne", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "APPR", "NN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Menschen Brust", "tokens": ["Der", "Men\u00b7schen", "Brust"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Mit einem tieffern Eindruck r\u00fchrt,", "tokens": ["Mit", "ei\u00b7nem", "tief\u00b7fern", "Ein\u00b7druck", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als wenn durch Wechsels-weis\u2019 erregte Triebe", "tokens": ["Als", "wenn", "durch", "Wech\u00b7sels\u00b7weis'", "er\u00b7reg\u00b7te", "Trie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "APPR", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Anmuth zugelassner Liebe", "tokens": ["Die", "An\u00b7muth", "zu\u00b7ge\u00b7lass\u00b7ner", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein paar verbundner Hertzen sp\u00fchrt;", "tokens": ["Ein", "paar", "ver\u00b7bund\u00b7ner", "Hert\u00b7zen", "sp\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So ist ja leichtlich zu begreiffen,", "tokens": ["So", "ist", "ja", "leicht\u00b7lich", "zu", "be\u00b7greif\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie vielfach sich ein inniges Ergetzen", "tokens": ["Wie", "viel\u00b7fach", "sich", "ein", "in\u00b7ni\u00b7ges", "Er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PRF", "ART", "ADJA", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "In dieser Menge m\u00fcsse h\u00e4uffen,", "tokens": ["In", "die\u00b7ser", "Men\u00b7ge", "m\u00fcs\u00b7se", "h\u00e4uf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und sie in seelge Lust versetzen,", "tokens": ["Und", "sie", "in", "seel\u00b7ge", "Lust", "ver\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Da ihrer viel in seelger Brunst sich \u00fcben", "tokens": ["Da", "ih\u00b7rer", "viel", "in", "seel\u00b7ger", "Brunst", "sich", "\u00fc\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADV", "APPR", "ADJA", "NN", "PRF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Sich immer mehr und mehr zu lieben.", "tokens": ["Sich", "im\u00b7mer", "mehr", "und", "mehr", "zu", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADV", "KON", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Solch eine Schaar bestand aus mehr", "tokens": ["Solch", "ei\u00b7ne", "Schaar", "be\u00b7stand", "aus", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ART", "NN", "VVFIN", "APPR", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als zehn mahl hundert tausend Seelen,", "tokens": ["Als", "zehn", "mahl", "hun\u00b7dert", "tau\u00b7send", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "ADV", "CARD", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die alle, zu des Sch\u00f6pfers Ehr,", "tokens": ["Die", "al\u00b7le", ",", "zu", "des", "Sch\u00f6p\u00b7fers", "Ehr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In ihrer Lust, die Macht und Lieb erzehlen,", "tokens": ["In", "ih\u00b7rer", "Lust", ",", "die", "Macht", "und", "Lieb", "er\u00b7zeh\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ART", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die t\u00e4g-ja st\u00fcndlich sich bey ihnen noch vermehrt.", "tokens": ["Die", "t\u00e4g\u00b7ja", "st\u00fcnd\u00b7lich", "sich", "bey", "ih\u00b7nen", "noch", "ver\u00b7mehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJD", "PRF", "APPR", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Hier\u00fcber wacht ich auf. Und ob mir gleich die Pracht", "tokens": ["Hier\u00b7\u00fc\u00b7ber", "wacht", "ich", "auf", ".", "Und", "ob", "mir", "gleich", "die", "Pracht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PTKVZ", "$.", "KON", "KOUS", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So vieler Sch\u00f6n- und Seltenheiten,", "tokens": ["So", "vie\u00b7ler", "Sch\u00f6n", "und", "Sel\u00b7ten\u00b7hei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So ungemeiner Herrlichkeiten,", "tokens": ["So", "un\u00b7ge\u00b7mei\u00b7ner", "Herr\u00b7lich\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Lust, Anmuth und Vergn\u00fcgen bracht;", "tokens": ["Lust", ",", "An\u00b7muth", "und", "Ver\u00b7gn\u00fc\u00b7gen", "bracht", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So war ich doch von der Durchdringlichkeit", "tokens": ["So", "war", "ich", "doch", "von", "der", "Durch\u00b7dring\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der dort gesehnen Creaturen", "tokens": ["Der", "dort", "ge\u00b7seh\u00b7nen", "Crea\u00b7tu\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Noch mehr, als den vortrefflichen Figuren,", "tokens": ["Noch", "mehr", ",", "als", "den", "vor\u00b7treff\u00b7li\u00b7chen", "Fi\u00b7gu\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "+-+-++-+-+-", "measure": "unknown.measure.hexa"}, "line.8": {"text": "Recht inniglich ger\u00fchrt. Wie die Beschaffenheit,", "tokens": ["Recht", "in\u00b7nig\u00b7lich", "ge\u00b7r\u00fchrt", ".", "Wie", "die", "Be\u00b7schaf\u00b7fen\u00b7heit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "$.", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da\u00df sie nicht f\u00fchlbar sind, nicht nur ein klares Zeichen", "tokens": ["Da\u00df", "sie", "nicht", "f\u00fchl\u00b7bar", "sind", ",", "nicht", "nur", "ein", "kla\u00b7res", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "VAFIN", "$,", "PTKNEG", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von ihrer steten Daur, (da blos dadurch allein,", "tokens": ["Von", "ih\u00b7rer", "ste\u00b7ten", "Daur", ",", "(", "da", "blos", "da\u00b7durch", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "$(", "ADV", "ADV", "PAV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da\u00df hier die C\u00f6rper fest und undurchdringlich seyn,", "tokens": ["Da\u00df", "hier", "die", "C\u00f6r\u00b7per", "fest", "und", "un\u00b7durch\u00b7dring\u00b7lich", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PTKVZ", "KON", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sie den Ver\u00e4ndrungen fast unaufh\u00f6rlich", "tokens": ["Sie", "den", "Ver\u00b7\u00e4n\u00b7drun\u00b7gen", "fast", "un\u00b7auf\u00b7h\u00f6r\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "ADV", "ADJD"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.13": {"text": "Sind ausgesetzt, und ihnen m\u00fcssen weichen,", "tokens": ["Sind", "aus\u00b7ge\u00b7setzt", ",", "und", "ih\u00b7nen", "m\u00fcs\u00b7sen", "wei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "KON", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Einfolglich stets verg\u00e4nglich und zerst\u00f6rlich,", "tokens": ["Ein\u00b7folg\u00b7lich", "stets", "ver\u00b7g\u00e4ng\u00b7lich", "und", "zer\u00b7st\u00f6r\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und unbest\u00e4ndig sind:) so zeigt es gleichfalls an,", "tokens": ["Und", "un\u00b7be\u00b7st\u00e4n\u00b7dig", "sind", ":)", "so", "zeigt", "es", "gleich\u00b7falls", "an", ","], "token_info": ["word", "word", "word", "emoticon", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "$(", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df, wie man ja nicht leugnen kann,", "tokens": ["Da\u00df", ",", "wie", "man", "ja", "nicht", "leug\u00b7nen", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWAV", "PIS", "ADV", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Dergleichen Wesen seyn und leben m\u00fcssen,", "tokens": ["Derg\u00b7lei\u00b7chen", "We\u00b7sen", "seyn", "und", "le\u00b7ben", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "VAINF", "KON", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Wir auch daher nicht unwahrscheinlich schliessen,", "tokens": ["Wir", "auch", "da\u00b7her", "nicht", "un\u00b7wahr\u00b7schein\u00b7lich", "schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PAV", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Da\u00df man vielleicht auch schon in diesem Leben", "tokens": ["Da\u00df", "man", "viel\u00b7leicht", "auch", "schon", "in", "die\u00b7sem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "ADV", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Mit Creaturen sey \u00fcmgeben,", "tokens": ["Mit", "Crea\u00b7tu\u00b7ren", "sey", "\u00fcm\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Die so, wie jene dort, nicht f\u00fchlbar, aber doch", "tokens": ["Die", "so", ",", "wie", "je\u00b7ne", "dort", ",", "nicht", "f\u00fchl\u00b7bar", ",", "a\u00b7ber", "doch"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADV", "$,", "PWAV", "PDS", "ADV", "$,", "PTKNEG", "ADJD", "$,", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Nicht minder w\u00fcrcklich sind.", "tokens": ["Nicht", "min\u00b7der", "w\u00fcrck\u00b7lich", "sind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Die\u00df war zuerst, was ich aus meinem Traum gedachte,", "tokens": ["Die\u00df", "war", "zu\u00b7erst", ",", "was", "ich", "aus", "mei\u00b7nem", "Traum", "ge\u00b7dach\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "$,", "PWS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bis er mich ferner noch auf die Gedancken brachte:", "tokens": ["Bis", "er", "mich", "fer\u00b7ner", "noch", "auf", "die", "Ge\u00b7dan\u00b7cken", "brach\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}}, "stanza.28": {"line.1": {"text": "Ich war von den vereinten Schaaren,", "tokens": ["Ich", "war", "von", "den", "ver\u00b7ein\u00b7ten", "Schaa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die, da sie mit unzehligem Vergn\u00fcgen,", "tokens": ["Die", ",", "da", "sie", "mit", "un\u00b7zeh\u00b7li\u00b7gem", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So allen allgemein, sich f\u00fcgen,", "tokens": ["So", "al\u00b7len", "all\u00b7ge\u00b7mein", ",", "sich", "f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJD", "$,", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und Glieder eines C\u00f6rpers waren,", "tokens": ["Und", "Glie\u00b7der", "ei\u00b7nes", "C\u00f6r\u00b7pers", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Recht sonderlich von neuen eingenommen,", "tokens": ["Recht", "son\u00b7der\u00b7lich", "von", "neu\u00b7en", "ein\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Bis ich dadurch auf die Gedancken kommen:", "tokens": ["Bis", "ich", "da\u00b7durch", "auf", "die", "Ge\u00b7dan\u00b7cken", "kom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Wie, dacht ich, kann es m\u00f6glich seyn,", "tokens": ["Wie", ",", "dacht", "ich", ",", "kann", "es", "m\u00f6g\u00b7lich", "seyn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "VVFIN", "PPER", "$,", "VMFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df Menschen iemahls auf der Erden", "tokens": ["Da\u00df", "Men\u00b7schen", "ie\u00b7mahls", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vergn\u00fcgt und gl\u00fccklich k\u00f6nnen werden?", "tokens": ["Ver\u00b7gn\u00fcgt", "und", "gl\u00fcck\u00b7lich", "k\u00f6n\u00b7nen", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da ieder blos f\u00fcr sich allein", "tokens": ["Da", "ie\u00b7der", "blos", "f\u00fcr", "sich", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "APPR", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gedencket, handelt, ist und lebet,", "tokens": ["Ge\u00b7den\u00b7cket", ",", "han\u00b7delt", ",", "ist", "und", "le\u00b7bet", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "VAFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da ieder f\u00fcr sein einzigs Ein,", "tokens": ["Da", "ie\u00b7der", "f\u00fcr", "sein", "ein\u00b7zigs", "Ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Mit aller Ausschlu\u00df, sorgt und strebet;", "tokens": ["Mit", "al\u00b7ler", "Aus\u00b7schlu\u00df", ",", "sorgt", "und", "stre\u00b7bet", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da ieder Wollust, Ehre, Geld,", "tokens": ["Da", "ie\u00b7der", "Wol\u00b7lust", ",", "Eh\u00b7re", ",", "Geld", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Des Gl\u00fcckes Vorw\u00fcrff\u2019 in der Welt,", "tokens": ["Des", "Gl\u00fc\u00b7ckes", "Vor\u00b7w\u00fcrff'", "in", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Auf solche Art f\u00fcr sich begehrt;", "tokens": ["Auf", "sol\u00b7che", "Art", "f\u00fcr", "sich", "be\u00b7gehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "PRF", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Da\u00df das, was er erh\u00e4lt,", "tokens": ["Da\u00df", "das", ",", "was", "er", "er\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Ein andrer missen mu\u00df. Je mehr dein Gut sich mehrt;", "tokens": ["Ein", "an\u00b7drer", "mis\u00b7sen", "mu\u00df", ".", "Je", "mehr", "dein", "Gut", "sich", "mehrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVINF", "VMFIN", "$.", "ADV", "ADV", "PPOSAT", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Je mehr beraubst du mich", "tokens": ["Je", "mehr", "be\u00b7raubst", "du", "mich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PRF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Desjenigen, so mein geliebtes Ich", "tokens": ["Des\u00b7je\u00b7ni\u00b7gen", ",", "so", "mein", "ge\u00b7lieb\u00b7tes", "Ich"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "$,", "ADV", "PPOSAT", "ADJA", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Erhalten und besitzen k\u00f6nnte.", "tokens": ["Er\u00b7hal\u00b7ten", "und", "be\u00b7sit\u00b7zen", "k\u00f6nn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Wie w\u00e4r es denn, nach meiner Eigen-Liebe,", "tokens": ["Wie", "w\u00e4r", "es", "denn", ",", "nach", "mei\u00b7ner", "Ei\u00b7gen\u00b7Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Die mich, nur mich zu lieben, triebe,", "tokens": ["Die", "mich", ",", "nur", "mich", "zu", "lie\u00b7ben", ",", "trie\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "$,", "ADV", "PPER", "PTKZU", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Doch m\u00f6glich, da\u00df ich dir es g\u00f6nnte?", "tokens": ["Doch", "m\u00f6g\u00b7lich", ",", "da\u00df", "ich", "dir", "es", "g\u00f6nn\u00b7te", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "KOUS", "PPER", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Wenn nicht die Furcht der Straff\u2019 allein,", "tokens": ["Wenn", "nicht", "die", "Furcht", "der", "Straff'", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Die auf Entw\u00e4ltigung gesetzet seyn,", "tokens": ["Die", "auf", "Ent\u00b7w\u00e4l\u00b7ti\u00b7gung", "ge\u00b7set\u00b7zet", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Mir die nat\u00fcrlichen Begierden und Gedancken", "tokens": ["Mir", "die", "na\u00b7t\u00fcr\u00b7li\u00b7chen", "Be\u00b7gier\u00b7den", "und", "Ge\u00b7dan\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Zwar in die vorgesetzte Schrancken,", "tokens": ["Zwar", "in", "die", "vor\u00b7ge\u00b7setz\u00b7te", "Schran\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Jedoch f\u00fcrwahr gezwungen, hielten.", "tokens": ["Je\u00b7doch", "f\u00fcr\u00b7wahr", "ge\u00b7zwun\u00b7gen", ",", "hiel\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Der Zwang allein ist der Ratur so sehr", "tokens": ["Der", "Zwang", "al\u00b7lein", "ist", "der", "Ra\u00b7tur", "so", "sehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Entgegen und zuwieder;", "tokens": ["Ent\u00b7ge\u00b7gen", "und", "zu\u00b7wie\u00b7der", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.26": {"text": "Da\u00df sonder Zweifel sich ein ieder,", "tokens": ["Da\u00df", "son\u00b7der", "Zwei\u00b7fel", "sich", "ein", "ie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "PRF", "ART", "PIAT", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "M\u00fcst er sich nicht bef\u00fcrchten oder sch\u00e4men,", "tokens": ["M\u00fcst", "er", "sich", "nicht", "be\u00b7f\u00fcrch\u00b7ten", "o\u00b7der", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PTKNEG", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Das meinige mir weg zu nehmen,", "tokens": ["Das", "mei\u00b7ni\u00b7ge", "mir", "weg", "zu", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Sich ohne Zweiffel leicht bequemen,", "tokens": ["Sich", "oh\u00b7ne", "Zweif\u00b7fel", "leicht", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "ADJD", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Und schnell entschliessen w\u00fcrd\u2019. Es zeigt sich dieses klar:", "tokens": ["Und", "schnell", "ent\u00b7schlies\u00b7sen", "w\u00fcrd'", ".", "Es", "zeigt", "sich", "die\u00b7ses", "klar", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "VAFIN", "$.", "PPER", "VVFIN", "PRF", "PDAT", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Weil eben auf den Raub der Ehre", "tokens": ["Weil", "e\u00b7ben", "auf", "den", "Raub", "der", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kein\u2019 Art von Straff\u2019 absonderlich gesetzt,", "tokens": ["Kein'", "Art", "von", "Straff'", "ab\u00b7son\u00b7der\u00b7lich", "ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NE", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und da\u00df man, ohn Gefahr,", "tokens": ["Und", "da\u00df", "man", ",", "ohn", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Des N\u00e4chsten Leumuth raubt, und ihn dadurch verletzt;", "tokens": ["Des", "N\u00e4chs\u00b7ten", "Leu\u00b7muth", "raubt", ",", "und", "ihn", "da\u00b7durch", "ver\u00b7letzt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "PPER", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So seh man doch, wie wir zum tadlen, affterreden,", "tokens": ["So", "seh", "man", "doch", ",", "wie", "wir", "zum", "tad\u00b7len", ",", "aff\u00b7ter\u00b7re\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$,", "PWAV", "PPER", "APPRART", "VVINF", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zum l\u00e4stern, spotten, zum verdrehn,", "tokens": ["Zum", "l\u00e4s\u00b7tern", ",", "spot\u00b7ten", ",", "zum", "ver\u00b7drehn", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "VVFIN", "$,", "APPRART", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Menschen unter sich so fertig sehn.", "tokens": ["Die", "Men\u00b7schen", "un\u00b7ter", "sich", "so", "fer\u00b7tig", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Es wird sich keiner leicht entbl\u00f6den,", "tokens": ["Es", "wird", "sich", "kei\u00b7ner", "leicht", "ent\u00b7bl\u00f6\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "PIS", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Um ins geheim sein Ich hinauf zur\u00fccken,", "tokens": ["Um", "ins", "ge\u00b7heim", "sein", "Ich", "hin\u00b7auf", "zu\u00b7r\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPRART", "ADJD", "VAINF", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Des N\u00e4chsten Ruhm zu unterdr\u00fccken,", "tokens": ["Des", "N\u00e4chs\u00b7ten", "Ruhm", "zu", "un\u00b7ter\u00b7dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und blo\u00df, da\u00df man ihn m\u00f6ge kl\u00fcger heissen,", "tokens": ["Und", "blo\u00df", ",", "da\u00df", "man", "ihn", "m\u00f6\u00b7ge", "kl\u00fc\u00b7ger", "heis\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PIS", "PPER", "VMFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Des N\u00e4chsten Ehren-Bau her\u00fcm zu reissen.", "tokens": ["Des", "N\u00e4chs\u00b7ten", "Eh\u00b7ren\u00b7Bau", "he\u00b7r\u00fcm", "zu", "reis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APZR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Pfuy! da\u00df man, wieder alle Pflichten,", "tokens": ["Pfuy", "!", "da\u00df", "man", ",", "wie\u00b7der", "al\u00b7le", "Pflich\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KOUS", "PIS", "$,", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Sich nicht entsieht, f\u00fcr sich, was man dem N\u00e4chsten stahl,", "tokens": ["Sich", "nicht", "ent\u00b7sieht", ",", "f\u00fcr", "sich", ",", "was", "man", "dem", "N\u00e4chs\u00b7ten", "stahl", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "VVFIN", "$,", "APPR", "PRF", "$,", "PRELS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Zu nehmen, und sein Ehren-Mahl", "tokens": ["Zu", "neh\u00b7men", ",", "und", "sein", "Eh\u00b7ren\u00b7Mahl"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Auf jenes Schand-Mahl aufzurichten!", "tokens": ["Auf", "je\u00b7nes", "Schan\u00b7dMahl", "auf\u00b7zu\u00b7rich\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Wie n\u00f6thig hier in dieser Welt", "tokens": ["Wie", "n\u00f6\u00b7thig", "hier", "in", "die\u00b7ser", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die N\u00e4chsten-Lieb\u2019, und die Geselligkeit,", "tokens": ["Die", "N\u00e4chs\u00b7ten\u00b7Lieb'", ",", "und", "die", "Ge\u00b7sel\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Hat Moses im Gesetz uns nicht nur vorgestellt;", "tokens": ["Hat", "Mo\u00b7ses", "im", "Ge\u00b7setz", "uns", "nicht", "nur", "vor\u00b7ge\u00b7stellt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "APPRART", "NN", "PPER", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Selbst Christus hat der Christenheit", "tokens": ["Selbst", "Chris\u00b7tus", "hat", "der", "Chris\u00b7ten\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "NE", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nicht unsre Freunde nur, so gar den Feind zu lieben,", "tokens": ["Nicht", "uns\u00b7re", "Freun\u00b7de", "nur", ",", "so", "gar", "den", "Feind", "zu", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "ADV", "$,", "ADV", "ADV", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als wie ein solch Gebot zur Regel vorgeschrieben,", "tokens": ["Als", "wie", "ein", "solch", "Ge\u00b7bot", "zur", "Re\u00b7gel", "vor\u00b7ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "PIAT", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Das fast dem gr\u00f6ssesten Gebot nicht weicht,", "tokens": ["Das", "fast", "dem", "gr\u00f6s\u00b7ses\u00b7ten", "Ge\u00b7bot", "nicht", "weicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "ADJA", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und sich an Wichtigkeit dem GOttes-Dienst vergleicht.", "tokens": ["Und", "sich", "an", "Wich\u00b7tig\u00b7keit", "dem", "Got\u00b7tes\u00b7Dienst", "ver\u00b7gleicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Je mehr wir diese Lehr erwegen,", "tokens": ["Je", "mehr", "wir", "die\u00b7se", "Lehr", "er\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Je mehr strahlt eine G\u00f6ttlichkeit,", "tokens": ["Je", "mehr", "strahlt", "ei\u00b7ne", "G\u00f6tt\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Erkenntni\u00df, Wahrheit, Heil und Segen", "tokens": ["Er\u00b7kennt\u00b7ni\u00df", ",", "Wahr\u00b7heit", ",", "Heil", "und", "Se\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus ihr, als wie ein Licht.", "tokens": ["Aus", "ihr", ",", "als", "wie", "ein", "Licht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KOUS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Kein Laster scheint fast \u00fcbrig mehr zu bleiben,", "tokens": ["Kein", "Las\u00b7ter", "scheint", "fast", "\u00fcb\u00b7rig", "mehr", "zu", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "ADJD", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "K\u00f6nnt einer nur", "tokens": ["K\u00f6nnt", "ei\u00b7ner", "nur"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PIS", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Von unsrer menschlichen Natur,", "tokens": ["Von", "uns\u00b7rer", "menschli\u00b7chen", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Der Eigen-Liebe Gifft vertreiben.", "tokens": ["Der", "Ei\u00b7gen\u00b7Lie\u00b7be", "Gifft", "ver\u00b7trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Es ist daher gewi\u00df, und bleibt dabey,", "tokens": ["Es", "ist", "da\u00b7her", "ge\u00b7wi\u00df", ",", "und", "bleibt", "da\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "ADV", "$,", "KON", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df die Geselligkeit und N\u00e4chsten-Liebe", "tokens": ["Da\u00df", "die", "Ge\u00b7sel\u00b7lig\u00b7keit", "und", "N\u00e4chs\u00b7ten\u00b7Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nicht nur ein Feind der lasterhaften Triebe,", "tokens": ["Nicht", "nur", "ein", "Feind", "der", "las\u00b7ter\u00b7haf\u00b7ten", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht nur der Inbegriff von aller Tugend sey;", "tokens": ["Nicht", "nur", "der", "In\u00b7be\u00b7griff", "von", "al\u00b7ler", "Tu\u00b7gend", "sey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "APPR", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nein, da\u00df vermuthlich gar in jener seelgen H\u00f6he", "tokens": ["Nein", ",", "da\u00df", "ver\u00b7muth\u00b7lich", "gar", "in", "je\u00b7ner", "seel\u00b7gen", "H\u00f6\u00b7he"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KOUS", "ADV", "ADV", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hierin ein grosses Theil der Seeligkeit bestehe,", "tokens": ["Hie\u00b7rin", "ein", "gros\u00b7ses", "Theil", "der", "See\u00b7lig\u00b7keit", "be\u00b7ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Durch andrer Freud und Lust die seine zu vermehren:", "tokens": ["Durch", "an\u00b7drer", "Freud", "und", "Lust", "die", "sei\u00b7ne", "zu", "ver\u00b7meh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "ART", "PPOSAT", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da sich auf solche Weis\u2019, ohn alle Maa\u00df und Zahl,", "tokens": ["Da", "sich", "auf", "sol\u00b7che", "Weis'", ",", "ohn", "al\u00b7le", "Maa\u00df", "und", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPR", "PIAT", "NN", "$,", "KOUI", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vergn\u00fcgungen und Anmuth auf einmahl,", "tokens": ["Ver\u00b7gn\u00fc\u00b7gun\u00b7gen", "und", "An\u00b7muth", "auf", "ein\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "ADV", "$,"], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.10": {"text": "Stat einer einzigen auf dieser Welt,", "tokens": ["Stat", "ei\u00b7ner", "ein\u00b7zi\u00b7gen", "auf", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "APPR", "PDAT", "NN", "$,"], "meter": "-+--+----+", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "In steter F\u00fclle zu uns kehren.", "tokens": ["In", "ste\u00b7ter", "F\u00fcl\u00b7le", "zu", "uns", "keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Ach wenn doch dieser Satz, n\u00e4chst unsrer Glaubens-Lehre,", "tokens": ["Ach", "wenn", "doch", "die\u00b7ser", "Satz", ",", "n\u00e4chst", "uns\u00b7rer", "Glau\u00b7bens\u00b7Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "KOUS", "ADV", "PDAT", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Richtschnur unsers Lebens w\u00e4re!", "tokens": ["Die", "Richt\u00b7schnur", "un\u00b7sers", "Le\u00b7bens", "w\u00e4\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wir w\u00fcrden nicht nur gl\u00fccklich hier allein,", "tokens": ["Wir", "w\u00fcr\u00b7den", "nicht", "nur", "gl\u00fcck\u00b7lich", "hier", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wilt du geliebet seyn, so liebe)", "tokens": ["Wilt", "du", "ge\u00b7lie\u00b7bet", "seyn", ",", "so", "lie\u00b7be", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "VAINF", "$,", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So gar, von vielen S\u00fcnden rein,", "tokens": ["So", "gar", ",", "von", "vie\u00b7len", "S\u00fcn\u00b7den", "rein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "APPR", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auch dort vergn\u00fcget seyn.", "tokens": ["Auch", "dort", "ver\u00b7gn\u00fc\u00b7get", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}