{"textgrid.poem.47921": {"metadata": {"author": {"name": "Rost, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich, der ich sonst geglaubt, da\u00df ich gebohren w\u00e4re", "genre": "verse", "period": "N.A.", "pub_year": 1741, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich, der ich sonst geglaubt, da\u00df ich gebohren w\u00e4re", "tokens": ["Ich", ",", "der", "ich", "sonst", "ge\u00b7glaubt", ",", "da\u00df", "ich", "ge\u00b7boh\u00b7ren", "w\u00e4\u00b7re"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,", "KOUS", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Bachus \u00e4chter Knecht, ein Priester der Cithere,", "tokens": ["Des", "Ba\u00b7chus", "\u00e4ch\u00b7ter", "Knecht", ",", "ein", "Pries\u00b7ter", "der", "Cit\u00b7he\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJA", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Voll, wie Anakreon, starck wie Ovid, zu seyn,", "tokens": ["Voll", ",", "wie", "A\u00b7nak\u00b7re\u00b7on", ",", "starck", "wie", "O\u00b7vid", ",", "zu", "seyn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "NE", "$,", "ADJD", "KOKOM", "NE", "$,", "PTKZU", "VAINF", "$,"], "meter": "+-+---+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Vergesse dieses mahl die Liebe, wie den Wein.", "tokens": ["Ver\u00b7ges\u00b7se", "die\u00b7ses", "mahl", "die", "Lie\u00b7be", ",", "wie", "den", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "ADV", "ART", "NN", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Werck, wodurch ich mich zu den Virgilen schwinge,", "tokens": ["Ein", "Werck", ",", "wo\u00b7durch", "ich", "mich", "zu", "den", "Vir\u00b7gi\u00b7len", "schwin\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist itzt mein Augenmerck. Es sey gewagt! Ich singe.", "tokens": ["Ist", "itzt", "mein", "Au\u00b7gen\u00b7merck", ".", "Es", "sey", "ge\u00b7wagt", "!", "Ich", "sin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "VVPP", "$.", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ich singe von der Frau, die um den Pleissenstrand,", "tokens": ["Ich", "sin\u00b7ge", "von", "der", "Frau", ",", "die", "um", "den", "Pleis\u00b7sen\u00b7strand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den deutschen Harlekin", "tokens": ["Den", "deut\u00b7schen", "Har\u00b7le\u00b7kin"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sich selbst bezwungen hat; die B\u00fchne stets verbessert;", "tokens": ["Sich", "selbst", "be\u00b7zwun\u00b7gen", "hat", ";", "die", "B\u00fch\u00b7ne", "stets", "ver\u00b7bes\u00b7sert", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVPP", "VAFIN", "$.", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kunst, Beyfall und Geschmack, wie ihren Ruhm, vergr\u00f6ssert;", "tokens": ["Kunst", ",", "Bey\u00b7fall", "und", "Ge\u00b7schmack", ",", "wie", "ih\u00b7ren", "Ruhm", ",", "ver\u00b7gr\u00f6s\u00b7sert", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,", "PWAV", "PPOSAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Annens grossen Thron,", "tokens": ["Die", "An\u00b7nens", "gros\u00b7sen", "Thron", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Bi\u00df des M\u00e4cenen Fall sie wieder heim geschickt.", "tokens": ["Bi\u00df", "des", "M\u00e4\u00b7ce\u00b7nen", "Fall", "sie", "wie\u00b7der", "heim", "ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPER", "ADV", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Jedoch ich singe nicht, ihr ganzes Lob zu singen:", "tokens": ["Je\u00b7doch", "ich", "sin\u00b7ge", "nicht", ",", "ihr", "gan\u00b7zes", "Lob", "zu", "sin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PTKNEG", "$,", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die\u00df mag ihr Lebens-Lauff der Nachwelt \u00fcberbringen;", "tokens": ["Die\u00df", "mag", "ihr", "Le\u00b7bens\u00b7Lauff", "der", "Nach\u00b7welt", "\u00fc\u00b7berb\u00b7rin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nur eine That von ihr errett ich aus der Zeit,", "tokens": ["Nur", "ei\u00b7ne", "That", "von", "ihr", "er\u00b7rett", "ich", "aus", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und \u00fcbergebe sie der Unverg\u00e4nglichkeit;", "tokens": ["Und", "\u00fc\u00b7ber\u00b7ge\u00b7be", "sie", "der", "Un\u00b7ver\u00b7g\u00e4ng\u00b7lich\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Den Sieg, doch nicht den Sieg gef\u00fchrter Liebes-Kriege;", "tokens": ["Den", "Sieg", ",", "doch", "nicht", "den", "Sieg", "ge\u00b7f\u00fchr\u00b7ter", "Lie\u00b7bes\u00b7Krie\u00b7ge", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PTKNEG", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ich singe dieses mahl den sch\u00f6nsten ihrer Siege;", "tokens": ["Ich", "sin\u00b7ge", "die\u00b7ses", "mahl", "den", "sch\u00f6ns\u00b7ten", "ih\u00b7rer", "Sie\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "ADV", "ART", "ADJA", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wie sehr ihr Vorspiel-Schertz, den sie selbst ausgedacht,", "tokens": ["Wie", "sehr", "ihr", "Vor\u00b7spiel\u00b7Schertz", ",", "den", "sie", "selbst", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Den hochgebr\u00fcsteten Professor klein gemacht,", "tokens": ["Den", "hoch\u00b7ge\u00b7br\u00fcs\u00b7te\u00b7ten", "Pro\u00b7fes\u00b7sor", "klein", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Zur Lust der Leipziger, so, da\u00df das Volck mit Hauffen,", "tokens": ["Zur", "Lust", "der", "Leip\u00b7zi\u00b7ger", ",", "so", ",", "da\u00df", "das", "Volck", "mit", "Hauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "ADV", "$,", "KOUS", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "In Zotens Hof", "tokens": ["In", "Zo\u00b7tens", "Hof"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NE", "NE"], "meter": "-+-+", "measure": "iambic.di"}, "line.17": {"text": "Da\u00df der Professor gar um Ph\u00f6bus Ausspruch bath,", "tokens": ["Da\u00df", "der", "Pro\u00b7fes\u00b7sor", "gar", "um", "Ph\u00f6\u00b7bus", "Aus\u00b7spruch", "ba\u00b7th", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}, "line.18": {"text": "Den aber doch Apoll, zu Gottscheds Schrecken, that.", "tokens": ["Den", "a\u00b7ber", "doch", "A\u00b7poll", ",", "zu", "Gott\u00b7scheds", "Schre\u00b7cken", ",", "that", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADV", "ADV", "NE", "$,", "APPR", "NE", "NN", "$,", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Ein Strahl, o Neuberin, ein Strahl von deinem Feuer", "tokens": ["Ein", "Strahl", ",", "o", "Neu\u00b7be\u00b7rin", ",", "ein", "Strahl", "von", "dei\u00b7nem", "Feu\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "FM", "NN", "$,", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durchdringe mir das Blut und schein auf meine Leyer!", "tokens": ["Durch\u00b7drin\u00b7ge", "mir", "das", "Blut", "und", "schein", "auf", "mei\u00b7ne", "Le\u00b7yer", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "KON", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.3": {"text": "Der Vorzug deiner Kunst, der Stellung Zauberkrafft", "tokens": ["Der", "Vor\u00b7zug", "dei\u00b7ner", "Kunst", ",", "der", "Stel\u00b7lung", "Zau\u00b7ber\u00b7krafft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sey, da ich singen will, des Ausdrucks Eigenschaft!", "tokens": ["Sey", ",", "da", "ich", "sin\u00b7gen", "will", ",", "des", "Aus\u00b7drucks", "Ei\u00b7gen\u00b7schaft", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Soll mir mein Helden-Lied, wie dir dein Sieg, gelingen:", "tokens": ["Soll", "mir", "mein", "Hel\u00b7den\u00b7Lied", ",", "wie", "dir", "dein", "Sieg", ",", "ge\u00b7lin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "$,", "PWAV", "PPER", "PPOSAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wohlan, so wie du spielst, w\u00fcnsch ich auch mir zu singen!", "tokens": ["Wo\u00b7hlan", ",", "so", "wie", "du", "spielst", ",", "w\u00fcnsch", "ich", "auch", "mir", "zu", "sin\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "KOKOM", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Der Preu\u00dfe, welcher erst die Deutschen deutsch gelehrt;", "tokens": ["Der", "Preu\u00b7\u00dfe", ",", "wel\u00b7cher", "erst", "die", "Deut\u00b7schen", "deutsch", "ge\u00b7lehrt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von welchem Leipzig nie ein falsches Wort geh\u00f6rt,", "tokens": ["Von", "wel\u00b7chem", "Leip\u00b7zig", "nie", "ein", "fal\u00b7sches", "Wort", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NE", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er spr\u00e4che denn Latein; der Hannibal im schreiben,", "tokens": ["Er", "spr\u00e4\u00b7che", "denn", "La\u00b7tein", ";", "der", "Han\u00b7ni\u00b7bal", "im", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "NN", "$.", "ART", "NE", "APPRART", "VVINF", "$,"], "meter": "-+-+++-+-+-+-", "measure": "unknown.measure.septa"}, "line.4": {"text": "Durch dessen Nahmen wir den Franzen schrecklich bleiben;", "tokens": ["Durch", "des\u00b7sen", "Nah\u00b7men", "wir", "den", "Fran\u00b7zen", "schreck\u00b7lich", "blei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Gottsched, welchem oft, als dem Magnificus,", "tokens": ["Der", "Gott\u00b7sched", ",", "wel\u00b7chem", "oft", ",", "als", "dem", "Mag\u00b7ni\u00b7fi\u00b7cus", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Der Oberste des Raths den Vortritt lassen mu\u00df;", "tokens": ["Der", "O\u00b7bers\u00b7te", "des", "Raths", "den", "Vor\u00b7tritt", "las\u00b7sen", "mu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.7": {"text": "Dem, Bayle,", "tokens": ["Dem", ",", "Bay\u00b7le", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["PDS", "$,", "NE", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Zwo Seiten und noch mehr in seinem G. verg\u00f6nnte,", "tokens": ["Zwo", "Sei\u00b7ten", "und", "noch", "mehr", "in", "sei\u00b7nem", "G.", "ver\u00b7g\u00f6nn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation", "word", "punct"], "pos": ["CARD", "NN", "KON", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Der nimmt sich v\u00e4terlich der deutschen B\u00fchnen an,", "tokens": ["Der", "nimmt", "sich", "v\u00e4\u00b7ter\u00b7lich", "der", "deut\u00b7schen", "B\u00fch\u00b7nen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADJD", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und hats dem Hallmann", "tokens": ["Und", "hats", "dem", "Hall\u00b7mann"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Ja selbst Victoria, die ihn, als Gattin, k\u00fcsset;", "tokens": ["Ja", "selbst", "Vic\u00b7to\u00b7ria", ",", "die", "ihn", ",", "als", "Gat\u00b7tin", ",", "k\u00fcs\u00b7set", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "ADV", "NE", "$,", "PRELS", "PPER", "$,", "KOUS", "NN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Vier Sprachen schreibt und spricht, und wie ein Leibnitz schl\u00fcsset,", "tokens": ["Vier", "Spra\u00b7chen", "schreibt", "und", "spricht", ",", "und", "wie", "ein", "Leib\u00b7nitz", "schl\u00fcs\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "KON", "VVFIN", "$,", "KON", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Hat sich nebst ihm bem\u00fcht, und es so weit gebracht,", "tokens": ["Hat", "sich", "nebst", "ihm", "be\u00b7m\u00fcht", ",", "und", "es", "so", "weit", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "APPR", "PPER", "VVFIN", "$,", "KON", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.14": {"text": "Da\u00df unser Schauplatz selbst die Franzen neidisch macht.", "tokens": ["Da\u00df", "un\u00b7ser", "Schau\u00b7platz", "selbst", "die", "Fran\u00b7zen", "nei\u00b7disch", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Man giebt der Neuberin, rein-\u00fcbersetzte St\u00fccke;", "tokens": ["Man", "giebt", "der", "Neu\u00b7be\u00b7rin", ",", "rein\u00b7\u00fcber\u00b7setz\u00b7te", "St\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Theilt selbst die Rollen aus: lehrt Stellung, Minen, Blicke;", "tokens": ["Theilt", "selbst", "die", "Rol\u00b7len", "aus", ":", "lehrt", "Stel\u00b7lung", ",", "Mi\u00b7nen", ",", "Bli\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKVZ", "$.", "VVFIN", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Sie dancket und gehorcht, zieht doppelten Gewinn:", "tokens": ["Sie", "dan\u00b7cket", "und", "ge\u00b7horcht", ",", "zieht", "dop\u00b7pel\u00b7ten", "Ge\u00b7winn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVPP", "$,", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.18": {"text": "Wer den Professor h\u00f6rt, geht auch zur Neuberin.", "tokens": ["Wer", "den", "Pro\u00b7fes\u00b7sor", "h\u00f6rt", ",", "geht", "auch", "zur", "Neu\u00b7be\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Thalia, die du hast den Streit voraus gesehen,", "tokens": ["Tha\u00b7lia", ",", "die", "du", "hast", "den", "Streit", "vo\u00b7raus", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPER", "VAFIN", "ART", "NN", "PTKVZ", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Was konnte, sag es mir, Victorien geschehen,", "tokens": ["Was", "konn\u00b7te", ",", "sag", "es", "mir", ",", "Vic\u00b7to\u00b7ri\u00b7en", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "$,", "VVFIN", "PPER", "PPER", "$,", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df sie aus Rache schwur: Geht auch der Schauplatz ein,", "tokens": ["Da\u00df", "sie", "aus", "Ra\u00b7che", "schwur", ":", "Geht", "auch", "der", "Schau\u00b7platz", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$.", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "So wahr die Gomez", "tokens": ["So", "wahr", "die", "Go\u00b7mez"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Thalia, noch einmahl: Wodurch ward Gottsched hitzig?", "tokens": ["Tha\u00b7lia", ",", "noch", "ein\u00b7mahl", ":", "Wo\u00b7durch", "ward", "Gott\u00b7sched", "hit\u00b7zig", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "ADV", "$.", "PWAV", "VAFIN", "NE", "ADJD", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Er schrieh; die Neuberin wird warlich aberwitzig.", "tokens": ["Er", "schrieh", ";", "die", "Neu\u00b7be\u00b7rin", "wird", "war\u00b7lich", "a\u00b7berw\u00b7it\u00b7zig", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was hat, entdecke mirs, die gute Frau ver\u00fcbt?", "tokens": ["Was", "hat", ",", "ent\u00b7de\u00b7cke", "mirs", ",", "die", "gu\u00b7te", "Frau", "ver\u00b7\u00fcbt", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "VVFIN", "NE", "$,", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auf einmahl ha\u00dft er sie mehr, als er sie geliebt.", "tokens": ["Auf", "ein\u00b7mahl", "ha\u00dft", "er", "sie", "mehr", ",", "als", "er", "sie", "ge\u00b7liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$,", "KOUS", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Der d\u00fcrre Neid, der Geist de M\u00fcllerischen Bande,", "tokens": ["Der", "d\u00fcr\u00b7re", "Neid", ",", "der", "Geist", "de", "M\u00fcl\u00b7le\u00b7ri\u00b7schen", "Ban\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "NE", "NE", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Schwur l\u00e4ngst der Neuberin Fall, Banckerot und Schande.", "tokens": ["Schwur", "l\u00e4ngst", "der", "Neu\u00b7be\u00b7rin", "Fall", ",", "Ban\u00b7cke\u00b7rot", "und", "Schan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er hatte schon den Gift dreymahl nach ihr gespritzt,", "tokens": ["Er", "hat\u00b7te", "schon", "den", "Gift", "drey\u00b7mahl", "nach", "ihr", "ge\u00b7spritzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Doch von der Schauspielkunst ward sie dreymahl besch\u00fctzt.", "tokens": ["Doch", "von", "der", "Schau\u00b7spiel\u00b7kunst", "ward", "sie", "drey\u00b7mahl", "be\u00b7sch\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "---+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Jetzt schwur er noch einmahl bey seinen Schlangen-Haaren:", "tokens": ["Jetzt", "schwur", "er", "noch", "ein\u00b7mahl", "bey", "sei\u00b7nen", "Schlan\u00b7gen\u00b7Haa\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u00bbda sie der Macht entweicht, soll sie die List erfahren!\u00ab", "tokens": ["\u00bb", "da", "sie", "der", "Macht", "ent\u00b7weicht", ",", "soll", "sie", "die", "List", "er\u00b7fah\u00b7ren", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VMFIN", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Nattern z\u00fcngelten, er sch\u00e4rffte sich den Zahn,", "tokens": ["Die", "Nat\u00b7tern", "z\u00fcn\u00b7gel\u00b7ten", ",", "er", "sch\u00e4rff\u00b7te", "sich", "den", "Zahn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und trat sogleich den Weg nach Gottscheds Wohnung an.", "tokens": ["Und", "trat", "sog\u00b7leich", "den", "Weg", "nach", "Gott\u00b7scheds", "Woh\u00b7nung", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "APPR", "NE", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Bi\u00df in den H\u00f6rsaal war der Neid, als Neid, gekommen;", "tokens": ["Bi\u00df", "in", "den", "H\u00f6r\u00b7saal", "war", "der", "Neid", ",", "als", "Neid", ",", "ge\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "VAFIN", "ART", "NN", "$,", "KOUS", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Allein itzt ward sein Werck mit Arglist unternommen,", "tokens": ["Al\u00b7lein", "itzt", "ward", "sein", "Werck", "mit", "Arg\u00b7list", "un\u00b7ter\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Darum verwandelte des Gl\u00fcckes Affter-Sohn", "tokens": ["Da\u00b7rum", "ver\u00b7wan\u00b7del\u00b7te", "des", "Gl\u00fc\u00b7ckes", "Aff\u00b7ter\u00b7Sohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sich, vor der Stube noch, und wurde zum Baron.", "tokens": ["Sich", ",", "vor", "der", "Stu\u00b7be", "noch", ",", "und", "wur\u00b7de", "zum", "Ba\u00b7ron", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "$,", "APPR", "ART", "NN", "ADV", "$,", "KON", "VAFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Hier sa\u00df Victoria auf ihrem Polster-Stuhle,", "tokens": ["Hier", "sa\u00df", "Vic\u00b7to\u00b7ria", "auf", "ih\u00b7rem", "Pols\u00b7ter\u00b7Stuh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Mit Ungeduld erf\u00fcllt, da\u00df ihre Feder-Spule", "tokens": ["Mit", "Un\u00b7ge\u00b7duld", "er\u00b7f\u00fcllt", ",", "da\u00df", "ih\u00b7re", "Fe\u00b7der\u00b7Spu\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "VVPP", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Uebersetzungen zu sparsam fliessen lie\u00df,", "tokens": ["Die", "Ue\u00b7ber\u00b7set\u00b7zun\u00b7gen", "zu", "spar\u00b7sam", "flies\u00b7sen", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKA", "ADJD", "VVINF", "VVFIN", "$,"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und sich nach Gottscheds Wunsch nicht fix genug erwie\u00df.", "tokens": ["Und", "sich", "nach", "Gott\u00b7scheds", "Wunsch", "nicht", "fix", "ge\u00b7nug", "er\u00b7wie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "NE", "NN", "PTKNEG", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gleich diesen Augenblick trat der Baron ins Zimmer,", "tokens": ["Gleich", "die\u00b7sen", "Au\u00b7gen\u00b7blick", "trat", "der", "Ba\u00b7ron", "ins", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und f\u00fcr die Neuberin war dieses desto schlimmer.", "tokens": ["Und", "f\u00fcr", "die", "Neu\u00b7be\u00b7rin", "war", "die\u00b7ses", "des\u00b7to", "schlim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "PDAT", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u00bbfrau! sprach er, die du selbst der Silphen Reich verdienst;", "tokens": ["\u00bb", "frau", "!", "sprach", "er", ",", "die", "du", "selbst", "der", "Sil\u00b7phen", "Reich", "ver\u00b7dienst", ";"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$.", "VVFIN", "PPER", "$,", "PRELS", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie eine Sapho singst, wie eine Daphne gr\u00fcnst;", "tokens": ["Wie", "ei\u00b7ne", "Sa\u00b7pho", "singst", ",", "wie", "ei\u00b7ne", "Daph\u00b7ne", "gr\u00fcnst", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du Ubersetzerin der g\u00f6ttlichen Alzire,", "tokens": ["Du", "Ub\u00b7er\u00b7set\u00b7ze\u00b7rin", "der", "g\u00f6tt\u00b7li\u00b7chen", "Al\u00b7zi\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein freches Weib verletzt die wiederhohlten Schw\u00fcre;", "tokens": ["Ein", "fre\u00b7ches", "Weib", "ver\u00b7letzt", "die", "wie\u00b7der\u00b7hohl\u00b7ten", "Schw\u00fc\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Alzire ward gespielt, von iedem hoch gesch\u00e4tzt,", "tokens": ["Al\u00b7zi\u00b7re", "ward", "ge\u00b7spielt", ",", "von", "ie\u00b7dem", "hoch", "ge\u00b7sch\u00e4tzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "VVPP", "$,", "APPR", "PIAT", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und auf dem Zettel stund: von St\u00fcven \u00fcbersetzt.", "tokens": ["Und", "auf", "dem", "Zet\u00b7tel", "stund", ":", "von", "St\u00fc\u00b7ven", "\u00fc\u00b7bers\u00b7etzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$.", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Hei\u00dft dieses kein Betrug, so wird kein Mensch betrogen;", "tokens": ["Hei\u00dft", "die\u00b7ses", "kein", "Be\u00b7trug", ",", "so", "wird", "kein", "Mensch", "be\u00b7tro\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "PIAT", "NN", "$,", "ADV", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Dir? St\u00fcven gleich gestellt?", "tokens": ["Dir", "?", "St\u00fc\u00b7ven", "gleich", "ge\u00b7stellt", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Ist wohl die Neuberin noch eures Schutzes werth?", "tokens": ["Ist", "wohl", "die", "Neu\u00b7be\u00b7rin", "noch", "eu\u00b7res", "Schut\u00b7zes", "werth", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wenn dein Gemahl mit ihr nicht die\u00dfmahl scharf verf\u00e4hrt;", "tokens": ["Wenn", "dein", "Ge\u00b7mahl", "mit", "ihr", "nicht", "die\u00df\u00b7mahl", "scharf", "ver\u00b7f\u00e4hrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "PPER", "PTKNEG", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So wird sie k\u00fcnfftig gar, Victorien zu qu\u00e4hlen,", "tokens": ["So", "wird", "sie", "k\u00fcnff\u00b7tig", "gar", ",", "Vic\u00b7to\u00b7ri\u00b7en", "zu", "qu\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ADV", "$,", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Die Uebersetzungen der Nieder-Sachsen w\u00e4hlen.\u00ab", "tokens": ["Die", "Ue\u00b7ber\u00b7set\u00b7zun\u00b7gen", "der", "Nie\u00b7der\u00b7Sach\u00b7sen", "w\u00e4h\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.19": {"text": "Hier k\u00fcssete der Neid der grossen Frau die Hand;", "tokens": ["Hier", "k\u00fcs\u00b7se\u00b7te", "der", "Neid", "der", "gros\u00b7sen", "Frau", "die", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ward, an der Th\u00fcre noch, zweymahl Baron genannt;", "tokens": ["Ward", ",", "an", "der", "Th\u00fc\u00b7re", "noch", ",", "zwey\u00b7mahl", "Ba\u00b7ron", "ge\u00b7nannt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "APPR", "ART", "NN", "ADV", "$,", "ADV", "NN", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Gieng, freute sich der List, und schickt im Augenblicke,", "tokens": ["Gieng", ",", "freu\u00b7te", "sich", "der", "List", ",", "und", "schickt", "im", "Au\u00b7gen\u00b7bli\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PRF", "ART", "NN", "$,", "KON", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die Schwester des Betrugs, die Eifersucht, zur\u00fccke.", "tokens": ["Die", "Schwes\u00b7ter", "des", "Be\u00b7trugs", ",", "die", "Ei\u00b7fer\u00b7sucht", ",", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sie fand Victorien gantz anders als der Neid:", "tokens": ["Sie", "fand", "Vic\u00b7to\u00b7ri\u00b7en", "gantz", "an\u00b7ders", "als", "der", "Neid", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADV", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Der Kulmus Auge sah erbittert und zerstreut;", "tokens": ["Der", "Kul\u00b7mus", "Au\u00b7ge", "sah", "er\u00b7bit\u00b7tert", "und", "zer\u00b7streut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ADJD", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Mit knirschen druckte sie den kleinen Mund zusammen;", "tokens": ["Mit", "knir\u00b7schen", "druck\u00b7te", "sie", "den", "klei\u00b7nen", "Mund", "zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Ihr Athem war ein Hauch, so hei\u00df als Feuer-Flammen;", "tokens": ["Ihr", "A\u00b7them", "war", "ein", "Hauch", ",", "so", "hei\u00df", "als", "Feu\u00b7er\u00b7Flam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$,", "ADV", "ADJD", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Drum hielt die Eifersucht, eh sich der Zorn verlohr,", "tokens": ["Drum", "hielt", "die", "Ei\u00b7fer\u00b7sucht", ",", "eh", "sich", "der", "Zorn", "ver\u00b7lohr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "$,", "KOUS", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ihr das Vergr\u00f6\u00dfrungs-Gla\u00df zur rechten Stunde vor.", "tokens": ["Ihr", "das", "Ver\u00b7gr\u00f6\u00df\u00b7rungs\u00b7Gla\u00df", "zur", "rech\u00b7ten", "Stun\u00b7de", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Hierwieder konnte sich die Neuberin nicht sch\u00fctzen:", "tokens": ["Hier\u00b7wie\u00b7der", "konn\u00b7te", "sich", "die", "Neu\u00b7be\u00b7rin", "nicht", "sch\u00fct\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PRF", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Die wilde G\u00f6ttin will Victorien erhitzen,", "tokens": ["Die", "wil\u00b7de", "G\u00f6t\u00b7tin", "will", "Vic\u00b7to\u00b7ri\u00b7en", "er\u00b7hit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Und, da die Wahrheit nicht hierzu beh\u00fclflich ist,", "tokens": ["Und", ",", "da", "die", "Wahr\u00b7heit", "nicht", "hier\u00b7zu", "be\u00b7h\u00fcl\u00b7flich", "ist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "PTKNEG", "PAV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "So greift sie zum Crystall und w\u00e4hlt Betrug und List;", "tokens": ["So", "greift", "sie", "zum", "Crys\u00b7tall", "und", "w\u00e4hlt", "Be\u00b7trug", "und", "List", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "KON", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "So hilfft die M\u00f6glichkeit, so hilfft der Schein betr\u00fcgen;", "tokens": ["So", "hilfft", "die", "M\u00f6g\u00b7lich\u00b7keit", ",", "so", "hilfft", "der", "Schein", "be\u00b7tr\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "So mahlt die Eifersucht ein Bild mit falschen Z\u00fcgen.", "tokens": ["So", "mahlt", "die", "Ei\u00b7fer\u00b7sucht", "ein", "Bild", "mit", "fal\u00b7schen", "Z\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Ihr Spiegel bildet nie die Wahrheit blo\u00df und rein;", "tokens": ["Ihr", "Spie\u00b7gel", "bil\u00b7det", "nie", "die", "Wahr\u00b7heit", "blo\u00df", "und", "rein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN", "ADV", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Was klein ist, macht er gro\u00df, was gro\u00df ist, macht er klein.", "tokens": ["Was", "klein", "ist", ",", "macht", "er", "gro\u00df", ",", "was", "gro\u00df", "ist", ",", "macht", "er", "klein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "VVFIN", "PPER", "ADJD", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Drum konnt er leicht auch hier ein Blendwerck zubereiten:", "tokens": ["Drum", "konnt", "er", "leicht", "auch", "hier", "ein", "Blend\u00b7werck", "zu\u00b7be\u00b7rei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADJD", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Es sah Victoria Gottscheds Magister-Zeiten;", "tokens": ["Es", "sah", "Vic\u00b7to\u00b7ria", "Gott\u00b7scheds", "Ma\u00b7gis\u00b7ter\u00b7Zei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NE", "NN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.39": {"text": "Bey ihm die Neuberin, weit reizender geschm\u00fcckt,", "tokens": ["Bey", "ihm", "die", "Neu\u00b7be\u00b7rin", ",", "weit", "rei\u00b7zen\u00b7der", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "$,", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Als f\u00fcr ein h\u00e4u\u00dflich Weib sichs sonst im Hause schickt.", "tokens": ["Als", "f\u00fcr", "ein", "h\u00e4u\u00df\u00b7lich", "Weib", "sichs", "sonst", "im", "Hau\u00b7se", "schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJD", "NN", "PIS", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Es ging, und wer? genug, es ging iemand nach Weine;", "tokens": ["Es", "ging", ",", "und", "wer", "?", "ge\u00b7nug", ",", "es", "ging", "ie\u00b7mand", "nach", "Wei\u00b7ne", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "PWS", "$.", "ADV", "$,", "PPER", "VVFIN", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.42": {"text": "Mit dem Magister blieb die Neuberin alleine.", "tokens": ["Mit", "dem", "Ma\u00b7gis\u00b7ter", "blieb", "die", "Neu\u00b7be\u00b7rin", "al\u00b7lei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Kurtz, durch das falsche Bild von der Magister-Zeit", "tokens": ["Kurtz", ",", "durch", "das", "fal\u00b7sche", "Bild", "von", "der", "Ma\u00b7gis\u00b7ter\u00b7Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "APPR", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Verlohr Victorie Kraft und Gelassenheit.", "tokens": ["Ver\u00b7lohr", "Vic\u00b7to\u00b7rie", "Kraft", "und", "Ge\u00b7las\u00b7sen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.45": {"text": "Sie \u00f6ffnete den Mund, ich wei\u00df nicht was, zu sprechen;", "tokens": ["Sie", "\u00f6ff\u00b7ne\u00b7te", "den", "Mund", ",", "ich", "wei\u00df", "nicht", "was", ",", "zu", "spre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PTKNEG", "PIS", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Doch Schwindel, Uebelkeit und hefftig Seitenstechen,", "tokens": ["Doch", "Schwin\u00b7del", ",", "Ue\u00b7bel\u00b7keit", "und", "heff\u00b7tig", "Sei\u00b7ten\u00b7ste\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Erlaubten ihr noch kaum ein kl\u00e4glich: Ach Herr Je \u2013 \u2013!", "tokens": ["Er\u00b7laub\u00b7ten", "ihr", "noch", "kaum", "ein", "kl\u00e4g\u00b7lich", ":", "Ach", "Herr", "Je", "\u2013", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "ADJD", "$.", "ITJ", "NN", "ADV", "$(", "$(", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Sie sprach das Wort nur halb, und fiel aufs Cannape.", "tokens": ["Sie", "sprach", "das", "Wort", "nur", "halb", ",", "und", "fiel", "aufs", "Can\u00b7na\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ADJD", "$,", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Die M\u00e4gde liefen zu, sie klagte Seitenschmertzen;", "tokens": ["Die", "M\u00e4g\u00b7de", "lie\u00b7fen", "zu", ",", "sie", "klag\u00b7te", "Sei\u00b7ten\u00b7schmert\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Die alte K\u00f6chin scherzt, als w\u00e4r es Zeit zu scherzen:", "tokens": ["Die", "al\u00b7te", "K\u00f6\u00b7chin", "scherzt", ",", "als", "w\u00e4r", "es", "Zeit", "zu", "scher\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KOKOM", "VAFIN", "PPER", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "\u00bbes ist ein Schmerzen-Sohn, ja, Frau Professorin,", "tokens": ["\u00bb", "es", "ist", "ein", "Schmer\u00b7zen\u00b7Sohn", ",", "ja", ",", "Frau", "Pro\u00b7fes\u00b7so\u00b7rin", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "PTKANT", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Man tauf ihn wie man will, ich hei\u00df ihn Benjamin.\u00ab", "tokens": ["Man", "tauf", "ihn", "wie", "man", "will", ",", "ich", "hei\u00df", "ihn", "Ben\u00b7ja\u00b7min", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PWAV", "PIS", "VMFIN", "$,", "PPER", "ADJD", "PPER", "NE", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Der schlaue Diener stund, und horchte vor der Th\u00fcre;", "tokens": ["Der", "schlau\u00b7e", "Die\u00b7ner", "stund", ",", "und", "horch\u00b7te", "vor", "der", "Th\u00fc\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Wenn, dacht er, die\u00df mein Herr von mir zuerst erf\u00fchre:", "tokens": ["Wenn", ",", "dacht", "er", ",", "die\u00df", "mein", "Herr", "von", "mir", "zu\u00b7erst", "er\u00b7f\u00fch\u00b7re", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "VVFIN", "PPER", "$,", "PDS", "PPOSAT", "NN", "APPR", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "So w\u00fcrde wenigstens doch ein Ducaten mein,", "tokens": ["So", "w\u00fcr\u00b7de", "we\u00b7nigs\u00b7tens", "doch", "ein", "Du\u00b7ca\u00b7ten", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ART", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Und der Professor froh, und ich zufrieden, seyn.", "tokens": ["Und", "der", "Pro\u00b7fes\u00b7sor", "froh", ",", "und", "ich", "zu\u00b7frie\u00b7den", ",", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "$,", "KON", "PPER", "ADJD", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Auf dieses spitzte sich der Ausbund von den Dienern,", "tokens": ["Auf", "die\u00b7ses", "spitz\u00b7te", "sich", "der", "Aus\u00b7bund", "von", "den", "Die\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.58": {"text": "Und flog mehr, als er ging, ins Kloster zun Paulinern,", "tokens": ["Und", "flog", "mehr", ",", "als", "er", "ging", ",", "ins", "Klos\u00b7ter", "zun", "Pau\u00b7li\u00b7nern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,", "APPRART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Wo der Professor sa\u00df, und gleich recht magnific,", "tokens": ["Wo", "der", "Pro\u00b7fes\u00b7sor", "sa\u00df", ",", "und", "gleich", "recht", "mag\u00b7ni\u00b7fic", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,", "KON", "ADV", "ADV", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Die\u00dfmahl dem Syndikus kein einzig Wort verschwieg.", "tokens": ["Die\u00df\u00b7mahl", "dem", "Syn\u00b7di\u00b7kus", "kein", "ein\u00b7zig", "Wort", "ver\u00b7schwieg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PIAT", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Was nun der frohe Knecht durchs Schl\u00fcsselloch gesehen,", "tokens": ["Was", "nun", "der", "fro\u00b7he", "Knecht", "durchs", "Schl\u00fcs\u00b7sel\u00b7loch", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Sagt er dem Herrn ins Ohr, ja mehr noch, als geschehen;", "tokens": ["Sagt", "er", "dem", "Herrn", "ins", "Ohr", ",", "ja", "mehr", "noch", ",", "als", "ge\u00b7sche\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$,", "ADV", "ADV", "ADV", "$,", "KOUS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Und lief, sein Herr befohls, dem er nie wiedersprach,", "tokens": ["Und", "lief", ",", "sein", "Herr", "be\u00b7fohls", ",", "dem", "er", "nie", "wie\u00b7der\u00b7sprach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPOSAT", "NN", "NE", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.64": {"text": "Sogleich voran zur\u00fcck, die\u00dfmahl ihm Gottsched nach.", "tokens": ["Sog\u00b7leich", "vo\u00b7ran", "zu\u00b7r\u00fcck", ",", "die\u00df\u00b7mahl", "ihm", "Gott\u00b7sched", "nach", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$,", "KOUS", "PPER", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Der weit gespaltne Herr erreichte bald das Zimmer;", "tokens": ["Der", "weit", "ge\u00b7spalt\u00b7ne", "Herr", "er\u00b7reich\u00b7te", "bald", "das", "Zim\u00b7mer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Er sah Victorien, sie ihn, die Noth ward schlimmer.", "tokens": ["Er", "sah", "Vic\u00b7to\u00b7ri\u00b7en", ",", "sie", "ihn", ",", "die", "Noth", "ward", "schlim\u00b7mer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$,", "PPER", "PPER", "$,", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Wie? half der Anblick nicht, da\u00df sie den Schmertz verga\u00df?", "tokens": ["Wie", "?", "half", "der", "An\u00b7blick", "nicht", ",", "da\u00df", "sie", "den", "Schmertz", "ver\u00b7ga\u00df", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "ART", "NN", "PTKNEG", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "O nein! sie dachte noch an das Vergr\u00f6\u00dfrungs-Gla\u00df.", "tokens": ["O", "nein", "!", "sie", "dach\u00b7te", "noch", "an", "das", "Ver\u00b7gr\u00f6\u00df\u00b7rungs\u00b7Gla\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$.", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.69": {"text": "Was war sein erstes Wort? geduldig, meine Sch\u00f6ne!", "tokens": ["Was", "war", "sein", "ers\u00b7tes", "Wort", "?", "ge\u00b7dul\u00b7dig", ",", "mei\u00b7ne", "Sch\u00f6\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "ADJA", "NN", "$.", "ADJD", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "\u00bbso leicht geb\u00e4hrt man nicht gelehrter M\u00e4nner S\u00f6hne:", "tokens": ["\u00bb", "so", "leicht", "ge\u00b7b\u00e4hrt", "man", "nicht", "ge\u00b7lehr\u00b7ter", "M\u00e4n\u00b7ner", "S\u00f6h\u00b7ne", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "VVFIN", "PIS", "PTKNEG", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Es schmerzete das Haupt den Zevs drey Monden lang,", "tokens": ["Es", "schmer\u00b7ze\u00b7te", "das", "Haupt", "den", "Zevs", "drey", "Mon\u00b7den", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NE", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Bevor Tritonia aus seiner Stirne sprang.\u00ab", "tokens": ["Be\u00b7vor", "Tri\u00b7to\u00b7nia", "aus", "sei\u00b7ner", "Stir\u00b7ne", "sprang", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.73": {"text": "Hierauf gab er Befehl, mehr Frauen her zu holen.", "tokens": ["Hier\u00b7auf", "gab", "er", "Be\u00b7fehl", ",", "mehr", "Frau\u00b7en", "her", "zu", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "NN", "$,", "PIAT", "NN", "APZR", "PTKZU", "VVINF", "$."], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.74": {"text": "Nein! schrieh Victoria, viel lieber anbefohlen,", "tokens": ["Nein", "!", "schrieh", "Vic\u00b7to\u00b7ria", ",", "viel", "lie\u00b7ber", "an\u00b7be\u00b7foh\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "VVFIN", "NE", "$,", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.75": {"text": "Da\u00df dieser M\u00e4gdeschwarm aus meinem Zimmer eilt,", "tokens": ["Da\u00df", "die\u00b7ser", "M\u00e4g\u00b7de\u00b7schwarm", "aus", "mei\u00b7nem", "Zim\u00b7mer", "eilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Weil sonst mein Mund mit dir nicht sein Geheimni\u00df theilt.", "tokens": ["Weil", "sonst", "mein", "Mund", "mit", "dir", "nicht", "sein", "Ge\u00b7heim\u00b7ni\u00df", "theilt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "APPR", "PPER", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Die M\u00e4gde gingen fort, das Zimmer ward verschlossen,", "tokens": ["Die", "M\u00e4g\u00b7de", "gin\u00b7gen", "fort", ",", "das", "Zim\u00b7mer", "ward", "ver\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Doch aussen stunden sie und horcheten zum Possen.", "tokens": ["Doch", "aus\u00b7sen", "stun\u00b7den", "sie", "und", "hor\u00b7che\u00b7ten", "zum", "Pos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIZU", "VVFIN", "PPER", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "\u00bbgeliebter!\u00ab sprach nunmehr die kluge Gottschedin,", "tokens": ["\u00bb", "ge\u00b7lieb\u00b7ter", "!", "\u00ab", "sprach", "nun\u00b7mehr", "die", "klu\u00b7ge", "Gott\u00b7sche\u00b7din", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "$.", "$(", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "\u00bbwofern ich deiner Gunst nicht werth gewesen bin,", "tokens": ["\u00bb", "wo\u00b7fern", "ich", "dei\u00b7ner", "Gunst", "nicht", "werth", "ge\u00b7we\u00b7sen", "bin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "ADJD", "VAPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Was nanntst du mich", "tokens": ["Was", "nanntst", "du", "mich"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PRF"], "meter": "-+-+", "measure": "iambic.di"}, "line.82": {"text": "Ein seltnes Meisterst\u00fcck von Witz, Verstand und Tugend?", "tokens": ["Ein", "selt\u00b7nes", "Meis\u00b7ter\u00b7st\u00fcck", "von", "Witz", ",", "Ver\u00b7stand", "und", "Tu\u00b7gend", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Der K\u00fcnste Sammel-Platz, dein Leben und dein Licht?", "tokens": ["Der", "K\u00fcns\u00b7te", "Sam\u00b7mel\u00b7Platz", ",", "dein", "Le\u00b7ben", "und", "dein", "Licht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Warum besannst du dich noch in Sechs Jahren nicht?", "tokens": ["Wa\u00b7rum", "be\u00b7sannst", "du", "dich", "noch", "in", "Sechs", "Jah\u00b7ren", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "ADV", "APPR", "CARD", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Und warum g\u00f6nntest du mich nicht dem Weichselstrande?", "tokens": ["Und", "wa\u00b7rum", "g\u00f6nn\u00b7test", "du", "mich", "nicht", "dem", "Weich\u00b7sel\u00b7stran\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "PRF", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Hier leb ich mir zur Last und deinem Ruhm zur Schande:", "tokens": ["Hier", "leb", "ich", "mir", "zur", "Last", "und", "dei\u00b7nem", "Ruhm", "zur", "Schan\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPRART", "NN", "KON", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Die stoltze Neuberin hat mich und dich verletzt;", "tokens": ["Die", "stolt\u00b7ze", "Neu\u00b7be\u00b7rin", "hat", "mich", "und", "dich", "ver\u00b7letzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "KON", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Hat mich, o Frevelthat! noch St\u00fcven nachgesetzt.", "tokens": ["Hat", "mich", ",", "o", "Fre\u00b7vel\u00b7that", "!", "noch", "St\u00fc\u00b7ven", "nach\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "FM", "NN", "$.", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Da wir Alziren gar zur Niedersachsin machen.", "tokens": ["Da", "wir", "Al\u00b7zi\u00b7ren", "gar", "zur", "Nie\u00b7der\u00b7sac\u00b7hsin", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Ich habe selbst die\u00df Spiel ins reinste deutsch gebracht,", "tokens": ["Ich", "ha\u00b7be", "selbst", "die\u00df", "Spiel", "ins", "reins\u00b7te", "deutsch", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PDS", "NN", "APPRART", "ADJA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Der neunmahl klugen ists dennoch nicht recht gemacht.", "tokens": ["Der", "neun\u00b7mahl", "klu\u00b7gen", "ists", "den\u00b7noch", "nicht", "recht", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "VAFIN", "ADV", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Du ausversch\u00e4mtes Weib! du wirst mich schreiben lehren;", "tokens": ["Du", "aus\u00b7ver\u00b7sch\u00e4m\u00b7tes", "Weib", "!", "du", "wirst", "mich", "schrei\u00b7ben", "leh\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$.", "PPER", "VAFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "K\u00f6nnt ihr, dein Vers und du, wohl unsrer Huld entbehren?", "tokens": ["K\u00f6nnt", "ihr", ",", "dein", "Vers", "und", "du", ",", "wohl", "uns\u00b7rer", "Huld", "ent\u00b7beh\u00b7ren", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "PPOSAT", "NN", "KON", "PPER", "$,", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Wir sprachen; werde gro\u00df! durch uns, durch uns allein,", "tokens": ["Wir", "spra\u00b7chen", ";", "wer\u00b7de", "gro\u00df", "!", "durch", "uns", ",", "durch", "uns", "al\u00b7lein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VAFIN", "ADJD", "$.", "APPR", "PPER", "$,", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Erhob sich deine Kunst: Nun werd auch wieder klein!", "tokens": ["Er\u00b7hob", "sich", "dei\u00b7ne", "Kunst", ":", "Nun", "werd", "auch", "wie\u00b7der", "klein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "$.", "ADV", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Giebt uns nur Sch\u00f6nemann", "tokens": ["Giebt", "uns", "nur", "Sch\u00f6\u00b7ne\u00b7mann"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.97": {"text": "So k\u00f6nnen wir auch ihn in unsern Schrifften loben.", "tokens": ["So", "k\u00f6n\u00b7nen", "wir", "auch", "ihn", "in", "un\u00b7sern", "Schriff\u00b7ten", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Geliebter! hat dein Hertz mich mit Bedacht erw\u00e4hlt;", "tokens": ["Ge\u00b7lieb\u00b7ter", "!", "hat", "dein", "Hertz", "mich", "mit", "Be\u00b7dacht", "er\u00b7w\u00e4hlt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VAFIN", "PPOSAT", "NN", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Hat halb Germanien", "tokens": ["Hat", "halb", "Ger\u00b7ma\u00b7ni\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ADJD", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.100": {"text": "Gabst du, mit Recht, dir M\u00fch, die Kulmus zu gewinnen;", "tokens": ["Gabst", "du", ",", "mit", "Recht", ",", "dir", "M\u00fch", ",", "die", "Kul\u00b7mus", "zu", "ge\u00b7win\u00b7nen", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "NN", "$,", "PPER", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Beschimpft mein Nahme nicht dich und die Tadlerinnen;", "tokens": ["Be\u00b7schimpft", "mein", "Nah\u00b7me", "nicht", "dich", "und", "die", "Tad\u00b7le\u00b7rin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "PPER", "KON", "ART", "NN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.102": {"text": "So zeige, da\u00df auch ich dir purpurheilig bin,", "tokens": ["So", "zei\u00b7ge", ",", "da\u00df", "auch", "ich", "dir", "pur\u00b7pur\u00b7hei\u00b7lig", "bin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "ADV", "PPER", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Und straf und z\u00fcchtige die wilde Neuberin.", "tokens": ["Und", "straf", "und", "z\u00fcch\u00b7ti\u00b7ge", "die", "wil\u00b7de", "Neu\u00b7be\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Allein, erlaubst du ihr Victorien zu kr\u00e4ncken:", "tokens": ["Al\u00b7lein", ",", "er\u00b7laubst", "du", "ihr", "Vic\u00b7to\u00b7ri\u00b7en", "zu", "kr\u00e4n\u00b7cken", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Was meinst du, da\u00df ich soll von deiner Sanftmuth dencken?\u00ab", "tokens": ["Was", "meinst", "du", ",", "da\u00df", "ich", "soll", "von", "dei\u00b7ner", "Sanft\u00b7muth", "den\u00b7cken", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "So hertzhafft, als kaum je die kluge Porzia,", "tokens": ["So", "hertz\u00b7hafft", ",", "als", "kaum", "je", "die", "klu\u00b7ge", "Por\u00b7zia", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "ADV", "ADV", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.107": {"text": "Den Brutus angeredt, sprach hier Victoria.", "tokens": ["Den", "Bru\u00b7tus", "an\u00b7ge\u00b7redt", ",", "sprach", "hier", "Vic\u00b7to\u00b7ria", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVPP", "$,", "VVFIN", "ADV", "NE", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.108": {"text": "Ein sch\u00f6ner Mund wirckt mehr als eine G\u00f6tter-Stimme;", "tokens": ["Ein", "sch\u00f6\u00b7ner", "Mund", "wirckt", "mehr", "als", "ei\u00b7ne", "G\u00f6t\u00b7ter\u00b7Stim\u00b7me", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Ein Auge, das gef\u00e4llt, reitzt auch bey seinem Grimme;", "tokens": ["Ein", "Au\u00b7ge", ",", "das", "ge\u00b7f\u00e4llt", ",", "reitzt", "auch", "bey", "sei\u00b7nem", "Grim\u00b7me", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVPP", "$,", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Mit Bitten herrscht die Frau und mit Befehl der Mann;", "tokens": ["Mit", "Bit\u00b7ten", "herrscht", "die", "Frau", "und", "mit", "Be\u00b7fehl", "der", "Mann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "KON", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Die eine, wenn sie will, der andre, wenn er kan.", "tokens": ["Die", "ei\u00b7ne", ",", "wenn", "sie", "will", ",", "der", "and\u00b7re", ",", "wenn", "er", "kan", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "$,", "KOUS", "PPER", "VMFIN", "$,", "PRELS", "PIS", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Auch Gottsched muste sich, als Ehmann, hier bequehmen,", "tokens": ["Auch", "Gott\u00b7sched", "mus\u00b7te", "sich", ",", "als", "Eh\u00b7mann", ",", "hier", "be\u00b7queh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "VMFIN", "PRF", "$,", "KOUS", "NN", "$,", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Victoriens Parthey, aus Z\u00e4rtlichkeit, zu nehmen.", "tokens": ["Vic\u00b7to\u00b7ri\u00b7ens", "Par\u00b7they", ",", "aus", "Z\u00e4rt\u00b7lich\u00b7keit", ",", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "APPR", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Sie z\u00f6rnt, er w\u00fctet schon; sie droht, er bl\u00e4st zur Schlacht;", "tokens": ["Sie", "z\u00f6rnt", ",", "er", "w\u00fc\u00b7tet", "schon", ";", "sie", "droht", ",", "er", "bl\u00e4st", "zur", "Schlacht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Z\u00e4hlt an den Fingern her, wie viel er klein gemacht;", "tokens": ["Z\u00e4hlt", "an", "den", "Fin\u00b7gern", "her", ",", "wie", "viel", "er", "klein", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,", "PWAV", "PIS", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "F\u00e4ngt vom Picander an, der Schweitzer unvergessen,", "tokens": ["F\u00e4ngt", "vom", "Pi\u00b7can\u00b7der", "an", ",", "der", "Schweit\u00b7zer", "un\u00b7ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PTKVZ", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Bis auf den ", "tokens": ["Bis", "auf", "den"], "token_info": ["word", "word", "word"], "pos": ["APPR", "APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.118": {"text": "Kurtz, wie Terentzens Held, zu seinem Gnatho spricht,", "tokens": ["Kurtz", ",", "wie", "Te\u00b7rent\u00b7zens", "Held", ",", "zu", "sei\u00b7nem", "Gna\u00b7tho", "spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "NN", "NN", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Sprach er; jedoch vielleicht gleicht Thraso ihm noch nicht.", "tokens": ["Sprach", "er", ";", "je\u00b7doch", "viel\u00b7leicht", "gleicht", "Thra\u00b7so", "ihm", "noch", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$.", "ADV", "ADV", "VVFIN", "NE", "PPER", "ADV", "PTKNEG", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.120": {"text": "Vor allen Dingen wird dem Diener anbefohlen,", "tokens": ["Vor", "al\u00b7len", "Din\u00b7gen", "wird", "dem", "Die\u00b7ner", "an\u00b7be\u00b7foh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Drey Freunde, die man nennt, den Abend noch zu hohlen.", "tokens": ["Drey", "Freun\u00b7de", ",", "die", "man", "nennt", ",", "den", "A\u00b7bend", "noch", "zu", "hoh\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,", "ART", "NN", "ADV", "APPR", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Er l\u00e4ufft, der eine liegt an der Cholick zu Bett;", "tokens": ["Er", "l\u00e4ufft", ",", "der", "ei\u00b7ne", "liegt", "an", "der", "Cho\u00b7lick", "zu", "Bett", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ART", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.123": {"text": "Ein andrer sitzt", "tokens": ["Ein", "an\u00b7drer", "sitzt"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.124": {"text": "In seiner Monaths-Schrifft, in den Belustigungen;", "tokens": ["In", "sei\u00b7ner", "Mo\u00b7naths\u00b7Schrifft", ",", "in", "den", "Be\u00b7lus\u00b7ti\u00b7gun\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Der dritte k\u00f6mmt", "tokens": ["Der", "drit\u00b7te", "k\u00f6mmt"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.126": {"text": "Doch die Gesellschafft ist vor dieses mahl zu klein,", "tokens": ["Doch", "die", "Ge\u00b7sell\u00b7schafft", "ist", "vor", "die\u00b7ses", "mahl", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "APPR", "PDAT", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Drum ladet man auch ihn auf morgen wieder ein.", "tokens": ["Drum", "la\u00b7det", "man", "auch", "ihn", "auf", "mor\u00b7gen", "wie\u00b7der", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADV", "PPER", "APPR", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Der Abend und die Nacht verstrichen wie die Stunden,", "tokens": ["Der", "A\u00b7bend", "und", "die", "Nacht", "ver\u00b7stri\u00b7chen", "wie", "die", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Die der Egerie mit dem Pompil verschwunden.", "tokens": ["Die", "der", "E\u00b7ge\u00b7rie", "mit", "dem", "Pom\u00b7pil", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.8": {"line.1": {"text": "Ich, der ich sonst geglaubt, da\u00df ich gebohren w\u00e4re", "tokens": ["Ich", ",", "der", "ich", "sonst", "ge\u00b7glaubt", ",", "da\u00df", "ich", "ge\u00b7boh\u00b7ren", "w\u00e4\u00b7re"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,", "KOUS", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Bachus \u00e4chter Knecht, ein Priester der Cithere,", "tokens": ["Des", "Ba\u00b7chus", "\u00e4ch\u00b7ter", "Knecht", ",", "ein", "Pries\u00b7ter", "der", "Cit\u00b7he\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJA", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Voll, wie Anakreon, starck wie Ovid, zu seyn,", "tokens": ["Voll", ",", "wie", "A\u00b7nak\u00b7re\u00b7on", ",", "starck", "wie", "O\u00b7vid", ",", "zu", "seyn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "NE", "$,", "ADJD", "KOKOM", "NE", "$,", "PTKZU", "VAINF", "$,"], "meter": "+-+---+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Vergesse dieses mahl die Liebe, wie den Wein.", "tokens": ["Ver\u00b7ges\u00b7se", "die\u00b7ses", "mahl", "die", "Lie\u00b7be", ",", "wie", "den", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "ADV", "ART", "NN", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Werck, wodurch ich mich zu den Virgilen schwinge,", "tokens": ["Ein", "Werck", ",", "wo\u00b7durch", "ich", "mich", "zu", "den", "Vir\u00b7gi\u00b7len", "schwin\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist itzt mein Augenmerck. Es sey gewagt! Ich singe.", "tokens": ["Ist", "itzt", "mein", "Au\u00b7gen\u00b7merck", ".", "Es", "sey", "ge\u00b7wagt", "!", "Ich", "sin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "VVPP", "$.", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ich singe von der Frau, die um den Pleissenstrand,", "tokens": ["Ich", "sin\u00b7ge", "von", "der", "Frau", ",", "die", "um", "den", "Pleis\u00b7sen\u00b7strand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den deutschen Harlekin", "tokens": ["Den", "deut\u00b7schen", "Har\u00b7le\u00b7kin"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sich selbst bezwungen hat; die B\u00fchne stets verbessert;", "tokens": ["Sich", "selbst", "be\u00b7zwun\u00b7gen", "hat", ";", "die", "B\u00fch\u00b7ne", "stets", "ver\u00b7bes\u00b7sert", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVPP", "VAFIN", "$.", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kunst, Beyfall und Geschmack, wie ihren Ruhm, vergr\u00f6ssert;", "tokens": ["Kunst", ",", "Bey\u00b7fall", "und", "Ge\u00b7schmack", ",", "wie", "ih\u00b7ren", "Ruhm", ",", "ver\u00b7gr\u00f6s\u00b7sert", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,", "PWAV", "PPOSAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Annens grossen Thron,", "tokens": ["Die", "An\u00b7nens", "gros\u00b7sen", "Thron", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Bi\u00df des M\u00e4cenen Fall sie wieder heim geschickt.", "tokens": ["Bi\u00df", "des", "M\u00e4\u00b7ce\u00b7nen", "Fall", "sie", "wie\u00b7der", "heim", "ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPER", "ADV", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Jedoch ich singe nicht, ihr ganzes Lob zu singen:", "tokens": ["Je\u00b7doch", "ich", "sin\u00b7ge", "nicht", ",", "ihr", "gan\u00b7zes", "Lob", "zu", "sin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PTKNEG", "$,", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die\u00df mag ihr Lebens-Lauff der Nachwelt \u00fcberbringen;", "tokens": ["Die\u00df", "mag", "ihr", "Le\u00b7bens\u00b7Lauff", "der", "Nach\u00b7welt", "\u00fc\u00b7berb\u00b7rin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nur eine That von ihr errett ich aus der Zeit,", "tokens": ["Nur", "ei\u00b7ne", "That", "von", "ihr", "er\u00b7rett", "ich", "aus", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und \u00fcbergebe sie der Unverg\u00e4nglichkeit;", "tokens": ["Und", "\u00fc\u00b7ber\u00b7ge\u00b7be", "sie", "der", "Un\u00b7ver\u00b7g\u00e4ng\u00b7lich\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Den Sieg, doch nicht den Sieg gef\u00fchrter Liebes-Kriege;", "tokens": ["Den", "Sieg", ",", "doch", "nicht", "den", "Sieg", "ge\u00b7f\u00fchr\u00b7ter", "Lie\u00b7bes\u00b7Krie\u00b7ge", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PTKNEG", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ich singe dieses mahl den sch\u00f6nsten ihrer Siege;", "tokens": ["Ich", "sin\u00b7ge", "die\u00b7ses", "mahl", "den", "sch\u00f6ns\u00b7ten", "ih\u00b7rer", "Sie\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "ADV", "ART", "ADJA", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wie sehr ihr Vorspiel-Schertz, den sie selbst ausgedacht,", "tokens": ["Wie", "sehr", "ihr", "Vor\u00b7spiel\u00b7Schertz", ",", "den", "sie", "selbst", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Den hochgebr\u00fcsteten Professor klein gemacht,", "tokens": ["Den", "hoch\u00b7ge\u00b7br\u00fcs\u00b7te\u00b7ten", "Pro\u00b7fes\u00b7sor", "klein", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Zur Lust der Leipziger, so, da\u00df das Volck mit Hauffen,", "tokens": ["Zur", "Lust", "der", "Leip\u00b7zi\u00b7ger", ",", "so", ",", "da\u00df", "das", "Volck", "mit", "Hauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "ADV", "$,", "KOUS", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "In Zotens Hof", "tokens": ["In", "Zo\u00b7tens", "Hof"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NE", "NE"], "meter": "-+-+", "measure": "iambic.di"}, "line.17": {"text": "Da\u00df der Professor gar um Ph\u00f6bus Ausspruch bath,", "tokens": ["Da\u00df", "der", "Pro\u00b7fes\u00b7sor", "gar", "um", "Ph\u00f6\u00b7bus", "Aus\u00b7spruch", "ba\u00b7th", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}, "line.18": {"text": "Den aber doch Apoll, zu Gottscheds Schrecken, that.", "tokens": ["Den", "a\u00b7ber", "doch", "A\u00b7poll", ",", "zu", "Gott\u00b7scheds", "Schre\u00b7cken", ",", "that", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADV", "ADV", "NE", "$,", "APPR", "NE", "NN", "$,", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.10": {"line.1": {"text": "Ein Strahl, o Neuberin, ein Strahl von deinem Feuer", "tokens": ["Ein", "Strahl", ",", "o", "Neu\u00b7be\u00b7rin", ",", "ein", "Strahl", "von", "dei\u00b7nem", "Feu\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "FM", "NN", "$,", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durchdringe mir das Blut und schein auf meine Leyer!", "tokens": ["Durch\u00b7drin\u00b7ge", "mir", "das", "Blut", "und", "schein", "auf", "mei\u00b7ne", "Le\u00b7yer", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "KON", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.3": {"text": "Der Vorzug deiner Kunst, der Stellung Zauberkrafft", "tokens": ["Der", "Vor\u00b7zug", "dei\u00b7ner", "Kunst", ",", "der", "Stel\u00b7lung", "Zau\u00b7ber\u00b7krafft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sey, da ich singen will, des Ausdrucks Eigenschaft!", "tokens": ["Sey", ",", "da", "ich", "sin\u00b7gen", "will", ",", "des", "Aus\u00b7drucks", "Ei\u00b7gen\u00b7schaft", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Soll mir mein Helden-Lied, wie dir dein Sieg, gelingen:", "tokens": ["Soll", "mir", "mein", "Hel\u00b7den\u00b7Lied", ",", "wie", "dir", "dein", "Sieg", ",", "ge\u00b7lin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "$,", "PWAV", "PPER", "PPOSAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wohlan, so wie du spielst, w\u00fcnsch ich auch mir zu singen!", "tokens": ["Wo\u00b7hlan", ",", "so", "wie", "du", "spielst", ",", "w\u00fcnsch", "ich", "auch", "mir", "zu", "sin\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "KOKOM", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Der Preu\u00dfe, welcher erst die Deutschen deutsch gelehrt;", "tokens": ["Der", "Preu\u00b7\u00dfe", ",", "wel\u00b7cher", "erst", "die", "Deut\u00b7schen", "deutsch", "ge\u00b7lehrt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von welchem Leipzig nie ein falsches Wort geh\u00f6rt,", "tokens": ["Von", "wel\u00b7chem", "Leip\u00b7zig", "nie", "ein", "fal\u00b7sches", "Wort", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NE", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er spr\u00e4che denn Latein; der Hannibal im schreiben,", "tokens": ["Er", "spr\u00e4\u00b7che", "denn", "La\u00b7tein", ";", "der", "Han\u00b7ni\u00b7bal", "im", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "NN", "$.", "ART", "NE", "APPRART", "VVINF", "$,"], "meter": "-+-+++-+-+-+-", "measure": "unknown.measure.septa"}, "line.4": {"text": "Durch dessen Nahmen wir den Franzen schrecklich bleiben;", "tokens": ["Durch", "des\u00b7sen", "Nah\u00b7men", "wir", "den", "Fran\u00b7zen", "schreck\u00b7lich", "blei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Gottsched, welchem oft, als dem Magnificus,", "tokens": ["Der", "Gott\u00b7sched", ",", "wel\u00b7chem", "oft", ",", "als", "dem", "Mag\u00b7ni\u00b7fi\u00b7cus", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Der Oberste des Raths den Vortritt lassen mu\u00df;", "tokens": ["Der", "O\u00b7bers\u00b7te", "des", "Raths", "den", "Vor\u00b7tritt", "las\u00b7sen", "mu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.7": {"text": "Dem, Bayle,", "tokens": ["Dem", ",", "Bay\u00b7le", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["PDS", "$,", "NE", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Zwo Seiten und noch mehr in seinem G. verg\u00f6nnte,", "tokens": ["Zwo", "Sei\u00b7ten", "und", "noch", "mehr", "in", "sei\u00b7nem", "G.", "ver\u00b7g\u00f6nn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation", "word", "punct"], "pos": ["CARD", "NN", "KON", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Der nimmt sich v\u00e4terlich der deutschen B\u00fchnen an,", "tokens": ["Der", "nimmt", "sich", "v\u00e4\u00b7ter\u00b7lich", "der", "deut\u00b7schen", "B\u00fch\u00b7nen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADJD", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und hats dem Hallmann", "tokens": ["Und", "hats", "dem", "Hall\u00b7mann"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Ja selbst Victoria, die ihn, als Gattin, k\u00fcsset;", "tokens": ["Ja", "selbst", "Vic\u00b7to\u00b7ria", ",", "die", "ihn", ",", "als", "Gat\u00b7tin", ",", "k\u00fcs\u00b7set", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "ADV", "NE", "$,", "PRELS", "PPER", "$,", "KOUS", "NN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Vier Sprachen schreibt und spricht, und wie ein Leibnitz schl\u00fcsset,", "tokens": ["Vier", "Spra\u00b7chen", "schreibt", "und", "spricht", ",", "und", "wie", "ein", "Leib\u00b7nitz", "schl\u00fcs\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "KON", "VVFIN", "$,", "KON", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Hat sich nebst ihm bem\u00fcht, und es so weit gebracht,", "tokens": ["Hat", "sich", "nebst", "ihm", "be\u00b7m\u00fcht", ",", "und", "es", "so", "weit", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "APPR", "PPER", "VVFIN", "$,", "KON", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.14": {"text": "Da\u00df unser Schauplatz selbst die Franzen neidisch macht.", "tokens": ["Da\u00df", "un\u00b7ser", "Schau\u00b7platz", "selbst", "die", "Fran\u00b7zen", "nei\u00b7disch", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Man giebt der Neuberin, rein-\u00fcbersetzte St\u00fccke;", "tokens": ["Man", "giebt", "der", "Neu\u00b7be\u00b7rin", ",", "rein\u00b7\u00fcber\u00b7setz\u00b7te", "St\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Theilt selbst die Rollen aus: lehrt Stellung, Minen, Blicke;", "tokens": ["Theilt", "selbst", "die", "Rol\u00b7len", "aus", ":", "lehrt", "Stel\u00b7lung", ",", "Mi\u00b7nen", ",", "Bli\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKVZ", "$.", "VVFIN", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Sie dancket und gehorcht, zieht doppelten Gewinn:", "tokens": ["Sie", "dan\u00b7cket", "und", "ge\u00b7horcht", ",", "zieht", "dop\u00b7pel\u00b7ten", "Ge\u00b7winn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVPP", "$,", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.18": {"text": "Wer den Professor h\u00f6rt, geht auch zur Neuberin.", "tokens": ["Wer", "den", "Pro\u00b7fes\u00b7sor", "h\u00f6rt", ",", "geht", "auch", "zur", "Neu\u00b7be\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Thalia, die du hast den Streit voraus gesehen,", "tokens": ["Tha\u00b7lia", ",", "die", "du", "hast", "den", "Streit", "vo\u00b7raus", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPER", "VAFIN", "ART", "NN", "PTKVZ", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Was konnte, sag es mir, Victorien geschehen,", "tokens": ["Was", "konn\u00b7te", ",", "sag", "es", "mir", ",", "Vic\u00b7to\u00b7ri\u00b7en", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "$,", "VVFIN", "PPER", "PPER", "$,", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df sie aus Rache schwur: Geht auch der Schauplatz ein,", "tokens": ["Da\u00df", "sie", "aus", "Ra\u00b7che", "schwur", ":", "Geht", "auch", "der", "Schau\u00b7platz", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$.", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "So wahr die Gomez", "tokens": ["So", "wahr", "die", "Go\u00b7mez"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Thalia, noch einmahl: Wodurch ward Gottsched hitzig?", "tokens": ["Tha\u00b7lia", ",", "noch", "ein\u00b7mahl", ":", "Wo\u00b7durch", "ward", "Gott\u00b7sched", "hit\u00b7zig", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "ADV", "$.", "PWAV", "VAFIN", "NE", "ADJD", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Er schrieh; die Neuberin wird warlich aberwitzig.", "tokens": ["Er", "schrieh", ";", "die", "Neu\u00b7be\u00b7rin", "wird", "war\u00b7lich", "a\u00b7berw\u00b7it\u00b7zig", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was hat, entdecke mirs, die gute Frau ver\u00fcbt?", "tokens": ["Was", "hat", ",", "ent\u00b7de\u00b7cke", "mirs", ",", "die", "gu\u00b7te", "Frau", "ver\u00b7\u00fcbt", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "VVFIN", "NE", "$,", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auf einmahl ha\u00dft er sie mehr, als er sie geliebt.", "tokens": ["Auf", "ein\u00b7mahl", "ha\u00dft", "er", "sie", "mehr", ",", "als", "er", "sie", "ge\u00b7liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$,", "KOUS", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Der d\u00fcrre Neid, der Geist de M\u00fcllerischen Bande,", "tokens": ["Der", "d\u00fcr\u00b7re", "Neid", ",", "der", "Geist", "de", "M\u00fcl\u00b7le\u00b7ri\u00b7schen", "Ban\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "NE", "NE", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Schwur l\u00e4ngst der Neuberin Fall, Banckerot und Schande.", "tokens": ["Schwur", "l\u00e4ngst", "der", "Neu\u00b7be\u00b7rin", "Fall", ",", "Ban\u00b7cke\u00b7rot", "und", "Schan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er hatte schon den Gift dreymahl nach ihr gespritzt,", "tokens": ["Er", "hat\u00b7te", "schon", "den", "Gift", "drey\u00b7mahl", "nach", "ihr", "ge\u00b7spritzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Doch von der Schauspielkunst ward sie dreymahl besch\u00fctzt.", "tokens": ["Doch", "von", "der", "Schau\u00b7spiel\u00b7kunst", "ward", "sie", "drey\u00b7mahl", "be\u00b7sch\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "---+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Jetzt schwur er noch einmahl bey seinen Schlangen-Haaren:", "tokens": ["Jetzt", "schwur", "er", "noch", "ein\u00b7mahl", "bey", "sei\u00b7nen", "Schlan\u00b7gen\u00b7Haa\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u00bbda sie der Macht entweicht, soll sie die List erfahren!\u00ab", "tokens": ["\u00bb", "da", "sie", "der", "Macht", "ent\u00b7weicht", ",", "soll", "sie", "die", "List", "er\u00b7fah\u00b7ren", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VMFIN", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Nattern z\u00fcngelten, er sch\u00e4rffte sich den Zahn,", "tokens": ["Die", "Nat\u00b7tern", "z\u00fcn\u00b7gel\u00b7ten", ",", "er", "sch\u00e4rff\u00b7te", "sich", "den", "Zahn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und trat sogleich den Weg nach Gottscheds Wohnung an.", "tokens": ["Und", "trat", "sog\u00b7leich", "den", "Weg", "nach", "Gott\u00b7scheds", "Woh\u00b7nung", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "APPR", "NE", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Bi\u00df in den H\u00f6rsaal war der Neid, als Neid, gekommen;", "tokens": ["Bi\u00df", "in", "den", "H\u00f6r\u00b7saal", "war", "der", "Neid", ",", "als", "Neid", ",", "ge\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "VAFIN", "ART", "NN", "$,", "KOUS", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Allein itzt ward sein Werck mit Arglist unternommen,", "tokens": ["Al\u00b7lein", "itzt", "ward", "sein", "Werck", "mit", "Arg\u00b7list", "un\u00b7ter\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Darum verwandelte des Gl\u00fcckes Affter-Sohn", "tokens": ["Da\u00b7rum", "ver\u00b7wan\u00b7del\u00b7te", "des", "Gl\u00fc\u00b7ckes", "Aff\u00b7ter\u00b7Sohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sich, vor der Stube noch, und wurde zum Baron.", "tokens": ["Sich", ",", "vor", "der", "Stu\u00b7be", "noch", ",", "und", "wur\u00b7de", "zum", "Ba\u00b7ron", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "$,", "APPR", "ART", "NN", "ADV", "$,", "KON", "VAFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Hier sa\u00df Victoria auf ihrem Polster-Stuhle,", "tokens": ["Hier", "sa\u00df", "Vic\u00b7to\u00b7ria", "auf", "ih\u00b7rem", "Pols\u00b7ter\u00b7Stuh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Mit Ungeduld erf\u00fcllt, da\u00df ihre Feder-Spule", "tokens": ["Mit", "Un\u00b7ge\u00b7duld", "er\u00b7f\u00fcllt", ",", "da\u00df", "ih\u00b7re", "Fe\u00b7der\u00b7Spu\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "VVPP", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Uebersetzungen zu sparsam fliessen lie\u00df,", "tokens": ["Die", "Ue\u00b7ber\u00b7set\u00b7zun\u00b7gen", "zu", "spar\u00b7sam", "flies\u00b7sen", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKA", "ADJD", "VVINF", "VVFIN", "$,"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und sich nach Gottscheds Wunsch nicht fix genug erwie\u00df.", "tokens": ["Und", "sich", "nach", "Gott\u00b7scheds", "Wunsch", "nicht", "fix", "ge\u00b7nug", "er\u00b7wie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "NE", "NN", "PTKNEG", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gleich diesen Augenblick trat der Baron ins Zimmer,", "tokens": ["Gleich", "die\u00b7sen", "Au\u00b7gen\u00b7blick", "trat", "der", "Ba\u00b7ron", "ins", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und f\u00fcr die Neuberin war dieses desto schlimmer.", "tokens": ["Und", "f\u00fcr", "die", "Neu\u00b7be\u00b7rin", "war", "die\u00b7ses", "des\u00b7to", "schlim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "PDAT", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u00bbfrau! sprach er, die du selbst der Silphen Reich verdienst;", "tokens": ["\u00bb", "frau", "!", "sprach", "er", ",", "die", "du", "selbst", "der", "Sil\u00b7phen", "Reich", "ver\u00b7dienst", ";"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$.", "VVFIN", "PPER", "$,", "PRELS", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie eine Sapho singst, wie eine Daphne gr\u00fcnst;", "tokens": ["Wie", "ei\u00b7ne", "Sa\u00b7pho", "singst", ",", "wie", "ei\u00b7ne", "Daph\u00b7ne", "gr\u00fcnst", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du Ubersetzerin der g\u00f6ttlichen Alzire,", "tokens": ["Du", "Ub\u00b7er\u00b7set\u00b7ze\u00b7rin", "der", "g\u00f6tt\u00b7li\u00b7chen", "Al\u00b7zi\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein freches Weib verletzt die wiederhohlten Schw\u00fcre;", "tokens": ["Ein", "fre\u00b7ches", "Weib", "ver\u00b7letzt", "die", "wie\u00b7der\u00b7hohl\u00b7ten", "Schw\u00fc\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Alzire ward gespielt, von iedem hoch gesch\u00e4tzt,", "tokens": ["Al\u00b7zi\u00b7re", "ward", "ge\u00b7spielt", ",", "von", "ie\u00b7dem", "hoch", "ge\u00b7sch\u00e4tzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "VVPP", "$,", "APPR", "PIAT", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und auf dem Zettel stund: von St\u00fcven \u00fcbersetzt.", "tokens": ["Und", "auf", "dem", "Zet\u00b7tel", "stund", ":", "von", "St\u00fc\u00b7ven", "\u00fc\u00b7bers\u00b7etzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$.", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Hei\u00dft dieses kein Betrug, so wird kein Mensch betrogen;", "tokens": ["Hei\u00dft", "die\u00b7ses", "kein", "Be\u00b7trug", ",", "so", "wird", "kein", "Mensch", "be\u00b7tro\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "PIAT", "NN", "$,", "ADV", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Dir? St\u00fcven gleich gestellt?", "tokens": ["Dir", "?", "St\u00fc\u00b7ven", "gleich", "ge\u00b7stellt", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Ist wohl die Neuberin noch eures Schutzes werth?", "tokens": ["Ist", "wohl", "die", "Neu\u00b7be\u00b7rin", "noch", "eu\u00b7res", "Schut\u00b7zes", "werth", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wenn dein Gemahl mit ihr nicht die\u00dfmahl scharf verf\u00e4hrt;", "tokens": ["Wenn", "dein", "Ge\u00b7mahl", "mit", "ihr", "nicht", "die\u00df\u00b7mahl", "scharf", "ver\u00b7f\u00e4hrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "PPER", "PTKNEG", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So wird sie k\u00fcnfftig gar, Victorien zu qu\u00e4hlen,", "tokens": ["So", "wird", "sie", "k\u00fcnff\u00b7tig", "gar", ",", "Vic\u00b7to\u00b7ri\u00b7en", "zu", "qu\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ADV", "$,", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Die Uebersetzungen der Nieder-Sachsen w\u00e4hlen.\u00ab", "tokens": ["Die", "Ue\u00b7ber\u00b7set\u00b7zun\u00b7gen", "der", "Nie\u00b7der\u00b7Sach\u00b7sen", "w\u00e4h\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.19": {"text": "Hier k\u00fcssete der Neid der grossen Frau die Hand;", "tokens": ["Hier", "k\u00fcs\u00b7se\u00b7te", "der", "Neid", "der", "gros\u00b7sen", "Frau", "die", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ward, an der Th\u00fcre noch, zweymahl Baron genannt;", "tokens": ["Ward", ",", "an", "der", "Th\u00fc\u00b7re", "noch", ",", "zwey\u00b7mahl", "Ba\u00b7ron", "ge\u00b7nannt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "APPR", "ART", "NN", "ADV", "$,", "ADV", "NN", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Gieng, freute sich der List, und schickt im Augenblicke,", "tokens": ["Gieng", ",", "freu\u00b7te", "sich", "der", "List", ",", "und", "schickt", "im", "Au\u00b7gen\u00b7bli\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PRF", "ART", "NN", "$,", "KON", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die Schwester des Betrugs, die Eifersucht, zur\u00fccke.", "tokens": ["Die", "Schwes\u00b7ter", "des", "Be\u00b7trugs", ",", "die", "Ei\u00b7fer\u00b7sucht", ",", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sie fand Victorien gantz anders als der Neid:", "tokens": ["Sie", "fand", "Vic\u00b7to\u00b7ri\u00b7en", "gantz", "an\u00b7ders", "als", "der", "Neid", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADV", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Der Kulmus Auge sah erbittert und zerstreut;", "tokens": ["Der", "Kul\u00b7mus", "Au\u00b7ge", "sah", "er\u00b7bit\u00b7tert", "und", "zer\u00b7streut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ADJD", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Mit knirschen druckte sie den kleinen Mund zusammen;", "tokens": ["Mit", "knir\u00b7schen", "druck\u00b7te", "sie", "den", "klei\u00b7nen", "Mund", "zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Ihr Athem war ein Hauch, so hei\u00df als Feuer-Flammen;", "tokens": ["Ihr", "A\u00b7them", "war", "ein", "Hauch", ",", "so", "hei\u00df", "als", "Feu\u00b7er\u00b7Flam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$,", "ADV", "ADJD", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Drum hielt die Eifersucht, eh sich der Zorn verlohr,", "tokens": ["Drum", "hielt", "die", "Ei\u00b7fer\u00b7sucht", ",", "eh", "sich", "der", "Zorn", "ver\u00b7lohr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "$,", "KOUS", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ihr das Vergr\u00f6\u00dfrungs-Gla\u00df zur rechten Stunde vor.", "tokens": ["Ihr", "das", "Ver\u00b7gr\u00f6\u00df\u00b7rungs\u00b7Gla\u00df", "zur", "rech\u00b7ten", "Stun\u00b7de", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Hierwieder konnte sich die Neuberin nicht sch\u00fctzen:", "tokens": ["Hier\u00b7wie\u00b7der", "konn\u00b7te", "sich", "die", "Neu\u00b7be\u00b7rin", "nicht", "sch\u00fct\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PRF", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Die wilde G\u00f6ttin will Victorien erhitzen,", "tokens": ["Die", "wil\u00b7de", "G\u00f6t\u00b7tin", "will", "Vic\u00b7to\u00b7ri\u00b7en", "er\u00b7hit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Und, da die Wahrheit nicht hierzu beh\u00fclflich ist,", "tokens": ["Und", ",", "da", "die", "Wahr\u00b7heit", "nicht", "hier\u00b7zu", "be\u00b7h\u00fcl\u00b7flich", "ist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "PTKNEG", "PAV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "So greift sie zum Crystall und w\u00e4hlt Betrug und List;", "tokens": ["So", "greift", "sie", "zum", "Crys\u00b7tall", "und", "w\u00e4hlt", "Be\u00b7trug", "und", "List", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "KON", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "So hilfft die M\u00f6glichkeit, so hilfft der Schein betr\u00fcgen;", "tokens": ["So", "hilfft", "die", "M\u00f6g\u00b7lich\u00b7keit", ",", "so", "hilfft", "der", "Schein", "be\u00b7tr\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "So mahlt die Eifersucht ein Bild mit falschen Z\u00fcgen.", "tokens": ["So", "mahlt", "die", "Ei\u00b7fer\u00b7sucht", "ein", "Bild", "mit", "fal\u00b7schen", "Z\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Ihr Spiegel bildet nie die Wahrheit blo\u00df und rein;", "tokens": ["Ihr", "Spie\u00b7gel", "bil\u00b7det", "nie", "die", "Wahr\u00b7heit", "blo\u00df", "und", "rein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN", "ADV", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Was klein ist, macht er gro\u00df, was gro\u00df ist, macht er klein.", "tokens": ["Was", "klein", "ist", ",", "macht", "er", "gro\u00df", ",", "was", "gro\u00df", "ist", ",", "macht", "er", "klein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "VVFIN", "PPER", "ADJD", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Drum konnt er leicht auch hier ein Blendwerck zubereiten:", "tokens": ["Drum", "konnt", "er", "leicht", "auch", "hier", "ein", "Blend\u00b7werck", "zu\u00b7be\u00b7rei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADJD", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Es sah Victoria Gottscheds Magister-Zeiten;", "tokens": ["Es", "sah", "Vic\u00b7to\u00b7ria", "Gott\u00b7scheds", "Ma\u00b7gis\u00b7ter\u00b7Zei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NE", "NN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.39": {"text": "Bey ihm die Neuberin, weit reizender geschm\u00fcckt,", "tokens": ["Bey", "ihm", "die", "Neu\u00b7be\u00b7rin", ",", "weit", "rei\u00b7zen\u00b7der", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "$,", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Als f\u00fcr ein h\u00e4u\u00dflich Weib sichs sonst im Hause schickt.", "tokens": ["Als", "f\u00fcr", "ein", "h\u00e4u\u00df\u00b7lich", "Weib", "sichs", "sonst", "im", "Hau\u00b7se", "schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJD", "NN", "PIS", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Es ging, und wer? genug, es ging iemand nach Weine;", "tokens": ["Es", "ging", ",", "und", "wer", "?", "ge\u00b7nug", ",", "es", "ging", "ie\u00b7mand", "nach", "Wei\u00b7ne", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "PWS", "$.", "ADV", "$,", "PPER", "VVFIN", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.42": {"text": "Mit dem Magister blieb die Neuberin alleine.", "tokens": ["Mit", "dem", "Ma\u00b7gis\u00b7ter", "blieb", "die", "Neu\u00b7be\u00b7rin", "al\u00b7lei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Kurtz, durch das falsche Bild von der Magister-Zeit", "tokens": ["Kurtz", ",", "durch", "das", "fal\u00b7sche", "Bild", "von", "der", "Ma\u00b7gis\u00b7ter\u00b7Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "APPR", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Verlohr Victorie Kraft und Gelassenheit.", "tokens": ["Ver\u00b7lohr", "Vic\u00b7to\u00b7rie", "Kraft", "und", "Ge\u00b7las\u00b7sen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.45": {"text": "Sie \u00f6ffnete den Mund, ich wei\u00df nicht was, zu sprechen;", "tokens": ["Sie", "\u00f6ff\u00b7ne\u00b7te", "den", "Mund", ",", "ich", "wei\u00df", "nicht", "was", ",", "zu", "spre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PTKNEG", "PIS", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Doch Schwindel, Uebelkeit und hefftig Seitenstechen,", "tokens": ["Doch", "Schwin\u00b7del", ",", "Ue\u00b7bel\u00b7keit", "und", "heff\u00b7tig", "Sei\u00b7ten\u00b7ste\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Erlaubten ihr noch kaum ein kl\u00e4glich: Ach Herr Je \u2013 \u2013!", "tokens": ["Er\u00b7laub\u00b7ten", "ihr", "noch", "kaum", "ein", "kl\u00e4g\u00b7lich", ":", "Ach", "Herr", "Je", "\u2013", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "ADJD", "$.", "ITJ", "NN", "ADV", "$(", "$(", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Sie sprach das Wort nur halb, und fiel aufs Cannape.", "tokens": ["Sie", "sprach", "das", "Wort", "nur", "halb", ",", "und", "fiel", "aufs", "Can\u00b7na\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ADJD", "$,", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Die M\u00e4gde liefen zu, sie klagte Seitenschmertzen;", "tokens": ["Die", "M\u00e4g\u00b7de", "lie\u00b7fen", "zu", ",", "sie", "klag\u00b7te", "Sei\u00b7ten\u00b7schmert\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Die alte K\u00f6chin scherzt, als w\u00e4r es Zeit zu scherzen:", "tokens": ["Die", "al\u00b7te", "K\u00f6\u00b7chin", "scherzt", ",", "als", "w\u00e4r", "es", "Zeit", "zu", "scher\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KOKOM", "VAFIN", "PPER", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "\u00bbes ist ein Schmerzen-Sohn, ja, Frau Professorin,", "tokens": ["\u00bb", "es", "ist", "ein", "Schmer\u00b7zen\u00b7Sohn", ",", "ja", ",", "Frau", "Pro\u00b7fes\u00b7so\u00b7rin", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "PTKANT", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Man tauf ihn wie man will, ich hei\u00df ihn Benjamin.\u00ab", "tokens": ["Man", "tauf", "ihn", "wie", "man", "will", ",", "ich", "hei\u00df", "ihn", "Ben\u00b7ja\u00b7min", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PWAV", "PIS", "VMFIN", "$,", "PPER", "ADJD", "PPER", "NE", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Der schlaue Diener stund, und horchte vor der Th\u00fcre;", "tokens": ["Der", "schlau\u00b7e", "Die\u00b7ner", "stund", ",", "und", "horch\u00b7te", "vor", "der", "Th\u00fc\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Wenn, dacht er, die\u00df mein Herr von mir zuerst erf\u00fchre:", "tokens": ["Wenn", ",", "dacht", "er", ",", "die\u00df", "mein", "Herr", "von", "mir", "zu\u00b7erst", "er\u00b7f\u00fch\u00b7re", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "VVFIN", "PPER", "$,", "PDS", "PPOSAT", "NN", "APPR", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "So w\u00fcrde wenigstens doch ein Ducaten mein,", "tokens": ["So", "w\u00fcr\u00b7de", "we\u00b7nigs\u00b7tens", "doch", "ein", "Du\u00b7ca\u00b7ten", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ART", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Und der Professor froh, und ich zufrieden, seyn.", "tokens": ["Und", "der", "Pro\u00b7fes\u00b7sor", "froh", ",", "und", "ich", "zu\u00b7frie\u00b7den", ",", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "$,", "KON", "PPER", "ADJD", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Auf dieses spitzte sich der Ausbund von den Dienern,", "tokens": ["Auf", "die\u00b7ses", "spitz\u00b7te", "sich", "der", "Aus\u00b7bund", "von", "den", "Die\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.58": {"text": "Und flog mehr, als er ging, ins Kloster zun Paulinern,", "tokens": ["Und", "flog", "mehr", ",", "als", "er", "ging", ",", "ins", "Klos\u00b7ter", "zun", "Pau\u00b7li\u00b7nern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,", "APPRART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Wo der Professor sa\u00df, und gleich recht magnific,", "tokens": ["Wo", "der", "Pro\u00b7fes\u00b7sor", "sa\u00df", ",", "und", "gleich", "recht", "mag\u00b7ni\u00b7fic", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,", "KON", "ADV", "ADV", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Die\u00dfmahl dem Syndikus kein einzig Wort verschwieg.", "tokens": ["Die\u00df\u00b7mahl", "dem", "Syn\u00b7di\u00b7kus", "kein", "ein\u00b7zig", "Wort", "ver\u00b7schwieg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PIAT", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Was nun der frohe Knecht durchs Schl\u00fcsselloch gesehen,", "tokens": ["Was", "nun", "der", "fro\u00b7he", "Knecht", "durchs", "Schl\u00fcs\u00b7sel\u00b7loch", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Sagt er dem Herrn ins Ohr, ja mehr noch, als geschehen;", "tokens": ["Sagt", "er", "dem", "Herrn", "ins", "Ohr", ",", "ja", "mehr", "noch", ",", "als", "ge\u00b7sche\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$,", "ADV", "ADV", "ADV", "$,", "KOUS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Und lief, sein Herr befohls, dem er nie wiedersprach,", "tokens": ["Und", "lief", ",", "sein", "Herr", "be\u00b7fohls", ",", "dem", "er", "nie", "wie\u00b7der\u00b7sprach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPOSAT", "NN", "NE", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.64": {"text": "Sogleich voran zur\u00fcck, die\u00dfmahl ihm Gottsched nach.", "tokens": ["Sog\u00b7leich", "vo\u00b7ran", "zu\u00b7r\u00fcck", ",", "die\u00df\u00b7mahl", "ihm", "Gott\u00b7sched", "nach", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$,", "KOUS", "PPER", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Der weit gespaltne Herr erreichte bald das Zimmer;", "tokens": ["Der", "weit", "ge\u00b7spalt\u00b7ne", "Herr", "er\u00b7reich\u00b7te", "bald", "das", "Zim\u00b7mer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Er sah Victorien, sie ihn, die Noth ward schlimmer.", "tokens": ["Er", "sah", "Vic\u00b7to\u00b7ri\u00b7en", ",", "sie", "ihn", ",", "die", "Noth", "ward", "schlim\u00b7mer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$,", "PPER", "PPER", "$,", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Wie? half der Anblick nicht, da\u00df sie den Schmertz verga\u00df?", "tokens": ["Wie", "?", "half", "der", "An\u00b7blick", "nicht", ",", "da\u00df", "sie", "den", "Schmertz", "ver\u00b7ga\u00df", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "ART", "NN", "PTKNEG", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "O nein! sie dachte noch an das Vergr\u00f6\u00dfrungs-Gla\u00df.", "tokens": ["O", "nein", "!", "sie", "dach\u00b7te", "noch", "an", "das", "Ver\u00b7gr\u00f6\u00df\u00b7rungs\u00b7Gla\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$.", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.69": {"text": "Was war sein erstes Wort? geduldig, meine Sch\u00f6ne!", "tokens": ["Was", "war", "sein", "ers\u00b7tes", "Wort", "?", "ge\u00b7dul\u00b7dig", ",", "mei\u00b7ne", "Sch\u00f6\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "ADJA", "NN", "$.", "ADJD", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "\u00bbso leicht geb\u00e4hrt man nicht gelehrter M\u00e4nner S\u00f6hne:", "tokens": ["\u00bb", "so", "leicht", "ge\u00b7b\u00e4hrt", "man", "nicht", "ge\u00b7lehr\u00b7ter", "M\u00e4n\u00b7ner", "S\u00f6h\u00b7ne", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "VVFIN", "PIS", "PTKNEG", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Es schmerzete das Haupt den Zevs drey Monden lang,", "tokens": ["Es", "schmer\u00b7ze\u00b7te", "das", "Haupt", "den", "Zevs", "drey", "Mon\u00b7den", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NE", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Bevor Tritonia aus seiner Stirne sprang.\u00ab", "tokens": ["Be\u00b7vor", "Tri\u00b7to\u00b7nia", "aus", "sei\u00b7ner", "Stir\u00b7ne", "sprang", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.73": {"text": "Hierauf gab er Befehl, mehr Frauen her zu holen.", "tokens": ["Hier\u00b7auf", "gab", "er", "Be\u00b7fehl", ",", "mehr", "Frau\u00b7en", "her", "zu", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "NN", "$,", "PIAT", "NN", "APZR", "PTKZU", "VVINF", "$."], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.74": {"text": "Nein! schrieh Victoria, viel lieber anbefohlen,", "tokens": ["Nein", "!", "schrieh", "Vic\u00b7to\u00b7ria", ",", "viel", "lie\u00b7ber", "an\u00b7be\u00b7foh\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "VVFIN", "NE", "$,", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.75": {"text": "Da\u00df dieser M\u00e4gdeschwarm aus meinem Zimmer eilt,", "tokens": ["Da\u00df", "die\u00b7ser", "M\u00e4g\u00b7de\u00b7schwarm", "aus", "mei\u00b7nem", "Zim\u00b7mer", "eilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Weil sonst mein Mund mit dir nicht sein Geheimni\u00df theilt.", "tokens": ["Weil", "sonst", "mein", "Mund", "mit", "dir", "nicht", "sein", "Ge\u00b7heim\u00b7ni\u00df", "theilt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "APPR", "PPER", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Die M\u00e4gde gingen fort, das Zimmer ward verschlossen,", "tokens": ["Die", "M\u00e4g\u00b7de", "gin\u00b7gen", "fort", ",", "das", "Zim\u00b7mer", "ward", "ver\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Doch aussen stunden sie und horcheten zum Possen.", "tokens": ["Doch", "aus\u00b7sen", "stun\u00b7den", "sie", "und", "hor\u00b7che\u00b7ten", "zum", "Pos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIZU", "VVFIN", "PPER", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "\u00bbgeliebter!\u00ab sprach nunmehr die kluge Gottschedin,", "tokens": ["\u00bb", "ge\u00b7lieb\u00b7ter", "!", "\u00ab", "sprach", "nun\u00b7mehr", "die", "klu\u00b7ge", "Gott\u00b7sche\u00b7din", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "$.", "$(", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "\u00bbwofern ich deiner Gunst nicht werth gewesen bin,", "tokens": ["\u00bb", "wo\u00b7fern", "ich", "dei\u00b7ner", "Gunst", "nicht", "werth", "ge\u00b7we\u00b7sen", "bin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "ADJD", "VAPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Was nanntst du mich", "tokens": ["Was", "nanntst", "du", "mich"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PRF"], "meter": "-+-+", "measure": "iambic.di"}, "line.82": {"text": "Ein seltnes Meisterst\u00fcck von Witz, Verstand und Tugend?", "tokens": ["Ein", "selt\u00b7nes", "Meis\u00b7ter\u00b7st\u00fcck", "von", "Witz", ",", "Ver\u00b7stand", "und", "Tu\u00b7gend", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Der K\u00fcnste Sammel-Platz, dein Leben und dein Licht?", "tokens": ["Der", "K\u00fcns\u00b7te", "Sam\u00b7mel\u00b7Platz", ",", "dein", "Le\u00b7ben", "und", "dein", "Licht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Warum besannst du dich noch in Sechs Jahren nicht?", "tokens": ["Wa\u00b7rum", "be\u00b7sannst", "du", "dich", "noch", "in", "Sechs", "Jah\u00b7ren", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "ADV", "APPR", "CARD", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Und warum g\u00f6nntest du mich nicht dem Weichselstrande?", "tokens": ["Und", "wa\u00b7rum", "g\u00f6nn\u00b7test", "du", "mich", "nicht", "dem", "Weich\u00b7sel\u00b7stran\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "PRF", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Hier leb ich mir zur Last und deinem Ruhm zur Schande:", "tokens": ["Hier", "leb", "ich", "mir", "zur", "Last", "und", "dei\u00b7nem", "Ruhm", "zur", "Schan\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPRART", "NN", "KON", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Die stoltze Neuberin hat mich und dich verletzt;", "tokens": ["Die", "stolt\u00b7ze", "Neu\u00b7be\u00b7rin", "hat", "mich", "und", "dich", "ver\u00b7letzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "KON", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Hat mich, o Frevelthat! noch St\u00fcven nachgesetzt.", "tokens": ["Hat", "mich", ",", "o", "Fre\u00b7vel\u00b7that", "!", "noch", "St\u00fc\u00b7ven", "nach\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "FM", "NN", "$.", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Da wir Alziren gar zur Niedersachsin machen.", "tokens": ["Da", "wir", "Al\u00b7zi\u00b7ren", "gar", "zur", "Nie\u00b7der\u00b7sac\u00b7hsin", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Ich habe selbst die\u00df Spiel ins reinste deutsch gebracht,", "tokens": ["Ich", "ha\u00b7be", "selbst", "die\u00df", "Spiel", "ins", "reins\u00b7te", "deutsch", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PDS", "NN", "APPRART", "ADJA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Der neunmahl klugen ists dennoch nicht recht gemacht.", "tokens": ["Der", "neun\u00b7mahl", "klu\u00b7gen", "ists", "den\u00b7noch", "nicht", "recht", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "VAFIN", "ADV", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Du ausversch\u00e4mtes Weib! du wirst mich schreiben lehren;", "tokens": ["Du", "aus\u00b7ver\u00b7sch\u00e4m\u00b7tes", "Weib", "!", "du", "wirst", "mich", "schrei\u00b7ben", "leh\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$.", "PPER", "VAFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "K\u00f6nnt ihr, dein Vers und du, wohl unsrer Huld entbehren?", "tokens": ["K\u00f6nnt", "ihr", ",", "dein", "Vers", "und", "du", ",", "wohl", "uns\u00b7rer", "Huld", "ent\u00b7beh\u00b7ren", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "PPOSAT", "NN", "KON", "PPER", "$,", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Wir sprachen; werde gro\u00df! durch uns, durch uns allein,", "tokens": ["Wir", "spra\u00b7chen", ";", "wer\u00b7de", "gro\u00df", "!", "durch", "uns", ",", "durch", "uns", "al\u00b7lein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VAFIN", "ADJD", "$.", "APPR", "PPER", "$,", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Erhob sich deine Kunst: Nun werd auch wieder klein!", "tokens": ["Er\u00b7hob", "sich", "dei\u00b7ne", "Kunst", ":", "Nun", "werd", "auch", "wie\u00b7der", "klein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "$.", "ADV", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Giebt uns nur Sch\u00f6nemann", "tokens": ["Giebt", "uns", "nur", "Sch\u00f6\u00b7ne\u00b7mann"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.97": {"text": "So k\u00f6nnen wir auch ihn in unsern Schrifften loben.", "tokens": ["So", "k\u00f6n\u00b7nen", "wir", "auch", "ihn", "in", "un\u00b7sern", "Schriff\u00b7ten", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Geliebter! hat dein Hertz mich mit Bedacht erw\u00e4hlt;", "tokens": ["Ge\u00b7lieb\u00b7ter", "!", "hat", "dein", "Hertz", "mich", "mit", "Be\u00b7dacht", "er\u00b7w\u00e4hlt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VAFIN", "PPOSAT", "NN", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Hat halb Germanien", "tokens": ["Hat", "halb", "Ger\u00b7ma\u00b7ni\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ADJD", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.100": {"text": "Gabst du, mit Recht, dir M\u00fch, die Kulmus zu gewinnen;", "tokens": ["Gabst", "du", ",", "mit", "Recht", ",", "dir", "M\u00fch", ",", "die", "Kul\u00b7mus", "zu", "ge\u00b7win\u00b7nen", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "NN", "$,", "PPER", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Beschimpft mein Nahme nicht dich und die Tadlerinnen;", "tokens": ["Be\u00b7schimpft", "mein", "Nah\u00b7me", "nicht", "dich", "und", "die", "Tad\u00b7le\u00b7rin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "PPER", "KON", "ART", "NN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.102": {"text": "So zeige, da\u00df auch ich dir purpurheilig bin,", "tokens": ["So", "zei\u00b7ge", ",", "da\u00df", "auch", "ich", "dir", "pur\u00b7pur\u00b7hei\u00b7lig", "bin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "ADV", "PPER", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Und straf und z\u00fcchtige die wilde Neuberin.", "tokens": ["Und", "straf", "und", "z\u00fcch\u00b7ti\u00b7ge", "die", "wil\u00b7de", "Neu\u00b7be\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Allein, erlaubst du ihr Victorien zu kr\u00e4ncken:", "tokens": ["Al\u00b7lein", ",", "er\u00b7laubst", "du", "ihr", "Vic\u00b7to\u00b7ri\u00b7en", "zu", "kr\u00e4n\u00b7cken", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Was meinst du, da\u00df ich soll von deiner Sanftmuth dencken?\u00ab", "tokens": ["Was", "meinst", "du", ",", "da\u00df", "ich", "soll", "von", "dei\u00b7ner", "Sanft\u00b7muth", "den\u00b7cken", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "So hertzhafft, als kaum je die kluge Porzia,", "tokens": ["So", "hertz\u00b7hafft", ",", "als", "kaum", "je", "die", "klu\u00b7ge", "Por\u00b7zia", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "ADV", "ADV", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.107": {"text": "Den Brutus angeredt, sprach hier Victoria.", "tokens": ["Den", "Bru\u00b7tus", "an\u00b7ge\u00b7redt", ",", "sprach", "hier", "Vic\u00b7to\u00b7ria", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVPP", "$,", "VVFIN", "ADV", "NE", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.108": {"text": "Ein sch\u00f6ner Mund wirckt mehr als eine G\u00f6tter-Stimme;", "tokens": ["Ein", "sch\u00f6\u00b7ner", "Mund", "wirckt", "mehr", "als", "ei\u00b7ne", "G\u00f6t\u00b7ter\u00b7Stim\u00b7me", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Ein Auge, das gef\u00e4llt, reitzt auch bey seinem Grimme;", "tokens": ["Ein", "Au\u00b7ge", ",", "das", "ge\u00b7f\u00e4llt", ",", "reitzt", "auch", "bey", "sei\u00b7nem", "Grim\u00b7me", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVPP", "$,", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Mit Bitten herrscht die Frau und mit Befehl der Mann;", "tokens": ["Mit", "Bit\u00b7ten", "herrscht", "die", "Frau", "und", "mit", "Be\u00b7fehl", "der", "Mann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "KON", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Die eine, wenn sie will, der andre, wenn er kan.", "tokens": ["Die", "ei\u00b7ne", ",", "wenn", "sie", "will", ",", "der", "and\u00b7re", ",", "wenn", "er", "kan", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "$,", "KOUS", "PPER", "VMFIN", "$,", "PRELS", "PIS", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Auch Gottsched muste sich, als Ehmann, hier bequehmen,", "tokens": ["Auch", "Gott\u00b7sched", "mus\u00b7te", "sich", ",", "als", "Eh\u00b7mann", ",", "hier", "be\u00b7queh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "VMFIN", "PRF", "$,", "KOUS", "NN", "$,", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Victoriens Parthey, aus Z\u00e4rtlichkeit, zu nehmen.", "tokens": ["Vic\u00b7to\u00b7ri\u00b7ens", "Par\u00b7they", ",", "aus", "Z\u00e4rt\u00b7lich\u00b7keit", ",", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "APPR", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Sie z\u00f6rnt, er w\u00fctet schon; sie droht, er bl\u00e4st zur Schlacht;", "tokens": ["Sie", "z\u00f6rnt", ",", "er", "w\u00fc\u00b7tet", "schon", ";", "sie", "droht", ",", "er", "bl\u00e4st", "zur", "Schlacht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Z\u00e4hlt an den Fingern her, wie viel er klein gemacht;", "tokens": ["Z\u00e4hlt", "an", "den", "Fin\u00b7gern", "her", ",", "wie", "viel", "er", "klein", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,", "PWAV", "PIS", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "F\u00e4ngt vom Picander an, der Schweitzer unvergessen,", "tokens": ["F\u00e4ngt", "vom", "Pi\u00b7can\u00b7der", "an", ",", "der", "Schweit\u00b7zer", "un\u00b7ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PTKVZ", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Bis auf den ", "tokens": ["Bis", "auf", "den"], "token_info": ["word", "word", "word"], "pos": ["APPR", "APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.118": {"text": "Kurtz, wie Terentzens Held, zu seinem Gnatho spricht,", "tokens": ["Kurtz", ",", "wie", "Te\u00b7rent\u00b7zens", "Held", ",", "zu", "sei\u00b7nem", "Gna\u00b7tho", "spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "NN", "NN", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Sprach er; jedoch vielleicht gleicht Thraso ihm noch nicht.", "tokens": ["Sprach", "er", ";", "je\u00b7doch", "viel\u00b7leicht", "gleicht", "Thra\u00b7so", "ihm", "noch", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$.", "ADV", "ADV", "VVFIN", "NE", "PPER", "ADV", "PTKNEG", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.120": {"text": "Vor allen Dingen wird dem Diener anbefohlen,", "tokens": ["Vor", "al\u00b7len", "Din\u00b7gen", "wird", "dem", "Die\u00b7ner", "an\u00b7be\u00b7foh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Drey Freunde, die man nennt, den Abend noch zu hohlen.", "tokens": ["Drey", "Freun\u00b7de", ",", "die", "man", "nennt", ",", "den", "A\u00b7bend", "noch", "zu", "hoh\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,", "ART", "NN", "ADV", "APPR", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Er l\u00e4ufft, der eine liegt an der Cholick zu Bett;", "tokens": ["Er", "l\u00e4ufft", ",", "der", "ei\u00b7ne", "liegt", "an", "der", "Cho\u00b7lick", "zu", "Bett", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ART", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.123": {"text": "Ein andrer sitzt", "tokens": ["Ein", "an\u00b7drer", "sitzt"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.124": {"text": "In seiner Monaths-Schrifft, in den Belustigungen;", "tokens": ["In", "sei\u00b7ner", "Mo\u00b7naths\u00b7Schrifft", ",", "in", "den", "Be\u00b7lus\u00b7ti\u00b7gun\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Der dritte k\u00f6mmt", "tokens": ["Der", "drit\u00b7te", "k\u00f6mmt"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.126": {"text": "Doch die Gesellschafft ist vor dieses mahl zu klein,", "tokens": ["Doch", "die", "Ge\u00b7sell\u00b7schafft", "ist", "vor", "die\u00b7ses", "mahl", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "APPR", "PDAT", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Drum ladet man auch ihn auf morgen wieder ein.", "tokens": ["Drum", "la\u00b7det", "man", "auch", "ihn", "auf", "mor\u00b7gen", "wie\u00b7der", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADV", "PPER", "APPR", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Der Abend und die Nacht verstrichen wie die Stunden,", "tokens": ["Der", "A\u00b7bend", "und", "die", "Nacht", "ver\u00b7stri\u00b7chen", "wie", "die", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Die der Egerie mit dem Pompil verschwunden.", "tokens": ["Die", "der", "E\u00b7ge\u00b7rie", "mit", "dem", "Pom\u00b7pil", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}}}}