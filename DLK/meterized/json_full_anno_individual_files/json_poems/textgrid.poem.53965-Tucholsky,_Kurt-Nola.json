{"textgrid.poem.53965": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Nola", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die schwarzen Platten tragen die Erinnerungen", "tokens": ["Die", "schwar\u00b7zen", "Plat\u00b7ten", "tra\u00b7gen", "die", "E\u00b7rin\u00b7ne\u00b7run\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und saugen auf, was sie mit uns erlebt . . .", "tokens": ["und", "sau\u00b7gen", "auf", ",", "was", "sie", "mit", "uns", "er\u00b7lebt", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "PRELS", "PPER", "APPR", "PPER", "VVPP", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbnola \u2013 \u00ab", "tokens": ["\u00bb", "no\u00b7la", "\u2013", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "FM", "$(", "$("], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "haben die M\u00e4nnerchen gesungen", "tokens": ["ha\u00b7ben", "die", "M\u00e4n\u00b7ner\u00b7chen", "ge\u00b7sun\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "VVPP"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "\u00bbnola \u2013 I love you \u2013 \u00ab", "tokens": ["\u00bb", "no\u00b7la", "\u2013", "I", "lo\u00b7ve", "yo\u00b7u", "\u2013", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "$(", "FM", "FM", "FM", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "die Membrane bebt . . .", "tokens": ["die", "Memb\u00b7ra\u00b7ne", "bebt", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$.", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Holznadel. Von vorn.", "tokens": ["Holz\u00b7na\u00b7del", ".", "Von", "vorn", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "APPR", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Und im Gesange schwebt heran", "tokens": ["Und", "im", "Ge\u00b7san\u00b7ge", "schwebt", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ein fr\u00fcher Tag im Herbst, mit allem Drum und Dran:", "tokens": ["ein", "fr\u00fc\u00b7her", "Tag", "im", "Herbst", ",", "mit", "al\u00b7lem", "Drum", "und", "Dran", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "$,", "APPR", "PIS", "PAV", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Das dicke Lottchen", "tokens": ["Das", "di\u00b7cke", "Lott\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "mit einem Wickel um den Hals \u2013", "tokens": ["mit", "ei\u00b7nem", "Wi\u00b7ckel", "um", "den", "Hals", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "die ", "tokens": ["die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "und lese, w\u00e4hrend alle Pulse klopfen,", "tokens": ["und", "le\u00b7se", ",", "w\u00e4h\u00b7rend", "al\u00b7le", "Pul\u00b7se", "klop\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "den neusten, d\u00fcmmsten Kriminalroman:", "tokens": ["den", "neus\u00b7ten", ",", "d\u00fcmms\u00b7ten", "Kri\u00b7mi\u00b7nal\u00b7ro\u00b7man", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "von England wird mit Mord und Tod bedroht,", "tokens": ["von", "En\u00b7gland", "wird", "mit", "Mord", "und", "Tod", "be\u00b7droht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "wenn er . . .", "tokens": ["wenn", "er", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "PPER", "$.", "$.", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.8": {"text": "Ja, gurgele nur mit Kali \u2013", "tokens": ["Ja", ",", "gur\u00b7ge\u00b7le", "nur", "mit", "Ka\u00b7li", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "ADV", "APPR", "NE", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "die Polizei ist fieberhaft im Schwung,", "tokens": ["die", "Po\u00b7li\u00b7zei", "ist", "fie\u00b7ber\u00b7haft", "im", "Schwung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die viere graben einen schwer geheimen Gang \u2013", "tokens": ["die", "vie\u00b7re", "gra\u00b7ben", "ei\u00b7nen", "schwer", "ge\u00b7hei\u00b7men", "Gang", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Manfred verr\u00e4t. Verr\u00e4t er? Oder nicht?", "tokens": ["Man\u00b7fred", "ver\u00b7r\u00e4t", ".", "Ver\u00b7r\u00e4t", "er", "?", "O\u00b7der", "nicht", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVPP", "$.", "NN", "PPER", "$.", "NE", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Nun wird der Abendhimmel sanft und blau \u2013", "tokens": ["Nun", "wird", "der", "A\u00b7bend\u00b7him\u00b7mel", "sanft", "und", "blau", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "das Lottchen ist mit Wonne krank und lieb und freundlich,", "tokens": ["das", "Lott\u00b7chen", "ist", "mit", "Won\u00b7ne", "krank", "und", "lieb", "und", "freund\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "ich trage ihr Kamillentee ans Bett \u2013", "tokens": ["ich", "tra\u00b7ge", "ihr", "Ka\u00b7mil\u00b7len\u00b7tee", "ans", "Bett", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "und st\u00fcrze mich von neuem in den Keller,", "tokens": ["und", "st\u00fcr\u00b7ze", "mich", "von", "neu\u00b7em", "in", "den", "Kel\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ADJA", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wo Manfred gr\u00e4bt. Das Attentat gelingt!", "tokens": ["wo", "Man\u00b7fred", "gr\u00e4bt", ".", "Das", "At\u00b7ten\u00b7tat", "ge\u00b7lingt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "VVFIN", "$.", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Tot wird der Chef in seinem Kabinett gefunden,", "tokens": ["Tot", "wird", "der", "Chef", "in", "sei\u00b7nem", "Ka\u00b7bi\u00b7nett", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "das Lottchen liest das Thermometer ab,", "tokens": ["das", "Lott\u00b7chen", "liest", "das", "Ther\u00b7mo\u00b7me\u00b7ter", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und das geht nach \u2013", "tokens": ["und", "das", "geht", "nach", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "APPR", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "verhallend: \u00bbNola \u2013 \u00ab", "tokens": ["ver\u00b7hal\u00b7lend", ":", "\u00bb", "No\u00b7la", "\u2013", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "punct", "punct"], "pos": ["VVPP", "$.", "$(", "NE", "$(", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Da ist Paris. Herr Tiger haben wohl geschlafen?", "tokens": ["Da", "ist", "Pa\u00b7ris", ".", "Herr", "Ti\u00b7ger", "ha\u00b7ben", "wohl", "ge\u00b7schla\u00b7fen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$.", "NN", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Platten bewahren alle Str\u00f6me auf, die sie jemals trafen \u2013", "tokens": ["Plat\u00b7ten", "be\u00b7wah\u00b7ren", "al\u00b7le", "Str\u00f6\u00b7me", "auf", ",", "die", "sie", "je\u00b7mals", "tra\u00b7fen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "PTKVZ", "$,", "PRELS", "PPER", "ADV", "VVINF", "$("], "meter": "+--+-+-+--+-+-+-", "measure": "iambic.septa.invert"}, "line.3": {"text": "Die hellen Herbstesn\u00e4chte sind entflohn . . .", "tokens": ["Die", "hel\u00b7len", "Herbs\u00b7tes\u00b7n\u00e4ch\u00b7te", "sind", "ent\u00b7flohn", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Erinnerung, du s\u00fc\u00dfes Grammophon \u2013!", "tokens": ["E\u00b7rin\u00b7ne\u00b7rung", ",", "du", "s\u00fc\u00b7\u00dfes", "Gram\u00b7mo\u00b7phon", "\u2013", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PPER", "ADJA", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Die schwarzen Platten tragen die Erinnerungen", "tokens": ["Die", "schwar\u00b7zen", "Plat\u00b7ten", "tra\u00b7gen", "die", "E\u00b7rin\u00b7ne\u00b7run\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und saugen auf, was sie mit uns erlebt . . .", "tokens": ["und", "sau\u00b7gen", "auf", ",", "was", "sie", "mit", "uns", "er\u00b7lebt", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "PRELS", "PPER", "APPR", "PPER", "VVPP", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbnola \u2013 \u00ab", "tokens": ["\u00bb", "no\u00b7la", "\u2013", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "FM", "$(", "$("], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "haben die M\u00e4nnerchen gesungen", "tokens": ["ha\u00b7ben", "die", "M\u00e4n\u00b7ner\u00b7chen", "ge\u00b7sun\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "VVPP"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "\u00bbnola \u2013 I love you \u2013 \u00ab", "tokens": ["\u00bb", "no\u00b7la", "\u2013", "I", "lo\u00b7ve", "yo\u00b7u", "\u2013", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "$(", "FM", "FM", "FM", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "die Membrane bebt . . .", "tokens": ["die", "Memb\u00b7ra\u00b7ne", "bebt", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$.", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Holznadel. Von vorn.", "tokens": ["Holz\u00b7na\u00b7del", ".", "Von", "vorn", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "APPR", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Und im Gesange schwebt heran", "tokens": ["Und", "im", "Ge\u00b7san\u00b7ge", "schwebt", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ein fr\u00fcher Tag im Herbst, mit allem Drum und Dran:", "tokens": ["ein", "fr\u00fc\u00b7her", "Tag", "im", "Herbst", ",", "mit", "al\u00b7lem", "Drum", "und", "Dran", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "$,", "APPR", "PIS", "PAV", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Das dicke Lottchen", "tokens": ["Das", "di\u00b7cke", "Lott\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "mit einem Wickel um den Hals \u2013", "tokens": ["mit", "ei\u00b7nem", "Wi\u00b7ckel", "um", "den", "Hals", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "die ", "tokens": ["die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "und lese, w\u00e4hrend alle Pulse klopfen,", "tokens": ["und", "le\u00b7se", ",", "w\u00e4h\u00b7rend", "al\u00b7le", "Pul\u00b7se", "klop\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "den neusten, d\u00fcmmsten Kriminalroman:", "tokens": ["den", "neus\u00b7ten", ",", "d\u00fcmms\u00b7ten", "Kri\u00b7mi\u00b7nal\u00b7ro\u00b7man", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "von England wird mit Mord und Tod bedroht,", "tokens": ["von", "En\u00b7gland", "wird", "mit", "Mord", "und", "Tod", "be\u00b7droht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "wenn er . . .", "tokens": ["wenn", "er", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "PPER", "$.", "$.", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.8": {"text": "Ja, gurgele nur mit Kali \u2013", "tokens": ["Ja", ",", "gur\u00b7ge\u00b7le", "nur", "mit", "Ka\u00b7li", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "ADV", "APPR", "NE", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "die Polizei ist fieberhaft im Schwung,", "tokens": ["die", "Po\u00b7li\u00b7zei", "ist", "fie\u00b7ber\u00b7haft", "im", "Schwung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die viere graben einen schwer geheimen Gang \u2013", "tokens": ["die", "vie\u00b7re", "gra\u00b7ben", "ei\u00b7nen", "schwer", "ge\u00b7hei\u00b7men", "Gang", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Manfred verr\u00e4t. Verr\u00e4t er? Oder nicht?", "tokens": ["Man\u00b7fred", "ver\u00b7r\u00e4t", ".", "Ver\u00b7r\u00e4t", "er", "?", "O\u00b7der", "nicht", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVPP", "$.", "NN", "PPER", "$.", "NE", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Nun wird der Abendhimmel sanft und blau \u2013", "tokens": ["Nun", "wird", "der", "A\u00b7bend\u00b7him\u00b7mel", "sanft", "und", "blau", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "das Lottchen ist mit Wonne krank und lieb und freundlich,", "tokens": ["das", "Lott\u00b7chen", "ist", "mit", "Won\u00b7ne", "krank", "und", "lieb", "und", "freund\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "ich trage ihr Kamillentee ans Bett \u2013", "tokens": ["ich", "tra\u00b7ge", "ihr", "Ka\u00b7mil\u00b7len\u00b7tee", "ans", "Bett", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "und st\u00fcrze mich von neuem in den Keller,", "tokens": ["und", "st\u00fcr\u00b7ze", "mich", "von", "neu\u00b7em", "in", "den", "Kel\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ADJA", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wo Manfred gr\u00e4bt. Das Attentat gelingt!", "tokens": ["wo", "Man\u00b7fred", "gr\u00e4bt", ".", "Das", "At\u00b7ten\u00b7tat", "ge\u00b7lingt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "VVFIN", "$.", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Tot wird der Chef in seinem Kabinett gefunden,", "tokens": ["Tot", "wird", "der", "Chef", "in", "sei\u00b7nem", "Ka\u00b7bi\u00b7nett", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "das Lottchen liest das Thermometer ab,", "tokens": ["das", "Lott\u00b7chen", "liest", "das", "Ther\u00b7mo\u00b7me\u00b7ter", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und das geht nach \u2013", "tokens": ["und", "das", "geht", "nach", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "APPR", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "verhallend: \u00bbNola \u2013 \u00ab", "tokens": ["ver\u00b7hal\u00b7lend", ":", "\u00bb", "No\u00b7la", "\u2013", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "punct", "punct"], "pos": ["VVPP", "$.", "$(", "NE", "$(", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.12": {"line.1": {"text": "Da ist Paris. Herr Tiger haben wohl geschlafen?", "tokens": ["Da", "ist", "Pa\u00b7ris", ".", "Herr", "Ti\u00b7ger", "ha\u00b7ben", "wohl", "ge\u00b7schla\u00b7fen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$.", "NN", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Platten bewahren alle Str\u00f6me auf, die sie jemals trafen \u2013", "tokens": ["Plat\u00b7ten", "be\u00b7wah\u00b7ren", "al\u00b7le", "Str\u00f6\u00b7me", "auf", ",", "die", "sie", "je\u00b7mals", "tra\u00b7fen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "PTKVZ", "$,", "PRELS", "PPER", "ADV", "VVINF", "$("], "meter": "+--+-+-+--+-+-+-", "measure": "iambic.septa.invert"}, "line.3": {"text": "Die hellen Herbstesn\u00e4chte sind entflohn . . .", "tokens": ["Die", "hel\u00b7len", "Herbs\u00b7tes\u00b7n\u00e4ch\u00b7te", "sind", "ent\u00b7flohn", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Erinnerung, du s\u00fc\u00dfes Grammophon \u2013!", "tokens": ["E\u00b7rin\u00b7ne\u00b7rung", ",", "du", "s\u00fc\u00b7\u00dfes", "Gram\u00b7mo\u00b7phon", "\u2013", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PPER", "ADJA", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}