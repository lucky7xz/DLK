{"textgrid.poem.44037": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Gesundheit, Gl\u00fcck und Trost und alles ist nun hin.", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gesundheit, Gl\u00fcck und Trost und alles ist nun hin.", "tokens": ["Ge\u00b7sund\u00b7heit", ",", "Gl\u00fcck", "und", "Trost", "und", "al\u00b7les", "ist", "nun", "hin", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "KON", "PIS", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mich wundert, da\u00df ich noch der Feder m\u00e4chtig bin;", "tokens": ["Mich", "wun\u00b7dert", ",", "da\u00df", "ich", "noch", "der", "Fe\u00b7der", "m\u00e4ch\u00b7tig", "bin", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Allein sie merckt es fast, wer da, nicht ich, geschrieben:", "tokens": ["Al\u00b7lein", "sie", "merckt", "es", "fast", ",", "wer", "da", ",", "nicht", "ich", ",", "ge\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ADV", "$,", "PWS", "ADV", "$,", "PTKNEG", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Himmel sey verehrt, der, da mich vieles pre\u00dft,", "tokens": ["Der", "Him\u00b7mel", "sey", "ver\u00b7ehrt", ",", "der", ",", "da", "mich", "vie\u00b7les", "pre\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "PRELS", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mir gleichwohl noch den Schaz von wenig Freunden l\u00e4st,", "tokens": ["Mir", "gleich\u00b7wohl", "noch", "den", "Schaz", "von", "we\u00b7nig", "Freun\u00b7den", "l\u00e4st", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die nicht aus Eigennuz noch blinder Einfalt lieben.", "tokens": ["Die", "nicht", "aus", "Ei\u00b7gen\u00b7nuz", "noch", "blin\u00b7der", "Ein\u00b7falt", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "APPR", "NN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Du bist, ich r\u00fchme mich auch bey der Sp\u00f6tter Hohn,", "tokens": ["Du", "bist", ",", "ich", "r\u00fch\u00b7me", "mich", "auch", "bey", "der", "Sp\u00f6t\u00b7ter", "Hohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von meiner Poesie der erstgebohrne Sohn", "tokens": ["Von", "mei\u00b7ner", "Poe\u00b7sie", "der", "erst\u00b7ge\u00b7bohr\u00b7ne", "Sohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und cr\u00f6nst dadurch mein Haupt mit neuen Lorbeerzweigen,", "tokens": ["Und", "cr\u00f6nst", "da\u00b7durch", "mein", "Haupt", "mit", "neu\u00b7en", "Lor\u00b7beer\u00b7zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein Herz ist von Natur so gut und treu gesinnt;", "tokens": ["Mein", "Herz", "ist", "von", "Na\u00b7tur", "so", "gut", "und", "treu", "ge\u00b7sinnt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "ADV", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sobald ein Mensch nur Lust zur Wi\u00dfenschaft gewinnt,", "tokens": ["So\u00b7bald", "ein", "Mensch", "nur", "Lust", "zur", "Wi\u00b7\u00dfen\u00b7schaft", "ge\u00b7winnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So wallt es vor Begier, ihm Rath und Weg zu zeigen.", "tokens": ["So", "wallt", "es", "vor", "Be\u00b7gier", ",", "ihm", "Rath", "und", "Weg", "zu", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$,", "PPER", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich hab ein kleines Pfund an Wei\u00dfheit und Verstand;", "tokens": ["Ich", "hab", "ein", "klei\u00b7nes", "Pfund", "an", "Wei\u00df\u00b7heit", "und", "Ver\u00b7stand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es w\u00fcrde dann und wann mit Nuzen angewand,", "tokens": ["Es", "w\u00fcr\u00b7de", "dann", "und", "wann", "mit", "Nu\u00b7zen", "an\u00b7ge\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "KON", "PWAV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wofern nur Feind und Noth den Vorsaz nicht betr\u00f6gen.", "tokens": ["Wo\u00b7fern", "nur", "Feind", "und", "Noth", "den", "Vor\u00b7saz", "nicht", "be\u00b7tr\u00f6\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "KON", "NN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jedennoch wenn auch nur ein einzig Wort bekleibt", "tokens": ["Je\u00b7den\u00b7noch", "wenn", "auch", "nur", "ein", "ein\u00b7zig", "Wort", "be\u00b7kleibt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ADV", "ADV", "ART", "ADJD", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und mancher, der mir buhlt, dem Zwecke n\u00e4her treibt,", "tokens": ["Und", "man\u00b7cher", ",", "der", "mir", "buhlt", ",", "dem", "Zwe\u00b7cke", "n\u00e4\u00b7her", "treibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So tr\u00f6stet sich mein Geist, er wuchre nach Verm\u00f6gen.", "tokens": ["So", "tr\u00f6s\u00b7tet", "sich", "mein", "Geist", ",", "er", "wuch\u00b7re", "nach", "Ver\u00b7m\u00f6\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ein grog- und rauher Stein macht Eisen blanck und scharf.", "tokens": ["Ein", "gro\u00b7g", "und", "rau\u00b7her", "Stein", "macht", "Ei\u00b7sen", "blanck", "und", "scharf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN", "VVFIN", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Dies Gleichn\u00fc\u00df zieh auf mich. Wofern ich rathen darf,", "tokens": ["Dies", "Gleich\u00b7n\u00fc\u00df", "zieh", "auf", "mich", ".", "Wo\u00b7fern", "ich", "ra\u00b7then", "darf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "APPR", "PPER", "$.", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So folge, werther Freund, dem aufgegangnen Lichte,", "tokens": ["So", "fol\u00b7ge", ",", "wert\u00b7her", "Freund", ",", "dem", "auf\u00b7ge\u00b7gang\u00b7nen", "Lich\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bau eifrig auf den Grund, den Wolf und Leibniz legt,", "tokens": ["Bau", "eif\u00b7rig", "auf", "den", "Grund", ",", "den", "Wolf", "und", "Leib\u00b7niz", "legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "$,", "ART", "NE", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Lis, pr\u00fcfe, denck und schreib; was eigner Flei\u00df nicht regt,", "tokens": ["Lis", ",", "pr\u00fc\u00b7fe", ",", "denck", "und", "schreib", ";", "was", "eig\u00b7ner", "Flei\u00df", "nicht", "regt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "VVIMP", "KON", "VVFIN", "$.", "PWS", "ADJA", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das, w\u00e4r es noch so gut, kriegt selten reife Fr\u00fcchte.", "tokens": ["Das", ",", "w\u00e4r", "es", "noch", "so", "gut", ",", "kriegt", "sel\u00b7ten", "rei\u00b7fe", "Fr\u00fcch\u00b7te", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "VVFIN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Erkennestu auch dich und vieles, was die Welt", "tokens": ["Er\u00b7ken\u00b7nes\u00b7tu", "auch", "dich", "und", "vie\u00b7les", ",", "was", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPER", "KON", "PIS", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der forschenden Vernunft zur \u00dcbung vorgestellt,", "tokens": ["Der", "for\u00b7schen\u00b7den", "Ver\u00b7nunft", "zur", "\u00dc\u00b7bung", "vor\u00b7ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So fang behutsam an, dein Gl\u00fccke fest zu sezen,", "tokens": ["So", "fang", "be\u00b7hut\u00b7sam", "an", ",", "dein", "Gl\u00fc\u00b7cke", "fest", "zu", "se\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PTKVZ", "$,", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Versorge Seel und Leib und sez ihr Heil in Ruh.", "tokens": ["Ver\u00b7sor\u00b7ge", "Seel", "und", "Leib", "und", "sez", "ihr", "Heil", "in", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "KON", "APPR", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Rast au\u00dfen Neid und Sturm, so sieh mit Gro\u00dfmuth zu", "tokens": ["Rast", "au\u00b7\u00dfen", "Neid", "und", "Sturm", ",", "so", "sieh", "mit", "Gro\u00df\u00b7muth", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "NN", "KON", "NN", "$,", "ADV", "VVFIN", "APPR", "NN", "PTKZU"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und lerne Farben, Schein, Beweis und Warheit sch\u00e4zen.", "tokens": ["Und", "ler\u00b7ne", "Far\u00b7ben", ",", "Schein", ",", "Be\u00b7weis", "und", "War\u00b7heit", "sch\u00e4\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Bewirb dich um den Kranz der wahren Dichterkunst;", "tokens": ["Be\u00b7wirb", "dich", "um", "den", "Kranz", "der", "wah\u00b7ren", "Dich\u00b7ter\u00b7kunst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie ist der Wei\u00dfheit Schmuck und bringt der Nachwelt Gunst;", "tokens": ["Sie", "ist", "der", "Wei\u00df\u00b7heit", "Schmuck", "und", "bringt", "der", "Nach\u00b7welt", "Gunst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir leben, stirbt das Fleisch, im klugen Angedencken;", "tokens": ["Wir", "le\u00b7ben", ",", "stirbt", "das", "Fleisch", ",", "im", "klu\u00b7gen", "An\u00b7ge\u00b7den\u00b7cken", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "ART", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie weckt, bes\u00e4nftigt, straft, erbaut, erg\u00f6zt und n\u00fczt,", "tokens": ["Sie", "weckt", ",", "be\u00b7s\u00e4nf\u00b7tigt", ",", "straft", ",", "er\u00b7baut", ",", "er\u00b7g\u00f6zt", "und", "n\u00fczt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVPP", "$,", "ADJD", "$,", "VVPP", "$,", "VVPP", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Giebt Enckeln Lust und Muth und macht den Geist erhizt,", "tokens": ["Giebt", "En\u00b7ckeln", "Lust", "und", "Muth", "und", "macht", "den", "Geist", "er\u00b7hizt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "NN", "KON", "NN", "KON", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Warheit, die man hast, ein g\u00fctig Ohr zu schencken.", "tokens": ["Der", "War\u00b7heit", ",", "die", "man", "hast", ",", "ein", "g\u00fc\u00b7tig", "Ohr", "zu", "schen\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VAFIN", "$,", "ART", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Die Alten gehn dir vor; die nimm und lis mit Flei\u00df.", "tokens": ["Die", "Al\u00b7ten", "gehn", "dir", "vor", ";", "die", "nimm", "und", "lis", "mit", "Flei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "VVIMP", "KON", "NE", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ihr Vorzug kostet sie viel N\u00e4chte, Kunst und Schwei\u00df.", "tokens": ["Ihr", "Vor\u00b7zug", "kos\u00b7tet", "sie", "viel", "N\u00e4ch\u00b7te", ",", "Kunst", "und", "Schwei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PIAT", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Virgil beschreibt genau, Homer bewegt und lodert,", "tokens": ["Vir\u00b7gil", "be\u00b7schreibt", "ge\u00b7nau", ",", "Ho\u00b7mer", "be\u00b7wegt", "und", "lo\u00b7dert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "$,", "NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Anacreon macht voll, Catull kan z\u00e4rtlich seyn,", "tokens": ["A\u00b7na\u00b7cre\u00b7on", "macht", "voll", ",", "Ca\u00b7tull", "kan", "z\u00e4rt\u00b7lich", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "$,", "NE", "VMFIN", "ADJD", "VAINF", "$,"], "meter": "+---+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Horaz ist reich und hoch, der Schwan von Sulmo rein,", "tokens": ["Ho\u00b7raz", "ist", "reich", "und", "hoch", ",", "der", "Schwan", "von", "Sul\u00b7mo", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "KON", "ADJD", "$,", "ART", "NN", "APPR", "NE", "ADJD", "$,"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.6": {"text": "Und was der Sappho fehlt, ist, da\u00df man mehrers fodert.", "tokens": ["Und", "was", "der", "Sap\u00b7pho", "fehlt", ",", "ist", ",", "da\u00df", "man", "meh\u00b7rers", "fo\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$,", "VAFIN", "$,", "KOUS", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Der Neuen Kunst f\u00e4llt ab; doch geht Petrarcha mit,", "tokens": ["Der", "Neu\u00b7en", "Kunst", "f\u00e4llt", "ab", ";", "doch", "geht", "Pe\u00b7trar\u00b7cha", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$.", "ADV", "VVFIN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der nebst noch wenigen die rechte Stra\u00dfe tritt.", "tokens": ["Der", "nebst", "noch", "we\u00b7ni\u00b7gen", "die", "rech\u00b7te", "Stra\u00b7\u00dfe", "tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PIAT", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sonst ha\u00df ich insgemein der Welschen hohe Grillen.", "tokens": ["Sonst", "ha\u00df", "ich", "ins\u00b7ge\u00b7mein", "der", "Wel\u00b7schen", "ho\u00b7he", "Gril\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was Ludwigs Gnadenglanz in Franckreich aufgeweckt,", "tokens": ["Was", "Lud\u00b7wigs", "Gna\u00b7den\u00b7glanz", "in", "Fran\u00b7ck\u00b7reich", "auf\u00b7ge\u00b7weckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "NN", "APPR", "NE", "VVPP", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Im Boileau, Racine und Moliere steckt,", "tokens": ["Im", "Boi\u00b7le\u00b7au", ",", "Ra\u00b7ci\u00b7ne", "und", "Mo\u00b7lie\u00b7re", "steckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "$,", "NN", "KON", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das kan ja auch die Lust gelehrter Sehnsucht stillen.", "tokens": ["Das", "kan", "ja", "auch", "die", "Lust", "ge\u00b7lehr\u00b7ter", "Sehn\u00b7sucht", "stil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ADV", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Der Deutsche kommt fein sp\u00e4t. Vom Opiz halt ich viel;", "tokens": ["Der", "Deut\u00b7sche", "kommt", "fein", "sp\u00e4t", ".", "Vom", "O\u00b7piz", "halt", "ich", "viel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ADJD", "$.", "APPRART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Geist des alten Gryph und Flemmings gr\u00fcndlich Spiel", "tokens": ["Der", "Geist", "des", "al\u00b7ten", "Gry\u00b7ph", "und", "Flem\u00b7mings", "gr\u00fcnd\u00b7lich", "Spiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "KON", "NN", "ADJD", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Verdient die Ewigkeit so gut als Neukirchs Fl\u00f6the;", "tokens": ["Ver\u00b7di\u00b7ent", "die", "E\u00b7wig\u00b7keit", "so", "gut", "als", "Neu\u00b7kirchs", "Fl\u00f6\u00b7the", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "ADV", "ADJD", "KOKOM", "CARD", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Im Caniz find ich Gold; die edle Lindenstadt", "tokens": ["Im", "Ca\u00b7niz", "find", "ich", "Gold", ";", "die", "ed\u00b7le", "Lin\u00b7den\u00b7stadt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Versteht nicht, was sie schon an Rabners Satyr hat;", "tokens": ["Ver\u00b7steht", "nicht", ",", "was", "sie", "schon", "an", "Rab\u00b7ners", "Sa\u00b7tyr", "hat", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PRELS", "PPER", "ADV", "APPR", "NN", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und manchem fehlt August, sonst w\u00fcrd er ein Poete.", "tokens": ["Und", "man\u00b7chem", "fehlt", "Au\u00b7gust", ",", "sonst", "w\u00fcrd", "er", "ein", "Poe\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "NN", "$,", "ADV", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.10": {"line.1": {"text": "Verdirb dein Urtheil nicht durch vielerley Geschmack,", "tokens": ["Ver\u00b7dirb", "dein", "Ur\u00b7theil", "nicht", "durch", "vie\u00b7ler\u00b7ley", "Ge\u00b7schmack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "PTKNEG", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hab einen weisen Freund, der scharf erinnern mag.", "tokens": ["Hab", "ei\u00b7nen", "wei\u00b7sen", "Freund", ",", "der", "scharf", "e\u00b7rin\u00b7nern", "mag."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "abbreviation"], "pos": ["NN", "ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Schreib wenig, aber gut, und schreite nicht auf Stelzen.", "tokens": ["Schreib", "we\u00b7nig", ",", "a\u00b7ber", "gut", ",", "und", "schrei\u00b7te", "nicht", "auf", "Stel\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "ADV", "ADJD", "$,", "KON", "VVFIN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und da der Phoebus stets dem Volcke, das er liebt,", "tokens": ["Und", "da", "der", "Phoe\u00b7bus", "stets", "dem", "Vol\u00b7cke", ",", "das", "er", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NE", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So wie auch Helden, nichts als Ruhm und Lorbeer giebt,", "tokens": ["So", "wie", "auch", "Hel\u00b7den", ",", "nichts", "als", "Ruhm", "und", "Lor\u00b7beer", "giebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "NN", "$,", "PIS", "KOKOM", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So halt es dir vor Schimpf, mit Reimen Geld zu schmelzen.", "tokens": ["So", "halt", "es", "dir", "vor", "Schimpf", ",", "mit", "Rei\u00b7men", "Geld", "zu", "schmel\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "$,", "APPR", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Du wilst nunmehr Bericht. Sobald ich Dresden lies,", "tokens": ["Du", "wilst", "nun\u00b7mehr", "Be\u00b7richt", ".", "So\u00b7bald", "ich", "Dres\u00b7den", "lies", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "NN", "$.", "KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beweint ich br\u00fcnstiglich der Sachsen Paradies.", "tokens": ["Be\u00b7weint", "ich", "br\u00fcns\u00b7tig\u00b7lich", "der", "Sach\u00b7sen", "Pa\u00b7ra\u00b7dies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bis Hirschberg hielt der Fu\u00df, drauf hinckt er, doch mit Freuden,", "tokens": ["Bis", "Hirschberg", "hielt", "der", "Fu\u00df", ",", "drauf", "hinckt", "er", ",", "doch", "mit", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$,", "PAV", "VVFIN", "PPER", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "In Meinung, sich davor in Striegau Guts zu thun.", "tokens": ["In", "Mei\u00b7nung", ",", "sich", "da\u00b7vor", "in", "Strie\u00b7gau", "Guts", "zu", "thun", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRF", "PAV", "APPR", "NE", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hier dacht ich mir einmahl mit Frieden auszuruhn", "tokens": ["Hier", "dacht", "ich", "mir", "ein\u00b7mahl", "mit", "Frie\u00b7den", "aus\u00b7zu\u00b7ruhn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und in der Eltern Schoos der L\u00e4strer Pfeil zu meiden.", "tokens": ["Und", "in", "der", "El\u00b7tern", "Schoos", "der", "L\u00e4st\u00b7rer", "Pfeil", "zu", "mei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ich gieng, ich kam und sah, ach, leider nichts als Leid.", "tokens": ["Ich", "gieng", ",", "ich", "kam", "und", "sah", ",", "ach", ",", "lei\u00b7der", "nichts", "als", "Leid", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "KON", "VVFIN", "$,", "ITJ", "$,", "ADV", "PIS", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein Vater lies mich vor. So viel vermag der Neid", "tokens": ["Kein", "Va\u00b7ter", "lies", "mich", "vor", ".", "So", "viel", "ver\u00b7mag", "der", "Neid"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und List und Eigensinn und Ha\u00df und Aberglauben.", "tokens": ["Und", "List", "und", "Ei\u00b7gen\u00b7sinn", "und", "Ha\u00df", "und", "A\u00b7berg\u00b7lau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die treue Mutter lag, die Schwester weint und schwieg.", "tokens": ["Die", "treu\u00b7e", "Mut\u00b7ter", "lag", ",", "die", "Schwes\u00b7ter", "weint", "und", "schwieg", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich zog mit Wehmuth aus; lieg, armes Striegau, lieg,", "tokens": ["Ich", "zog", "mit", "Weh\u00b7muth", "aus", ";", "lieg", ",", "ar\u00b7mes", "Strie\u00b7gau", ",", "lieg", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$.", "VVFIN", "$,", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich mag schon keinen Scherf aus deiner Asche klauben.", "tokens": ["Ich", "mag", "schon", "kei\u00b7nen", "Scherf", "aus", "dei\u00b7ner", "A\u00b7sche", "klau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Zwo Meilen f\u00fchrten mich nach Schweidniz bey der Nacht;", "tokens": ["Zwo", "Mei\u00b7len", "f\u00fchr\u00b7ten", "mich", "nach", "Schweid\u00b7niz", "bey", "der", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PRF", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Ankunft ward sogleich der Misgunst zugebracht,", "tokens": ["Die", "An\u00b7kunft", "ward", "sog\u00b7leich", "der", "Mis\u00b7gunst", "zu\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Misgunst, der ich dort viel Hecheln angehangen.", "tokens": ["Der", "Mis\u00b7gunst", ",", "der", "ich", "dort", "viel", "He\u00b7cheln", "an\u00b7ge\u00b7han\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Feinde drohten Lerm und schritten schon zur That.", "tokens": ["Die", "Fein\u00b7de", "droh\u00b7ten", "Lerm", "und", "schrit\u00b7ten", "schon", "zur", "That", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bleib, Schweidniz, was du bist, ich kenne deinen Rath", "tokens": ["Bleib", ",", "Schweid\u00b7niz", ",", "was", "du", "bist", ",", "ich", "ken\u00b7ne", "dei\u00b7nen", "Rath"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "PWS", "PPER", "VAFIN", "$,", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und habe schon in dir mein Gutes l\u00e4ngst empfangen.", "tokens": ["Und", "ha\u00b7be", "schon", "in", "dir", "mein", "Gu\u00b7tes", "l\u00e4ngst", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPR", "PPER", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Mit Sorgen, ohne Geld und durch die kr\u00fcmmste Bahn", "tokens": ["Mit", "Sor\u00b7gen", ",", "oh\u00b7ne", "Geld", "und", "durch", "die", "kr\u00fcmms\u00b7te", "Bahn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "KOUI", "NN", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gelangt ich wunderlich im gro\u00dfen Bre\u00dflau an.", "tokens": ["Ge\u00b7langt", "ich", "wun\u00b7der\u00b7lich", "im", "gro\u00b7\u00dfen", "Bre\u00df\u00b7lau", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich zecht auf Kreide los. Was hilft's? Die Noth lehrt bethen.", "tokens": ["Ich", "zecht", "auf", "Krei\u00b7de", "los", ".", "Was", "hilft's", "?", "Die", "Noth", "lehrt", "be\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$.", "PWS", "VVFIN", "$.", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+---", "measure": "unknown.measure.penta"}, "line.4": {"text": "Man sperrte mir das Maul mit viel Bef\u00f6rdrung auf;", "tokens": ["Man", "sperr\u00b7te", "mir", "das", "Maul", "mit", "viel", "Be\u00b7f\u00f6r\u00b7drung", "auf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Wind kam hinten nach und trieb mich hintern Lauf,", "tokens": ["Der", "Wind", "kam", "hin\u00b7ten", "nach", "und", "trieb", "mich", "hin\u00b7tern", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "KON", "VVFIN", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Eh Wafen, Feind und Schuld den kurzen Pa\u00df vertreten.", "tokens": ["Eh", "Wa\u00b7fen", ",", "Feind", "und", "Schuld", "den", "kur\u00b7zen", "Pa\u00df", "ver\u00b7tre\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Zwey St\u00fccke r\u00fchm ich noch. Des klugen Bre\u00dflers Haus", "tokens": ["Zwey", "St\u00fc\u00b7cke", "r\u00fchm", "ich", "noch", ".", "Des", "klu\u00b7gen", "Bre\u00df\u00b7lers", "Haus"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "PPER", "ADV", "$.", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gewann mein Dichten lieb. Hier wurden Schlaf und Schmaus", "tokens": ["Ge\u00b7wann", "mein", "Dich\u00b7ten", "lieb", ".", "Hier", "wur\u00b7den", "Schlaf", "und", "Schmaus"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "ADJD", "$.", "ADV", "VAFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit Lustgespr\u00e4chen, Wein und Versen aufgezogen.", "tokens": ["Mit", "Lust\u00b7ge\u00b7spr\u00e4\u00b7chen", ",", "Wein", "und", "Ver\u00b7sen", "auf\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Voraus entz\u00fcckte mich der sch\u00f6nen Wirthin Geist,", "tokens": ["Vo\u00b7raus", "ent\u00b7z\u00fcck\u00b7te", "mich", "der", "sch\u00f6\u00b7nen", "Wirt\u00b7hin", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Salz und Feuer f\u00fchrt und in der Feder weist,", "tokens": ["Die", "Salz", "und", "Feu\u00b7er", "f\u00fchrt", "und", "in", "der", "Fe\u00b7der", "weist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es hab ihr die Natur viel Pfunde zugewogen.", "tokens": ["Es", "hab", "ihr", "die", "Na\u00b7tur", "viel", "Pfun\u00b7de", "zu\u00b7ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Mit was vor Lust und Schmerz gedenck ich noch an dich,", "tokens": ["Mit", "was", "vor", "Lust", "und", "Schmerz", "ge\u00b7denck", "ich", "noch", "an", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "NN", "KON", "NN", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du ruhiges Camin! Bey dir erg\u00f6zten mich", "tokens": ["Du", "ru\u00b7hi\u00b7ges", "Ca\u00b7min", "!", "Bey", "dir", "er\u00b7g\u00f6z\u00b7ten", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$.", "APPR", "PPER", "VVFIN", "PPER"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Ein Baro in der That und einer nach dem Nahmen;", "tokens": ["Ein", "Ba\u00b7ro", "in", "der", "That", "und", "ei\u00b7ner", "nach", "dem", "Nah\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "KON", "ART", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der lezte scherzt galant, der erste spricht gelehrt,", "tokens": ["Der", "lez\u00b7te", "scherzt", "ga\u00b7lant", ",", "der", "ers\u00b7te", "spricht", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADJD", "$,", "ART", "ADJA", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kennt Wirthschaft, Hof und Vers. Was ward da nicht geh\u00f6rt,", "tokens": ["Kennt", "Wirth\u00b7schaft", ",", "Hof", "und", "Vers", ".", "Was", "ward", "da", "nicht", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "NN", "KON", "NN", "$.", "PWS", "VAFIN", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn Thor und b\u00f6se Zeit uns auf die Zunge kamen!", "tokens": ["Wenn", "Thor", "und", "b\u00f6\u00b7se", "Zeit", "uns", "auf", "die", "Zun\u00b7ge", "ka\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Noch jenseit blickt ein Schlo\u00df auf unsern Oderstrand;", "tokens": ["Noch", "jen\u00b7seit", "blickt", "ein", "Schlo\u00df", "auf", "un\u00b7sern", "O\u00b7der\u00b7strand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "(die Sp\u00f6tter suchen hier das Besenbinderland;)", "tokens": ["(", "die", "Sp\u00f6t\u00b7ter", "su\u00b7chen", "hier", "das", "Be\u00b7sen\u00b7bin\u00b7der\u00b7land", ";)"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "emoticon"], "pos": ["$(", "ART", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auf diesem lernt ich auch, da\u00df alte Gunst nicht roste.", "tokens": ["Auf", "die\u00b7sem", "lernt", "ich", "auch", ",", "da\u00df", "al\u00b7te", "Gunst", "nicht", "ros\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "ADV", "$,", "KOUS", "ADJA", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was thut nicht, dencke nach, Trunck, Freyheit, Liebe, Nacht?", "tokens": ["Was", "thut", "nicht", ",", "den\u00b7cke", "nach", ",", "Trunck", ",", "Frey\u00b7heit", ",", "Lie\u00b7be", ",", "Nacht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "$,", "VVFIN", "PTKVZ", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sobald der zw\u00f6lfte Schlag das Volck zur Ruh gebracht,", "tokens": ["So\u00b7bald", "der", "zw\u00f6lf\u00b7te", "Schlag", "das", "Volck", "zur", "Ruh", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Verga\u00dfen wir der Noth bey selbst gew\u00fcrztem Moste.", "tokens": ["Ver\u00b7ga\u00b7\u00dfen", "wir", "der", "Noth", "bey", "selbst", "ge\u00b7w\u00fcrz\u00b7tem", "Mos\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Ein traurig Lebewohl beschlo\u00df die keusche Lust.", "tokens": ["Ein", "trau\u00b7rig", "Le\u00b7be\u00b7wohl", "be\u00b7schlo\u00df", "die", "keu\u00b7sche", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O Himmel, da\u00df du stets so grausam wechseln must!", "tokens": ["O", "Him\u00b7mel", ",", "da\u00df", "du", "stets", "so", "grau\u00b7sam", "wech\u00b7seln", "must", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich ri\u00df mich br\u00fcnstig los, sie sah betr\u00fcbt zur\u00fccke.", "tokens": ["Ich", "ri\u00df", "mich", "br\u00fcns\u00b7tig", "los", ",", "sie", "sah", "be\u00b7tr\u00fcbt", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "PPER", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verstehstu, wie man liebt, so bild es dir nur ein,", "tokens": ["Ver\u00b7steh\u00b7stu", ",", "wie", "man", "liebt", ",", "so", "bild", "es", "dir", "nur", "ein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PIS", "VVFIN", "$,", "ADV", "ADJD", "PPER", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was Thr\u00e4nen solcher Angst vor Scheidewa\u00dfer seyn;", "tokens": ["Was", "Thr\u00e4\u00b7nen", "sol\u00b7cher", "Angst", "vor", "Schei\u00b7de\u00b7wa\u00b7\u00dfer", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "PIAT", "NN", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich f\u00fchl es, wenn ich nur das Abschiedslied erblicke.", "tokens": ["Ich", "f\u00fchl", "es", ",", "wenn", "ich", "nur", "das", "Ab\u00b7schieds\u00b7lied", "er\u00b7bli\u00b7cke", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Es geht auf Lauben zu: Ich me\u00dfe Thal und H\u00f6h", "tokens": ["Es", "geht", "auf", "Lau\u00b7ben", "zu", ":", "Ich", "me\u00b7\u00dfe", "Thal", "und", "H\u00f6h"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durch Graben, Regen, Wind, Frost, Unruh, Angst und Schnee.", "tokens": ["Durch", "Gra\u00b7ben", ",", "Re\u00b7gen", ",", "Wind", ",", "Frost", ",", "Un\u00b7ruh", ",", "Angst", "und", "Schnee", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie manches Nachtquartier beschwert mir Kopf und Lenden!", "tokens": ["Wie", "man\u00b7ches", "Nacht\u00b7quar\u00b7tier", "be\u00b7schwert", "mir", "Kopf", "und", "Len\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In Jauer st\u00e4rckt mich Gorn, ein alt- und treuer Freund,", "tokens": ["In", "Jau\u00b7er", "st\u00e4rckt", "mich", "Gorn", ",", "ein", "al\u00b7t", "und", "treu\u00b7er", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "NE", "$,", "ART", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Mit Bette, Tisch und Rath und dem, was trostreich scheint,", "tokens": ["Mit", "Bet\u00b7te", ",", "Tisch", "und", "Rath", "und", "dem", ",", "was", "trost\u00b7reich", "scheint", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "KON", "ART", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von Leuten meiner Qual Verzweiflung abzuwenden.", "tokens": ["Von", "Leu\u00b7ten", "mei\u00b7ner", "Qual", "Ver\u00b7zwei\u00b7flung", "ab\u00b7zu\u00b7wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Mit Noth erreich ich noch die Gr\u00e4nzstadt um den Queis,", "tokens": ["Mit", "Noth", "er\u00b7reich", "ich", "noch", "die", "Gr\u00e4nz\u00b7stadt", "um", "den", "Que\u00b7is", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "PPER", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um den sich jezt das Volck wohl kaum zu n\u00e4hren weis.", "tokens": ["Um", "den", "sich", "jezt", "das", "Volck", "wohl", "kaum", "zu", "n\u00e4h\u00b7ren", "weis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PRF", "ADV", "ART", "NN", "ADV", "ADV", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Armuth henckt sich auf, der Reiche will verzagen;", "tokens": ["Die", "Ar\u00b7muth", "henckt", "sich", "auf", ",", "der", "Rei\u00b7che", "will", "ver\u00b7za\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PTKVZ", "$,", "ART", "NE", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Hunger speist mit Lust von Eicheln, Rind und Stroh;", "tokens": ["Der", "Hun\u00b7ger", "speist", "mit", "Lust", "von", "Ei\u00b7cheln", ",", "Rind", "und", "Stroh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kein Gleichn\u00fc\u00df gleicht der Noth; in Cabul war es so", "tokens": ["Kein", "Gleich\u00b7n\u00fc\u00df", "gleicht", "der", "Noth", ";", "in", "Ca\u00b7bul", "war", "es", "so"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$.", "APPR", "NE", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und dort, wo Mosis Stab den d\u00fcrren Fels geschlagen.", "tokens": ["Und", "dort", ",", "wo", "Mo\u00b7sis", "Stab", "den", "d\u00fcr\u00b7ren", "Fels", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "NE", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "So komm ich \u00fcberall dem Elend eben recht.", "tokens": ["So", "komm", "ich", "\u00fc\u00b7be\u00b7rall", "dem", "E\u00b7lend", "e\u00b7ben", "recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier lieg ich nun gestreckt, die Kr\u00e4fte sind geschw\u00e4cht;", "tokens": ["Hier", "lieg", "ich", "nun", "ge\u00b7streckt", ",", "die", "Kr\u00e4f\u00b7te", "sind", "ge\u00b7schw\u00e4cht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "VVPP", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den Schenckel will der Flu\u00df, der Gram das Herze fre\u00dfen;", "tokens": ["Den", "Schen\u00b7ckel", "will", "der", "Flu\u00df", ",", "der", "Gram", "das", "Her\u00b7ze", "fre\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Nordwind deckt mich oft mit Flocken durch das Dach.", "tokens": ["Der", "Nord\u00b7wind", "deckt", "mich", "oft", "mit", "Flo\u00b7cken", "durch", "das", "Dach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kein Freund, kein Mensch, kein Hund erf\u00e4hrt mein Ungemach;", "tokens": ["Kein", "Freund", ",", "kein", "Mensch", ",", "kein", "Hund", "er\u00b7f\u00e4hrt", "mein", "Un\u00b7ge\u00b7mach", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dies kan ich auch sogar im Schlafe nicht verge\u00dfen.", "tokens": ["Dies", "kan", "ich", "auch", "so\u00b7gar", "im", "Schla\u00b7fe", "nicht", "ver\u00b7ge\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Mu\u00df ist ein schwerer Trost, doch ist's ein Trost vor den,", "tokens": ["Mu\u00df", "ist", "ein", "schwe\u00b7rer", "Trost", ",", "doch", "ist's", "ein", "Trost", "vor", "den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAFIN", "ART", "ADJA", "NN", "$,", "ADV", "VAFIN", "ART", "NN", "APPR", "ART", "$,"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.2": {"text": "Der, was er mit Vernunft zuvor schon \u00fcbersehn,", "tokens": ["Der", ",", "was", "er", "mit", "Ver\u00b7nunft", "zu\u00b7vor", "schon", "\u00fc\u00b7ber\u00b7sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWS", "PPER", "APPR", "NN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch durch Erfahrung lernt: Die Vorsicht kan nicht wancken.", "tokens": ["Auch", "durch", "Er\u00b7fah\u00b7rung", "lernt", ":", "Die", "Vor\u00b7sicht", "kan", "nicht", "wan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$.", "ART", "NN", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer ist ein Thor und flucht auf Wetter, Zeit und Ort?", "tokens": ["Wer", "ist", "ein", "Thor", "und", "flucht", "auf", "Wet\u00b7ter", ",", "Zeit", "und", "Ort", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "KON", "VVFIN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Schickung starcker Trieb geht ungehindert fort,", "tokens": ["Der", "Schi\u00b7ckung", "star\u00b7cker", "Trieb", "geht", "un\u00b7ge\u00b7hin\u00b7dert", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ohn Absicht auf den Wuntsch verdrie\u00dflicher Gedancken.", "tokens": ["Ohn", "Ab\u00b7sicht", "auf", "den", "Wunt\u00b7sch", "ver\u00b7drie\u00df\u00b7li\u00b7cher", "Ge\u00b7dan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.23": {"line.1": {"text": "Gott lege, was er will und was mir zukommt, auf.", "tokens": ["Gott", "le\u00b7ge", ",", "was", "er", "will", "und", "was", "mir", "zu\u00b7kommt", ",", "auf", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PWS", "PPER", "VMFIN", "KON", "PWS", "PPER", "VVFIN", "$,", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Er wird und darf auch nicht den wohlbestellten Lauf", "tokens": ["Er", "wird", "und", "darf", "auch", "nicht", "den", "wohl\u00b7be\u00b7stell\u00b7ten", "Lauf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "KON", "VMFIN", "ADV", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der gro\u00dfen Creatur erst mir zu Liebe st\u00f6ren.", "tokens": ["Der", "gro\u00b7\u00dfen", "Crea\u00b7tur", "erst", "mir", "zu", "Lie\u00b7be", "st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Sein Zweck ist \u00fcberhaupt des Weltgeb\u00e4udes Heil;", "tokens": ["Sein", "Zweck", "ist", "\u00fc\u00b7ber\u00b7haupt", "des", "Welt\u00b7ge\u00b7b\u00e4u\u00b7des", "Heil", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir, ich und auch mein Creuz, sind davon nur ein Theil", "tokens": ["Wir", ",", "ich", "und", "auch", "mein", "Creuz", ",", "sind", "da\u00b7von", "nur", "ein", "Theil"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PPER", "KON", "ADV", "PPOSAT", "NN", "$,", "VAFIN", "PAV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und m\u00fc\u00dfen auch den Schmuck der ganzen Ordnung mehren.", "tokens": ["Und", "m\u00fc\u00b7\u00dfen", "auch", "den", "Schmuck", "der", "gan\u00b7zen", "Ord\u00b7nung", "meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Dies mercke, werther Freund. Und dr\u00fcckt auch dich ein Joch,", "tokens": ["Dies", "mer\u00b7cke", ",", "wert\u00b7her", "Freund", ".", "Und", "dr\u00fcckt", "auch", "dich", "ein", "Joch", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "ADJA", "NN", "$.", "KON", "VVFIN", "ADV", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So schlepp es freudig mit. Mein Herz empfindet noch;", "tokens": ["So", "schlepp", "es", "freu\u00b7dig", "mit", ".", "Mein", "Herz", "emp\u00b7fin\u00b7det", "noch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "PPOSAT", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Seele der Gedult will ich die Hofnung nennen.", "tokens": ["Die", "See\u00b7le", "der", "Ge\u00b7dult", "will", "ich", "die", "Hof\u00b7nung", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Gl\u00fccke schl\u00e4ft recht aus, wofern ich scherzen mag,", "tokens": ["Das", "Gl\u00fc\u00b7cke", "schl\u00e4ft", "recht", "aus", ",", "wo\u00b7fern", "ich", "scher\u00b7zen", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Damit, wenn einmahl kommt sein Auferstehungstag,", "tokens": ["Da\u00b7mit", ",", "wenn", "ein\u00b7mahl", "kommt", "sein", "Auf\u00b7er\u00b7ste\u00b7hungs\u00b7tag", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wir desto muntrer seyn und l\u00e4nger wachen k\u00f6nnen.", "tokens": ["Wir", "des\u00b7to", "mun\u00b7trer", "seyn", "und", "l\u00e4n\u00b7ger", "wa\u00b7chen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VAINF", "KON", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Das Ansehn unsrer Zeit droht L\u00e4ndern hier und dar,", "tokens": ["Das", "An\u00b7sehn", "uns\u00b7rer", "Zeit", "droht", "L\u00e4n\u00b7dern", "hier", "und", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "NN", "ADV", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man braucht nicht weit zu sehn, viel Jammer und Gefahr.", "tokens": ["Man", "braucht", "nicht", "weit", "zu", "sehn", ",", "viel", "Jam\u00b7mer", "und", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$,", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach armes Schlesien, du liegst zu nah an Polen.", "tokens": ["Ach", "ar\u00b7mes", "Schle\u00b7si\u00b7en", ",", "du", "liegst", "zu", "nah", "an", "Po\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJA", "NN", "$,", "PPER", "VVFIN", "PTKA", "ADJD", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gewis, wir haben viel und gro\u00dfe Ding erlebt;", "tokens": ["Ge\u00b7wis", ",", "wir", "ha\u00b7ben", "viel", "und", "gro\u00b7\u00dfe", "Ding", "er\u00b7lebt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADV", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Las seyn, da\u00df alles bricht und Erd und Abgrund bebt,", "tokens": ["Las", "seyn", ",", "da\u00df", "al\u00b7les", "bricht", "und", "Erd", "und", "Ab\u00b7grund", "bebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAINF", "$,", "KOUS", "PIS", "VVFIN", "KON", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Weiser weis den Trost blos in sich selbst zu holen.", "tokens": ["Ein", "Wei\u00b7ser", "weis", "den", "Trost", "blos", "in", "sich", "selbst", "zu", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "ART", "NN", "ADV", "APPR", "PRF", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Carl hat Verdienst und Macht, der Herr ist Tempel werth.", "tokens": ["Carl", "hat", "Ver\u00b7dienst", "und", "Macht", ",", "der", "Herr", "ist", "Tem\u00b7pel", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NN", "KON", "NN", "$,", "ART", "NN", "VAFIN", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er siegt in West und Ost und giebt auf Blut und Schwerd", "tokens": ["Er", "siegt", "in", "West", "und", "Ost", "und", "giebt", "auf", "Blut", "und", "Schwerd"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "KON", "NN", "KON", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "(was k\u00f6nt er Gr\u00f6\u00dfers thun?) den V\u00f6lckern Schuz und Friede.", "tokens": ["(", "was", "k\u00f6nt", "er", "Gr\u00f6\u00b7\u00dfers", "thun", "?", ")", "den", "V\u00f6l\u00b7ckern", "Schuz", "und", "Frie\u00b7de", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "PPER", "NN", "VVINF", "$.", "$(", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer weis, wie unverhoft sein Arm in deutscher Luft", "tokens": ["Wer", "weis", ",", "wie", "un\u00b7ver\u00b7hoft", "sein", "Arm", "in", "deut\u00b7scher", "Luft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKVZ", "$,", "PWAV", "ADJD", "PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Musen g\u00f6ldne Zeit aus ihren Winckeln ruft?", "tokens": ["Der", "Mu\u00b7sen", "g\u00f6ld\u00b7ne", "Zeit", "aus", "ih\u00b7ren", "Win\u00b7ckeln", "ruft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Europa, mache nur der Feinde Thorheit m\u00fcde!", "tokens": ["Eu\u00b7ro\u00b7pa", ",", "ma\u00b7che", "nur", "der", "Fein\u00b7de", "Thor\u00b7heit", "m\u00fc\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "ADV", "ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Der Herr, der Cronen nimmt, auch Cronen giebt und h\u00e4lt,", "tokens": ["Der", "Herr", ",", "der", "Cro\u00b7nen", "nimmt", ",", "auch", "Cro\u00b7nen", "giebt", "und", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,", "ADV", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erhalte Rudolphs Stamm, das Wunder unsrer Welt,", "tokens": ["Er\u00b7hal\u00b7te", "Ru\u00b7dolphs", "Stamm", ",", "das", "Wun\u00b7der", "uns\u00b7rer", "Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und mehre durch sein Blut den Saamen der Gerechten.", "tokens": ["Und", "meh\u00b7re", "durch", "sein", "Blut", "den", "Saa\u00b7men", "der", "Ge\u00b7rech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So lange Carl noch lebt und Sachsens Raute bl\u00fcht,", "tokens": ["So", "lan\u00b7ge", "Carl", "noch", "lebt", "und", "Sach\u00b7sens", "Rau\u00b7te", "bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "ADV", "VVFIN", "KON", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So lange f\u00fcrcht ich nicht, so schlecht es immer sieht,", "tokens": ["So", "lan\u00b7ge", "f\u00fcrcht", "ich", "nicht", ",", "so", "schlecht", "es", "im\u00b7mer", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df Neid und Barbarey in Deutschland siegen m\u00f6chten.", "tokens": ["Da\u00df", "Neid", "und", "Bar\u00b7ba\u00b7rey", "in", "Deutschland", "sie\u00b7gen", "m\u00f6ch\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "APPR", "NE", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.28": {"line.1": {"text": "Was etwan \u00fcbrig ist, (die Dinte wird fast hart)", "tokens": ["Was", "et\u00b7wan", "\u00fcb\u00b7rig", "ist", ",", "(", "die", "Din\u00b7te", "wird", "fast", "hart", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "VAFIN", "$,", "$(", "ART", "NN", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das hast der Reime Zwang und will nur Gegenwart;", "tokens": ["Das", "hast", "der", "Rei\u00b7me", "Zwang", "und", "will", "nur", "Ge\u00b7gen\u00b7wart", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "KON", "VMFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich habe viel mit dir, es wird sich ehstens schicken.", "tokens": ["Ich", "ha\u00b7be", "viel", "mit", "dir", ",", "es", "wird", "sich", "ehs\u00b7tens", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPER", "$,", "PPER", "VAFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Schreib, eile, sey nicht kurz. Ein S\u00e4ugling sucht die Brust;", "tokens": ["Schreib", ",", "ei\u00b7le", ",", "sey", "nicht", "kurz", ".", "Ein", "S\u00e4ug\u00b7ling", "sucht", "die", "Brust", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VAFIN", "PTKNEG", "ADJD", "$.", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Sehnsucht, edler Freund, hat auch nur halbe Lust,", "tokens": ["Die", "Sehn\u00b7sucht", ",", "ed\u00b7ler", "Freund", ",", "hat", "auch", "nur", "hal\u00b7be", "Lust", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJA", "NN", "$,", "VAFIN", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den Ku\u00df, der dir geh\u00f6rt, auf kalt Papier zu dr\u00fccken.", "tokens": ["Den", "Ku\u00df", ",", "der", "dir", "ge\u00b7h\u00f6rt", ",", "auf", "kalt", "Pa\u00b7pier", "zu", "dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPR", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Gesundheit, Gl\u00fcck und Trost und alles ist nun hin.", "tokens": ["Ge\u00b7sund\u00b7heit", ",", "Gl\u00fcck", "und", "Trost", "und", "al\u00b7les", "ist", "nun", "hin", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "KON", "PIS", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mich wundert, da\u00df ich noch der Feder m\u00e4chtig bin;", "tokens": ["Mich", "wun\u00b7dert", ",", "da\u00df", "ich", "noch", "der", "Fe\u00b7der", "m\u00e4ch\u00b7tig", "bin", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Allein sie merckt es fast, wer da, nicht ich, geschrieben:", "tokens": ["Al\u00b7lein", "sie", "merckt", "es", "fast", ",", "wer", "da", ",", "nicht", "ich", ",", "ge\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ADV", "$,", "PWS", "ADV", "$,", "PTKNEG", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Himmel sey verehrt, der, da mich vieles pre\u00dft,", "tokens": ["Der", "Him\u00b7mel", "sey", "ver\u00b7ehrt", ",", "der", ",", "da", "mich", "vie\u00b7les", "pre\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "PRELS", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mir gleichwohl noch den Schaz von wenig Freunden l\u00e4st,", "tokens": ["Mir", "gleich\u00b7wohl", "noch", "den", "Schaz", "von", "we\u00b7nig", "Freun\u00b7den", "l\u00e4st", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die nicht aus Eigennuz noch blinder Einfalt lieben.", "tokens": ["Die", "nicht", "aus", "Ei\u00b7gen\u00b7nuz", "noch", "blin\u00b7der", "Ein\u00b7falt", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "APPR", "NN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Du bist, ich r\u00fchme mich auch bey der Sp\u00f6tter Hohn,", "tokens": ["Du", "bist", ",", "ich", "r\u00fch\u00b7me", "mich", "auch", "bey", "der", "Sp\u00f6t\u00b7ter", "Hohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von meiner Poesie der erstgebohrne Sohn", "tokens": ["Von", "mei\u00b7ner", "Poe\u00b7sie", "der", "erst\u00b7ge\u00b7bohr\u00b7ne", "Sohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und cr\u00f6nst dadurch mein Haupt mit neuen Lorbeerzweigen,", "tokens": ["Und", "cr\u00f6nst", "da\u00b7durch", "mein", "Haupt", "mit", "neu\u00b7en", "Lor\u00b7beer\u00b7zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein Herz ist von Natur so gut und treu gesinnt;", "tokens": ["Mein", "Herz", "ist", "von", "Na\u00b7tur", "so", "gut", "und", "treu", "ge\u00b7sinnt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "ADV", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sobald ein Mensch nur Lust zur Wi\u00dfenschaft gewinnt,", "tokens": ["So\u00b7bald", "ein", "Mensch", "nur", "Lust", "zur", "Wi\u00b7\u00dfen\u00b7schaft", "ge\u00b7winnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So wallt es vor Begier, ihm Rath und Weg zu zeigen.", "tokens": ["So", "wallt", "es", "vor", "Be\u00b7gier", ",", "ihm", "Rath", "und", "Weg", "zu", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$,", "PPER", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Ich hab ein kleines Pfund an Wei\u00dfheit und Verstand;", "tokens": ["Ich", "hab", "ein", "klei\u00b7nes", "Pfund", "an", "Wei\u00df\u00b7heit", "und", "Ver\u00b7stand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es w\u00fcrde dann und wann mit Nuzen angewand,", "tokens": ["Es", "w\u00fcr\u00b7de", "dann", "und", "wann", "mit", "Nu\u00b7zen", "an\u00b7ge\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "KON", "PWAV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wofern nur Feind und Noth den Vorsaz nicht betr\u00f6gen.", "tokens": ["Wo\u00b7fern", "nur", "Feind", "und", "Noth", "den", "Vor\u00b7saz", "nicht", "be\u00b7tr\u00f6\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "KON", "NN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jedennoch wenn auch nur ein einzig Wort bekleibt", "tokens": ["Je\u00b7den\u00b7noch", "wenn", "auch", "nur", "ein", "ein\u00b7zig", "Wort", "be\u00b7kleibt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ADV", "ADV", "ART", "ADJD", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und mancher, der mir buhlt, dem Zwecke n\u00e4her treibt,", "tokens": ["Und", "man\u00b7cher", ",", "der", "mir", "buhlt", ",", "dem", "Zwe\u00b7cke", "n\u00e4\u00b7her", "treibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So tr\u00f6stet sich mein Geist, er wuchre nach Verm\u00f6gen.", "tokens": ["So", "tr\u00f6s\u00b7tet", "sich", "mein", "Geist", ",", "er", "wuch\u00b7re", "nach", "Ver\u00b7m\u00f6\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Ein grog- und rauher Stein macht Eisen blanck und scharf.", "tokens": ["Ein", "gro\u00b7g", "und", "rau\u00b7her", "Stein", "macht", "Ei\u00b7sen", "blanck", "und", "scharf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN", "VVFIN", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Dies Gleichn\u00fc\u00df zieh auf mich. Wofern ich rathen darf,", "tokens": ["Dies", "Gleich\u00b7n\u00fc\u00df", "zieh", "auf", "mich", ".", "Wo\u00b7fern", "ich", "ra\u00b7then", "darf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "APPR", "PPER", "$.", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So folge, werther Freund, dem aufgegangnen Lichte,", "tokens": ["So", "fol\u00b7ge", ",", "wert\u00b7her", "Freund", ",", "dem", "auf\u00b7ge\u00b7gang\u00b7nen", "Lich\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bau eifrig auf den Grund, den Wolf und Leibniz legt,", "tokens": ["Bau", "eif\u00b7rig", "auf", "den", "Grund", ",", "den", "Wolf", "und", "Leib\u00b7niz", "legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "$,", "ART", "NE", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Lis, pr\u00fcfe, denck und schreib; was eigner Flei\u00df nicht regt,", "tokens": ["Lis", ",", "pr\u00fc\u00b7fe", ",", "denck", "und", "schreib", ";", "was", "eig\u00b7ner", "Flei\u00df", "nicht", "regt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "VVIMP", "KON", "VVFIN", "$.", "PWS", "ADJA", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das, w\u00e4r es noch so gut, kriegt selten reife Fr\u00fcchte.", "tokens": ["Das", ",", "w\u00e4r", "es", "noch", "so", "gut", ",", "kriegt", "sel\u00b7ten", "rei\u00b7fe", "Fr\u00fcch\u00b7te", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "VVFIN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Erkennestu auch dich und vieles, was die Welt", "tokens": ["Er\u00b7ken\u00b7nes\u00b7tu", "auch", "dich", "und", "vie\u00b7les", ",", "was", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPER", "KON", "PIS", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der forschenden Vernunft zur \u00dcbung vorgestellt,", "tokens": ["Der", "for\u00b7schen\u00b7den", "Ver\u00b7nunft", "zur", "\u00dc\u00b7bung", "vor\u00b7ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So fang behutsam an, dein Gl\u00fccke fest zu sezen,", "tokens": ["So", "fang", "be\u00b7hut\u00b7sam", "an", ",", "dein", "Gl\u00fc\u00b7cke", "fest", "zu", "se\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PTKVZ", "$,", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Versorge Seel und Leib und sez ihr Heil in Ruh.", "tokens": ["Ver\u00b7sor\u00b7ge", "Seel", "und", "Leib", "und", "sez", "ihr", "Heil", "in", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "KON", "APPR", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Rast au\u00dfen Neid und Sturm, so sieh mit Gro\u00dfmuth zu", "tokens": ["Rast", "au\u00b7\u00dfen", "Neid", "und", "Sturm", ",", "so", "sieh", "mit", "Gro\u00df\u00b7muth", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "NN", "KON", "NN", "$,", "ADV", "VVFIN", "APPR", "NN", "PTKZU"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und lerne Farben, Schein, Beweis und Warheit sch\u00e4zen.", "tokens": ["Und", "ler\u00b7ne", "Far\u00b7ben", ",", "Schein", ",", "Be\u00b7weis", "und", "War\u00b7heit", "sch\u00e4\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Bewirb dich um den Kranz der wahren Dichterkunst;", "tokens": ["Be\u00b7wirb", "dich", "um", "den", "Kranz", "der", "wah\u00b7ren", "Dich\u00b7ter\u00b7kunst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie ist der Wei\u00dfheit Schmuck und bringt der Nachwelt Gunst;", "tokens": ["Sie", "ist", "der", "Wei\u00df\u00b7heit", "Schmuck", "und", "bringt", "der", "Nach\u00b7welt", "Gunst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir leben, stirbt das Fleisch, im klugen Angedencken;", "tokens": ["Wir", "le\u00b7ben", ",", "stirbt", "das", "Fleisch", ",", "im", "klu\u00b7gen", "An\u00b7ge\u00b7den\u00b7cken", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "ART", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie weckt, bes\u00e4nftigt, straft, erbaut, erg\u00f6zt und n\u00fczt,", "tokens": ["Sie", "weckt", ",", "be\u00b7s\u00e4nf\u00b7tigt", ",", "straft", ",", "er\u00b7baut", ",", "er\u00b7g\u00f6zt", "und", "n\u00fczt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVPP", "$,", "ADJD", "$,", "VVPP", "$,", "VVPP", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Giebt Enckeln Lust und Muth und macht den Geist erhizt,", "tokens": ["Giebt", "En\u00b7ckeln", "Lust", "und", "Muth", "und", "macht", "den", "Geist", "er\u00b7hizt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "NN", "KON", "NN", "KON", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Warheit, die man hast, ein g\u00fctig Ohr zu schencken.", "tokens": ["Der", "War\u00b7heit", ",", "die", "man", "hast", ",", "ein", "g\u00fc\u00b7tig", "Ohr", "zu", "schen\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VAFIN", "$,", "ART", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Die Alten gehn dir vor; die nimm und lis mit Flei\u00df.", "tokens": ["Die", "Al\u00b7ten", "gehn", "dir", "vor", ";", "die", "nimm", "und", "lis", "mit", "Flei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "VVIMP", "KON", "NE", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ihr Vorzug kostet sie viel N\u00e4chte, Kunst und Schwei\u00df.", "tokens": ["Ihr", "Vor\u00b7zug", "kos\u00b7tet", "sie", "viel", "N\u00e4ch\u00b7te", ",", "Kunst", "und", "Schwei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PIAT", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Virgil beschreibt genau, Homer bewegt und lodert,", "tokens": ["Vir\u00b7gil", "be\u00b7schreibt", "ge\u00b7nau", ",", "Ho\u00b7mer", "be\u00b7wegt", "und", "lo\u00b7dert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "$,", "NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Anacreon macht voll, Catull kan z\u00e4rtlich seyn,", "tokens": ["A\u00b7na\u00b7cre\u00b7on", "macht", "voll", ",", "Ca\u00b7tull", "kan", "z\u00e4rt\u00b7lich", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "$,", "NE", "VMFIN", "ADJD", "VAINF", "$,"], "meter": "+---+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Horaz ist reich und hoch, der Schwan von Sulmo rein,", "tokens": ["Ho\u00b7raz", "ist", "reich", "und", "hoch", ",", "der", "Schwan", "von", "Sul\u00b7mo", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "KON", "ADJD", "$,", "ART", "NN", "APPR", "NE", "ADJD", "$,"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.6": {"text": "Und was der Sappho fehlt, ist, da\u00df man mehrers fodert.", "tokens": ["Und", "was", "der", "Sap\u00b7pho", "fehlt", ",", "ist", ",", "da\u00df", "man", "meh\u00b7rers", "fo\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$,", "VAFIN", "$,", "KOUS", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Der Neuen Kunst f\u00e4llt ab; doch geht Petrarcha mit,", "tokens": ["Der", "Neu\u00b7en", "Kunst", "f\u00e4llt", "ab", ";", "doch", "geht", "Pe\u00b7trar\u00b7cha", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$.", "ADV", "VVFIN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der nebst noch wenigen die rechte Stra\u00dfe tritt.", "tokens": ["Der", "nebst", "noch", "we\u00b7ni\u00b7gen", "die", "rech\u00b7te", "Stra\u00b7\u00dfe", "tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PIAT", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sonst ha\u00df ich insgemein der Welschen hohe Grillen.", "tokens": ["Sonst", "ha\u00df", "ich", "ins\u00b7ge\u00b7mein", "der", "Wel\u00b7schen", "ho\u00b7he", "Gril\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was Ludwigs Gnadenglanz in Franckreich aufgeweckt,", "tokens": ["Was", "Lud\u00b7wigs", "Gna\u00b7den\u00b7glanz", "in", "Fran\u00b7ck\u00b7reich", "auf\u00b7ge\u00b7weckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "NN", "APPR", "NE", "VVPP", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Im Boileau, Racine und Moliere steckt,", "tokens": ["Im", "Boi\u00b7le\u00b7au", ",", "Ra\u00b7ci\u00b7ne", "und", "Mo\u00b7lie\u00b7re", "steckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "$,", "NN", "KON", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das kan ja auch die Lust gelehrter Sehnsucht stillen.", "tokens": ["Das", "kan", "ja", "auch", "die", "Lust", "ge\u00b7lehr\u00b7ter", "Sehn\u00b7sucht", "stil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ADV", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Der Deutsche kommt fein sp\u00e4t. Vom Opiz halt ich viel;", "tokens": ["Der", "Deut\u00b7sche", "kommt", "fein", "sp\u00e4t", ".", "Vom", "O\u00b7piz", "halt", "ich", "viel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ADJD", "$.", "APPRART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Geist des alten Gryph und Flemmings gr\u00fcndlich Spiel", "tokens": ["Der", "Geist", "des", "al\u00b7ten", "Gry\u00b7ph", "und", "Flem\u00b7mings", "gr\u00fcnd\u00b7lich", "Spiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "KON", "NN", "ADJD", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Verdient die Ewigkeit so gut als Neukirchs Fl\u00f6the;", "tokens": ["Ver\u00b7di\u00b7ent", "die", "E\u00b7wig\u00b7keit", "so", "gut", "als", "Neu\u00b7kirchs", "Fl\u00f6\u00b7the", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "ADV", "ADJD", "KOKOM", "CARD", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Im Caniz find ich Gold; die edle Lindenstadt", "tokens": ["Im", "Ca\u00b7niz", "find", "ich", "Gold", ";", "die", "ed\u00b7le", "Lin\u00b7den\u00b7stadt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Versteht nicht, was sie schon an Rabners Satyr hat;", "tokens": ["Ver\u00b7steht", "nicht", ",", "was", "sie", "schon", "an", "Rab\u00b7ners", "Sa\u00b7tyr", "hat", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PRELS", "PPER", "ADV", "APPR", "NN", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und manchem fehlt August, sonst w\u00fcrd er ein Poete.", "tokens": ["Und", "man\u00b7chem", "fehlt", "Au\u00b7gust", ",", "sonst", "w\u00fcrd", "er", "ein", "Poe\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "NN", "$,", "ADV", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.38": {"line.1": {"text": "Verdirb dein Urtheil nicht durch vielerley Geschmack,", "tokens": ["Ver\u00b7dirb", "dein", "Ur\u00b7theil", "nicht", "durch", "vie\u00b7ler\u00b7ley", "Ge\u00b7schmack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "PTKNEG", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hab einen weisen Freund, der scharf erinnern mag.", "tokens": ["Hab", "ei\u00b7nen", "wei\u00b7sen", "Freund", ",", "der", "scharf", "e\u00b7rin\u00b7nern", "mag."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "abbreviation"], "pos": ["NN", "ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Schreib wenig, aber gut, und schreite nicht auf Stelzen.", "tokens": ["Schreib", "we\u00b7nig", ",", "a\u00b7ber", "gut", ",", "und", "schrei\u00b7te", "nicht", "auf", "Stel\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "ADV", "ADJD", "$,", "KON", "VVFIN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und da der Phoebus stets dem Volcke, das er liebt,", "tokens": ["Und", "da", "der", "Phoe\u00b7bus", "stets", "dem", "Vol\u00b7cke", ",", "das", "er", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NE", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So wie auch Helden, nichts als Ruhm und Lorbeer giebt,", "tokens": ["So", "wie", "auch", "Hel\u00b7den", ",", "nichts", "als", "Ruhm", "und", "Lor\u00b7beer", "giebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "NN", "$,", "PIS", "KOKOM", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So halt es dir vor Schimpf, mit Reimen Geld zu schmelzen.", "tokens": ["So", "halt", "es", "dir", "vor", "Schimpf", ",", "mit", "Rei\u00b7men", "Geld", "zu", "schmel\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "$,", "APPR", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.39": {"line.1": {"text": "Du wilst nunmehr Bericht. Sobald ich Dresden lies,", "tokens": ["Du", "wilst", "nun\u00b7mehr", "Be\u00b7richt", ".", "So\u00b7bald", "ich", "Dres\u00b7den", "lies", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "NN", "$.", "KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beweint ich br\u00fcnstiglich der Sachsen Paradies.", "tokens": ["Be\u00b7weint", "ich", "br\u00fcns\u00b7tig\u00b7lich", "der", "Sach\u00b7sen", "Pa\u00b7ra\u00b7dies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bis Hirschberg hielt der Fu\u00df, drauf hinckt er, doch mit Freuden,", "tokens": ["Bis", "Hirschberg", "hielt", "der", "Fu\u00df", ",", "drauf", "hinckt", "er", ",", "doch", "mit", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$,", "PAV", "VVFIN", "PPER", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "In Meinung, sich davor in Striegau Guts zu thun.", "tokens": ["In", "Mei\u00b7nung", ",", "sich", "da\u00b7vor", "in", "Strie\u00b7gau", "Guts", "zu", "thun", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRF", "PAV", "APPR", "NE", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hier dacht ich mir einmahl mit Frieden auszuruhn", "tokens": ["Hier", "dacht", "ich", "mir", "ein\u00b7mahl", "mit", "Frie\u00b7den", "aus\u00b7zu\u00b7ruhn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und in der Eltern Schoos der L\u00e4strer Pfeil zu meiden.", "tokens": ["Und", "in", "der", "El\u00b7tern", "Schoos", "der", "L\u00e4st\u00b7rer", "Pfeil", "zu", "mei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Ich gieng, ich kam und sah, ach, leider nichts als Leid.", "tokens": ["Ich", "gieng", ",", "ich", "kam", "und", "sah", ",", "ach", ",", "lei\u00b7der", "nichts", "als", "Leid", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "KON", "VVFIN", "$,", "ITJ", "$,", "ADV", "PIS", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein Vater lies mich vor. So viel vermag der Neid", "tokens": ["Kein", "Va\u00b7ter", "lies", "mich", "vor", ".", "So", "viel", "ver\u00b7mag", "der", "Neid"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und List und Eigensinn und Ha\u00df und Aberglauben.", "tokens": ["Und", "List", "und", "Ei\u00b7gen\u00b7sinn", "und", "Ha\u00df", "und", "A\u00b7berg\u00b7lau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die treue Mutter lag, die Schwester weint und schwieg.", "tokens": ["Die", "treu\u00b7e", "Mut\u00b7ter", "lag", ",", "die", "Schwes\u00b7ter", "weint", "und", "schwieg", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich zog mit Wehmuth aus; lieg, armes Striegau, lieg,", "tokens": ["Ich", "zog", "mit", "Weh\u00b7muth", "aus", ";", "lieg", ",", "ar\u00b7mes", "Strie\u00b7gau", ",", "lieg", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$.", "VVFIN", "$,", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich mag schon keinen Scherf aus deiner Asche klauben.", "tokens": ["Ich", "mag", "schon", "kei\u00b7nen", "Scherf", "aus", "dei\u00b7ner", "A\u00b7sche", "klau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "Zwo Meilen f\u00fchrten mich nach Schweidniz bey der Nacht;", "tokens": ["Zwo", "Mei\u00b7len", "f\u00fchr\u00b7ten", "mich", "nach", "Schweid\u00b7niz", "bey", "der", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PRF", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Ankunft ward sogleich der Misgunst zugebracht,", "tokens": ["Die", "An\u00b7kunft", "ward", "sog\u00b7leich", "der", "Mis\u00b7gunst", "zu\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Misgunst, der ich dort viel Hecheln angehangen.", "tokens": ["Der", "Mis\u00b7gunst", ",", "der", "ich", "dort", "viel", "He\u00b7cheln", "an\u00b7ge\u00b7han\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Feinde drohten Lerm und schritten schon zur That.", "tokens": ["Die", "Fein\u00b7de", "droh\u00b7ten", "Lerm", "und", "schrit\u00b7ten", "schon", "zur", "That", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bleib, Schweidniz, was du bist, ich kenne deinen Rath", "tokens": ["Bleib", ",", "Schweid\u00b7niz", ",", "was", "du", "bist", ",", "ich", "ken\u00b7ne", "dei\u00b7nen", "Rath"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "PWS", "PPER", "VAFIN", "$,", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und habe schon in dir mein Gutes l\u00e4ngst empfangen.", "tokens": ["Und", "ha\u00b7be", "schon", "in", "dir", "mein", "Gu\u00b7tes", "l\u00e4ngst", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPR", "PPER", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.42": {"line.1": {"text": "Mit Sorgen, ohne Geld und durch die kr\u00fcmmste Bahn", "tokens": ["Mit", "Sor\u00b7gen", ",", "oh\u00b7ne", "Geld", "und", "durch", "die", "kr\u00fcmms\u00b7te", "Bahn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "KOUI", "NN", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gelangt ich wunderlich im gro\u00dfen Bre\u00dflau an.", "tokens": ["Ge\u00b7langt", "ich", "wun\u00b7der\u00b7lich", "im", "gro\u00b7\u00dfen", "Bre\u00df\u00b7lau", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich zecht auf Kreide los. Was hilft's? Die Noth lehrt bethen.", "tokens": ["Ich", "zecht", "auf", "Krei\u00b7de", "los", ".", "Was", "hilft's", "?", "Die", "Noth", "lehrt", "be\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$.", "PWS", "VVFIN", "$.", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+---", "measure": "unknown.measure.penta"}, "line.4": {"text": "Man sperrte mir das Maul mit viel Bef\u00f6rdrung auf;", "tokens": ["Man", "sperr\u00b7te", "mir", "das", "Maul", "mit", "viel", "Be\u00b7f\u00f6r\u00b7drung", "auf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Wind kam hinten nach und trieb mich hintern Lauf,", "tokens": ["Der", "Wind", "kam", "hin\u00b7ten", "nach", "und", "trieb", "mich", "hin\u00b7tern", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "KON", "VVFIN", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Eh Wafen, Feind und Schuld den kurzen Pa\u00df vertreten.", "tokens": ["Eh", "Wa\u00b7fen", ",", "Feind", "und", "Schuld", "den", "kur\u00b7zen", "Pa\u00df", "ver\u00b7tre\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.43": {"line.1": {"text": "Zwey St\u00fccke r\u00fchm ich noch. Des klugen Bre\u00dflers Haus", "tokens": ["Zwey", "St\u00fc\u00b7cke", "r\u00fchm", "ich", "noch", ".", "Des", "klu\u00b7gen", "Bre\u00df\u00b7lers", "Haus"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "PPER", "ADV", "$.", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gewann mein Dichten lieb. Hier wurden Schlaf und Schmaus", "tokens": ["Ge\u00b7wann", "mein", "Dich\u00b7ten", "lieb", ".", "Hier", "wur\u00b7den", "Schlaf", "und", "Schmaus"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "ADJD", "$.", "ADV", "VAFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit Lustgespr\u00e4chen, Wein und Versen aufgezogen.", "tokens": ["Mit", "Lust\u00b7ge\u00b7spr\u00e4\u00b7chen", ",", "Wein", "und", "Ver\u00b7sen", "auf\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Voraus entz\u00fcckte mich der sch\u00f6nen Wirthin Geist,", "tokens": ["Vo\u00b7raus", "ent\u00b7z\u00fcck\u00b7te", "mich", "der", "sch\u00f6\u00b7nen", "Wirt\u00b7hin", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Salz und Feuer f\u00fchrt und in der Feder weist,", "tokens": ["Die", "Salz", "und", "Feu\u00b7er", "f\u00fchrt", "und", "in", "der", "Fe\u00b7der", "weist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es hab ihr die Natur viel Pfunde zugewogen.", "tokens": ["Es", "hab", "ihr", "die", "Na\u00b7tur", "viel", "Pfun\u00b7de", "zu\u00b7ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "Mit was vor Lust und Schmerz gedenck ich noch an dich,", "tokens": ["Mit", "was", "vor", "Lust", "und", "Schmerz", "ge\u00b7denck", "ich", "noch", "an", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "NN", "KON", "NN", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du ruhiges Camin! Bey dir erg\u00f6zten mich", "tokens": ["Du", "ru\u00b7hi\u00b7ges", "Ca\u00b7min", "!", "Bey", "dir", "er\u00b7g\u00f6z\u00b7ten", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$.", "APPR", "PPER", "VVFIN", "PPER"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Ein Baro in der That und einer nach dem Nahmen;", "tokens": ["Ein", "Ba\u00b7ro", "in", "der", "That", "und", "ei\u00b7ner", "nach", "dem", "Nah\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "KON", "ART", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der lezte scherzt galant, der erste spricht gelehrt,", "tokens": ["Der", "lez\u00b7te", "scherzt", "ga\u00b7lant", ",", "der", "ers\u00b7te", "spricht", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADJD", "$,", "ART", "ADJA", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kennt Wirthschaft, Hof und Vers. Was ward da nicht geh\u00f6rt,", "tokens": ["Kennt", "Wirth\u00b7schaft", ",", "Hof", "und", "Vers", ".", "Was", "ward", "da", "nicht", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "NN", "KON", "NN", "$.", "PWS", "VAFIN", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn Thor und b\u00f6se Zeit uns auf die Zunge kamen!", "tokens": ["Wenn", "Thor", "und", "b\u00f6\u00b7se", "Zeit", "uns", "auf", "die", "Zun\u00b7ge", "ka\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Noch jenseit blickt ein Schlo\u00df auf unsern Oderstrand;", "tokens": ["Noch", "jen\u00b7seit", "blickt", "ein", "Schlo\u00df", "auf", "un\u00b7sern", "O\u00b7der\u00b7strand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "(die Sp\u00f6tter suchen hier das Besenbinderland;)", "tokens": ["(", "die", "Sp\u00f6t\u00b7ter", "su\u00b7chen", "hier", "das", "Be\u00b7sen\u00b7bin\u00b7der\u00b7land", ";)"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "emoticon"], "pos": ["$(", "ART", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auf diesem lernt ich auch, da\u00df alte Gunst nicht roste.", "tokens": ["Auf", "die\u00b7sem", "lernt", "ich", "auch", ",", "da\u00df", "al\u00b7te", "Gunst", "nicht", "ros\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "ADV", "$,", "KOUS", "ADJA", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was thut nicht, dencke nach, Trunck, Freyheit, Liebe, Nacht?", "tokens": ["Was", "thut", "nicht", ",", "den\u00b7cke", "nach", ",", "Trunck", ",", "Frey\u00b7heit", ",", "Lie\u00b7be", ",", "Nacht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "$,", "VVFIN", "PTKVZ", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sobald der zw\u00f6lfte Schlag das Volck zur Ruh gebracht,", "tokens": ["So\u00b7bald", "der", "zw\u00f6lf\u00b7te", "Schlag", "das", "Volck", "zur", "Ruh", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Verga\u00dfen wir der Noth bey selbst gew\u00fcrztem Moste.", "tokens": ["Ver\u00b7ga\u00b7\u00dfen", "wir", "der", "Noth", "bey", "selbst", "ge\u00b7w\u00fcrz\u00b7tem", "Mos\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Ein traurig Lebewohl beschlo\u00df die keusche Lust.", "tokens": ["Ein", "trau\u00b7rig", "Le\u00b7be\u00b7wohl", "be\u00b7schlo\u00df", "die", "keu\u00b7sche", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O Himmel, da\u00df du stets so grausam wechseln must!", "tokens": ["O", "Him\u00b7mel", ",", "da\u00df", "du", "stets", "so", "grau\u00b7sam", "wech\u00b7seln", "must", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich ri\u00df mich br\u00fcnstig los, sie sah betr\u00fcbt zur\u00fccke.", "tokens": ["Ich", "ri\u00df", "mich", "br\u00fcns\u00b7tig", "los", ",", "sie", "sah", "be\u00b7tr\u00fcbt", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "PPER", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verstehstu, wie man liebt, so bild es dir nur ein,", "tokens": ["Ver\u00b7steh\u00b7stu", ",", "wie", "man", "liebt", ",", "so", "bild", "es", "dir", "nur", "ein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PIS", "VVFIN", "$,", "ADV", "ADJD", "PPER", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was Thr\u00e4nen solcher Angst vor Scheidewa\u00dfer seyn;", "tokens": ["Was", "Thr\u00e4\u00b7nen", "sol\u00b7cher", "Angst", "vor", "Schei\u00b7de\u00b7wa\u00b7\u00dfer", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "PIAT", "NN", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich f\u00fchl es, wenn ich nur das Abschiedslied erblicke.", "tokens": ["Ich", "f\u00fchl", "es", ",", "wenn", "ich", "nur", "das", "Ab\u00b7schieds\u00b7lied", "er\u00b7bli\u00b7cke", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.47": {"line.1": {"text": "Es geht auf Lauben zu: Ich me\u00dfe Thal und H\u00f6h", "tokens": ["Es", "geht", "auf", "Lau\u00b7ben", "zu", ":", "Ich", "me\u00b7\u00dfe", "Thal", "und", "H\u00f6h"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durch Graben, Regen, Wind, Frost, Unruh, Angst und Schnee.", "tokens": ["Durch", "Gra\u00b7ben", ",", "Re\u00b7gen", ",", "Wind", ",", "Frost", ",", "Un\u00b7ruh", ",", "Angst", "und", "Schnee", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie manches Nachtquartier beschwert mir Kopf und Lenden!", "tokens": ["Wie", "man\u00b7ches", "Nacht\u00b7quar\u00b7tier", "be\u00b7schwert", "mir", "Kopf", "und", "Len\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In Jauer st\u00e4rckt mich Gorn, ein alt- und treuer Freund,", "tokens": ["In", "Jau\u00b7er", "st\u00e4rckt", "mich", "Gorn", ",", "ein", "al\u00b7t", "und", "treu\u00b7er", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "NE", "$,", "ART", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Mit Bette, Tisch und Rath und dem, was trostreich scheint,", "tokens": ["Mit", "Bet\u00b7te", ",", "Tisch", "und", "Rath", "und", "dem", ",", "was", "trost\u00b7reich", "scheint", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "KON", "ART", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von Leuten meiner Qual Verzweiflung abzuwenden.", "tokens": ["Von", "Leu\u00b7ten", "mei\u00b7ner", "Qual", "Ver\u00b7zwei\u00b7flung", "ab\u00b7zu\u00b7wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Mit Noth erreich ich noch die Gr\u00e4nzstadt um den Queis,", "tokens": ["Mit", "Noth", "er\u00b7reich", "ich", "noch", "die", "Gr\u00e4nz\u00b7stadt", "um", "den", "Que\u00b7is", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "PPER", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um den sich jezt das Volck wohl kaum zu n\u00e4hren weis.", "tokens": ["Um", "den", "sich", "jezt", "das", "Volck", "wohl", "kaum", "zu", "n\u00e4h\u00b7ren", "weis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PRF", "ADV", "ART", "NN", "ADV", "ADV", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Armuth henckt sich auf, der Reiche will verzagen;", "tokens": ["Die", "Ar\u00b7muth", "henckt", "sich", "auf", ",", "der", "Rei\u00b7che", "will", "ver\u00b7za\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PTKVZ", "$,", "ART", "NE", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Hunger speist mit Lust von Eicheln, Rind und Stroh;", "tokens": ["Der", "Hun\u00b7ger", "speist", "mit", "Lust", "von", "Ei\u00b7cheln", ",", "Rind", "und", "Stroh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kein Gleichn\u00fc\u00df gleicht der Noth; in Cabul war es so", "tokens": ["Kein", "Gleich\u00b7n\u00fc\u00df", "gleicht", "der", "Noth", ";", "in", "Ca\u00b7bul", "war", "es", "so"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$.", "APPR", "NE", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und dort, wo Mosis Stab den d\u00fcrren Fels geschlagen.", "tokens": ["Und", "dort", ",", "wo", "Mo\u00b7sis", "Stab", "den", "d\u00fcr\u00b7ren", "Fels", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "NE", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "So komm ich \u00fcberall dem Elend eben recht.", "tokens": ["So", "komm", "ich", "\u00fc\u00b7be\u00b7rall", "dem", "E\u00b7lend", "e\u00b7ben", "recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier lieg ich nun gestreckt, die Kr\u00e4fte sind geschw\u00e4cht;", "tokens": ["Hier", "lieg", "ich", "nun", "ge\u00b7streckt", ",", "die", "Kr\u00e4f\u00b7te", "sind", "ge\u00b7schw\u00e4cht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "VVPP", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den Schenckel will der Flu\u00df, der Gram das Herze fre\u00dfen;", "tokens": ["Den", "Schen\u00b7ckel", "will", "der", "Flu\u00df", ",", "der", "Gram", "das", "Her\u00b7ze", "fre\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Nordwind deckt mich oft mit Flocken durch das Dach.", "tokens": ["Der", "Nord\u00b7wind", "deckt", "mich", "oft", "mit", "Flo\u00b7cken", "durch", "das", "Dach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kein Freund, kein Mensch, kein Hund erf\u00e4hrt mein Ungemach;", "tokens": ["Kein", "Freund", ",", "kein", "Mensch", ",", "kein", "Hund", "er\u00b7f\u00e4hrt", "mein", "Un\u00b7ge\u00b7mach", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dies kan ich auch sogar im Schlafe nicht verge\u00dfen.", "tokens": ["Dies", "kan", "ich", "auch", "so\u00b7gar", "im", "Schla\u00b7fe", "nicht", "ver\u00b7ge\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.50": {"line.1": {"text": "Mu\u00df ist ein schwerer Trost, doch ist's ein Trost vor den,", "tokens": ["Mu\u00df", "ist", "ein", "schwe\u00b7rer", "Trost", ",", "doch", "ist's", "ein", "Trost", "vor", "den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAFIN", "ART", "ADJA", "NN", "$,", "ADV", "VAFIN", "ART", "NN", "APPR", "ART", "$,"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.2": {"text": "Der, was er mit Vernunft zuvor schon \u00fcbersehn,", "tokens": ["Der", ",", "was", "er", "mit", "Ver\u00b7nunft", "zu\u00b7vor", "schon", "\u00fc\u00b7ber\u00b7sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWS", "PPER", "APPR", "NN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch durch Erfahrung lernt: Die Vorsicht kan nicht wancken.", "tokens": ["Auch", "durch", "Er\u00b7fah\u00b7rung", "lernt", ":", "Die", "Vor\u00b7sicht", "kan", "nicht", "wan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$.", "ART", "NN", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer ist ein Thor und flucht auf Wetter, Zeit und Ort?", "tokens": ["Wer", "ist", "ein", "Thor", "und", "flucht", "auf", "Wet\u00b7ter", ",", "Zeit", "und", "Ort", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "KON", "VVFIN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Schickung starcker Trieb geht ungehindert fort,", "tokens": ["Der", "Schi\u00b7ckung", "star\u00b7cker", "Trieb", "geht", "un\u00b7ge\u00b7hin\u00b7dert", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ohn Absicht auf den Wuntsch verdrie\u00dflicher Gedancken.", "tokens": ["Ohn", "Ab\u00b7sicht", "auf", "den", "Wunt\u00b7sch", "ver\u00b7drie\u00df\u00b7li\u00b7cher", "Ge\u00b7dan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.51": {"line.1": {"text": "Gott lege, was er will und was mir zukommt, auf.", "tokens": ["Gott", "le\u00b7ge", ",", "was", "er", "will", "und", "was", "mir", "zu\u00b7kommt", ",", "auf", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PWS", "PPER", "VMFIN", "KON", "PWS", "PPER", "VVFIN", "$,", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Er wird und darf auch nicht den wohlbestellten Lauf", "tokens": ["Er", "wird", "und", "darf", "auch", "nicht", "den", "wohl\u00b7be\u00b7stell\u00b7ten", "Lauf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "KON", "VMFIN", "ADV", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der gro\u00dfen Creatur erst mir zu Liebe st\u00f6ren.", "tokens": ["Der", "gro\u00b7\u00dfen", "Crea\u00b7tur", "erst", "mir", "zu", "Lie\u00b7be", "st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Sein Zweck ist \u00fcberhaupt des Weltgeb\u00e4udes Heil;", "tokens": ["Sein", "Zweck", "ist", "\u00fc\u00b7ber\u00b7haupt", "des", "Welt\u00b7ge\u00b7b\u00e4u\u00b7des", "Heil", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir, ich und auch mein Creuz, sind davon nur ein Theil", "tokens": ["Wir", ",", "ich", "und", "auch", "mein", "Creuz", ",", "sind", "da\u00b7von", "nur", "ein", "Theil"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PPER", "KON", "ADV", "PPOSAT", "NN", "$,", "VAFIN", "PAV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und m\u00fc\u00dfen auch den Schmuck der ganzen Ordnung mehren.", "tokens": ["Und", "m\u00fc\u00b7\u00dfen", "auch", "den", "Schmuck", "der", "gan\u00b7zen", "Ord\u00b7nung", "meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.52": {"line.1": {"text": "Dies mercke, werther Freund. Und dr\u00fcckt auch dich ein Joch,", "tokens": ["Dies", "mer\u00b7cke", ",", "wert\u00b7her", "Freund", ".", "Und", "dr\u00fcckt", "auch", "dich", "ein", "Joch", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "ADJA", "NN", "$.", "KON", "VVFIN", "ADV", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So schlepp es freudig mit. Mein Herz empfindet noch;", "tokens": ["So", "schlepp", "es", "freu\u00b7dig", "mit", ".", "Mein", "Herz", "emp\u00b7fin\u00b7det", "noch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "PPOSAT", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Seele der Gedult will ich die Hofnung nennen.", "tokens": ["Die", "See\u00b7le", "der", "Ge\u00b7dult", "will", "ich", "die", "Hof\u00b7nung", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Gl\u00fccke schl\u00e4ft recht aus, wofern ich scherzen mag,", "tokens": ["Das", "Gl\u00fc\u00b7cke", "schl\u00e4ft", "recht", "aus", ",", "wo\u00b7fern", "ich", "scher\u00b7zen", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Damit, wenn einmahl kommt sein Auferstehungstag,", "tokens": ["Da\u00b7mit", ",", "wenn", "ein\u00b7mahl", "kommt", "sein", "Auf\u00b7er\u00b7ste\u00b7hungs\u00b7tag", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wir desto muntrer seyn und l\u00e4nger wachen k\u00f6nnen.", "tokens": ["Wir", "des\u00b7to", "mun\u00b7trer", "seyn", "und", "l\u00e4n\u00b7ger", "wa\u00b7chen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VAINF", "KON", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.53": {"line.1": {"text": "Das Ansehn unsrer Zeit droht L\u00e4ndern hier und dar,", "tokens": ["Das", "An\u00b7sehn", "uns\u00b7rer", "Zeit", "droht", "L\u00e4n\u00b7dern", "hier", "und", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "NN", "ADV", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man braucht nicht weit zu sehn, viel Jammer und Gefahr.", "tokens": ["Man", "braucht", "nicht", "weit", "zu", "sehn", ",", "viel", "Jam\u00b7mer", "und", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$,", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach armes Schlesien, du liegst zu nah an Polen.", "tokens": ["Ach", "ar\u00b7mes", "Schle\u00b7si\u00b7en", ",", "du", "liegst", "zu", "nah", "an", "Po\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJA", "NN", "$,", "PPER", "VVFIN", "PTKA", "ADJD", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gewis, wir haben viel und gro\u00dfe Ding erlebt;", "tokens": ["Ge\u00b7wis", ",", "wir", "ha\u00b7ben", "viel", "und", "gro\u00b7\u00dfe", "Ding", "er\u00b7lebt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADV", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Las seyn, da\u00df alles bricht und Erd und Abgrund bebt,", "tokens": ["Las", "seyn", ",", "da\u00df", "al\u00b7les", "bricht", "und", "Erd", "und", "Ab\u00b7grund", "bebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAINF", "$,", "KOUS", "PIS", "VVFIN", "KON", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Weiser weis den Trost blos in sich selbst zu holen.", "tokens": ["Ein", "Wei\u00b7ser", "weis", "den", "Trost", "blos", "in", "sich", "selbst", "zu", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "ART", "NN", "ADV", "APPR", "PRF", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.54": {"line.1": {"text": "Carl hat Verdienst und Macht, der Herr ist Tempel werth.", "tokens": ["Carl", "hat", "Ver\u00b7dienst", "und", "Macht", ",", "der", "Herr", "ist", "Tem\u00b7pel", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NN", "KON", "NN", "$,", "ART", "NN", "VAFIN", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er siegt in West und Ost und giebt auf Blut und Schwerd", "tokens": ["Er", "siegt", "in", "West", "und", "Ost", "und", "giebt", "auf", "Blut", "und", "Schwerd"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "KON", "NN", "KON", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "(was k\u00f6nt er Gr\u00f6\u00dfers thun?) den V\u00f6lckern Schuz und Friede.", "tokens": ["(", "was", "k\u00f6nt", "er", "Gr\u00f6\u00b7\u00dfers", "thun", "?", ")", "den", "V\u00f6l\u00b7ckern", "Schuz", "und", "Frie\u00b7de", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "PPER", "NN", "VVINF", "$.", "$(", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer weis, wie unverhoft sein Arm in deutscher Luft", "tokens": ["Wer", "weis", ",", "wie", "un\u00b7ver\u00b7hoft", "sein", "Arm", "in", "deut\u00b7scher", "Luft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKVZ", "$,", "PWAV", "ADJD", "PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Musen g\u00f6ldne Zeit aus ihren Winckeln ruft?", "tokens": ["Der", "Mu\u00b7sen", "g\u00f6ld\u00b7ne", "Zeit", "aus", "ih\u00b7ren", "Win\u00b7ckeln", "ruft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Europa, mache nur der Feinde Thorheit m\u00fcde!", "tokens": ["Eu\u00b7ro\u00b7pa", ",", "ma\u00b7che", "nur", "der", "Fein\u00b7de", "Thor\u00b7heit", "m\u00fc\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "ADV", "ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.55": {"line.1": {"text": "Der Herr, der Cronen nimmt, auch Cronen giebt und h\u00e4lt,", "tokens": ["Der", "Herr", ",", "der", "Cro\u00b7nen", "nimmt", ",", "auch", "Cro\u00b7nen", "giebt", "und", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,", "ADV", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erhalte Rudolphs Stamm, das Wunder unsrer Welt,", "tokens": ["Er\u00b7hal\u00b7te", "Ru\u00b7dolphs", "Stamm", ",", "das", "Wun\u00b7der", "uns\u00b7rer", "Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und mehre durch sein Blut den Saamen der Gerechten.", "tokens": ["Und", "meh\u00b7re", "durch", "sein", "Blut", "den", "Saa\u00b7men", "der", "Ge\u00b7rech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So lange Carl noch lebt und Sachsens Raute bl\u00fcht,", "tokens": ["So", "lan\u00b7ge", "Carl", "noch", "lebt", "und", "Sach\u00b7sens", "Rau\u00b7te", "bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "ADV", "VVFIN", "KON", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So lange f\u00fcrcht ich nicht, so schlecht es immer sieht,", "tokens": ["So", "lan\u00b7ge", "f\u00fcrcht", "ich", "nicht", ",", "so", "schlecht", "es", "im\u00b7mer", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df Neid und Barbarey in Deutschland siegen m\u00f6chten.", "tokens": ["Da\u00df", "Neid", "und", "Bar\u00b7ba\u00b7rey", "in", "Deutschland", "sie\u00b7gen", "m\u00f6ch\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "APPR", "NE", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.56": {"line.1": {"text": "Was etwan \u00fcbrig ist, (die Dinte wird fast hart)", "tokens": ["Was", "et\u00b7wan", "\u00fcb\u00b7rig", "ist", ",", "(", "die", "Din\u00b7te", "wird", "fast", "hart", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "VAFIN", "$,", "$(", "ART", "NN", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das hast der Reime Zwang und will nur Gegenwart;", "tokens": ["Das", "hast", "der", "Rei\u00b7me", "Zwang", "und", "will", "nur", "Ge\u00b7gen\u00b7wart", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "KON", "VMFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich habe viel mit dir, es wird sich ehstens schicken.", "tokens": ["Ich", "ha\u00b7be", "viel", "mit", "dir", ",", "es", "wird", "sich", "ehs\u00b7tens", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPER", "$,", "PPER", "VAFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Schreib, eile, sey nicht kurz. Ein S\u00e4ugling sucht die Brust;", "tokens": ["Schreib", ",", "ei\u00b7le", ",", "sey", "nicht", "kurz", ".", "Ein", "S\u00e4ug\u00b7ling", "sucht", "die", "Brust", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VAFIN", "PTKNEG", "ADJD", "$.", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Sehnsucht, edler Freund, hat auch nur halbe Lust,", "tokens": ["Die", "Sehn\u00b7sucht", ",", "ed\u00b7ler", "Freund", ",", "hat", "auch", "nur", "hal\u00b7be", "Lust", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJA", "NN", "$,", "VAFIN", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den Ku\u00df, der dir geh\u00f6rt, auf kalt Papier zu dr\u00fccken.", "tokens": ["Den", "Ku\u00df", ",", "der", "dir", "ge\u00b7h\u00f6rt", ",", "auf", "kalt", "Pa\u00b7pier", "zu", "dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPR", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}