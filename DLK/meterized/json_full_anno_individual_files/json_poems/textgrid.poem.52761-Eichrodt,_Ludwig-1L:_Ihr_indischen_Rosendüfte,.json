{"textgrid.poem.52761": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ihr indischen Rosend\u00fcfte,", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr indischen Rosend\u00fcfte,", "tokens": ["Ihr", "in\u00b7di\u00b7schen", "Ro\u00b7sen\u00b7d\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Habt ihr mein M\u00e4dchen gesehn?", "tokens": ["Habt", "ihr", "mein", "M\u00e4d\u00b7chen", "ge\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ihr Wellen, die ich beschiffte,", "tokens": ["Ihr", "Wel\u00b7len", ",", "die", "ich", "be\u00b7schiff\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Habt ihr vernommen ihr Flehn?", "tokens": ["Habt", "ihr", "ver\u00b7nom\u00b7men", "ihr", "Flehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.2": {"line.1": {"text": "Es war in dunkler Stunde", "tokens": ["Es", "war", "in", "dunk\u00b7ler", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da schritten wir \u00fcber den Sand,", "tokens": ["Da", "schrit\u00b7ten", "wir", "\u00fc\u00b7ber", "den", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "O, habt ihr gar keine Kunde,", "tokens": ["O", ",", "habt", "ihr", "gar", "kei\u00b7ne", "Kun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VAFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wohin meine G\u00f6ttin verschwand?", "tokens": ["Wo\u00b7hin", "mei\u00b7ne", "G\u00f6t\u00b7tin", "ver\u00b7schwand", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Sie weint', ich konnte nicht weinen,", "tokens": ["Sie", "weint'", ",", "ich", "konn\u00b7te", "nicht", "wei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und endlich weint' ich auch \u2013", "tokens": ["Und", "end\u00b7lich", "weint'", "ich", "auch", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich that es nur ihr zu Liebe ...", "tokens": ["Ich", "that", "es", "nur", "ihr", "zu", "Lie\u00b7be", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PPER", "APPR", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wir schritten im Windeshauch.", "tokens": ["Wir", "schrit\u00b7ten", "im", "Win\u00b7des\u00b7hauch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Nun sprecht, ihr Wellen, ihr D\u00fcfte,", "tokens": ["Nun", "sprecht", ",", "ihr", "Wel\u00b7len", ",", "ihr", "D\u00fcf\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Habt ihr mein M\u00e4dchen geseh'n?", "tokens": ["Habt", "ihr", "mein", "M\u00e4d\u00b7chen", "ge\u00b7seh'n", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Vernimmst du nicht mein Fleh'n?", "tokens": ["Ver\u00b7nimmst", "du", "nicht", "mein", "Fleh'n", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "O, sprecht ihr Wellen, ihr D\u00fcfte,", "tokens": ["O", ",", "sprecht", "ihr", "Wel\u00b7len", ",", "ihr", "D\u00fcf\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Habt ihr sie besser ger\u00fchrt?", "tokens": ["Habt", "ihr", "sie", "bes\u00b7ser", "ge\u00b7r\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Habt ihr durch s\u00fc\u00dfere Klagen", "tokens": ["Habt", "ihr", "durch", "s\u00fc\u00b7\u00dfe\u00b7re", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Lacertchen mir entf\u00fchrt?", "tokens": ["La\u00b7cert\u00b7chen", "mir", "ent\u00b7f\u00fchrt", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ihr indischen Rosend\u00fcfte,", "tokens": ["Ihr", "in\u00b7di\u00b7schen", "Ro\u00b7sen\u00b7d\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Habt ihr mein M\u00e4dchen gesehn?", "tokens": ["Habt", "ihr", "mein", "M\u00e4d\u00b7chen", "ge\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ihr Wellen, die ich beschiffte,", "tokens": ["Ihr", "Wel\u00b7len", ",", "die", "ich", "be\u00b7schiff\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Habt ihr vernommen ihr Flehn?", "tokens": ["Habt", "ihr", "ver\u00b7nom\u00b7men", "ihr", "Flehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.7": {"line.1": {"text": "Es war in dunkler Stunde", "tokens": ["Es", "war", "in", "dunk\u00b7ler", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da schritten wir \u00fcber den Sand,", "tokens": ["Da", "schrit\u00b7ten", "wir", "\u00fc\u00b7ber", "den", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "O, habt ihr gar keine Kunde,", "tokens": ["O", ",", "habt", "ihr", "gar", "kei\u00b7ne", "Kun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VAFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wohin meine G\u00f6ttin verschwand?", "tokens": ["Wo\u00b7hin", "mei\u00b7ne", "G\u00f6t\u00b7tin", "ver\u00b7schwand", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Sie weint', ich konnte nicht weinen,", "tokens": ["Sie", "weint'", ",", "ich", "konn\u00b7te", "nicht", "wei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und endlich weint' ich auch \u2013", "tokens": ["Und", "end\u00b7lich", "weint'", "ich", "auch", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich that es nur ihr zu Liebe ...", "tokens": ["Ich", "that", "es", "nur", "ihr", "zu", "Lie\u00b7be", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PPER", "APPR", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wir schritten im Windeshauch.", "tokens": ["Wir", "schrit\u00b7ten", "im", "Win\u00b7des\u00b7hauch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Nun sprecht, ihr Wellen, ihr D\u00fcfte,", "tokens": ["Nun", "sprecht", ",", "ihr", "Wel\u00b7len", ",", "ihr", "D\u00fcf\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Habt ihr mein M\u00e4dchen geseh'n?", "tokens": ["Habt", "ihr", "mein", "M\u00e4d\u00b7chen", "ge\u00b7seh'n", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Vernimmst du nicht mein Fleh'n?", "tokens": ["Ver\u00b7nimmst", "du", "nicht", "mein", "Fleh'n", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "O, sprecht ihr Wellen, ihr D\u00fcfte,", "tokens": ["O", ",", "sprecht", "ihr", "Wel\u00b7len", ",", "ihr", "D\u00fcf\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Habt ihr sie besser ger\u00fchrt?", "tokens": ["Habt", "ihr", "sie", "bes\u00b7ser", "ge\u00b7r\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Habt ihr durch s\u00fc\u00dfere Klagen", "tokens": ["Habt", "ihr", "durch", "s\u00fc\u00b7\u00dfe\u00b7re", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Lacertchen mir entf\u00fchrt?", "tokens": ["La\u00b7cert\u00b7chen", "mir", "ent\u00b7f\u00fchrt", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}