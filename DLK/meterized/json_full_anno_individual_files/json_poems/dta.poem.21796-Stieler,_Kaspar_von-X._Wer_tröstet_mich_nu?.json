{"dta.poem.21796": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "X.  \n  Wer tr\u00f6stet mich nu?", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Es hielte mich das Norden-land", "tokens": ["Es", "hiel\u00b7te", "mich", "das", "Nor\u00b7den\u00b7land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wo Zyntius zu Bette gehet/", "tokens": ["wo", "Zyn\u00b7tius", "zu", "Bet\u00b7te", "ge\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPR", "NN", "VVFIN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "die Gegend war mir unbekand/", "tokens": ["die", "Ge\u00b7gend", "war", "mir", "un\u00b7be\u00b7kand", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ihr fremder Steig mit Schnee verwehet/", "tokens": ["ihr", "frem\u00b7der", "Steig", "mit", "Schnee", "ver\u00b7we\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "da stund\u2019 ich au\u00df Gefahr und Noht", "tokens": ["da", "stund'", "ich", "au\u00df", "Ge\u00b7fahr", "und", "Noht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "es stritten mit mir Furcht und Tod:", "tokens": ["es", "strit\u00b7ten", "mit", "mir", "Furcht", "und", "Tod", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "der scharffe Sebel der Barbaren", "tokens": ["der", "scharf\u00b7fe", "Se\u00b7bel", "der", "Bar\u00b7ba\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "ist offters um mein Haupt gefahren.", "tokens": ["ist", "off\u00b7ters", "um", "mein", "Haupt", "ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Gradivus lie\u00df mich keiner Ruh", "tokens": ["Gra\u00b7di\u00b7vus", "lie\u00df", "mich", "kei\u00b7ner", "Ruh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "PIAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "in vielen N\u00e4chten nicht geniessen.", "tokens": ["in", "vie\u00b7len", "N\u00e4ch\u00b7ten", "nicht", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du Bug und strenges Masau du", "tokens": ["Du", "Bug", "und", "stren\u00b7ges", "Ma\u00b7sau", "du"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "KON", "ADJA", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ihr werdet mir es zeugen m\u00fcssen.", "tokens": ["ihr", "wer\u00b7det", "mir", "es", "zeu\u00b7gen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PPER", "VVFIN", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch hab\u2019 ich in so vieler M\u00fch", "tokens": ["Doch", "hab'", "ich", "in", "so", "vie\u00b7ler", "M\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "APPR", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Angst/ Sorg\u2019 und Furcht geklaget nie", "tokens": ["Angst", "/", "Sor\u00b7g'", "und", "Furcht", "ge\u00b7kla\u00b7get", "nie"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "NN", "KON", "NN", "VVPP", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "warum? der Stern der Fr\u00f6ligkeiten/", "tokens": ["wa\u00b7rum", "?", "der", "Stern", "der", "Fr\u00f6\u00b7lig\u00b7kei\u00b7ten", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Rosillette leuch/ mir zur Seiten.", "tokens": ["Ro\u00b7sil\u00b7let\u00b7te", "leuch", "/", "mir", "zur", "Sei\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "PPER", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "Rosill\u2019 ist mir Gewerb und Hau\u00df/", "tokens": ["Ro\u00b7sill'", "ist", "mir", "Ge\u00b7werb", "und", "Hau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "NN", "KON", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Freund/ Eltern/ Vaterland und alles", "tokens": ["Freund", "/", "El\u00b7tern", "/", "Va\u00b7ter\u00b7land", "und", "al\u00b7les"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "PIS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "bey ihr halt\u2019 ich all Elend au\u00df/", "tokens": ["bey", "ihr", "halt'", "ich", "all", "E\u00b7lend", "au\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "PIAT", "NN", "PTKVZ", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "bey ihr bef\u00fcrcht\u2019 ich keines Falles.", "tokens": ["bey", "ihr", "be\u00b7f\u00fcrcht'", "ich", "kei\u00b7nes", "Fal\u00b7les", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Will sie: ich geh mit ihr zur See", "tokens": ["Will", "sie", ":", "ich", "geh", "mit", "ihr", "zur", "See"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "wenn Sturm und Blizz spielt auff der H\u00f6h/", "tokens": ["wenn", "Sturm", "und", "Blizz", "spielt", "auff", "der", "H\u00f6h", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "ich wage mich in ferne W\u00fcsten", "tokens": ["ich", "wa\u00b7ge", "mich", "in", "fer\u00b7ne", "W\u00fcs\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "und wohne/ wo die Schlangen nisten.", "tokens": ["und", "woh\u00b7ne", "/", "wo", "die", "Schlan\u00b7gen", "nis\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Jezt h\u00e4lt mich ein beqweemer Ort", "tokens": ["Jezt", "h\u00e4lt", "mich", "ein", "be\u00b7qwee\u00b7mer", "Ort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mich k\u00fchlt ein Zefyr au\u00df der Gehre/", "tokens": ["mich", "k\u00fchlt", "ein", "Ze\u00b7fyr", "au\u00df", "der", "Geh\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "ich bin bedienet fort f\u00fcr fort", "tokens": ["ich", "bin", "be\u00b7die\u00b7net", "fort", "f\u00fcr", "fort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "PTKVZ", "APPR", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mir mangelt nichts an Gunst und Ehre.", "tokens": ["mir", "man\u00b7gelt", "nichts", "an", "Gunst", "und", "Eh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch wird mir mein Gesichte bla\u00df", "tokens": ["Doch", "wird", "mir", "mein", "Ge\u00b7sich\u00b7te", "bla\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der Augen Lauge macht mich na\u00df", "tokens": ["der", "Au\u00b7gen", "Lau\u00b7ge", "macht", "mich", "na\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "ich bin ein Sch\u00e4m und Schein zunennen", "tokens": ["ich", "bin", "ein", "Sch\u00e4m", "und", "Schein", "zu\u00b7nen\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "und kan mich selber kaum erkennen.", "tokens": ["und", "kan", "mich", "sel\u00b7ber", "kaum", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der weite Weg/ der mich von ihr", "tokens": ["Der", "wei\u00b7te", "Weg", "/", "der", "mich", "von", "ihr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "PRELS", "PRF", "APPR", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in so geschwinder Zeit verstossen/", "tokens": ["in", "so", "ge\u00b7schwin\u00b7der", "Zeit", "ver\u00b7stos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "ent\u00e4dert meines Leibes Zier/", "tokens": ["en\u00b7t\u00e4\u00b7dert", "mei\u00b7nes", "Lei\u00b7bes", "Zier", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ich gleiche Leten Hau\u00dfgenossen/", "tokens": ["ich", "glei\u00b7che", "Le\u00b7ten", "Hau\u00df\u00b7ge\u00b7nos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "weil ich so mancher s\u00fcssen Lust", "tokens": ["weil", "ich", "so", "man\u00b7cher", "s\u00fcs\u00b7sen", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "des Kusses/ der beliebten Brust", "tokens": ["des", "Kus\u00b7ses", "/", "der", "be\u00b7lieb\u00b7ten", "Brust"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "auff ewig/ ach! in dieser Erden", "tokens": ["auff", "e\u00b7wig", "/", "ach", "!", "in", "die\u00b7ser", "Er\u00b7den"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJD", "$(", "XY", "$.", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "mu\u00df mangeln und beraubet werden.", "tokens": ["mu\u00df", "man\u00b7geln", "und", "be\u00b7rau\u00b7bet", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "KON", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Zwar bin ich schlechter Mensch nicht wehrt/", "tokens": ["Zwar", "bin", "ich", "schlech\u00b7ter", "Mensch", "nicht", "wehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJA", "NN", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ihr/ der Sch\u00f6nen/ mein etwegen", "tokens": ["da\u00df", "ihr", "/", "der", "Sch\u00f6\u00b7nen", "/", "mein", "et\u00b7we\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "$(", "ART", "NN", "$(", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "ein einig Seuffzgen nur entf\u00e4hrt", "tokens": ["ein", "ei\u00b7nig", "Seuffz\u00b7gen", "nur", "ent\u00b7f\u00e4hrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch wil ich schweren/ da\u00df sie sich", "tokens": ["Doch", "wil", "ich", "schwe\u00b7ren", "/", "da\u00df", "sie", "sich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "$(", "KOUS", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "mehr qw\u00e4lt und \u00e4ngstigt/ weder ich/", "tokens": ["mehr", "qw\u00e4lt", "und", "\u00e4ngs\u00b7tigt", "/", "we\u00b7der", "ich", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "$(", "KON", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ach! m\u00f6cht\u2019 ich doch nur bey ihr stehen", "tokens": ["Ach", "!", "m\u00f6cht'", "ich", "doch", "nur", "bey", "ihr", "ste\u00b7hen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VMFIN", "PPER", "ADV", "ADV", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "und ihr Betr\u00fcbnis an-mit sehen.", "tokens": ["und", "ihr", "Be\u00b7tr\u00fcb\u00b7nis", "an\u00b7mit", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Gl\u00fckkseelig ist der/ welcher kan", "tokens": ["Gl\u00fckk\u00b7see\u00b7lig", "ist", "der", "/", "wel\u00b7cher", "kan"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VAFIN", "ART", "$(", "PWS", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in Gegenwart der Liebsten weinen.", "tokens": ["in", "Ge\u00b7gen\u00b7wart", "der", "Liebs\u00b7ten", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Gl\u00fckkseelig ist/ wer siehet an", "tokens": ["Gl\u00fckk\u00b7see\u00b7lig", "ist", "/", "wer", "sie\u00b7het", "an"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "$(", "PWS", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wie ihr Herz auch nicht sey au\u00df Steinen.", "tokens": ["wie", "ihr", "Herz", "auch", "nicht", "sey", "au\u00df", "Stei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADV", "PTKNEG", "VAFIN", "APPR", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ich wei\u00df nicht/ was die Tr\u00e4hnen-saat", "tokens": ["Ich", "wei\u00df", "nicht", "/", "was", "die", "Tr\u00e4h\u00b7nen\u00b7saat"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "PWS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "f\u00fcr stille Freuden in sich hat", "tokens": ["f\u00fcr", "stil\u00b7le", "Freu\u00b7den", "in", "sich", "hat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "APPR", "PRF", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "wenn sie sich l\u00e4\u00dft zusammen sprengen", "tokens": ["wenn", "sie", "sich", "l\u00e4\u00dft", "zu\u00b7sam\u00b7men", "spren\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "und treulich in einander mengen.", "tokens": ["und", "treu\u00b7lich", "in", "ein\u00b7an\u00b7der", "men\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Nun/ weil ich nicht kan um sie sein", "tokens": ["Nun", "/", "weil", "ich", "nicht", "kan", "um", "sie", "sein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$(", "KOUS", "PPER", "PTKNEG", "VMFIN", "APPR", "PPER", "PPOSAT"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "die Elis auch nichts r\u00e4umen ein/", "tokens": ["die", "E\u00b7lis", "auch", "nichts", "r\u00e4u\u00b7men", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "PIS", "VVFIN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Tessaljen schwarz vergiffte W\u00e4lder.", "tokens": ["Tes\u00b7sal\u00b7jen", "schwarz", "ver\u00b7giff\u00b7te", "W\u00e4l\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fchr mich dahin S\u00fcdwesten-wind", "tokens": ["F\u00fchr", "mich", "da\u00b7hin", "S\u00fcd\u00b7wes\u00b7ten\u00b7wind"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "PAV", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "wo die Rosille Blumen bindt/", "tokens": ["wo", "die", "Ro\u00b7sil\u00b7le", "Blu\u00b7men", "bindt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "ich wil mein Schiffgen allen Wellen", "tokens": ["ich", "wil", "mein", "Schiff\u00b7gen", "al\u00b7len", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "ganz unverzagt entgegen stellen.", "tokens": ["ganz", "un\u00b7ver\u00b7zagt", "ent\u00b7ge\u00b7gen", "stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKVZ", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}