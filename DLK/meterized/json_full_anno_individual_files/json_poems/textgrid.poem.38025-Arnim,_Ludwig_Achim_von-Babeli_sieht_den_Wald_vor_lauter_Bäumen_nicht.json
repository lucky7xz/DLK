{"textgrid.poem.38025": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Babeli sieht den Wald vor lauter B\u00e4umen nicht", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schwarzbrauns Babeli,", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Steh auf und la\u00df mich 'nein,", "tokens": ["Steh", "auf", "und", "la\u00df", "mich", "'n\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ich bin allein,", "tokens": ["Ich", "bin", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Und bring dir Wein,", "tokens": ["Und", "bring", "dir", "Wein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "La\u00df mich in die Kammer 'nein;", "tokens": ["La\u00df", "mich", "in", "die", "Kam\u00b7mer", "'n\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Schwarzbrauns Babeli,", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.7": {"text": "Mit deinen schwarzen A\u00fcgeli,", "tokens": ["Mit", "dei\u00b7nen", "schwar\u00b7zen", "A\u00b7\u00fc\u00b7ge\u00b7li", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Steh auf und la\u00df mich 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "mich", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.2": {"line.1": {"text": "'s sind unser eins, 's sind unser zwey,", "tokens": ["'s", "sind", "un\u00b7ser", "eins", ",", "'s", "sind", "un\u00b7ser", "zwey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "PIS", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Bringen dir ein Osterey,", "tokens": ["Brin\u00b7gen", "dir", "ein", "Os\u00b7te\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein;", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "'s sind unser zwey, 's sind unser drey,", "tokens": ["'s", "sind", "un\u00b7ser", "zwey", ",", "'s", "sind", "un\u00b7ser", "drey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Babeli komm geschwind herbey.", "tokens": ["Ba\u00b7be\u00b7li", "komm", "ge\u00b7schwind", "her\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Schwarzbrauns Babeli,", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf, und la\u00df uns 'nein.", "tokens": ["Steh", "auf", ",", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "'s sind unser drey, 's sind unser vier,", "tokens": ["'s", "sind", "un\u00b7ser", "drey", ",", "'s", "sind", "un\u00b7ser", "vier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Kaufen dir gut Wein und Bier,", "tokens": ["Kau\u00b7fen", "dir", "gut", "Wein", "und", "Bier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein;", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "'s sind unser vier, 's sind unser f\u00fcnf,", "tokens": ["'s", "sind", "un\u00b7ser", "vier", ",", "'s", "sind", "un\u00b7ser", "f\u00fcnf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Kaufen dir ein Dutzend Str\u00fcmpf.", "tokens": ["Kau\u00b7fen", "dir", "ein", "Dut\u00b7zend", "Str\u00fcmpf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "'s sind unser f\u00fcnf, 's sind unser sechs,", "tokens": ["'s", "sind", "un\u00b7ser", "f\u00fcnf", ",", "'s", "sind", "un\u00b7ser", "sechs", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Kaufen dir ein Kreuzersweck,", "tokens": ["Kau\u00b7fen", "dir", "ein", "Kreu\u00b7zers\u00b7weck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "'s sind unser sechs, 's sind unser sieben,", "tokens": ["'s", "sind", "un\u00b7ser", "sechs", ",", "'s", "sind", "un\u00b7ser", "sie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Welchen will das Babeli lieben?", "tokens": ["Wel\u00b7chen", "will", "das", "Ba\u00b7be\u00b7li", "lie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "'s sind unser sieben, 's sind unser acht,", "tokens": ["'s", "sind", "un\u00b7ser", "sie\u00b7ben", ",", "'s", "sind", "un\u00b7ser", "acht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "W\u00fcnschen dir eine gute Nacht,", "tokens": ["W\u00fcn\u00b7schen", "dir", "ei\u00b7ne", "gu\u00b7te", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "'s sind unser acht, 's sind unser neun,", "tokens": ["'s", "sind", "un\u00b7ser", "acht", ",", "'s", "sind", "un\u00b7ser", "neun", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Welcher darf zum Babeli 'nein?", "tokens": ["Wel\u00b7cher", "darf", "zum", "Ba\u00b7be\u00b7li", "'n\u00b7ein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "VMFIN", "APPRART", "NE", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "'s sind unser neun, 's sind unser zehn,", "tokens": ["'s", "sind", "un\u00b7ser", "neun", ",", "'s", "sind", "un\u00b7ser", "zehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "M\u00f6chten gern das Babeli sehn,", "tokens": ["M\u00f6ch\u00b7ten", "gern", "das", "Ba\u00b7be\u00b7li", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NE", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "'s sind unser zehn, 's sind unser eilf,", "tokens": ["'s", "sind", "un\u00b7ser", "zehn", ",", "'s", "sind", "un\u00b7ser", "eilf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Liebes Babeli komm und helf.", "tokens": ["Lie\u00b7bes", "Ba\u00b7be\u00b7li", "komm", "und", "helf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.7": {"line.1": {"text": "'s sind unser eilf, 's sind unser zw\u00f6lf,", "tokens": ["'s", "sind", "un\u00b7ser", "eilf", ",", "'s", "sind", "un\u00b7ser", "zw\u00f6lf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ist ein ganze Heerde W\u00f6lf,", "tokens": ["Ist", "ein", "gan\u00b7ze", "Heer\u00b7de", "W\u00f6lf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "La\u00df uns in die Kammer 'nein,", "tokens": ["La\u00df", "uns", "in", "die", "Kam\u00b7mer", "'n\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "NE", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Bringen dir ein Kanne Wein.", "tokens": ["Brin\u00b7gen", "dir", "ein", "Kan\u00b7ne", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Schwarzbrauns Babeli,", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Schwarzbrauns Babeli,", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Steh auf und la\u00df mich 'nein,", "tokens": ["Steh", "auf", "und", "la\u00df", "mich", "'n\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ich bin allein,", "tokens": ["Ich", "bin", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Und bring dir Wein,", "tokens": ["Und", "bring", "dir", "Wein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "La\u00df mich in die Kammer 'nein;", "tokens": ["La\u00df", "mich", "in", "die", "Kam\u00b7mer", "'n\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Schwarzbrauns Babeli,", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.7": {"text": "Mit deinen schwarzen A\u00fcgeli,", "tokens": ["Mit", "dei\u00b7nen", "schwar\u00b7zen", "A\u00b7\u00fc\u00b7ge\u00b7li", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Steh auf und la\u00df mich 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "mich", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.9": {"line.1": {"text": "'s sind unser eins, 's sind unser zwey,", "tokens": ["'s", "sind", "un\u00b7ser", "eins", ",", "'s", "sind", "un\u00b7ser", "zwey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "PIS", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Bringen dir ein Osterey,", "tokens": ["Brin\u00b7gen", "dir", "ein", "Os\u00b7te\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein;", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "'s sind unser zwey, 's sind unser drey,", "tokens": ["'s", "sind", "un\u00b7ser", "zwey", ",", "'s", "sind", "un\u00b7ser", "drey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Babeli komm geschwind herbey.", "tokens": ["Ba\u00b7be\u00b7li", "komm", "ge\u00b7schwind", "her\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Schwarzbrauns Babeli,", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf, und la\u00df uns 'nein.", "tokens": ["Steh", "auf", ",", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.10": {"line.1": {"text": "'s sind unser drey, 's sind unser vier,", "tokens": ["'s", "sind", "un\u00b7ser", "drey", ",", "'s", "sind", "un\u00b7ser", "vier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Kaufen dir gut Wein und Bier,", "tokens": ["Kau\u00b7fen", "dir", "gut", "Wein", "und", "Bier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein;", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "'s sind unser vier, 's sind unser f\u00fcnf,", "tokens": ["'s", "sind", "un\u00b7ser", "vier", ",", "'s", "sind", "un\u00b7ser", "f\u00fcnf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Kaufen dir ein Dutzend Str\u00fcmpf.", "tokens": ["Kau\u00b7fen", "dir", "ein", "Dut\u00b7zend", "Str\u00fcmpf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.11": {"line.1": {"text": "'s sind unser f\u00fcnf, 's sind unser sechs,", "tokens": ["'s", "sind", "un\u00b7ser", "f\u00fcnf", ",", "'s", "sind", "un\u00b7ser", "sechs", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Kaufen dir ein Kreuzersweck,", "tokens": ["Kau\u00b7fen", "dir", "ein", "Kreu\u00b7zers\u00b7weck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "'s sind unser sechs, 's sind unser sieben,", "tokens": ["'s", "sind", "un\u00b7ser", "sechs", ",", "'s", "sind", "un\u00b7ser", "sie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Welchen will das Babeli lieben?", "tokens": ["Wel\u00b7chen", "will", "das", "Ba\u00b7be\u00b7li", "lie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.12": {"line.1": {"text": "'s sind unser sieben, 's sind unser acht,", "tokens": ["'s", "sind", "un\u00b7ser", "sie\u00b7ben", ",", "'s", "sind", "un\u00b7ser", "acht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "W\u00fcnschen dir eine gute Nacht,", "tokens": ["W\u00fcn\u00b7schen", "dir", "ei\u00b7ne", "gu\u00b7te", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "'s sind unser acht, 's sind unser neun,", "tokens": ["'s", "sind", "un\u00b7ser", "acht", ",", "'s", "sind", "un\u00b7ser", "neun", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Welcher darf zum Babeli 'nein?", "tokens": ["Wel\u00b7cher", "darf", "zum", "Ba\u00b7be\u00b7li", "'n\u00b7ein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "VMFIN", "APPRART", "NE", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.13": {"line.1": {"text": "'s sind unser neun, 's sind unser zehn,", "tokens": ["'s", "sind", "un\u00b7ser", "neun", ",", "'s", "sind", "un\u00b7ser", "zehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "M\u00f6chten gern das Babeli sehn,", "tokens": ["M\u00f6ch\u00b7ten", "gern", "das", "Ba\u00b7be\u00b7li", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NE", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "'s sind unser zehn, 's sind unser eilf,", "tokens": ["'s", "sind", "un\u00b7ser", "zehn", ",", "'s", "sind", "un\u00b7ser", "eilf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Liebes Babeli komm und helf.", "tokens": ["Lie\u00b7bes", "Ba\u00b7be\u00b7li", "komm", "und", "helf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.14": {"line.1": {"text": "'s sind unser eilf, 's sind unser zw\u00f6lf,", "tokens": ["'s", "sind", "un\u00b7ser", "eilf", ",", "'s", "sind", "un\u00b7ser", "zw\u00f6lf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "$,", "PPER", "VAFIN", "PPOSAT", "CARD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ist ein ganze Heerde W\u00f6lf,", "tokens": ["Ist", "ein", "gan\u00b7ze", "Heer\u00b7de", "W\u00f6lf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarzbrauns Babeli", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "La\u00df uns in die Kammer 'nein,", "tokens": ["La\u00df", "uns", "in", "die", "Kam\u00b7mer", "'n\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "NE", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Bringen dir ein Kanne Wein.", "tokens": ["Brin\u00b7gen", "dir", "ein", "Kan\u00b7ne", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Schwarzbrauns Babeli,", "tokens": ["Schwarz\u00b7brauns", "Ba\u00b7be\u00b7li", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Steh auf und la\u00df uns 'nein.", "tokens": ["Steh", "auf", "und", "la\u00df", "uns", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}}}}