{"textgrid.poem.24277": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als sich zum f\u00fcnften Male im Westen", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als sich zum f\u00fcnften Male im Westen", "tokens": ["Als", "sich", "zum", "f\u00fcnf\u00b7ten", "Ma\u00b7le", "im", "Wes\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "APPRART", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Sonne verbarg vor des Mondes Schein,", "tokens": ["Die", "Son\u00b7ne", "ver\u00b7barg", "vor", "des", "Mon\u00b7des", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Bedr\u00fcckte wieder die Luft Chodschesten,", "tokens": ["Be\u00b7dr\u00fcck\u00b7te", "wie\u00b7der", "die", "Luft", "Chod\u00b7sches\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Des sch\u00f6nen Fremdlings Lust zu sein.", "tokens": ["Des", "sch\u00f6\u00b7nen", "Fremd\u00b7lings", "Lust", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sprach mit Seufzern, tief entpre\u00dften,", "tokens": ["Und", "sprach", "mit", "Seuf\u00b7zern", ",", "tief", "ent\u00b7pre\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu unserm klugen Papagein:", "tokens": ["Zu", "un\u00b7serm", "klu\u00b7gen", "Pa\u00b7pa\u00b7gein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie kannst du mich so bangen sehn!", "tokens": ["Wie", "kannst", "du", "mich", "so", "ban\u00b7gen", "sehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Grausamer Vogel, la\u00df heute mich gehn!", "tokens": ["Grau\u00b7sa\u00b7mer", "Vo\u00b7gel", ",", "la\u00df", "heu\u00b7te", "mich", "gehn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVIMP", "ADV", "PPER", "VVINF", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "Der Papagei benetzte sich", "tokens": ["Der", "Pa\u00b7pa\u00b7gei", "be\u00b7netz\u00b7te", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die dicke Zung, tat einen Strich", "tokens": ["Die", "di\u00b7cke", "Zung", ",", "tat", "ei\u00b7nen", "Strich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Mit seinem Schnabel am Gefieder,", "tokens": ["Mit", "sei\u00b7nem", "Schna\u00b7bel", "am", "Ge\u00b7fie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Hob m\u00fcd die schweren Augenlider", "tokens": ["Hob", "m\u00fcd", "die", "schwe\u00b7ren", "Au\u00b7gen\u00b7li\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und sprach, ein wenig schl\u00e4ferig:", "tokens": ["Und", "sprach", ",", "ein", "we\u00b7nig", "schl\u00e4\u00b7fe\u00b7rig", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Geh, sch\u00f6ne Frau! Beeile dich!", "tokens": ["Geh", ",", "sch\u00f6\u00b7ne", "Frau", "!", "Be\u00b7ei\u00b7le", "dich", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$.", "NN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Denn, Herrin, sieh, es kann geschehn,", "tokens": ["Denn", ",", "Her\u00b7rin", ",", "sieh", ",", "es", "kann", "ge\u00b7schehn", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "$,", "VVFIN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Dein Gatte kehrt mit einmal wieder,", "tokens": ["Dein", "Gat\u00b7te", "kehrt", "mit", "ein\u00b7mal", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und, was du dir in W\u00fcnschen baust,", "tokens": ["Und", ",", "was", "du", "dir", "in", "W\u00fcn\u00b7schen", "baust", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "PPER", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "In hei\u00dfen Sinnen lebend schaust,", "tokens": ["In", "hei\u00b7\u00dfen", "Sin\u00b7nen", "le\u00b7bend", "schaust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Wirst pl\u00f6tzlich du verschwinden sehn,", "tokens": ["Wirst", "pl\u00f6tz\u00b7lich", "du", "ver\u00b7schwin\u00b7den", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPER", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Wie jene Vier ihr Meisterst\u00fcck.", "tokens": ["Wie", "je\u00b7ne", "Vier", "ihr", "Meis\u00b7ter\u00b7st\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "CARD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Verschwunden wars, kam nie zur\u00fcck.", "tokens": ["Ver\u00b7schwun\u00b7den", "wars", ",", "kam", "nie", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Was denn? Was wars? Was ist verschwunden?", "tokens": ["Was", "denn", "?", "Was", "wars", "?", "Was", "ist", "ver\u00b7schwun\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$.", "PWS", "VAFIN", "$.", "PWS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Meisterst\u00fcck? Nie mehr gefunden?", "tokens": ["Ein", "Meis\u00b7ter\u00b7st\u00fcck", "?", "Nie", "mehr", "ge\u00b7fun\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Wars wirklich so ein kostbar Ding?", "tokens": ["Wars", "wirk\u00b7lich", "so", "ein", "kost\u00b7bar", "Ding", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Bild? Ein Lied? Ein Kleid? Ein Ring?", "tokens": ["Ein", "Bild", "?", "Ein", "Lied", "?", "Ein", "Kleid", "?", "Ein", "Ring", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "NN", "$.", "ART", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach, liebes, gutes Papchen, sprich!", "tokens": ["Ach", ",", "lie\u00b7bes", ",", "gu\u00b7tes", "Pap\u00b7chen", ",", "sprich", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ITJ", "$,", "ADJA", "$,", "ADJA", "NN", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Und Frau Chodscheste setzte sich.", "tokens": ["Und", "Frau", "Chod\u00b7sches\u00b7te", "setz\u00b7te", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NE", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der Vogel kraute sich am Schopfe", "tokens": ["Der", "Vo\u00b7gel", "krau\u00b7te", "sich", "am", "Schop\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und wackelte mit seinem Kopfe", "tokens": ["Und", "wa\u00b7ckel\u00b7te", "mit", "sei\u00b7nem", "Kop\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und tat das linke Auge zu", "tokens": ["Und", "tat", "das", "lin\u00b7ke", "Au\u00b7ge", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sprach nach seiner Art, gemessen,", "tokens": ["Und", "sprach", "nach", "sei\u00b7ner", "Art", ",", "ge\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Langsam, um ja nichts zu vergessen:", "tokens": ["Lang\u00b7sam", ",", "um", "ja", "nichts", "zu", "ver\u00b7ges\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUI", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "So h\u00f6re, du!", "tokens": ["So", "h\u00f6\u00b7re", ",", "du", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Ein Goldschmied und ein Zimmermann,", "tokens": ["Ein", "Gold\u00b7schmied", "und", "ein", "Zim\u00b7mer\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die huben eine Reise an", "tokens": ["Die", "hu\u00b7ben", "ei\u00b7ne", "Rei\u00b7se", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und fanden, wie sie f\u00fcrba\u00df schritten,", "tokens": ["Und", "fan\u00b7den", ",", "wie", "sie", "f\u00fcr\u00b7ba\u00df", "schrit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Am Wege als willkommnen Dritten", "tokens": ["Am", "We\u00b7ge", "als", "will\u00b7komm\u00b7nen", "Drit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Einen alt ehrw\u00fcrdigen Eremiten,", "tokens": ["Ei\u00b7nen", "alt", "ehr\u00b7w\u00fcr\u00b7di\u00b7gen", "E\u00b7re\u00b7mi\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.12": {"text": "Und, als sie weiter pilgerierten,", "tokens": ["Und", ",", "als", "sie", "wei\u00b7ter", "pil\u00b7ge\u00b7rier\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Gleichfalls willkommen einen Vierten.", "tokens": ["Gleich\u00b7falls", "will\u00b7kom\u00b7men", "ei\u00b7nen", "Vier\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Das war ein Schneider lobesan,", "tokens": ["Das", "war", "ein", "Schnei\u00b7der", "lo\u00b7be\u00b7san", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Mit dem sie flei\u00dfig diskutierten.", "tokens": ["Mit", "dem", "sie", "flei\u00b7\u00dfig", "dis\u00b7ku\u00b7tier\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "So kam denn bald die Nacht heran.", "tokens": ["So", "kam", "denn", "bald", "die", "Nacht", "he\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Kein Baum, kein Strauch in weiter Runden:", "tokens": ["Kein", "Baum", ",", "kein", "Strauch", "in", "wei\u00b7ter", "Run\u00b7den", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Die W\u00fcste wars, in der sie stunden.", "tokens": ["Die", "W\u00fcs\u00b7te", "wars", ",", "in", "der", "sie", "stun\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "APPR", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "\u00bbich mein, wir wolln uns schlafen legen!\u00ab", "tokens": ["\u00bb", "ich", "mein", ",", "wir", "wolln", "uns", "schla\u00b7fen", "le\u00b7gen", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "PPOSAT", "$,", "PPER", "VMFIN", "PPER", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Schneider sprach. Und \u00bbmeinetwegen\u00ab", "tokens": ["Der", "Schnei\u00b7der", "sprach", ".", "Und", "\u00bb", "mei\u00b7net\u00b7we\u00b7gen", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "KON", "$(", "ADV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erwiderte der Zimmermann.", "tokens": ["Er\u00b7wi\u00b7der\u00b7te", "der", "Zim\u00b7mer\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Der Goldschmied war auch nicht dagegen,", "tokens": ["Der", "Gold\u00b7schmied", "war", "auch", "nicht", "da\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "PAV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und, weil man zu nachtschlafner Zeit", "tokens": ["Und", ",", "weil", "man", "zu", "nacht\u00b7schlaf\u00b7ner", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PIS", "APPR", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Nichts Be\u00dfres tun, als schlafen kann,", "tokens": ["Nichts", "Be\u00df\u00b7res", "tun", ",", "als", "schla\u00b7fen", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "VVINF", "$,", "KOUS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gab auch Einsiedel seinen Segen.", "tokens": ["Gab", "auch", "Ein\u00b7sie\u00b7del", "sei\u00b7nen", "Se\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Jedoch gebot F\u00fcrsichtigkeit,", "tokens": ["Je\u00b7doch", "ge\u00b7bot", "F\u00fcr\u00b7sich\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df jeder einmal nach der Reih", "tokens": ["Da\u00df", "je\u00b7der", "ein\u00b7mal", "nach", "der", "Reih"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zur Sicherheit der Kumpanei", "tokens": ["Zur", "Si\u00b7cher\u00b7heit", "der", "Kum\u00b7pa\u00b7nei"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Gebotner Wache mu\u00dfte pflegen.", "tokens": ["Ge\u00b7bot\u00b7ner", "Wa\u00b7che", "mu\u00df\u00b7te", "pfle\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Den Zimmermann, als j\u00fcngsten, traf", "tokens": ["Den", "Zim\u00b7mer\u00b7mann", ",", "als", "j\u00fcng\u00b7sten", ",", "traf"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "KOUS", "ADJA", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die erste Wache. Tief in Schlaf", "tokens": ["Die", "ers\u00b7te", "Wa\u00b7che", ".", "Tief", "in", "Schlaf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ADJD", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verfielen bald die andern Drei.", "tokens": ["Ver\u00b7fie\u00b7len", "bald", "die", "an\u00b7dern", "Drei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Da\u00df ihm nicht auch die Lider s\u00e4nken,", "tokens": ["Da\u00df", "ihm", "nicht", "auch", "die", "Li\u00b7der", "s\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Begann im Kreise weit herum", "tokens": ["Be\u00b7gann", "im", "Krei\u00b7se", "weit", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Zimmermann den Schritt zu lenken.", "tokens": ["Der", "Zim\u00b7mer\u00b7mann", "den", "Schritt", "zu", "len\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und, siehe da, er fand ein Trumm", "tokens": ["Und", ",", "sie\u00b7he", "da", ",", "er", "fand", "ein", "Trumm"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "VVIMP", "ADV", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von einem Lorbeerbaum am Wege.", "tokens": ["Von", "ei\u00b7nem", "Lor\u00b7beer\u00b7baum", "am", "We\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbdu kommst mir recht in mein Gehege\u00ab,", "tokens": ["\u00bb", "du", "kommst", "mir", "recht", "in", "mein", "Ge\u00b7he\u00b7ge", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sprach allsogleich der Zimmermann", "tokens": ["Sprach", "all\u00b7so\u00b7gleich", "der", "Zim\u00b7mer\u00b7mann"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den sch\u00f6nen dicken Baumstamm an,", "tokens": ["Den", "sch\u00f6\u00b7nen", "di\u00b7cken", "Baum\u00b7stamm", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und nahm sein Beil und hieb ihn glatt", "tokens": ["Und", "nahm", "sein", "Beil", "und", "hieb", "ihn", "glatt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und rund und sch\u00f6n. Und, noch nicht satt", "tokens": ["Und", "rund", "und", "sch\u00f6n", ".", "Und", ",", "noch", "nicht", "satt"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD", "$.", "KON", "$,", "ADV", "PTKNEG", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Der lieben Arbeit, sachte, sachte", "tokens": ["Der", "lie\u00b7ben", "Ar\u00b7beit", ",", "sach\u00b7te", ",", "sach\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Er ein Fig\u00fcrchen daraus machte,", "tokens": ["Er", "ein", "Fi\u00b7g\u00fcr\u00b7chen", "da\u00b7raus", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Sch\u00f6ngliederig und schlank und fein,", "tokens": ["Sch\u00f6ng\u00b7lie\u00b7de\u00b7rig", "und", "schlank", "und", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "So, wie er sich das M\u00e4dchen dachte,", "tokens": ["So", ",", "wie", "er", "sich", "das", "M\u00e4d\u00b7chen", "dach\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Das einmal m\u00f6cht sein Weibchen sein.", "tokens": ["Das", "ein\u00b7mal", "m\u00f6cht", "sein", "Weib\u00b7chen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Drauf weckte er den Juwelier", "tokens": ["Drauf", "weck\u00b7te", "er", "den", "Ju\u00b7we\u00b7lier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sprach: \u00bbIch la\u00df Gesellschaft dir,", "tokens": ["Und", "sprach", ":", "\u00bb", "Ich", "la\u00df", "Ge\u00b7sell\u00b7schaft", "dir", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VVFIN", "NN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und zwar zur Nacht die allerbeste!\u00ab", "tokens": ["Und", "zwar", "zur", "Nacht", "die", "al\u00b7ler\u00b7bes\u00b7te", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "ADJA", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "(hier l\u00e4chelte vergn\u00fcgt Chodscheste.)", "tokens": ["(", "hier", "l\u00e4\u00b7chel\u00b7te", "ver\u00b7gn\u00fcgt", "Chod\u00b7sches\u00b7te", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADJD", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der Goldschmied sah das Dingchen an", "tokens": ["Der", "Gold\u00b7schmied", "sah", "das", "Ding\u00b7chen", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und dachte sich: \u00bbDa fehlt was dran.", "tokens": ["Und", "dach\u00b7te", "sich", ":", "\u00bb", "Da", "fehlt", "was", "dran", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "$.", "$(", "ADV", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein M\u00e4dchen ohne Kett und Ring,", "tokens": ["Ein", "M\u00e4d\u00b7chen", "oh\u00b7ne", "Kett", "und", "Ring", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ist f\u00fcrwahr ein halbes Ding.\u00ab", "tokens": ["Das", "ist", "f\u00fcr\u00b7wahr", "ein", "hal\u00b7bes", "Ding", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und t\u00e4t sogleich den zierlichen Gelenken", "tokens": ["Und", "t\u00e4t", "sog\u00b7leich", "den", "zier\u00b7li\u00b7chen", "Ge\u00b7len\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "An Fu\u00df und Hand Goldreife schenken", "tokens": ["An", "Fu\u00df", "und", "Hand", "Gold\u00b7rei\u00b7fe", "schen\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und eine Perlschnur um den Hals.", "tokens": ["Und", "ei\u00b7ne", "Perl\u00b7schnur", "um", "den", "Hals", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Brust, Stirn und Ohren ebenfalls", "tokens": ["Brust", ",", "Stirn", "und", "Oh\u00b7ren", "e\u00b7ben\u00b7falls"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bedacht er kunstreich mit Geschmeiden.", "tokens": ["Be\u00b7dacht", "er", "kuns\u00b7treich", "mit", "Ge\u00b7schmei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Dann tippte er den Schneidersmann", "tokens": ["Dann", "tipp\u00b7te", "er", "den", "Schnei\u00b7ders\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit leisem Finger weckend an", "tokens": ["Mit", "lei\u00b7sem", "Fin\u00b7ger", "we\u00b7ckend", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sprach: \u00bbIch la\u00df dir was zu kleiden!\u00ab", "tokens": ["Und", "sprach", ":", "\u00bb", "Ich", "la\u00df", "dir", "was", "zu", "klei\u00b7den", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbwas!?\u00ab rief der Schneider, \u00bbin der Nacht?!", "tokens": ["\u00bb", "was", "!?", "\u00ab", "rief", "der", "Schnei\u00b7der", ",", "\u00bb", "in", "der", "Nacht", "?!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "$.", "$(", "VVFIN", "ART", "NE", "$,", "$(", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In dieser leeren W\u00fcstenei?\u00ab", "tokens": ["In", "die\u00b7ser", "lee\u00b7ren", "W\u00fcs\u00b7te\u00b7nei", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dann aber: \u00bbHimmel! Welche Pracht!\u00ab", "tokens": ["Dann", "a\u00b7ber", ":", "\u00bb", "Him\u00b7mel", "!", "Wel\u00b7che", "Pracht", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "$.", "$(", "NN", "$.", "PWAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und gleich begann die Schneiderei.", "tokens": ["Und", "gleich", "be\u00b7gann", "die", "Schnei\u00b7de\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Denn, was ein rechter Schneider hei\u00dft,", "tokens": ["Denn", ",", "was", "ein", "rech\u00b7ter", "Schnei\u00b7der", "hei\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "ART", "ADJA", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Nacktheit nicht als h\u00f6chstes preist,", "tokens": ["Die", "Nackt\u00b7heit", "nicht", "als", "h\u00f6chs\u00b7tes", "preist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und wenn sie zehnmal g\u00f6ttlich sei.", "tokens": ["Und", "wenn", "sie", "zehn\u00b7mal", "g\u00f6tt\u00b7lich", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Hat also Kleiderchen gemacht", "tokens": ["Hat", "al\u00b7so", "Klei\u00b7der\u00b7chen", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Dem Weibchen so aufs allerbeste,", "tokens": ["Dem", "Weib\u00b7chen", "so", "aufs", "al\u00b7ler\u00b7bes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Da\u00df es, obwohl aus Holze, lacht", "tokens": ["Da\u00df", "es", ",", "ob\u00b7wohl", "aus", "Hol\u00b7ze", ",", "lacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "$,", "KOUS", "APPR", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "(das gleiche tat Madam Chodscheste)", "tokens": ["(", "das", "glei\u00b7che", "tat", "Ma\u00b7dam", "Chod\u00b7sches\u00b7te", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "FM", "FM", "FM", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Und selig in die W\u00fcste schaut,", "tokens": ["Und", "se\u00b7lig", "in", "die", "W\u00fcs\u00b7te", "schaut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Als w\u00e4rs lebendig eine Braut.", "tokens": ["Als", "w\u00e4rs", "le\u00b7ben\u00b7dig", "ei\u00b7ne", "Braut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Der Schneider sehr zufrieden war.", "tokens": ["Der", "Schnei\u00b7der", "sehr", "zu\u00b7frie\u00b7den", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zupfte Einsiedelmann am Haar", "tokens": ["Zupf\u00b7te", "Ein\u00b7sie\u00b7del\u00b7mann", "am", "Haar"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPRART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und sprach: \u00bbHochw\u00fcrden wollt geruhn,", "tokens": ["Und", "sprach", ":", "\u00bb", "Hoch\u00b7w\u00fcr\u00b7den", "wollt", "ge\u00b7ruhn", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Einen frommen Blick dorthin zu tun,", "tokens": ["Ei\u00b7nen", "from\u00b7men", "Blick", "dor\u00b7thin", "zu", "tun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Wo uns Besuch geworden ist,", "tokens": ["Wo", "uns", "Be\u00b7such", "ge\u00b7wor\u00b7den", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VAPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Erbaulich f\u00fcr Moslem und Christ.", "tokens": ["Er\u00b7bau\u00b7lich", "f\u00fcr", "Mos\u00b7lem", "und", "Christ", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NE", "KON", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Ich wei\u00df, es wird Euch nicht verdrie\u00dfen,", "tokens": ["Ich", "wei\u00df", ",", "es", "wird", "Euch", "nicht", "ver\u00b7drie\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Einer Huri Anblick zu genie\u00dfen,", "tokens": ["Ei\u00b7ner", "Hu\u00b7ri", "An\u00b7blick", "zu", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Und sicher ist, wie m\u00fcd Ihr seid:", "tokens": ["Und", "si\u00b7cher", "ist", ",", "wie", "m\u00fcd", "Ihr", "seid", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Vor Schlaf seid Ihr anjetzt gefeit!\u00ab", "tokens": ["Vor", "Schlaf", "seid", "Ihr", "an\u00b7jetzt", "ge\u00b7feit", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.13": {"line.1": {"text": "Und also wars. Einsiedelmann", "tokens": ["Und", "al\u00b7so", "wars", ".", "Ein\u00b7sie\u00b7del\u00b7mann"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "ADV", "VAFIN", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(dieweil ein Frommer sonst nichts kann)", "tokens": ["(", "die\u00b7weil", "ein", "From\u00b7mer", "sonst", "nichts", "kann", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ART", "NN", "ADV", "PIS", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hub allsogleich zu beten an", "tokens": ["Hub", "all\u00b7so\u00b7gleich", "zu", "be\u00b7ten", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PTKZU", "VVINF", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit selig hochgezogenen Braun", "tokens": ["Mit", "se\u00b7lig", "hoch\u00b7ge\u00b7zo\u00b7ge\u00b7nen", "Braun"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ADJA", "NN"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Zum Dank, da\u00df ihm das Gl\u00fcck beschert,", "tokens": ["Zum", "Dank", ",", "da\u00df", "ihm", "das", "Gl\u00fcck", "be\u00b7schert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In W\u00fcstennacht ein Weib zu schaun,", "tokens": ["In", "W\u00fcs\u00b7ten\u00b7nacht", "ein", "Weib", "zu", "schaun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "An Sch\u00f6nheit des Propheten wert.", "tokens": ["An", "Sch\u00f6n\u00b7heit", "des", "Pro\u00b7phe\u00b7ten", "wert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbnur\u00ab, sprach er zu sich selber dann,", "tokens": ["\u00bb", "nur", "\u00ab", ",", "sprach", "er", "zu", "sich", "sel\u00b7ber", "dann", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "PPER", "APPR", "PRF", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "\u00bbwie schade, da\u00df das Ding nicht lebt,", "tokens": ["\u00bb", "wie", "scha\u00b7de", ",", "da\u00df", "das", "Ding", "nicht", "lebt", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADJD", "$,", "KOUS", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der Busen sich nicht senkt und hebt,", "tokens": ["Der", "Bu\u00b7sen", "sich", "nicht", "senkt", "und", "hebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "PTKNEG", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Der volle Arm ans Herz nicht dr\u00fcckt,", "tokens": ["Der", "vol\u00b7le", "Arm", "ans", "Herz", "nicht", "dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Das dunkle Aug ins Herz nicht blickt!\u00ab", "tokens": ["Das", "dunk\u00b7le", "Aug", "ins", "Herz", "nicht", "blickt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "PTKNEG", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Und warf sich nieder auf die Erden:", "tokens": ["Und", "warf", "sich", "nie\u00b7der", "auf", "die", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKVZ", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "\u00bbbei Allah! Das mu\u00df anders werden!", "tokens": ["\u00bb", "bei", "Al\u00b7lah", "!", "Das", "mu\u00df", "an\u00b7ders", "wer\u00b7den", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$.", "PDS", "VMFIN", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Allah ist gro\u00df! Allah vermag", "tokens": ["Al\u00b7lah", "ist", "gro\u00df", "!", "Al\u00b7lah", "ver\u00b7mag"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VAFIN", "ADJD", "$.", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Aus Nacht zu machen hellen Tag;", "tokens": ["Aus", "Nacht", "zu", "ma\u00b7chen", "hel\u00b7len", "Tag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Drum wird er, wenn ein Frommer fleht", "tokens": ["Drum", "wird", "er", ",", "wenn", "ein", "From\u00b7mer", "fleht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "$,", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "(wie ich), auf herzliches Gebet", "tokens": ["(", "wie", "ich", ")", ",", "auf", "herz\u00b7li\u00b7ches", "Ge\u00b7bet"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PWAV", "PPER", "$(", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Gewi\u00df, gewi\u00df ein Wunder tun!", "tokens": ["Ge\u00b7wi\u00df", ",", "ge\u00b7wi\u00df", "ein", "Wun\u00b7der", "tun", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Allah, nicht wahr, du wirst geruhn", "tokens": ["Al\u00b7lah", ",", "nicht", "wahr", ",", "du", "wirst", "ge\u00b7ruhn"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PTKNEG", "ADJD", "$,", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Und allsogleich befehlen nun,", "tokens": ["Und", "all\u00b7so\u00b7gleich", "be\u00b7feh\u00b7len", "nun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Da\u00df Lebensodem in sie weht,", "tokens": ["Da\u00df", "Le\u00b7ben\u00b7so\u00b7dem", "in", "sie", "weht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Die viel zu sch\u00f6n ist, tot zu bleiben!", "tokens": ["Die", "viel", "zu", "sch\u00f6n", "ist", ",", "tot", "zu", "blei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKA", "ADJD", "VAFIN", "$,", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "O Allah, la\u00df sie nicht blo\u00df leiben!", "tokens": ["O", "Al\u00b7lah", ",", "la\u00df", "sie", "nicht", "blo\u00df", "lei\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVIMP", "PPER", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "La\u00df sie auch leben! Und \u2013 la\u00df sie lieben!", "tokens": ["La\u00df", "sie", "auch", "le\u00b7ben", "!", "Und", "\u2013", "la\u00df", "sie", "lie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "VVINF", "$.", "KON", "$(", "VVIMP", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.26": {"text": "Wir alle w\u00e4ren ja Staub geblieben,", "tokens": ["Wir", "al\u00b7le", "w\u00e4\u00b7ren", "ja", "Staub", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VAFIN", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "H\u00e4ttest nicht du in unsre Nasen", "tokens": ["H\u00e4t\u00b7test", "nicht", "du", "in", "uns\u00b7re", "Na\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Deines Geistes einen Hauch geblasen.\u00ab", "tokens": ["Dei\u00b7nes", "Geis\u00b7tes", "ei\u00b7nen", "Hauch", "ge\u00b7bla\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.14": {"line.1": {"text": "Und sieh: Ein Wehn kam durch die Nacht", "tokens": ["Und", "sieh", ":", "Ein", "Wehn", "kam", "durch", "die", "Nacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hat lebendig das Holz gemacht,", "tokens": ["Und", "hat", "le\u00b7ben\u00b7dig", "das", "Holz", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das augenblicks mit seinem Munde", "tokens": ["Das", "au\u00b7gen\u00b7blicks", "mit", "sei\u00b7nem", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Silberhell zu lachen begunnte,", "tokens": ["Sil\u00b7ber\u00b7hell", "zu", "la\u00b7chen", "be\u00b7gunn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Da\u00df Zimmermann, Schneider und Juwelier", "tokens": ["Da\u00df", "Zim\u00b7mer\u00b7mann", ",", "Schnei\u00b7der", "und", "Ju\u00b7we\u00b7lier"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "NE", "KON", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Aufwachten und rasten vor Liebe schier.", "tokens": ["Auf\u00b7wach\u00b7ten", "und", "ras\u00b7ten", "vor", "Lie\u00b7be", "schier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "APPR", "NN", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.15": {"line.1": {"text": "Und, da den alten Eremiten", "tokens": ["Und", ",", "da", "den", "al\u00b7ten", "E\u00b7re\u00b7mi\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Liebe gleichfalls hat geritten,", "tokens": ["Die", "Lie\u00b7be", "gleich\u00b7falls", "hat", "ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So rasten gemeinsam alle Vier.", "tokens": ["So", "ras\u00b7ten", "ge\u00b7mein\u00b7sam", "al\u00b7le", "Vier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PIAT", "CARD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "Das Weiblein aber, was tat \u2013 Es?", "tokens": ["Das", "Weib\u00b7lein", "a\u00b7ber", ",", "was", "tat", "\u2013", "Es", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PWS", "VVFIN", "$(", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Je nun, \u2013 nichts weiter Besonderes.", "tokens": ["Je", "nun", ",", "\u2013", "nichts", "wei\u00b7ter", "Be\u00b7son\u00b7de\u00b7res", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "$(", "PIS", "ADV", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Setzte sich still auf den Bettelsack", "tokens": ["Setz\u00b7te", "sich", "still", "auf", "den", "Bet\u00b7tel\u00b7sack"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADJD", "APPR", "ART", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Des Eremiten in guter Ruh", "tokens": ["Des", "E\u00b7re\u00b7mi\u00b7ten", "in", "gu\u00b7ter", "Ruh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und schaute dem Tanze der Viere zu,", "tokens": ["Und", "schau\u00b7te", "dem", "Tan\u00b7ze", "der", "Vie\u00b7re", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Die sich traktierten wie Lumpenpack.", "tokens": ["Die", "sich", "trak\u00b7tier\u00b7ten", "wie", "Lum\u00b7pen\u00b7pack", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Mit viel Gefuchtel, Geschimpf, Geschrei", "tokens": ["Mit", "viel", "Ge\u00b7fuch\u00b7tel", ",", "Ge\u00b7schimpf", ",", "Ge\u00b7schrei"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "NN", "$,", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Rief jeder, da\u00df sie sein Eigen sei", "tokens": ["Rief", "je\u00b7der", ",", "da\u00df", "sie", "sein", "Ei\u00b7gen", "sei"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Und jeder andre ein Schubiak.", "tokens": ["Und", "je\u00b7der", "and\u00b7re", "ein", "Schu\u00b7bi\u00b7ak", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PIS", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "\u00bbwer machte sie?\u00ab rief der Schreiner stolz:", "tokens": ["\u00bb", "wer", "mach\u00b7te", "sie", "?", "\u00ab", "rief", "der", "Schrei\u00b7ner", "stolz", ":"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$.", "$(", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbich, ich, ich, ich! Aus Lorbeerholz!\u00ab", "tokens": ["\u00bb", "ich", ",", "ich", ",", "ich", ",", "ich", "!", "Aus", "Lor\u00b7beer\u00b7holz", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "$,", "PPER", "$,", "PPER", "$,", "PPER", "$.", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "\u00bbwer schm\u00fcckte sie?\u00ab rief der Goldschmied aus:", "tokens": ["\u00bb", "wer", "schm\u00fcck\u00b7te", "sie", "?", "\u00ab", "rief", "der", "Gold\u00b7schmied", "aus", ":"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$.", "$(", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbich! Vorher sah sie nach gar nichts aus!\u00ab", "tokens": ["\u00bb", "ich", "!", "Vor\u00b7her", "sah", "sie", "nach", "gar", "nichts", "aus", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "$.", "ADV", "VVFIN", "PPER", "APPR", "ADV", "PIS", "PTKVZ", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "\u00bbwer zog sie an?\u00ab der Schneider schrie:", "tokens": ["\u00bb", "wer", "zog", "sie", "an", "?", "\u00ab", "der", "Schnei\u00b7der", "schrie", ":"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbich machte gesellschaftsf\u00e4hig sie!\u00ab", "tokens": ["\u00bb", "ich", "mach\u00b7te", "ge\u00b7sell\u00b7schafts\u00b7f\u00e4\u00b7hig", "sie", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADJD", "PPER", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.20": {"line.1": {"text": "\u00bbwer betete ihr das Leben an?", "tokens": ["\u00bb", "wer", "be\u00b7te\u00b7te", "ihr", "das", "Le\u00b7ben", "an", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wer? Ich!\u00ab rief der Einsiedelmann.", "tokens": ["Wer", "?", "Ich", "!", "\u00ab", "rief", "der", "Ein\u00b7sie\u00b7del\u00b7mann", "."], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "PPER", "$.", "$(", "VVFIN", "ART", "NN", "$."], "meter": "--+-+---", "measure": "anapaest.init"}}, "stanza.21": {"line.1": {"text": "Indessen trat durch Ostens Tor", "tokens": ["In\u00b7des\u00b7sen", "trat", "durch", "Os\u00b7tens", "Tor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sonne k\u00f6niglich hervor", "tokens": ["Die", "Son\u00b7ne", "k\u00f6\u00b7nig\u00b7lich", "her\u00b7vor"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und tauchte in Gold mit ihrem Schein", "tokens": ["Und", "tauch\u00b7te", "in", "Gold", "mit", "ih\u00b7rem", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die weite W\u00fcste leuchtend ein.", "tokens": ["Die", "wei\u00b7te", "W\u00fcs\u00b7te", "leuch\u00b7tend", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sieh: Es war in ihrem Strahle", "tokens": ["Und", "sieh", ":", "Es", "war", "in", "ih\u00b7rem", "Strah\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "PPER", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die W\u00fcste eine goldne Schale,", "tokens": ["Die", "W\u00fcs\u00b7te", "ei\u00b7ne", "gold\u00b7ne", "Scha\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nur ein Gef\u00e4\u00df f\u00fcr deren Pracht,", "tokens": ["Nur", "ein", "Ge\u00b7f\u00e4\u00df", "f\u00fcr", "de\u00b7ren", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PRELAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die in der wunderlichen Nacht", "tokens": ["Die", "in", "der", "wun\u00b7der\u00b7li\u00b7chen", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Viere wie im Traum gemacht.", "tokens": ["Die", "Vie\u00b7re", "wie", "im", "Traum", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "KOKOM", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Und auf die Kniee hin vor ihr,", "tokens": ["Und", "auf", "die", "Kni\u00b7ee", "hin", "vor", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der L\u00e4chelnden, die sich nicht r\u00fchrte,", "tokens": ["Der", "L\u00e4\u00b7cheln\u00b7den", ",", "die", "sich", "nicht", "r\u00fchr\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "St\u00fcrzten verz\u00fcckt, ber\u00fcckt die Vier,", "tokens": ["St\u00fcrz\u00b7ten", "ver\u00b7z\u00fcckt", ",", "be\u00b7r\u00fcckt", "die", "Vier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Als ob nicht Allah das Gebet geb\u00fchrte.", "tokens": ["Als", "ob", "nicht", "Al\u00b7lah", "das", "Ge\u00b7bet", "ge\u00b7b\u00fchr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PTKNEG", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.23": {"line.1": {"text": "So gottlos ist verliebter Lust Begier.", "tokens": ["So", "gott\u00b7los", "ist", "ver\u00b7lieb\u00b7ter", "Lust", "Be\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Doch Strafe folgt der S\u00fcnde auf dem Fu\u00df.", "tokens": ["Doch", "Stra\u00b7fe", "folgt", "der", "S\u00fcn\u00b7de", "auf", "dem", "Fu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dies, Herrin, ist nicht eines Kakadus", "tokens": ["Dies", ",", "Her\u00b7rin", ",", "ist", "nicht", "ei\u00b7nes", "Ka\u00b7ka\u00b7dus"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "$,", "NN", "$,", "VAFIN", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Private Meinung, sondern tief erwiesen.", "tokens": ["Pri\u00b7va\u00b7te", "Mei\u00b7nung", ",", "son\u00b7dern", "tief", "er\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein s\u00fc\u00df Konfekt ist s\u00fcndiges Genie\u00dfen,", "tokens": ["Ein", "s\u00fc\u00df", "Kon\u00b7fekt", "ist", "s\u00fcn\u00b7di\u00b7ges", "Ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Doch nachher kommt das bittre Myrrhenmus", "tokens": ["Doch", "nach\u00b7her", "kommt", "das", "bitt\u00b7re", "Myr\u00b7rhen\u00b7mus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Verdienter Strafe. Niemand feiert Feste", "tokens": ["Ver\u00b7dien\u00b7ter", "Stra\u00b7fe", ".", "Nie\u00b7mand", "fei\u00b7ert", "Fes\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "PIS", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Verbotenen Rausches ohne Nachgeschmack!", "tokens": ["Ver\u00b7bo\u00b7te\u00b7nen", "Rau\u00b7sches", "oh\u00b7ne", "Nach\u00b7ge\u00b7schmack", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.25": {"line.1": {"text": "(halt dich nicht auf! stirnrunzelte Chodscheste.)", "tokens": ["(", "halt", "dich", "nicht", "auf", "!", "stirn\u00b7run\u00b7zel\u00b7te", "Chod\u00b7sches\u00b7te", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$.", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.26": {"line.1": {"text": "Wie du befiehlst! Also: Das Schnick und Schnack", "tokens": ["Wie", "du", "be\u00b7fiehlst", "!", "Al\u00b7so", ":", "Das", "Schnick", "und", "Schnack"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "$.", "ADV", "$.", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Viere, die verz\u00fcckt auf ihren Knien lagen,", "tokens": ["Der", "Vie\u00b7re", ",", "die", "ver\u00b7z\u00fcckt", "auf", "ih\u00b7ren", "Kni\u00b7en", "la\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ward pl\u00f6tzlich unterbrochen. H\u00fch! und hoh!", "tokens": ["Ward", "pl\u00f6tz\u00b7lich", "un\u00b7ter\u00b7bro\u00b7chen", ".", "H\u00fch", "!", "und", "hoh", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVPP", "$.", "NN", "$.", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Erscholl und das Geknirsch von einem Reisewagen,", "tokens": ["Er\u00b7scholl", "und", "das", "Ge\u00b7knirsch", "von", "ei\u00b7nem", "Rei\u00b7se\u00b7wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auf dem, im Sande nicht prestissimo,", "tokens": ["Auf", "dem", ",", "im", "San\u00b7de", "nicht", "pres\u00b7tis\u00b7si\u00b7mo", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "APPRART", "NN", "PTKNEG", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ein reicher Mann herbeigefahren kam.", "tokens": ["Ein", "rei\u00b7cher", "Mann", "her\u00b7bei\u00b7ge\u00b7fah\u00b7ren", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wie der das Weib sah auf dem Bettelsack,", "tokens": ["Wie", "der", "das", "Weib", "sah", "auf", "dem", "Bet\u00b7tel\u00b7sack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Gabs einen Ruck ihm, und er rief: \u00bbO scham-,", "tokens": ["Gabs", "ei\u00b7nen", "Ruck", "ihm", ",", "und", "er", "rief", ":", "\u00bb", "O", "scham", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "PPER", "$,", "KON", "PPER", "VVFIN", "$.", "$(", "NE", "TRUNC", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Schamloseste von allen Frauen! Da,", "tokens": ["Scham\u00b7lo\u00b7ses\u00b7te", "von", "al\u00b7len", "Frau\u00b7en", "!", "Da", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$.", "ADV", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Auf diesem Bettelsacke sitzt sie, ha!", "tokens": ["Auf", "die\u00b7sem", "Bet\u00b7tel\u00b7sa\u00b7cke", "sitzt", "sie", ",", "ha", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "$,", "ITJ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Die ich verliebt zum Eheweibe nahm!", "tokens": ["Die", "ich", "ver\u00b7liebt", "zum", "E\u00b7he\u00b7wei\u00b7be", "nahm", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Ein sch\u00f6nes Wiedersehn, f\u00fcrwahr, Madam!", "tokens": ["Ein", "sch\u00f6\u00b7nes", "Wie\u00b7der\u00b7sehn", ",", "f\u00fcr\u00b7wahr", ",", "Ma\u00b7dam", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Mit Vieren, Vieren! ist sie durchgegangen,", "tokens": ["Mit", "Vie\u00b7ren", ",", "Vie\u00b7ren", "!", "ist", "sie", "durch\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$.", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Drum ist nicht ein-, nein viermal sie infam,", "tokens": ["Drum", "ist", "nicht", "ein", ",", "nein", "vier\u00b7mal", "sie", "in\u00b7fam", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PTKNEG", "TRUNC", "$,", "PTKANT", "ADV", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Und diese Viere m\u00fcssen schleunigst hangen!", "tokens": ["Und", "die\u00b7se", "Vie\u00b7re", "m\u00fcs\u00b7sen", "schleu\u00b7nigst", "han\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Auf! Bindet sie \u2013 und sie! Bei meinem Gram!", "tokens": ["Auf", "!", "Bin\u00b7det", "sie", "\u2013", "und", "sie", "!", "Bei", "mei\u00b7nem", "Gram", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VAFIN", "PPER", "$(", "KON", "PPER", "$.", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Ich will mein Recht und ihren Tod erlangen!\u00ab", "tokens": ["Ich", "will", "mein", "Recht", "und", "ih\u00b7ren", "Tod", "er\u00b7lan\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Es schrie das Weib. Die vier Verliebten schrien.", "tokens": ["Es", "schrie", "das", "Weib", ".", "Die", "vier", "Ver\u00b7lieb\u00b7ten", "schri\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "ART", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es schrie der reiche Mann und seine Knechte.", "tokens": ["Es", "schrie", "der", "rei\u00b7che", "Mann", "und", "sei\u00b7ne", "Knech\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es war, als ob ein Heer von Moslemin", "tokens": ["Es", "war", ",", "als", "ob", "ein", "Heer", "von", "Mos\u00b7le\u00b7min"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "KOUS", "ART", "NN", "APPR", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "F\u00fcr Allah schrie im heiligen Gefechte.", "tokens": ["F\u00fcr", "Al\u00b7lah", "schrie", "im", "hei\u00b7li\u00b7gen", "Ge\u00b7fech\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.28": {"line.1": {"text": "Doch, als die F\u00fcnfe dann gebunden waren,", "tokens": ["Doch", ",", "als", "die", "F\u00fcn\u00b7fe", "dann", "ge\u00b7bun\u00b7den", "wa\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ist schweigend man zu einer nahen Feste,", "tokens": ["Ist", "schwei\u00b7gend", "man", "zu", "ei\u00b7ner", "na\u00b7hen", "Fes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PIS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In ders an Galgen keineswegs gebrach,", "tokens": ["In", "ders", "an", "Gal\u00b7gen", "kei\u00b7nes\u00b7wegs", "ge\u00b7brach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPR", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Durch tiefen W\u00fcstensand langsam gefahren.", "tokens": ["Durch", "tie\u00b7fen", "W\u00fcs\u00b7ten\u00b7sand", "lang\u00b7sam", "ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.29": {"line.1": {"text": "(hier sch\u00fcttelte das sch\u00f6ne Haupt Chodscheste,", "tokens": ["(", "hier", "sch\u00fct\u00b7tel\u00b7te", "das", "sch\u00f6\u00b7ne", "Haupt", "Chod\u00b7sches\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Indessen sie im Ton der Neugier sprach:", "tokens": ["In\u00b7des\u00b7sen", "sie", "im", "Ton", "der", "Neu\u00b7gier", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wie empfing der Kommandeur die G\u00e4ste?)", "tokens": ["Und", "wie", "emp\u00b7fing", "der", "Kom\u00b7man\u00b7deur", "die", "G\u00e4s\u00b7te", "?", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWAV", "VVFIN", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Gleich, Herrin, gleich! Du wei\u00dft es ja: das Beste", "tokens": ["Gleich", ",", "Her\u00b7rin", ",", "gleich", "!", "Du", "wei\u00dft", "es", "ja", ":", "das", "Bes\u00b7te"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "NN", "$,", "ADV", "$.", "PPER", "VVFIN", "PPER", "ADV", "$.", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kommt bei Geschichten immer hintennach.", "tokens": ["Kommt", "bei", "Ge\u00b7schich\u00b7ten", "im\u00b7mer", "hin\u00b7ten\u00b7nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Denk dir! Der Kommandeur, kaum, da\u00df ein Blick", "tokens": ["Denk", "dir", "!", "Der", "Kom\u00b7man\u00b7deur", ",", "kaum", ",", "da\u00df", "ein", "Blick"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "$.", "ART", "NN", "$,", "ADV", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Aus seinem dunklen Aug das Weib gestreift,", "tokens": ["Aus", "sei\u00b7nem", "dunk\u00b7len", "Aug", "das", "Weib", "ge\u00b7streift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ruft aus: \u00bbDank, Allah, dir und dem Geschick!", "tokens": ["Ruft", "aus", ":", "\u00bb", "Dank", ",", "Al\u00b7lah", ",", "dir", "und", "dem", "Ge\u00b7schick", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "$(", "NN", "$,", "NN", "$,", "PPER", "KON", "ART", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Da ist sie, sie, die scham- und treuelose,", "tokens": ["Da", "ist", "sie", ",", "sie", ",", "die", "scham", "und", "treu\u00b7e\u00b7lo\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PPER", "$,", "ART", "TRUNC", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die viel zu fr\u00fch mein Jugendhaar bereift", "tokens": ["Die", "viel", "zu", "fr\u00fch", "mein", "Ju\u00b7gend\u00b7haar", "be\u00b7reift"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PTKA", "ADJD", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Mit schneeigem Schimmer hat, die meine Rose", "tokens": ["Mit", "schne\u00b7e\u00b7i\u00b7gem", "Schim\u00b7mer", "hat", ",", "die", "mei\u00b7ne", "Ro\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Verliebt ich hie\u00df, und die ich jetzt,", "tokens": ["Ver\u00b7liebt", "ich", "hie\u00df", ",", "und", "die", "ich", "jetzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "$,", "KON", "PRELS", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da sie mein Herz zerrissen und zerfetzt,", "tokens": ["Da", "sie", "mein", "Herz", "zer\u00b7ris\u00b7sen", "und", "zer\u00b7fetzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Den Dornbusch aller Schande nenne,", "tokens": ["Den", "Dorn\u00b7busch", "al\u00b7ler", "Schan\u00b7de", "nen\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Den Dornbusch, den ich, wenn Gerechtigkeit", "tokens": ["Den", "Dorn\u00b7busch", ",", "den", "ich", ",", "wenn", "Ge\u00b7rech\u00b7tig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "$,", "KOUS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "In unserm Land noch herrscht, bei meinem Eid,", "tokens": ["In", "un\u00b7serm", "Land", "noch", "herrscht", ",", "bei", "mei\u00b7nem", "Eid", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVPP", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Samt dem Gestr\u00fcpp, das ihn umgibt, verbrenne!", "tokens": ["Samt", "dem", "Ge\u00b7str\u00fcpp", ",", "das", "ihn", "um\u00b7gibt", ",", "ver\u00b7bren\u00b7ne", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.15": {"text": "Zum Kadi! Auf zum Kadi augenblicks", "tokens": ["Zum", "Ka\u00b7di", "!", "Auf", "zum", "Ka\u00b7di", "au\u00b7gen\u00b7blicks"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NE", "$.", "APPR", "APPRART", "NE", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Mit ihr und jenen, die mir hinterr\u00fccks,", "tokens": ["Mit", "ihr", "und", "je\u00b7nen", ",", "die", "mir", "hin\u00b7ter\u00b7r\u00fccks", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "PDS", "$,", "PRELS", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Die frechen Hunde, sie, mein Weib, geraubt!\u00ab", "tokens": ["Die", "fre\u00b7chen", "Hun\u00b7de", ",", "sie", ",", "mein", "Weib", ",", "ge\u00b7raubt", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPER", "$,", "PPOSAT", "NN", "$,", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Der reiche Mann reibt sich die Augen, glaubt,", "tokens": ["Der", "rei\u00b7che", "Mann", "reibt", "sich", "die", "Au\u00b7gen", ",", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Er tr\u00e4ume, ringt nach Worten, stottert, st\u00f6hnt, \u2013", "tokens": ["Er", "tr\u00e4u\u00b7me", ",", "ringt", "nach", "Wor\u00b7ten", ",", "stot\u00b7tert", ",", "st\u00f6hnt", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "APPR", "NN", "$,", "VVFIN", "$,", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Es hilft ihm nichts, man l\u00e4\u00dft ihn nicht beginnen.", "tokens": ["Es", "hilft", "ihm", "nichts", ",", "man", "l\u00e4\u00dft", "ihn", "nicht", "be\u00b7gin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Es wird die Hand, des Hanfschmucks nicht gew\u00f6hnt,", "tokens": ["Es", "wird", "die", "Hand", ",", "des", "Hanf\u00b7schmucks", "nicht", "ge\u00b7w\u00f6hnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Seilfest gefesselt, und er mu\u00df von hinnen.", "tokens": ["Seil\u00b7fest", "ge\u00b7fes\u00b7selt", ",", "und", "er", "mu\u00df", "von", "hin\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "KON", "PPER", "VMFIN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "Und unsre Vier, nat\u00fcrlich, ebenfalls.", "tokens": ["Und", "uns\u00b7re", "Vier", ",", "na\u00b7t\u00fcr\u00b7lich", ",", "e\u00b7ben\u00b7falls", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ADV", "$,", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbzum Kadi! Wehe! Wehe unserm Hals!\u00ab", "tokens": ["\u00bb", "zum", "Ka\u00b7di", "!", "We\u00b7he", "!", "We\u00b7he", "un\u00b7serm", "Hals", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPRART", "NE", "$.", "NN", "$.", "NN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Nur das Madamchen bleibt ganz still und la\u00df;", "tokens": ["Nur", "das", "Ma\u00b7dam\u00b7chen", "bleibt", "ganz", "still", "und", "la\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ADV", "ADJD", "KON", "VVIMP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie hat sogar, obgleich auch sie gebunden", "tokens": ["Sie", "hat", "so\u00b7gar", ",", "ob\u00b7gleich", "auch", "sie", "ge\u00b7bun\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "$,", "KOUS", "ADV", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und an den Kn\u00f6chelchen leicht aufgeschunden", "tokens": ["Und", "an", "den", "Kn\u00f6\u00b7chel\u00b7chen", "leicht", "auf\u00b7ge\u00b7schun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von diesen dummen Stricken war, etwas", "tokens": ["Von", "die\u00b7sen", "dum\u00b7men", "Stri\u00b7cken", "war", ",", "et\u00b7was"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VAFIN", "$,", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wie kitzelnde Genugtuung empfunden:", "tokens": ["Wie", "kit\u00b7zeln\u00b7de", "Ge\u00b7nug\u00b7tu\u00b7ung", "emp\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ob auch die Fessel ihr das P\u00fclschen pre\u00dfte,", "tokens": ["Ob", "auch", "die", "Fes\u00b7sel", "ihr", "das", "P\u00fcl\u00b7schen", "pre\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Sie f\u00fchlte sich wie V\u00f6gelchen im Neste", "tokens": ["Sie", "f\u00fchl\u00b7te", "sich", "wie", "V\u00f6\u00b7gel\u00b7chen", "im", "Nes\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "KOKOM", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Bei der sehr angenehmen Rechnung, da\u00df", "tokens": ["Bei", "der", "sehr", "an\u00b7ge\u00b7neh\u00b7men", "Rech\u00b7nung", ",", "da\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "$,", "KOUS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Sechs M\u00e4nner sich in sie verliebt in wenigen Stunden.", "tokens": ["Sechs", "M\u00e4n\u00b7ner", "sich", "in", "sie", "ver\u00b7liebt", "in", "we\u00b7ni\u00b7gen", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PRF", "APPR", "PPER", "VVPP", "APPR", "PIAT", "NN", "$."], "meter": "-+--+--+-+--+-", "measure": "amphibrach.tri.plus"}}, "stanza.33": {"line.1": {"text": "(sechs! tr\u00e4umte vor sich hin Chodscheste.)", "tokens": ["(", "sechs", "!", "tr\u00e4um\u00b7te", "vor", "sich", "hin", "Chod\u00b7sches\u00b7te", ".", ")"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "CARD", "$.", "VVFIN", "APPR", "PRF", "ADV", "NN", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.34": {"line.1": {"text": "Und nun zum Kadi denn! Hoch zu Kamele", "tokens": ["Und", "nun", "zum", "Ka\u00b7di", "denn", "!", "Hoch", "zu", "Ka\u00b7me\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NE", "KON", "$.", "ADJD", "APPR", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ritt schlanken Pa\u00dftrabs schnell der Kommandeur", "tokens": ["Ritt", "schlan\u00b7ken", "Pa\u00df\u00b7trabs", "schnell", "der", "Kom\u00b7man\u00b7deur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "NE", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Voll Rachedurst voraus, und seiner Seele", "tokens": ["Voll", "Ra\u00b7che\u00b7durst", "vo\u00b7raus", ",", "und", "sei\u00b7ner", "See\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "NN", "PTKVZ", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hinstr\u00f6mender Ergu\u00df fand huldreiches Geh\u00f6r.", "tokens": ["Hins\u00b7tr\u00f6\u00b7men\u00b7der", "Er\u00b7gu\u00df", "fand", "huld\u00b7rei\u00b7ches", "Ge\u00b7h\u00f6r", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+---+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Der Kadi sprach: \u00bbBei Gott! die Philomele,", "tokens": ["Der", "Ka\u00b7di", "sprach", ":", "\u00bb", "Bei", "Gott", "!", "die", "Phi\u00b7lo\u00b7me\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "$(", "APPR", "NN", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die dich betrogen hat, singt bald nicht mehr!", "tokens": ["Die", "dich", "be\u00b7tro\u00b7gen", "hat", ",", "singt", "bald", "nicht", "mehr", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "$,", "VVFIN", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Denn Ehebruch hei\u00dft Kapitalverbrechen,", "tokens": ["Denn", "E\u00b7heb\u00b7ruch", "hei\u00dft", "Ka\u00b7pi\u00b7tal\u00b7ver\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und nur der Tod kann den Geh\u00f6rnten r\u00e4chen!\u00ab", "tokens": ["Und", "nur", "der", "Tod", "kann", "den", "Ge\u00b7h\u00f6rn\u00b7ten", "r\u00e4\u00b7chen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VMFIN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Du siehst, der Kadi war ein strenger Mann.", "tokens": ["Du", "siehst", ",", "der", "Ka\u00b7di", "war", "ein", "stren\u00b7ger", "Mann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NE", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "(sind alle so? frug bang Chodscheste an.)", "tokens": ["(", "sind", "al\u00b7le", "so", "?", "frug", "bang", "Chod\u00b7sches\u00b7te", "an", ".", ")"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PIS", "ADV", "$.", "VVFIN", "ADJD", "NN", "PTKVZ", "$.", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.36": {"line.1": {"text": "Der unsere wars, d.h. \u2013 nun, du wirst sehn.", "tokens": ["Der", "un\u00b7se\u00b7re", "wars", ",", "d.", "h.", "\u2013", "nun", ",", "du", "wirst", "sehn", "."], "token_info": ["word", "word", "word", "punct", "abbreviation", "abbreviation", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "$,", "PDS", "VVFIN", "$(", "ADV", "$,", "PPER", "VAFIN", "VVINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er war schon alt. Schwer wurde ihm das Gehn,", "tokens": ["Er", "war", "schon", "alt", ".", "Schwer", "wur\u00b7de", "ihm", "das", "Gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$.", "ADJD", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und reichlich fettbeladen war er auch.", "tokens": ["Und", "reich\u00b7lich", "fett\u00b7be\u00b7la\u00b7den", "war", "er", "auch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Nie sah die Welt so ungeheuren Bauch,", "tokens": ["Nie", "sah", "die", "Welt", "so", "un\u00b7ge\u00b7heu\u00b7ren", "Bauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und niemals, glaub ich, sieht sie mehr", "tokens": ["Und", "nie\u00b7mals", ",", "glaub", "ich", ",", "sieht", "sie", "mehr"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An einem Menschen soviel Schmeer.", "tokens": ["An", "ei\u00b7nem", "Men\u00b7schen", "so\u00b7viel", "Schmeer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Augen aber waren winzig,", "tokens": ["Die", "Au\u00b7gen", "a\u00b7ber", "wa\u00b7ren", "win\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der Blick war bl\u00f6de, m\u00fcde, blinzig,", "tokens": ["Der", "Blick", "war", "bl\u00f6\u00b7de", ",", "m\u00fc\u00b7de", ",", "blin\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJA", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die Haut war, ja, wie sag ich gleich,", "tokens": ["Die", "Haut", "war", ",", "ja", ",", "wie", "sag", "ich", "gleich", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PTKANT", "$,", "PWAV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nicht seiden- oder sammetweich:", "tokens": ["Nicht", "sei\u00b7den", "o\u00b7der", "sam\u00b7met\u00b7weich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "TRUNC", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Mehr lederartig und dabei", "tokens": ["Mehr", "le\u00b7der\u00b7ar\u00b7tig", "und", "da\u00b7bei"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "PAV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Nicht ganz von kleinen Flecken frei,", "tokens": ["Nicht", "ganz", "von", "klei\u00b7nen", "Fle\u00b7cken", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die ab und an ein wenig n\u00e4\u00dften.", "tokens": ["Die", "ab", "und", "an", "ein", "we\u00b7nig", "n\u00e4\u00df\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKVZ", "KON", "APPR", "ART", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "(hier wurde nicht ganz wohl Chodschesten.)", "tokens": ["(", "hier", "wur\u00b7de", "nicht", "ganz", "wohl", "Chod\u00b7sches\u00b7ten", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "PTKNEG", "ADV", "ADV", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Kurz: reizend war er eben nicht.", "tokens": ["Kurz", ":", "rei\u00b7zend", "war", "er", "e\u00b7ben", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "VVPP", "VAFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch, wer sucht Reize bei Gericht?", "tokens": ["Doch", ",", "wer", "sucht", "Rei\u00b7ze", "bei", "Ge\u00b7richt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "VVFIN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch hatte er, das mu\u00df der Neid ihm lassen,", "tokens": ["Auch", "hat\u00b7te", "er", ",", "das", "mu\u00df", "der", "Neid", "ihm", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PDS", "VMFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Kunst der niederschmetternden Grimassen,", "tokens": ["Die", "Kunst", "der", "nie\u00b7der\u00b7schmet\u00b7tern\u00b7den", "Gri\u00b7mas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--++-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Vor denen, wer mit S\u00fcndenlast", "tokens": ["Vor", "de\u00b7nen", ",", "wer", "mit", "S\u00fcn\u00b7den\u00b7last"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PRELS", "$,", "PWS", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In ihr Bereich tritt, j\u00e4h erbla\u00dft.", "tokens": ["In", "ihr", "Be\u00b7reich", "tritt", ",", "j\u00e4h", "er\u00b7bla\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So sa\u00df er da mit f\u00fcrchterlichen Mienen,", "tokens": ["So", "sa\u00df", "er", "da", "mit", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Mie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Als unsere Vier vor ihm erschienen,", "tokens": ["Als", "un\u00b7se\u00b7re", "Vier", "vor", "ihm", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Und, \u2013 na, was ist? um Gottes willen,", "tokens": ["Und", ",", "\u2013", "na", ",", "was", "ist", "?", "um", "Got\u00b7tes", "wil\u00b7len", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "$(", "ITJ", "$,", "PWS", "VAFIN", "$.", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Was ist denn los? \u2013: der Kadi schreit", "tokens": ["Was", "ist", "denn", "los", "?", "\u2013", ":", "der", "Ka\u00b7di", "schreit"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "PTKVZ", "$.", "$(", "$.", "ART", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und rei\u00dft die kleinen Augen weit,", "tokens": ["Und", "rei\u00dft", "die", "klei\u00b7nen", "Au\u00b7gen", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Unglaublich weit auf: \u00bbMeine Brillen!", "tokens": ["Un\u00b7glaub\u00b7lich", "weit", "auf", ":", "\u00bb", "Mei\u00b7ne", "Bril\u00b7len", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKVZ", "$.", "$(", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "So bringt mir doch die Brillen!\u00ab \u2013 Da, \u2013", "tokens": ["So", "bringt", "mir", "doch", "die", "Bril\u00b7len", "!", "\u00ab", "\u2013", "Da", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$.", "$(", "$(", "ADV", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Er setzt sie auf: \u2013 \u00bbBei Allah! Ja!", "tokens": ["Er", "setzt", "sie", "auf", ":", "\u2013", "\u00bb", "Bei", "Al\u00b7lah", "!", "Ja", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "$(", "APPR", "NN", "$.", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Sie ists! Sie ists! O welch Entz\u00fccken!", "tokens": ["Sie", "ists", "!", "Sie", "ists", "!", "O", "welch", "Ent\u00b7z\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "PPER", "VAFIN", "$.", "NE", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Komm, la\u00df an meine Brust dich dr\u00fccken!", "tokens": ["Komm", ",", "la\u00df", "an", "mei\u00b7ne", "Brust", "dich", "dr\u00fc\u00b7cken", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVIMP", "APPR", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Hab keine Angst, ich straf dich nicht,", "tokens": ["Hab", "kei\u00b7ne", "Angst", ",", "ich", "straf", "dich", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "O du mein Mond- und Sonnenlicht!", "tokens": ["O", "du", "mein", "Mon\u00b7d", "und", "Son\u00b7nen\u00b7licht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPOSAT", "TRUNC", "KON", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.19": {"text": "Was du auch tatst, es ist verziehn,", "tokens": ["Was", "du", "auch", "tatst", ",", "es", "ist", "ver\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Willst du nur nicht noch einmal fliehn!", "tokens": ["Willst", "du", "nur", "nicht", "noch", "ein\u00b7mal", "fliehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PTKNEG", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Mein Zuckersch\u00f6tchen! Mein Perlenschneckchen!", "tokens": ["Mein", "Zu\u00b7cker\u00b7sch\u00f6t\u00b7chen", "!", "Mein", "Per\u00b7len\u00b7schneck\u00b7chen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Mein Sammetf\u00fc\u00dfchen! Mein Honigweckchen!", "tokens": ["Mein", "Sam\u00b7met\u00b7f\u00fc\u00df\u00b7chen", "!", "Mein", "Ho\u00b7nig\u00b7weck\u00b7chen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "O komm, sei gut, o komm zu mir,", "tokens": ["O", "komm", ",", "sei", "gut", ",", "o", "komm", "zu", "mir", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VAFIN", "ADJD", "$,", "FM", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Mein Seligkeitenelixier!", "tokens": ["Mein", "Se\u00b7lig\u00b7kei\u00b7ten\u00b7e\u00b7li\u00b7xier", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Was du verlangst, ich will dir alles schenken,", "tokens": ["Was", "du", "ver\u00b7langst", ",", "ich", "will", "dir", "al\u00b7les", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Und blo\u00df die andern la\u00df ich henken!\u00ab", "tokens": ["Und", "blo\u00df", "die", "an\u00b7dern", "la\u00df", "ich", "hen\u00b7ken", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "VVIMP", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Bei diesen Worten des alten Kadi", "tokens": ["Bei", "die\u00b7sen", "Wor\u00b7ten", "des", "al\u00b7ten", "Ka\u00b7di"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "ART", "ADJA", "NE"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Standen bilds\u00e4ulen\u00e4hnlich da die", "tokens": ["Stan\u00b7den", "bild\u00b7s\u00e4u\u00b7le\u00b7n\u00e4hn\u00b7lich", "da", "die"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "ADV", "ART"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "M\u00e4nnlichen Personen dieser Geschichte.", "tokens": ["M\u00e4nn\u00b7li\u00b7chen", "Per\u00b7so\u00b7nen", "die\u00b7ser", "Ge\u00b7schich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PDAT", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Doch auf des Weibes sch\u00f6nem Gesichte", "tokens": ["Doch", "auf", "des", "Wei\u00b7bes", "sch\u00f6\u00b7nem", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "War immer das gleiche L\u00e4cheln zu sehn", "tokens": ["War", "im\u00b7mer", "das", "glei\u00b7che", "L\u00e4\u00b7cheln", "zu", "sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und nicht ", "tokens": ["Und", "nicht"], "token_info": ["word", "word"], "pos": ["KON", "PTKNEG"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Es schien, was alles auch passierte,", "tokens": ["Es", "schien", ",", "was", "al\u00b7les", "auch", "pas\u00b7sier\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das holde D\u00e4mchen fand es blo\u00df scharmant,", "tokens": ["Das", "hol\u00b7de", "D\u00e4m\u00b7chen", "fand", "es", "blo\u00df", "schar\u00b7mant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Da\u00df jeder Mann f\u00fcr sich sie reklamierte.", "tokens": ["Da\u00df", "je\u00b7der", "Mann", "f\u00fcr", "sich", "sie", "re\u00b7kla\u00b7mier\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "APPR", "PRF", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Die ganze Welt schien ihr ein Zuckerkant,", "tokens": ["Die", "gan\u00b7ze", "Welt", "schien", "ihr", "ein", "Zu\u00b7cker\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Den sie mit L\u00e4cheln schnabulierte,", "tokens": ["Den", "sie", "mit", "L\u00e4\u00b7cheln", "schna\u00b7bu\u00b7lier\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Im S\u00fc\u00dfigkeitenknabbern h\u00f6chst gewandt.", "tokens": ["Im", "S\u00fc\u00b7\u00dfig\u00b7kei\u00b7ten\u00b7knab\u00b7bern", "h\u00f6chst", "ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.40": {"line.1": {"text": "Sie tat, als w\u00e4r sie zum Vergn\u00fcgen hier.", "tokens": ["Sie", "tat", ",", "als", "w\u00e4r", "sie", "zum", "Ver\u00b7gn\u00fc\u00b7gen", "hier", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOKOM", "VAFIN", "PPER", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sogar der Kadi machte ihr Pl\u00e4sier.", "tokens": ["So\u00b7gar", "der", "Ka\u00b7di", "mach\u00b7te", "ihr", "Pl\u00e4\u00b7sier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.41": {"line.1": {"text": "Die andern aber, als das starre Staunen", "tokens": ["Die", "an\u00b7dern", "a\u00b7ber", ",", "als", "das", "star\u00b7re", "Stau\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADV", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vor\u00fcber war, emp\u00f6rten sich gewaltig", "tokens": ["Vor\u00b7\u00fc\u00b7ber", "war", ",", "em\u00b7p\u00f6r\u00b7ten", "sich", "ge\u00b7wal\u00b7tig"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$,", "VVFIN", "PRF", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und \u00e4u\u00dferten mit Worten mannigfaltig,", "tokens": ["Und", "\u00e4u\u00b7\u00dfer\u00b7ten", "mit", "Wor\u00b7ten", "man\u00b7nig\u00b7fal\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch mehr mit Br\u00fcllen, als mit leisem Raunen,", "tokens": ["Doch", "mehr", "mit", "Br\u00fcl\u00b7len", ",", "als", "mit", "lei\u00b7sem", "Rau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "$,", "KOUS", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie seien nicht im mindesten gesonnen,", "tokens": ["Sie", "sei\u00b7en", "nicht", "im", "min\u00b7des\u00b7ten", "ge\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "APPRART", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Beim Fest der richterlichen Liebeswonnen", "tokens": ["Beim", "Fest", "der", "rich\u00b7ter\u00b7li\u00b7chen", "Lie\u00b7bes\u00b7won\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Als Fahnenschmuck am Galgenstamm zu dienen.", "tokens": ["Als", "Fah\u00b7nen\u00b7schmuck", "am", "Gal\u00b7gen\u00b7stamm", "zu", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "\u00bbdas Weib ist mein!\u00ab rief jeglicher von ihnen,", "tokens": ["\u00bb", "das", "Weib", "ist", "mein", "!", "\u00ab", "rief", "jeg\u00b7li\u00b7cher", "von", "ih\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PPOSAT", "$.", "$(", "VVFIN", "PIAT", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbund der Herr Kadi ist jetzt selbst Partei.\u00ab", "tokens": ["\u00bb", "und", "der", "Herr", "Ka\u00b7di", "ist", "jetzt", "selbst", "Par\u00b7tei", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "ART", "NN", "NE", "VAFIN", "ADV", "ADV", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.42": {"line.1": {"text": "Es war ein Armefuchteln, ein Geschrei,", "tokens": ["Es", "war", "ein", "Ar\u00b7me\u00b7fuch\u00b7teln", ",", "ein", "Ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein F\u00e4usteballen, H\u00e4lserecken, Toben,", "tokens": ["Ein", "F\u00e4us\u00b7te\u00b7bal\u00b7len", ",", "H\u00e4l\u00b7ser\u00b7e\u00b7cken", ",", "To\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df selbst die Seligen im Himmel oben", "tokens": ["Da\u00df", "selbst", "die", "Se\u00b7li\u00b7gen", "im", "Him\u00b7mel", "o\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sich wolkennieder b\u00fcckten, was denn sei;", "tokens": ["Sich", "wol\u00b7ken\u00b7nie\u00b7der", "b\u00fcck\u00b7ten", ",", "was", "denn", "sei", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVFIN", "$,", "PRELS", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und alles Volk, aus K\u00fcchen, Kellern, Koben,", "tokens": ["Und", "al\u00b7les", "Volk", ",", "aus", "K\u00fc\u00b7chen", ",", "Kel\u00b7lern", ",", "Ko\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wer sich nur regen konnte, kam herbei;", "tokens": ["Wer", "sich", "nur", "re\u00b7gen", "konn\u00b7te", ",", "kam", "her\u00b7bei", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADV", "ADJA", "VMFIN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sogar die Koransch\u00fcler kriegten frei", "tokens": ["So\u00b7gar", "die", "Ko\u00b7ran\u00b7sch\u00fc\u00b7ler", "krieg\u00b7ten", "frei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und hatten einen Grund ", "tokens": ["Und", "hat\u00b7ten", "ei\u00b7nen", "Grund"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "So gro\u00df war das Getrubel und Geschw\u00e4rme,", "tokens": ["So", "gro\u00df", "war", "das", "Ge\u00b7tru\u00b7bel", "und", "Ge\u00b7schw\u00e4r\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So ungeheuer war des Volks Gel\u00e4rme,", "tokens": ["So", "un\u00b7ge\u00b7heu\u00b7er", "war", "des", "Volks", "Ge\u00b7l\u00e4r\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df selbst ein Dschogi, der nun schon ein Jahr,", "tokens": ["Da\u00df", "selbst", "ein", "Dscho\u00b7gi", ",", "der", "nun", "schon", "ein", "Jahr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NE", "$,", "PRELS", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "And\u00e4chtig, aller Weltgedanken bar,", "tokens": ["An\u00b7d\u00e4ch\u00b7tig", ",", "al\u00b7ler", "Welt\u00b7ge\u00b7dan\u00b7ken", "bar", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Verz\u00fcckt auf einer hohen S\u00e4ule Knauf", "tokens": ["Ver\u00b7z\u00fcckt", "auf", "ei\u00b7ner", "ho\u00b7hen", "S\u00e4u\u00b7le", "Knauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Gleich einem \u00d6lbaumstrunk gestanden war,", "tokens": ["Gleich", "ei\u00b7nem", "\u00d6l\u00b7baum\u00b7strunk", "ge\u00b7stan\u00b7den", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Das Wesen merkte. Niemand sah hinauf", "tokens": ["Das", "We\u00b7sen", "merk\u00b7te", ".", "Nie\u00b7mand", "sah", "hin\u00b7auf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Zu seiner frommen Pose. Selbst die Weiberschar,", "tokens": ["Zu", "sei\u00b7ner", "from\u00b7men", "Po\u00b7se", ".", "Selbst", "die", "Wei\u00b7ber\u00b7schar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$.", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die stets bewundernd ihm zu F\u00fc\u00dfen stand", "tokens": ["Die", "stets", "be\u00b7wun\u00b7dernd", "ihm", "zu", "F\u00fc\u00b7\u00dfen", "stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVPP", "PPER", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und nie genug Bewunderungsworte fand,", "tokens": ["Und", "nie", "ge\u00b7nug", "Be\u00b7wun\u00b7de\u00b7rungs\u00b7wor\u00b7te", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+----+", "measure": "unknown.measure.tetra"}, "line.11": {"text": "Des Heiligen Kraft und Wundertum zu preisen:", "tokens": ["Des", "Hei\u00b7li\u00b7gen", "Kraft", "und", "Wun\u00b7der\u00b7tum", "zu", "prei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Selbst sie war weg, war einfach durchgebrannt.", "tokens": ["Selbst", "sie", "war", "weg", ",", "war", "ein\u00b7fach", "durch\u00b7ge\u00b7brannt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADV", "$,", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Der Dschogi kam sich vor wie altes Eisen.", "tokens": ["Der", "Dscho\u00b7gi", "kam", "sich", "vor", "wie", "al\u00b7tes", "Ei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PRF", "PTKVZ", "KOKOM", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.44": {"line.1": {"text": "\u00bbdas also ist der Welten Lauf!\u00ab", "tokens": ["\u00bb", "das", "al\u00b7so", "ist", "der", "Wel\u00b7ten", "Lauf", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "ADV", "VAFIN", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So rief er aus: \u00bbIch la\u00df mir durch die Hand", "tokens": ["So", "rief", "er", "aus", ":", "\u00bb", "Ich", "la\u00df", "mir", "durch", "die", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das ganze liebe Jahr die N\u00e4gel wachsen,", "tokens": ["Das", "gan\u00b7ze", "lie\u00b7be", "Jahr", "die", "N\u00e4\u00b7gel", "wach\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und die Bewunderung h\u00f6rt mit einmal auf,", "tokens": ["Und", "die", "Be\u00b7wun\u00b7de\u00b7rung", "h\u00f6rt", "mit", "ein\u00b7mal", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "ADV", "PTKVZ", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Macht irgendwer, Gott wei\u00df es was f\u00fcr Faxen,", "tokens": ["Macht", "ir\u00b7gend\u00b7wer", ",", "Gott", "wei\u00df", "es", "was", "f\u00fcr", "Fa\u00b7xen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "NN", "VVFIN", "PPER", "PIS", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die, darauf nehm ich Gift, gar nichts bedeuten.", "tokens": ["Die", ",", "da\u00b7rauf", "nehm", "ich", "Gift", ",", "gar", "nichts", "be\u00b7deu\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PAV", "VVFIN", "PPER", "NN", "$,", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Schlimm ist die Welt, wei\u00df Gott, die Zeit ist b\u00f6s;", "tokens": ["Schlimm", "ist", "die", "Welt", ",", "wei\u00df", "Gott", ",", "die", "Zeit", "ist", "b\u00f6s", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,", "VVFIN", "NN", "$,", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Sogar die Weiber sind irreligi\u00f6s,", "tokens": ["So\u00b7gar", "die", "Wei\u00b7ber", "sind", "ir\u00b7re\u00b7li\u00b7gi\u00b7\u00f6s", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+--++--+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Und \u00fcberhaupt, es ist nichts mit den Leuten.\u00ab", "tokens": ["Und", "\u00fc\u00b7ber\u00b7haupt", ",", "es", "ist", "nichts", "mit", "den", "Leu\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "$,", "PPER", "VAFIN", "PIS", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.45": {"line.1": {"text": "Nach diesen Worten drehte er sich um", "tokens": ["Nach", "die\u00b7sen", "Wor\u00b7ten", "dreh\u00b7te", "er", "sich", "um"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "PRF", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und hob die d\u00fcnnen H\u00e4nde (krumm,", "tokens": ["Und", "hob", "die", "d\u00fcn\u00b7nen", "H\u00e4n\u00b7de", "(", "krumm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$(", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weil wirklich sie durchwachsen waren", "tokens": ["Weil", "wirk\u00b7lich", "sie", "durch\u00b7wach\u00b7sen", "wa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von seinen N\u00e4geln) \u00fcbers Augenpaar,", "tokens": ["Von", "sei\u00b7nen", "N\u00e4\u00b7geln", ")", "\u00fc\u00b7bers", "Au\u00b7gen\u00b7paar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Zu sehn, wohin das Volk in Scharen", "tokens": ["Zu", "sehn", ",", "wo\u00b7hin", "das", "Volk", "in", "Scha\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "PWAV", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Denn eigentlich gelaufen war.", "tokens": ["Denn", "ei\u00b7gent\u00b7lich", "ge\u00b7lau\u00b7fen", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbnat\u00fcrlich! Ein Proze\u00df! Beim Kadi. Hum!", "tokens": ["\u00bb", "na\u00b7t\u00fcr\u00b7lich", "!", "Ein", "Pro\u00b7ze\u00df", "!", "Beim", "Ka\u00b7di", ".", "Hum", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADV", "$.", "ART", "NN", "$.", "APPRART", "NE", "$.", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Gewi\u00df ein sch\u00f6ner Fall! Wie dumm, wie dumm,", "tokens": ["Ge\u00b7wi\u00df", "ein", "sch\u00f6\u00b7ner", "Fall", "!", "Wie", "dumm", ",", "wie", "dumm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$.", "PWAV", "ADJD", "$,", "PWAV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Da\u00df just der g\u00f6ttlichste Jurist", "tokens": ["Da\u00df", "just", "der", "g\u00f6tt\u00b7lichs\u00b7te", "Ju\u00b7rist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Vom Zuh\u00f6rn ausgeschlossen ist!\u00ab", "tokens": ["Vom", "Zu\u00b7h\u00f6rn", "aus\u00b7ge\u00b7schlos\u00b7sen", "ist", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "(der Dschogi n\u00e4mlich, da\u00df ihrs wi\u00dft,", "tokens": ["(", "der", "Dscho\u00b7gi", "n\u00e4m\u00b7lich", ",", "da\u00df", "ihrs", "wi\u00dft", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NE", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "War fr\u00fcher, eh ihm klar geworden,", "tokens": ["War", "fr\u00fc\u00b7her", ",", "eh", "ihm", "klar", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "KOUS", "PPER", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Da\u00df nichts vergleichbar sei im ganzen Staat", "tokens": ["Da\u00df", "nichts", "ver\u00b7gleich\u00b7bar", "sei", "im", "gan\u00b7zen", "Staat"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADJD", "VAFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "An innerem Wert dem Bettelorden,", "tokens": ["An", "in\u00b7ne\u00b7rem", "Wert", "dem", "Bet\u00b7tel\u00b7or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Ein h\u00f6chst ber\u00fchmter Advokat.)", "tokens": ["Ein", "h\u00f6chst", "be\u00b7r\u00fchm\u00b7ter", "Ad\u00b7vo\u00b7kat", ".", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "\u00bbich, gerade ich! Beim Himmel: nein!", "tokens": ["\u00bb", "ich", ",", "ge\u00b7ra\u00b7de", "ich", "!", "Beim", "Him\u00b7mel", ":", "nein", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "$,", "ADV", "PPER", "$.", "APPRART", "NN", "$.", "PTKANT", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.17": {"text": "Ich will und mu\u00df zugegen sein!", "tokens": ["Ich", "will", "und", "mu\u00df", "zu\u00b7ge\u00b7gen", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KON", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Ein Fall, der alle interessiert,", "tokens": ["Ein", "Fall", ",", "der", "al\u00b7le", "in\u00b7ter\u00b7es\u00b7siert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.19": {"text": "Wird w\u00fcrdig nur durch mich pl\u00e4diert.\u00ab", "tokens": ["Wird", "w\u00fcr\u00b7dig", "nur", "durch", "mich", "pl\u00e4\u00b7diert", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "APPR", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Und sieh, der Heilige, der sonst nichts kannte,", "tokens": ["Und", "sieh", ",", "der", "Hei\u00b7li\u00b7ge", ",", "der", "sonst", "nichts", "kann\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "ADJA", "$,", "PRELS", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als tiefste Selbstversunkenheit,", "tokens": ["Als", "tiefs\u00b7te", "Selbst\u00b7ver\u00b7sun\u00b7ken\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der allem Leben Abgewandte", "tokens": ["Der", "al\u00b7lem", "Le\u00b7ben", "Ab\u00b7ge\u00b7wand\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIS", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In tiefster Seelentrunkenheit,", "tokens": ["In", "tiefs\u00b7ter", "See\u00b7len\u00b7trun\u00b7ken\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der alles Wollen aus sich bannte", "tokens": ["Der", "al\u00b7les", "Wol\u00b7len", "aus", "sich", "bann\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In dieser Welt Halunkenheit:", "tokens": ["In", "die\u00b7ser", "Welt", "Ha\u00b7lun\u00b7ken\u00b7heit", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der S\u00e4ulenheilige umspannte", "tokens": ["Der", "S\u00e4u\u00b7len\u00b7hei\u00b7li\u00b7ge", "um\u00b7spann\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit seinem d\u00fcrren Beinepaar", "tokens": ["Mit", "sei\u00b7nem", "d\u00fcr\u00b7ren", "Bei\u00b7ne\u00b7paar"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der S\u00e4ule Schaft \u2013 und war viel eher unten,", "tokens": ["Der", "S\u00e4u\u00b7le", "Schaft", "\u2013", "und", "war", "viel", "e\u00b7her", "un\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "KON", "VAFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Als seinem Hinterteile dienlich war.", "tokens": ["Als", "sei\u00b7nem", "Hin\u00b7ter\u00b7tei\u00b7le", "dien\u00b7lich", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Er hat nicht leicht das Gleichgewicht gefunden.", "tokens": ["Er", "hat", "nicht", "leicht", "das", "Gleich\u00b7ge\u00b7wicht", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Doch, als ers hatte, hei, wie rannte er!", "tokens": ["Doch", ",", "als", "ers", "hat\u00b7te", ",", "hei", ",", "wie", "rann\u00b7te", "er", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "VAFIN", "$,", "ITJ", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "-++--+-+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Sein Lendenschurz genierte ihn nicht sehr,", "tokens": ["Sein", "Len\u00b7den\u00b7schurz", "ge\u00b7nier\u00b7te", "ihn", "nicht", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Und, als er ihn verlor im hei\u00dfen Lauf,", "tokens": ["Und", ",", "als", "er", "ihn", "ver\u00b7lor", "im", "hei\u00b7\u00dfen", "Lauf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Hielt unsern guten Dschogi gar nichts mehr,", "tokens": ["Hielt", "un\u00b7sern", "gu\u00b7ten", "Dscho\u00b7gi", "gar", "nichts", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NE", "ADV", "PIS", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Als h\u00f6chstens seine schwache Lunge auf.", "tokens": ["Als", "h\u00f6chs\u00b7tens", "sei\u00b7ne", "schwa\u00b7che", "Lun\u00b7ge", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.47": {"line.1": {"text": "Mit Keuchen kam der heilige Mann", "tokens": ["Mit", "Keu\u00b7chen", "kam", "der", "hei\u00b7li\u00b7ge", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "In des Gerichts Get\u00fcmmel an,", "tokens": ["In", "des", "Ge\u00b7richts", "Ge\u00b7t\u00fcm\u00b7mel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und alles schrie: \u00bbPa\u00dft auf! Jetzt wird es Licht!", "tokens": ["Und", "al\u00b7les", "schrie", ":", "\u00bb", "Pa\u00dft", "auf", "!", "Jetzt", "wird", "es", "Licht", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$.", "$(", "VVIMP", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Jetzt sitzt der Heilige zu Gericht!\u00ab", "tokens": ["Jetzt", "sitzt", "der", "Hei\u00b7li\u00b7ge", "zu", "Ge\u00b7richt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "APPR", "NN", "$.", "$("], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}}, "stanza.48": {"line.1": {"text": "Und als nun Seit an Seit das Paar,", "tokens": ["Und", "als", "nun", "Seit", "an", "Seit", "das", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "NN", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Dicke und der D\u00fcnne sa\u00df,", "tokens": ["Der", "Di\u00b7cke", "und", "der", "D\u00fcn\u00b7ne", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da sah das Publikum erst klar,", "tokens": ["Da", "sah", "das", "Pub\u00b7li\u00b7kum", "erst", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie dick sein dicker Kadi war:", "tokens": ["Wie", "dick", "sein", "di\u00b7cker", "Ka\u00b7di", "war", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "ADJA", "NE", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der D\u00fcnne war des Dicken Ma\u00df.", "tokens": ["Der", "D\u00fcn\u00b7ne", "war", "des", "Di\u00b7cken", "Ma\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und zu gemeinem Gaudium", "tokens": ["Und", "zu", "ge\u00b7mei\u00b7nem", "Gau\u00b7di\u00b7um"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Rief einer aus dem Publikum:", "tokens": ["Rief", "ei\u00b7ner", "aus", "dem", "Pub\u00b7li\u00b7kum", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbseht, welch ein Spa\u00df:", "tokens": ["\u00bb", "seht", ",", "welch", "ein", "Spa\u00df", ":"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "PWAT", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Die Mutterzwiebel und das Zittergras!\u00ab", "tokens": ["Die", "Mut\u00b7ter\u00b7zwie\u00b7bel", "und", "das", "Zit\u00b7ter\u00b7gras", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.49": {"line.1": {"text": "(f\u00fcr welchen Witz der Humorist,", "tokens": ["(", "f\u00fcr", "wel\u00b7chen", "Witz", "der", "Hu\u00b7mo\u00b7rist", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PWAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der so des Ortes W\u00fcrdigkeit verga\u00df,", "tokens": ["Der", "so", "des", "Or\u00b7tes", "W\u00fcr\u00b7dig\u00b7keit", "ver\u00b7ga\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gleich krumm geschlossen worden ist.)", "tokens": ["Gleich", "krumm", "ge\u00b7schlos\u00b7sen", "wor\u00b7den", "ist", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAPP", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Und aller Blicke wandten sich", "tokens": ["Und", "al\u00b7ler", "Bli\u00b7cke", "wand\u00b7ten", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem heiligen Manne zu, und: \u00bbSprich!", "tokens": ["Dem", "hei\u00b7li\u00b7gen", "Man\u00b7ne", "zu", ",", "und", ":", "\u00bb", "Sprich", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,", "KON", "$.", "$(", "VVIMP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sprich Recht, du Unbefleckter!\u00ab schrien", "tokens": ["Sprich", "Recht", ",", "du", "Un\u00b7be\u00b7fleck\u00b7ter", "!", "\u00ab", "schri\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word"], "pos": ["VVIMP", "NN", "$,", "PPER", "NN", "$.", "$(", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Tausende und nannten ihn", "tokens": ["Die", "Tau\u00b7sen\u00b7de", "und", "nann\u00b7ten", "ihn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bei tausend Heiligen- und Ehrennamen.", "tokens": ["Bei", "tau\u00b7send", "Hei\u00b7li\u00b7gen", "und", "Eh\u00b7ren\u00b7na\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.51": {"line.1": {"text": "Er aber sprang in seiner Nacktheit hoch", "tokens": ["Er", "a\u00b7ber", "sprang", "in", "sei\u00b7ner", "Nackt\u00b7heit", "hoch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Vom Sitz empor und drehte sich im Kreise,", "tokens": ["Vom", "Sitz", "em\u00b7por", "und", "dreh\u00b7te", "sich", "im", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "KON", "VVFIN", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Indes den Leib er wie im Krampfe bog,", "tokens": ["In\u00b7des", "den", "Leib", "er", "wie", "im", "Kramp\u00b7fe", "bog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPER", "KOKOM", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und schrie auf f\u00fcrchterliche Weise:", "tokens": ["Und", "schrie", "auf", "f\u00fcrch\u00b7ter\u00b7li\u00b7che", "Wei\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbamen! Amen! Amen!", "tokens": ["\u00bb", "a\u00b7men", "!", "A\u00b7men", "!", "A\u00b7men", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "VVINF", "$.", "NN", "$.", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Allah illallilah!", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Allah illallilah!", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Kniet nieder! Nieder! Nieder!", "tokens": ["Kniet", "nie\u00b7der", "!", "Nie\u00b7der", "!", "Nie\u00b7der", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "ADV", "$.", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Der Vogel des Paradieses kam wieder!", "tokens": ["Der", "Vo\u00b7gel", "des", "Pa\u00b7ra\u00b7die\u00b7ses", "kam", "wie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Mein Gl\u00fcck ist wieder da!", "tokens": ["Mein", "Gl\u00fcck", "ist", "wie\u00b7der", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Und nun auf von den Knien!", "tokens": ["Und", "nun", "auf", "von", "den", "Kni\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "APPR", "ART", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "Allah illallilah!", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Tanzt, Moslemin!", "tokens": ["Tanzt", ",", "Mos\u00b7le\u00b7min", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.14": {"text": "Allah illallilah!", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Tanzet um ihn,", "tokens": ["Tan\u00b7zet", "um", "ihn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.16": {"text": "Tanzt um den Vogel mit goldnem Gefieder!", "tokens": ["Tanzt", "um", "den", "Vo\u00b7gel", "mit", "gold\u00b7nem", "Ge\u00b7fie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.17": {"text": "Viel besser ists, um ihn sich drehn,", "tokens": ["Viel", "bes\u00b7ser", "ists", ",", "um", "ihn", "sich", "drehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "KOUI", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Allah illallilah,", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Als auf dem S\u00e4ulenknauf zu stehn,", "tokens": ["Als", "auf", "dem", "S\u00e4u\u00b7len\u00b7knauf", "zu", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Allah illallilah,", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Und der Sonne ins goldne Gesicht zu sehn.", "tokens": ["Und", "der", "Son\u00b7ne", "ins", "gold\u00b7ne", "Ge\u00b7sicht", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.22": {"text": "Ich tu es niemals wieder,", "tokens": ["Ich", "tu", "es", "nie\u00b7mals", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Seitdem ", "tokens": ["Seit\u00b7dem"], "token_info": ["word"], "pos": ["PAV"], "meter": "+-", "measure": "trochaic.single"}, "line.24": {"text": "Allah illallilah,", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.25": {"text": "Und nie soll sie wieder von mir gehn!\u00ab", "tokens": ["Und", "nie", "soll", "sie", "wie\u00b7der", "von", "mir", "gehn", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.52": {"line.1": {"text": "Du siehst, o Herrin, unser Dschogi war", "tokens": ["Du", "siehst", ",", "o", "Her\u00b7rin", ",", "un\u00b7ser", "Dscho\u00b7gi", "war"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "FM", "NN", "$,", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Seit Jahresfrist ein Heiliger zwar,", "tokens": ["Seit", "Jah\u00b7res\u00b7frist", "ein", "Hei\u00b7li\u00b7ger", "zwar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Jedoch in puncto puncti just auch nicht der beste.", "tokens": ["Je\u00b7doch", "in", "punc\u00b7to", "punc\u00b7ti", "just", "auch", "nicht", "der", "bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "FM", "FM", "FM", "ADV", "PTKNEG", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.53": {"line.1": {"text": "(das d\u00fcnkt mich weiter nicht so wunderbar,", "tokens": ["(", "das", "d\u00fcnkt", "mich", "wei\u00b7ter", "nicht", "so", "wun\u00b7der\u00b7bar", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dieweil ein M\u00f6nch \u2013 ein Mann, erwiderte Chodscheste.", "tokens": ["Die\u00b7weil", "ein", "M\u00f6nch", "\u2013", "ein", "Mann", ",", "er\u00b7wi\u00b7der\u00b7te", "Chod\u00b7sches\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$(", "ART", "NN", "$,", "VVFIN", "NE", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und wieder zeigt der alte Spruch sich wahr:", "tokens": ["Und", "wie\u00b7der", "zeigt", "der", "al\u00b7te", "Spruch", "sich", "wahr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wie klein davon auch immer sein die Reste:", "tokens": ["Wie", "klein", "da\u00b7von", "auch", "im\u00b7mer", "sein", "die", "Res\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PAV", "ADV", "ADV", "PPOSAT", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Moschus und Liebe sind un-aus-treib-bar.", "tokens": ["Mo\u00b7schus", "und", "Lie\u00b7be", "sind", "un\u00b7aus\u00b7treib\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Die Tugend kann ein jeder Mensch verhehlen,", "tokens": ["Die", "Tu\u00b7gend", "kann", "ein", "je\u00b7der", "Mensch", "ver\u00b7heh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Vertreibbar ist Geruch selbst von Kamelen,", "tokens": ["Ver\u00b7treib\u00b7bar", "ist", "Ge\u00b7ruch", "selbst", "von", "Ka\u00b7me\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "NN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Doch, wo nur Liebe je und Moschus war:", "tokens": ["Doch", ",", "wo", "nur", "Lie\u00b7be", "je", "und", "Mo\u00b7schus", "war", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ADV", "NN", "ADV", "KON", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ein R\u00fcchlein bleibt in K\u00e4sten oder Seelen.)", "tokens": ["Ein", "R\u00fcch\u00b7lein", "bleibt", "in", "K\u00e4s\u00b7ten", "o\u00b7der", "See\u00b7len", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.54": {"line.1": {"text": "Sehr richtig, Herrin! Und in diesem Falle", "tokens": ["Sehr", "rich\u00b7tig", ",", "Her\u00b7rin", "!", "Und", "in", "die\u00b7sem", "Fal\u00b7le"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "NN", "$.", "KON", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Rochen den Braten auf der Stelle Alle.", "tokens": ["Ro\u00b7chen", "den", "Bra\u00b7ten", "auf", "der", "Stel\u00b7le", "Al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "ART", "NN", "PIAT", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und wie aus einem Munde schrie", "tokens": ["Und", "wie", "aus", "ei\u00b7nem", "Mun\u00b7de", "schrie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ganze Volk: \u00bbSchon wieder sie!", "tokens": ["Das", "gan\u00b7ze", "Volk", ":", "\u00bb", "Schon", "wie\u00b7der", "sie", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$(", "ADV", "ADV", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Weibchen, scheints, hat eine gute Kralle!", "tokens": ["Das", "Weib\u00b7chen", ",", "scheints", ",", "hat", "ei\u00b7ne", "gu\u00b7te", "Kral\u00b7le", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "$,", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wer soll hier richten, wenn ein Heiliger gar", "tokens": ["Wer", "soll", "hier", "rich\u00b7ten", ",", "wenn", "ein", "Hei\u00b7li\u00b7ger", "gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "ADV", "VVINF", "$,", "KOUS", "ART", "NN", "ADV"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Bekennen mu\u00df verliebtestes Verfehlen?", "tokens": ["Be\u00b7ken\u00b7nen", "mu\u00df", "ver\u00b7lieb\u00b7tes\u00b7tes", "Ver\u00b7feh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sie kann wohl selbst nicht ihre Liebsten z\u00e4hlen,", "tokens": ["Sie", "kann", "wohl", "selbst", "nicht", "ih\u00b7re", "Liebs\u00b7ten", "z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "PTKNEG", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und niemals wird ihr dunkler Rechtsstreit klar,", "tokens": ["Und", "nie\u00b7mals", "wird", "ihr", "dunk\u00b7ler", "Rechts\u00b7streit", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wolln wir zu Richtern nicht die Weiber w\u00e4hlen.\u00ab", "tokens": ["Wolln", "wir", "zu", "Rich\u00b7tern", "nicht", "die", "Wei\u00b7ber", "w\u00e4h\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "PTKNEG", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.55": {"line.1": {"text": "Der Punkt war kritisch. Denn die Weiber, jetzt", "tokens": ["Der", "Punkt", "war", "kri\u00b7tisch", ".", "Denn", "die", "Wei\u00b7ber", ",", "jetzt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "KON", "ART", "NN", "$,", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Durch Eifersucht und \u2013 Tugend aufgehetzt,", "tokens": ["Durch", "Ei\u00b7fer\u00b7sucht", "und", "\u2013", "Tu\u00b7gend", "auf\u00b7ge\u00b7hetzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "$(", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Begannen in der Tat, ein wenig Lust zu sp\u00fcren,", "tokens": ["Be\u00b7gan\u00b7nen", "in", "der", "Tat", ",", "ein", "we\u00b7nig", "Lust", "zu", "sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "ART", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Weibe, das (gewi\u00df mit Hexerei) bet\u00f6rt", "tokens": ["Dem", "Wei\u00b7be", ",", "das", "(", "ge\u00b7wi\u00df", "mit", "He\u00b7xe\u00b7rei", ")", "be\u00b7t\u00f6rt"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PRELS", "$(", "ADV", "APPR", "NN", "$(", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So viele M\u00e4nner schon, was sich geh\u00f6rt", "tokens": ["So", "vie\u00b7le", "M\u00e4n\u00b7ner", "schon", ",", "was", "sich", "ge\u00b7h\u00f6rt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "ADV", "$,", "PRELS", "PRF", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "F\u00fcr eine brave Frau, scharf zu Gem\u00fct zu f\u00fchren.", "tokens": ["F\u00fcr", "ei\u00b7ne", "bra\u00b7ve", "Frau", ",", "scharf", "zu", "Ge\u00b7m\u00fct", "zu", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "VVFIN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.56": {"line.1": {"text": "Schon rief, Xanthippen gleich, ein krasses Weib: \u00bbSo setzt", "tokens": ["Schon", "rief", ",", "Xan\u00b7thip\u00b7pen", "gleich", ",", "ein", "kras\u00b7ses", "Weib", ":", "\u00bb", "So", "setzt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "NN", "ADV", "$,", "ART", "ADJA", "NN", "$.", "$(", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ihr doch die Daumenschrauben an!", "tokens": ["Ihr", "doch", "die", "Dau\u00b7men\u00b7schrau\u00b7ben", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will doch sehn, ob nicht mit meinem Mann", "tokens": ["Ich", "will", "doch", "sehn", ",", "ob", "nicht", "mit", "mei\u00b7nem", "Mann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$,", "KOUS", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Sie auch das heilige Eherecht verletzt", "tokens": ["Sie", "auch", "das", "hei\u00b7li\u00b7ge", "E\u00b7he\u00b7recht", "ver\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "So wie mit jenen hat. Und dann:", "tokens": ["So", "wie", "mit", "je\u00b7nen", "hat", ".", "Und", "dann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "PDS", "VAFIN", "$.", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ins Feuer, Feuer mit dem H\u00f6llenbraten", "tokens": ["Ins", "Feu\u00b7er", ",", "Feu\u00b7er", "mit", "dem", "H\u00f6l\u00b7len\u00b7bra\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "F\u00fcr seine schauderhaften Freveltaten,", "tokens": ["F\u00fcr", "sei\u00b7ne", "schau\u00b7der\u00b7haf\u00b7ten", "Fre\u00b7vel\u00b7ta\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df er nicht weiter Unheil stiften kann!\u00ab", "tokens": ["Da\u00df", "er", "nicht", "wei\u00b7ter", "Un\u00b7heil", "stif\u00b7ten", "kann", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "NN", "VVFIN", "VMFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.57": {"line.1": {"text": "So, Mann und Weib verschiedentlich bewegt,", "tokens": ["So", ",", "Mann", "und", "Weib", "ver\u00b7schie\u00b7dent\u00b7lich", "be\u00b7wegt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "KON", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "War unseres dicken Kadi Tribunal", "tokens": ["War", "un\u00b7se\u00b7res", "di\u00b7cken", "Ka\u00b7di", "Tri\u00b7bu\u00b7nal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NE", "NE"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dem Meere gleich, vom Nordwind \u00fcberfegt.", "tokens": ["Dem", "Mee\u00b7re", "gleich", ",", "vom", "Nord\u00b7wind", "\u00fc\u00b7ber\u00b7fegt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Nur sie, die den Spektakel hat erregt,", "tokens": ["Nur", "sie", ",", "die", "den", "Spek\u00b7ta\u00b7kel", "hat", "er\u00b7regt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PRELS", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Steht ruhig da, als w\u00e4r es ihr egal,", "tokens": ["Steht", "ru\u00b7hig", "da", ",", "als", "w\u00e4r", "es", "ihr", "e\u00b7gal", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "$,", "KOKOM", "VAFIN", "PPER", "PPER", "ADV", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Woher, wohin die wilde Woge schl\u00e4gt.", "tokens": ["Wo\u00b7her", ",", "wo\u00b7hin", "die", "wil\u00b7de", "Wo\u00b7ge", "schl\u00e4gt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sie h\u00fcllt ihr Haupt in ihren seidnen Schal", "tokens": ["Sie", "h\u00fcllt", "ihr", "Haupt", "in", "ih\u00b7ren", "seid\u00b7nen", "Schal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und hat sich, unerh\u00f6rt! dem Eremiten,", "tokens": ["Und", "hat", "sich", ",", "un\u00b7er\u00b7h\u00f6rt", "!", "dem", "E\u00b7re\u00b7mi\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PRF", "$,", "ADJD", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Als wollte schlafen sie, jetzt, hier, inmitten", "tokens": ["Als", "woll\u00b7te", "schla\u00b7fen", "sie", ",", "jetzt", ",", "hier", ",", "in\u00b7mit\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "VMFIN", "VVFIN", "PPER", "$,", "ADV", "$,", "ADV", "$,", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Des tollen Tobens, an die Brust gelegt.", "tokens": ["Des", "tol\u00b7len", "To\u00b7bens", ",", "an", "die", "Brust", "ge\u00b7legt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.58": {"line.1": {"text": "Und sieh, wie sie die Augen schlo\u00df,", "tokens": ["Und", "sieh", ",", "wie", "sie", "die", "Au\u00b7gen", "schlo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da ward es still mit einemmal,", "tokens": ["Da", "ward", "es", "still", "mit", "ei\u00b7nem\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "APPR", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indes vom Himmel sich ein breiter Strahl", "tokens": ["In\u00b7des", "vom", "Him\u00b7mel", "sich", "ein", "brei\u00b7ter", "Strahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von Sonnenlicht durch Wolkenspalt ergo\u00df.", "tokens": ["Von", "Son\u00b7nen\u00b7licht", "durch", "Wol\u00b7ken\u00b7spalt", "er\u00b7go\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und durch die Menge, die sich teilte, ritt,", "tokens": ["Und", "durch", "die", "Men\u00b7ge", ",", "die", "sich", "teil\u00b7te", ",", "ritt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PRELS", "PRF", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Man wu\u00dfte, ahnte nicht woher, ein greiser,", "tokens": ["Man", "wu\u00df\u00b7te", ",", "ahn\u00b7te", "nicht", "wo\u00b7her", ",", "ein", "grei\u00b7ser", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "VVFIN", "PTKNEG", "ADJD", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Doch sch\u00f6ner Mann, ein Herrscher oder Weiser,", "tokens": ["Doch", "sch\u00f6\u00b7ner", "Mann", ",", "ein", "Herr\u00b7scher", "o\u00b7der", "Wei\u00b7ser", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Gem\u00e4chlich, l\u00e4chelnd, ritt im Schritt", "tokens": ["Ge\u00b7m\u00e4ch\u00b7lich", ",", "l\u00e4\u00b7chelnd", ",", "ritt", "im", "Schritt"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "ADJD", "$,", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bis zu der Stelle, wo der Eremit", "tokens": ["Bis", "zu", "der", "Stel\u00b7le", ",", "wo", "der", "E\u00b7re\u00b7mit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Mit unserm Weibchen stand, das ruhig, tief,", "tokens": ["Mit", "un\u00b7serm", "Weib\u00b7chen", "stand", ",", "das", "ru\u00b7hig", ",", "tief", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "PRELS", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Mit vollen Kinderatemz\u00fcgen schlief", "tokens": ["Mit", "vol\u00b7len", "Kin\u00b7de\u00b7ra\u00b7tem\u00b7z\u00fc\u00b7gen", "schlief"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Und l\u00e4ngst wer wei\u00df in welchen Traums Bereichen", "tokens": ["Und", "l\u00e4ngst", "wer", "wei\u00df", "in", "wel\u00b7chen", "Traums", "Be\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PWS", "VVFIN", "APPR", "PWAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Zufrieden und zu Hause war.", "tokens": ["Zu\u00b7frie\u00b7den", "und", "zu", "Hau\u00b7se", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Hier hielt der alte w\u00fcrdevolle Mann", "tokens": ["Hier", "hielt", "der", "al\u00b7te", "w\u00fcr\u00b7de\u00b7vol\u00b7le", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Sein Reittier an", "tokens": ["Sein", "Reit\u00b7tier", "an"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR"], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "Und gab, so schien es, einer Dienerschar,", "tokens": ["Und", "gab", ",", "so", "schien", "es", ",", "ei\u00b7ner", "Die\u00b7ner\u00b7schar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Die, allem Volke unsichtbar,", "tokens": ["Die", ",", "al\u00b7lem", "Vol\u00b7ke", "un\u00b7sicht\u00b7bar", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PIS", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Ihn dienstbereit umgab, ein Zeichen.", "tokens": ["Ihn", "dienst\u00b7be\u00b7reit", "um\u00b7gab", ",", "ein", "Zei\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Drauf ward, von wem ist nicht zu sagen,", "tokens": ["Drauf", "ward", ",", "von", "wem", "ist", "nicht", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "$,", "APPR", "PWS", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Das Weib behutsam, da\u00df es nicht erwachte,", "tokens": ["Das", "Weib", "be\u00b7hut\u00b7sam", ",", "da\u00df", "es", "nicht", "er\u00b7wach\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Von unsichtbaren Armen sachte, sachte", "tokens": ["Von", "un\u00b7sicht\u00b7ba\u00b7ren", "Ar\u00b7men", "sach\u00b7te", ",", "sach\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Erhoben und in einer S\u00e4nfte, nein,", "tokens": ["Er\u00b7ho\u00b7ben", "und", "in", "ei\u00b7ner", "S\u00e4nf\u00b7te", ",", "nein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVPP", "KON", "APPR", "ART", "NN", "$,", "PTKANT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Es war ja keine da, doch wars der Schein,", "tokens": ["Es", "war", "ja", "kei\u00b7ne", "da", ",", "doch", "wars", "der", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADV", "$,", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Als l\u00e4gs in einer S\u00e4nfte, still davongetragen.", "tokens": ["Als", "l\u00e4gs", "in", "ei\u00b7ner", "S\u00e4nf\u00b7te", ",", "still", "da\u00b7von\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.59": {"line.1": {"text": "Und ruhig ritt der Alte hinterdrein.", "tokens": ["Und", "ru\u00b7hig", "ritt", "der", "Al\u00b7te", "hin\u00b7ter\u00b7drein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.60": {"line.1": {"text": "Lautlos, als w\u00e4rs mit einmal stumm,", "tokens": ["Laut\u00b7los", ",", "als", "w\u00e4rs", "mit", "ein\u00b7mal", "stumm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOKOM", "VAFIN", "APPR", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das eben noch so laute, auf Gehei\u00df", "tokens": ["Das", "e\u00b7ben", "noch", "so", "lau\u00b7te", ",", "auf", "Ge\u00b7hei\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "ADV", "ADV", "ADV", "VVFIN", "$,", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Allahs geworden, schritt das Publikum,", "tokens": ["Al\u00b7lahs", "ge\u00b7wor\u00b7den", ",", "schritt", "das", "Pub\u00b7li\u00b7kum", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VAPP", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Voran die immer noch verliebten Achte,", "tokens": ["Vo\u00b7ran", "die", "im\u00b7mer", "noch", "ver\u00b7lieb\u00b7ten", "Ach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Zum Zug geordnet gleichfalls hinterher,", "tokens": ["Zum", "Zug", "ge\u00b7ord\u00b7net", "gleich\u00b7falls", "hin\u00b7ter\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Als ob die Schwebende ein zaubrischer Magnet,", "tokens": ["Als", "ob", "die", "Schwe\u00b7ben\u00b7de", "ein", "zaub\u00b7ri\u00b7scher", "Mag\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+---+--+-", "measure": "dactylic.di.plus"}, "line.7": {"text": "Das ganze Tribunal ein Zauberkreis", "tokens": ["Das", "gan\u00b7ze", "Tri\u00b7bu\u00b7nal", "ein", "Zau\u00b7ber\u00b7kreis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und jeder einzelne ein Mensch nicht mehr,", "tokens": ["Und", "je\u00b7der", "ein\u00b7zel\u00b7ne", "ein", "Mensch", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "ART", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Nein, eine willenlose Puppe w\u00e4r,", "tokens": ["Nein", ",", "ei\u00b7ne", "wil\u00b7len\u00b7lo\u00b7se", "Pup\u00b7pe", "w\u00e4r", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Von unsichtbarer Hand bewegt, gedreht.", "tokens": ["Von", "un\u00b7sicht\u00b7ba\u00b7rer", "Hand", "be\u00b7wegt", ",", "ge\u00b7dreht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Und, wunderlich, ein jeder sagte sich:", "tokens": ["Und", ",", "wun\u00b7der\u00b7lich", ",", "ein", "je\u00b7der", "sag\u00b7te", "sich", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "$,", "ART", "PIS", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Nicht jene Achte oder irgendwen: nein: mich", "tokens": ["Nicht", "je\u00b7ne", "Ach\u00b7te", "o\u00b7der", "ir\u00b7gend\u00b7wen", ":", "nein", ":", "mich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PTKNEG", "PDAT", "NN", "KON", "ADV", "$.", "PTKANT", "$.", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Geht diese Sache an, \u2013 das Weib ist mein!", "tokens": ["Geht", "die\u00b7se", "Sa\u00b7che", "an", ",", "\u2013", "das", "Weib", "ist", "mein", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "PTKVZ", "$,", "$(", "ART", "NN", "VAFIN", "PPOSAT", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Die Weiber aber trollten hinterdrein", "tokens": ["Die", "Wei\u00b7ber", "a\u00b7ber", "troll\u00b7ten", "hin\u00b7ter\u00b7drein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Und f\u00fchlten nicht den allermindsten Stich", "tokens": ["Und", "f\u00fchl\u00b7ten", "nicht", "den", "al\u00b7ler\u00b7minds\u00b7ten", "Stich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Von Eifersucht. Im Gegenteil, sie schienen", "tokens": ["Von", "Ei\u00b7fer\u00b7sucht", ".", "Im", "Ge\u00b7gen\u00b7teil", ",", "sie", "schie\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$.", "APPRART", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Geschmeichelt und zufrieden wie noch nie.", "tokens": ["Ge\u00b7schmei\u00b7chelt", "und", "zu\u00b7frie\u00b7den", "wie", "noch", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "KOKOM", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "So ganz vollkommen war die Harmonie", "tokens": ["So", "ganz", "voll\u00b7kom\u00b7men", "war", "die", "Har\u00b7mo\u00b7nie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "In allen Blicken, allen Mienen,", "tokens": ["In", "al\u00b7len", "Bli\u00b7cken", ",", "al\u00b7len", "Mie\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Da\u00df diese selig stille Prozession", "tokens": ["Da\u00df", "die\u00b7se", "se\u00b7lig", "stil\u00b7le", "Pro\u00b7zes\u00b7si\u00b7on"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "ADJD", "ADJA", "NN"], "meter": "---+-+-+--+", "measure": "iambic.tetra.chol"}, "line.21": {"text": "Ein Zug von Engeln schien und nicht von Leuten,", "tokens": ["Ein", "Zug", "von", "En\u00b7geln", "schien", "und", "nicht", "von", "Leu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "KON", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Von denen doch ein jedes schon", "tokens": ["Von", "de\u00b7nen", "doch", "ein", "je\u00b7des", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "ADV", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Gebrandmarkt war von Schmerzen und von Freuden.", "tokens": ["Ge\u00b7brand\u00b7markt", "war", "von", "Schmer\u00b7zen", "und", "von", "Freu\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.61": {"line.1": {"text": "Bei Allah, ja! Es war kein Gehn: ein Wallen;", "tokens": ["Bei", "Al\u00b7lah", ",", "ja", "!", "Es", "war", "kein", "Gehn", ":", "ein", "Wal\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "$.", "PPER", "VAFIN", "PIAT", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So mancher Schuft auch unter ihnen war.", "tokens": ["So", "man\u00b7cher", "Schuft", "auch", "un\u00b7ter", "ih\u00b7nen", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADV", "APPR", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es schwebte wie durch Paradieseshallen", "tokens": ["Es", "schweb\u00b7te", "wie", "durch", "Pa\u00b7ra\u00b7die\u00b7ses\u00b7hal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem allgeliebten Weibe nach die Schar.", "tokens": ["Dem", "all\u00b7ge\u00b7lieb\u00b7ten", "Wei\u00b7be", "nach", "die", "Schar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.62": {"line.1": {"text": "Wie lang dies w\u00e4hrte, wei\u00df ich nicht zu k\u00fcnden.", "tokens": ["Wie", "lang", "dies", "w\u00e4hr\u00b7te", ",", "wei\u00df", "ich", "nicht", "zu", "k\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PDS", "VVFIN", "$,", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es hielt die Zeit, so schiens, den Atem an.", "tokens": ["Es", "hielt", "die", "Zeit", ",", "so", "schiens", ",", "den", "A\u00b7tem", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADV", "ADV", "$,", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vielleicht gabs \u00fcberhaupt in diesen Gr\u00fcnden", "tokens": ["Viel\u00b7leicht", "gabs", "\u00fc\u00b7ber\u00b7haupt", "in", "die\u00b7sen", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das gar nicht mehr, was Zeit man nennen kann,", "tokens": ["Das", "gar", "nicht", "mehr", ",", "was", "Zeit", "man", "nen\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PTKNEG", "ADV", "$,", "PWS", "NN", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dies Stundenlaufen und Zusammenr\u00fcnden", "tokens": ["Dies", "Stun\u00b7den\u00b7lau\u00b7fen", "und", "Zu\u00b7sam\u00b7men\u00b7r\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "NN", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Von War und Ist und Einst und Nun und Dann.", "tokens": ["Von", "War", "und", "Ist", "und", "Einst", "und", "Nun", "und", "Dann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "VAFIN", "KON", "NN", "KON", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.63": {"line.1": {"text": "Jedoch, mit einem Male kam ein Punkt,", "tokens": ["Je\u00b7doch", ",", "mit", "ei\u00b7nem", "Ma\u00b7le", "kam", "ein", "Punkt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und alles war in tiefste Nacht getunkt.", "tokens": ["Und", "al\u00b7les", "war", "in", "tiefs\u00b7te", "Nacht", "ge\u00b7tunkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.64": {"line.1": {"text": "Nur Eines sah man grell als wie im Traum:", "tokens": ["Nur", "Ei\u00b7nes", "sah", "man", "grell", "als", "wie", "im", "Traum", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PIS", "ADJD", "KOKOM", "KOKOM", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Auf einem H\u00fcgel einen Lorbeerbaum,", "tokens": ["Auf", "ei\u00b7nem", "H\u00fc\u00b7gel", "ei\u00b7nen", "Lor\u00b7beer\u00b7baum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Uralt und hoch und bis hinauf gespalten,", "tokens": ["Ur\u00b7alt", "und", "hoch", "und", "bis", "hin\u00b7auf", "ge\u00b7spal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "KON", "APPR", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wies sonst des \u00d6lbaums Art, und neben ihm,", "tokens": ["Wies", "sonst", "des", "\u00d6l\u00b7baums", "Art", ",", "und", "ne\u00b7ben", "ihm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "$,", "KON", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Umleuchtet wie die ewigen Seraphim", "tokens": ["Um\u00b7leuch\u00b7tet", "wie", "die", "e\u00b7wi\u00b7gen", "Se\u00b7ra\u00b7phim"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Von \u00fcberirdisch mildem Glanz, den Alten,", "tokens": ["Von", "\u00fc\u00b7be\u00b7rir\u00b7disch", "mil\u00b7dem", "Glanz", ",", "den", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Vor dem das Weib, ein wenig dunkler, stand.", "tokens": ["Vor", "dem", "das", "Weib", ",", "ein", "we\u00b7nig", "dunk\u00b7ler", ",", "stand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "$,", "ART", "PIAT", "ADJA", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Dunkler, obwohl kein F\u00e4serchen Gewand", "tokens": ["Dunk\u00b7ler", ",", "ob\u00b7wohl", "kein", "F\u00e4\u00b7ser\u00b7chen", "Ge\u00b7wand"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "PIAT", "NN", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "Den wundervollen Leib umpre\u00dfte.", "tokens": ["Den", "wun\u00b7der\u00b7vol\u00b7len", "Leib", "um\u00b7pre\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "(vor allen Leuten? Pfui! Wie kann man nur!", "tokens": ["(", "vor", "al\u00b7len", "Leu\u00b7ten", "?", "Pfui", "!", "Wie", "kann", "man", "nur", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "$.", "NN", "$.", "PWAV", "VMFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ereiferte sich stark chokiert Chodscheste,", "tokens": ["Er\u00b7ei\u00b7fer\u00b7te", "sich", "stark", "cho\u00b7kiert", "Chod\u00b7sches\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "VVFIN", "NN", "$,"], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Indem sie \u00fcber J\u00e4ckchen, H\u00f6schen, Weste", "tokens": ["In\u00b7dem", "sie", "\u00fc\u00b7ber", "J\u00e4ck\u00b7chen", ",", "H\u00f6\u00b7schen", ",", "Wes\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit schambeflissenen Fingern fuhr.)", "tokens": ["Mit", "scham\u00b7be\u00b7flis\u00b7se\u00b7nen", "Fin\u00b7gern", "fuhr", ".", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.66": {"line.1": {"text": "Es tut mir leid, da\u00df ichs nicht leugnen kann:", "tokens": ["Es", "tut", "mir", "leid", ",", "da\u00df", "ichs", "nicht", "leug\u00b7nen", "kann", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "PIS", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie hatte wirklich nicht das mindste an:", "tokens": ["Sie", "hat\u00b7te", "wirk\u00b7lich", "nicht", "das", "minds\u00b7te", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "PTKNEG", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nackt war sie, nackt; nackt wie die liebe Sonne.", "tokens": ["Nackt", "war", "sie", ",", "nackt", ";", "nackt", "wie", "die", "lie\u00b7be", "Son\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "$,", "ADJD", "$.", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und niemand, sonderbar, nicht Weib noch Mann,", "tokens": ["Und", "nie\u00b7mand", ",", "son\u00b7der\u00b7bar", ",", "nicht", "Weib", "noch", "Mann", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "ADJD", "$,", "PTKNEG", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nahm irgendwie den kleinsten Ansto\u00df dran,", "tokens": ["Nahm", "ir\u00b7gend\u00b7wie", "den", "kleins\u00b7ten", "An\u00b7sto\u00df", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Erf\u00fcllt von andachtsvoller heiliger Wonne.", "tokens": ["Er\u00b7f\u00fcllt", "von", "an\u00b7dachts\u00b7vol\u00b7ler", "hei\u00b7li\u00b7ger", "Won\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Es war so ein erhabener Moment", "tokens": ["Es", "war", "so", "ein", "er\u00b7ha\u00b7be\u00b7ner", "Mo\u00b7ment"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "(sie sind sehr selten unter Menschgebornen),", "tokens": ["(", "sie", "sind", "sehr", "sel\u00b7ten", "un\u00b7ter", "Menschge\u00b7bor\u00b7nen", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "APPR", "NN", "$(", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Wo m\u00e4nniglich nichts weiter f\u00fchlt und kennt,", "tokens": ["Wo", "m\u00e4n\u00b7nig\u00b7lich", "nichts", "wei\u00b7ter", "f\u00fchlt", "und", "kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PIS", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Als tiefe Ahnung eines l\u00e4ngst Verlornen;", "tokens": ["Als", "tie\u00b7fe", "Ah\u00b7nung", "ei\u00b7nes", "l\u00e4ngst", "Ver\u00b7lor\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ART", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Und bei Empfindungen von solcher St\u00e4rke", "tokens": ["Und", "bei", "Emp\u00b7fin\u00b7dun\u00b7gen", "von", "sol\u00b7cher", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "APPR", "PIAT", "NN"], "meter": "----+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Denkt selbst ein Schneider nicht an Schneiders Werke.", "tokens": ["Denkt", "selbst", "ein", "Schnei\u00b7der", "nicht", "an", "Schnei\u00b7ders", "Wer\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NE", "PTKNEG", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Wahrlich, ich sage dir: durch jede Brust,", "tokens": ["Wahr\u00b7lich", ",", "ich", "sa\u00b7ge", "dir", ":", "durch", "je\u00b7de", "Brust", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PPER", "$.", "APPR", "PIAT", "NN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.14": {"text": "Ein Strom, ein Sturm, fuhr ungeheure Lust", "tokens": ["Ein", "Strom", ",", "ein", "Sturm", ",", "fuhr", "un\u00b7ge\u00b7heu\u00b7re", "Lust"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Des allertiefsten innigsten Begreifens,", "tokens": ["Des", "al\u00b7ler\u00b7tiefs\u00b7ten", "in\u00b7nigs\u00b7ten", "Be\u00b7grei\u00b7fens", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Des Lebensinnersten, des Urgebots,", "tokens": ["Des", "Le\u00b7ben\u00b7sin\u00b7ners\u00b7ten", ",", "des", "Ur\u00b7ge\u00b7bots", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.17": {"text": "Des dunklen Werdens, st\u00e4tig hellen Reifens,", "tokens": ["Des", "dunk\u00b7len", "Wer\u00b7dens", ",", "st\u00e4\u00b7tig", "hel\u00b7len", "Rei\u00b7fens", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Des Zeugens und Geb\u00e4rens und des Tods.", "tokens": ["Des", "Zeu\u00b7gens", "und", "Ge\u00b7b\u00e4\u00b7rens", "und", "des", "Tods", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.67": {"line.1": {"text": "All in die Knie nieder sanken sie, wie wenn", "tokens": ["All", "in", "die", "Knie", "nie\u00b7der", "san\u00b7ken", "sie", ",", "wie", "wenn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "PTKVZ", "VVFIN", "PPER", "$,", "KOKOM", "KOUS"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Der Gottheit Odem \u00fcber ihnen bliese,", "tokens": ["Der", "Got\u00b7theit", "O\u00b7dem", "\u00fc\u00b7ber", "ih\u00b7nen", "blie\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Stirn zur Erde nieder schlugen sie, wie wenn", "tokens": ["Die", "Stirn", "zur", "Er\u00b7de", "nie\u00b7der", "schlu\u00b7gen", "sie", ",", "wie", "wenn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "PTKVZ", "VVFIN", "PPER", "$,", "KOKOM", "KOUS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Gottheit Hand sie auf die Erde stie\u00dfe,", "tokens": ["Der", "Got\u00b7theit", "Hand", "sie", "auf", "die", "Er\u00b7de", "stie\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und wieder hoch sodann die K\u00f6pfe all, wie wenn", "tokens": ["Und", "wie\u00b7der", "hoch", "so\u00b7dann", "die", "K\u00f6p\u00b7fe", "all", ",", "wie", "wenn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "ADJD", "ADV", "ART", "NN", "PIAT", "$,", "KOKOM", "KOUS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Gottheit Mund sie rief zum Paradiese.", "tokens": ["Der", "Got\u00b7theit", "Mund", "sie", "rief", "zum", "Pa\u00b7ra\u00b7die\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.68": {"line.1": {"text": "Und ihre Augen, siehe, sie ersahn", "tokens": ["Und", "ih\u00b7re", "Au\u00b7gen", ",", "sie\u00b7he", ",", "sie", "er\u00b7sahn"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "$,", "VVIMP", "$,", "PPER", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den Lorbeerbaum das nackte Weib umfahn.", "tokens": ["Den", "Lor\u00b7beer\u00b7baum", "das", "nack\u00b7te", "Weib", "um\u00b7fahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.69": {"line.1": {"text": "Es ist nicht leicht zu sagen, wie das war.", "tokens": ["Es", "ist", "nicht", "leicht", "zu", "sa\u00b7gen", ",", "wie", "das", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$,", "PWAV", "PDS", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Denn, war bisher schon manches wunderbar,", "tokens": ["Denn", ",", "war", "bis\u00b7her", "schon", "man\u00b7ches", "wun\u00b7der\u00b7bar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "ADV", "ADV", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dies, Herrin, war noch wunder-wunderbarer.", "tokens": ["Dies", ",", "Her\u00b7rin", ",", "war", "noch", "wun\u00b7der\u00b7wun\u00b7der\u00b7ba\u00b7rer", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "NN", "$,", "VAFIN", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Er nahm sie in sich auf mit Haut und Haar", "tokens": ["Er", "nahm", "sie", "in", "sich", "auf", "mit", "Haut", "und", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PRF", "APPR", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und schlo\u00df sich dann, gleich einem Schatzbewahrer;", "tokens": ["Und", "schlo\u00df", "sich", "dann", ",", "gleich", "ei\u00b7nem", "Schatz\u00b7be\u00b7wah\u00b7rer", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "$,", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verschwunden war sie in ihm ganz und gar.", "tokens": ["Ver\u00b7schwun\u00b7den", "war", "sie", "in", "ihm", "ganz", "und", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "APPR", "PPER", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der Alte aber, schien es, war der Paarer,", "tokens": ["Der", "Al\u00b7te", "a\u00b7ber", ",", "schien", "es", ",", "war", "der", "Paa\u00b7rer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Der Priester Gottes, der den Segen gibt,", "tokens": ["Der", "Pries\u00b7ter", "Got\u00b7tes", ",", "der", "den", "Se\u00b7gen", "gibt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Wenn er vereint, was sich so innig liebt,", "tokens": ["Wenn", "er", "ver\u00b7eint", ",", "was", "sich", "so", "in\u00b7nig", "liebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$,", "PRELS", "PRF", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Da\u00df es allein nicht f\u00fcrder leben mag. \u2013", "tokens": ["Da\u00df", "es", "al\u00b7lein", "nicht", "f\u00fcr\u00b7der", "le\u00b7ben", "mag.", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "Er hob die H\u00e4nde, und \u2013 es wurde Tag.", "tokens": ["Er", "hob", "die", "H\u00e4n\u00b7de", ",", "und", "\u2013", "es", "wur\u00b7de", "Tag", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KON", "$(", "PPER", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.71": {"line.1": {"text": "Zum Tage aber will kein Wunder taugen.", "tokens": ["Zum", "Ta\u00b7ge", "a\u00b7ber", "will", "kein", "Wun\u00b7der", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VMFIN", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Volk stand auf und wischte sich die Augen,", "tokens": ["Das", "Volk", "stand", "auf", "und", "wischte", "sich", "die", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "KON", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Rieb sich die Kniee, kraute sich am Ohr", "tokens": ["Rieb", "sich", "die", "Kni\u00b7ee", ",", "krau\u00b7te", "sich", "am", "Ohr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN", "$,", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und kam sich eigentlich bel\u00e4mmert vor.", "tokens": ["Und", "kam", "sich", "ei\u00b7gent\u00b7lich", "be\u00b7l\u00e4m\u00b7mert", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.72": {"line.1": {"text": "\u00bbherr Gott!\u00ab schrie auf ein Weib, \u00bbmein Mittagsessen!", "tokens": ["\u00bb", "herr", "Gott", "!", "\u00ab", "schrie", "auf", "ein", "Weib", ",", "\u00bb", "mein", "Mit\u00b7ta\u00b7gses\u00b7sen", "!"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "NN", "NN", "$.", "$(", "VVFIN", "APPR", "ART", "NN", "$,", "$(", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ganz sicher, es ist angebrannt.\u00ab", "tokens": ["Ganz", "si\u00b7cher", ",", "es", "ist", "an\u00b7ge\u00b7brannt", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "$,", "PPER", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbich hab den Schl\u00fcssel abzuziehn vergessen", "tokens": ["\u00bb", "ich", "hab", "den", "Schl\u00fcs\u00b7sel", "ab\u00b7zu\u00b7ziehn", "ver\u00b7ges\u00b7sen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "VVIZU", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von meinem Geldschrank,\u00ab rief ein Bankier.", "tokens": ["Von", "mei\u00b7nem", "Geld\u00b7schrank", ",", "\u00ab", "rief", "ein", "Ban\u00b7kier", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbgerechter Himmel! Ich mu\u00df ins Caf\u00e9!\u00ab", "tokens": ["\u00bb", "ge\u00b7rech\u00b7ter", "Him\u00b7mel", "!", "Ich", "mu\u00df", "ins", "Ca\u00b7f\u00e9", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "NN", "$.", "PPER", "VMFIN", "APPRART", "NN", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ein M\u00fc\u00dfigg\u00e4nger. Ein Schmuckfabrikant", "tokens": ["Ein", "M\u00fc\u00b7\u00dfig\u00b7g\u00e4n\u00b7ger", ".", "Ein", "Schmuck\u00b7fab\u00b7ri\u00b7kant"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$.", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Rang wild die H\u00e4nde: \u00bbMeine neuen Tressen!\u00ab", "tokens": ["Rang", "wild", "die", "H\u00e4n\u00b7de", ":", "\u00bb", "Mei\u00b7ne", "neu\u00b7en", "Tres\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADJD", "ART", "NN", "$.", "$(", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ein Priester wimmerte: \u00bbO domine!", "tokens": ["Ein", "Pries\u00b7ter", "wim\u00b7mer\u00b7te", ":", "\u00bb", "O", "do\u00b7mi\u00b7ne", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NE", "NE", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Die Vesperlitanei! Die Seelenmessen!\u00ab", "tokens": ["Die", "Ves\u00b7per\u00b7li\u00b7ta\u00b7nei", "!", "Die", "See\u00b7len\u00b7mes\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$.", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Und ein Konditor, v\u00f6llig wie besessen,", "tokens": ["Und", "ein", "Kon\u00b7di\u00b7tor", ",", "v\u00f6l\u00b7lig", "wie", "be\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ADJD", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Ri\u00df sich am Bart: \u00bbVerpappt ist mein Tragant!\u00ab", "tokens": ["Ri\u00df", "sich", "am", "Bart", ":", "\u00bb", "Ver\u00b7pappt", "ist", "mein", "Tra\u00b7gant", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PRF", "APPRART", "NN", "$.", "$(", "VVPP", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.12": {"text": "Ein tausendstimmiges Herrjemineh", "tokens": ["Ein", "tau\u00b7sends\u00b7tim\u00b7mi\u00b7ges", "Herr\u00b7je\u00b7mi\u00b7neh"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "T\u00e4t tausend Lippen kreischend sich entpressen,", "tokens": ["T\u00e4t", "tau\u00b7send", "Lip\u00b7pen", "krei\u00b7schend", "sich", "ent\u00b7pres\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "ADJD", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Und alles ist davongerannt.", "tokens": ["Und", "al\u00b7les", "ist", "da\u00b7von\u00b7ge\u00b7rannt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "Nur jener Alte blieb am Baume stehn", "tokens": ["Nur", "je\u00b7ner", "Al\u00b7te", "blieb", "am", "Bau\u00b7me", "stehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDAT", "NN", "VVFIN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und blickte l\u00e4chelnd hinterher dem Volke,", "tokens": ["Und", "blick\u00b7te", "l\u00e4\u00b7chelnd", "hin\u00b7ter\u00b7her", "dem", "Vol\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Von dem bald nichts als eine dicke Wolke", "tokens": ["Von", "dem", "bald", "nichts", "als", "ei\u00b7ne", "di\u00b7cke", "Wol\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "PIS", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von aufgetriebenem Staube war zu sehn.", "tokens": ["Von", "auf\u00b7ge\u00b7trie\u00b7be\u00b7nem", "Stau\u00b7be", "war", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.74": {"line.1": {"text": "Im Lorbeerzweigicht aber hob ein Wehn", "tokens": ["Im", "Lor\u00b7beer\u00b7zwei\u00b7gicht", "a\u00b7ber", "hob", "ein", "Wehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Als wie von Windesstimmen s\u00e4uselnd an,", "tokens": ["Als", "wie", "von", "Win\u00b7dess\u00b7tim\u00b7men", "s\u00e4u\u00b7selnd", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "APPR", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aus dem, o wie so s\u00fc\u00df, ein Zwiegesang,", "tokens": ["Aus", "dem", ",", "o", "wie", "so", "s\u00fc\u00df", ",", "ein", "Zwie\u00b7ge\u00b7sang", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "FM", "KOKOM", "ADV", "ADJD", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Adams und Evas Liebeslied, begann:", "tokens": ["A\u00b7dams", "und", "E\u00b7vas", "Lie\u00b7bes\u00b7lied", ",", "be\u00b7gann", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "KON", "NE", "NN", "$,", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Ein Sichdurchflechten, Miteinanderschweben,", "tokens": ["Ein", "Sich\u00b7durch\u00b7flech\u00b7ten", ",", "Mi\u00b7tein\u00b7an\u00b7der\u00b7schwe\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ein Insichdringen, Durcheinanderweben,", "tokens": ["Ein", "In\u00b7sich\u00b7drin\u00b7gen", ",", "Durch\u00b7ein\u00b7an\u00b7der\u00b7we\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ein Insichsterben, Insichwiederleben,", "tokens": ["Ein", "In\u00b7sichs\u00b7ter\u00b7ben", ",", "In\u00b7sich\u00b7wie\u00b7der\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ein Durcheinanderbl\u00fchn im Doppelklang.", "tokens": ["Ein", "Durch\u00b7ein\u00b7an\u00b7der\u00b7bl\u00fchn", "im", "Dop\u00b7pel\u00b7klang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.75": {"line.1": {"text": "Der Alte kreuzte \u00fcber seiner Brust", "tokens": ["Der", "Al\u00b7te", "kreuz\u00b7te", "\u00fc\u00b7ber", "sei\u00b7ner", "Brust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Andachtdurchseligt seine sch\u00f6nen H\u00e4nde", "tokens": ["An\u00b7dacht\u00b7durch\u00b7se\u00b7ligt", "sei\u00b7ne", "sch\u00f6\u00b7nen", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und murmelte: \u00bbVon Anfang bis zu Ende,", "tokens": ["Und", "mur\u00b7mel\u00b7te", ":", "\u00bb", "Von", "An\u00b7fang", "bis", "zu", "En\u00b7de", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "APPR", "NN", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "All\u00fcberall ist Gott, und Gott ist Lust.", "tokens": ["Al\u00b7l\u00fc\u00b7be\u00b7rall", "ist", "Gott", ",", "und", "Gott", "ist", "Lust", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$,", "KON", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Gepriesen sei die Welt! Die Welt ist recht.", "tokens": ["Ge\u00b7prie\u00b7sen", "sei", "die", "Welt", "!", "Die", "Welt", "ist", "recht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Kein Str\u00e4hnchen Irrtum geht durch das Geflecht", "tokens": ["Kein", "Str\u00e4hn\u00b7chen", "Irr\u00b7tum", "geht", "durch", "das", "Ge\u00b7flecht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "NE", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Des Lebensteppichs, der die Tempelw\u00e4nde", "tokens": ["Des", "Le\u00b7bens\u00b7tep\u00b7pichs", ",", "der", "die", "Tem\u00b7pel\u00b7w\u00e4n\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Des urvollkommnen Alls bespannt,", "tokens": ["Des", "ur\u00b7voll\u00b7komm\u00b7nen", "Alls", "be\u00b7spannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und wer es auch im Traume nur erkannt,", "tokens": ["Und", "wer", "es", "auch", "im", "Trau\u00b7me", "nur", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Einmal im Traume nur und unbewu\u00dft:", "tokens": ["Ein\u00b7mal", "im", "Trau\u00b7me", "nur", "und", "un\u00b7be\u00b7wu\u00dft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADV", "KON", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.11": {"text": "Er ist voll Gott und ewiglich gerecht.", "tokens": ["Er", "ist", "voll", "Gott", "und", "e\u00b7wig\u00b7lich", "ge\u00b7recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "NN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.76": {"line.1": {"text": "Was sahen sie, die jetzt davongerannt sind", "tokens": ["Was", "sa\u00b7hen", "sie", ",", "die", "jetzt", "da\u00b7von\u00b7ge\u00b7rannt", "sind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PRELS", "ADV", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und wieder nun ins Enge eingebannt sind? \u2013:", "tokens": ["Und", "wie\u00b7der", "nun", "ins", "En\u00b7ge", "ein\u00b7ge\u00b7bannt", "sind", "?", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "ADV", "APPRART", "NN", "VVPP", "VAFIN", "$.", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ins Feuer sahn sie und ins Herz der Welt.", "tokens": ["Ins", "Feu\u00b7er", "sahn", "sie", "und", "ins", "Herz", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "KON", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Allahs Augapfel sahen sie: das Weib,", "tokens": ["Al\u00b7lahs", "Aug\u00b7ap\u00b7fel", "sa\u00b7hen", "sie", ":", "das", "Weib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$.", "ART", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ein P\u00fcppchen erst, geschnitzt zum Zeitvertreib,", "tokens": ["Ein", "P\u00fcpp\u00b7chen", "erst", ",", "ge\u00b7schnitzt", "zum", "Zeit\u00b7ver\u00b7treib", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und dann der Sinn des Seins, der alles h\u00e4lt:", "tokens": ["Und", "dann", "der", "Sinn", "des", "Seins", ",", "der", "al\u00b7les", "h\u00e4lt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Natur und Liebe, Weg zur Ewigkeit", "tokens": ["Na\u00b7tur", "und", "Lie\u00b7be", ",", "Weg", "zur", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Aus eines Augenblicks Vergessenheit, \u2013", "tokens": ["Aus", "ei\u00b7nes", "Au\u00b7gen\u00b7blicks", "Ver\u00b7ges\u00b7sen\u00b7heit", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ein Nichts und Alles, \u2013 wie es euch gef\u00e4llt.\u00ab", "tokens": ["Ein", "Nichts", "und", "Al\u00b7les", ",", "\u2013", "wie", "es", "euch", "ge\u00b7f\u00e4llt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "PIS", "$,", "$(", "PWAV", "PPER", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.77": {"line.1": {"text": "Als sich zum f\u00fcnften Male im Westen", "tokens": ["Als", "sich", "zum", "f\u00fcnf\u00b7ten", "Ma\u00b7le", "im", "Wes\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "APPRART", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Sonne verbarg vor des Mondes Schein,", "tokens": ["Die", "Son\u00b7ne", "ver\u00b7barg", "vor", "des", "Mon\u00b7des", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Bedr\u00fcckte wieder die Luft Chodschesten,", "tokens": ["Be\u00b7dr\u00fcck\u00b7te", "wie\u00b7der", "die", "Luft", "Chod\u00b7sches\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Des sch\u00f6nen Fremdlings Lust zu sein.", "tokens": ["Des", "sch\u00f6\u00b7nen", "Fremd\u00b7lings", "Lust", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sprach mit Seufzern, tief entpre\u00dften,", "tokens": ["Und", "sprach", "mit", "Seuf\u00b7zern", ",", "tief", "ent\u00b7pre\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu unserm klugen Papagein:", "tokens": ["Zu", "un\u00b7serm", "klu\u00b7gen", "Pa\u00b7pa\u00b7gein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie kannst du mich so bangen sehn!", "tokens": ["Wie", "kannst", "du", "mich", "so", "ban\u00b7gen", "sehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Grausamer Vogel, la\u00df heute mich gehn!", "tokens": ["Grau\u00b7sa\u00b7mer", "Vo\u00b7gel", ",", "la\u00df", "heu\u00b7te", "mich", "gehn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVIMP", "ADV", "PPER", "VVINF", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "Der Papagei benetzte sich", "tokens": ["Der", "Pa\u00b7pa\u00b7gei", "be\u00b7netz\u00b7te", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die dicke Zung, tat einen Strich", "tokens": ["Die", "di\u00b7cke", "Zung", ",", "tat", "ei\u00b7nen", "Strich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Mit seinem Schnabel am Gefieder,", "tokens": ["Mit", "sei\u00b7nem", "Schna\u00b7bel", "am", "Ge\u00b7fie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Hob m\u00fcd die schweren Augenlider", "tokens": ["Hob", "m\u00fcd", "die", "schwe\u00b7ren", "Au\u00b7gen\u00b7li\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und sprach, ein wenig schl\u00e4ferig:", "tokens": ["Und", "sprach", ",", "ein", "we\u00b7nig", "schl\u00e4\u00b7fe\u00b7rig", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Geh, sch\u00f6ne Frau! Beeile dich!", "tokens": ["Geh", ",", "sch\u00f6\u00b7ne", "Frau", "!", "Be\u00b7ei\u00b7le", "dich", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$.", "NN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Denn, Herrin, sieh, es kann geschehn,", "tokens": ["Denn", ",", "Her\u00b7rin", ",", "sieh", ",", "es", "kann", "ge\u00b7schehn", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "$,", "VVFIN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Dein Gatte kehrt mit einmal wieder,", "tokens": ["Dein", "Gat\u00b7te", "kehrt", "mit", "ein\u00b7mal", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und, was du dir in W\u00fcnschen baust,", "tokens": ["Und", ",", "was", "du", "dir", "in", "W\u00fcn\u00b7schen", "baust", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "PPER", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "In hei\u00dfen Sinnen lebend schaust,", "tokens": ["In", "hei\u00b7\u00dfen", "Sin\u00b7nen", "le\u00b7bend", "schaust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Wirst pl\u00f6tzlich du verschwinden sehn,", "tokens": ["Wirst", "pl\u00f6tz\u00b7lich", "du", "ver\u00b7schwin\u00b7den", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPER", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Wie jene Vier ihr Meisterst\u00fcck.", "tokens": ["Wie", "je\u00b7ne", "Vier", "ihr", "Meis\u00b7ter\u00b7st\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "CARD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Verschwunden wars, kam nie zur\u00fcck.", "tokens": ["Ver\u00b7schwun\u00b7den", "wars", ",", "kam", "nie", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.78": {"line.1": {"text": "Was denn? Was wars? Was ist verschwunden?", "tokens": ["Was", "denn", "?", "Was", "wars", "?", "Was", "ist", "ver\u00b7schwun\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$.", "PWS", "VAFIN", "$.", "PWS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Meisterst\u00fcck? Nie mehr gefunden?", "tokens": ["Ein", "Meis\u00b7ter\u00b7st\u00fcck", "?", "Nie", "mehr", "ge\u00b7fun\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Wars wirklich so ein kostbar Ding?", "tokens": ["Wars", "wirk\u00b7lich", "so", "ein", "kost\u00b7bar", "Ding", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Bild? Ein Lied? Ein Kleid? Ein Ring?", "tokens": ["Ein", "Bild", "?", "Ein", "Lied", "?", "Ein", "Kleid", "?", "Ein", "Ring", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "NN", "$.", "ART", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach, liebes, gutes Papchen, sprich!", "tokens": ["Ach", ",", "lie\u00b7bes", ",", "gu\u00b7tes", "Pap\u00b7chen", ",", "sprich", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ITJ", "$,", "ADJA", "$,", "ADJA", "NN", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.79": {"line.1": {"text": "Und Frau Chodscheste setzte sich.", "tokens": ["Und", "Frau", "Chod\u00b7sches\u00b7te", "setz\u00b7te", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NE", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.80": {"line.1": {"text": "Der Vogel kraute sich am Schopfe", "tokens": ["Der", "Vo\u00b7gel", "krau\u00b7te", "sich", "am", "Schop\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und wackelte mit seinem Kopfe", "tokens": ["Und", "wa\u00b7ckel\u00b7te", "mit", "sei\u00b7nem", "Kop\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und tat das linke Auge zu", "tokens": ["Und", "tat", "das", "lin\u00b7ke", "Au\u00b7ge", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sprach nach seiner Art, gemessen,", "tokens": ["Und", "sprach", "nach", "sei\u00b7ner", "Art", ",", "ge\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Langsam, um ja nichts zu vergessen:", "tokens": ["Lang\u00b7sam", ",", "um", "ja", "nichts", "zu", "ver\u00b7ges\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUI", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "So h\u00f6re, du!", "tokens": ["So", "h\u00f6\u00b7re", ",", "du", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Ein Goldschmied und ein Zimmermann,", "tokens": ["Ein", "Gold\u00b7schmied", "und", "ein", "Zim\u00b7mer\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die huben eine Reise an", "tokens": ["Die", "hu\u00b7ben", "ei\u00b7ne", "Rei\u00b7se", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und fanden, wie sie f\u00fcrba\u00df schritten,", "tokens": ["Und", "fan\u00b7den", ",", "wie", "sie", "f\u00fcr\u00b7ba\u00df", "schrit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Am Wege als willkommnen Dritten", "tokens": ["Am", "We\u00b7ge", "als", "will\u00b7komm\u00b7nen", "Drit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Einen alt ehrw\u00fcrdigen Eremiten,", "tokens": ["Ei\u00b7nen", "alt", "ehr\u00b7w\u00fcr\u00b7di\u00b7gen", "E\u00b7re\u00b7mi\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.12": {"text": "Und, als sie weiter pilgerierten,", "tokens": ["Und", ",", "als", "sie", "wei\u00b7ter", "pil\u00b7ge\u00b7rier\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Gleichfalls willkommen einen Vierten.", "tokens": ["Gleich\u00b7falls", "will\u00b7kom\u00b7men", "ei\u00b7nen", "Vier\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Das war ein Schneider lobesan,", "tokens": ["Das", "war", "ein", "Schnei\u00b7der", "lo\u00b7be\u00b7san", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Mit dem sie flei\u00dfig diskutierten.", "tokens": ["Mit", "dem", "sie", "flei\u00b7\u00dfig", "dis\u00b7ku\u00b7tier\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "So kam denn bald die Nacht heran.", "tokens": ["So", "kam", "denn", "bald", "die", "Nacht", "he\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Kein Baum, kein Strauch in weiter Runden:", "tokens": ["Kein", "Baum", ",", "kein", "Strauch", "in", "wei\u00b7ter", "Run\u00b7den", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Die W\u00fcste wars, in der sie stunden.", "tokens": ["Die", "W\u00fcs\u00b7te", "wars", ",", "in", "der", "sie", "stun\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "APPR", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.81": {"line.1": {"text": "\u00bbich mein, wir wolln uns schlafen legen!\u00ab", "tokens": ["\u00bb", "ich", "mein", ",", "wir", "wolln", "uns", "schla\u00b7fen", "le\u00b7gen", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "PPOSAT", "$,", "PPER", "VMFIN", "PPER", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Schneider sprach. Und \u00bbmeinetwegen\u00ab", "tokens": ["Der", "Schnei\u00b7der", "sprach", ".", "Und", "\u00bb", "mei\u00b7net\u00b7we\u00b7gen", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "KON", "$(", "ADV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erwiderte der Zimmermann.", "tokens": ["Er\u00b7wi\u00b7der\u00b7te", "der", "Zim\u00b7mer\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Der Goldschmied war auch nicht dagegen,", "tokens": ["Der", "Gold\u00b7schmied", "war", "auch", "nicht", "da\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "PAV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und, weil man zu nachtschlafner Zeit", "tokens": ["Und", ",", "weil", "man", "zu", "nacht\u00b7schlaf\u00b7ner", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PIS", "APPR", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Nichts Be\u00dfres tun, als schlafen kann,", "tokens": ["Nichts", "Be\u00df\u00b7res", "tun", ",", "als", "schla\u00b7fen", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "VVINF", "$,", "KOUS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gab auch Einsiedel seinen Segen.", "tokens": ["Gab", "auch", "Ein\u00b7sie\u00b7del", "sei\u00b7nen", "Se\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Jedoch gebot F\u00fcrsichtigkeit,", "tokens": ["Je\u00b7doch", "ge\u00b7bot", "F\u00fcr\u00b7sich\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df jeder einmal nach der Reih", "tokens": ["Da\u00df", "je\u00b7der", "ein\u00b7mal", "nach", "der", "Reih"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zur Sicherheit der Kumpanei", "tokens": ["Zur", "Si\u00b7cher\u00b7heit", "der", "Kum\u00b7pa\u00b7nei"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Gebotner Wache mu\u00dfte pflegen.", "tokens": ["Ge\u00b7bot\u00b7ner", "Wa\u00b7che", "mu\u00df\u00b7te", "pfle\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.82": {"line.1": {"text": "Den Zimmermann, als j\u00fcngsten, traf", "tokens": ["Den", "Zim\u00b7mer\u00b7mann", ",", "als", "j\u00fcng\u00b7sten", ",", "traf"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "KOUS", "ADJA", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die erste Wache. Tief in Schlaf", "tokens": ["Die", "ers\u00b7te", "Wa\u00b7che", ".", "Tief", "in", "Schlaf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ADJD", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verfielen bald die andern Drei.", "tokens": ["Ver\u00b7fie\u00b7len", "bald", "die", "an\u00b7dern", "Drei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.83": {"line.1": {"text": "Da\u00df ihm nicht auch die Lider s\u00e4nken,", "tokens": ["Da\u00df", "ihm", "nicht", "auch", "die", "Li\u00b7der", "s\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Begann im Kreise weit herum", "tokens": ["Be\u00b7gann", "im", "Krei\u00b7se", "weit", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Zimmermann den Schritt zu lenken.", "tokens": ["Der", "Zim\u00b7mer\u00b7mann", "den", "Schritt", "zu", "len\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und, siehe da, er fand ein Trumm", "tokens": ["Und", ",", "sie\u00b7he", "da", ",", "er", "fand", "ein", "Trumm"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "VVIMP", "ADV", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von einem Lorbeerbaum am Wege.", "tokens": ["Von", "ei\u00b7nem", "Lor\u00b7beer\u00b7baum", "am", "We\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbdu kommst mir recht in mein Gehege\u00ab,", "tokens": ["\u00bb", "du", "kommst", "mir", "recht", "in", "mein", "Ge\u00b7he\u00b7ge", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sprach allsogleich der Zimmermann", "tokens": ["Sprach", "all\u00b7so\u00b7gleich", "der", "Zim\u00b7mer\u00b7mann"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den sch\u00f6nen dicken Baumstamm an,", "tokens": ["Den", "sch\u00f6\u00b7nen", "di\u00b7cken", "Baum\u00b7stamm", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und nahm sein Beil und hieb ihn glatt", "tokens": ["Und", "nahm", "sein", "Beil", "und", "hieb", "ihn", "glatt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und rund und sch\u00f6n. Und, noch nicht satt", "tokens": ["Und", "rund", "und", "sch\u00f6n", ".", "Und", ",", "noch", "nicht", "satt"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD", "$.", "KON", "$,", "ADV", "PTKNEG", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Der lieben Arbeit, sachte, sachte", "tokens": ["Der", "lie\u00b7ben", "Ar\u00b7beit", ",", "sach\u00b7te", ",", "sach\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Er ein Fig\u00fcrchen daraus machte,", "tokens": ["Er", "ein", "Fi\u00b7g\u00fcr\u00b7chen", "da\u00b7raus", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Sch\u00f6ngliederig und schlank und fein,", "tokens": ["Sch\u00f6ng\u00b7lie\u00b7de\u00b7rig", "und", "schlank", "und", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "So, wie er sich das M\u00e4dchen dachte,", "tokens": ["So", ",", "wie", "er", "sich", "das", "M\u00e4d\u00b7chen", "dach\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Das einmal m\u00f6cht sein Weibchen sein.", "tokens": ["Das", "ein\u00b7mal", "m\u00f6cht", "sein", "Weib\u00b7chen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.84": {"line.1": {"text": "Drauf weckte er den Juwelier", "tokens": ["Drauf", "weck\u00b7te", "er", "den", "Ju\u00b7we\u00b7lier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sprach: \u00bbIch la\u00df Gesellschaft dir,", "tokens": ["Und", "sprach", ":", "\u00bb", "Ich", "la\u00df", "Ge\u00b7sell\u00b7schaft", "dir", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VVFIN", "NN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und zwar zur Nacht die allerbeste!\u00ab", "tokens": ["Und", "zwar", "zur", "Nacht", "die", "al\u00b7ler\u00b7bes\u00b7te", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "ADJA", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.85": {"line.1": {"text": "(hier l\u00e4chelte vergn\u00fcgt Chodscheste.)", "tokens": ["(", "hier", "l\u00e4\u00b7chel\u00b7te", "ver\u00b7gn\u00fcgt", "Chod\u00b7sches\u00b7te", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADJD", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.86": {"line.1": {"text": "Der Goldschmied sah das Dingchen an", "tokens": ["Der", "Gold\u00b7schmied", "sah", "das", "Ding\u00b7chen", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und dachte sich: \u00bbDa fehlt was dran.", "tokens": ["Und", "dach\u00b7te", "sich", ":", "\u00bb", "Da", "fehlt", "was", "dran", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "$.", "$(", "ADV", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein M\u00e4dchen ohne Kett und Ring,", "tokens": ["Ein", "M\u00e4d\u00b7chen", "oh\u00b7ne", "Kett", "und", "Ring", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ist f\u00fcrwahr ein halbes Ding.\u00ab", "tokens": ["Das", "ist", "f\u00fcr\u00b7wahr", "ein", "hal\u00b7bes", "Ding", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und t\u00e4t sogleich den zierlichen Gelenken", "tokens": ["Und", "t\u00e4t", "sog\u00b7leich", "den", "zier\u00b7li\u00b7chen", "Ge\u00b7len\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "An Fu\u00df und Hand Goldreife schenken", "tokens": ["An", "Fu\u00df", "und", "Hand", "Gold\u00b7rei\u00b7fe", "schen\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und eine Perlschnur um den Hals.", "tokens": ["Und", "ei\u00b7ne", "Perl\u00b7schnur", "um", "den", "Hals", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Brust, Stirn und Ohren ebenfalls", "tokens": ["Brust", ",", "Stirn", "und", "Oh\u00b7ren", "e\u00b7ben\u00b7falls"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bedacht er kunstreich mit Geschmeiden.", "tokens": ["Be\u00b7dacht", "er", "kuns\u00b7treich", "mit", "Ge\u00b7schmei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.87": {"line.1": {"text": "Dann tippte er den Schneidersmann", "tokens": ["Dann", "tipp\u00b7te", "er", "den", "Schnei\u00b7ders\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit leisem Finger weckend an", "tokens": ["Mit", "lei\u00b7sem", "Fin\u00b7ger", "we\u00b7ckend", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sprach: \u00bbIch la\u00df dir was zu kleiden!\u00ab", "tokens": ["Und", "sprach", ":", "\u00bb", "Ich", "la\u00df", "dir", "was", "zu", "klei\u00b7den", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbwas!?\u00ab rief der Schneider, \u00bbin der Nacht?!", "tokens": ["\u00bb", "was", "!?", "\u00ab", "rief", "der", "Schnei\u00b7der", ",", "\u00bb", "in", "der", "Nacht", "?!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "$.", "$(", "VVFIN", "ART", "NE", "$,", "$(", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In dieser leeren W\u00fcstenei?\u00ab", "tokens": ["In", "die\u00b7ser", "lee\u00b7ren", "W\u00fcs\u00b7te\u00b7nei", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dann aber: \u00bbHimmel! Welche Pracht!\u00ab", "tokens": ["Dann", "a\u00b7ber", ":", "\u00bb", "Him\u00b7mel", "!", "Wel\u00b7che", "Pracht", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "$.", "$(", "NN", "$.", "PWAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und gleich begann die Schneiderei.", "tokens": ["Und", "gleich", "be\u00b7gann", "die", "Schnei\u00b7de\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Denn, was ein rechter Schneider hei\u00dft,", "tokens": ["Denn", ",", "was", "ein", "rech\u00b7ter", "Schnei\u00b7der", "hei\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "ART", "ADJA", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Nacktheit nicht als h\u00f6chstes preist,", "tokens": ["Die", "Nackt\u00b7heit", "nicht", "als", "h\u00f6chs\u00b7tes", "preist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und wenn sie zehnmal g\u00f6ttlich sei.", "tokens": ["Und", "wenn", "sie", "zehn\u00b7mal", "g\u00f6tt\u00b7lich", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Hat also Kleiderchen gemacht", "tokens": ["Hat", "al\u00b7so", "Klei\u00b7der\u00b7chen", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Dem Weibchen so aufs allerbeste,", "tokens": ["Dem", "Weib\u00b7chen", "so", "aufs", "al\u00b7ler\u00b7bes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Da\u00df es, obwohl aus Holze, lacht", "tokens": ["Da\u00df", "es", ",", "ob\u00b7wohl", "aus", "Hol\u00b7ze", ",", "lacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "$,", "KOUS", "APPR", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "(das gleiche tat Madam Chodscheste)", "tokens": ["(", "das", "glei\u00b7che", "tat", "Ma\u00b7dam", "Chod\u00b7sches\u00b7te", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "FM", "FM", "FM", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Und selig in die W\u00fcste schaut,", "tokens": ["Und", "se\u00b7lig", "in", "die", "W\u00fcs\u00b7te", "schaut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Als w\u00e4rs lebendig eine Braut.", "tokens": ["Als", "w\u00e4rs", "le\u00b7ben\u00b7dig", "ei\u00b7ne", "Braut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.88": {"line.1": {"text": "Der Schneider sehr zufrieden war.", "tokens": ["Der", "Schnei\u00b7der", "sehr", "zu\u00b7frie\u00b7den", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zupfte Einsiedelmann am Haar", "tokens": ["Zupf\u00b7te", "Ein\u00b7sie\u00b7del\u00b7mann", "am", "Haar"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPRART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und sprach: \u00bbHochw\u00fcrden wollt geruhn,", "tokens": ["Und", "sprach", ":", "\u00bb", "Hoch\u00b7w\u00fcr\u00b7den", "wollt", "ge\u00b7ruhn", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Einen frommen Blick dorthin zu tun,", "tokens": ["Ei\u00b7nen", "from\u00b7men", "Blick", "dor\u00b7thin", "zu", "tun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Wo uns Besuch geworden ist,", "tokens": ["Wo", "uns", "Be\u00b7such", "ge\u00b7wor\u00b7den", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VAPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Erbaulich f\u00fcr Moslem und Christ.", "tokens": ["Er\u00b7bau\u00b7lich", "f\u00fcr", "Mos\u00b7lem", "und", "Christ", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NE", "KON", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Ich wei\u00df, es wird Euch nicht verdrie\u00dfen,", "tokens": ["Ich", "wei\u00df", ",", "es", "wird", "Euch", "nicht", "ver\u00b7drie\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Einer Huri Anblick zu genie\u00dfen,", "tokens": ["Ei\u00b7ner", "Hu\u00b7ri", "An\u00b7blick", "zu", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Und sicher ist, wie m\u00fcd Ihr seid:", "tokens": ["Und", "si\u00b7cher", "ist", ",", "wie", "m\u00fcd", "Ihr", "seid", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Vor Schlaf seid Ihr anjetzt gefeit!\u00ab", "tokens": ["Vor", "Schlaf", "seid", "Ihr", "an\u00b7jetzt", "ge\u00b7feit", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.89": {"line.1": {"text": "Und also wars. Einsiedelmann", "tokens": ["Und", "al\u00b7so", "wars", ".", "Ein\u00b7sie\u00b7del\u00b7mann"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "ADV", "VAFIN", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(dieweil ein Frommer sonst nichts kann)", "tokens": ["(", "die\u00b7weil", "ein", "From\u00b7mer", "sonst", "nichts", "kann", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ART", "NN", "ADV", "PIS", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hub allsogleich zu beten an", "tokens": ["Hub", "all\u00b7so\u00b7gleich", "zu", "be\u00b7ten", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PTKZU", "VVINF", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit selig hochgezogenen Braun", "tokens": ["Mit", "se\u00b7lig", "hoch\u00b7ge\u00b7zo\u00b7ge\u00b7nen", "Braun"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ADJA", "NN"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Zum Dank, da\u00df ihm das Gl\u00fcck beschert,", "tokens": ["Zum", "Dank", ",", "da\u00df", "ihm", "das", "Gl\u00fcck", "be\u00b7schert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In W\u00fcstennacht ein Weib zu schaun,", "tokens": ["In", "W\u00fcs\u00b7ten\u00b7nacht", "ein", "Weib", "zu", "schaun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "An Sch\u00f6nheit des Propheten wert.", "tokens": ["An", "Sch\u00f6n\u00b7heit", "des", "Pro\u00b7phe\u00b7ten", "wert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbnur\u00ab, sprach er zu sich selber dann,", "tokens": ["\u00bb", "nur", "\u00ab", ",", "sprach", "er", "zu", "sich", "sel\u00b7ber", "dann", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "PPER", "APPR", "PRF", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "\u00bbwie schade, da\u00df das Ding nicht lebt,", "tokens": ["\u00bb", "wie", "scha\u00b7de", ",", "da\u00df", "das", "Ding", "nicht", "lebt", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADJD", "$,", "KOUS", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der Busen sich nicht senkt und hebt,", "tokens": ["Der", "Bu\u00b7sen", "sich", "nicht", "senkt", "und", "hebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "PTKNEG", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Der volle Arm ans Herz nicht dr\u00fcckt,", "tokens": ["Der", "vol\u00b7le", "Arm", "ans", "Herz", "nicht", "dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Das dunkle Aug ins Herz nicht blickt!\u00ab", "tokens": ["Das", "dunk\u00b7le", "Aug", "ins", "Herz", "nicht", "blickt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "PTKNEG", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Und warf sich nieder auf die Erden:", "tokens": ["Und", "warf", "sich", "nie\u00b7der", "auf", "die", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKVZ", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "\u00bbbei Allah! Das mu\u00df anders werden!", "tokens": ["\u00bb", "bei", "Al\u00b7lah", "!", "Das", "mu\u00df", "an\u00b7ders", "wer\u00b7den", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$.", "PDS", "VMFIN", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Allah ist gro\u00df! Allah vermag", "tokens": ["Al\u00b7lah", "ist", "gro\u00df", "!", "Al\u00b7lah", "ver\u00b7mag"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VAFIN", "ADJD", "$.", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Aus Nacht zu machen hellen Tag;", "tokens": ["Aus", "Nacht", "zu", "ma\u00b7chen", "hel\u00b7len", "Tag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Drum wird er, wenn ein Frommer fleht", "tokens": ["Drum", "wird", "er", ",", "wenn", "ein", "From\u00b7mer", "fleht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "$,", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "(wie ich), auf herzliches Gebet", "tokens": ["(", "wie", "ich", ")", ",", "auf", "herz\u00b7li\u00b7ches", "Ge\u00b7bet"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PWAV", "PPER", "$(", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Gewi\u00df, gewi\u00df ein Wunder tun!", "tokens": ["Ge\u00b7wi\u00df", ",", "ge\u00b7wi\u00df", "ein", "Wun\u00b7der", "tun", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Allah, nicht wahr, du wirst geruhn", "tokens": ["Al\u00b7lah", ",", "nicht", "wahr", ",", "du", "wirst", "ge\u00b7ruhn"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PTKNEG", "ADJD", "$,", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Und allsogleich befehlen nun,", "tokens": ["Und", "all\u00b7so\u00b7gleich", "be\u00b7feh\u00b7len", "nun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Da\u00df Lebensodem in sie weht,", "tokens": ["Da\u00df", "Le\u00b7ben\u00b7so\u00b7dem", "in", "sie", "weht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Die viel zu sch\u00f6n ist, tot zu bleiben!", "tokens": ["Die", "viel", "zu", "sch\u00f6n", "ist", ",", "tot", "zu", "blei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKA", "ADJD", "VAFIN", "$,", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "O Allah, la\u00df sie nicht blo\u00df leiben!", "tokens": ["O", "Al\u00b7lah", ",", "la\u00df", "sie", "nicht", "blo\u00df", "lei\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVIMP", "PPER", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "La\u00df sie auch leben! Und \u2013 la\u00df sie lieben!", "tokens": ["La\u00df", "sie", "auch", "le\u00b7ben", "!", "Und", "\u2013", "la\u00df", "sie", "lie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "VVINF", "$.", "KON", "$(", "VVIMP", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.26": {"text": "Wir alle w\u00e4ren ja Staub geblieben,", "tokens": ["Wir", "al\u00b7le", "w\u00e4\u00b7ren", "ja", "Staub", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VAFIN", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "H\u00e4ttest nicht du in unsre Nasen", "tokens": ["H\u00e4t\u00b7test", "nicht", "du", "in", "uns\u00b7re", "Na\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Deines Geistes einen Hauch geblasen.\u00ab", "tokens": ["Dei\u00b7nes", "Geis\u00b7tes", "ei\u00b7nen", "Hauch", "ge\u00b7bla\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.90": {"line.1": {"text": "Und sieh: Ein Wehn kam durch die Nacht", "tokens": ["Und", "sieh", ":", "Ein", "Wehn", "kam", "durch", "die", "Nacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hat lebendig das Holz gemacht,", "tokens": ["Und", "hat", "le\u00b7ben\u00b7dig", "das", "Holz", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das augenblicks mit seinem Munde", "tokens": ["Das", "au\u00b7gen\u00b7blicks", "mit", "sei\u00b7nem", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Silberhell zu lachen begunnte,", "tokens": ["Sil\u00b7ber\u00b7hell", "zu", "la\u00b7chen", "be\u00b7gunn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Da\u00df Zimmermann, Schneider und Juwelier", "tokens": ["Da\u00df", "Zim\u00b7mer\u00b7mann", ",", "Schnei\u00b7der", "und", "Ju\u00b7we\u00b7lier"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "NE", "KON", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Aufwachten und rasten vor Liebe schier.", "tokens": ["Auf\u00b7wach\u00b7ten", "und", "ras\u00b7ten", "vor", "Lie\u00b7be", "schier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "APPR", "NN", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.91": {"line.1": {"text": "Und, da den alten Eremiten", "tokens": ["Und", ",", "da", "den", "al\u00b7ten", "E\u00b7re\u00b7mi\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Liebe gleichfalls hat geritten,", "tokens": ["Die", "Lie\u00b7be", "gleich\u00b7falls", "hat", "ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So rasten gemeinsam alle Vier.", "tokens": ["So", "ras\u00b7ten", "ge\u00b7mein\u00b7sam", "al\u00b7le", "Vier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PIAT", "CARD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.92": {"line.1": {"text": "Das Weiblein aber, was tat \u2013 Es?", "tokens": ["Das", "Weib\u00b7lein", "a\u00b7ber", ",", "was", "tat", "\u2013", "Es", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PWS", "VVFIN", "$(", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Je nun, \u2013 nichts weiter Besonderes.", "tokens": ["Je", "nun", ",", "\u2013", "nichts", "wei\u00b7ter", "Be\u00b7son\u00b7de\u00b7res", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "$(", "PIS", "ADV", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Setzte sich still auf den Bettelsack", "tokens": ["Setz\u00b7te", "sich", "still", "auf", "den", "Bet\u00b7tel\u00b7sack"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADJD", "APPR", "ART", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Des Eremiten in guter Ruh", "tokens": ["Des", "E\u00b7re\u00b7mi\u00b7ten", "in", "gu\u00b7ter", "Ruh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und schaute dem Tanze der Viere zu,", "tokens": ["Und", "schau\u00b7te", "dem", "Tan\u00b7ze", "der", "Vie\u00b7re", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Die sich traktierten wie Lumpenpack.", "tokens": ["Die", "sich", "trak\u00b7tier\u00b7ten", "wie", "Lum\u00b7pen\u00b7pack", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Mit viel Gefuchtel, Geschimpf, Geschrei", "tokens": ["Mit", "viel", "Ge\u00b7fuch\u00b7tel", ",", "Ge\u00b7schimpf", ",", "Ge\u00b7schrei"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "NN", "$,", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Rief jeder, da\u00df sie sein Eigen sei", "tokens": ["Rief", "je\u00b7der", ",", "da\u00df", "sie", "sein", "Ei\u00b7gen", "sei"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Und jeder andre ein Schubiak.", "tokens": ["Und", "je\u00b7der", "and\u00b7re", "ein", "Schu\u00b7bi\u00b7ak", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PIS", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.93": {"line.1": {"text": "\u00bbwer machte sie?\u00ab rief der Schreiner stolz:", "tokens": ["\u00bb", "wer", "mach\u00b7te", "sie", "?", "\u00ab", "rief", "der", "Schrei\u00b7ner", "stolz", ":"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$.", "$(", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbich, ich, ich, ich! Aus Lorbeerholz!\u00ab", "tokens": ["\u00bb", "ich", ",", "ich", ",", "ich", ",", "ich", "!", "Aus", "Lor\u00b7beer\u00b7holz", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "$,", "PPER", "$,", "PPER", "$,", "PPER", "$.", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.94": {"line.1": {"text": "\u00bbwer schm\u00fcckte sie?\u00ab rief der Goldschmied aus:", "tokens": ["\u00bb", "wer", "schm\u00fcck\u00b7te", "sie", "?", "\u00ab", "rief", "der", "Gold\u00b7schmied", "aus", ":"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$.", "$(", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbich! Vorher sah sie nach gar nichts aus!\u00ab", "tokens": ["\u00bb", "ich", "!", "Vor\u00b7her", "sah", "sie", "nach", "gar", "nichts", "aus", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "$.", "ADV", "VVFIN", "PPER", "APPR", "ADV", "PIS", "PTKVZ", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.95": {"line.1": {"text": "\u00bbwer zog sie an?\u00ab der Schneider schrie:", "tokens": ["\u00bb", "wer", "zog", "sie", "an", "?", "\u00ab", "der", "Schnei\u00b7der", "schrie", ":"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbich machte gesellschaftsf\u00e4hig sie!\u00ab", "tokens": ["\u00bb", "ich", "mach\u00b7te", "ge\u00b7sell\u00b7schafts\u00b7f\u00e4\u00b7hig", "sie", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADJD", "PPER", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.96": {"line.1": {"text": "\u00bbwer betete ihr das Leben an?", "tokens": ["\u00bb", "wer", "be\u00b7te\u00b7te", "ihr", "das", "Le\u00b7ben", "an", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wer? Ich!\u00ab rief der Einsiedelmann.", "tokens": ["Wer", "?", "Ich", "!", "\u00ab", "rief", "der", "Ein\u00b7sie\u00b7del\u00b7mann", "."], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "PPER", "$.", "$(", "VVFIN", "ART", "NN", "$."], "meter": "--+-+---", "measure": "anapaest.init"}}, "stanza.97": {"line.1": {"text": "Indessen trat durch Ostens Tor", "tokens": ["In\u00b7des\u00b7sen", "trat", "durch", "Os\u00b7tens", "Tor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sonne k\u00f6niglich hervor", "tokens": ["Die", "Son\u00b7ne", "k\u00f6\u00b7nig\u00b7lich", "her\u00b7vor"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und tauchte in Gold mit ihrem Schein", "tokens": ["Und", "tauch\u00b7te", "in", "Gold", "mit", "ih\u00b7rem", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die weite W\u00fcste leuchtend ein.", "tokens": ["Die", "wei\u00b7te", "W\u00fcs\u00b7te", "leuch\u00b7tend", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sieh: Es war in ihrem Strahle", "tokens": ["Und", "sieh", ":", "Es", "war", "in", "ih\u00b7rem", "Strah\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "PPER", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die W\u00fcste eine goldne Schale,", "tokens": ["Die", "W\u00fcs\u00b7te", "ei\u00b7ne", "gold\u00b7ne", "Scha\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nur ein Gef\u00e4\u00df f\u00fcr deren Pracht,", "tokens": ["Nur", "ein", "Ge\u00b7f\u00e4\u00df", "f\u00fcr", "de\u00b7ren", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PRELAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die in der wunderlichen Nacht", "tokens": ["Die", "in", "der", "wun\u00b7der\u00b7li\u00b7chen", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Viere wie im Traum gemacht.", "tokens": ["Die", "Vie\u00b7re", "wie", "im", "Traum", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "KOKOM", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.98": {"line.1": {"text": "Und auf die Kniee hin vor ihr,", "tokens": ["Und", "auf", "die", "Kni\u00b7ee", "hin", "vor", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der L\u00e4chelnden, die sich nicht r\u00fchrte,", "tokens": ["Der", "L\u00e4\u00b7cheln\u00b7den", ",", "die", "sich", "nicht", "r\u00fchr\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "St\u00fcrzten verz\u00fcckt, ber\u00fcckt die Vier,", "tokens": ["St\u00fcrz\u00b7ten", "ver\u00b7z\u00fcckt", ",", "be\u00b7r\u00fcckt", "die", "Vier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Als ob nicht Allah das Gebet geb\u00fchrte.", "tokens": ["Als", "ob", "nicht", "Al\u00b7lah", "das", "Ge\u00b7bet", "ge\u00b7b\u00fchr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PTKNEG", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.99": {"line.1": {"text": "So gottlos ist verliebter Lust Begier.", "tokens": ["So", "gott\u00b7los", "ist", "ver\u00b7lieb\u00b7ter", "Lust", "Be\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.100": {"line.1": {"text": "Doch Strafe folgt der S\u00fcnde auf dem Fu\u00df.", "tokens": ["Doch", "Stra\u00b7fe", "folgt", "der", "S\u00fcn\u00b7de", "auf", "dem", "Fu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dies, Herrin, ist nicht eines Kakadus", "tokens": ["Dies", ",", "Her\u00b7rin", ",", "ist", "nicht", "ei\u00b7nes", "Ka\u00b7ka\u00b7dus"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "$,", "NN", "$,", "VAFIN", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Private Meinung, sondern tief erwiesen.", "tokens": ["Pri\u00b7va\u00b7te", "Mei\u00b7nung", ",", "son\u00b7dern", "tief", "er\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein s\u00fc\u00df Konfekt ist s\u00fcndiges Genie\u00dfen,", "tokens": ["Ein", "s\u00fc\u00df", "Kon\u00b7fekt", "ist", "s\u00fcn\u00b7di\u00b7ges", "Ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Doch nachher kommt das bittre Myrrhenmus", "tokens": ["Doch", "nach\u00b7her", "kommt", "das", "bitt\u00b7re", "Myr\u00b7rhen\u00b7mus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Verdienter Strafe. Niemand feiert Feste", "tokens": ["Ver\u00b7dien\u00b7ter", "Stra\u00b7fe", ".", "Nie\u00b7mand", "fei\u00b7ert", "Fes\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "PIS", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Verbotenen Rausches ohne Nachgeschmack!", "tokens": ["Ver\u00b7bo\u00b7te\u00b7nen", "Rau\u00b7sches", "oh\u00b7ne", "Nach\u00b7ge\u00b7schmack", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.101": {"line.1": {"text": "(halt dich nicht auf! stirnrunzelte Chodscheste.)", "tokens": ["(", "halt", "dich", "nicht", "auf", "!", "stirn\u00b7run\u00b7zel\u00b7te", "Chod\u00b7sches\u00b7te", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$.", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.102": {"line.1": {"text": "Wie du befiehlst! Also: Das Schnick und Schnack", "tokens": ["Wie", "du", "be\u00b7fiehlst", "!", "Al\u00b7so", ":", "Das", "Schnick", "und", "Schnack"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "$.", "ADV", "$.", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Viere, die verz\u00fcckt auf ihren Knien lagen,", "tokens": ["Der", "Vie\u00b7re", ",", "die", "ver\u00b7z\u00fcckt", "auf", "ih\u00b7ren", "Kni\u00b7en", "la\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ward pl\u00f6tzlich unterbrochen. H\u00fch! und hoh!", "tokens": ["Ward", "pl\u00f6tz\u00b7lich", "un\u00b7ter\u00b7bro\u00b7chen", ".", "H\u00fch", "!", "und", "hoh", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVPP", "$.", "NN", "$.", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Erscholl und das Geknirsch von einem Reisewagen,", "tokens": ["Er\u00b7scholl", "und", "das", "Ge\u00b7knirsch", "von", "ei\u00b7nem", "Rei\u00b7se\u00b7wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auf dem, im Sande nicht prestissimo,", "tokens": ["Auf", "dem", ",", "im", "San\u00b7de", "nicht", "pres\u00b7tis\u00b7si\u00b7mo", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "APPRART", "NN", "PTKNEG", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ein reicher Mann herbeigefahren kam.", "tokens": ["Ein", "rei\u00b7cher", "Mann", "her\u00b7bei\u00b7ge\u00b7fah\u00b7ren", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wie der das Weib sah auf dem Bettelsack,", "tokens": ["Wie", "der", "das", "Weib", "sah", "auf", "dem", "Bet\u00b7tel\u00b7sack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Gabs einen Ruck ihm, und er rief: \u00bbO scham-,", "tokens": ["Gabs", "ei\u00b7nen", "Ruck", "ihm", ",", "und", "er", "rief", ":", "\u00bb", "O", "scham", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "PPER", "$,", "KON", "PPER", "VVFIN", "$.", "$(", "NE", "TRUNC", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Schamloseste von allen Frauen! Da,", "tokens": ["Scham\u00b7lo\u00b7ses\u00b7te", "von", "al\u00b7len", "Frau\u00b7en", "!", "Da", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$.", "ADV", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Auf diesem Bettelsacke sitzt sie, ha!", "tokens": ["Auf", "die\u00b7sem", "Bet\u00b7tel\u00b7sa\u00b7cke", "sitzt", "sie", ",", "ha", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "$,", "ITJ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Die ich verliebt zum Eheweibe nahm!", "tokens": ["Die", "ich", "ver\u00b7liebt", "zum", "E\u00b7he\u00b7wei\u00b7be", "nahm", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Ein sch\u00f6nes Wiedersehn, f\u00fcrwahr, Madam!", "tokens": ["Ein", "sch\u00f6\u00b7nes", "Wie\u00b7der\u00b7sehn", ",", "f\u00fcr\u00b7wahr", ",", "Ma\u00b7dam", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Mit Vieren, Vieren! ist sie durchgegangen,", "tokens": ["Mit", "Vie\u00b7ren", ",", "Vie\u00b7ren", "!", "ist", "sie", "durch\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$.", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Drum ist nicht ein-, nein viermal sie infam,", "tokens": ["Drum", "ist", "nicht", "ein", ",", "nein", "vier\u00b7mal", "sie", "in\u00b7fam", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PTKNEG", "TRUNC", "$,", "PTKANT", "ADV", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Und diese Viere m\u00fcssen schleunigst hangen!", "tokens": ["Und", "die\u00b7se", "Vie\u00b7re", "m\u00fcs\u00b7sen", "schleu\u00b7nigst", "han\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Auf! Bindet sie \u2013 und sie! Bei meinem Gram!", "tokens": ["Auf", "!", "Bin\u00b7det", "sie", "\u2013", "und", "sie", "!", "Bei", "mei\u00b7nem", "Gram", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VAFIN", "PPER", "$(", "KON", "PPER", "$.", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Ich will mein Recht und ihren Tod erlangen!\u00ab", "tokens": ["Ich", "will", "mein", "Recht", "und", "ih\u00b7ren", "Tod", "er\u00b7lan\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.103": {"line.1": {"text": "Es schrie das Weib. Die vier Verliebten schrien.", "tokens": ["Es", "schrie", "das", "Weib", ".", "Die", "vier", "Ver\u00b7lieb\u00b7ten", "schri\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "ART", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es schrie der reiche Mann und seine Knechte.", "tokens": ["Es", "schrie", "der", "rei\u00b7che", "Mann", "und", "sei\u00b7ne", "Knech\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es war, als ob ein Heer von Moslemin", "tokens": ["Es", "war", ",", "als", "ob", "ein", "Heer", "von", "Mos\u00b7le\u00b7min"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "KOUS", "ART", "NN", "APPR", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "F\u00fcr Allah schrie im heiligen Gefechte.", "tokens": ["F\u00fcr", "Al\u00b7lah", "schrie", "im", "hei\u00b7li\u00b7gen", "Ge\u00b7fech\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.104": {"line.1": {"text": "Doch, als die F\u00fcnfe dann gebunden waren,", "tokens": ["Doch", ",", "als", "die", "F\u00fcn\u00b7fe", "dann", "ge\u00b7bun\u00b7den", "wa\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ist schweigend man zu einer nahen Feste,", "tokens": ["Ist", "schwei\u00b7gend", "man", "zu", "ei\u00b7ner", "na\u00b7hen", "Fes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PIS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In ders an Galgen keineswegs gebrach,", "tokens": ["In", "ders", "an", "Gal\u00b7gen", "kei\u00b7nes\u00b7wegs", "ge\u00b7brach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPR", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Durch tiefen W\u00fcstensand langsam gefahren.", "tokens": ["Durch", "tie\u00b7fen", "W\u00fcs\u00b7ten\u00b7sand", "lang\u00b7sam", "ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.105": {"line.1": {"text": "(hier sch\u00fcttelte das sch\u00f6ne Haupt Chodscheste,", "tokens": ["(", "hier", "sch\u00fct\u00b7tel\u00b7te", "das", "sch\u00f6\u00b7ne", "Haupt", "Chod\u00b7sches\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Indessen sie im Ton der Neugier sprach:", "tokens": ["In\u00b7des\u00b7sen", "sie", "im", "Ton", "der", "Neu\u00b7gier", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wie empfing der Kommandeur die G\u00e4ste?)", "tokens": ["Und", "wie", "emp\u00b7fing", "der", "Kom\u00b7man\u00b7deur", "die", "G\u00e4s\u00b7te", "?", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWAV", "VVFIN", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.106": {"line.1": {"text": "Gleich, Herrin, gleich! Du wei\u00dft es ja: das Beste", "tokens": ["Gleich", ",", "Her\u00b7rin", ",", "gleich", "!", "Du", "wei\u00dft", "es", "ja", ":", "das", "Bes\u00b7te"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "NN", "$,", "ADV", "$.", "PPER", "VVFIN", "PPER", "ADV", "$.", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kommt bei Geschichten immer hintennach.", "tokens": ["Kommt", "bei", "Ge\u00b7schich\u00b7ten", "im\u00b7mer", "hin\u00b7ten\u00b7nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Denk dir! Der Kommandeur, kaum, da\u00df ein Blick", "tokens": ["Denk", "dir", "!", "Der", "Kom\u00b7man\u00b7deur", ",", "kaum", ",", "da\u00df", "ein", "Blick"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "$.", "ART", "NN", "$,", "ADV", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Aus seinem dunklen Aug das Weib gestreift,", "tokens": ["Aus", "sei\u00b7nem", "dunk\u00b7len", "Aug", "das", "Weib", "ge\u00b7streift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ruft aus: \u00bbDank, Allah, dir und dem Geschick!", "tokens": ["Ruft", "aus", ":", "\u00bb", "Dank", ",", "Al\u00b7lah", ",", "dir", "und", "dem", "Ge\u00b7schick", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "$(", "NN", "$,", "NN", "$,", "PPER", "KON", "ART", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Da ist sie, sie, die scham- und treuelose,", "tokens": ["Da", "ist", "sie", ",", "sie", ",", "die", "scham", "und", "treu\u00b7e\u00b7lo\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PPER", "$,", "ART", "TRUNC", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die viel zu fr\u00fch mein Jugendhaar bereift", "tokens": ["Die", "viel", "zu", "fr\u00fch", "mein", "Ju\u00b7gend\u00b7haar", "be\u00b7reift"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PTKA", "ADJD", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Mit schneeigem Schimmer hat, die meine Rose", "tokens": ["Mit", "schne\u00b7e\u00b7i\u00b7gem", "Schim\u00b7mer", "hat", ",", "die", "mei\u00b7ne", "Ro\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Verliebt ich hie\u00df, und die ich jetzt,", "tokens": ["Ver\u00b7liebt", "ich", "hie\u00df", ",", "und", "die", "ich", "jetzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "$,", "KON", "PRELS", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da sie mein Herz zerrissen und zerfetzt,", "tokens": ["Da", "sie", "mein", "Herz", "zer\u00b7ris\u00b7sen", "und", "zer\u00b7fetzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Den Dornbusch aller Schande nenne,", "tokens": ["Den", "Dorn\u00b7busch", "al\u00b7ler", "Schan\u00b7de", "nen\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Den Dornbusch, den ich, wenn Gerechtigkeit", "tokens": ["Den", "Dorn\u00b7busch", ",", "den", "ich", ",", "wenn", "Ge\u00b7rech\u00b7tig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "$,", "KOUS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "In unserm Land noch herrscht, bei meinem Eid,", "tokens": ["In", "un\u00b7serm", "Land", "noch", "herrscht", ",", "bei", "mei\u00b7nem", "Eid", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVPP", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Samt dem Gestr\u00fcpp, das ihn umgibt, verbrenne!", "tokens": ["Samt", "dem", "Ge\u00b7str\u00fcpp", ",", "das", "ihn", "um\u00b7gibt", ",", "ver\u00b7bren\u00b7ne", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.15": {"text": "Zum Kadi! Auf zum Kadi augenblicks", "tokens": ["Zum", "Ka\u00b7di", "!", "Auf", "zum", "Ka\u00b7di", "au\u00b7gen\u00b7blicks"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NE", "$.", "APPR", "APPRART", "NE", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Mit ihr und jenen, die mir hinterr\u00fccks,", "tokens": ["Mit", "ihr", "und", "je\u00b7nen", ",", "die", "mir", "hin\u00b7ter\u00b7r\u00fccks", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "PDS", "$,", "PRELS", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Die frechen Hunde, sie, mein Weib, geraubt!\u00ab", "tokens": ["Die", "fre\u00b7chen", "Hun\u00b7de", ",", "sie", ",", "mein", "Weib", ",", "ge\u00b7raubt", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPER", "$,", "PPOSAT", "NN", "$,", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Der reiche Mann reibt sich die Augen, glaubt,", "tokens": ["Der", "rei\u00b7che", "Mann", "reibt", "sich", "die", "Au\u00b7gen", ",", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Er tr\u00e4ume, ringt nach Worten, stottert, st\u00f6hnt, \u2013", "tokens": ["Er", "tr\u00e4u\u00b7me", ",", "ringt", "nach", "Wor\u00b7ten", ",", "stot\u00b7tert", ",", "st\u00f6hnt", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "APPR", "NN", "$,", "VVFIN", "$,", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Es hilft ihm nichts, man l\u00e4\u00dft ihn nicht beginnen.", "tokens": ["Es", "hilft", "ihm", "nichts", ",", "man", "l\u00e4\u00dft", "ihn", "nicht", "be\u00b7gin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Es wird die Hand, des Hanfschmucks nicht gew\u00f6hnt,", "tokens": ["Es", "wird", "die", "Hand", ",", "des", "Hanf\u00b7schmucks", "nicht", "ge\u00b7w\u00f6hnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Seilfest gefesselt, und er mu\u00df von hinnen.", "tokens": ["Seil\u00b7fest", "ge\u00b7fes\u00b7selt", ",", "und", "er", "mu\u00df", "von", "hin\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "KON", "PPER", "VMFIN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.107": {"line.1": {"text": "Und unsre Vier, nat\u00fcrlich, ebenfalls.", "tokens": ["Und", "uns\u00b7re", "Vier", ",", "na\u00b7t\u00fcr\u00b7lich", ",", "e\u00b7ben\u00b7falls", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ADV", "$,", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbzum Kadi! Wehe! Wehe unserm Hals!\u00ab", "tokens": ["\u00bb", "zum", "Ka\u00b7di", "!", "We\u00b7he", "!", "We\u00b7he", "un\u00b7serm", "Hals", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPRART", "NE", "$.", "NN", "$.", "NN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.108": {"line.1": {"text": "Nur das Madamchen bleibt ganz still und la\u00df;", "tokens": ["Nur", "das", "Ma\u00b7dam\u00b7chen", "bleibt", "ganz", "still", "und", "la\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ADV", "ADJD", "KON", "VVIMP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie hat sogar, obgleich auch sie gebunden", "tokens": ["Sie", "hat", "so\u00b7gar", ",", "ob\u00b7gleich", "auch", "sie", "ge\u00b7bun\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "$,", "KOUS", "ADV", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und an den Kn\u00f6chelchen leicht aufgeschunden", "tokens": ["Und", "an", "den", "Kn\u00f6\u00b7chel\u00b7chen", "leicht", "auf\u00b7ge\u00b7schun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von diesen dummen Stricken war, etwas", "tokens": ["Von", "die\u00b7sen", "dum\u00b7men", "Stri\u00b7cken", "war", ",", "et\u00b7was"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VAFIN", "$,", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wie kitzelnde Genugtuung empfunden:", "tokens": ["Wie", "kit\u00b7zeln\u00b7de", "Ge\u00b7nug\u00b7tu\u00b7ung", "emp\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ob auch die Fessel ihr das P\u00fclschen pre\u00dfte,", "tokens": ["Ob", "auch", "die", "Fes\u00b7sel", "ihr", "das", "P\u00fcl\u00b7schen", "pre\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Sie f\u00fchlte sich wie V\u00f6gelchen im Neste", "tokens": ["Sie", "f\u00fchl\u00b7te", "sich", "wie", "V\u00f6\u00b7gel\u00b7chen", "im", "Nes\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "KOKOM", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Bei der sehr angenehmen Rechnung, da\u00df", "tokens": ["Bei", "der", "sehr", "an\u00b7ge\u00b7neh\u00b7men", "Rech\u00b7nung", ",", "da\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "$,", "KOUS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Sechs M\u00e4nner sich in sie verliebt in wenigen Stunden.", "tokens": ["Sechs", "M\u00e4n\u00b7ner", "sich", "in", "sie", "ver\u00b7liebt", "in", "we\u00b7ni\u00b7gen", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PRF", "APPR", "PPER", "VVPP", "APPR", "PIAT", "NN", "$."], "meter": "-+--+--+-+--+-", "measure": "amphibrach.tri.plus"}}, "stanza.109": {"line.1": {"text": "(sechs! tr\u00e4umte vor sich hin Chodscheste.)", "tokens": ["(", "sechs", "!", "tr\u00e4um\u00b7te", "vor", "sich", "hin", "Chod\u00b7sches\u00b7te", ".", ")"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "CARD", "$.", "VVFIN", "APPR", "PRF", "ADV", "NN", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.110": {"line.1": {"text": "Und nun zum Kadi denn! Hoch zu Kamele", "tokens": ["Und", "nun", "zum", "Ka\u00b7di", "denn", "!", "Hoch", "zu", "Ka\u00b7me\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NE", "KON", "$.", "ADJD", "APPR", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ritt schlanken Pa\u00dftrabs schnell der Kommandeur", "tokens": ["Ritt", "schlan\u00b7ken", "Pa\u00df\u00b7trabs", "schnell", "der", "Kom\u00b7man\u00b7deur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "NE", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Voll Rachedurst voraus, und seiner Seele", "tokens": ["Voll", "Ra\u00b7che\u00b7durst", "vo\u00b7raus", ",", "und", "sei\u00b7ner", "See\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "NN", "PTKVZ", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hinstr\u00f6mender Ergu\u00df fand huldreiches Geh\u00f6r.", "tokens": ["Hins\u00b7tr\u00f6\u00b7men\u00b7der", "Er\u00b7gu\u00df", "fand", "huld\u00b7rei\u00b7ches", "Ge\u00b7h\u00f6r", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+---+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Der Kadi sprach: \u00bbBei Gott! die Philomele,", "tokens": ["Der", "Ka\u00b7di", "sprach", ":", "\u00bb", "Bei", "Gott", "!", "die", "Phi\u00b7lo\u00b7me\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "$(", "APPR", "NN", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die dich betrogen hat, singt bald nicht mehr!", "tokens": ["Die", "dich", "be\u00b7tro\u00b7gen", "hat", ",", "singt", "bald", "nicht", "mehr", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "$,", "VVFIN", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Denn Ehebruch hei\u00dft Kapitalverbrechen,", "tokens": ["Denn", "E\u00b7heb\u00b7ruch", "hei\u00dft", "Ka\u00b7pi\u00b7tal\u00b7ver\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und nur der Tod kann den Geh\u00f6rnten r\u00e4chen!\u00ab", "tokens": ["Und", "nur", "der", "Tod", "kann", "den", "Ge\u00b7h\u00f6rn\u00b7ten", "r\u00e4\u00b7chen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VMFIN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.111": {"line.1": {"text": "Du siehst, der Kadi war ein strenger Mann.", "tokens": ["Du", "siehst", ",", "der", "Ka\u00b7di", "war", "ein", "stren\u00b7ger", "Mann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NE", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "(sind alle so? frug bang Chodscheste an.)", "tokens": ["(", "sind", "al\u00b7le", "so", "?", "frug", "bang", "Chod\u00b7sches\u00b7te", "an", ".", ")"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PIS", "ADV", "$.", "VVFIN", "ADJD", "NN", "PTKVZ", "$.", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.112": {"line.1": {"text": "Der unsere wars, d.h. \u2013 nun, du wirst sehn.", "tokens": ["Der", "un\u00b7se\u00b7re", "wars", ",", "d.", "h.", "\u2013", "nun", ",", "du", "wirst", "sehn", "."], "token_info": ["word", "word", "word", "punct", "abbreviation", "abbreviation", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "$,", "PDS", "VVFIN", "$(", "ADV", "$,", "PPER", "VAFIN", "VVINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er war schon alt. Schwer wurde ihm das Gehn,", "tokens": ["Er", "war", "schon", "alt", ".", "Schwer", "wur\u00b7de", "ihm", "das", "Gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$.", "ADJD", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und reichlich fettbeladen war er auch.", "tokens": ["Und", "reich\u00b7lich", "fett\u00b7be\u00b7la\u00b7den", "war", "er", "auch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Nie sah die Welt so ungeheuren Bauch,", "tokens": ["Nie", "sah", "die", "Welt", "so", "un\u00b7ge\u00b7heu\u00b7ren", "Bauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und niemals, glaub ich, sieht sie mehr", "tokens": ["Und", "nie\u00b7mals", ",", "glaub", "ich", ",", "sieht", "sie", "mehr"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An einem Menschen soviel Schmeer.", "tokens": ["An", "ei\u00b7nem", "Men\u00b7schen", "so\u00b7viel", "Schmeer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Augen aber waren winzig,", "tokens": ["Die", "Au\u00b7gen", "a\u00b7ber", "wa\u00b7ren", "win\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der Blick war bl\u00f6de, m\u00fcde, blinzig,", "tokens": ["Der", "Blick", "war", "bl\u00f6\u00b7de", ",", "m\u00fc\u00b7de", ",", "blin\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJA", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die Haut war, ja, wie sag ich gleich,", "tokens": ["Die", "Haut", "war", ",", "ja", ",", "wie", "sag", "ich", "gleich", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PTKANT", "$,", "PWAV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nicht seiden- oder sammetweich:", "tokens": ["Nicht", "sei\u00b7den", "o\u00b7der", "sam\u00b7met\u00b7weich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "TRUNC", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Mehr lederartig und dabei", "tokens": ["Mehr", "le\u00b7der\u00b7ar\u00b7tig", "und", "da\u00b7bei"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "PAV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Nicht ganz von kleinen Flecken frei,", "tokens": ["Nicht", "ganz", "von", "klei\u00b7nen", "Fle\u00b7cken", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die ab und an ein wenig n\u00e4\u00dften.", "tokens": ["Die", "ab", "und", "an", "ein", "we\u00b7nig", "n\u00e4\u00df\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKVZ", "KON", "APPR", "ART", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.113": {"line.1": {"text": "(hier wurde nicht ganz wohl Chodschesten.)", "tokens": ["(", "hier", "wur\u00b7de", "nicht", "ganz", "wohl", "Chod\u00b7sches\u00b7ten", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "PTKNEG", "ADV", "ADV", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.114": {"line.1": {"text": "Kurz: reizend war er eben nicht.", "tokens": ["Kurz", ":", "rei\u00b7zend", "war", "er", "e\u00b7ben", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "VVPP", "VAFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch, wer sucht Reize bei Gericht?", "tokens": ["Doch", ",", "wer", "sucht", "Rei\u00b7ze", "bei", "Ge\u00b7richt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "VVFIN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch hatte er, das mu\u00df der Neid ihm lassen,", "tokens": ["Auch", "hat\u00b7te", "er", ",", "das", "mu\u00df", "der", "Neid", "ihm", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PDS", "VMFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Kunst der niederschmetternden Grimassen,", "tokens": ["Die", "Kunst", "der", "nie\u00b7der\u00b7schmet\u00b7tern\u00b7den", "Gri\u00b7mas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--++-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Vor denen, wer mit S\u00fcndenlast", "tokens": ["Vor", "de\u00b7nen", ",", "wer", "mit", "S\u00fcn\u00b7den\u00b7last"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PRELS", "$,", "PWS", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In ihr Bereich tritt, j\u00e4h erbla\u00dft.", "tokens": ["In", "ihr", "Be\u00b7reich", "tritt", ",", "j\u00e4h", "er\u00b7bla\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So sa\u00df er da mit f\u00fcrchterlichen Mienen,", "tokens": ["So", "sa\u00df", "er", "da", "mit", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Mie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Als unsere Vier vor ihm erschienen,", "tokens": ["Als", "un\u00b7se\u00b7re", "Vier", "vor", "ihm", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Und, \u2013 na, was ist? um Gottes willen,", "tokens": ["Und", ",", "\u2013", "na", ",", "was", "ist", "?", "um", "Got\u00b7tes", "wil\u00b7len", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "$(", "ITJ", "$,", "PWS", "VAFIN", "$.", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Was ist denn los? \u2013: der Kadi schreit", "tokens": ["Was", "ist", "denn", "los", "?", "\u2013", ":", "der", "Ka\u00b7di", "schreit"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "PTKVZ", "$.", "$(", "$.", "ART", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und rei\u00dft die kleinen Augen weit,", "tokens": ["Und", "rei\u00dft", "die", "klei\u00b7nen", "Au\u00b7gen", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Unglaublich weit auf: \u00bbMeine Brillen!", "tokens": ["Un\u00b7glaub\u00b7lich", "weit", "auf", ":", "\u00bb", "Mei\u00b7ne", "Bril\u00b7len", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKVZ", "$.", "$(", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "So bringt mir doch die Brillen!\u00ab \u2013 Da, \u2013", "tokens": ["So", "bringt", "mir", "doch", "die", "Bril\u00b7len", "!", "\u00ab", "\u2013", "Da", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$.", "$(", "$(", "ADV", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Er setzt sie auf: \u2013 \u00bbBei Allah! Ja!", "tokens": ["Er", "setzt", "sie", "auf", ":", "\u2013", "\u00bb", "Bei", "Al\u00b7lah", "!", "Ja", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "$(", "APPR", "NN", "$.", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Sie ists! Sie ists! O welch Entz\u00fccken!", "tokens": ["Sie", "ists", "!", "Sie", "ists", "!", "O", "welch", "Ent\u00b7z\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "PPER", "VAFIN", "$.", "NE", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Komm, la\u00df an meine Brust dich dr\u00fccken!", "tokens": ["Komm", ",", "la\u00df", "an", "mei\u00b7ne", "Brust", "dich", "dr\u00fc\u00b7cken", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVIMP", "APPR", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Hab keine Angst, ich straf dich nicht,", "tokens": ["Hab", "kei\u00b7ne", "Angst", ",", "ich", "straf", "dich", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "O du mein Mond- und Sonnenlicht!", "tokens": ["O", "du", "mein", "Mon\u00b7d", "und", "Son\u00b7nen\u00b7licht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPOSAT", "TRUNC", "KON", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.19": {"text": "Was du auch tatst, es ist verziehn,", "tokens": ["Was", "du", "auch", "tatst", ",", "es", "ist", "ver\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Willst du nur nicht noch einmal fliehn!", "tokens": ["Willst", "du", "nur", "nicht", "noch", "ein\u00b7mal", "fliehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PTKNEG", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Mein Zuckersch\u00f6tchen! Mein Perlenschneckchen!", "tokens": ["Mein", "Zu\u00b7cker\u00b7sch\u00f6t\u00b7chen", "!", "Mein", "Per\u00b7len\u00b7schneck\u00b7chen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Mein Sammetf\u00fc\u00dfchen! Mein Honigweckchen!", "tokens": ["Mein", "Sam\u00b7met\u00b7f\u00fc\u00df\u00b7chen", "!", "Mein", "Ho\u00b7nig\u00b7weck\u00b7chen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "O komm, sei gut, o komm zu mir,", "tokens": ["O", "komm", ",", "sei", "gut", ",", "o", "komm", "zu", "mir", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VAFIN", "ADJD", "$,", "FM", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Mein Seligkeitenelixier!", "tokens": ["Mein", "Se\u00b7lig\u00b7kei\u00b7ten\u00b7e\u00b7li\u00b7xier", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Was du verlangst, ich will dir alles schenken,", "tokens": ["Was", "du", "ver\u00b7langst", ",", "ich", "will", "dir", "al\u00b7les", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Und blo\u00df die andern la\u00df ich henken!\u00ab", "tokens": ["Und", "blo\u00df", "die", "an\u00b7dern", "la\u00df", "ich", "hen\u00b7ken", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "VVIMP", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.115": {"line.1": {"text": "Bei diesen Worten des alten Kadi", "tokens": ["Bei", "die\u00b7sen", "Wor\u00b7ten", "des", "al\u00b7ten", "Ka\u00b7di"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "ART", "ADJA", "NE"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Standen bilds\u00e4ulen\u00e4hnlich da die", "tokens": ["Stan\u00b7den", "bild\u00b7s\u00e4u\u00b7le\u00b7n\u00e4hn\u00b7lich", "da", "die"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "ADV", "ART"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "M\u00e4nnlichen Personen dieser Geschichte.", "tokens": ["M\u00e4nn\u00b7li\u00b7chen", "Per\u00b7so\u00b7nen", "die\u00b7ser", "Ge\u00b7schich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PDAT", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Doch auf des Weibes sch\u00f6nem Gesichte", "tokens": ["Doch", "auf", "des", "Wei\u00b7bes", "sch\u00f6\u00b7nem", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "War immer das gleiche L\u00e4cheln zu sehn", "tokens": ["War", "im\u00b7mer", "das", "glei\u00b7che", "L\u00e4\u00b7cheln", "zu", "sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und nicht ", "tokens": ["Und", "nicht"], "token_info": ["word", "word"], "pos": ["KON", "PTKNEG"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Es schien, was alles auch passierte,", "tokens": ["Es", "schien", ",", "was", "al\u00b7les", "auch", "pas\u00b7sier\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das holde D\u00e4mchen fand es blo\u00df scharmant,", "tokens": ["Das", "hol\u00b7de", "D\u00e4m\u00b7chen", "fand", "es", "blo\u00df", "schar\u00b7mant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Da\u00df jeder Mann f\u00fcr sich sie reklamierte.", "tokens": ["Da\u00df", "je\u00b7der", "Mann", "f\u00fcr", "sich", "sie", "re\u00b7kla\u00b7mier\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "APPR", "PRF", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Die ganze Welt schien ihr ein Zuckerkant,", "tokens": ["Die", "gan\u00b7ze", "Welt", "schien", "ihr", "ein", "Zu\u00b7cker\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Den sie mit L\u00e4cheln schnabulierte,", "tokens": ["Den", "sie", "mit", "L\u00e4\u00b7cheln", "schna\u00b7bu\u00b7lier\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Im S\u00fc\u00dfigkeitenknabbern h\u00f6chst gewandt.", "tokens": ["Im", "S\u00fc\u00b7\u00dfig\u00b7kei\u00b7ten\u00b7knab\u00b7bern", "h\u00f6chst", "ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.116": {"line.1": {"text": "Sie tat, als w\u00e4r sie zum Vergn\u00fcgen hier.", "tokens": ["Sie", "tat", ",", "als", "w\u00e4r", "sie", "zum", "Ver\u00b7gn\u00fc\u00b7gen", "hier", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOKOM", "VAFIN", "PPER", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sogar der Kadi machte ihr Pl\u00e4sier.", "tokens": ["So\u00b7gar", "der", "Ka\u00b7di", "mach\u00b7te", "ihr", "Pl\u00e4\u00b7sier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.117": {"line.1": {"text": "Die andern aber, als das starre Staunen", "tokens": ["Die", "an\u00b7dern", "a\u00b7ber", ",", "als", "das", "star\u00b7re", "Stau\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADV", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vor\u00fcber war, emp\u00f6rten sich gewaltig", "tokens": ["Vor\u00b7\u00fc\u00b7ber", "war", ",", "em\u00b7p\u00f6r\u00b7ten", "sich", "ge\u00b7wal\u00b7tig"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$,", "VVFIN", "PRF", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und \u00e4u\u00dferten mit Worten mannigfaltig,", "tokens": ["Und", "\u00e4u\u00b7\u00dfer\u00b7ten", "mit", "Wor\u00b7ten", "man\u00b7nig\u00b7fal\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch mehr mit Br\u00fcllen, als mit leisem Raunen,", "tokens": ["Doch", "mehr", "mit", "Br\u00fcl\u00b7len", ",", "als", "mit", "lei\u00b7sem", "Rau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "$,", "KOUS", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie seien nicht im mindesten gesonnen,", "tokens": ["Sie", "sei\u00b7en", "nicht", "im", "min\u00b7des\u00b7ten", "ge\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "APPRART", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Beim Fest der richterlichen Liebeswonnen", "tokens": ["Beim", "Fest", "der", "rich\u00b7ter\u00b7li\u00b7chen", "Lie\u00b7bes\u00b7won\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Als Fahnenschmuck am Galgenstamm zu dienen.", "tokens": ["Als", "Fah\u00b7nen\u00b7schmuck", "am", "Gal\u00b7gen\u00b7stamm", "zu", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "\u00bbdas Weib ist mein!\u00ab rief jeglicher von ihnen,", "tokens": ["\u00bb", "das", "Weib", "ist", "mein", "!", "\u00ab", "rief", "jeg\u00b7li\u00b7cher", "von", "ih\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PPOSAT", "$.", "$(", "VVFIN", "PIAT", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbund der Herr Kadi ist jetzt selbst Partei.\u00ab", "tokens": ["\u00bb", "und", "der", "Herr", "Ka\u00b7di", "ist", "jetzt", "selbst", "Par\u00b7tei", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "ART", "NN", "NE", "VAFIN", "ADV", "ADV", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.118": {"line.1": {"text": "Es war ein Armefuchteln, ein Geschrei,", "tokens": ["Es", "war", "ein", "Ar\u00b7me\u00b7fuch\u00b7teln", ",", "ein", "Ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein F\u00e4usteballen, H\u00e4lserecken, Toben,", "tokens": ["Ein", "F\u00e4us\u00b7te\u00b7bal\u00b7len", ",", "H\u00e4l\u00b7ser\u00b7e\u00b7cken", ",", "To\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df selbst die Seligen im Himmel oben", "tokens": ["Da\u00df", "selbst", "die", "Se\u00b7li\u00b7gen", "im", "Him\u00b7mel", "o\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sich wolkennieder b\u00fcckten, was denn sei;", "tokens": ["Sich", "wol\u00b7ken\u00b7nie\u00b7der", "b\u00fcck\u00b7ten", ",", "was", "denn", "sei", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVFIN", "$,", "PRELS", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und alles Volk, aus K\u00fcchen, Kellern, Koben,", "tokens": ["Und", "al\u00b7les", "Volk", ",", "aus", "K\u00fc\u00b7chen", ",", "Kel\u00b7lern", ",", "Ko\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wer sich nur regen konnte, kam herbei;", "tokens": ["Wer", "sich", "nur", "re\u00b7gen", "konn\u00b7te", ",", "kam", "her\u00b7bei", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADV", "ADJA", "VMFIN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sogar die Koransch\u00fcler kriegten frei", "tokens": ["So\u00b7gar", "die", "Ko\u00b7ran\u00b7sch\u00fc\u00b7ler", "krieg\u00b7ten", "frei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und hatten einen Grund ", "tokens": ["Und", "hat\u00b7ten", "ei\u00b7nen", "Grund"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.119": {"line.1": {"text": "So gro\u00df war das Getrubel und Geschw\u00e4rme,", "tokens": ["So", "gro\u00df", "war", "das", "Ge\u00b7tru\u00b7bel", "und", "Ge\u00b7schw\u00e4r\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So ungeheuer war des Volks Gel\u00e4rme,", "tokens": ["So", "un\u00b7ge\u00b7heu\u00b7er", "war", "des", "Volks", "Ge\u00b7l\u00e4r\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df selbst ein Dschogi, der nun schon ein Jahr,", "tokens": ["Da\u00df", "selbst", "ein", "Dscho\u00b7gi", ",", "der", "nun", "schon", "ein", "Jahr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NE", "$,", "PRELS", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "And\u00e4chtig, aller Weltgedanken bar,", "tokens": ["An\u00b7d\u00e4ch\u00b7tig", ",", "al\u00b7ler", "Welt\u00b7ge\u00b7dan\u00b7ken", "bar", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Verz\u00fcckt auf einer hohen S\u00e4ule Knauf", "tokens": ["Ver\u00b7z\u00fcckt", "auf", "ei\u00b7ner", "ho\u00b7hen", "S\u00e4u\u00b7le", "Knauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Gleich einem \u00d6lbaumstrunk gestanden war,", "tokens": ["Gleich", "ei\u00b7nem", "\u00d6l\u00b7baum\u00b7strunk", "ge\u00b7stan\u00b7den", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Das Wesen merkte. Niemand sah hinauf", "tokens": ["Das", "We\u00b7sen", "merk\u00b7te", ".", "Nie\u00b7mand", "sah", "hin\u00b7auf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Zu seiner frommen Pose. Selbst die Weiberschar,", "tokens": ["Zu", "sei\u00b7ner", "from\u00b7men", "Po\u00b7se", ".", "Selbst", "die", "Wei\u00b7ber\u00b7schar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$.", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die stets bewundernd ihm zu F\u00fc\u00dfen stand", "tokens": ["Die", "stets", "be\u00b7wun\u00b7dernd", "ihm", "zu", "F\u00fc\u00b7\u00dfen", "stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVPP", "PPER", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und nie genug Bewunderungsworte fand,", "tokens": ["Und", "nie", "ge\u00b7nug", "Be\u00b7wun\u00b7de\u00b7rungs\u00b7wor\u00b7te", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+----+", "measure": "unknown.measure.tetra"}, "line.11": {"text": "Des Heiligen Kraft und Wundertum zu preisen:", "tokens": ["Des", "Hei\u00b7li\u00b7gen", "Kraft", "und", "Wun\u00b7der\u00b7tum", "zu", "prei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Selbst sie war weg, war einfach durchgebrannt.", "tokens": ["Selbst", "sie", "war", "weg", ",", "war", "ein\u00b7fach", "durch\u00b7ge\u00b7brannt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADV", "$,", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Der Dschogi kam sich vor wie altes Eisen.", "tokens": ["Der", "Dscho\u00b7gi", "kam", "sich", "vor", "wie", "al\u00b7tes", "Ei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PRF", "PTKVZ", "KOKOM", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.120": {"line.1": {"text": "\u00bbdas also ist der Welten Lauf!\u00ab", "tokens": ["\u00bb", "das", "al\u00b7so", "ist", "der", "Wel\u00b7ten", "Lauf", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "ADV", "VAFIN", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So rief er aus: \u00bbIch la\u00df mir durch die Hand", "tokens": ["So", "rief", "er", "aus", ":", "\u00bb", "Ich", "la\u00df", "mir", "durch", "die", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das ganze liebe Jahr die N\u00e4gel wachsen,", "tokens": ["Das", "gan\u00b7ze", "lie\u00b7be", "Jahr", "die", "N\u00e4\u00b7gel", "wach\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und die Bewunderung h\u00f6rt mit einmal auf,", "tokens": ["Und", "die", "Be\u00b7wun\u00b7de\u00b7rung", "h\u00f6rt", "mit", "ein\u00b7mal", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "ADV", "PTKVZ", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Macht irgendwer, Gott wei\u00df es was f\u00fcr Faxen,", "tokens": ["Macht", "ir\u00b7gend\u00b7wer", ",", "Gott", "wei\u00df", "es", "was", "f\u00fcr", "Fa\u00b7xen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "NN", "VVFIN", "PPER", "PIS", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die, darauf nehm ich Gift, gar nichts bedeuten.", "tokens": ["Die", ",", "da\u00b7rauf", "nehm", "ich", "Gift", ",", "gar", "nichts", "be\u00b7deu\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PAV", "VVFIN", "PPER", "NN", "$,", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Schlimm ist die Welt, wei\u00df Gott, die Zeit ist b\u00f6s;", "tokens": ["Schlimm", "ist", "die", "Welt", ",", "wei\u00df", "Gott", ",", "die", "Zeit", "ist", "b\u00f6s", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,", "VVFIN", "NN", "$,", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Sogar die Weiber sind irreligi\u00f6s,", "tokens": ["So\u00b7gar", "die", "Wei\u00b7ber", "sind", "ir\u00b7re\u00b7li\u00b7gi\u00b7\u00f6s", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+--++--+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Und \u00fcberhaupt, es ist nichts mit den Leuten.\u00ab", "tokens": ["Und", "\u00fc\u00b7ber\u00b7haupt", ",", "es", "ist", "nichts", "mit", "den", "Leu\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "$,", "PPER", "VAFIN", "PIS", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.121": {"line.1": {"text": "Nach diesen Worten drehte er sich um", "tokens": ["Nach", "die\u00b7sen", "Wor\u00b7ten", "dreh\u00b7te", "er", "sich", "um"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "PRF", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und hob die d\u00fcnnen H\u00e4nde (krumm,", "tokens": ["Und", "hob", "die", "d\u00fcn\u00b7nen", "H\u00e4n\u00b7de", "(", "krumm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$(", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weil wirklich sie durchwachsen waren", "tokens": ["Weil", "wirk\u00b7lich", "sie", "durch\u00b7wach\u00b7sen", "wa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von seinen N\u00e4geln) \u00fcbers Augenpaar,", "tokens": ["Von", "sei\u00b7nen", "N\u00e4\u00b7geln", ")", "\u00fc\u00b7bers", "Au\u00b7gen\u00b7paar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Zu sehn, wohin das Volk in Scharen", "tokens": ["Zu", "sehn", ",", "wo\u00b7hin", "das", "Volk", "in", "Scha\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "PWAV", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Denn eigentlich gelaufen war.", "tokens": ["Denn", "ei\u00b7gent\u00b7lich", "ge\u00b7lau\u00b7fen", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbnat\u00fcrlich! Ein Proze\u00df! Beim Kadi. Hum!", "tokens": ["\u00bb", "na\u00b7t\u00fcr\u00b7lich", "!", "Ein", "Pro\u00b7ze\u00df", "!", "Beim", "Ka\u00b7di", ".", "Hum", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADV", "$.", "ART", "NN", "$.", "APPRART", "NE", "$.", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Gewi\u00df ein sch\u00f6ner Fall! Wie dumm, wie dumm,", "tokens": ["Ge\u00b7wi\u00df", "ein", "sch\u00f6\u00b7ner", "Fall", "!", "Wie", "dumm", ",", "wie", "dumm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$.", "PWAV", "ADJD", "$,", "PWAV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Da\u00df just der g\u00f6ttlichste Jurist", "tokens": ["Da\u00df", "just", "der", "g\u00f6tt\u00b7lichs\u00b7te", "Ju\u00b7rist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Vom Zuh\u00f6rn ausgeschlossen ist!\u00ab", "tokens": ["Vom", "Zu\u00b7h\u00f6rn", "aus\u00b7ge\u00b7schlos\u00b7sen", "ist", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "(der Dschogi n\u00e4mlich, da\u00df ihrs wi\u00dft,", "tokens": ["(", "der", "Dscho\u00b7gi", "n\u00e4m\u00b7lich", ",", "da\u00df", "ihrs", "wi\u00dft", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NE", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "War fr\u00fcher, eh ihm klar geworden,", "tokens": ["War", "fr\u00fc\u00b7her", ",", "eh", "ihm", "klar", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "KOUS", "PPER", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Da\u00df nichts vergleichbar sei im ganzen Staat", "tokens": ["Da\u00df", "nichts", "ver\u00b7gleich\u00b7bar", "sei", "im", "gan\u00b7zen", "Staat"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADJD", "VAFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "An innerem Wert dem Bettelorden,", "tokens": ["An", "in\u00b7ne\u00b7rem", "Wert", "dem", "Bet\u00b7tel\u00b7or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Ein h\u00f6chst ber\u00fchmter Advokat.)", "tokens": ["Ein", "h\u00f6chst", "be\u00b7r\u00fchm\u00b7ter", "Ad\u00b7vo\u00b7kat", ".", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "\u00bbich, gerade ich! Beim Himmel: nein!", "tokens": ["\u00bb", "ich", ",", "ge\u00b7ra\u00b7de", "ich", "!", "Beim", "Him\u00b7mel", ":", "nein", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "$,", "ADV", "PPER", "$.", "APPRART", "NN", "$.", "PTKANT", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.17": {"text": "Ich will und mu\u00df zugegen sein!", "tokens": ["Ich", "will", "und", "mu\u00df", "zu\u00b7ge\u00b7gen", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KON", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Ein Fall, der alle interessiert,", "tokens": ["Ein", "Fall", ",", "der", "al\u00b7le", "in\u00b7ter\u00b7es\u00b7siert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.19": {"text": "Wird w\u00fcrdig nur durch mich pl\u00e4diert.\u00ab", "tokens": ["Wird", "w\u00fcr\u00b7dig", "nur", "durch", "mich", "pl\u00e4\u00b7diert", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "APPR", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.122": {"line.1": {"text": "Und sieh, der Heilige, der sonst nichts kannte,", "tokens": ["Und", "sieh", ",", "der", "Hei\u00b7li\u00b7ge", ",", "der", "sonst", "nichts", "kann\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "ADJA", "$,", "PRELS", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als tiefste Selbstversunkenheit,", "tokens": ["Als", "tiefs\u00b7te", "Selbst\u00b7ver\u00b7sun\u00b7ken\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der allem Leben Abgewandte", "tokens": ["Der", "al\u00b7lem", "Le\u00b7ben", "Ab\u00b7ge\u00b7wand\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIS", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In tiefster Seelentrunkenheit,", "tokens": ["In", "tiefs\u00b7ter", "See\u00b7len\u00b7trun\u00b7ken\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der alles Wollen aus sich bannte", "tokens": ["Der", "al\u00b7les", "Wol\u00b7len", "aus", "sich", "bann\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In dieser Welt Halunkenheit:", "tokens": ["In", "die\u00b7ser", "Welt", "Ha\u00b7lun\u00b7ken\u00b7heit", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der S\u00e4ulenheilige umspannte", "tokens": ["Der", "S\u00e4u\u00b7len\u00b7hei\u00b7li\u00b7ge", "um\u00b7spann\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit seinem d\u00fcrren Beinepaar", "tokens": ["Mit", "sei\u00b7nem", "d\u00fcr\u00b7ren", "Bei\u00b7ne\u00b7paar"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der S\u00e4ule Schaft \u2013 und war viel eher unten,", "tokens": ["Der", "S\u00e4u\u00b7le", "Schaft", "\u2013", "und", "war", "viel", "e\u00b7her", "un\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "KON", "VAFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Als seinem Hinterteile dienlich war.", "tokens": ["Als", "sei\u00b7nem", "Hin\u00b7ter\u00b7tei\u00b7le", "dien\u00b7lich", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Er hat nicht leicht das Gleichgewicht gefunden.", "tokens": ["Er", "hat", "nicht", "leicht", "das", "Gleich\u00b7ge\u00b7wicht", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Doch, als ers hatte, hei, wie rannte er!", "tokens": ["Doch", ",", "als", "ers", "hat\u00b7te", ",", "hei", ",", "wie", "rann\u00b7te", "er", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "VAFIN", "$,", "ITJ", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "-++--+-+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Sein Lendenschurz genierte ihn nicht sehr,", "tokens": ["Sein", "Len\u00b7den\u00b7schurz", "ge\u00b7nier\u00b7te", "ihn", "nicht", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Und, als er ihn verlor im hei\u00dfen Lauf,", "tokens": ["Und", ",", "als", "er", "ihn", "ver\u00b7lor", "im", "hei\u00b7\u00dfen", "Lauf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Hielt unsern guten Dschogi gar nichts mehr,", "tokens": ["Hielt", "un\u00b7sern", "gu\u00b7ten", "Dscho\u00b7gi", "gar", "nichts", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NE", "ADV", "PIS", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Als h\u00f6chstens seine schwache Lunge auf.", "tokens": ["Als", "h\u00f6chs\u00b7tens", "sei\u00b7ne", "schwa\u00b7che", "Lun\u00b7ge", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.123": {"line.1": {"text": "Mit Keuchen kam der heilige Mann", "tokens": ["Mit", "Keu\u00b7chen", "kam", "der", "hei\u00b7li\u00b7ge", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "In des Gerichts Get\u00fcmmel an,", "tokens": ["In", "des", "Ge\u00b7richts", "Ge\u00b7t\u00fcm\u00b7mel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und alles schrie: \u00bbPa\u00dft auf! Jetzt wird es Licht!", "tokens": ["Und", "al\u00b7les", "schrie", ":", "\u00bb", "Pa\u00dft", "auf", "!", "Jetzt", "wird", "es", "Licht", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$.", "$(", "VVIMP", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Jetzt sitzt der Heilige zu Gericht!\u00ab", "tokens": ["Jetzt", "sitzt", "der", "Hei\u00b7li\u00b7ge", "zu", "Ge\u00b7richt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "APPR", "NN", "$.", "$("], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}}, "stanza.124": {"line.1": {"text": "Und als nun Seit an Seit das Paar,", "tokens": ["Und", "als", "nun", "Seit", "an", "Seit", "das", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "NN", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Dicke und der D\u00fcnne sa\u00df,", "tokens": ["Der", "Di\u00b7cke", "und", "der", "D\u00fcn\u00b7ne", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da sah das Publikum erst klar,", "tokens": ["Da", "sah", "das", "Pub\u00b7li\u00b7kum", "erst", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie dick sein dicker Kadi war:", "tokens": ["Wie", "dick", "sein", "di\u00b7cker", "Ka\u00b7di", "war", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "ADJA", "NE", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der D\u00fcnne war des Dicken Ma\u00df.", "tokens": ["Der", "D\u00fcn\u00b7ne", "war", "des", "Di\u00b7cken", "Ma\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und zu gemeinem Gaudium", "tokens": ["Und", "zu", "ge\u00b7mei\u00b7nem", "Gau\u00b7di\u00b7um"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Rief einer aus dem Publikum:", "tokens": ["Rief", "ei\u00b7ner", "aus", "dem", "Pub\u00b7li\u00b7kum", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbseht, welch ein Spa\u00df:", "tokens": ["\u00bb", "seht", ",", "welch", "ein", "Spa\u00df", ":"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "PWAT", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Die Mutterzwiebel und das Zittergras!\u00ab", "tokens": ["Die", "Mut\u00b7ter\u00b7zwie\u00b7bel", "und", "das", "Zit\u00b7ter\u00b7gras", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.125": {"line.1": {"text": "(f\u00fcr welchen Witz der Humorist,", "tokens": ["(", "f\u00fcr", "wel\u00b7chen", "Witz", "der", "Hu\u00b7mo\u00b7rist", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PWAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der so des Ortes W\u00fcrdigkeit verga\u00df,", "tokens": ["Der", "so", "des", "Or\u00b7tes", "W\u00fcr\u00b7dig\u00b7keit", "ver\u00b7ga\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gleich krumm geschlossen worden ist.)", "tokens": ["Gleich", "krumm", "ge\u00b7schlos\u00b7sen", "wor\u00b7den", "ist", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAPP", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.126": {"line.1": {"text": "Und aller Blicke wandten sich", "tokens": ["Und", "al\u00b7ler", "Bli\u00b7cke", "wand\u00b7ten", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem heiligen Manne zu, und: \u00bbSprich!", "tokens": ["Dem", "hei\u00b7li\u00b7gen", "Man\u00b7ne", "zu", ",", "und", ":", "\u00bb", "Sprich", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,", "KON", "$.", "$(", "VVIMP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sprich Recht, du Unbefleckter!\u00ab schrien", "tokens": ["Sprich", "Recht", ",", "du", "Un\u00b7be\u00b7fleck\u00b7ter", "!", "\u00ab", "schri\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word"], "pos": ["VVIMP", "NN", "$,", "PPER", "NN", "$.", "$(", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Tausende und nannten ihn", "tokens": ["Die", "Tau\u00b7sen\u00b7de", "und", "nann\u00b7ten", "ihn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bei tausend Heiligen- und Ehrennamen.", "tokens": ["Bei", "tau\u00b7send", "Hei\u00b7li\u00b7gen", "und", "Eh\u00b7ren\u00b7na\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.127": {"line.1": {"text": "Er aber sprang in seiner Nacktheit hoch", "tokens": ["Er", "a\u00b7ber", "sprang", "in", "sei\u00b7ner", "Nackt\u00b7heit", "hoch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Vom Sitz empor und drehte sich im Kreise,", "tokens": ["Vom", "Sitz", "em\u00b7por", "und", "dreh\u00b7te", "sich", "im", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "KON", "VVFIN", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Indes den Leib er wie im Krampfe bog,", "tokens": ["In\u00b7des", "den", "Leib", "er", "wie", "im", "Kramp\u00b7fe", "bog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPER", "KOKOM", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und schrie auf f\u00fcrchterliche Weise:", "tokens": ["Und", "schrie", "auf", "f\u00fcrch\u00b7ter\u00b7li\u00b7che", "Wei\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbamen! Amen! Amen!", "tokens": ["\u00bb", "a\u00b7men", "!", "A\u00b7men", "!", "A\u00b7men", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "VVINF", "$.", "NN", "$.", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Allah illallilah!", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Allah illallilah!", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Kniet nieder! Nieder! Nieder!", "tokens": ["Kniet", "nie\u00b7der", "!", "Nie\u00b7der", "!", "Nie\u00b7der", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "ADV", "$.", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Der Vogel des Paradieses kam wieder!", "tokens": ["Der", "Vo\u00b7gel", "des", "Pa\u00b7ra\u00b7die\u00b7ses", "kam", "wie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Mein Gl\u00fcck ist wieder da!", "tokens": ["Mein", "Gl\u00fcck", "ist", "wie\u00b7der", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Und nun auf von den Knien!", "tokens": ["Und", "nun", "auf", "von", "den", "Kni\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "APPR", "ART", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "Allah illallilah!", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Tanzt, Moslemin!", "tokens": ["Tanzt", ",", "Mos\u00b7le\u00b7min", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.14": {"text": "Allah illallilah!", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Tanzet um ihn,", "tokens": ["Tan\u00b7zet", "um", "ihn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.16": {"text": "Tanzt um den Vogel mit goldnem Gefieder!", "tokens": ["Tanzt", "um", "den", "Vo\u00b7gel", "mit", "gold\u00b7nem", "Ge\u00b7fie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.17": {"text": "Viel besser ists, um ihn sich drehn,", "tokens": ["Viel", "bes\u00b7ser", "ists", ",", "um", "ihn", "sich", "drehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "KOUI", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Allah illallilah,", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Als auf dem S\u00e4ulenknauf zu stehn,", "tokens": ["Als", "auf", "dem", "S\u00e4u\u00b7len\u00b7knauf", "zu", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Allah illallilah,", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Und der Sonne ins goldne Gesicht zu sehn.", "tokens": ["Und", "der", "Son\u00b7ne", "ins", "gold\u00b7ne", "Ge\u00b7sicht", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.22": {"text": "Ich tu es niemals wieder,", "tokens": ["Ich", "tu", "es", "nie\u00b7mals", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Seitdem ", "tokens": ["Seit\u00b7dem"], "token_info": ["word"], "pos": ["PAV"], "meter": "+-", "measure": "trochaic.single"}, "line.24": {"text": "Allah illallilah,", "tokens": ["Al\u00b7lah", "il\u00b7lal\u00b7li\u00b7lah", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.25": {"text": "Und nie soll sie wieder von mir gehn!\u00ab", "tokens": ["Und", "nie", "soll", "sie", "wie\u00b7der", "von", "mir", "gehn", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.128": {"line.1": {"text": "Du siehst, o Herrin, unser Dschogi war", "tokens": ["Du", "siehst", ",", "o", "Her\u00b7rin", ",", "un\u00b7ser", "Dscho\u00b7gi", "war"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "FM", "NN", "$,", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Seit Jahresfrist ein Heiliger zwar,", "tokens": ["Seit", "Jah\u00b7res\u00b7frist", "ein", "Hei\u00b7li\u00b7ger", "zwar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Jedoch in puncto puncti just auch nicht der beste.", "tokens": ["Je\u00b7doch", "in", "punc\u00b7to", "punc\u00b7ti", "just", "auch", "nicht", "der", "bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "FM", "FM", "FM", "ADV", "PTKNEG", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.129": {"line.1": {"text": "(das d\u00fcnkt mich weiter nicht so wunderbar,", "tokens": ["(", "das", "d\u00fcnkt", "mich", "wei\u00b7ter", "nicht", "so", "wun\u00b7der\u00b7bar", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dieweil ein M\u00f6nch \u2013 ein Mann, erwiderte Chodscheste.", "tokens": ["Die\u00b7weil", "ein", "M\u00f6nch", "\u2013", "ein", "Mann", ",", "er\u00b7wi\u00b7der\u00b7te", "Chod\u00b7sches\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$(", "ART", "NN", "$,", "VVFIN", "NE", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und wieder zeigt der alte Spruch sich wahr:", "tokens": ["Und", "wie\u00b7der", "zeigt", "der", "al\u00b7te", "Spruch", "sich", "wahr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wie klein davon auch immer sein die Reste:", "tokens": ["Wie", "klein", "da\u00b7von", "auch", "im\u00b7mer", "sein", "die", "Res\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PAV", "ADV", "ADV", "PPOSAT", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Moschus und Liebe sind un-aus-treib-bar.", "tokens": ["Mo\u00b7schus", "und", "Lie\u00b7be", "sind", "un\u00b7aus\u00b7treib\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Die Tugend kann ein jeder Mensch verhehlen,", "tokens": ["Die", "Tu\u00b7gend", "kann", "ein", "je\u00b7der", "Mensch", "ver\u00b7heh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Vertreibbar ist Geruch selbst von Kamelen,", "tokens": ["Ver\u00b7treib\u00b7bar", "ist", "Ge\u00b7ruch", "selbst", "von", "Ka\u00b7me\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "NN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Doch, wo nur Liebe je und Moschus war:", "tokens": ["Doch", ",", "wo", "nur", "Lie\u00b7be", "je", "und", "Mo\u00b7schus", "war", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ADV", "NN", "ADV", "KON", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ein R\u00fcchlein bleibt in K\u00e4sten oder Seelen.)", "tokens": ["Ein", "R\u00fcch\u00b7lein", "bleibt", "in", "K\u00e4s\u00b7ten", "o\u00b7der", "See\u00b7len", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.130": {"line.1": {"text": "Sehr richtig, Herrin! Und in diesem Falle", "tokens": ["Sehr", "rich\u00b7tig", ",", "Her\u00b7rin", "!", "Und", "in", "die\u00b7sem", "Fal\u00b7le"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "NN", "$.", "KON", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Rochen den Braten auf der Stelle Alle.", "tokens": ["Ro\u00b7chen", "den", "Bra\u00b7ten", "auf", "der", "Stel\u00b7le", "Al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "ART", "NN", "PIAT", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und wie aus einem Munde schrie", "tokens": ["Und", "wie", "aus", "ei\u00b7nem", "Mun\u00b7de", "schrie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ganze Volk: \u00bbSchon wieder sie!", "tokens": ["Das", "gan\u00b7ze", "Volk", ":", "\u00bb", "Schon", "wie\u00b7der", "sie", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$(", "ADV", "ADV", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Weibchen, scheints, hat eine gute Kralle!", "tokens": ["Das", "Weib\u00b7chen", ",", "scheints", ",", "hat", "ei\u00b7ne", "gu\u00b7te", "Kral\u00b7le", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "$,", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wer soll hier richten, wenn ein Heiliger gar", "tokens": ["Wer", "soll", "hier", "rich\u00b7ten", ",", "wenn", "ein", "Hei\u00b7li\u00b7ger", "gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "ADV", "VVINF", "$,", "KOUS", "ART", "NN", "ADV"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Bekennen mu\u00df verliebtestes Verfehlen?", "tokens": ["Be\u00b7ken\u00b7nen", "mu\u00df", "ver\u00b7lieb\u00b7tes\u00b7tes", "Ver\u00b7feh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sie kann wohl selbst nicht ihre Liebsten z\u00e4hlen,", "tokens": ["Sie", "kann", "wohl", "selbst", "nicht", "ih\u00b7re", "Liebs\u00b7ten", "z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "PTKNEG", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und niemals wird ihr dunkler Rechtsstreit klar,", "tokens": ["Und", "nie\u00b7mals", "wird", "ihr", "dunk\u00b7ler", "Rechts\u00b7streit", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wolln wir zu Richtern nicht die Weiber w\u00e4hlen.\u00ab", "tokens": ["Wolln", "wir", "zu", "Rich\u00b7tern", "nicht", "die", "Wei\u00b7ber", "w\u00e4h\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "PTKNEG", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.131": {"line.1": {"text": "Der Punkt war kritisch. Denn die Weiber, jetzt", "tokens": ["Der", "Punkt", "war", "kri\u00b7tisch", ".", "Denn", "die", "Wei\u00b7ber", ",", "jetzt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "KON", "ART", "NN", "$,", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Durch Eifersucht und \u2013 Tugend aufgehetzt,", "tokens": ["Durch", "Ei\u00b7fer\u00b7sucht", "und", "\u2013", "Tu\u00b7gend", "auf\u00b7ge\u00b7hetzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "$(", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Begannen in der Tat, ein wenig Lust zu sp\u00fcren,", "tokens": ["Be\u00b7gan\u00b7nen", "in", "der", "Tat", ",", "ein", "we\u00b7nig", "Lust", "zu", "sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "ART", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Weibe, das (gewi\u00df mit Hexerei) bet\u00f6rt", "tokens": ["Dem", "Wei\u00b7be", ",", "das", "(", "ge\u00b7wi\u00df", "mit", "He\u00b7xe\u00b7rei", ")", "be\u00b7t\u00f6rt"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PRELS", "$(", "ADV", "APPR", "NN", "$(", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So viele M\u00e4nner schon, was sich geh\u00f6rt", "tokens": ["So", "vie\u00b7le", "M\u00e4n\u00b7ner", "schon", ",", "was", "sich", "ge\u00b7h\u00f6rt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "ADV", "$,", "PRELS", "PRF", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "F\u00fcr eine brave Frau, scharf zu Gem\u00fct zu f\u00fchren.", "tokens": ["F\u00fcr", "ei\u00b7ne", "bra\u00b7ve", "Frau", ",", "scharf", "zu", "Ge\u00b7m\u00fct", "zu", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "VVFIN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.132": {"line.1": {"text": "Schon rief, Xanthippen gleich, ein krasses Weib: \u00bbSo setzt", "tokens": ["Schon", "rief", ",", "Xan\u00b7thip\u00b7pen", "gleich", ",", "ein", "kras\u00b7ses", "Weib", ":", "\u00bb", "So", "setzt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "NN", "ADV", "$,", "ART", "ADJA", "NN", "$.", "$(", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ihr doch die Daumenschrauben an!", "tokens": ["Ihr", "doch", "die", "Dau\u00b7men\u00b7schrau\u00b7ben", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will doch sehn, ob nicht mit meinem Mann", "tokens": ["Ich", "will", "doch", "sehn", ",", "ob", "nicht", "mit", "mei\u00b7nem", "Mann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$,", "KOUS", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Sie auch das heilige Eherecht verletzt", "tokens": ["Sie", "auch", "das", "hei\u00b7li\u00b7ge", "E\u00b7he\u00b7recht", "ver\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "So wie mit jenen hat. Und dann:", "tokens": ["So", "wie", "mit", "je\u00b7nen", "hat", ".", "Und", "dann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "PDS", "VAFIN", "$.", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ins Feuer, Feuer mit dem H\u00f6llenbraten", "tokens": ["Ins", "Feu\u00b7er", ",", "Feu\u00b7er", "mit", "dem", "H\u00f6l\u00b7len\u00b7bra\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "F\u00fcr seine schauderhaften Freveltaten,", "tokens": ["F\u00fcr", "sei\u00b7ne", "schau\u00b7der\u00b7haf\u00b7ten", "Fre\u00b7vel\u00b7ta\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df er nicht weiter Unheil stiften kann!\u00ab", "tokens": ["Da\u00df", "er", "nicht", "wei\u00b7ter", "Un\u00b7heil", "stif\u00b7ten", "kann", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "NN", "VVFIN", "VMFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.133": {"line.1": {"text": "So, Mann und Weib verschiedentlich bewegt,", "tokens": ["So", ",", "Mann", "und", "Weib", "ver\u00b7schie\u00b7dent\u00b7lich", "be\u00b7wegt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "KON", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "War unseres dicken Kadi Tribunal", "tokens": ["War", "un\u00b7se\u00b7res", "di\u00b7cken", "Ka\u00b7di", "Tri\u00b7bu\u00b7nal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NE", "NE"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dem Meere gleich, vom Nordwind \u00fcberfegt.", "tokens": ["Dem", "Mee\u00b7re", "gleich", ",", "vom", "Nord\u00b7wind", "\u00fc\u00b7ber\u00b7fegt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Nur sie, die den Spektakel hat erregt,", "tokens": ["Nur", "sie", ",", "die", "den", "Spek\u00b7ta\u00b7kel", "hat", "er\u00b7regt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PRELS", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Steht ruhig da, als w\u00e4r es ihr egal,", "tokens": ["Steht", "ru\u00b7hig", "da", ",", "als", "w\u00e4r", "es", "ihr", "e\u00b7gal", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "$,", "KOKOM", "VAFIN", "PPER", "PPER", "ADV", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Woher, wohin die wilde Woge schl\u00e4gt.", "tokens": ["Wo\u00b7her", ",", "wo\u00b7hin", "die", "wil\u00b7de", "Wo\u00b7ge", "schl\u00e4gt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sie h\u00fcllt ihr Haupt in ihren seidnen Schal", "tokens": ["Sie", "h\u00fcllt", "ihr", "Haupt", "in", "ih\u00b7ren", "seid\u00b7nen", "Schal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und hat sich, unerh\u00f6rt! dem Eremiten,", "tokens": ["Und", "hat", "sich", ",", "un\u00b7er\u00b7h\u00f6rt", "!", "dem", "E\u00b7re\u00b7mi\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PRF", "$,", "ADJD", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Als wollte schlafen sie, jetzt, hier, inmitten", "tokens": ["Als", "woll\u00b7te", "schla\u00b7fen", "sie", ",", "jetzt", ",", "hier", ",", "in\u00b7mit\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "VMFIN", "VVFIN", "PPER", "$,", "ADV", "$,", "ADV", "$,", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Des tollen Tobens, an die Brust gelegt.", "tokens": ["Des", "tol\u00b7len", "To\u00b7bens", ",", "an", "die", "Brust", "ge\u00b7legt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.134": {"line.1": {"text": "Und sieh, wie sie die Augen schlo\u00df,", "tokens": ["Und", "sieh", ",", "wie", "sie", "die", "Au\u00b7gen", "schlo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da ward es still mit einemmal,", "tokens": ["Da", "ward", "es", "still", "mit", "ei\u00b7nem\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "APPR", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indes vom Himmel sich ein breiter Strahl", "tokens": ["In\u00b7des", "vom", "Him\u00b7mel", "sich", "ein", "brei\u00b7ter", "Strahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von Sonnenlicht durch Wolkenspalt ergo\u00df.", "tokens": ["Von", "Son\u00b7nen\u00b7licht", "durch", "Wol\u00b7ken\u00b7spalt", "er\u00b7go\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und durch die Menge, die sich teilte, ritt,", "tokens": ["Und", "durch", "die", "Men\u00b7ge", ",", "die", "sich", "teil\u00b7te", ",", "ritt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PRELS", "PRF", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Man wu\u00dfte, ahnte nicht woher, ein greiser,", "tokens": ["Man", "wu\u00df\u00b7te", ",", "ahn\u00b7te", "nicht", "wo\u00b7her", ",", "ein", "grei\u00b7ser", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "VVFIN", "PTKNEG", "ADJD", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Doch sch\u00f6ner Mann, ein Herrscher oder Weiser,", "tokens": ["Doch", "sch\u00f6\u00b7ner", "Mann", ",", "ein", "Herr\u00b7scher", "o\u00b7der", "Wei\u00b7ser", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Gem\u00e4chlich, l\u00e4chelnd, ritt im Schritt", "tokens": ["Ge\u00b7m\u00e4ch\u00b7lich", ",", "l\u00e4\u00b7chelnd", ",", "ritt", "im", "Schritt"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "ADJD", "$,", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bis zu der Stelle, wo der Eremit", "tokens": ["Bis", "zu", "der", "Stel\u00b7le", ",", "wo", "der", "E\u00b7re\u00b7mit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Mit unserm Weibchen stand, das ruhig, tief,", "tokens": ["Mit", "un\u00b7serm", "Weib\u00b7chen", "stand", ",", "das", "ru\u00b7hig", ",", "tief", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "PRELS", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Mit vollen Kinderatemz\u00fcgen schlief", "tokens": ["Mit", "vol\u00b7len", "Kin\u00b7de\u00b7ra\u00b7tem\u00b7z\u00fc\u00b7gen", "schlief"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Und l\u00e4ngst wer wei\u00df in welchen Traums Bereichen", "tokens": ["Und", "l\u00e4ngst", "wer", "wei\u00df", "in", "wel\u00b7chen", "Traums", "Be\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PWS", "VVFIN", "APPR", "PWAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Zufrieden und zu Hause war.", "tokens": ["Zu\u00b7frie\u00b7den", "und", "zu", "Hau\u00b7se", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Hier hielt der alte w\u00fcrdevolle Mann", "tokens": ["Hier", "hielt", "der", "al\u00b7te", "w\u00fcr\u00b7de\u00b7vol\u00b7le", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Sein Reittier an", "tokens": ["Sein", "Reit\u00b7tier", "an"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR"], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "Und gab, so schien es, einer Dienerschar,", "tokens": ["Und", "gab", ",", "so", "schien", "es", ",", "ei\u00b7ner", "Die\u00b7ner\u00b7schar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Die, allem Volke unsichtbar,", "tokens": ["Die", ",", "al\u00b7lem", "Vol\u00b7ke", "un\u00b7sicht\u00b7bar", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PIS", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Ihn dienstbereit umgab, ein Zeichen.", "tokens": ["Ihn", "dienst\u00b7be\u00b7reit", "um\u00b7gab", ",", "ein", "Zei\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Drauf ward, von wem ist nicht zu sagen,", "tokens": ["Drauf", "ward", ",", "von", "wem", "ist", "nicht", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "$,", "APPR", "PWS", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Das Weib behutsam, da\u00df es nicht erwachte,", "tokens": ["Das", "Weib", "be\u00b7hut\u00b7sam", ",", "da\u00df", "es", "nicht", "er\u00b7wach\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Von unsichtbaren Armen sachte, sachte", "tokens": ["Von", "un\u00b7sicht\u00b7ba\u00b7ren", "Ar\u00b7men", "sach\u00b7te", ",", "sach\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Erhoben und in einer S\u00e4nfte, nein,", "tokens": ["Er\u00b7ho\u00b7ben", "und", "in", "ei\u00b7ner", "S\u00e4nf\u00b7te", ",", "nein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVPP", "KON", "APPR", "ART", "NN", "$,", "PTKANT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Es war ja keine da, doch wars der Schein,", "tokens": ["Es", "war", "ja", "kei\u00b7ne", "da", ",", "doch", "wars", "der", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADV", "$,", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Als l\u00e4gs in einer S\u00e4nfte, still davongetragen.", "tokens": ["Als", "l\u00e4gs", "in", "ei\u00b7ner", "S\u00e4nf\u00b7te", ",", "still", "da\u00b7von\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.135": {"line.1": {"text": "Und ruhig ritt der Alte hinterdrein.", "tokens": ["Und", "ru\u00b7hig", "ritt", "der", "Al\u00b7te", "hin\u00b7ter\u00b7drein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.136": {"line.1": {"text": "Lautlos, als w\u00e4rs mit einmal stumm,", "tokens": ["Laut\u00b7los", ",", "als", "w\u00e4rs", "mit", "ein\u00b7mal", "stumm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOKOM", "VAFIN", "APPR", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das eben noch so laute, auf Gehei\u00df", "tokens": ["Das", "e\u00b7ben", "noch", "so", "lau\u00b7te", ",", "auf", "Ge\u00b7hei\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "ADV", "ADV", "ADV", "VVFIN", "$,", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Allahs geworden, schritt das Publikum,", "tokens": ["Al\u00b7lahs", "ge\u00b7wor\u00b7den", ",", "schritt", "das", "Pub\u00b7li\u00b7kum", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VAPP", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Voran die immer noch verliebten Achte,", "tokens": ["Vo\u00b7ran", "die", "im\u00b7mer", "noch", "ver\u00b7lieb\u00b7ten", "Ach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Zum Zug geordnet gleichfalls hinterher,", "tokens": ["Zum", "Zug", "ge\u00b7ord\u00b7net", "gleich\u00b7falls", "hin\u00b7ter\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Als ob die Schwebende ein zaubrischer Magnet,", "tokens": ["Als", "ob", "die", "Schwe\u00b7ben\u00b7de", "ein", "zaub\u00b7ri\u00b7scher", "Mag\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+---+--+-", "measure": "dactylic.di.plus"}, "line.7": {"text": "Das ganze Tribunal ein Zauberkreis", "tokens": ["Das", "gan\u00b7ze", "Tri\u00b7bu\u00b7nal", "ein", "Zau\u00b7ber\u00b7kreis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und jeder einzelne ein Mensch nicht mehr,", "tokens": ["Und", "je\u00b7der", "ein\u00b7zel\u00b7ne", "ein", "Mensch", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "ART", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Nein, eine willenlose Puppe w\u00e4r,", "tokens": ["Nein", ",", "ei\u00b7ne", "wil\u00b7len\u00b7lo\u00b7se", "Pup\u00b7pe", "w\u00e4r", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Von unsichtbarer Hand bewegt, gedreht.", "tokens": ["Von", "un\u00b7sicht\u00b7ba\u00b7rer", "Hand", "be\u00b7wegt", ",", "ge\u00b7dreht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Und, wunderlich, ein jeder sagte sich:", "tokens": ["Und", ",", "wun\u00b7der\u00b7lich", ",", "ein", "je\u00b7der", "sag\u00b7te", "sich", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "$,", "ART", "PIS", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Nicht jene Achte oder irgendwen: nein: mich", "tokens": ["Nicht", "je\u00b7ne", "Ach\u00b7te", "o\u00b7der", "ir\u00b7gend\u00b7wen", ":", "nein", ":", "mich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PTKNEG", "PDAT", "NN", "KON", "ADV", "$.", "PTKANT", "$.", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Geht diese Sache an, \u2013 das Weib ist mein!", "tokens": ["Geht", "die\u00b7se", "Sa\u00b7che", "an", ",", "\u2013", "das", "Weib", "ist", "mein", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "PTKVZ", "$,", "$(", "ART", "NN", "VAFIN", "PPOSAT", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Die Weiber aber trollten hinterdrein", "tokens": ["Die", "Wei\u00b7ber", "a\u00b7ber", "troll\u00b7ten", "hin\u00b7ter\u00b7drein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Und f\u00fchlten nicht den allermindsten Stich", "tokens": ["Und", "f\u00fchl\u00b7ten", "nicht", "den", "al\u00b7ler\u00b7minds\u00b7ten", "Stich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Von Eifersucht. Im Gegenteil, sie schienen", "tokens": ["Von", "Ei\u00b7fer\u00b7sucht", ".", "Im", "Ge\u00b7gen\u00b7teil", ",", "sie", "schie\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$.", "APPRART", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Geschmeichelt und zufrieden wie noch nie.", "tokens": ["Ge\u00b7schmei\u00b7chelt", "und", "zu\u00b7frie\u00b7den", "wie", "noch", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "KOKOM", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "So ganz vollkommen war die Harmonie", "tokens": ["So", "ganz", "voll\u00b7kom\u00b7men", "war", "die", "Har\u00b7mo\u00b7nie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "In allen Blicken, allen Mienen,", "tokens": ["In", "al\u00b7len", "Bli\u00b7cken", ",", "al\u00b7len", "Mie\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Da\u00df diese selig stille Prozession", "tokens": ["Da\u00df", "die\u00b7se", "se\u00b7lig", "stil\u00b7le", "Pro\u00b7zes\u00b7si\u00b7on"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "ADJD", "ADJA", "NN"], "meter": "---+-+-+--+", "measure": "iambic.tetra.chol"}, "line.21": {"text": "Ein Zug von Engeln schien und nicht von Leuten,", "tokens": ["Ein", "Zug", "von", "En\u00b7geln", "schien", "und", "nicht", "von", "Leu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "KON", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Von denen doch ein jedes schon", "tokens": ["Von", "de\u00b7nen", "doch", "ein", "je\u00b7des", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "ADV", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Gebrandmarkt war von Schmerzen und von Freuden.", "tokens": ["Ge\u00b7brand\u00b7markt", "war", "von", "Schmer\u00b7zen", "und", "von", "Freu\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.137": {"line.1": {"text": "Bei Allah, ja! Es war kein Gehn: ein Wallen;", "tokens": ["Bei", "Al\u00b7lah", ",", "ja", "!", "Es", "war", "kein", "Gehn", ":", "ein", "Wal\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "$.", "PPER", "VAFIN", "PIAT", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So mancher Schuft auch unter ihnen war.", "tokens": ["So", "man\u00b7cher", "Schuft", "auch", "un\u00b7ter", "ih\u00b7nen", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADV", "APPR", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es schwebte wie durch Paradieseshallen", "tokens": ["Es", "schweb\u00b7te", "wie", "durch", "Pa\u00b7ra\u00b7die\u00b7ses\u00b7hal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem allgeliebten Weibe nach die Schar.", "tokens": ["Dem", "all\u00b7ge\u00b7lieb\u00b7ten", "Wei\u00b7be", "nach", "die", "Schar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.138": {"line.1": {"text": "Wie lang dies w\u00e4hrte, wei\u00df ich nicht zu k\u00fcnden.", "tokens": ["Wie", "lang", "dies", "w\u00e4hr\u00b7te", ",", "wei\u00df", "ich", "nicht", "zu", "k\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PDS", "VVFIN", "$,", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es hielt die Zeit, so schiens, den Atem an.", "tokens": ["Es", "hielt", "die", "Zeit", ",", "so", "schiens", ",", "den", "A\u00b7tem", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADV", "ADV", "$,", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vielleicht gabs \u00fcberhaupt in diesen Gr\u00fcnden", "tokens": ["Viel\u00b7leicht", "gabs", "\u00fc\u00b7ber\u00b7haupt", "in", "die\u00b7sen", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das gar nicht mehr, was Zeit man nennen kann,", "tokens": ["Das", "gar", "nicht", "mehr", ",", "was", "Zeit", "man", "nen\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PTKNEG", "ADV", "$,", "PWS", "NN", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dies Stundenlaufen und Zusammenr\u00fcnden", "tokens": ["Dies", "Stun\u00b7den\u00b7lau\u00b7fen", "und", "Zu\u00b7sam\u00b7men\u00b7r\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "NN", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Von War und Ist und Einst und Nun und Dann.", "tokens": ["Von", "War", "und", "Ist", "und", "Einst", "und", "Nun", "und", "Dann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "VAFIN", "KON", "NN", "KON", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.139": {"line.1": {"text": "Jedoch, mit einem Male kam ein Punkt,", "tokens": ["Je\u00b7doch", ",", "mit", "ei\u00b7nem", "Ma\u00b7le", "kam", "ein", "Punkt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und alles war in tiefste Nacht getunkt.", "tokens": ["Und", "al\u00b7les", "war", "in", "tiefs\u00b7te", "Nacht", "ge\u00b7tunkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.140": {"line.1": {"text": "Nur Eines sah man grell als wie im Traum:", "tokens": ["Nur", "Ei\u00b7nes", "sah", "man", "grell", "als", "wie", "im", "Traum", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PIS", "ADJD", "KOKOM", "KOKOM", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Auf einem H\u00fcgel einen Lorbeerbaum,", "tokens": ["Auf", "ei\u00b7nem", "H\u00fc\u00b7gel", "ei\u00b7nen", "Lor\u00b7beer\u00b7baum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Uralt und hoch und bis hinauf gespalten,", "tokens": ["Ur\u00b7alt", "und", "hoch", "und", "bis", "hin\u00b7auf", "ge\u00b7spal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "KON", "APPR", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wies sonst des \u00d6lbaums Art, und neben ihm,", "tokens": ["Wies", "sonst", "des", "\u00d6l\u00b7baums", "Art", ",", "und", "ne\u00b7ben", "ihm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "$,", "KON", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Umleuchtet wie die ewigen Seraphim", "tokens": ["Um\u00b7leuch\u00b7tet", "wie", "die", "e\u00b7wi\u00b7gen", "Se\u00b7ra\u00b7phim"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Von \u00fcberirdisch mildem Glanz, den Alten,", "tokens": ["Von", "\u00fc\u00b7be\u00b7rir\u00b7disch", "mil\u00b7dem", "Glanz", ",", "den", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Vor dem das Weib, ein wenig dunkler, stand.", "tokens": ["Vor", "dem", "das", "Weib", ",", "ein", "we\u00b7nig", "dunk\u00b7ler", ",", "stand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "$,", "ART", "PIAT", "ADJA", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Dunkler, obwohl kein F\u00e4serchen Gewand", "tokens": ["Dunk\u00b7ler", ",", "ob\u00b7wohl", "kein", "F\u00e4\u00b7ser\u00b7chen", "Ge\u00b7wand"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "PIAT", "NN", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "Den wundervollen Leib umpre\u00dfte.", "tokens": ["Den", "wun\u00b7der\u00b7vol\u00b7len", "Leib", "um\u00b7pre\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.141": {"line.1": {"text": "(vor allen Leuten? Pfui! Wie kann man nur!", "tokens": ["(", "vor", "al\u00b7len", "Leu\u00b7ten", "?", "Pfui", "!", "Wie", "kann", "man", "nur", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "$.", "NN", "$.", "PWAV", "VMFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ereiferte sich stark chokiert Chodscheste,", "tokens": ["Er\u00b7ei\u00b7fer\u00b7te", "sich", "stark", "cho\u00b7kiert", "Chod\u00b7sches\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "VVFIN", "NN", "$,"], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Indem sie \u00fcber J\u00e4ckchen, H\u00f6schen, Weste", "tokens": ["In\u00b7dem", "sie", "\u00fc\u00b7ber", "J\u00e4ck\u00b7chen", ",", "H\u00f6\u00b7schen", ",", "Wes\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit schambeflissenen Fingern fuhr.)", "tokens": ["Mit", "scham\u00b7be\u00b7flis\u00b7se\u00b7nen", "Fin\u00b7gern", "fuhr", ".", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.142": {"line.1": {"text": "Es tut mir leid, da\u00df ichs nicht leugnen kann:", "tokens": ["Es", "tut", "mir", "leid", ",", "da\u00df", "ichs", "nicht", "leug\u00b7nen", "kann", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "PIS", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie hatte wirklich nicht das mindste an:", "tokens": ["Sie", "hat\u00b7te", "wirk\u00b7lich", "nicht", "das", "minds\u00b7te", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "PTKNEG", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nackt war sie, nackt; nackt wie die liebe Sonne.", "tokens": ["Nackt", "war", "sie", ",", "nackt", ";", "nackt", "wie", "die", "lie\u00b7be", "Son\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "$,", "ADJD", "$.", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und niemand, sonderbar, nicht Weib noch Mann,", "tokens": ["Und", "nie\u00b7mand", ",", "son\u00b7der\u00b7bar", ",", "nicht", "Weib", "noch", "Mann", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "ADJD", "$,", "PTKNEG", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nahm irgendwie den kleinsten Ansto\u00df dran,", "tokens": ["Nahm", "ir\u00b7gend\u00b7wie", "den", "kleins\u00b7ten", "An\u00b7sto\u00df", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Erf\u00fcllt von andachtsvoller heiliger Wonne.", "tokens": ["Er\u00b7f\u00fcllt", "von", "an\u00b7dachts\u00b7vol\u00b7ler", "hei\u00b7li\u00b7ger", "Won\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Es war so ein erhabener Moment", "tokens": ["Es", "war", "so", "ein", "er\u00b7ha\u00b7be\u00b7ner", "Mo\u00b7ment"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "(sie sind sehr selten unter Menschgebornen),", "tokens": ["(", "sie", "sind", "sehr", "sel\u00b7ten", "un\u00b7ter", "Menschge\u00b7bor\u00b7nen", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "APPR", "NN", "$(", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Wo m\u00e4nniglich nichts weiter f\u00fchlt und kennt,", "tokens": ["Wo", "m\u00e4n\u00b7nig\u00b7lich", "nichts", "wei\u00b7ter", "f\u00fchlt", "und", "kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PIS", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Als tiefe Ahnung eines l\u00e4ngst Verlornen;", "tokens": ["Als", "tie\u00b7fe", "Ah\u00b7nung", "ei\u00b7nes", "l\u00e4ngst", "Ver\u00b7lor\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ART", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Und bei Empfindungen von solcher St\u00e4rke", "tokens": ["Und", "bei", "Emp\u00b7fin\u00b7dun\u00b7gen", "von", "sol\u00b7cher", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "APPR", "PIAT", "NN"], "meter": "----+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Denkt selbst ein Schneider nicht an Schneiders Werke.", "tokens": ["Denkt", "selbst", "ein", "Schnei\u00b7der", "nicht", "an", "Schnei\u00b7ders", "Wer\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NE", "PTKNEG", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Wahrlich, ich sage dir: durch jede Brust,", "tokens": ["Wahr\u00b7lich", ",", "ich", "sa\u00b7ge", "dir", ":", "durch", "je\u00b7de", "Brust", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PPER", "$.", "APPR", "PIAT", "NN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.14": {"text": "Ein Strom, ein Sturm, fuhr ungeheure Lust", "tokens": ["Ein", "Strom", ",", "ein", "Sturm", ",", "fuhr", "un\u00b7ge\u00b7heu\u00b7re", "Lust"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Des allertiefsten innigsten Begreifens,", "tokens": ["Des", "al\u00b7ler\u00b7tiefs\u00b7ten", "in\u00b7nigs\u00b7ten", "Be\u00b7grei\u00b7fens", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Des Lebensinnersten, des Urgebots,", "tokens": ["Des", "Le\u00b7ben\u00b7sin\u00b7ners\u00b7ten", ",", "des", "Ur\u00b7ge\u00b7bots", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.17": {"text": "Des dunklen Werdens, st\u00e4tig hellen Reifens,", "tokens": ["Des", "dunk\u00b7len", "Wer\u00b7dens", ",", "st\u00e4\u00b7tig", "hel\u00b7len", "Rei\u00b7fens", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Des Zeugens und Geb\u00e4rens und des Tods.", "tokens": ["Des", "Zeu\u00b7gens", "und", "Ge\u00b7b\u00e4\u00b7rens", "und", "des", "Tods", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.143": {"line.1": {"text": "All in die Knie nieder sanken sie, wie wenn", "tokens": ["All", "in", "die", "Knie", "nie\u00b7der", "san\u00b7ken", "sie", ",", "wie", "wenn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "PTKVZ", "VVFIN", "PPER", "$,", "KOKOM", "KOUS"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Der Gottheit Odem \u00fcber ihnen bliese,", "tokens": ["Der", "Got\u00b7theit", "O\u00b7dem", "\u00fc\u00b7ber", "ih\u00b7nen", "blie\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Stirn zur Erde nieder schlugen sie, wie wenn", "tokens": ["Die", "Stirn", "zur", "Er\u00b7de", "nie\u00b7der", "schlu\u00b7gen", "sie", ",", "wie", "wenn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "PTKVZ", "VVFIN", "PPER", "$,", "KOKOM", "KOUS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Gottheit Hand sie auf die Erde stie\u00dfe,", "tokens": ["Der", "Got\u00b7theit", "Hand", "sie", "auf", "die", "Er\u00b7de", "stie\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und wieder hoch sodann die K\u00f6pfe all, wie wenn", "tokens": ["Und", "wie\u00b7der", "hoch", "so\u00b7dann", "die", "K\u00f6p\u00b7fe", "all", ",", "wie", "wenn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "ADJD", "ADV", "ART", "NN", "PIAT", "$,", "KOKOM", "KOUS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Gottheit Mund sie rief zum Paradiese.", "tokens": ["Der", "Got\u00b7theit", "Mund", "sie", "rief", "zum", "Pa\u00b7ra\u00b7die\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.144": {"line.1": {"text": "Und ihre Augen, siehe, sie ersahn", "tokens": ["Und", "ih\u00b7re", "Au\u00b7gen", ",", "sie\u00b7he", ",", "sie", "er\u00b7sahn"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "$,", "VVIMP", "$,", "PPER", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den Lorbeerbaum das nackte Weib umfahn.", "tokens": ["Den", "Lor\u00b7beer\u00b7baum", "das", "nack\u00b7te", "Weib", "um\u00b7fahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.145": {"line.1": {"text": "Es ist nicht leicht zu sagen, wie das war.", "tokens": ["Es", "ist", "nicht", "leicht", "zu", "sa\u00b7gen", ",", "wie", "das", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$,", "PWAV", "PDS", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Denn, war bisher schon manches wunderbar,", "tokens": ["Denn", ",", "war", "bis\u00b7her", "schon", "man\u00b7ches", "wun\u00b7der\u00b7bar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "ADV", "ADV", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dies, Herrin, war noch wunder-wunderbarer.", "tokens": ["Dies", ",", "Her\u00b7rin", ",", "war", "noch", "wun\u00b7der\u00b7wun\u00b7der\u00b7ba\u00b7rer", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "NN", "$,", "VAFIN", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Er nahm sie in sich auf mit Haut und Haar", "tokens": ["Er", "nahm", "sie", "in", "sich", "auf", "mit", "Haut", "und", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PRF", "APPR", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und schlo\u00df sich dann, gleich einem Schatzbewahrer;", "tokens": ["Und", "schlo\u00df", "sich", "dann", ",", "gleich", "ei\u00b7nem", "Schatz\u00b7be\u00b7wah\u00b7rer", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "$,", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verschwunden war sie in ihm ganz und gar.", "tokens": ["Ver\u00b7schwun\u00b7den", "war", "sie", "in", "ihm", "ganz", "und", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "APPR", "PPER", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der Alte aber, schien es, war der Paarer,", "tokens": ["Der", "Al\u00b7te", "a\u00b7ber", ",", "schien", "es", ",", "war", "der", "Paa\u00b7rer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Der Priester Gottes, der den Segen gibt,", "tokens": ["Der", "Pries\u00b7ter", "Got\u00b7tes", ",", "der", "den", "Se\u00b7gen", "gibt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Wenn er vereint, was sich so innig liebt,", "tokens": ["Wenn", "er", "ver\u00b7eint", ",", "was", "sich", "so", "in\u00b7nig", "liebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$,", "PRELS", "PRF", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Da\u00df es allein nicht f\u00fcrder leben mag. \u2013", "tokens": ["Da\u00df", "es", "al\u00b7lein", "nicht", "f\u00fcr\u00b7der", "le\u00b7ben", "mag.", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.146": {"line.1": {"text": "Er hob die H\u00e4nde, und \u2013 es wurde Tag.", "tokens": ["Er", "hob", "die", "H\u00e4n\u00b7de", ",", "und", "\u2013", "es", "wur\u00b7de", "Tag", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KON", "$(", "PPER", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.147": {"line.1": {"text": "Zum Tage aber will kein Wunder taugen.", "tokens": ["Zum", "Ta\u00b7ge", "a\u00b7ber", "will", "kein", "Wun\u00b7der", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VMFIN", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Volk stand auf und wischte sich die Augen,", "tokens": ["Das", "Volk", "stand", "auf", "und", "wischte", "sich", "die", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "KON", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Rieb sich die Kniee, kraute sich am Ohr", "tokens": ["Rieb", "sich", "die", "Kni\u00b7ee", ",", "krau\u00b7te", "sich", "am", "Ohr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN", "$,", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und kam sich eigentlich bel\u00e4mmert vor.", "tokens": ["Und", "kam", "sich", "ei\u00b7gent\u00b7lich", "be\u00b7l\u00e4m\u00b7mert", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.148": {"line.1": {"text": "\u00bbherr Gott!\u00ab schrie auf ein Weib, \u00bbmein Mittagsessen!", "tokens": ["\u00bb", "herr", "Gott", "!", "\u00ab", "schrie", "auf", "ein", "Weib", ",", "\u00bb", "mein", "Mit\u00b7ta\u00b7gses\u00b7sen", "!"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "NN", "NN", "$.", "$(", "VVFIN", "APPR", "ART", "NN", "$,", "$(", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ganz sicher, es ist angebrannt.\u00ab", "tokens": ["Ganz", "si\u00b7cher", ",", "es", "ist", "an\u00b7ge\u00b7brannt", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "$,", "PPER", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbich hab den Schl\u00fcssel abzuziehn vergessen", "tokens": ["\u00bb", "ich", "hab", "den", "Schl\u00fcs\u00b7sel", "ab\u00b7zu\u00b7ziehn", "ver\u00b7ges\u00b7sen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "VVIZU", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von meinem Geldschrank,\u00ab rief ein Bankier.", "tokens": ["Von", "mei\u00b7nem", "Geld\u00b7schrank", ",", "\u00ab", "rief", "ein", "Ban\u00b7kier", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbgerechter Himmel! Ich mu\u00df ins Caf\u00e9!\u00ab", "tokens": ["\u00bb", "ge\u00b7rech\u00b7ter", "Him\u00b7mel", "!", "Ich", "mu\u00df", "ins", "Ca\u00b7f\u00e9", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "NN", "$.", "PPER", "VMFIN", "APPRART", "NN", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ein M\u00fc\u00dfigg\u00e4nger. Ein Schmuckfabrikant", "tokens": ["Ein", "M\u00fc\u00b7\u00dfig\u00b7g\u00e4n\u00b7ger", ".", "Ein", "Schmuck\u00b7fab\u00b7ri\u00b7kant"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$.", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Rang wild die H\u00e4nde: \u00bbMeine neuen Tressen!\u00ab", "tokens": ["Rang", "wild", "die", "H\u00e4n\u00b7de", ":", "\u00bb", "Mei\u00b7ne", "neu\u00b7en", "Tres\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADJD", "ART", "NN", "$.", "$(", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ein Priester wimmerte: \u00bbO domine!", "tokens": ["Ein", "Pries\u00b7ter", "wim\u00b7mer\u00b7te", ":", "\u00bb", "O", "do\u00b7mi\u00b7ne", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NE", "NE", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Die Vesperlitanei! Die Seelenmessen!\u00ab", "tokens": ["Die", "Ves\u00b7per\u00b7li\u00b7ta\u00b7nei", "!", "Die", "See\u00b7len\u00b7mes\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$.", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Und ein Konditor, v\u00f6llig wie besessen,", "tokens": ["Und", "ein", "Kon\u00b7di\u00b7tor", ",", "v\u00f6l\u00b7lig", "wie", "be\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ADJD", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Ri\u00df sich am Bart: \u00bbVerpappt ist mein Tragant!\u00ab", "tokens": ["Ri\u00df", "sich", "am", "Bart", ":", "\u00bb", "Ver\u00b7pappt", "ist", "mein", "Tra\u00b7gant", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PRF", "APPRART", "NN", "$.", "$(", "VVPP", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.12": {"text": "Ein tausendstimmiges Herrjemineh", "tokens": ["Ein", "tau\u00b7sends\u00b7tim\u00b7mi\u00b7ges", "Herr\u00b7je\u00b7mi\u00b7neh"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "T\u00e4t tausend Lippen kreischend sich entpressen,", "tokens": ["T\u00e4t", "tau\u00b7send", "Lip\u00b7pen", "krei\u00b7schend", "sich", "ent\u00b7pres\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "ADJD", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Und alles ist davongerannt.", "tokens": ["Und", "al\u00b7les", "ist", "da\u00b7von\u00b7ge\u00b7rannt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.149": {"line.1": {"text": "Nur jener Alte blieb am Baume stehn", "tokens": ["Nur", "je\u00b7ner", "Al\u00b7te", "blieb", "am", "Bau\u00b7me", "stehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDAT", "NN", "VVFIN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und blickte l\u00e4chelnd hinterher dem Volke,", "tokens": ["Und", "blick\u00b7te", "l\u00e4\u00b7chelnd", "hin\u00b7ter\u00b7her", "dem", "Vol\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Von dem bald nichts als eine dicke Wolke", "tokens": ["Von", "dem", "bald", "nichts", "als", "ei\u00b7ne", "di\u00b7cke", "Wol\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "PIS", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von aufgetriebenem Staube war zu sehn.", "tokens": ["Von", "auf\u00b7ge\u00b7trie\u00b7be\u00b7nem", "Stau\u00b7be", "war", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.150": {"line.1": {"text": "Im Lorbeerzweigicht aber hob ein Wehn", "tokens": ["Im", "Lor\u00b7beer\u00b7zwei\u00b7gicht", "a\u00b7ber", "hob", "ein", "Wehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Als wie von Windesstimmen s\u00e4uselnd an,", "tokens": ["Als", "wie", "von", "Win\u00b7dess\u00b7tim\u00b7men", "s\u00e4u\u00b7selnd", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "APPR", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aus dem, o wie so s\u00fc\u00df, ein Zwiegesang,", "tokens": ["Aus", "dem", ",", "o", "wie", "so", "s\u00fc\u00df", ",", "ein", "Zwie\u00b7ge\u00b7sang", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "FM", "KOKOM", "ADV", "ADJD", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Adams und Evas Liebeslied, begann:", "tokens": ["A\u00b7dams", "und", "E\u00b7vas", "Lie\u00b7bes\u00b7lied", ",", "be\u00b7gann", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "KON", "NE", "NN", "$,", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Ein Sichdurchflechten, Miteinanderschweben,", "tokens": ["Ein", "Sich\u00b7durch\u00b7flech\u00b7ten", ",", "Mi\u00b7tein\u00b7an\u00b7der\u00b7schwe\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ein Insichdringen, Durcheinanderweben,", "tokens": ["Ein", "In\u00b7sich\u00b7drin\u00b7gen", ",", "Durch\u00b7ein\u00b7an\u00b7der\u00b7we\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ein Insichsterben, Insichwiederleben,", "tokens": ["Ein", "In\u00b7sichs\u00b7ter\u00b7ben", ",", "In\u00b7sich\u00b7wie\u00b7der\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ein Durcheinanderbl\u00fchn im Doppelklang.", "tokens": ["Ein", "Durch\u00b7ein\u00b7an\u00b7der\u00b7bl\u00fchn", "im", "Dop\u00b7pel\u00b7klang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.151": {"line.1": {"text": "Der Alte kreuzte \u00fcber seiner Brust", "tokens": ["Der", "Al\u00b7te", "kreuz\u00b7te", "\u00fc\u00b7ber", "sei\u00b7ner", "Brust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Andachtdurchseligt seine sch\u00f6nen H\u00e4nde", "tokens": ["An\u00b7dacht\u00b7durch\u00b7se\u00b7ligt", "sei\u00b7ne", "sch\u00f6\u00b7nen", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und murmelte: \u00bbVon Anfang bis zu Ende,", "tokens": ["Und", "mur\u00b7mel\u00b7te", ":", "\u00bb", "Von", "An\u00b7fang", "bis", "zu", "En\u00b7de", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "APPR", "NN", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "All\u00fcberall ist Gott, und Gott ist Lust.", "tokens": ["Al\u00b7l\u00fc\u00b7be\u00b7rall", "ist", "Gott", ",", "und", "Gott", "ist", "Lust", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$,", "KON", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Gepriesen sei die Welt! Die Welt ist recht.", "tokens": ["Ge\u00b7prie\u00b7sen", "sei", "die", "Welt", "!", "Die", "Welt", "ist", "recht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Kein Str\u00e4hnchen Irrtum geht durch das Geflecht", "tokens": ["Kein", "Str\u00e4hn\u00b7chen", "Irr\u00b7tum", "geht", "durch", "das", "Ge\u00b7flecht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "NE", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Des Lebensteppichs, der die Tempelw\u00e4nde", "tokens": ["Des", "Le\u00b7bens\u00b7tep\u00b7pichs", ",", "der", "die", "Tem\u00b7pel\u00b7w\u00e4n\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Des urvollkommnen Alls bespannt,", "tokens": ["Des", "ur\u00b7voll\u00b7komm\u00b7nen", "Alls", "be\u00b7spannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und wer es auch im Traume nur erkannt,", "tokens": ["Und", "wer", "es", "auch", "im", "Trau\u00b7me", "nur", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Einmal im Traume nur und unbewu\u00dft:", "tokens": ["Ein\u00b7mal", "im", "Trau\u00b7me", "nur", "und", "un\u00b7be\u00b7wu\u00dft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADV", "KON", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.11": {"text": "Er ist voll Gott und ewiglich gerecht.", "tokens": ["Er", "ist", "voll", "Gott", "und", "e\u00b7wig\u00b7lich", "ge\u00b7recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "NN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.152": {"line.1": {"text": "Was sahen sie, die jetzt davongerannt sind", "tokens": ["Was", "sa\u00b7hen", "sie", ",", "die", "jetzt", "da\u00b7von\u00b7ge\u00b7rannt", "sind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PRELS", "ADV", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und wieder nun ins Enge eingebannt sind? \u2013:", "tokens": ["Und", "wie\u00b7der", "nun", "ins", "En\u00b7ge", "ein\u00b7ge\u00b7bannt", "sind", "?", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "ADV", "APPRART", "NN", "VVPP", "VAFIN", "$.", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ins Feuer sahn sie und ins Herz der Welt.", "tokens": ["Ins", "Feu\u00b7er", "sahn", "sie", "und", "ins", "Herz", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "KON", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Allahs Augapfel sahen sie: das Weib,", "tokens": ["Al\u00b7lahs", "Aug\u00b7ap\u00b7fel", "sa\u00b7hen", "sie", ":", "das", "Weib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$.", "ART", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ein P\u00fcppchen erst, geschnitzt zum Zeitvertreib,", "tokens": ["Ein", "P\u00fcpp\u00b7chen", "erst", ",", "ge\u00b7schnitzt", "zum", "Zeit\u00b7ver\u00b7treib", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und dann der Sinn des Seins, der alles h\u00e4lt:", "tokens": ["Und", "dann", "der", "Sinn", "des", "Seins", ",", "der", "al\u00b7les", "h\u00e4lt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Natur und Liebe, Weg zur Ewigkeit", "tokens": ["Na\u00b7tur", "und", "Lie\u00b7be", ",", "Weg", "zur", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Aus eines Augenblicks Vergessenheit, \u2013", "tokens": ["Aus", "ei\u00b7nes", "Au\u00b7gen\u00b7blicks", "Ver\u00b7ges\u00b7sen\u00b7heit", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ein Nichts und Alles, \u2013 wie es euch gef\u00e4llt.\u00ab", "tokens": ["Ein", "Nichts", "und", "Al\u00b7les", ",", "\u2013", "wie", "es", "euch", "ge\u00b7f\u00e4llt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "PIS", "$,", "$(", "PWAV", "PPER", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}