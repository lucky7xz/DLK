{"textgrid.poem.34103": {"metadata": {"author": {"name": "Hebbel, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Welt-Poesie", "genre": "verse", "period": "N.A.", "pub_year": 1838, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Keine edlere Flamme, die V\u00f6lker in Eins zu verschmelzen,", "tokens": ["Kei\u00b7ne", "ed\u00b7le\u00b7re", "Flam\u00b7me", ",", "die", "V\u00f6l\u00b7ker", "in", "Eins", "zu", "ver\u00b7schmel\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Als die poetische, nur gehen wir Deutsche zu weit,", "tokens": ["Als", "die", "po\u00b7e\u00b7ti\u00b7sche", ",", "nur", "ge\u00b7hen", "wir", "Deut\u00b7sche", "zu", "weit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "$,", "ADV", "VVFIN", "PPER", "NN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wenn wir den Persern die Tropen f\u00fcr uns're Gedanken entlehnen,", "tokens": ["Wenn", "wir", "den", "Per\u00b7sern", "die", "Tro\u00b7pen", "f\u00fcr", "un\u00b7s'\u00b7re", "Ge\u00b7dan\u00b7ken", "ent\u00b7leh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+--+--+---+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Denn es wird nur verlangt, da\u00df wir die Perser versteh'n.", "tokens": ["Denn", "es", "wird", "nur", "ver\u00b7langt", ",", "da\u00df", "wir", "die", "Per\u00b7ser", "ver\u00b7steh'", "n."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "PPER", "VAFIN", "ADV", "VVPP", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "NE"], "meter": "--+--+-+-+--+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Oder w\u00e4re die Zeit der letzten Vers\u00f6hnung gekommen,", "tokens": ["O\u00b7der", "w\u00e4\u00b7re", "die", "Zeit", "der", "letz\u00b7ten", "Ver\u00b7s\u00f6h\u00b7nung", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.6": {"text": "Wenn man Persisch bei uns dichtet, in Persien Deutsch?", "tokens": ["Wenn", "man", "Per\u00b7sisch", "bei", "uns", "dich\u00b7tet", ",", "in", "Per\u00b7si\u00b7en", "Deutsch", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "APPR", "PPER", "VVFIN", "$,", "APPR", "NE", "NE", "$."], "meter": "--+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Wenn wir die Stimme des Fr\u00fchlings am Lech als Bulbul begr\u00fc\u00dfen,", "tokens": ["Wenn", "wir", "die", "Stim\u00b7me", "des", "Fr\u00fch\u00b7lings", "am", "Lech", "als", "Bul\u00b7bul", "be\u00b7gr\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "APPRART", "NN", "KOKOM", "NE", "VVINF", "$,"], "meter": "-+-+--+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "W\u00e4hrend ein neuer Hafis dort von der Nachtigall singt?", "tokens": ["W\u00e4h\u00b7rend", "ein", "neu\u00b7er", "Ha\u00b7fis", "dort", "von", "der", "Nach\u00b7ti\u00b7gall", "singt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+--+--+", "measure": "iambic.hexa.invert"}}, "stanza.2": {"line.1": {"text": "Keine edlere Flamme, die V\u00f6lker in Eins zu verschmelzen,", "tokens": ["Kei\u00b7ne", "ed\u00b7le\u00b7re", "Flam\u00b7me", ",", "die", "V\u00f6l\u00b7ker", "in", "Eins", "zu", "ver\u00b7schmel\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Als die poetische, nur gehen wir Deutsche zu weit,", "tokens": ["Als", "die", "po\u00b7e\u00b7ti\u00b7sche", ",", "nur", "ge\u00b7hen", "wir", "Deut\u00b7sche", "zu", "weit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "$,", "ADV", "VVFIN", "PPER", "NN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wenn wir den Persern die Tropen f\u00fcr uns're Gedanken entlehnen,", "tokens": ["Wenn", "wir", "den", "Per\u00b7sern", "die", "Tro\u00b7pen", "f\u00fcr", "un\u00b7s'\u00b7re", "Ge\u00b7dan\u00b7ken", "ent\u00b7leh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+--+--+---+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Denn es wird nur verlangt, da\u00df wir die Perser versteh'n.", "tokens": ["Denn", "es", "wird", "nur", "ver\u00b7langt", ",", "da\u00df", "wir", "die", "Per\u00b7ser", "ver\u00b7steh'", "n."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "PPER", "VAFIN", "ADV", "VVPP", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "NE"], "meter": "--+--+-+-+--+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Oder w\u00e4re die Zeit der letzten Vers\u00f6hnung gekommen,", "tokens": ["O\u00b7der", "w\u00e4\u00b7re", "die", "Zeit", "der", "letz\u00b7ten", "Ver\u00b7s\u00f6h\u00b7nung", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.6": {"text": "Wenn man Persisch bei uns dichtet, in Persien Deutsch?", "tokens": ["Wenn", "man", "Per\u00b7sisch", "bei", "uns", "dich\u00b7tet", ",", "in", "Per\u00b7si\u00b7en", "Deutsch", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "APPR", "PPER", "VVFIN", "$,", "APPR", "NE", "NE", "$."], "meter": "--+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Wenn wir die Stimme des Fr\u00fchlings am Lech als Bulbul begr\u00fc\u00dfen,", "tokens": ["Wenn", "wir", "die", "Stim\u00b7me", "des", "Fr\u00fch\u00b7lings", "am", "Lech", "als", "Bul\u00b7bul", "be\u00b7gr\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "APPRART", "NN", "KOKOM", "NE", "VVINF", "$,"], "meter": "-+-+--+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "W\u00e4hrend ein neuer Hafis dort von der Nachtigall singt?", "tokens": ["W\u00e4h\u00b7rend", "ein", "neu\u00b7er", "Ha\u00b7fis", "dort", "von", "der", "Nach\u00b7ti\u00b7gall", "singt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+--+--+", "measure": "iambic.hexa.invert"}}}}}