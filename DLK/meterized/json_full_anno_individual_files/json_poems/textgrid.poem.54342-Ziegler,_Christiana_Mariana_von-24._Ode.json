{"textgrid.poem.54342": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "24. Ode", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Fragt mich nur nicht, ihr Pierinnen!", "tokens": ["Fragt", "mich", "nur", "nicht", ",", "ihr", "Pie\u00b7rin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was hier mein Kopf f\u00fcr Grillen heckt?", "tokens": ["Was", "hier", "mein", "Kopf", "f\u00fcr", "Gril\u00b7len", "heckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Warum ihr mich so tief seht sinnen,", "tokens": ["Wa\u00b7rum", "ihr", "mich", "so", "tief", "seht", "sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "ADJD", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und was mir im Gehirne steckt?", "tokens": ["Und", "was", "mir", "im", "Ge\u00b7hir\u00b7ne", "steckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich selber bin mit mir nicht einig,", "tokens": ["Ich", "sel\u00b7ber", "bin", "mit", "mir", "nicht", "ei\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "APPR", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Ungeduld, so mich bestrickt,", "tokens": ["Die", "Un\u00b7ge\u00b7duld", ",", "so", "mich", "be\u00b7strickt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Macht, da\u00df man mich so fr\u00fch und schleunig,", "tokens": ["Macht", ",", "da\u00df", "man", "mich", "so", "fr\u00fch", "und", "schleu\u00b7nig", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PIS", "PRF", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Voll Unmuth und verst\u00f6hrt erblickt.", "tokens": ["Voll", "Un\u00b7muth", "und", "ver\u00b7st\u00f6hrt", "er\u00b7blickt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich sch\u00e4me mich vor eurem Orden,", "tokens": ["Ich", "sch\u00e4\u00b7me", "mich", "vor", "eu\u00b7rem", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und weis gewi\u00df, da\u00df ihr nun sprecht,", "tokens": ["Und", "weis", "ge\u00b7wi\u00df", ",", "da\u00df", "ihr", "nun", "sprecht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "ADV", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich sey zur L\u00fcgnerin geworden;", "tokens": ["Ich", "sey", "zur", "L\u00fcg\u00b7ne\u00b7rin", "ge\u00b7wor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr habt dazu vielleicht auch Recht.", "tokens": ["Ihr", "habt", "da\u00b7zu", "viel\u00b7leicht", "auch", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nun denk ich allererst zur\u00fccke,", "tokens": ["Nun", "denk", "ich", "al\u00b7le\u00b7rerst", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie wohl zu sp\u00e4t, was ich gethan;", "tokens": ["Wie", "wohl", "zu", "sp\u00e4t", ",", "was", "ich", "ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PTKA", "ADJD", "$,", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Allein, wer ist, der dem Geschicke", "tokens": ["Al\u00b7lein", ",", "wer", "ist", ",", "der", "dem", "Ge\u00b7schi\u00b7cke"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PWS", "VAFIN", "$,", "PRELS", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Best\u00e4ndig wiederstreben kann?", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "wie\u00b7der\u00b7stre\u00b7ben", "kann", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein Wort, ein Mann, pflegt man zu sagen,", "tokens": ["Ein", "Wort", ",", "ein", "Mann", ",", "pflegt", "man", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "VVFIN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dies zielt auf blosse M\u00e4nner nicht.", "tokens": ["Dies", "zielt", "auf", "blos\u00b7se", "M\u00e4n\u00b7ner", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie? ist es in den Wind zu schlagen,", "tokens": ["Wie", "?", "ist", "es", "in", "den", "Wind", "zu", "schla\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VAFIN", "PPER", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn Frauenzimmer was verspricht?", "tokens": ["Wenn", "Frau\u00b7en\u00b7zim\u00b7mer", "was", "ver\u00b7spricht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nein; Glaub und Treu schm\u00fcckt ihre Sch\u00f6ne,", "tokens": ["Nein", ";", "Glaub", "und", "Treu", "schm\u00fcckt", "ih\u00b7re", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "NN", "KON", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als andre, Zierde, Putz und Pracht,", "tokens": ["Als", "and\u00b7re", ",", "Zier\u00b7de", ",", "Putz", "und", "Pracht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dies wissen wir so gut als jene,", "tokens": ["Dies", "wis\u00b7sen", "wir", "so", "gut", "als", "je\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADJD", "KOKOM", "PDS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und doch hab ich nicht dran gedacht.", "tokens": ["Und", "doch", "hab", "ich", "nicht", "dran", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PTKNEG", "PAV", "VVPP", "$."], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Mein banges Herze will sich l\u00fcften,", "tokens": ["Mein", "ban\u00b7ges", "Her\u00b7ze", "will", "sich", "l\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Stein mu\u00df weg, der solches dr\u00fcckt.", "tokens": ["Der", "Stein", "mu\u00df", "weg", ",", "der", "sol\u00b7ches", "dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie? habt ihr nicht in meinen Schriften", "tokens": ["Wie", "?", "habt", "ihr", "nicht", "in", "mei\u00b7nen", "Schrif\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "VAFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zugleich ein Abschiedslied erblickt?", "tokens": ["Zu\u00b7gleich", "ein", "Ab\u00b7schieds\u00b7lied", "er\u00b7blickt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ja, ja, der Korb ward euch gegeben,", "tokens": ["Ja", ",", "ja", ",", "der", "Korb", "ward", "euch", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was spricht man denn? gesteht es mir,", "tokens": ["Was", "spricht", "man", "denn", "?", "ge\u00b7steht", "es", "mir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ADV", "$.", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und sieht man mich dawider leben,", "tokens": ["Und", "sieht", "man", "mich", "da\u00b7wi\u00b7der", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PRF", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "R\u00fcckt man mir nicht den Fehler f\u00fcr?", "tokens": ["R\u00fcckt", "man", "mir", "nicht", "den", "Feh\u00b7ler", "f\u00fcr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "PTKNEG", "ART", "NN", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ja wohl; man wird unfehlbar sprechen:", "tokens": ["Ja", "wohl", ";", "man", "wird", "un\u00b7fehl\u00b7bar", "spre\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$.", "PIS", "VAFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da sieht man, was der Wankelmuth,", "tokens": ["Da", "sieht", "man", ",", "was", "der", "Wan\u00b7kel\u00b7muth", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "PRELS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der oft pflegt Wort und Schwur zu brechen,", "tokens": ["Der", "oft", "pflegt", "Wort", "und", "Schwur", "zu", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "NN", "KON", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Am weiblichen Geschlechte thut.", "tokens": ["Am", "weib\u00b7li\u00b7chen", "Ge\u00b7schlech\u00b7te", "thut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gemach! la\u00dft euch nur nicht verhetzen,", "tokens": ["Ge\u00b7mach", "!", "la\u00dft", "euch", "nur", "nicht", "ver\u00b7het\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVIMP", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich weis es freylich allzu wohl,", "tokens": ["Ich", "weis", "es", "frey\u00b7lich", "all\u00b7zu", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PPER", "ADV", "PTKA", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df ich, mein Wort nicht zu verletzen,", "tokens": ["Da\u00df", "ich", ",", "mein", "Wort", "nicht", "zu", "ver\u00b7let\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PPOSAT", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nicht mehr in Versen schreiben soll.", "tokens": ["Nicht", "mehr", "in", "Ver\u00b7sen", "schrei\u00b7ben", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Der Scheidebrief ist unvergessen,", "tokens": ["Der", "Schei\u00b7de\u00b7brief", "ist", "un\u00b7ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den ich der Welt im Drucke wies,", "tokens": ["Den", "ich", "der", "Welt", "im", "Dru\u00b7cke", "wies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als ich den Platz, den ich besessen,", "tokens": ["Als", "ich", "den", "Platz", ",", "den", "ich", "be\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An andre Sch\u00fcler \u00fcberlie\u00df.", "tokens": ["An", "and\u00b7re", "Sch\u00fc\u00b7ler", "\u00fc\u00b7ber\u00b7lie\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich weis mich wohl noch zu besinnen,", "tokens": ["Ich", "weis", "mich", "wohl", "noch", "zu", "be\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PPER", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was damals mich dazu bewog,", "tokens": ["Was", "da\u00b7mals", "mich", "da\u00b7zu", "be\u00b7wog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PRF", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als ich, mehr Freyheit zu gewinnen,", "tokens": ["Als", "ich", ",", "mehr", "Frey\u00b7heit", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Von euch, geliebte Musen, zog.", "tokens": ["Von", "euch", ",", "ge\u00b7lieb\u00b7te", "Mu\u00b7sen", ",", "zog", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPER", "$,", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Jedoch! sucht euch nur nicht zu r\u00e4chen,", "tokens": ["Je\u00b7doch", "!", "sucht", "euch", "nur", "nicht", "zu", "r\u00e4\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "PPER", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-----+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "Da\u00df ihr mich mit dem Vorwurf qu\u00e4lt,", "tokens": ["Da\u00df", "ihr", "mich", "mit", "dem", "Vor\u00b7wurf", "qu\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der bey vergeblichem Versprechen", "tokens": ["Der", "bey", "ver\u00b7geb\u00b7li\u00b7chem", "Ver\u00b7spre\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mich zu den Flattergeistern zehlt.", "tokens": ["Mich", "zu", "den", "Flat\u00b7ter\u00b7geis\u00b7tern", "zehlt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr w\u00fcrdet mich zu sehr besch\u00e4men,", "tokens": ["Ihr", "w\u00fcr\u00b7det", "mich", "zu", "sehr", "be\u00b7sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKA", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Drum h\u00f6rt nur an, was hier mein Kiel", "tokens": ["Drum", "h\u00f6rt", "nur", "an", ",", "was", "hier", "mein", "Kiel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "PTKVZ", "$,", "PRELS", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dergleichen Argwohn zu benehmen,", "tokens": ["Derg\u00b7lei\u00b7chen", "Arg\u00b7wohn", "zu", "be\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Euch im Vertrauen sagen will.", "tokens": ["Euch", "im", "Ver\u00b7trau\u00b7en", "sa\u00b7gen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Die Nachtigal, so sich den Netzen", "tokens": ["Die", "Nach\u00b7ti\u00b7gal", ",", "so", "sich", "den", "Net\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "PRF", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Einmal begl\u00fcckt entreissen kann,", "tokens": ["Ein\u00b7mal", "be\u00b7gl\u00fcckt", "en\u00b7treis\u00b7sen", "kann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VVINF", "VMFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Bei\u00dft, ihre Freyheit nachzusetzen,", "tokens": ["Bei\u00dft", ",", "ih\u00b7re", "Frey\u00b7heit", "nach\u00b7zu\u00b7set\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zum andern mal nicht wieder an.", "tokens": ["Zum", "an\u00b7dern", "mal", "nicht", "wie\u00b7der", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mir aber wollt es nicht gelingen;", "tokens": ["Mir", "a\u00b7ber", "wollt", "es", "nicht", "ge\u00b7lin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich ri\u00df mich zwar von eurem Hayn;", "tokens": ["Ich", "ri\u00df", "mich", "zwar", "von", "eu\u00b7rem", "Hayn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und dennoch schlo\u00df durch sanftes Singen", "tokens": ["Und", "den\u00b7noch", "schlo\u00df", "durch", "sanf\u00b7tes", "Sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ein ander Chor mich wieder ein.", "tokens": ["Ein", "an\u00b7der", "Chor", "mich", "wie\u00b7der", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Die Deutschen Musen unsrer Linden,", "tokens": ["Die", "Deut\u00b7schen", "Mu\u00b7sen", "uns\u00b7rer", "Lin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die blo\u00df, ihr m\u00fc\u00dft es selbst gestehn,", "tokens": ["Die", "blo\u00df", ",", "ihr", "m\u00fc\u00dft", "es", "selbst", "ge\u00b7stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "PPER", "VMFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Deswegen ihre Reyhen binden,", "tokens": ["Des\u00b7we\u00b7gen", "ih\u00b7re", "Rey\u00b7hen", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Damit sie diese Sprach erh\u00f6hn.", "tokens": ["Da\u00b7mit", "sie", "die\u00b7se", "Sprach", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die, wie mit Eifer ist geschehen,", "tokens": ["Die", ",", "wie", "mit", "Ei\u00b7fer", "ist", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAV", "APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bey r\u00fchmensw\u00fcrdiger Geduld", "tokens": ["Bey", "r\u00fch\u00b7mens\u00b7w\u00fcr\u00b7di\u00b7ger", "Ge\u00b7duld"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Germanien ins Herze sehen,", "tokens": ["Ger\u00b7ma\u00b7ni\u00b7en", "ins", "Her\u00b7ze", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die sind daran, sonst Niemand schuld.", "tokens": ["Die", "sind", "da\u00b7ran", ",", "sonst", "Nie\u00b7mand", "schuld", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PAV", "$,", "ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Sie winkten mir auch sonder bitten,", "tokens": ["Sie", "wink\u00b7ten", "mir", "auch", "son\u00b7der", "bit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und riefen mich zu ihrer Schaar,", "tokens": ["Und", "rie\u00b7fen", "mich", "zu", "ih\u00b7rer", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu der mein Fu\u00df so gleich geschritten,", "tokens": ["Zu", "der", "mein", "Fu\u00df", "so", "gleich", "ge\u00b7schrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So sch\u00fcchtern er auch immer war.", "tokens": ["So", "sch\u00fcch\u00b7tern", "er", "auch", "im\u00b7mer", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du sollst zuerst die Bahne brechen,", "tokens": ["Du", "sollst", "zu\u00b7erst", "die", "Bah\u00b7ne", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gedacht ich dazumal bey mir,", "tokens": ["Ge\u00b7dacht", "ich", "da\u00b7zu\u00b7mal", "bey", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Was wird hierzu wohl Momus sprechen?", "tokens": ["Was", "wird", "hier\u00b7zu", "wohl", "Mo\u00b7mus", "spre\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PAV", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich weis gewi\u00df, er drohet dir.", "tokens": ["Ich", "weis", "ge\u00b7wi\u00df", ",", "er", "dro\u00b7het", "dir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "ADV", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Allein ich lie\u00df ihn immer dr\u00e4uen,", "tokens": ["Al\u00b7lein", "ich", "lie\u00df", "ihn", "im\u00b7mer", "dr\u00e4u\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warum? es war einmal geschehn;", "tokens": ["Wa\u00b7rum", "?", "es", "war", "ein\u00b7mal", "ge\u00b7schehn", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man kann in der Gelehrten Reyhen", "tokens": ["Man", "kann", "in", "der", "Ge\u00b7lehr\u00b7ten", "Rey\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zwar hier nicht Frauenzimmer sehn;", "tokens": ["Zwar", "hier", "nicht", "Frau\u00b7en\u00b7zim\u00b7mer", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und doch trifft man in fremden L\u00e4ndern", "tokens": ["Und", "doch", "trifft", "man", "in", "frem\u00b7den", "L\u00e4n\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "APPR", "ADJA", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Dergleichen Mitgespielen an,", "tokens": ["Derg\u00b7lei\u00b7chen", "Mit\u00b7ge\u00b7spie\u00b7len", "an", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Drum wollt ich den Entschlu\u00df nicht \u00e4ndern,", "tokens": ["Drum", "wollt", "ich", "den", "Ent\u00b7schlu\u00df", "nicht", "\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und gieng mit dreistem Muth daran.", "tokens": ["Und", "gieng", "mit", "dreis\u00b7tem", "Muth", "da\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Z\u00fcrnt, liebste Musen, nicht dar\u00fcber;", "tokens": ["Z\u00fcrnt", ",", "liebs\u00b7te", "Mu\u00b7sen", ",", "nicht", "da\u00b7r\u00fc\u00b7ber", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,", "PTKNEG", "PAV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Geht eure Mariane gleich", "tokens": ["Geht", "eu\u00b7re", "Ma\u00b7ri\u00b7a\u00b7ne", "gleich"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NE", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu diesen Deutschen Musen \u00fcber,", "tokens": ["Zu", "die\u00b7sen", "Deut\u00b7schen", "Mu\u00b7sen", "\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sitzt sie doch mitten unter euch.", "tokens": ["Sitzt", "sie", "doch", "mit\u00b7ten", "un\u00b7ter", "euch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sind ja eure rechten Br\u00fcder,", "tokens": ["Sie", "sind", "ja", "eu\u00b7re", "rech\u00b7ten", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie dichten ja durch eure Gunst", "tokens": ["Sie", "dich\u00b7ten", "ja", "durch", "eu\u00b7re", "Gunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So sch\u00f6n und angenehme Lieder,", "tokens": ["So", "sch\u00f6n", "und", "an\u00b7ge\u00b7neh\u00b7me", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und danken euch blo\u00df ihre Kunst.", "tokens": ["Und", "dan\u00b7ken", "euch", "blo\u00df", "ih\u00b7re", "Kunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}}, "stanza.13": {"line.1": {"text": "Dies wird vor mich und euren Orden", "tokens": ["Dies", "wird", "vor", "mich", "und", "eu\u00b7ren", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein mehr als grosser Vortheil seyn,", "tokens": ["Ein", "mehr", "als", "gros\u00b7ser", "Vor\u00b7theil", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "KOKOM", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df ich ihr Mitglied bin geworden;", "tokens": ["Da\u00df", "ich", "ihr", "Mit\u00b7glied", "bin", "ge\u00b7wor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gebt also nur eur Jawort drein.", "tokens": ["Gebt", "al\u00b7so", "nur", "eur", "Ja\u00b7wort", "drein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr kluges Tadeln und Verbessern,", "tokens": ["Ihr", "klu\u00b7ges", "Ta\u00b7deln", "und", "Ver\u00b7bes\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der wohlgestimmt und reine Thon", "tokens": ["Der", "wohl\u00b7ge\u00b7stimmt", "und", "rei\u00b7ne", "Thon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wird meiner Seiten Klang vergr\u00f6ssern,", "tokens": ["Wird", "mei\u00b7ner", "Sei\u00b7ten", "Klang", "ver\u00b7gr\u00f6s\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mir ist, als sp\u00fchrt ich solches schon.", "tokens": ["Mir", "ist", ",", "als", "sp\u00fchrt", "ich", "sol\u00b7ches", "schon", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "VVFIN", "PPER", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Fahrt fort, ihr Deutschen Musens\u00f6hne,", "tokens": ["Fahrt", "fort", ",", "ihr", "Deut\u00b7schen", "Mu\u00b7sen\u00b7s\u00f6h\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mir ferner an die Hand zu gehn.", "tokens": ["Mir", "fer\u00b7ner", "an", "die", "Hand", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vertreibt mein rauhes Waldgeth\u00f6ne,", "tokens": ["Ver\u00b7treibt", "mein", "rau\u00b7hes", "Wald\u00b7ge\u00b7th\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Lehrt mich die Wirbel richtig drehn.", "tokens": ["Lehrt", "mich", "die", "Wir\u00b7bel", "rich\u00b7tig", "drehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verge\u00dft den Held nicht zu besingen,", "tokens": ["Ver\u00b7ge\u00dft", "den", "Held", "nicht", "zu", "be\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Reich und Chur so klug besch\u00fctzt,", "tokens": ["Der", "Reich", "und", "Chur", "so", "klug", "be\u00b7sch\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und, wenn wir ihm ein Opfer bringen,", "tokens": ["Und", ",", "wenn", "wir", "ihm", "ein", "Op\u00b7fer", "brin\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zugleich auch unsre Musen st\u00fctzt.", "tokens": ["Zu\u00b7gleich", "auch", "uns\u00b7re", "Mu\u00b7sen", "st\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Weckt unter seines Scepters Schimmer", "tokens": ["Weckt", "un\u00b7ter", "sei\u00b7nes", "Scep\u00b7ters", "Schim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Deutsche Sprache wieder auf.", "tokens": ["Die", "Deut\u00b7sche", "Spra\u00b7che", "wie\u00b7der", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie liegt und schl\u00e4ft noch leider immer,", "tokens": ["Sie", "liegt", "und", "schl\u00e4ft", "noch", "lei\u00b7der", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bringt wieder Zung und Kiel in Lauf.", "tokens": ["Bringt", "wie\u00b7der", "Zung", "und", "Kiel", "in", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "KON", "NE", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sucht Quell und Ursprung zu ergr\u00fcnden,", "tokens": ["Sucht", "Quell", "und", "Ur\u00b7sprung", "zu", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bespiegelt euch an Frankreichs Witz;", "tokens": ["Be\u00b7spie\u00b7gelt", "euch", "an", "Fran\u00b7kreichs", "Witz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So nennt die Welt den Hayn der Linden", "tokens": ["So", "nennt", "die", "Welt", "den", "Hayn", "der", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "ART", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit Recht der Deutschen Musen Sitz.", "tokens": ["Mit", "Recht", "der", "Deut\u00b7schen", "Mu\u00b7sen", "Sitz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Fragt mich nur nicht, ihr Pierinnen!", "tokens": ["Fragt", "mich", "nur", "nicht", ",", "ihr", "Pie\u00b7rin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was hier mein Kopf f\u00fcr Grillen heckt?", "tokens": ["Was", "hier", "mein", "Kopf", "f\u00fcr", "Gril\u00b7len", "heckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Warum ihr mich so tief seht sinnen,", "tokens": ["Wa\u00b7rum", "ihr", "mich", "so", "tief", "seht", "sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "ADJD", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und was mir im Gehirne steckt?", "tokens": ["Und", "was", "mir", "im", "Ge\u00b7hir\u00b7ne", "steckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich selber bin mit mir nicht einig,", "tokens": ["Ich", "sel\u00b7ber", "bin", "mit", "mir", "nicht", "ei\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "APPR", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Ungeduld, so mich bestrickt,", "tokens": ["Die", "Un\u00b7ge\u00b7duld", ",", "so", "mich", "be\u00b7strickt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Macht, da\u00df man mich so fr\u00fch und schleunig,", "tokens": ["Macht", ",", "da\u00df", "man", "mich", "so", "fr\u00fch", "und", "schleu\u00b7nig", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PIS", "PRF", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Voll Unmuth und verst\u00f6hrt erblickt.", "tokens": ["Voll", "Un\u00b7muth", "und", "ver\u00b7st\u00f6hrt", "er\u00b7blickt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Ich sch\u00e4me mich vor eurem Orden,", "tokens": ["Ich", "sch\u00e4\u00b7me", "mich", "vor", "eu\u00b7rem", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und weis gewi\u00df, da\u00df ihr nun sprecht,", "tokens": ["Und", "weis", "ge\u00b7wi\u00df", ",", "da\u00df", "ihr", "nun", "sprecht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "ADV", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich sey zur L\u00fcgnerin geworden;", "tokens": ["Ich", "sey", "zur", "L\u00fcg\u00b7ne\u00b7rin", "ge\u00b7wor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr habt dazu vielleicht auch Recht.", "tokens": ["Ihr", "habt", "da\u00b7zu", "viel\u00b7leicht", "auch", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nun denk ich allererst zur\u00fccke,", "tokens": ["Nun", "denk", "ich", "al\u00b7le\u00b7rerst", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie wohl zu sp\u00e4t, was ich gethan;", "tokens": ["Wie", "wohl", "zu", "sp\u00e4t", ",", "was", "ich", "ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PTKA", "ADJD", "$,", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Allein, wer ist, der dem Geschicke", "tokens": ["Al\u00b7lein", ",", "wer", "ist", ",", "der", "dem", "Ge\u00b7schi\u00b7cke"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PWS", "VAFIN", "$,", "PRELS", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Best\u00e4ndig wiederstreben kann?", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "wie\u00b7der\u00b7stre\u00b7ben", "kann", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Ein Wort, ein Mann, pflegt man zu sagen,", "tokens": ["Ein", "Wort", ",", "ein", "Mann", ",", "pflegt", "man", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "VVFIN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dies zielt auf blosse M\u00e4nner nicht.", "tokens": ["Dies", "zielt", "auf", "blos\u00b7se", "M\u00e4n\u00b7ner", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie? ist es in den Wind zu schlagen,", "tokens": ["Wie", "?", "ist", "es", "in", "den", "Wind", "zu", "schla\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VAFIN", "PPER", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn Frauenzimmer was verspricht?", "tokens": ["Wenn", "Frau\u00b7en\u00b7zim\u00b7mer", "was", "ver\u00b7spricht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nein; Glaub und Treu schm\u00fcckt ihre Sch\u00f6ne,", "tokens": ["Nein", ";", "Glaub", "und", "Treu", "schm\u00fcckt", "ih\u00b7re", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "NN", "KON", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als andre, Zierde, Putz und Pracht,", "tokens": ["Als", "and\u00b7re", ",", "Zier\u00b7de", ",", "Putz", "und", "Pracht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dies wissen wir so gut als jene,", "tokens": ["Dies", "wis\u00b7sen", "wir", "so", "gut", "als", "je\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADJD", "KOKOM", "PDS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und doch hab ich nicht dran gedacht.", "tokens": ["Und", "doch", "hab", "ich", "nicht", "dran", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PTKNEG", "PAV", "VVPP", "$."], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "Mein banges Herze will sich l\u00fcften,", "tokens": ["Mein", "ban\u00b7ges", "Her\u00b7ze", "will", "sich", "l\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Stein mu\u00df weg, der solches dr\u00fcckt.", "tokens": ["Der", "Stein", "mu\u00df", "weg", ",", "der", "sol\u00b7ches", "dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie? habt ihr nicht in meinen Schriften", "tokens": ["Wie", "?", "habt", "ihr", "nicht", "in", "mei\u00b7nen", "Schrif\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "VAFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zugleich ein Abschiedslied erblickt?", "tokens": ["Zu\u00b7gleich", "ein", "Ab\u00b7schieds\u00b7lied", "er\u00b7blickt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ja, ja, der Korb ward euch gegeben,", "tokens": ["Ja", ",", "ja", ",", "der", "Korb", "ward", "euch", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was spricht man denn? gesteht es mir,", "tokens": ["Was", "spricht", "man", "denn", "?", "ge\u00b7steht", "es", "mir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ADV", "$.", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und sieht man mich dawider leben,", "tokens": ["Und", "sieht", "man", "mich", "da\u00b7wi\u00b7der", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PRF", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "R\u00fcckt man mir nicht den Fehler f\u00fcr?", "tokens": ["R\u00fcckt", "man", "mir", "nicht", "den", "Feh\u00b7ler", "f\u00fcr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "PTKNEG", "ART", "NN", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Ja wohl; man wird unfehlbar sprechen:", "tokens": ["Ja", "wohl", ";", "man", "wird", "un\u00b7fehl\u00b7bar", "spre\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$.", "PIS", "VAFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da sieht man, was der Wankelmuth,", "tokens": ["Da", "sieht", "man", ",", "was", "der", "Wan\u00b7kel\u00b7muth", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "PRELS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der oft pflegt Wort und Schwur zu brechen,", "tokens": ["Der", "oft", "pflegt", "Wort", "und", "Schwur", "zu", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "NN", "KON", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Am weiblichen Geschlechte thut.", "tokens": ["Am", "weib\u00b7li\u00b7chen", "Ge\u00b7schlech\u00b7te", "thut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gemach! la\u00dft euch nur nicht verhetzen,", "tokens": ["Ge\u00b7mach", "!", "la\u00dft", "euch", "nur", "nicht", "ver\u00b7het\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVIMP", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich weis es freylich allzu wohl,", "tokens": ["Ich", "weis", "es", "frey\u00b7lich", "all\u00b7zu", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PPER", "ADV", "PTKA", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df ich, mein Wort nicht zu verletzen,", "tokens": ["Da\u00df", "ich", ",", "mein", "Wort", "nicht", "zu", "ver\u00b7let\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PPOSAT", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nicht mehr in Versen schreiben soll.", "tokens": ["Nicht", "mehr", "in", "Ver\u00b7sen", "schrei\u00b7ben", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Der Scheidebrief ist unvergessen,", "tokens": ["Der", "Schei\u00b7de\u00b7brief", "ist", "un\u00b7ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den ich der Welt im Drucke wies,", "tokens": ["Den", "ich", "der", "Welt", "im", "Dru\u00b7cke", "wies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als ich den Platz, den ich besessen,", "tokens": ["Als", "ich", "den", "Platz", ",", "den", "ich", "be\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An andre Sch\u00fcler \u00fcberlie\u00df.", "tokens": ["An", "and\u00b7re", "Sch\u00fc\u00b7ler", "\u00fc\u00b7ber\u00b7lie\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich weis mich wohl noch zu besinnen,", "tokens": ["Ich", "weis", "mich", "wohl", "noch", "zu", "be\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PPER", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was damals mich dazu bewog,", "tokens": ["Was", "da\u00b7mals", "mich", "da\u00b7zu", "be\u00b7wog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PRF", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als ich, mehr Freyheit zu gewinnen,", "tokens": ["Als", "ich", ",", "mehr", "Frey\u00b7heit", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Von euch, geliebte Musen, zog.", "tokens": ["Von", "euch", ",", "ge\u00b7lieb\u00b7te", "Mu\u00b7sen", ",", "zog", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPER", "$,", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Jedoch! sucht euch nur nicht zu r\u00e4chen,", "tokens": ["Je\u00b7doch", "!", "sucht", "euch", "nur", "nicht", "zu", "r\u00e4\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "PPER", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-----+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "Da\u00df ihr mich mit dem Vorwurf qu\u00e4lt,", "tokens": ["Da\u00df", "ihr", "mich", "mit", "dem", "Vor\u00b7wurf", "qu\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der bey vergeblichem Versprechen", "tokens": ["Der", "bey", "ver\u00b7geb\u00b7li\u00b7chem", "Ver\u00b7spre\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mich zu den Flattergeistern zehlt.", "tokens": ["Mich", "zu", "den", "Flat\u00b7ter\u00b7geis\u00b7tern", "zehlt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr w\u00fcrdet mich zu sehr besch\u00e4men,", "tokens": ["Ihr", "w\u00fcr\u00b7det", "mich", "zu", "sehr", "be\u00b7sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKA", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Drum h\u00f6rt nur an, was hier mein Kiel", "tokens": ["Drum", "h\u00f6rt", "nur", "an", ",", "was", "hier", "mein", "Kiel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "PTKVZ", "$,", "PRELS", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dergleichen Argwohn zu benehmen,", "tokens": ["Derg\u00b7lei\u00b7chen", "Arg\u00b7wohn", "zu", "be\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Euch im Vertrauen sagen will.", "tokens": ["Euch", "im", "Ver\u00b7trau\u00b7en", "sa\u00b7gen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Die Nachtigal, so sich den Netzen", "tokens": ["Die", "Nach\u00b7ti\u00b7gal", ",", "so", "sich", "den", "Net\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "PRF", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Einmal begl\u00fcckt entreissen kann,", "tokens": ["Ein\u00b7mal", "be\u00b7gl\u00fcckt", "en\u00b7treis\u00b7sen", "kann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VVINF", "VMFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Bei\u00dft, ihre Freyheit nachzusetzen,", "tokens": ["Bei\u00dft", ",", "ih\u00b7re", "Frey\u00b7heit", "nach\u00b7zu\u00b7set\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zum andern mal nicht wieder an.", "tokens": ["Zum", "an\u00b7dern", "mal", "nicht", "wie\u00b7der", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mir aber wollt es nicht gelingen;", "tokens": ["Mir", "a\u00b7ber", "wollt", "es", "nicht", "ge\u00b7lin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich ri\u00df mich zwar von eurem Hayn;", "tokens": ["Ich", "ri\u00df", "mich", "zwar", "von", "eu\u00b7rem", "Hayn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und dennoch schlo\u00df durch sanftes Singen", "tokens": ["Und", "den\u00b7noch", "schlo\u00df", "durch", "sanf\u00b7tes", "Sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ein ander Chor mich wieder ein.", "tokens": ["Ein", "an\u00b7der", "Chor", "mich", "wie\u00b7der", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Die Deutschen Musen unsrer Linden,", "tokens": ["Die", "Deut\u00b7schen", "Mu\u00b7sen", "uns\u00b7rer", "Lin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die blo\u00df, ihr m\u00fc\u00dft es selbst gestehn,", "tokens": ["Die", "blo\u00df", ",", "ihr", "m\u00fc\u00dft", "es", "selbst", "ge\u00b7stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "PPER", "VMFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Deswegen ihre Reyhen binden,", "tokens": ["Des\u00b7we\u00b7gen", "ih\u00b7re", "Rey\u00b7hen", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Damit sie diese Sprach erh\u00f6hn.", "tokens": ["Da\u00b7mit", "sie", "die\u00b7se", "Sprach", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die, wie mit Eifer ist geschehen,", "tokens": ["Die", ",", "wie", "mit", "Ei\u00b7fer", "ist", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAV", "APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bey r\u00fchmensw\u00fcrdiger Geduld", "tokens": ["Bey", "r\u00fch\u00b7mens\u00b7w\u00fcr\u00b7di\u00b7ger", "Ge\u00b7duld"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Germanien ins Herze sehen,", "tokens": ["Ger\u00b7ma\u00b7ni\u00b7en", "ins", "Her\u00b7ze", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die sind daran, sonst Niemand schuld.", "tokens": ["Die", "sind", "da\u00b7ran", ",", "sonst", "Nie\u00b7mand", "schuld", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PAV", "$,", "ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Sie winkten mir auch sonder bitten,", "tokens": ["Sie", "wink\u00b7ten", "mir", "auch", "son\u00b7der", "bit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und riefen mich zu ihrer Schaar,", "tokens": ["Und", "rie\u00b7fen", "mich", "zu", "ih\u00b7rer", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu der mein Fu\u00df so gleich geschritten,", "tokens": ["Zu", "der", "mein", "Fu\u00df", "so", "gleich", "ge\u00b7schrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So sch\u00fcchtern er auch immer war.", "tokens": ["So", "sch\u00fcch\u00b7tern", "er", "auch", "im\u00b7mer", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du sollst zuerst die Bahne brechen,", "tokens": ["Du", "sollst", "zu\u00b7erst", "die", "Bah\u00b7ne", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gedacht ich dazumal bey mir,", "tokens": ["Ge\u00b7dacht", "ich", "da\u00b7zu\u00b7mal", "bey", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Was wird hierzu wohl Momus sprechen?", "tokens": ["Was", "wird", "hier\u00b7zu", "wohl", "Mo\u00b7mus", "spre\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PAV", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich weis gewi\u00df, er drohet dir.", "tokens": ["Ich", "weis", "ge\u00b7wi\u00df", ",", "er", "dro\u00b7het", "dir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "ADV", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Allein ich lie\u00df ihn immer dr\u00e4uen,", "tokens": ["Al\u00b7lein", "ich", "lie\u00df", "ihn", "im\u00b7mer", "dr\u00e4u\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warum? es war einmal geschehn;", "tokens": ["Wa\u00b7rum", "?", "es", "war", "ein\u00b7mal", "ge\u00b7schehn", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man kann in der Gelehrten Reyhen", "tokens": ["Man", "kann", "in", "der", "Ge\u00b7lehr\u00b7ten", "Rey\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zwar hier nicht Frauenzimmer sehn;", "tokens": ["Zwar", "hier", "nicht", "Frau\u00b7en\u00b7zim\u00b7mer", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und doch trifft man in fremden L\u00e4ndern", "tokens": ["Und", "doch", "trifft", "man", "in", "frem\u00b7den", "L\u00e4n\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "APPR", "ADJA", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Dergleichen Mitgespielen an,", "tokens": ["Derg\u00b7lei\u00b7chen", "Mit\u00b7ge\u00b7spie\u00b7len", "an", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Drum wollt ich den Entschlu\u00df nicht \u00e4ndern,", "tokens": ["Drum", "wollt", "ich", "den", "Ent\u00b7schlu\u00df", "nicht", "\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und gieng mit dreistem Muth daran.", "tokens": ["Und", "gieng", "mit", "dreis\u00b7tem", "Muth", "da\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Z\u00fcrnt, liebste Musen, nicht dar\u00fcber;", "tokens": ["Z\u00fcrnt", ",", "liebs\u00b7te", "Mu\u00b7sen", ",", "nicht", "da\u00b7r\u00fc\u00b7ber", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,", "PTKNEG", "PAV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Geht eure Mariane gleich", "tokens": ["Geht", "eu\u00b7re", "Ma\u00b7ri\u00b7a\u00b7ne", "gleich"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NE", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu diesen Deutschen Musen \u00fcber,", "tokens": ["Zu", "die\u00b7sen", "Deut\u00b7schen", "Mu\u00b7sen", "\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sitzt sie doch mitten unter euch.", "tokens": ["Sitzt", "sie", "doch", "mit\u00b7ten", "un\u00b7ter", "euch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sind ja eure rechten Br\u00fcder,", "tokens": ["Sie", "sind", "ja", "eu\u00b7re", "rech\u00b7ten", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie dichten ja durch eure Gunst", "tokens": ["Sie", "dich\u00b7ten", "ja", "durch", "eu\u00b7re", "Gunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So sch\u00f6n und angenehme Lieder,", "tokens": ["So", "sch\u00f6n", "und", "an\u00b7ge\u00b7neh\u00b7me", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und danken euch blo\u00df ihre Kunst.", "tokens": ["Und", "dan\u00b7ken", "euch", "blo\u00df", "ih\u00b7re", "Kunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}}, "stanza.28": {"line.1": {"text": "Dies wird vor mich und euren Orden", "tokens": ["Dies", "wird", "vor", "mich", "und", "eu\u00b7ren", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein mehr als grosser Vortheil seyn,", "tokens": ["Ein", "mehr", "als", "gros\u00b7ser", "Vor\u00b7theil", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "KOKOM", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df ich ihr Mitglied bin geworden;", "tokens": ["Da\u00df", "ich", "ihr", "Mit\u00b7glied", "bin", "ge\u00b7wor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gebt also nur eur Jawort drein.", "tokens": ["Gebt", "al\u00b7so", "nur", "eur", "Ja\u00b7wort", "drein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr kluges Tadeln und Verbessern,", "tokens": ["Ihr", "klu\u00b7ges", "Ta\u00b7deln", "und", "Ver\u00b7bes\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der wohlgestimmt und reine Thon", "tokens": ["Der", "wohl\u00b7ge\u00b7stimmt", "und", "rei\u00b7ne", "Thon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wird meiner Seiten Klang vergr\u00f6ssern,", "tokens": ["Wird", "mei\u00b7ner", "Sei\u00b7ten", "Klang", "ver\u00b7gr\u00f6s\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mir ist, als sp\u00fchrt ich solches schon.", "tokens": ["Mir", "ist", ",", "als", "sp\u00fchrt", "ich", "sol\u00b7ches", "schon", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "VVFIN", "PPER", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Fahrt fort, ihr Deutschen Musens\u00f6hne,", "tokens": ["Fahrt", "fort", ",", "ihr", "Deut\u00b7schen", "Mu\u00b7sen\u00b7s\u00f6h\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mir ferner an die Hand zu gehn.", "tokens": ["Mir", "fer\u00b7ner", "an", "die", "Hand", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vertreibt mein rauhes Waldgeth\u00f6ne,", "tokens": ["Ver\u00b7treibt", "mein", "rau\u00b7hes", "Wald\u00b7ge\u00b7th\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Lehrt mich die Wirbel richtig drehn.", "tokens": ["Lehrt", "mich", "die", "Wir\u00b7bel", "rich\u00b7tig", "drehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verge\u00dft den Held nicht zu besingen,", "tokens": ["Ver\u00b7ge\u00dft", "den", "Held", "nicht", "zu", "be\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Reich und Chur so klug besch\u00fctzt,", "tokens": ["Der", "Reich", "und", "Chur", "so", "klug", "be\u00b7sch\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und, wenn wir ihm ein Opfer bringen,", "tokens": ["Und", ",", "wenn", "wir", "ihm", "ein", "Op\u00b7fer", "brin\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zugleich auch unsre Musen st\u00fctzt.", "tokens": ["Zu\u00b7gleich", "auch", "uns\u00b7re", "Mu\u00b7sen", "st\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Weckt unter seines Scepters Schimmer", "tokens": ["Weckt", "un\u00b7ter", "sei\u00b7nes", "Scep\u00b7ters", "Schim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Deutsche Sprache wieder auf.", "tokens": ["Die", "Deut\u00b7sche", "Spra\u00b7che", "wie\u00b7der", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie liegt und schl\u00e4ft noch leider immer,", "tokens": ["Sie", "liegt", "und", "schl\u00e4ft", "noch", "lei\u00b7der", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bringt wieder Zung und Kiel in Lauf.", "tokens": ["Bringt", "wie\u00b7der", "Zung", "und", "Kiel", "in", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "KON", "NE", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sucht Quell und Ursprung zu ergr\u00fcnden,", "tokens": ["Sucht", "Quell", "und", "Ur\u00b7sprung", "zu", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bespiegelt euch an Frankreichs Witz;", "tokens": ["Be\u00b7spie\u00b7gelt", "euch", "an", "Fran\u00b7kreichs", "Witz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So nennt die Welt den Hayn der Linden", "tokens": ["So", "nennt", "die", "Welt", "den", "Hayn", "der", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "ART", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit Recht der Deutschen Musen Sitz.", "tokens": ["Mit", "Recht", "der", "Deut\u00b7schen", "Mu\u00b7sen", "Sitz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}