{"dta.poem.5502": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Erbauliche Betrachtung schnell- verge-  \n hender Wolcken.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich sitze hier und seh den D\u00fcften,", "tokens": ["Ich", "sit\u00b7ze", "hier", "und", "seh", "den", "D\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie sie sich, in den regen L\u00fcften", "tokens": ["Wie", "sie", "sich", ",", "in", "den", "re\u00b7gen", "L\u00fcf\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Formiren, mit Bewundrung, zu.", "tokens": ["For\u00b7mi\u00b7ren", ",", "mit", "Be\u00b7wund\u00b7rung", ",", "zu", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "APPR", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie sie sich bilden und entbilden,", "tokens": ["Wie", "sie", "sich", "bil\u00b7den", "und", "ent\u00b7bil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVINF", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sich hier versilbern, dort verg\u00fclden,", "tokens": ["Sich", "hier", "ver\u00b7sil\u00b7bern", ",", "dort", "ver\u00b7g\u00fcl\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVINF", "$,", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In steter Aendrung, ohne Ruh.", "tokens": ["In", "ste\u00b7ter", "A\u00b7en\u00b7drung", ",", "oh\u00b7ne", "Ruh", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUI", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "Bald sieht man sie sich schnell verdunckeln;", "tokens": ["Bald", "sieht", "man", "sie", "sich", "schnell", "ver\u00b7dun\u00b7ckeln", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bald wie Rubin und Purpur funckeln,", "tokens": ["Bald", "wie", "Ru\u00b7bin", "und", "Pur\u00b7pur", "fun\u00b7ckeln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "NE", "KON", "NN", "VVINF", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Durch wechselnden Empfang des Lichts.", "tokens": ["Durch", "wech\u00b7seln\u00b7den", "Emp\u00b7fang", "des", "Lichts", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Bald gleichen sie erhabnen Bergen,", "tokens": ["Bald", "glei\u00b7chen", "sie", "er\u00b7hab\u00b7nen", "Ber\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Bald werden sie zu kleinen Zwergen;", "tokens": ["Bald", "wer\u00b7den", "sie", "zu", "klei\u00b7nen", "Zwer\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bald sind sie klein, bald gro\u00df, bald nichts.", "tokens": ["Bald", "sind", "sie", "klein", ",", "bald", "gro\u00df", ",", "bald", "nichts", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "ADV", "ADJD", "$,", "ADV", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "So schnell formiren sich Figuren,", "tokens": ["So", "schnell", "for\u00b7mi\u00b7ren", "sich", "Fi\u00b7gu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PRF", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So schnell vergehn die Creaturen", "tokens": ["So", "schnell", "ver\u00b7gehn", "die", "Crea\u00b7tu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dort oben in der L\u00fcfte Reich:", "tokens": ["Dort", "o\u00b7ben", "in", "der", "L\u00fcf\u00b7te", "Reich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Allein! sind C\u00f6rper, die auf Erden,", "tokens": ["Al\u00b7lein", "!", "sind", "C\u00f6r\u00b7per", ",", "die", "auf", "Er\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VAFIN", "NE", "$,", "PRELS", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dem Schein nach, fest gefunden werden,", "tokens": ["Dem", "Schein", "nach", ",", "fest", "ge\u00b7fun\u00b7den", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADJD", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht ihnen fast an Dauer gleich?", "tokens": ["Nicht", "ih\u00b7nen", "fast", "an", "Dau\u00b7er", "gleich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPER", "ADV", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die Blumen, welche man im Lentzen,", "tokens": ["Die", "Blu\u00b7men", ",", "wel\u00b7che", "man", "im", "Lent\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In zierlichsten Gestalten gl\u00e4ntzen,", "tokens": ["In", "zier\u00b7lichs\u00b7ten", "Ge\u00b7stal\u00b7ten", "gl\u00e4nt\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "Und sch\u00f6n an Form und Farben sieht,", "tokens": ["Und", "sch\u00f6n", "an", "Form", "und", "Far\u00b7ben", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind oftermahls in wenig Stunden", "tokens": ["Sind", "of\u00b7ter\u00b7mahls", "in", "we\u00b7nig", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Verwelcket, ihre Pracht verschwunden,", "tokens": ["Ver\u00b7wel\u00b7cket", ",", "ih\u00b7re", "Pracht", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und, eh man sichs versieht, verbl\u00fcht.", "tokens": ["Und", ",", "eh", "man", "sichs", "ver\u00b7sieht", ",", "ver\u00b7bl\u00fcht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "PIS", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "So gar auch von der Menschen Leben", "tokens": ["So", "gar", "auch", "von", "der", "Men\u00b7schen", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kann ein Gew\u00f6lck ein Beyspiel geben;", "tokens": ["Kann", "ein", "Ge\u00b7w\u00f6lck", "ein", "Bey\u00b7spiel", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kann nicht, mit Recht, ein Fel\u00df, ein Stein", "tokens": ["Kann", "nicht", ",", "mit", "Recht", ",", "ein", "Fel\u00df", ",", "ein", "Stein"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VMFIN", "PTKNEG", "$,", "APPR", "NN", "$,", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu uns, wie wir zum Wolcken, sagen:", "tokens": ["Zu", "uns", ",", "wie", "wir", "zum", "Wol\u00b7cken", ",", "sa\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PWAV", "PPER", "APPRART", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie la\u00dft ihr euch so schnell verjagen,", "tokens": ["Wie", "la\u00dft", "ihr", "euch", "so", "schnell", "ver\u00b7ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie ist doch eure Dau\u2019r so klein!", "tokens": ["Wie", "ist", "doch", "eu\u00b7re", "Dau'r", "so", "klein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Da ihr fast sterbt, wann ihr entstehet,", "tokens": ["Da", "ihr", "fast", "sterbt", ",", "wann", "ihr", "ent\u00b7ste\u00b7het", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Jm Kommen gleichsam schon vergehet,", "tokens": ["Jm", "Kom\u00b7men", "gleich\u00b7sam", "schon", "ver\u00b7ge\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie schleunig seyd ihr nicht mehr da!", "tokens": ["Wie", "schleu\u00b7nig", "seyd", "ihr", "nicht", "mehr", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "PTKNEG", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch, lieber Stein, du magst nur schweigen;", "tokens": ["Doch", ",", "lie\u00b7ber", "Stein", ",", "du", "magst", "nur", "schwei\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "NN", "$,", "PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du kannst uns keinen Fehler zeigen:", "tokens": ["Du", "kannst", "uns", "kei\u00b7nen", "Feh\u00b7ler", "zei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Es ist des Sch\u00f6pfers Ordnung ja.", "tokens": ["Es", "ist", "des", "Sch\u00f6p\u00b7fers", "Ord\u00b7nung", "ja", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Zudem da Dinge dieser Erden", "tokens": ["Zu\u00b7dem", "da", "Din\u00b7ge", "die\u00b7ser", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das, wof\u00fcr sie gehalten werden,", "tokens": ["Das", ",", "wo\u00b7f\u00fcr", "sie", "ge\u00b7hal\u00b7ten", "wer\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWAV", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur blos Vergleichungs-weise seyn;", "tokens": ["Nur", "blos", "Ver\u00b7glei\u00b7chungs\u00b7wei\u00b7se", "seyn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wie ein Ton, f\u00fcr sich betrachtet,", "tokens": ["Und", "wie", "ein", "Ton", ",", "f\u00fcr", "sich", "be\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "$,", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nicht hoch nicht niedrig wird geachtet,", "tokens": ["Nicht", "hoch", "nicht", "nied\u00b7rig", "wird", "ge\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "PTKNEG", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So ist, f\u00fcr sich, nichts gro\u00df, nichts klein.", "tokens": ["So", "ist", ",", "f\u00fcr", "sich", ",", "nichts", "gro\u00df", ",", "nichts", "klein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "APPR", "PRF", "$,", "PIS", "ADJD", "$,", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Es sollen mir denn Stein und Eisen", "tokens": ["Es", "sol\u00b7len", "mir", "denn", "Stein", "und", "Ei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht meiner Daur Vergleichung weisen,", "tokens": ["Nicht", "mei\u00b7ner", "Daur", "Ver\u00b7glei\u00b7chung", "wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich gehe zu der schnellen Luft;", "tokens": ["Ich", "ge\u00b7he", "zu", "der", "schnel\u00b7len", "Luft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da wirst du ja nicht l\u00e4ugnen k\u00f6nnen,", "tokens": ["Da", "wirst", "du", "ja", "nicht", "l\u00e4ug\u00b7nen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df wir uns nicht so pl\u00f6tzlich trennen,", "tokens": ["Da\u00df", "wir", "uns", "nicht", "so", "pl\u00f6tz\u00b7lich", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als wie ein stets-vergehnder Duft.", "tokens": ["Als", "wie", "ein", "stets\u00b7ver\u00b7gehn\u00b7der", "Duft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Man thut dann wol, es umzukehren,", "tokens": ["Man", "thut", "dann", "wol", ",", "es", "um\u00b7zu\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "$,", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df wir vom Duft uns lassen lehren,", "tokens": ["Da\u00df", "wir", "vom", "Duft", "uns", "las\u00b7sen", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PPER", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df wir so pl\u00f6tzlich nicht vergehn;", "tokens": ["Da\u00df", "wir", "so", "pl\u00f6tz\u00b7lich", "nicht", "ver\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df tausend Ding\u2019 auf dieser Erden,", "tokens": ["Da\u00df", "tau\u00b7send", "Ding'", "auf", "die\u00b7ser", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn sie mit uns verglichen werden,", "tokens": ["Wenn", "sie", "mit", "uns", "ver\u00b7gli\u00b7chen", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So lange nicht, als wir, bestehn.", "tokens": ["So", "lan\u00b7ge", "nicht", ",", "als", "wir", ",", "be\u00b7stehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "$,", "KOUS", "PPER", "$,", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ja w\u00e4r uns Menschen auch ein Leben", "tokens": ["Ja", "w\u00e4r", "uns", "Men\u00b7schen", "auch", "ein", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "VAFIN", "PPER", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von gr\u00f6ssrer Daur, als Stein, gegeben;", "tokens": ["Von", "gr\u00f6ss\u00b7rer", "Daur", ",", "als", "Stein", ",", "ge\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUS", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "W\u00e4r es doch eine kurtze Zeit:", "tokens": ["W\u00e4r", "es", "doch", "ei\u00b7ne", "kurt\u00b7ze", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man w\u00fcrd\u2019 es nicht einst rechnen k\u00f6nnen", "tokens": ["Man", "w\u00fcrd'", "es", "nicht", "einst", "rech\u00b7nen", "k\u00f6n\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "PTKNEG", "ADV", "VVINF", "VMINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und w\u00e4re kaum ein Punct zu nennen;", "tokens": ["Und", "w\u00e4\u00b7re", "kaum", "ein", "Punct", "zu", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Verglich mans mit der Ewigkeit.", "tokens": ["Ver\u00b7glich", "mans", "mit", "der", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Noch mehr: verlischt die Lebens-Kertze,", "tokens": ["Noch", "mehr", ":", "ver\u00b7lischt", "die", "Le\u00b7bens\u00b7Kert\u00b7ze", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So traure darum nicht, mein Hertze,", "tokens": ["So", "trau\u00b7re", "da\u00b7rum", "nicht", ",", "mein", "Hert\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PAV", "PTKNEG", "$,", "PPOSAT", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df sie nicht l\u00e4nger brennen kann.", "tokens": ["Da\u00df", "sie", "nicht", "l\u00e4n\u00b7ger", "bren\u00b7nen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn etwan Seel\u2019 und Leib sich trennen,", "tokens": ["Wenn", "et\u00b7wan", "Seel'", "und", "Leib", "sich", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "KON", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Must du die\u00df kein Vergehen nennen;", "tokens": ["Must", "du", "die\u00df", "kein", "Ver\u00b7ge\u00b7hen", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PDS", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Aendrung geht den Leib nur an.", "tokens": ["Die", "A\u00b7en\u00b7drung", "geht", "den", "Leib", "nur", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Der Sch\u00f6pfer hat dein wahres Wesen", "tokens": ["Der", "Sch\u00f6p\u00b7fer", "hat", "dein", "wah\u00b7res", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zu einer gr\u00f6ssern Daur erlesen;", "tokens": ["Zu", "ei\u00b7ner", "gr\u00f6s\u00b7sern", "Daur", "er\u00b7le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Indem er selber ewig ist.", "tokens": ["In\u00b7dem", "er", "sel\u00b7ber", "e\u00b7wig", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So thut man wol, wenn ihm zu Ehren,", "tokens": ["So", "thut", "man", "wol", ",", "wenn", "ihm", "zu", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$,", "KOUS", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Man, unsrer Seelen Daur und W\u00e4hren,", "tokens": ["Man", ",", "uns\u00b7rer", "See\u00b7len", "Daur", "und", "W\u00e4h\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PPOSAT", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nach seiner ew\u2019gen Liebe mi\u00dft.", "tokens": ["Nach", "sei\u00b7ner", "ew'\u00b7gen", "Lie\u00b7be", "mi\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Drum w\u00fcnscht nicht l\u00e4nger hier zu bleiben,", "tokens": ["Drum", "w\u00fcnscht", "nicht", "l\u00e4n\u00b7ger", "hier", "zu", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PTKNEG", "ADJD", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als, unser Ziel uns vorzuschreiben", "tokens": ["Als", ",", "un\u00b7ser", "Ziel", "uns", "vor\u00b7zu\u00b7schrei\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "PPOSAT", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Beschlossen hat, der uns gemacht.", "tokens": ["Be\u00b7schlos\u00b7sen", "hat", ",", "der", "uns", "ge\u00b7macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn unser Lebens-Tocht verlodert,", "tokens": ["Wenn", "un\u00b7ser", "Le\u00b7bens\u00b7Tocht", "ver\u00b7lo\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und uns der Sch\u00f6pfer zu sich fodert,", "tokens": ["Und", "uns", "der", "Sch\u00f6p\u00b7fer", "zu", "sich", "fo\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So saget fr\u00f6lich: gute Nacht!", "tokens": ["So", "sa\u00b7get", "fr\u00f6\u00b7lich", ":", "gu\u00b7te", "Nacht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}