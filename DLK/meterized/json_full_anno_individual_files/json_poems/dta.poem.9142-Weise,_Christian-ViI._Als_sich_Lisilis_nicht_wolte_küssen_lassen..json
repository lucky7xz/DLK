{"dta.poem.9142": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "ViI.  \n Als sich Lisilis nicht wolte k\u00fcssen lassen.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Du freundliche Lisilis soll ich dich k\u00fcssen/", "tokens": ["Du", "freund\u00b7li\u00b7che", "Li\u00b7si\u00b7lis", "soll", "ich", "dich", "k\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NE", "VMFIN", "PPER", "PRF", "VVINF", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "So zeug doch nicht das m\u00fcndgen weg/", "tokens": ["So", "zeug", "doch", "nicht", "das", "m\u00fcnd\u00b7gen", "weg", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKNEG", "ART", "ADJA", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein k\u00fc\u00dfgen ist leichtlich zu tode geb\u00fcssen/", "tokens": ["Ein", "k\u00fc\u00df\u00b7gen", "ist", "leicht\u00b7lich", "zu", "to\u00b7de", "ge\u00b7b\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADJD", "APPR", "NN", "VVPP", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Und macht ja keinen schwartzen fleck.", "tokens": ["Und", "macht", "ja", "kei\u00b7nen", "schwart\u00b7zen", "fleck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach halte mein l\u00e4mgen ach halte gewi\u00df/", "tokens": ["Ach", "hal\u00b7te", "mein", "l\u00e4m\u00b7gen", "ach", "hal\u00b7te", "ge\u00b7wi\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPOSAT", "VVFIN", "ADV", "VVFIN", "ADV", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Ich gebe dir einen empfindlichen bi\u00df/", "tokens": ["Ich", "ge\u00b7be", "dir", "ei\u00b7nen", "emp\u00b7find\u00b7li\u00b7chen", "bi\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "APPR", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Ach Lisilis.", "tokens": ["Ach", "Li\u00b7si\u00b7lis", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "2. Ach beuge dein leibgen nicht immer zur\u00fccke/", "tokens": ["Ach", "beu\u00b7ge", "dein", "leib\u00b7gen", "nicht", "im\u00b7mer", "zu\u00b7r\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPOSAT", "ADJA", "PTKNEG", "ADV", "VVFIN", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Sonst kan ich warlich nicht darzu/", "tokens": ["Sonst", "kan", "ich", "war\u00b7lich", "nicht", "dar\u00b7zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein engel gib achtung indem ich dich dr\u00fccke/", "tokens": ["Mein", "en\u00b7gel", "gib", "ach\u00b7tung", "in\u00b7dem", "ich", "dich", "dr\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVIMP", "NN", "KOUS", "PPER", "PRF", "VVFIN", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Da\u00df ich dir nichts zu leide thu/", "tokens": ["Da\u00df", "ich", "dir", "nichts", "zu", "lei\u00b7de", "thu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PIS", "PTKZU", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein k\u00fc\u00dfgen verbleibet mein liebes-genie\u00df/", "tokens": ["Ein", "k\u00fc\u00df\u00b7gen", "ver\u00b7blei\u00b7bet", "mein", "lie\u00b7bes\u00b7ge\u00b7ni\u00b7e\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Ich bitte zum sch\u00f6nsten/ verg\u00f6nne mir di\u00df/", "tokens": ["Ich", "bit\u00b7te", "zum", "sch\u00f6ns\u00b7ten", "/", "ver\u00b7g\u00f6n\u00b7ne", "mir", "di\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "ADJA", "$(", "VVFIN", "PPER", "PDS", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Ach Lisilis.", "tokens": ["Ach", "Li\u00b7si\u00b7lis", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "3. Halt stille mein hertzgen/ was heissen die possen/", "tokens": ["Halt", "stil\u00b7le", "mein", "hertz\u00b7gen", "/", "was", "heis\u00b7sen", "die", "pos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "VVINF", "$(", "PWS", "VVFIN", "ART", "NN", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Nun h\u00e4ltst du gar die h\u00e4nde vor/", "tokens": ["Nun", "h\u00e4ltst", "du", "gar", "die", "h\u00e4n\u00b7de", "vor", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die haben sich \u00fcber die lippen geschlossen/", "tokens": ["Die", "ha\u00b7ben", "sich", "\u00fc\u00b7ber", "die", "lip\u00b7pen", "ge\u00b7schlos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Doch gib das k\u00f6pffgen nur empor/", "tokens": ["Doch", "gib", "das", "k\u00f6pff\u00b7gen", "nur", "em\u00b7por", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "ADJA", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In warheit ich habe das kinne gewi\u00df/", "tokens": ["In", "war\u00b7heit", "ich", "ha\u00b7be", "das", "kin\u00b7ne", "ge\u00b7wi\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VAFIN", "ART", "NN", "ADV", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Drum halt ich dich feste/ verzeihe mir di\u00df.", "tokens": ["Drum", "halt", "ich", "dich", "fes\u00b7te", "/", "ver\u00b7zei\u00b7he", "mir", "di\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADJA", "$(", "VVFIN", "PPER", "PDS", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Ach Lisilis.", "tokens": ["Ach", "Li\u00b7si\u00b7lis", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "4. Was wilstu dich wehren/ was wilstu noch ringen/", "tokens": ["Was", "wils\u00b7tu", "dich", "weh\u00b7ren", "/", "was", "wils\u00b7tu", "noch", "rin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$(", "PWS", "VMFIN", "ADV", "VVFIN", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wo flog der tieffe seuffzer hin/", "tokens": ["Wo", "flog", "der", "tief\u00b7fe", "seuff\u00b7zer", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein l\u00e4mgen/ ach lasse dich immer bezwingen/", "tokens": ["Mein", "l\u00e4m\u00b7gen", "/", "ach", "las\u00b7se", "dich", "im\u00b7mer", "be\u00b7zwin\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "$(", "ADV", "VVFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Weil ich dir schon so nahe bin/", "tokens": ["Weil", "ich", "dir", "schon", "so", "na\u00b7he", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich habe gewonnen/ mein liebes-genie\u00df", "tokens": ["Ich", "ha\u00b7be", "ge\u00b7won\u00b7nen", "/", "mein", "lie\u00b7bes\u00b7ge\u00b7ni\u00b7e\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "PPOSAT", "NN"], "meter": "-+--+--+---+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Bleibt meinen entz\u00fccketen lippen gewi\u00df/", "tokens": ["Bleibt", "mei\u00b7nen", "ent\u00b7z\u00fc\u00b7cke\u00b7ten", "lip\u00b7pen", "ge\u00b7wi\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "ADV", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Ach Lisilis.", "tokens": ["Ach", "Li\u00b7si\u00b7lis", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "5. Ach Lisilis hab ich dich endlich betrogen/", "tokens": ["Ach", "Li\u00b7si\u00b7lis", "hab", "ich", "dich", "end\u00b7lich", "be\u00b7tro\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "PPER", "PRF", "ADV", "VVPP", "$("], "meter": "-+-+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich habe dich dreymal gek\u00fcst/", "tokens": ["Ich", "ha\u00b7be", "dich", "drey\u00b7mal", "ge\u00b7k\u00fcst", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Und keinmal vor freuden zur\u00fccke gezogen/", "tokens": ["Und", "kein\u00b7mal", "vor", "freu\u00b7den", "zu\u00b7r\u00fc\u00b7cke", "ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVFIN", "VVPP", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Nun suche wo das fleckgen ist.", "tokens": ["Nun", "su\u00b7che", "wo", "das", "fleck\u00b7gen", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PWAV", "ART", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach halte mein l\u00e4mgen/ ach halte gewi\u00df/", "tokens": ["Ach", "hal\u00b7te", "mein", "l\u00e4m\u00b7gen", "/", "ach", "hal\u00b7te", "ge\u00b7wi\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPOSAT", "ADJA", "$(", "ADV", "VVFIN", "ADV", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Ich gebe noch einen empfindlichen bi\u00df/", "tokens": ["Ich", "ge\u00b7be", "noch", "ei\u00b7nen", "emp\u00b7find\u00b7li\u00b7chen", "bi\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "APPR", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Ach Lisilis.", "tokens": ["Ach", "Li\u00b7si\u00b7lis", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}