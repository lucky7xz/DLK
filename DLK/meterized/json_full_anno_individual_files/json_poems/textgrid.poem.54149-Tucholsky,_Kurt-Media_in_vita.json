{"textgrid.poem.54149": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Media in vita", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die l\u00e4uft rum, die mir die Augen zudr\u00fcckt:", "tokens": ["Die", "l\u00e4uft", "rum", ",", "die", "mir", "die", "Au\u00b7gen", "zu\u00b7dr\u00fcckt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKVZ", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "eine Krankenpflegerin.", "tokens": ["ei\u00b7ne", "Kran\u00b7ken\u00b7pfle\u00b7ge\u00b7rin", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ordnet noch die Fl\u00e4schchen auf dem Nachttisch,", "tokens": ["Ord\u00b7net", "noch", "die", "Fl\u00e4\u00b7schchen", "auf", "dem", "Nacht\u00b7tisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "wenn ich schon hin\u00fcber bin.", "tokens": ["wenn", "ich", "schon", "hin\u00b7\u00fc\u00b7ber", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Leise kreuzt sie meine H\u00e4nde \u00fcbern Bauch.", "tokens": ["Lei\u00b7se", "kreuzt", "sie", "mei\u00b7ne", "H\u00e4n\u00b7de", "\u00fc\u00b7bern", "Bauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Das ist ein Beruf wie andre auch.", "tokens": ["Das", "ist", "ein", "Be\u00b7ruf", "wie", "and\u00b7re", "auch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "KOKOM", "PIS", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Jeden Morgen, wenn ich mich rasiere,", "tokens": ["Je\u00b7den", "Mor\u00b7gen", ",", "wenn", "ich", "mich", "ra\u00b7sie\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "denk ich in dem Glanz des Lampenscheins,", "tokens": ["denk", "ich", "in", "dem", "Glanz", "des", "Lam\u00b7pen\u00b7scheins", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "w\u00e4hrend ich mich voller Seife schmiere:", "tokens": ["w\u00e4h\u00b7rend", "ich", "mich", "vol\u00b7ler", "Sei\u00b7fe", "schmie\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "jetzt sinds nur noch x-mal minus eins.", "tokens": ["jetzt", "sinds", "nur", "noch", "x\u00b7mal", "mi\u00b7nus", "eins", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ADV", "ADV", "PIS", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und da steh ich voller Schaum und Fr\u00f6mmigkeit,", "tokens": ["Und", "da", "steh", "ich", "vol\u00b7ler", "Schaum", "und", "Fr\u00f6m\u00b7mig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "und ich tu mir au\u00dferordentlich leid.", "tokens": ["und", "ich", "tu", "mir", "au\u00b7\u00dfer\u00b7or\u00b7dent\u00b7lich", "leid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Da, wo sich die Parallelen", "tokens": ["Da", ",", "wo", "sich", "die", "Par\u00b7al\u00b7le\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "PRF", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "schneiden, fliege ich dann hin.", "tokens": ["schnei\u00b7den", ",", "flie\u00b7ge", "ich", "dann", "hin", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, ich werde mir doch m\u00e4chtig fehlen,", "tokens": ["Ach", ",", "ich", "wer\u00b7de", "mir", "doch", "m\u00e4ch\u00b7tig", "feh\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "wenn ich einst gestorben bin,", "tokens": ["wenn", "ich", "einst", "ge\u00b7stor\u00b7ben", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Andern auch \u2013? Wer seine Augen aufmacht, sieht:", "tokens": ["An\u00b7dern", "auch", "\u2013", "?", "Wer", "sei\u00b7ne", "Au\u00b7gen", "auf\u00b7macht", ",", "sieht", ":"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJA", "ADV", "$(", "$.", "PWS", "PPOSAT", "NN", "VVPP", "$,", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Sterben ist, wie wenn man einen L\u00f6ffel aus dem Kleister zieht.", "tokens": ["Ster\u00b7ben", "ist", ",", "wie", "wenn", "man", "ei\u00b7nen", "L\u00f6f\u00b7fel", "aus", "dem", "Kleis\u00b7ter", "zieht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KOKOM", "KOUS", "PIS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.4": {"line.1": {"text": "Die l\u00e4uft rum, die mir die Augen zudr\u00fcckt:", "tokens": ["Die", "l\u00e4uft", "rum", ",", "die", "mir", "die", "Au\u00b7gen", "zu\u00b7dr\u00fcckt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKVZ", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "eine Krankenpflegerin.", "tokens": ["ei\u00b7ne", "Kran\u00b7ken\u00b7pfle\u00b7ge\u00b7rin", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ordnet noch die Fl\u00e4schchen auf dem Nachttisch,", "tokens": ["Ord\u00b7net", "noch", "die", "Fl\u00e4\u00b7schchen", "auf", "dem", "Nacht\u00b7tisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "wenn ich schon hin\u00fcber bin.", "tokens": ["wenn", "ich", "schon", "hin\u00b7\u00fc\u00b7ber", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Leise kreuzt sie meine H\u00e4nde \u00fcbern Bauch.", "tokens": ["Lei\u00b7se", "kreuzt", "sie", "mei\u00b7ne", "H\u00e4n\u00b7de", "\u00fc\u00b7bern", "Bauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Das ist ein Beruf wie andre auch.", "tokens": ["Das", "ist", "ein", "Be\u00b7ruf", "wie", "and\u00b7re", "auch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "KOKOM", "PIS", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Jeden Morgen, wenn ich mich rasiere,", "tokens": ["Je\u00b7den", "Mor\u00b7gen", ",", "wenn", "ich", "mich", "ra\u00b7sie\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "denk ich in dem Glanz des Lampenscheins,", "tokens": ["denk", "ich", "in", "dem", "Glanz", "des", "Lam\u00b7pen\u00b7scheins", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "w\u00e4hrend ich mich voller Seife schmiere:", "tokens": ["w\u00e4h\u00b7rend", "ich", "mich", "vol\u00b7ler", "Sei\u00b7fe", "schmie\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "jetzt sinds nur noch x-mal minus eins.", "tokens": ["jetzt", "sinds", "nur", "noch", "x\u00b7mal", "mi\u00b7nus", "eins", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ADV", "ADV", "PIS", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und da steh ich voller Schaum und Fr\u00f6mmigkeit,", "tokens": ["Und", "da", "steh", "ich", "vol\u00b7ler", "Schaum", "und", "Fr\u00f6m\u00b7mig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "und ich tu mir au\u00dferordentlich leid.", "tokens": ["und", "ich", "tu", "mir", "au\u00b7\u00dfer\u00b7or\u00b7dent\u00b7lich", "leid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.6": {"line.1": {"text": "Da, wo sich die Parallelen", "tokens": ["Da", ",", "wo", "sich", "die", "Par\u00b7al\u00b7le\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "PRF", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "schneiden, fliege ich dann hin.", "tokens": ["schnei\u00b7den", ",", "flie\u00b7ge", "ich", "dann", "hin", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, ich werde mir doch m\u00e4chtig fehlen,", "tokens": ["Ach", ",", "ich", "wer\u00b7de", "mir", "doch", "m\u00e4ch\u00b7tig", "feh\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "wenn ich einst gestorben bin,", "tokens": ["wenn", "ich", "einst", "ge\u00b7stor\u00b7ben", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Andern auch \u2013? Wer seine Augen aufmacht, sieht:", "tokens": ["An\u00b7dern", "auch", "\u2013", "?", "Wer", "sei\u00b7ne", "Au\u00b7gen", "auf\u00b7macht", ",", "sieht", ":"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJA", "ADV", "$(", "$.", "PWS", "PPOSAT", "NN", "VVPP", "$,", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Sterben ist, wie wenn man einen L\u00f6ffel aus dem Kleister zieht.", "tokens": ["Ster\u00b7ben", "ist", ",", "wie", "wenn", "man", "ei\u00b7nen", "L\u00f6f\u00b7fel", "aus", "dem", "Kleis\u00b7ter", "zieht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KOKOM", "KOUS", "PIS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}}}}