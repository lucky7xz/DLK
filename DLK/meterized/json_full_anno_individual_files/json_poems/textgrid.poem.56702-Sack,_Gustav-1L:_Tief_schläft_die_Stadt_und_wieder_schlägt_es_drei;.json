{"textgrid.poem.56702": {"metadata": {"author": {"name": "Sack, Gustav", "birth": "N.A.", "death": "N.A."}, "title": "1L: Tief schl\u00e4ft die Stadt und wieder schl\u00e4gt es drei;", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Tief schl\u00e4ft die Stadt und wieder schl\u00e4gt es drei;", "tokens": ["Tief", "schl\u00e4ft", "die", "Stadt", "und", "wie\u00b7der", "schl\u00e4gt", "es", "drei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "KON", "ADV", "VVFIN", "PPER", "CARD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "doch eine Ewigkeit mu\u00df noch verflie\u00dfen,", "tokens": ["doch", "ei\u00b7ne", "E\u00b7wig\u00b7keit", "mu\u00df", "noch", "ver\u00b7flie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "bis aus den feucht verhangenen Verlie\u00dfen", "tokens": ["bis", "aus", "den", "feucht", "ver\u00b7han\u00b7ge\u00b7nen", "Ver\u00b7lie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der alte lichtdurcht\u00f6nte Tag sich frei", "tokens": ["der", "al\u00b7te", "licht\u00b7durch\u00b7t\u00f6n\u00b7te", "Tag", "sich", "frei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "PRF", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "gemacht und ihn mit ihrem Morgenschrei", "tokens": ["ge\u00b7macht", "und", "ihn", "mit", "ih\u00b7rem", "Mor\u00b7gen\u00b7schrei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "KON", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die schwarzen Amseln von den D\u00e4chern gr\u00fc\u00dfen.", "tokens": ["die", "schwar\u00b7zen", "Am\u00b7seln", "von", "den", "D\u00e4\u00b7chern", "gr\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Drei N\u00e4chte \u2013 drei endlose N\u00e4chte stie\u00dfen", "tokens": ["Drei", "N\u00e4ch\u00b7te", "\u2013", "drei", "end\u00b7lo\u00b7se", "N\u00e4ch\u00b7te", "stie\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["CARD", "NN", "$(", "CARD", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "sich hohl und qualenwach an mir vorbei \u2013", "tokens": ["sich", "hohl", "und", "qua\u00b7len\u00b7wach", "an", "mir", "vor\u00b7bei", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "KON", "VVFIN", "APPR", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "doch w\u00e4hrend sie die l\u00e4ngst verharschten Wunden", "tokens": ["doch", "w\u00e4h\u00b7rend", "sie", "die", "l\u00e4ngst", "ver\u00b7harschten", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "blutig aufbrachen und im bangen Scho\u00df", "tokens": ["blu\u00b7tig", "auf\u00b7bra\u00b7chen", "und", "im", "ban\u00b7gen", "Scho\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVINF", "KON", "APPRART", "ADJA", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "der g\u00e4hnend grenzenlos gedehnten Stunden", "tokens": ["der", "g\u00e4h\u00b7nend", "gren\u00b7zen\u00b7los", "ge\u00b7dehn\u00b7ten", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "des Tages Bitternisse riesengro\u00df", "tokens": ["des", "Ta\u00b7ges", "Bit\u00b7ter\u00b7nis\u00b7se", "rie\u00b7sen\u00b7gro\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "aufbauschten, sah ich, obwohl ganz zerschunden,", "tokens": ["auf\u00b7bauschten", ",", "sah", "ich", ",", "ob\u00b7wohl", "ganz", "zer\u00b7schun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "$,", "KOUS", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "hellseherisch mein vorbestimmtes Los.", "tokens": ["hell\u00b7se\u00b7he\u00b7risch", "mein", "vor\u00b7be\u00b7stimm\u00b7tes", "Los", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.5": {"line.1": {"text": "Tief schl\u00e4ft die Stadt und wieder schl\u00e4gt es drei;", "tokens": ["Tief", "schl\u00e4ft", "die", "Stadt", "und", "wie\u00b7der", "schl\u00e4gt", "es", "drei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "KON", "ADV", "VVFIN", "PPER", "CARD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "doch eine Ewigkeit mu\u00df noch verflie\u00dfen,", "tokens": ["doch", "ei\u00b7ne", "E\u00b7wig\u00b7keit", "mu\u00df", "noch", "ver\u00b7flie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "bis aus den feucht verhangenen Verlie\u00dfen", "tokens": ["bis", "aus", "den", "feucht", "ver\u00b7han\u00b7ge\u00b7nen", "Ver\u00b7lie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der alte lichtdurcht\u00f6nte Tag sich frei", "tokens": ["der", "al\u00b7te", "licht\u00b7durch\u00b7t\u00f6n\u00b7te", "Tag", "sich", "frei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "PRF", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "gemacht und ihn mit ihrem Morgenschrei", "tokens": ["ge\u00b7macht", "und", "ihn", "mit", "ih\u00b7rem", "Mor\u00b7gen\u00b7schrei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "KON", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die schwarzen Amseln von den D\u00e4chern gr\u00fc\u00dfen.", "tokens": ["die", "schwar\u00b7zen", "Am\u00b7seln", "von", "den", "D\u00e4\u00b7chern", "gr\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Drei N\u00e4chte \u2013 drei endlose N\u00e4chte stie\u00dfen", "tokens": ["Drei", "N\u00e4ch\u00b7te", "\u2013", "drei", "end\u00b7lo\u00b7se", "N\u00e4ch\u00b7te", "stie\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["CARD", "NN", "$(", "CARD", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "sich hohl und qualenwach an mir vorbei \u2013", "tokens": ["sich", "hohl", "und", "qua\u00b7len\u00b7wach", "an", "mir", "vor\u00b7bei", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "KON", "VVFIN", "APPR", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "doch w\u00e4hrend sie die l\u00e4ngst verharschten Wunden", "tokens": ["doch", "w\u00e4h\u00b7rend", "sie", "die", "l\u00e4ngst", "ver\u00b7harschten", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "blutig aufbrachen und im bangen Scho\u00df", "tokens": ["blu\u00b7tig", "auf\u00b7bra\u00b7chen", "und", "im", "ban\u00b7gen", "Scho\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVINF", "KON", "APPRART", "ADJA", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "der g\u00e4hnend grenzenlos gedehnten Stunden", "tokens": ["der", "g\u00e4h\u00b7nend", "gren\u00b7zen\u00b7los", "ge\u00b7dehn\u00b7ten", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "des Tages Bitternisse riesengro\u00df", "tokens": ["des", "Ta\u00b7ges", "Bit\u00b7ter\u00b7nis\u00b7se", "rie\u00b7sen\u00b7gro\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "aufbauschten, sah ich, obwohl ganz zerschunden,", "tokens": ["auf\u00b7bauschten", ",", "sah", "ich", ",", "ob\u00b7wohl", "ganz", "zer\u00b7schun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "$,", "KOUS", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "hellseherisch mein vorbestimmtes Los.", "tokens": ["hell\u00b7se\u00b7he\u00b7risch", "mein", "vor\u00b7be\u00b7stimm\u00b7tes", "Los", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}}}}