{"textgrid.poem.57095": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Oliven.", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Oliven.", "tokens": ["O\u00b7li\u00b7ven", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.2": {"text": "Erst wenn der Wind euch beugt und schaudern macht,", "tokens": ["Erst", "wenn", "der", "Wind", "euch", "beugt", "und", "schau\u00b7dern", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "PPER", "VVFIN", "KON", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "enth\u00fcllt ihr eure silbernen Tiefen.", "tokens": ["ent\u00b7h\u00fcllt", "ihr", "eu\u00b7re", "sil\u00b7ber\u00b7nen", "Tie\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Zypressen.", "tokens": ["Zyp\u00b7res\u00b7sen", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.2": {"text": "Ihr lehrt mit nicht gemeinem Ma\u00df", "tokens": ["Ihr", "lehrt", "mit", "nicht", "ge\u00b7mei\u00b7nem", "Ma\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PTKNEG", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "die Dinge messen.", "tokens": ["die", "Din\u00b7ge", "mes\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Feigen.", "tokens": ["Fei\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "So sinnlich sah ich keinen zweiten Baum", "tokens": ["So", "sinn\u00b7lich", "sah", "ich", "kei\u00b7nen", "zwei\u00b7ten", "Baum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Unfa\u00dfbares umzweigen.", "tokens": ["Un\u00b7fa\u00df\u00b7ba\u00b7res", "um\u00b7zwei\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "VVIZU", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.4": {"line.1": {"text": "K\u00e4uzchenschreie.", "tokens": ["K\u00e4uz\u00b7chen\u00b7schrei\u00b7e", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Des Ungl\u00fccks Bote ruft durch stille Nacht.", "tokens": ["Des", "Un\u00b7gl\u00fccks", "Bo\u00b7te", "ruft", "durch", "stil\u00b7le", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wann kommt an uns die Reihe?", "tokens": ["Wann", "kommt", "an", "uns", "die", "Rei\u00b7he", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Mondn\u00e4chte, klare.", "tokens": ["Mond\u00b7n\u00e4ch\u00b7te", ",", "kla\u00b7re", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "In solchen N\u00e4chten stiehlt man nichts", "tokens": ["In", "sol\u00b7chen", "N\u00e4ch\u00b7ten", "stiehlt", "man", "nichts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PIS", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "denn Liebesware.", "tokens": ["denn", "Lie\u00b7bes\u00b7wa\u00b7re", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Nachtschatten.", "tokens": ["Nacht\u00b7schat\u00b7ten", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Erinnerst du dich, fernes M\u00e4dchen, noch,", "tokens": ["E\u00b7rin\u00b7nerst", "du", "dich", ",", "fer\u00b7nes", "M\u00e4d\u00b7chen", ",", "noch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "ADJA", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wie lieb wir uns einst hatten?", "tokens": ["wie", "lieb", "wir", "uns", "einst", "hat\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PRF", "ADV", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Judasb\u00e4ume.", "tokens": ["Ju\u00b7das\u00b7b\u00e4u\u00b7me", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Da\u00df ich vor euch nicht von verratner Liebe", "tokens": ["Da\u00df", "ich", "vor", "euch", "nicht", "von", "ver\u00b7rat\u00b7ner", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPER", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "tr\u00e4ume!", "tokens": ["tr\u00e4u\u00b7me", "!"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.8": {"line.1": {"text": "Verfr\u00fchter Falter.", "tokens": ["Ver\u00b7fr\u00fch\u00b7ter", "Fal\u00b7ter", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Du flogst, verwegner Geist, der Zeit voraus;", "tokens": ["Du", "flogst", ",", "ver\u00b7weg\u00b7ner", "Geist", ",", "der", "Zeit", "vo\u00b7raus", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJA", "NN", "$,", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "noch ", "tokens": ["noch"], "token_info": ["word"], "pos": ["ADV"], "meter": "-", "measure": "single.down"}}, "stanza.9": {"line.1": {"text": "Gl\u00e4nzende D\u00e4cher.", "tokens": ["Gl\u00e4n\u00b7zen\u00b7de", "D\u00e4\u00b7cher", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Im Mittagschleier ruht die Arnostadt,", "tokens": ["Im", "Mit\u00b7tag\u00b7schlei\u00b7er", "ruht", "die", "Ar\u00b7nos\u00b7tadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "ein edelsteinbesetzter F\u00e4cher.", "tokens": ["ein", "e\u00b7del\u00b7stein\u00b7be\u00b7setz\u00b7ter", "F\u00e4\u00b7cher", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Zw\u00f6lfuhr-Schu\u00df.", "tokens": ["Zw\u00f6l\u00b7fuhr\u00b7Schu\u00df", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Dem Aug' blitzt Mittag schon, indes das Ohr", "tokens": ["Dem", "Aug'", "blitzt", "Mit\u00b7tag", "schon", ",", "in\u00b7des", "das", "Ohr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NN", "ADV", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sich noch im Vormittag gedulden mu\u00df.", "tokens": ["sich", "noch", "im", "Vor\u00b7mit\u00b7tag", "ge\u00b7dul\u00b7den", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Domglocke brummt:", "tokens": ["Dom\u00b7glo\u00b7cke", "brummt", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Aus H\u00f6hn und Tiefen keine Antwort mehr:", "tokens": ["Aus", "H\u00f6hn", "und", "Tie\u00b7fen", "kei\u00b7ne", "Ant\u00b7wort", "mehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mein Gott, mein Mensch sind beide l\u00e4ngst verstummt.", "tokens": ["Mein", "Gott", ",", "mein", "Mensch", "sind", "bei\u00b7de", "l\u00e4ngst", "ver\u00b7stummt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "VAFIN", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Ihr sanften H\u00fcgelketten!", "tokens": ["Ihr", "sanf\u00b7ten", "H\u00fc\u00b7gel\u00b7ket\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Umsonst versuch' ich in mein Buch zu schaun;", "tokens": ["Um\u00b7sonst", "ver\u00b7such'", "ich", "in", "mein", "Buch", "zu", "schaun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wer k\u00f6nnte sich vor Eurer Anmut retten!", "tokens": ["wer", "k\u00f6nn\u00b7te", "sich", "vor", "Eu\u00b7rer", "An\u00b7mut", "ret\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Eidechse.", "tokens": ["Ei\u00b7dech\u00b7se", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Solang ich pfeife, h\u00e4ltst du still und horchst, \u2013", "tokens": ["So\u00b7lang", "ich", "pfei\u00b7fe", ",", "h\u00e4ltst", "du", "still", "und", "horchst", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADJD", "KON", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "doch greif' ich zu, entwischst du, kleine Hexe.", "tokens": ["doch", "greif'", "ich", "zu", ",", "ent\u00b7wischst", "du", ",", "klei\u00b7ne", "He\u00b7xe", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.14": {"line.1": {"text": "Amsel fl\u00f6tet, Biene summt,", "tokens": ["Am\u00b7sel", "fl\u00f6\u00b7tet", ",", "Bie\u00b7ne", "summt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Fr\u00fchling jubelt \u00fcber allem Leben ...", "tokens": ["Fr\u00fch\u00b7ling", "ju\u00b7belt", "\u00fc\u00b7ber", "al\u00b7lem", "Le\u00b7ben", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PIS", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Mund des Gl\u00fccks, du warst mir lang verstummt.", "tokens": ["Mund", "des", "Gl\u00fccks", ",", "du", "warst", "mir", "lang", "ver\u00b7stummt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.15": {"line.1": {"text": "O Welt!", "tokens": ["O", "Welt", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Wie gern gen\u00f6ss' ich als ein Schauspiel dich,", "tokens": ["Wie", "gern", "ge\u00b7n\u00f6\u00b7ss'", "ich", "als", "ein", "Schau\u00b7spiel", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "KOUS", "ART", "NN", "PPER", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "von halber H\u00f6h', nur locker dir gesellt.", "tokens": ["von", "hal\u00b7ber", "H\u00f6h'", ",", "nur", "lo\u00b7cker", "dir", "ge\u00b7sellt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADV", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Von halber H\u00f6h' \u2013 ein Adel, der mir pa\u00dft.", "tokens": ["Von", "hal\u00b7ber", "H\u00f6h'", "\u2013", "ein", "A\u00b7del", ",", "der", "mir", "pa\u00dft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$(", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So lebt' ich immer, zwischen Tier und Gott,", "tokens": ["So", "lebt'", "ich", "im\u00b7mer", ",", "zwi\u00b7schen", "Tier", "und", "Gott", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "halb Mensch, halb Vogel, zweier Reiche Gast.", "tokens": ["halb", "Mensch", ",", "halb", "Vo\u00b7gel", ",", "zwei\u00b7er", "Rei\u00b7che", "Gast", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "ADJD", "NE", "$,", "ADJA", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Glanzgrauer Tag.", "tokens": ["Glanz\u00b7grau\u00b7er", "Tag", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Aus deinem Taft soll man die Flagge machen,", "tokens": ["Aus", "dei\u00b7nem", "Taft", "soll", "man", "die", "Flag\u00b7ge", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PIS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "darin man mich dereinst begraben mag.", "tokens": ["da\u00b7rin", "man", "mich", "de\u00b7reinst", "be\u00b7gra\u00b7ben", "mag."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["PAV", "PIS", "PRF", "ADV", "VVPP", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Der Freund schreibt:", "tokens": ["Der", "Freund", "schreibt", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Des Herzens unverwandte Einsamkeit,", "tokens": ["Des", "Her\u00b7zens", "un\u00b7ver\u00b7wand\u00b7te", "Ein\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "du f\u00fchlst sie auch \u2013 und wie sie nichts vertreibt.", "tokens": ["du", "f\u00fchlst", "sie", "auch", "\u2013", "und", "wie", "sie", "nichts", "ver\u00b7treibt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$(", "KON", "PWAV", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Mohn im Winde.", "tokens": ["Mohn", "im", "Win\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "So neigen wir uns gl\u00fchend geneinander, \u2013", "tokens": ["So", "nei\u00b7gen", "wir", "uns", "gl\u00fc\u00b7hend", "ge\u00b7nein\u00b7an\u00b7der", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "ADJA", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "doch nie wird zwei zu eins \u2013 als einst im Kinde.", "tokens": ["doch", "nie", "wird", "zwei", "zu", "eins", "\u2013", "als", "einst", "im", "Kin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "CARD", "APPR", "PIS", "$(", "KOKOM", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Epheuranke.", "tokens": ["E\u00b7pheu\u00b7ran\u00b7ke", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "--+-", "measure": "anapaest.init"}, "line.2": {"text": "So reich verkleidet Tr\u00fcmmer und Zerfall", "tokens": ["So", "reich", "ver\u00b7klei\u00b7det", "Tr\u00fcm\u00b7mer", "und", "Zer\u00b7fall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVPP", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "nur Eins noch: der Gedanke.", "tokens": ["nur", "Eins", "noch", ":", "der", "Ge\u00b7dan\u00b7ke", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "$.", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Die F\u00fcnfuhr-Glocke ruft durch bleiche Nacht:", "tokens": ["Die", "F\u00fcnf\u00b7uhr\u00b7Glo\u00b7cke", "ruft", "durch", "blei\u00b7che", "Nacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wer schl\u00e4ft, wach' auf, und wer da wacht, schlaf' ein;", "tokens": ["Wer", "schl\u00e4ft", ",", "wach'", "auf", ",", "und", "wer", "da", "wacht", ",", "schlaf'", "ein", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "VVFIN", "PTKVZ", "$,", "KON", "PWS", "ADV", "VVFIN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so hab' ich jedem, was ihm frommt, gebracht.", "tokens": ["so", "hab'", "ich", "je\u00b7dem", ",", "was", "ihm", "frommt", ",", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Morgenhauch.", "tokens": ["Mor\u00b7gen\u00b7hauch", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Aus Bett und Haust\u00fcr ziehst du mich hinaus,", "tokens": ["Aus", "Bett", "und", "Haus\u00b7t\u00fcr", "ziehst", "du", "mich", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "PRF", "APZR", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wie aus der Esse den verschlafnen Rauch.", "tokens": ["wie", "aus", "der", "Es\u00b7se", "den", "ver\u00b7schlaf\u00b7nen", "Rauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.23": {"line.1": {"text": "Giottos Grabschrift von Polizian.", "tokens": ["Giot\u00b7tos", "Grab\u00b7schrift", "von", "Po\u00b7li\u00b7zi\u00b7an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "NE", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Zwiefacher Hauch der Vorzeit traf uns voll,", "tokens": ["Zwie\u00b7fac\u00b7her", "Hauch", "der", "Vor\u00b7zeit", "traf", "uns", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "als wir im Dom die stolzen Verse sahn.", "tokens": ["als", "wir", "im", "Dom", "die", "stol\u00b7zen", "Ver\u00b7se", "sahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "In meinem Burckhardt w\u00fchlt emp\u00f6rt der Sturm:", "tokens": ["In", "mei\u00b7nem", "Burck\u00b7hardt", "w\u00fchlt", "em\u00b7p\u00f6rt", "der", "Sturm", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So war es einst, so soll es wieder sein!", "tokens": ["So", "war", "es", "einst", ",", "so", "soll", "es", "wie\u00b7der", "sein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$,", "ADV", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das gafft nur, schafft nicht mehr um Giottos Turm.", "tokens": ["Das", "gafft", "nur", ",", "schafft", "nicht", "mehr", "um", "Giot\u00b7tos", "Turm", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$,", "VVFIN", "PTKNEG", "ADV", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Kaum mehr erhoffte Tage!", "tokens": ["Kaum", "mehr", "er\u00b7hoff\u00b7te", "Ta\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit drei\u00dfig Jahren fand ich eine Stadt,", "tokens": ["Mit", "drei\u00b7\u00dfig", "Jah\u00b7ren", "fand", "ich", "ei\u00b7ne", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "zu deren Bild ich ja und Amen sage.", "tokens": ["zu", "de\u00b7ren", "Bild", "ich", "ja", "und", "A\u00b7men", "sa\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "ADV", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Oliven.", "tokens": ["O\u00b7li\u00b7ven", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.2": {"text": "Erst wenn der Wind euch beugt und schaudern macht,", "tokens": ["Erst", "wenn", "der", "Wind", "euch", "beugt", "und", "schau\u00b7dern", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "PPER", "VVFIN", "KON", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "enth\u00fcllt ihr eure silbernen Tiefen.", "tokens": ["ent\u00b7h\u00fcllt", "ihr", "eu\u00b7re", "sil\u00b7ber\u00b7nen", "Tie\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.27": {"line.1": {"text": "Zypressen.", "tokens": ["Zyp\u00b7res\u00b7sen", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.2": {"text": "Ihr lehrt mit nicht gemeinem Ma\u00df", "tokens": ["Ihr", "lehrt", "mit", "nicht", "ge\u00b7mei\u00b7nem", "Ma\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PTKNEG", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "die Dinge messen.", "tokens": ["die", "Din\u00b7ge", "mes\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.28": {"line.1": {"text": "Feigen.", "tokens": ["Fei\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "So sinnlich sah ich keinen zweiten Baum", "tokens": ["So", "sinn\u00b7lich", "sah", "ich", "kei\u00b7nen", "zwei\u00b7ten", "Baum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Unfa\u00dfbares umzweigen.", "tokens": ["Un\u00b7fa\u00df\u00b7ba\u00b7res", "um\u00b7zwei\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "VVIZU", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.29": {"line.1": {"text": "K\u00e4uzchenschreie.", "tokens": ["K\u00e4uz\u00b7chen\u00b7schrei\u00b7e", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Des Ungl\u00fccks Bote ruft durch stille Nacht.", "tokens": ["Des", "Un\u00b7gl\u00fccks", "Bo\u00b7te", "ruft", "durch", "stil\u00b7le", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wann kommt an uns die Reihe?", "tokens": ["Wann", "kommt", "an", "uns", "die", "Rei\u00b7he", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Mondn\u00e4chte, klare.", "tokens": ["Mond\u00b7n\u00e4ch\u00b7te", ",", "kla\u00b7re", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "In solchen N\u00e4chten stiehlt man nichts", "tokens": ["In", "sol\u00b7chen", "N\u00e4ch\u00b7ten", "stiehlt", "man", "nichts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PIS", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "denn Liebesware.", "tokens": ["denn", "Lie\u00b7bes\u00b7wa\u00b7re", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.31": {"line.1": {"text": "Nachtschatten.", "tokens": ["Nacht\u00b7schat\u00b7ten", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Erinnerst du dich, fernes M\u00e4dchen, noch,", "tokens": ["E\u00b7rin\u00b7nerst", "du", "dich", ",", "fer\u00b7nes", "M\u00e4d\u00b7chen", ",", "noch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "ADJA", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wie lieb wir uns einst hatten?", "tokens": ["wie", "lieb", "wir", "uns", "einst", "hat\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PRF", "ADV", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Judasb\u00e4ume.", "tokens": ["Ju\u00b7das\u00b7b\u00e4u\u00b7me", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Da\u00df ich vor euch nicht von verratner Liebe", "tokens": ["Da\u00df", "ich", "vor", "euch", "nicht", "von", "ver\u00b7rat\u00b7ner", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPER", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "tr\u00e4ume!", "tokens": ["tr\u00e4u\u00b7me", "!"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.33": {"line.1": {"text": "Verfr\u00fchter Falter.", "tokens": ["Ver\u00b7fr\u00fch\u00b7ter", "Fal\u00b7ter", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Du flogst, verwegner Geist, der Zeit voraus;", "tokens": ["Du", "flogst", ",", "ver\u00b7weg\u00b7ner", "Geist", ",", "der", "Zeit", "vo\u00b7raus", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJA", "NN", "$,", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "noch ", "tokens": ["noch"], "token_info": ["word"], "pos": ["ADV"], "meter": "-", "measure": "single.down"}}, "stanza.34": {"line.1": {"text": "Gl\u00e4nzende D\u00e4cher.", "tokens": ["Gl\u00e4n\u00b7zen\u00b7de", "D\u00e4\u00b7cher", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Im Mittagschleier ruht die Arnostadt,", "tokens": ["Im", "Mit\u00b7tag\u00b7schlei\u00b7er", "ruht", "die", "Ar\u00b7nos\u00b7tadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "ein edelsteinbesetzter F\u00e4cher.", "tokens": ["ein", "e\u00b7del\u00b7stein\u00b7be\u00b7setz\u00b7ter", "F\u00e4\u00b7cher", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Zw\u00f6lfuhr-Schu\u00df.", "tokens": ["Zw\u00f6l\u00b7fuhr\u00b7Schu\u00df", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Dem Aug' blitzt Mittag schon, indes das Ohr", "tokens": ["Dem", "Aug'", "blitzt", "Mit\u00b7tag", "schon", ",", "in\u00b7des", "das", "Ohr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NN", "ADV", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sich noch im Vormittag gedulden mu\u00df.", "tokens": ["sich", "noch", "im", "Vor\u00b7mit\u00b7tag", "ge\u00b7dul\u00b7den", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.36": {"line.1": {"text": "Domglocke brummt:", "tokens": ["Dom\u00b7glo\u00b7cke", "brummt", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Aus H\u00f6hn und Tiefen keine Antwort mehr:", "tokens": ["Aus", "H\u00f6hn", "und", "Tie\u00b7fen", "kei\u00b7ne", "Ant\u00b7wort", "mehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mein Gott, mein Mensch sind beide l\u00e4ngst verstummt.", "tokens": ["Mein", "Gott", ",", "mein", "Mensch", "sind", "bei\u00b7de", "l\u00e4ngst", "ver\u00b7stummt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "VAFIN", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.37": {"line.1": {"text": "Ihr sanften H\u00fcgelketten!", "tokens": ["Ihr", "sanf\u00b7ten", "H\u00fc\u00b7gel\u00b7ket\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Umsonst versuch' ich in mein Buch zu schaun;", "tokens": ["Um\u00b7sonst", "ver\u00b7such'", "ich", "in", "mein", "Buch", "zu", "schaun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wer k\u00f6nnte sich vor Eurer Anmut retten!", "tokens": ["wer", "k\u00f6nn\u00b7te", "sich", "vor", "Eu\u00b7rer", "An\u00b7mut", "ret\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.38": {"line.1": {"text": "Eidechse.", "tokens": ["Ei\u00b7dech\u00b7se", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Solang ich pfeife, h\u00e4ltst du still und horchst, \u2013", "tokens": ["So\u00b7lang", "ich", "pfei\u00b7fe", ",", "h\u00e4ltst", "du", "still", "und", "horchst", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADJD", "KON", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "doch greif' ich zu, entwischst du, kleine Hexe.", "tokens": ["doch", "greif'", "ich", "zu", ",", "ent\u00b7wischst", "du", ",", "klei\u00b7ne", "He\u00b7xe", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.39": {"line.1": {"text": "Amsel fl\u00f6tet, Biene summt,", "tokens": ["Am\u00b7sel", "fl\u00f6\u00b7tet", ",", "Bie\u00b7ne", "summt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Fr\u00fchling jubelt \u00fcber allem Leben ...", "tokens": ["Fr\u00fch\u00b7ling", "ju\u00b7belt", "\u00fc\u00b7ber", "al\u00b7lem", "Le\u00b7ben", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PIS", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Mund des Gl\u00fccks, du warst mir lang verstummt.", "tokens": ["Mund", "des", "Gl\u00fccks", ",", "du", "warst", "mir", "lang", "ver\u00b7stummt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.40": {"line.1": {"text": "O Welt!", "tokens": ["O", "Welt", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Wie gern gen\u00f6ss' ich als ein Schauspiel dich,", "tokens": ["Wie", "gern", "ge\u00b7n\u00f6\u00b7ss'", "ich", "als", "ein", "Schau\u00b7spiel", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "KOUS", "ART", "NN", "PPER", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "von halber H\u00f6h', nur locker dir gesellt.", "tokens": ["von", "hal\u00b7ber", "H\u00f6h'", ",", "nur", "lo\u00b7cker", "dir", "ge\u00b7sellt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADV", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.41": {"line.1": {"text": "Von halber H\u00f6h' \u2013 ein Adel, der mir pa\u00dft.", "tokens": ["Von", "hal\u00b7ber", "H\u00f6h'", "\u2013", "ein", "A\u00b7del", ",", "der", "mir", "pa\u00dft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$(", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So lebt' ich immer, zwischen Tier und Gott,", "tokens": ["So", "lebt'", "ich", "im\u00b7mer", ",", "zwi\u00b7schen", "Tier", "und", "Gott", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "halb Mensch, halb Vogel, zweier Reiche Gast.", "tokens": ["halb", "Mensch", ",", "halb", "Vo\u00b7gel", ",", "zwei\u00b7er", "Rei\u00b7che", "Gast", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "ADJD", "NE", "$,", "ADJA", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.42": {"line.1": {"text": "Glanzgrauer Tag.", "tokens": ["Glanz\u00b7grau\u00b7er", "Tag", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Aus deinem Taft soll man die Flagge machen,", "tokens": ["Aus", "dei\u00b7nem", "Taft", "soll", "man", "die", "Flag\u00b7ge", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PIS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "darin man mich dereinst begraben mag.", "tokens": ["da\u00b7rin", "man", "mich", "de\u00b7reinst", "be\u00b7gra\u00b7ben", "mag."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["PAV", "PIS", "PRF", "ADV", "VVPP", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Der Freund schreibt:", "tokens": ["Der", "Freund", "schreibt", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Des Herzens unverwandte Einsamkeit,", "tokens": ["Des", "Her\u00b7zens", "un\u00b7ver\u00b7wand\u00b7te", "Ein\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "du f\u00fchlst sie auch \u2013 und wie sie nichts vertreibt.", "tokens": ["du", "f\u00fchlst", "sie", "auch", "\u2013", "und", "wie", "sie", "nichts", "ver\u00b7treibt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$(", "KON", "PWAV", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.44": {"line.1": {"text": "Mohn im Winde.", "tokens": ["Mohn", "im", "Win\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "So neigen wir uns gl\u00fchend geneinander, \u2013", "tokens": ["So", "nei\u00b7gen", "wir", "uns", "gl\u00fc\u00b7hend", "ge\u00b7nein\u00b7an\u00b7der", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "ADJA", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "doch nie wird zwei zu eins \u2013 als einst im Kinde.", "tokens": ["doch", "nie", "wird", "zwei", "zu", "eins", "\u2013", "als", "einst", "im", "Kin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "CARD", "APPR", "PIS", "$(", "KOKOM", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.45": {"line.1": {"text": "Epheuranke.", "tokens": ["E\u00b7pheu\u00b7ran\u00b7ke", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "--+-", "measure": "anapaest.init"}, "line.2": {"text": "So reich verkleidet Tr\u00fcmmer und Zerfall", "tokens": ["So", "reich", "ver\u00b7klei\u00b7det", "Tr\u00fcm\u00b7mer", "und", "Zer\u00b7fall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVPP", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "nur Eins noch: der Gedanke.", "tokens": ["nur", "Eins", "noch", ":", "der", "Ge\u00b7dan\u00b7ke", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "$.", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.46": {"line.1": {"text": "Die F\u00fcnfuhr-Glocke ruft durch bleiche Nacht:", "tokens": ["Die", "F\u00fcnf\u00b7uhr\u00b7Glo\u00b7cke", "ruft", "durch", "blei\u00b7che", "Nacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wer schl\u00e4ft, wach' auf, und wer da wacht, schlaf' ein;", "tokens": ["Wer", "schl\u00e4ft", ",", "wach'", "auf", ",", "und", "wer", "da", "wacht", ",", "schlaf'", "ein", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "VVFIN", "PTKVZ", "$,", "KON", "PWS", "ADV", "VVFIN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so hab' ich jedem, was ihm frommt, gebracht.", "tokens": ["so", "hab'", "ich", "je\u00b7dem", ",", "was", "ihm", "frommt", ",", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.47": {"line.1": {"text": "Morgenhauch.", "tokens": ["Mor\u00b7gen\u00b7hauch", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Aus Bett und Haust\u00fcr ziehst du mich hinaus,", "tokens": ["Aus", "Bett", "und", "Haus\u00b7t\u00fcr", "ziehst", "du", "mich", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "PRF", "APZR", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wie aus der Esse den verschlafnen Rauch.", "tokens": ["wie", "aus", "der", "Es\u00b7se", "den", "ver\u00b7schlaf\u00b7nen", "Rauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.48": {"line.1": {"text": "Giottos Grabschrift von Polizian.", "tokens": ["Giot\u00b7tos", "Grab\u00b7schrift", "von", "Po\u00b7li\u00b7zi\u00b7an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "NE", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Zwiefacher Hauch der Vorzeit traf uns voll,", "tokens": ["Zwie\u00b7fac\u00b7her", "Hauch", "der", "Vor\u00b7zeit", "traf", "uns", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "als wir im Dom die stolzen Verse sahn.", "tokens": ["als", "wir", "im", "Dom", "die", "stol\u00b7zen", "Ver\u00b7se", "sahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.49": {"line.1": {"text": "In meinem Burckhardt w\u00fchlt emp\u00f6rt der Sturm:", "tokens": ["In", "mei\u00b7nem", "Burck\u00b7hardt", "w\u00fchlt", "em\u00b7p\u00f6rt", "der", "Sturm", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So war es einst, so soll es wieder sein!", "tokens": ["So", "war", "es", "einst", ",", "so", "soll", "es", "wie\u00b7der", "sein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$,", "ADV", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das gafft nur, schafft nicht mehr um Giottos Turm.", "tokens": ["Das", "gafft", "nur", ",", "schafft", "nicht", "mehr", "um", "Giot\u00b7tos", "Turm", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$,", "VVFIN", "PTKNEG", "ADV", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.50": {"line.1": {"text": "Kaum mehr erhoffte Tage!", "tokens": ["Kaum", "mehr", "er\u00b7hoff\u00b7te", "Ta\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit drei\u00dfig Jahren fand ich eine Stadt,", "tokens": ["Mit", "drei\u00b7\u00dfig", "Jah\u00b7ren", "fand", "ich", "ei\u00b7ne", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "zu deren Bild ich ja und Amen sage.", "tokens": ["zu", "de\u00b7ren", "Bild", "ich", "ja", "und", "A\u00b7men", "sa\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "ADV", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}