{"textgrid.poem.25716": {"metadata": {"author": {"name": "Goeckingk, Leopold Friedrich G\u00fcnther von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich bin doch wohl ein rechter Thor,", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin doch wohl ein rechter Thor,", "tokens": ["Ich", "bin", "doch", "wohl", "ein", "rech\u00b7ter", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was auff\u00e4llt, so zu meiden!", "tokens": ["Was", "auf\u00b7f\u00e4llt", ",", "so", "zu", "mei\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mich nicht durch irgend etwas, vor", "tokens": ["Mich", "nicht", "durch", "ir\u00b7gend", "et\u00b7was", ",", "vor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "PTKNEG", "APPR", "ADV", "PIS", "$,", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Welt zu unterscheiden,", "tokens": ["Der", "Welt", "zu", "un\u00b7ter\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So schlecht und recht, fast wie ein Tropf,", "tokens": ["So", "schlecht", "und", "recht", ",", "fast", "wie", "ein", "Tropf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$,", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Nase nachzuschleichen,", "tokens": ["Der", "Na\u00b7se", "nach\u00b7zu\u00b7schlei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und jedem, wenn's mit seinem Kopf'", "tokens": ["Und", "je\u00b7dem", ",", "wenn's", "mit", "sei\u00b7nem", "Kopf'"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PIS", "$,", "KOUS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nur richtig ist, zu gleichen.", "tokens": ["Nur", "rich\u00b7tig", "ist", ",", "zu", "glei\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Gebt aber Acht! Man soll, im Fall'", "tokens": ["Gebt", "a\u00b7ber", "Acht", "!", "Man", "soll", ",", "im", "Fall'"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "ADV", "CARD", "$.", "PIS", "VMFIN", "$,", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mir Witz und Gl\u00fcck nicht fehlen,", "tokens": ["Mir", "Witz", "und", "Gl\u00fcck", "nicht", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "In kurzer Zeit wohl \u00fcberall", "tokens": ["In", "kur\u00b7zer", "Zeit", "wohl", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "So viel von mir erz\u00e4hlen,", "tokens": ["So", "viel", "von", "mir", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Da\u00df Fremde, zwanzig Meilen weit,", "tokens": ["Da\u00df", "Frem\u00b7de", ",", "zwan\u00b7zig", "Mei\u00b7len", "weit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Mit Wagen und mit Pferden,", "tokens": ["Mit", "Wa\u00b7gen", "und", "mit", "Pfer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Um mich zu sehn, mich Seltenheit,", "tokens": ["Um", "mich", "zu", "sehn", ",", "mich", "Sel\u00b7ten\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PPER", "PTKZU", "VVINF", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Nach ", "tokens": ["Nach"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.17": {"text": "Wer wird dann Schachte noch besehn?", "tokens": ["Wer", "wird", "dann", "Schach\u00b7te", "noch", "be\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Wer H\u00fctten? Keine Seele!", "tokens": ["Wer", "H\u00fct\u00b7ten", "?", "Kei\u00b7ne", "See\u00b7le", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Ver\u00f6det wird der Brocken stehn,", "tokens": ["Ver\u00b7\u00f6\u00b7det", "wird", "der", "Bro\u00b7cken", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Und leer die Baumannsh\u00f6hle.", "tokens": ["Und", "leer", "die", "Bau\u00b7manns\u00b7h\u00f6h\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Wer mich sah liegen, stehn und gehn,", "tokens": ["Wer", "mich", "sah", "lie\u00b7gen", ",", "stehn", "und", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "VVFIN", "$,", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "(zeigt das mein Bild von ", "tokens": ["(", "zeigt", "das", "mein", "Bild", "von"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "ART", "PPOSAT", "NN", "APPR"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.23": {"text": "Der hat f\u00fcrwahr genug gesehn,", "tokens": ["Der", "hat", "f\u00fcr\u00b7wahr", "ge\u00b7nug", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Und f\u00fchlet stracks sich weiser.", "tokens": ["Und", "f\u00fch\u00b7let", "stracks", "sich", "wei\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PRF", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.25": {"text": "Denn alle Schnellkraft der Genies", "tokens": ["Denn", "al\u00b7le", "Schnell\u00b7kraft", "der", "Ge\u00b7nies"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Will ich in mir vereinen;", "tokens": ["Will", "ich", "in", "mir", "ver\u00b7ei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.27": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.28": {"text": "Will ich verschrein, verneinen;", "tokens": ["Will", "ich", "ver\u00b7schrein", ",", "ver\u00b7nei\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKVZ", "$,", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.29": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.30": {"text": "Laut preisen, grob bejahen,", "tokens": ["Laut", "prei\u00b7sen", ",", "grob", "be\u00b7ja\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "$,", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.31": {"text": "Und kurz, ", "tokens": ["Und", "kurz", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADJD", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.32": {"text": "Und morgen ", "tokens": ["Und", "mor\u00b7gen"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.33": {"text": "Die Sprach' \u2013 kommt mir ein Drang, ein' Grill' \u2013", "tokens": ["Die", "Sprach'", "\u2013", "kommt", "mir", "ein", "Drang", ",", "ein'", "Grill'", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "VVFIN", "PPER", "ART", "NN", "$,", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Verhunzen werd', verdrehen,", "tokens": ["Ver\u00b7hun\u00b7zen", "werd'", ",", "ver\u00b7dre\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.35": {"text": "Soll, traun! schier der 's verstehn mir will,", "tokens": ["Soll", ",", "traun", "!", "schier", "der", "'s", "ver\u00b7stehn", "mir", "will", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "VVINF", "$.", "ADV", "ART", "PPER", "VVFIN", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.36": {"text": "Gleich'n Hahn nach'm Morg'nlicht kr\u00e4hen.", "tokens": ["Gleich'n", "Hahn", "nach'm", "Mor\u00b7g'\u00b7nlicht", "kr\u00e4\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.37": {"text": "Und w\u00e4re noch die Eselin", "tokens": ["Und", "w\u00e4\u00b7re", "noch", "die", "E\u00b7se\u00b7lin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Von Bileam am Leben:", "tokens": ["Von", "Bi\u00b7leam", "am", "Le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.39": {"text": "Schrein sollte sie: J-A! darin", "tokens": ["Schrein", "soll\u00b7te", "sie", ":", "J\u00b7A", "!", "da\u00b7rin"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["NN", "VMFIN", "PPER", "$.", "NE", "$.", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Ist Kraft und Drang und Streben!", "tokens": ["Ist", "Kraft", "und", "Drang", "und", "Stre\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.41": {"text": "Ich nehme, wenn's die Obrigkeit", "tokens": ["Ich", "neh\u00b7me", ",", "wenn's", "die", "Ob\u00b7rig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Erlauben will, zwei Frauen,", "tokens": ["Er\u00b7lau\u00b7ben", "will", ",", "zwei", "Frau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$,", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.43": {"text": "Und lasse der Empfindsamkeit", "tokens": ["Und", "las\u00b7se", "der", "Emp\u00b7find\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Capell' und Altar bauen.", "tokens": ["Ca\u00b7pell'", "und", "Al\u00b7tar", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.45": {"text": "Zum Priester wird sich, wie bekannt,", "tokens": ["Zum", "Pries\u00b7ter", "wird", "sich", ",", "wie", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PRF", "$,", "PWAV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "Herr ", "tokens": ["Herr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.47": {"text": "Dem la\u00df ich denn ein Me\u00dfgewand", "tokens": ["Dem", "la\u00df", "ich", "denn", "ein", "Me\u00df\u00b7ge\u00b7wand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "Von Gold und Perlen sticken.", "tokens": ["Von", "Gold", "und", "Per\u00b7len", "sti\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.49": {"text": "Doch, ich Patronus, merkt das wohl!", "tokens": ["Doch", ",", "ich", "Pat\u00b7ro\u00b7nus", ",", "merkt", "das", "wohl", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPER", "NE", "$,", "VVFIN", "PDS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "Geh' im zerri\u00dfnen Kittel,", "tokens": ["Geh'", "im", "zer\u00b7ri\u00df\u00b7nen", "Kit\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.51": {"text": "Hab' aber alle Taschen voll", "tokens": ["Hab'", "a\u00b7ber", "al\u00b7le", "Ta\u00b7schen", "voll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "Yorikischer Capittel.", "tokens": ["Y\u00b7o\u00b7ri\u00b7ki\u00b7scher", "Ca\u00b7pit\u00b7tel", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.53": {"text": "Doch la\u00df ich, wenn mir's Kurzweil schafft,", "tokens": ["Doch", "la\u00df", "ich", ",", "wenn", "mir's", "Kurz\u00b7weil", "schafft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "$,", "KOUS", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.54": {"text": "Die H\u00fclfe fleh'nden Armen,", "tokens": ["Die", "H\u00fcl\u00b7fe", "fleh'n\u00b7den", "Ar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.55": {"text": "Durch meinen Schweitzer, ", "tokens": ["Durch", "mei\u00b7nen", "Schweit\u00b7zer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.56": {"text": "Zerpr\u00fcgeln oh'n Erbarmen.", "tokens": ["Zer\u00b7pr\u00fc\u00b7geln", "oh'n", "Er\u00b7bar\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.57": {"text": "Scheint eine Physiognomie", "tokens": ["Scheint", "ei\u00b7ne", "Phy\u00b7si\u00b7og\u00b7no\u00b7mie"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Mir neu von Bau und Falten,", "tokens": ["Mir", "neu", "von", "Bau", "und", "Fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.59": {"text": "So frag' ich nicht: \u00bbHerr! wollen Sie?\u00ab", "tokens": ["So", "frag'", "ich", "nicht", ":", "\u00bb", "Herr", "!", "wol\u00b7len", "Sie", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "NN", "$.", "VMFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.60": {"text": "Bis ", "tokens": ["Bis"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.61": {"text": "Gesicht mir lasse kommen,", "tokens": ["Ge\u00b7sicht", "mir", "las\u00b7se", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.62": {"text": "Den sonderbaren Schattenri\u00df", "tokens": ["Den", "son\u00b7der\u00b7ba\u00b7ren", "Schat\u00b7ten\u00b7ri\u00df"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.63": {"text": "F\u00fcr mich hat aufgenommen.", "tokens": ["F\u00fcr", "mich", "hat", "auf\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.64": {"text": "F\u00e4llt mir es ein, so kann ich ja", "tokens": ["F\u00e4llt", "mir", "es", "ein", ",", "so", "kann", "ich", "ja"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "PTKVZ", "$,", "ADV", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "Wohl auch nach Hofe gehen;", "tokens": ["Wohl", "auch", "nach", "Ho\u00b7fe", "ge\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.66": {"text": "In aller Absicht werd' ich da", "tokens": ["In", "al\u00b7ler", "Ab\u00b7sicht", "werd'", "ich", "da"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Mich gar nicht \u00fcbel stehen;", "tokens": ["Mich", "gar", "nicht", "\u00fc\u00b7bel", "ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.68": {"text": "Denn Bischoff und Champagner Wein", "tokens": ["Denn", "Bi\u00b7schoff", "und", "Cham\u00b7pag\u00b7ner", "Wein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.69": {"text": "Kann ich wie Wasser saufen,", "tokens": ["Kann", "ich", "wie", "Was\u00b7ser", "sau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.70": {"text": "Und, werfen Nachts wir Fenster ein,", "tokens": ["Und", ",", "wer\u00b7fen", "Nachts", "wir", "Fens\u00b7ter", "ein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "ADV", "PPER", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "Gewi\u00df am schnellsten laufen.", "tokens": ["Ge\u00b7wi\u00df", "am", "schnells\u00b7ten", "lau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ich bin doch wohl ein rechter Thor,", "tokens": ["Ich", "bin", "doch", "wohl", "ein", "rech\u00b7ter", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was auff\u00e4llt, so zu meiden!", "tokens": ["Was", "auf\u00b7f\u00e4llt", ",", "so", "zu", "mei\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mich nicht durch irgend etwas, vor", "tokens": ["Mich", "nicht", "durch", "ir\u00b7gend", "et\u00b7was", ",", "vor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "PTKNEG", "APPR", "ADV", "PIS", "$,", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Welt zu unterscheiden,", "tokens": ["Der", "Welt", "zu", "un\u00b7ter\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So schlecht und recht, fast wie ein Tropf,", "tokens": ["So", "schlecht", "und", "recht", ",", "fast", "wie", "ein", "Tropf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$,", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Nase nachzuschleichen,", "tokens": ["Der", "Na\u00b7se", "nach\u00b7zu\u00b7schlei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und jedem, wenn's mit seinem Kopf'", "tokens": ["Und", "je\u00b7dem", ",", "wenn's", "mit", "sei\u00b7nem", "Kopf'"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PIS", "$,", "KOUS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nur richtig ist, zu gleichen.", "tokens": ["Nur", "rich\u00b7tig", "ist", ",", "zu", "glei\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Gebt aber Acht! Man soll, im Fall'", "tokens": ["Gebt", "a\u00b7ber", "Acht", "!", "Man", "soll", ",", "im", "Fall'"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "ADV", "CARD", "$.", "PIS", "VMFIN", "$,", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mir Witz und Gl\u00fcck nicht fehlen,", "tokens": ["Mir", "Witz", "und", "Gl\u00fcck", "nicht", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "In kurzer Zeit wohl \u00fcberall", "tokens": ["In", "kur\u00b7zer", "Zeit", "wohl", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "So viel von mir erz\u00e4hlen,", "tokens": ["So", "viel", "von", "mir", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Da\u00df Fremde, zwanzig Meilen weit,", "tokens": ["Da\u00df", "Frem\u00b7de", ",", "zwan\u00b7zig", "Mei\u00b7len", "weit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Mit Wagen und mit Pferden,", "tokens": ["Mit", "Wa\u00b7gen", "und", "mit", "Pfer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Um mich zu sehn, mich Seltenheit,", "tokens": ["Um", "mich", "zu", "sehn", ",", "mich", "Sel\u00b7ten\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PPER", "PTKZU", "VVINF", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Nach ", "tokens": ["Nach"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.17": {"text": "Wer wird dann Schachte noch besehn?", "tokens": ["Wer", "wird", "dann", "Schach\u00b7te", "noch", "be\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Wer H\u00fctten? Keine Seele!", "tokens": ["Wer", "H\u00fct\u00b7ten", "?", "Kei\u00b7ne", "See\u00b7le", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Ver\u00f6det wird der Brocken stehn,", "tokens": ["Ver\u00b7\u00f6\u00b7det", "wird", "der", "Bro\u00b7cken", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Und leer die Baumannsh\u00f6hle.", "tokens": ["Und", "leer", "die", "Bau\u00b7manns\u00b7h\u00f6h\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Wer mich sah liegen, stehn und gehn,", "tokens": ["Wer", "mich", "sah", "lie\u00b7gen", ",", "stehn", "und", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "VVFIN", "$,", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "(zeigt das mein Bild von ", "tokens": ["(", "zeigt", "das", "mein", "Bild", "von"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "ART", "PPOSAT", "NN", "APPR"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.23": {"text": "Der hat f\u00fcrwahr genug gesehn,", "tokens": ["Der", "hat", "f\u00fcr\u00b7wahr", "ge\u00b7nug", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Und f\u00fchlet stracks sich weiser.", "tokens": ["Und", "f\u00fch\u00b7let", "stracks", "sich", "wei\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PRF", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.25": {"text": "Denn alle Schnellkraft der Genies", "tokens": ["Denn", "al\u00b7le", "Schnell\u00b7kraft", "der", "Ge\u00b7nies"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Will ich in mir vereinen;", "tokens": ["Will", "ich", "in", "mir", "ver\u00b7ei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.27": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.28": {"text": "Will ich verschrein, verneinen;", "tokens": ["Will", "ich", "ver\u00b7schrein", ",", "ver\u00b7nei\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKVZ", "$,", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.29": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.30": {"text": "Laut preisen, grob bejahen,", "tokens": ["Laut", "prei\u00b7sen", ",", "grob", "be\u00b7ja\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "$,", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.31": {"text": "Und kurz, ", "tokens": ["Und", "kurz", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADJD", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.32": {"text": "Und morgen ", "tokens": ["Und", "mor\u00b7gen"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.33": {"text": "Die Sprach' \u2013 kommt mir ein Drang, ein' Grill' \u2013", "tokens": ["Die", "Sprach'", "\u2013", "kommt", "mir", "ein", "Drang", ",", "ein'", "Grill'", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "VVFIN", "PPER", "ART", "NN", "$,", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Verhunzen werd', verdrehen,", "tokens": ["Ver\u00b7hun\u00b7zen", "werd'", ",", "ver\u00b7dre\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.35": {"text": "Soll, traun! schier der 's verstehn mir will,", "tokens": ["Soll", ",", "traun", "!", "schier", "der", "'s", "ver\u00b7stehn", "mir", "will", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "VVINF", "$.", "ADV", "ART", "PPER", "VVFIN", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.36": {"text": "Gleich'n Hahn nach'm Morg'nlicht kr\u00e4hen.", "tokens": ["Gleich'n", "Hahn", "nach'm", "Mor\u00b7g'\u00b7nlicht", "kr\u00e4\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.37": {"text": "Und w\u00e4re noch die Eselin", "tokens": ["Und", "w\u00e4\u00b7re", "noch", "die", "E\u00b7se\u00b7lin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Von Bileam am Leben:", "tokens": ["Von", "Bi\u00b7leam", "am", "Le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.39": {"text": "Schrein sollte sie: J-A! darin", "tokens": ["Schrein", "soll\u00b7te", "sie", ":", "J\u00b7A", "!", "da\u00b7rin"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["NN", "VMFIN", "PPER", "$.", "NE", "$.", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Ist Kraft und Drang und Streben!", "tokens": ["Ist", "Kraft", "und", "Drang", "und", "Stre\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.41": {"text": "Ich nehme, wenn's die Obrigkeit", "tokens": ["Ich", "neh\u00b7me", ",", "wenn's", "die", "Ob\u00b7rig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Erlauben will, zwei Frauen,", "tokens": ["Er\u00b7lau\u00b7ben", "will", ",", "zwei", "Frau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$,", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.43": {"text": "Und lasse der Empfindsamkeit", "tokens": ["Und", "las\u00b7se", "der", "Emp\u00b7find\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Capell' und Altar bauen.", "tokens": ["Ca\u00b7pell'", "und", "Al\u00b7tar", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.45": {"text": "Zum Priester wird sich, wie bekannt,", "tokens": ["Zum", "Pries\u00b7ter", "wird", "sich", ",", "wie", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PRF", "$,", "PWAV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "Herr ", "tokens": ["Herr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.47": {"text": "Dem la\u00df ich denn ein Me\u00dfgewand", "tokens": ["Dem", "la\u00df", "ich", "denn", "ein", "Me\u00df\u00b7ge\u00b7wand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "Von Gold und Perlen sticken.", "tokens": ["Von", "Gold", "und", "Per\u00b7len", "sti\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.49": {"text": "Doch, ich Patronus, merkt das wohl!", "tokens": ["Doch", ",", "ich", "Pat\u00b7ro\u00b7nus", ",", "merkt", "das", "wohl", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPER", "NE", "$,", "VVFIN", "PDS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "Geh' im zerri\u00dfnen Kittel,", "tokens": ["Geh'", "im", "zer\u00b7ri\u00df\u00b7nen", "Kit\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.51": {"text": "Hab' aber alle Taschen voll", "tokens": ["Hab'", "a\u00b7ber", "al\u00b7le", "Ta\u00b7schen", "voll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "Yorikischer Capittel.", "tokens": ["Y\u00b7o\u00b7ri\u00b7ki\u00b7scher", "Ca\u00b7pit\u00b7tel", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.53": {"text": "Doch la\u00df ich, wenn mir's Kurzweil schafft,", "tokens": ["Doch", "la\u00df", "ich", ",", "wenn", "mir's", "Kurz\u00b7weil", "schafft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "$,", "KOUS", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.54": {"text": "Die H\u00fclfe fleh'nden Armen,", "tokens": ["Die", "H\u00fcl\u00b7fe", "fleh'n\u00b7den", "Ar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.55": {"text": "Durch meinen Schweitzer, ", "tokens": ["Durch", "mei\u00b7nen", "Schweit\u00b7zer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.56": {"text": "Zerpr\u00fcgeln oh'n Erbarmen.", "tokens": ["Zer\u00b7pr\u00fc\u00b7geln", "oh'n", "Er\u00b7bar\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.57": {"text": "Scheint eine Physiognomie", "tokens": ["Scheint", "ei\u00b7ne", "Phy\u00b7si\u00b7og\u00b7no\u00b7mie"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Mir neu von Bau und Falten,", "tokens": ["Mir", "neu", "von", "Bau", "und", "Fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.59": {"text": "So frag' ich nicht: \u00bbHerr! wollen Sie?\u00ab", "tokens": ["So", "frag'", "ich", "nicht", ":", "\u00bb", "Herr", "!", "wol\u00b7len", "Sie", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "NN", "$.", "VMFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.60": {"text": "Bis ", "tokens": ["Bis"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.61": {"text": "Gesicht mir lasse kommen,", "tokens": ["Ge\u00b7sicht", "mir", "las\u00b7se", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.62": {"text": "Den sonderbaren Schattenri\u00df", "tokens": ["Den", "son\u00b7der\u00b7ba\u00b7ren", "Schat\u00b7ten\u00b7ri\u00df"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.63": {"text": "F\u00fcr mich hat aufgenommen.", "tokens": ["F\u00fcr", "mich", "hat", "auf\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.64": {"text": "F\u00e4llt mir es ein, so kann ich ja", "tokens": ["F\u00e4llt", "mir", "es", "ein", ",", "so", "kann", "ich", "ja"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "PTKVZ", "$,", "ADV", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "Wohl auch nach Hofe gehen;", "tokens": ["Wohl", "auch", "nach", "Ho\u00b7fe", "ge\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.66": {"text": "In aller Absicht werd' ich da", "tokens": ["In", "al\u00b7ler", "Ab\u00b7sicht", "werd'", "ich", "da"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Mich gar nicht \u00fcbel stehen;", "tokens": ["Mich", "gar", "nicht", "\u00fc\u00b7bel", "ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.68": {"text": "Denn Bischoff und Champagner Wein", "tokens": ["Denn", "Bi\u00b7schoff", "und", "Cham\u00b7pag\u00b7ner", "Wein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.69": {"text": "Kann ich wie Wasser saufen,", "tokens": ["Kann", "ich", "wie", "Was\u00b7ser", "sau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.70": {"text": "Und, werfen Nachts wir Fenster ein,", "tokens": ["Und", ",", "wer\u00b7fen", "Nachts", "wir", "Fens\u00b7ter", "ein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "ADV", "PPER", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "Gewi\u00df am schnellsten laufen.", "tokens": ["Ge\u00b7wi\u00df", "am", "schnells\u00b7ten", "lau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}