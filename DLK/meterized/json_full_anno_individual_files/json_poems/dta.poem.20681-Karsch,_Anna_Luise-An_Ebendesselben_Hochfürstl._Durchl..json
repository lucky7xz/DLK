{"dta.poem.20681": {"metadata": {"author": {"name": "Karsch, Anna Luise", "birth": "N.A.", "death": "N.A."}, "title": "An  \n  Ebendesselben  \n Hochf\u00fcrstl. Durchl.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1792", "urn": "urn:nbn:de:kobv:b4-200905193016", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Durchlauchter Fels, der ehemals den Wogen                 ", "tokens": ["Durch\u00b7lauch\u00b7ter", "Fels", ",", "der", "e\u00b7he\u00b7mals", "den", "Wo\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Krieges m\u00e4chtig widerstand,", "tokens": ["Des", "Krie\u00b7ges", "m\u00e4ch\u00b7tig", "wi\u00b7der\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Warum ist Dir nicht j\u00fcngst die Muse zugeflogen,", "tokens": ["Wa\u00b7rum", "ist", "Dir", "nicht", "j\u00fcngst", "die", "Mu\u00b7se", "zu\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PTKNEG", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als sie den bittern Schimpf empfand,", "tokens": ["Als", "sie", "den", "bit\u00b7tern", "Schimpf", "emp\u00b7fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den K\u00f6nig Friedrichs Kammerknechte", "tokens": ["Den", "K\u00f6\u00b7nig", "Fried\u00b7richs", "Kam\u00b7mer\u00b7knech\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr h\u00f6hnisch lachend angethan.", "tokens": ["Ihr", "h\u00f6h\u00b7nisch", "la\u00b7chend", "an\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich schrieb an Ihn und sprach: da\u00df Er bedenken m\u00f6chte,", "tokens": ["Ich", "schrieb", "an", "Ihn", "und", "sprach", ":", "da\u00df", "Er", "be\u00b7den\u00b7ken", "m\u00f6ch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "KON", "VVFIN", "$.", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie zehnmal schon auf seiner Bahn", "tokens": ["Wie", "zehn\u00b7mal", "schon", "auf", "sei\u00b7ner", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sich Ph\u00f6bus umgewandt, seitdem mir Friedrich sagte", "tokens": ["Sich", "Ph\u00f6\u00b7bus", "um\u00b7ge\u00b7wandt", ",", "seit\u00b7dem", "mir", "Fried\u00b7rich", "sag\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "NE", "VVPP", "$,", "KOUS", "PPER", "NE", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Er wollte mein Versorger seyn.", "tokens": ["Er", "woll\u00b7te", "mein", "Ver\u00b7sor\u00b7ger", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich hatte Recht, da\u00df ich Ihn zu erinnern wagte,", "tokens": ["Ich", "hat\u00b7te", "Recht", ",", "da\u00df", "ich", "Ihn", "zu", "e\u00b7rin\u00b7nern", "wag\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "KOUS", "PPER", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Er aber sch\u00e4tzt die Deutschen klein.", "tokens": ["Er", "a\u00b7ber", "sch\u00e4tzt", "die", "Deut\u00b7schen", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man siegelte auf Sein Befehlen", "tokens": ["Man", "sie\u00b7gel\u00b7te", "auf", "Sein", "Be\u00b7feh\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "--+-++-+-", "measure": "anapaest.init"}, "line.4": {"text": "Zwo ganze Friedrichsthaler ein,                 ", "tokens": ["Zwo", "gan\u00b7ze", "Fried\u00b7rich\u00b7stha\u00b7ler", "ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wollt\u2019 es \u00f6ffentlich erz\u00e4hlen,", "tokens": ["Und", "wollt'", "es", "\u00f6f\u00b7fent\u00b7lich", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Indem man auf den Umschlag schrieb:", "tokens": ["In\u00b7dem", "man", "auf", "den", "Um\u00b7schlag", "schrieb", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u201ezwey Thaler zum gen\u00e4digen Geschenke", "tokens": ["\u201e", "zwey", "Tha\u00b7ler", "zum", "ge\u00b7n\u00e4\u00b7di\u00b7gen", "Ge\u00b7schen\u00b7ke"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "CARD", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "\u201ef\u00fcr Deutschlands Dichterin.\u201c Dies that man, wie", "tokens": ["\u201e", "f\u00fcr", "Deutschlands", "Dich\u00b7te\u00b7rin", ".", "\u201c", "Dies", "that", "man", ",", "wie"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word"], "pos": ["$(", "APPR", "NE", "NN", "$.", "$(", "PDS", "VVFIN", "PIS", "$,", "PWAV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "ich denke,", "tokens": ["ich", "den\u00b7ke", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.3": {"line.1": {"text": "Aus eignem schadenfreuden Trieb.", "tokens": ["Aus", "eig\u00b7nem", "scha\u00b7den\u00b7freu\u00b7den", "Trieb", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich fa\u00dfte kurzen Schlu\u00df; ich l\u00e4chelte catonisch", "tokens": ["Ich", "fa\u00df\u00b7te", "kur\u00b7zen", "Schlu\u00df", ";", "ich", "l\u00e4\u00b7chel\u00b7te", "ca\u00b7to\u00b7nisch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$.", "PPER", "VVFIN", "NE"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auf dies Geschenk herab, und schrieb", "tokens": ["Auf", "dies", "Ge\u00b7schenk", "her\u00b7ab", ",", "und", "schrieb"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PDS", "NN", "ADV", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit kaltem Blute ganz laconisch,", "tokens": ["Mit", "kal\u00b7tem", "Blu\u00b7te", "ganz", "la\u00b7co\u00b7nisch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Weil mir nichts weiter \u00fcbrig blieb:", "tokens": ["Weil", "mir", "nichts", "wei\u00b7ter", "\u00fcb\u00b7rig", "blieb", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "\u201ezwei Thaler giebt kein gro\u00dfer K\u00f6nig;", "tokens": ["\u201e", "zwei", "Tha\u00b7ler", "giebt", "kein", "gro\u00b7\u00dfer", "K\u00f6\u00b7nig", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "CARD", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eein solch Geschenk vergr\u00f6\u00dfert nicht mein Gl\u00fcck,", "tokens": ["\u201e", "ein", "solch", "Ge\u00b7schenk", "ver\u00b7gr\u00f6\u00b7\u00dfert", "nicht", "mein", "Gl\u00fcck", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "PIAT", "NN", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u201enein, es erniedrigt mich ein wenig,", "tokens": ["\u201e", "nein", ",", "es", "er\u00b7nied\u00b7rigt", "mich", "ein", "we\u00b7nig", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "ART", "PIS", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "\u201edrum geb ich es zur\u00fcck.", "tokens": ["\u201e", "drum", "geb", "ich", "es", "zu\u00b7r\u00fcck", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "So sprach ich, und so mu\u00dft\u2019 ich sprechen,", "tokens": ["So", "sprach", "ich", ",", "und", "so", "mu\u00dft'", "ich", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KON", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und siegelte die Thaler ein,", "tokens": ["Und", "sie\u00b7gel\u00b7te", "die", "Tha\u00b7ler", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und sandte sie zur\u00fcck, und will sich Friedrich r\u00e4chen,", "tokens": ["Und", "sand\u00b7te", "sie", "zu\u00b7r\u00fcck", ",", "und", "will", "sich", "Fried\u00b7rich", "r\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VMFIN", "PRF", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So mag Er Dir an Gro\u00dfmuth \u00e4hnlich seyn", "tokens": ["So", "mag", "Er", "Dir", "an", "Gro\u00df\u00b7muth", "\u00e4hn\u00b7lich", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "APPR", "NN", "ADJD", "VAINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und mir ein Jahrgeschenke geben.", "tokens": ["Und", "mir", "ein", "Jahr\u00b7ge\u00b7schen\u00b7ke", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Er s\u00fcndigte bei Seinem Leben", "tokens": ["Er", "s\u00fcn\u00b7dig\u00b7te", "bei", "Sei\u00b7nem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "An Seiner eignen Ehre durch die That,", "tokens": ["An", "Sei\u00b7ner", "eig\u00b7nen", "Eh\u00b7re", "durch", "die", "That", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und ich betrug mich, wie ich sollte,", "tokens": ["Und", "ich", "be\u00b7trug", "mich", ",", "wie", "ich", "soll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr mich war gar kein andrer Rath.", "tokens": ["F\u00fcr", "mich", "war", "gar", "kein", "an\u00b7drer", "Rath", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Denn wenn ich dies Geschenk behalten wollte,", "tokens": ["Denn", "wenn", "ich", "dies", "Ge\u00b7schenk", "be\u00b7hal\u00b7ten", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PDS", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Mit solcher niedern Art gesandt,", "tokens": ["Mit", "sol\u00b7cher", "nie\u00b7dern", "Art", "ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Alsdann verdient\u2019 ich k\u00fcnftig nimmer", "tokens": ["Als\u00b7dann", "ver\u00b7dient'", "ich", "k\u00fcnf\u00b7tig", "nim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Ehre, da\u00df der gro\u00dfe Ferdinand", "tokens": ["Die", "Eh\u00b7re", ",", "da\u00df", "der", "gro\u00b7\u00dfe", "Fer\u00b7di\u00b7nand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Sich meiner k\u00fchnen Sangart immer", "tokens": ["Sich", "mei\u00b7ner", "k\u00fch\u00b7nen", "San\u00b7gart", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "PPOSAT", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Mit g\u00fcnstiglichem Auge neigt.", "tokens": ["Mit", "g\u00fcns\u00b7tig\u00b7li\u00b7chem", "Au\u00b7ge", "neigt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ich folgte einem meiner Freunde,", "tokens": ["Ich", "folg\u00b7te", "ei\u00b7nem", "mei\u00b7ner", "Freun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Der ehrlich denkt und ehrlich sich bezeigt,", "tokens": ["Der", "ehr\u00b7lich", "denkt", "und", "ehr\u00b7lich", "sich", "be\u00b7zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "KON", "ADJD", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Und schrieb dem K\u00f6nige, der tausend neue Feinde", "tokens": ["Und", "schrieb", "dem", "K\u00f6\u00b7ni\u00b7ge", ",", "der", "tau\u00b7send", "neu\u00b7e", "Fein\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "PRELS", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Mit tausend neuen D\u00f6rfern sich erstrebt.", "tokens": ["Mit", "tau\u00b7send", "neu\u00b7en", "D\u00f6r\u00b7fern", "sich", "er\u00b7strebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADJA", "NN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Der Freund hat\u2019s gut gemeint, indem Er mich belebt,", "tokens": ["Der", "Freund", "hat's", "gut", "ge\u00b7meint", ",", "in\u00b7dem", "Er", "mich", "be\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVPP", "$,", "KOUS", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den K\u00f6nig an Sein Wort zu denken", "tokens": ["Den", "K\u00f6\u00b7nig", "an", "Sein", "Wort", "zu", "den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nach zehn verflogner Jahre Frist,", "tokens": ["Nach", "zehn", "ver\u00b7flog\u00b7ner", "Jah\u00b7re", "Frist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ich bin ohne Philosophengr\u00fcnde", "tokens": ["Und", "ich", "bin", "oh\u00b7ne", "Phi\u00b7lo\u00b7so\u00b7phen\u00b7gr\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "So ruhig wie ein Weiser ist.", "tokens": ["So", "ru\u00b7hig", "wie", "ein", "Wei\u00b7ser", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Rings um mich her blick ich und finde", "tokens": ["Rings", "um", "mich", "her", "blick", "ich", "und", "fin\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PRF", "APZR", "VVFIN", "PPER", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Viel Tausend mir an Gl\u00fcck nicht gleich,", "tokens": ["Viel", "Tau\u00b7send", "mir", "an", "Gl\u00fcck", "nicht", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "APPR", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und auch nicht gleich an Ruhm und W\u00fcrde.", "tokens": ["Und", "auch", "nicht", "gleich", "an", "Ruhm", "und", "W\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Hab ich nicht eine Goldesb\u00fcrde,", "tokens": ["Hab", "ich", "nicht", "ei\u00b7ne", "Gol\u00b7des\u00b7b\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So bin ich doch an Briefen reich,", "tokens": ["So", "bin", "ich", "doch", "an", "Brie\u00b7fen", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Die mir mein g\u00f6ttlichgro\u00dfer G\u00f6nner,", "tokens": ["Die", "mir", "mein", "g\u00f6tt\u00b7lich\u00b7gro\u00b7\u00dfer", "G\u00f6n\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Held Ferdinand von Herzen zugeschickt,", "tokens": ["Held", "Fer\u00b7di\u00b7nand", "von", "Her\u00b7zen", "zu\u00b7ge\u00b7schickt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und stolzer bin ich drauf, als Weiber auf die M\u00e4nner,", "tokens": ["Und", "stol\u00b7zer", "bin", "ich", "drauf", ",", "als", "Wei\u00b7ber", "auf", "die", "M\u00e4n\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "PTKVZ", "$,", "KOUS", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die sie mit Steinchen ausgeschm\u00fcckt", "tokens": ["Die", "sie", "mit", "Stein\u00b7chen", "aus\u00b7ge\u00b7schm\u00fcckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und ihnen Titeldunst gegeben \u2014", "tokens": ["Und", "ih\u00b7nen", "Ti\u00b7tel\u00b7dunst", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Ich br\u00fcste mich mit ganz erhabnem Geist,", "tokens": ["Ich", "br\u00fcs\u00b7te", "mich", "mit", "ganz", "er\u00b7hab\u00b7nem", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "So oft der Held, f\u00fcr den noch jezt die Franzen beben,", "tokens": ["So", "oft", "der", "Held", ",", "f\u00fcr", "den", "noch", "jezt", "die", "Fran\u00b7zen", "be\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,", "APPR", "ART", "ADV", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Mich \u201eSeine liebe Karschin\u201e hei\u00dft.", "tokens": ["Mich", "\u201e", "Sei\u00b7ne", "lie\u00b7be", "Kar\u00b7schin", "\u201e", "hei\u00dft", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "$(", "PPOSAT", "ADJA", "NN", "$(", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}