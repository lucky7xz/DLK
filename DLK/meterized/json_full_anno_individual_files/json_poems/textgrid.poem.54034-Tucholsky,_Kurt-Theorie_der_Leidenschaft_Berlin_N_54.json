{"textgrid.poem.54034": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Theorie der Leidenschaft Berlin N 54", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Von wejen Liebe . . .", "tokens": ["Von", "we\u00b7jen", "Lie\u00b7be", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Wat der Affe kl\u00f6nt!", "tokens": ["Wat", "der", "Af\u00b7fe", "kl\u00f6nt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Ick hab ma ehmt blo\u00df an 'n jew\u00f6hnt!", "tokens": ["Ick", "hab", "ma", "ehmt", "blo\u00df", "an", "'n", "je\u00b7w\u00f6hnt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "VVFIN", "ADV", "APPR", "NE", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ick we\u00df nu schon: det Morjens seine Socken . . .", "tokens": ["Ick", "we\u00df", "nu", "schon", ":", "det", "Mor\u00b7jens", "sei\u00b7ne", "So\u00b7cken", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "PDS", "ADV", "PPOSAT", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "uff seinen Oberarm die zweenhalb Pocken . . .", "tokens": ["uff", "sei\u00b7nen", "O\u00b7be\u00b7rarm", "die", "zween\u00b7halb", "Po\u00b7cken", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "CARD", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Von wejen Liebe \u2013!", "tokens": ["Von", "we\u00b7jen", "Lie\u00b7be", "\u2013", "!"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$(", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "H\u00f6! So siehste aus.", "tokens": ["H\u00f6", "!", "So", "siehs\u00b7te", "aus", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.8": {"text": "Mensch, nischt wie raus!", "tokens": ["Mensch", ",", "nischt", "wie", "raus", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "KOKOM", "ADV", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "Da sind wa neulich in 'n Film jewesen.", "tokens": ["Da", "sind", "wa", "neu\u00b7lich", "in", "'n", "Film", "je\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "APPR", "NE", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da jab et eenen sch\u00f6nen Brief zu lesen.", "tokens": ["Da", "jab", "et", "e\u00b7e\u00b7nen", "sch\u00f6\u00b7nen", "Brief", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Een Vers:", "tokens": ["E\u00b7en", "Vers", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "DiE EIFERSUCHT IST EINE LEIDENSCHAFT,", "tokens": ["DiE", "Ei\u00b7FER\u00b7SUCHT", "IsT", "Ei\u00b7NE", "LeI\u00b7DEN\u00b7SCHAFT", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "DiE MIT EIFER SUCHT, WAS LEIDEN SCHAFFT.", "tokens": ["DiE", "MiT", "Ei\u00b7FER", "SuCHT", ",", "WaS", "LeI\u00b7DEN", "ScHAFFT", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,", "NE", "NE", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Na ja doch. Abadet w\u00e4r ja jelacht:", "tokens": ["Na", "ja", "doch", ".", "Ab\u00b7a\u00b7det", "w\u00e4r", "ja", "je\u00b7lacht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "ADV", "$.", "VVPP", "VAFIN", "ADV", "ADV", "$."], "meter": "---+--+---", "measure": "iambic.di.relaxed"}, "line.7": {"text": "Wenn der mit seine Nutten macht \u2013", "tokens": ["Wenn", "der", "mit", "sei\u00b7ne", "Nut\u00b7ten", "macht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ick sahre nischt. Ick kenn doch di\u00df jenau!", "tokens": ["ick", "sah\u00b7re", "nischt", ".", "Ick", "kenn", "doch", "di\u00df", "je\u00b7nau", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$.", "PPER", "VVFIN", "ADV", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Son fauler Kopp. Ick \u00e4rja mir blo\u00df blau,", "tokens": ["Son", "fau\u00b7ler", "Kopp", ".", "Ick", "\u00e4r\u00b7ja", "mir", "blo\u00df", "blau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.10": {"text": "det ick mir \u00e4rjere. Denn der vadient det jahnich,", "tokens": ["det", "ick", "mir", "\u00e4r\u00b7je\u00b7re", ".", "Denn", "der", "va\u00b7di\u00b7ent", "det", "jah\u00b7nich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "VVFIN", "$.", "KON", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-++-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.11": {"text": "der Affenschwanz, der olle Piesenkranich.", "tokens": ["der", "Af\u00b7fen\u00b7schwanz", ",", "der", "ol\u00b7le", "Pie\u00b7sen\u00b7kra\u00b7nich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "Ick mach et janz jenau wie er \u2013 son Aas . . . !", "tokens": ["Ick", "mach", "et", "janz", "je\u00b7nau", "wie", "er", "\u2013", "son", "Aas", ".", ".", ".", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADV", "ADJD", "KOKOM", "PPER", "$(", "XY", "NE", "$.", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "A det is komisch: mir machts keenen Spa\u00df.", "tokens": ["A", "det", "is", "ko\u00b7misch", ":", "mir", "machts", "ke\u00b7e\u00b7nen", "Spa\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "ADJD", "$.", "PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.14": {"text": "Mich kann die janze M\u00e4nnerbransche \u2013!", "tokens": ["Mich", "kann", "die", "jan\u00b7ze", "M\u00e4n\u00b7ner\u00b7bran\u00b7sche", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Ick nehme jahnich jern Revansche.", "tokens": ["Ick", "neh\u00b7me", "jah\u00b7nich", "jern", "Re\u00b7van\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Ick, Lottchen, bin ja dazu viel zu schlau.", "tokens": ["Ick", ",", "Lott\u00b7chen", ",", "bin", "ja", "da\u00b7zu", "viel", "zu", "schlau", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "VAFIN", "ADV", "PAV", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "So is det meine Meinung nach mit jede Frau:", "tokens": ["So", "is", "det", "mei\u00b7ne", "Mei\u00b7nung", "nach", "mit", "je\u00b7de", "Frau", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "VVFIN", "PPOSAT", "NN", "APPR", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sofern wir iebahaupt 'n Herrn ham,", "tokens": ["So\u00b7fern", "wir", "ie\u00b7ba\u00b7haupt", "'n", "Herrn", "ham", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "denn ham wir jern, det wirn jern ham!", "tokens": ["denn", "ham", "wir", "jern", ",", "det", "wirn", "jern", "ham", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "PPER", "ADV", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ob Schupouniform, ob in Zevil:", "tokens": ["Ob", "Schu\u00b7po\u00b7u\u00b7ni\u00b7form", ",", "ob", "in", "Ze\u00b7vil", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "KOUS", "APPR", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "es is von wejen det Jefiehl.", "tokens": ["es", "is", "von", "we\u00b7jen", "det", "Je\u00b7fiehl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "FM", "APPR", "NE", "NE", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.22": {"text": "Da wee\u00df der jahnischt von. Der pust sich auf", "tokens": ["Da", "wee\u00df", "der", "jah\u00b7nischt", "von", ".", "Der", "pust", "sich", "auf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "$.", "ART", "VVFIN", "PRF", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "und kommt sich vor un is noch stolz dadrauf . . .", "tokens": ["und", "kommt", "sich", "vor", "un", "is", "noch", "stolz", "da\u00b7drauf", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "FM", "FM", "ADV", "ADJD", "PAV", "$.", "$.", "$."], "meter": "-+-----+-+", "measure": "dactylic.init"}, "line.24": {"text": "Von wejen Liebe . . .", "tokens": ["Von", "we\u00b7jen", "Lie\u00b7be", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.25": {"text": "Det bestimmt doch keinesfalls", "tokens": ["Det", "be\u00b7stimmt", "doch", "kei\u00b7nes\u00b7falls"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.26": {"text": "der Mann mit seinen unjewaschenen Hals!", "tokens": ["der", "Mann", "mit", "sei\u00b7nen", "un\u00b7je\u00b7wa\u00b7sche\u00b7nen", "Hals", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.27": {"text": "Ich k\u00fcsse Ihre Hand, Madam.", "tokens": ["Ich", "k\u00fcs\u00b7se", "Ih\u00b7re", "Hand", ",", "Ma\u00b7dam", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Di\u00df jlauben blo\u00df die K\u00e4lber.", "tokens": ["Di\u00df", "jlau\u00b7ben", "blo\u00df", "die", "K\u00e4l\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.29": {"text": "Ick sahre so \u2013:", "tokens": ["Ick", "sah\u00b7re", "so", "\u2013", ":"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.30": {"text": "Det Sch\u00f6nste an die Liebe is die Liebe selber.", "tokens": ["Det", "Sch\u00f6ns\u00b7te", "an", "die", "Lie\u00b7be", "is", "die", "Lie\u00b7be", "sel\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ART", "NN", "FM", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Von wejen Liebe . . .", "tokens": ["Von", "we\u00b7jen", "Lie\u00b7be", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Wat der Affe kl\u00f6nt!", "tokens": ["Wat", "der", "Af\u00b7fe", "kl\u00f6nt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Ick hab ma ehmt blo\u00df an 'n jew\u00f6hnt!", "tokens": ["Ick", "hab", "ma", "ehmt", "blo\u00df", "an", "'n", "je\u00b7w\u00f6hnt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "VVFIN", "ADV", "APPR", "NE", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ick we\u00df nu schon: det Morjens seine Socken . . .", "tokens": ["Ick", "we\u00df", "nu", "schon", ":", "det", "Mor\u00b7jens", "sei\u00b7ne", "So\u00b7cken", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "PDS", "ADV", "PPOSAT", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "uff seinen Oberarm die zweenhalb Pocken . . .", "tokens": ["uff", "sei\u00b7nen", "O\u00b7be\u00b7rarm", "die", "zween\u00b7halb", "Po\u00b7cken", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "CARD", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Von wejen Liebe \u2013!", "tokens": ["Von", "we\u00b7jen", "Lie\u00b7be", "\u2013", "!"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$(", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "H\u00f6! So siehste aus.", "tokens": ["H\u00f6", "!", "So", "siehs\u00b7te", "aus", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.8": {"text": "Mensch, nischt wie raus!", "tokens": ["Mensch", ",", "nischt", "wie", "raus", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "KOKOM", "ADV", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.4": {"line.1": {"text": "Da sind wa neulich in 'n Film jewesen.", "tokens": ["Da", "sind", "wa", "neu\u00b7lich", "in", "'n", "Film", "je\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "APPR", "NE", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da jab et eenen sch\u00f6nen Brief zu lesen.", "tokens": ["Da", "jab", "et", "e\u00b7e\u00b7nen", "sch\u00f6\u00b7nen", "Brief", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Een Vers:", "tokens": ["E\u00b7en", "Vers", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "DiE EIFERSUCHT IST EINE LEIDENSCHAFT,", "tokens": ["DiE", "Ei\u00b7FER\u00b7SUCHT", "IsT", "Ei\u00b7NE", "LeI\u00b7DEN\u00b7SCHAFT", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "DiE MIT EIFER SUCHT, WAS LEIDEN SCHAFFT.", "tokens": ["DiE", "MiT", "Ei\u00b7FER", "SuCHT", ",", "WaS", "LeI\u00b7DEN", "ScHAFFT", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,", "NE", "NE", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Na ja doch. Abadet w\u00e4r ja jelacht:", "tokens": ["Na", "ja", "doch", ".", "Ab\u00b7a\u00b7det", "w\u00e4r", "ja", "je\u00b7lacht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "ADV", "$.", "VVPP", "VAFIN", "ADV", "ADV", "$."], "meter": "---+--+---", "measure": "iambic.di.relaxed"}, "line.7": {"text": "Wenn der mit seine Nutten macht \u2013", "tokens": ["Wenn", "der", "mit", "sei\u00b7ne", "Nut\u00b7ten", "macht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ick sahre nischt. Ick kenn doch di\u00df jenau!", "tokens": ["ick", "sah\u00b7re", "nischt", ".", "Ick", "kenn", "doch", "di\u00df", "je\u00b7nau", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$.", "PPER", "VVFIN", "ADV", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Son fauler Kopp. Ick \u00e4rja mir blo\u00df blau,", "tokens": ["Son", "fau\u00b7ler", "Kopp", ".", "Ick", "\u00e4r\u00b7ja", "mir", "blo\u00df", "blau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.10": {"text": "det ick mir \u00e4rjere. Denn der vadient det jahnich,", "tokens": ["det", "ick", "mir", "\u00e4r\u00b7je\u00b7re", ".", "Denn", "der", "va\u00b7di\u00b7ent", "det", "jah\u00b7nich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "VVFIN", "$.", "KON", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-++-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.11": {"text": "der Affenschwanz, der olle Piesenkranich.", "tokens": ["der", "Af\u00b7fen\u00b7schwanz", ",", "der", "ol\u00b7le", "Pie\u00b7sen\u00b7kra\u00b7nich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "Ick mach et janz jenau wie er \u2013 son Aas . . . !", "tokens": ["Ick", "mach", "et", "janz", "je\u00b7nau", "wie", "er", "\u2013", "son", "Aas", ".", ".", ".", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADV", "ADJD", "KOKOM", "PPER", "$(", "XY", "NE", "$.", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "A det is komisch: mir machts keenen Spa\u00df.", "tokens": ["A", "det", "is", "ko\u00b7misch", ":", "mir", "machts", "ke\u00b7e\u00b7nen", "Spa\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "ADJD", "$.", "PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.14": {"text": "Mich kann die janze M\u00e4nnerbransche \u2013!", "tokens": ["Mich", "kann", "die", "jan\u00b7ze", "M\u00e4n\u00b7ner\u00b7bran\u00b7sche", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Ick nehme jahnich jern Revansche.", "tokens": ["Ick", "neh\u00b7me", "jah\u00b7nich", "jern", "Re\u00b7van\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Ick, Lottchen, bin ja dazu viel zu schlau.", "tokens": ["Ick", ",", "Lott\u00b7chen", ",", "bin", "ja", "da\u00b7zu", "viel", "zu", "schlau", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "VAFIN", "ADV", "PAV", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "So is det meine Meinung nach mit jede Frau:", "tokens": ["So", "is", "det", "mei\u00b7ne", "Mei\u00b7nung", "nach", "mit", "je\u00b7de", "Frau", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "VVFIN", "PPOSAT", "NN", "APPR", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sofern wir iebahaupt 'n Herrn ham,", "tokens": ["So\u00b7fern", "wir", "ie\u00b7ba\u00b7haupt", "'n", "Herrn", "ham", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "denn ham wir jern, det wirn jern ham!", "tokens": ["denn", "ham", "wir", "jern", ",", "det", "wirn", "jern", "ham", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "PPER", "ADV", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ob Schupouniform, ob in Zevil:", "tokens": ["Ob", "Schu\u00b7po\u00b7u\u00b7ni\u00b7form", ",", "ob", "in", "Ze\u00b7vil", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "KOUS", "APPR", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "es is von wejen det Jefiehl.", "tokens": ["es", "is", "von", "we\u00b7jen", "det", "Je\u00b7fiehl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "FM", "APPR", "NE", "NE", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.22": {"text": "Da wee\u00df der jahnischt von. Der pust sich auf", "tokens": ["Da", "wee\u00df", "der", "jah\u00b7nischt", "von", ".", "Der", "pust", "sich", "auf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "$.", "ART", "VVFIN", "PRF", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "und kommt sich vor un is noch stolz dadrauf . . .", "tokens": ["und", "kommt", "sich", "vor", "un", "is", "noch", "stolz", "da\u00b7drauf", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "FM", "FM", "ADV", "ADJD", "PAV", "$.", "$.", "$."], "meter": "-+-----+-+", "measure": "dactylic.init"}, "line.24": {"text": "Von wejen Liebe . . .", "tokens": ["Von", "we\u00b7jen", "Lie\u00b7be", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.25": {"text": "Det bestimmt doch keinesfalls", "tokens": ["Det", "be\u00b7stimmt", "doch", "kei\u00b7nes\u00b7falls"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.26": {"text": "der Mann mit seinen unjewaschenen Hals!", "tokens": ["der", "Mann", "mit", "sei\u00b7nen", "un\u00b7je\u00b7wa\u00b7sche\u00b7nen", "Hals", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.27": {"text": "Ich k\u00fcsse Ihre Hand, Madam.", "tokens": ["Ich", "k\u00fcs\u00b7se", "Ih\u00b7re", "Hand", ",", "Ma\u00b7dam", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Di\u00df jlauben blo\u00df die K\u00e4lber.", "tokens": ["Di\u00df", "jlau\u00b7ben", "blo\u00df", "die", "K\u00e4l\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.29": {"text": "Ick sahre so \u2013:", "tokens": ["Ick", "sah\u00b7re", "so", "\u2013", ":"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.30": {"text": "Det Sch\u00f6nste an die Liebe is die Liebe selber.", "tokens": ["Det", "Sch\u00f6ns\u00b7te", "an", "die", "Lie\u00b7be", "is", "die", "Lie\u00b7be", "sel\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ART", "NN", "FM", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}