{"dta.poem.19089": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "LxXI.  Ins Br\u00e4utigams Nahmen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Deine Wunder-Kraft,", "tokens": ["Dei\u00b7ne", "Wun\u00b7der\u00b7Kraft", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Liebe! hats geschaft,", "tokens": ["Lie\u00b7be", "!", "hats", "ge\u00b7schaft", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "VAFIN", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df ich diesen Ort bewohne:", "tokens": ["Da\u00df", "ich", "die\u00b7sen", "Ort", "be\u00b7woh\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mein Gnaden-Rath im Sohne.", "tokens": ["Und", "mein", "Gna\u00b7den\u00b7Rath", "im", "Soh\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Macht mir diesen Ort", "tokens": ["Macht", "mir", "die\u00b7sen", "Ort"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "PDAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Zum gew\u00fcnschten Port.", "tokens": ["Zum", "ge\u00b7w\u00fcnschten", "Port", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "Francken gab das Licht.", "tokens": ["Fran\u00b7cken", "gab", "das", "Licht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Graben solt ich nicht;", "tokens": ["Gra\u00b7ben", "solt", "ich", "nicht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Sondern muste mich bequemen,", "tokens": ["Son\u00b7dern", "mus\u00b7te", "mich", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Andre Dinge vorzunehmen.", "tokens": ["And\u00b7re", "Din\u00b7ge", "vor\u00b7zu\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch dein Zug an dich", "tokens": ["Doch", "dein", "Zug", "an", "dich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PPER"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Ubereilte mich.", "tokens": ["U\u00b7be\u00b7reil\u00b7te", "mich", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPER", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Wie vor Zeiten zwar,", "tokens": ["Wie", "vor", "Zei\u00b7ten", "zwar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Manche Wittwe war,", "tokens": ["Man\u00b7che", "Witt\u00b7we", "war", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Und Elias kam zu keiner", "tokens": ["Und", "E\u00b7lias", "kam", "zu", "kei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "APPR", "PIS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In dem Volck, als nur zu einer,", "tokens": ["In", "dem", "Volck", ",", "als", "nur", "zu", "ei\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "ADV", "APPR", "ART", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo ihn deine Hand", "tokens": ["Wo", "ihn", "dei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Schleunig hingesandt:", "tokens": ["Schleu\u00b7nig", "hin\u00b7ge\u00b7sandt", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Also giengs mit mir", "tokens": ["Al\u00b7so", "giengs", "mit", "mir"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPER"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Ungew\u00f6hnlich f\u00fcr.", "tokens": ["Un\u00b7ge\u00b7w\u00f6hn\u00b7lich", "f\u00fcr", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "APPR", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Denn, mein Graf, der deine Regung", "tokens": ["Denn", ",", "mein", "Graf", ",", "der", "dei\u00b7ne", "Re\u00b7gung"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ehret ohne Widerlegung,", "tokens": ["Eh\u00b7ret", "oh\u00b7ne", "Wi\u00b7der\u00b7le\u00b7gung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hie\u00df mich mit sich gehn,", "tokens": ["Hie\u00df", "mich", "mit", "sich", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PRF", "VVINF", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Eh er mich gesehn.", "tokens": ["Eh", "er", "mich", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Wilt du, hub er an,", "tokens": ["Wilt", "du", ",", "hub", "er", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Mit zu diesem Mann,", "tokens": ["Mit", "zu", "die\u00b7sem", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Welchen meine Seele kennet,", "tokens": ["Wel\u00b7chen", "mei\u00b7ne", "See\u00b7le", "ken\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Den mein Hertz die Liebe nennet?", "tokens": ["Den", "mein", "Hertz", "die", "Lie\u00b7be", "nen\u00b7net", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Folge meinem Schritt,", "tokens": ["Fol\u00b7ge", "mei\u00b7nem", "Schritt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "In die Fremde mit.", "tokens": ["In", "die", "Frem\u00b7de", "mit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Kaum, da\u00df ich gesagt,", "tokens": ["Kaum", ",", "da\u00df", "ich", "ge\u00b7sagt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Ja! das sey gewagt,", "tokens": ["Ja", "!", "das", "sey", "ge\u00b7wagt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PDS", "VAFIN", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Zog ein freundliches Erzehlen", "tokens": ["Zog", "ein", "freund\u00b7li\u00b7ches", "Er\u00b7zeh\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von des Samuels Erwehlen,", "tokens": ["Von", "des", "Sa\u00b7mu\u00b7els", "Er\u00b7weh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Mein noch irrdisch Hertz,", "tokens": ["Mein", "noch", "irr\u00b7disch", "Hertz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJD", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Kr\u00e4ftig Himmel-werts.", "tokens": ["Kr\u00e4f\u00b7tig", "Him\u00b7mel\u00b7werts", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Wer nur beten kan,", "tokens": ["Wer", "nur", "be\u00b7ten", "kan", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Dem geht alles an,", "tokens": ["Dem", "geht", "al\u00b7les", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Dieser Rath ward mir gegeben,", "tokens": ["Die\u00b7ser", "Rath", "ward", "mir", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und zugleich der Weg zum Leben.", "tokens": ["Und", "zu\u00b7gleich", "der", "Weg", "zum", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unser B\u00fcrg und Held,", "tokens": ["Un\u00b7ser", "B\u00fcrg", "und", "Held", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Ward mir vorgestellt.", "tokens": ["Ward", "mir", "vor\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Also zogen wir,", "tokens": ["Al\u00b7so", "zo\u00b7gen", "wir", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Her in di\u00df Revier,", "tokens": ["Her", "in", "di\u00df", "Re\u00b7vier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDS", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Wo mein Herr und ich nicht hatten,", "tokens": ["Wo", "mein", "Herr", "und", "ich", "nicht", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "KON", "PPER", "PTKNEG", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Stein zu \u00fcberschatten;", "tokens": ["Ei\u00b7nen", "Stein", "zu", "\u00fc\u00b7bersc\u00b7hat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und erharrten da,", "tokens": ["Und", "er\u00b7harr\u00b7ten", "da", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Was hernach geschah.", "tokens": ["Was", "her\u00b7nach", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Auf derselben Bahn", "tokens": ["Auf", "der\u00b7sel\u00b7ben", "Bahn"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PDAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Kam noch mancher an,", "tokens": ["Kam", "noch", "man\u00b7cher", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PIS", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Den die Liebe \u00fcberwogen,", "tokens": ["Den", "die", "Lie\u00b7be", "\u00fc\u00b7ber\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und von ferne hergezogen;", "tokens": ["Und", "von", "fer\u00b7ne", "her\u00b7ge\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber wer bekleibt?", "tokens": ["A\u00b7ber", "wer", "be\u00b7kleibt", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Ohne der, da gl\u00e4ubt.", "tokens": ["Oh\u00b7ne", "der", ",", "da", "gl\u00e4ubt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "ADV", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Mancher innre Kampf,", "tokens": ["Man\u00b7cher", "inn\u00b7re", "Kampf", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Mancher \u00e4u\u00dfre Dampf,", "tokens": ["Man\u00b7cher", "\u00e4u\u00df\u00b7re", "Dampf", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Ubte damals Herrn und Knechte:", "tokens": ["Ub\u00b7te", "da\u00b7mals", "Herrn", "und", "Knech\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Endlich f\u00fchrte GOttes Rechte", "tokens": ["End\u00b7lich", "f\u00fchr\u00b7te", "Got\u00b7tes", "Rech\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Das Gericht und Strau\u00df", "tokens": ["Das", "Ge\u00b7richt", "und", "Strau\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NE"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Bi\u00df zum Siege aus.", "tokens": ["Bi\u00df", "zum", "Sie\u00b7ge", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Seelen regten sich", "tokens": ["See\u00b7len", "reg\u00b7ten", "sich"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "PRF"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Damals m\u00e4chtiglich;", "tokens": ["Da\u00b7mals", "m\u00e4ch\u00b7tig\u00b7lich", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Und in unsers Hauses H\u00fctte", "tokens": ["Und", "in", "un\u00b7sers", "Hau\u00b7ses", "H\u00fct\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stiegen auf Gebet und Bitte", "tokens": ["Stie\u00b7gen", "auf", "Ge\u00b7bet", "und", "Bit\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Um die beste Wahl,", "tokens": ["Um", "die", "bes\u00b7te", "Wahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Zu des Herrn Gemahl.", "tokens": ["Zu", "des", "Herrn", "Ge\u00b7mahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Kaum, da\u00df wir geh\u00f6rt,", "tokens": ["Kaum", ",", "da\u00df", "wir", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "--+-+", "measure": "anapaest.init"}, "line.2": {"text": "Was uns GOtt beschehrt,", "tokens": ["Was", "uns", "Gott", "be\u00b7schehrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "NN", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Legete sich unser Hauffe,", "tokens": ["Le\u00b7ge\u00b7te", "sich", "un\u00b7ser", "Hauf\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach vollf\u00fchrtem Pilgrims-Lauffe,", "tokens": ["Nach", "voll\u00b7f\u00fchr\u00b7tem", "Pil\u00b7grims\u00b7Lauf\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "In ein Bethlehem,", "tokens": ["In", "ein", "Beth\u00b7le\u00b7hem", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Das dem Herrn bequem.", "tokens": ["Das", "dem", "Herrn", "be\u00b7quem", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Starb der Prediger;", "tokens": ["Starb", "der", "Pre\u00b7di\u00b7ger", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Kam ein andrer her,", "tokens": ["Kam", "ein", "an\u00b7drer", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Welcher sich zu Ehr und Schande,", "tokens": ["Wel\u00b7cher", "sich", "zu", "Ehr", "und", "Schan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "PRF", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als vor GOtt mit uns verbande.", "tokens": ["Als", "vor", "Gott", "mit", "uns", "ver\u00b7ban\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und so waren wir", "tokens": ["Und", "so", "wa\u00b7ren", "wir"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Damals unsrer vier.", "tokens": ["Da\u00b7mals", "uns\u00b7rer", "vier", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "CARD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Schleunig rief der HErr", "tokens": ["Schleu\u00b7nig", "rief", "der", "Herr"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Einen Wanderer,", "tokens": ["Ei\u00b7nen", "Wan\u00b7de\u00b7rer", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Aus Paris der grossen St\u00e4dte,", "tokens": ["Aus", "Pa\u00b7ris", "der", "gros\u00b7sen", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und nach ringendem Gebete", "tokens": ["Und", "nach", "rin\u00b7gen\u00b7dem", "Ge\u00b7be\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Band er diesen Mann", "tokens": ["Band", "er", "die\u00b7sen", "Mann"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "PDAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Kr\u00e4ftig an uns an.", "tokens": ["Kr\u00e4f\u00b7tig", "an", "uns", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "Meine Seele wei\u00df,", "tokens": ["Mei\u00b7ne", "See\u00b7le", "wei\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Was vor Angst und Schwei\u00df,", "tokens": ["Was", "vor", "Angst", "und", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Was vor Kampf in sieben Jahren", "tokens": ["Was", "vor", "Kampf", "in", "sie\u00b7ben", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "NN", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsre Br\u00fcderschaft erfahren.", "tokens": ["Uns\u00b7re", "Br\u00fc\u00b7der\u00b7schaft", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch gelobt sey GOtt", "tokens": ["Doch", "ge\u00b7lobt", "sey", "Gott"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVPP", "VAFIN", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Auch vor diesen Tod.", "tokens": ["Auch", "vor", "die\u00b7sen", "Tod", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Mir kam dann und wann", "tokens": ["Mir", "kam", "dann", "und", "wann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "KON", "PWAV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Erst ein Schauer an,", "tokens": ["Erst", "ein", "Schau\u00b7er", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Wenn ich meines Herren Regung,", "tokens": ["Wenn", "ich", "mei\u00b7nes", "Her\u00b7ren", "Re\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ohne merckliche Bewegung,", "tokens": ["Oh\u00b7ne", "merck\u00b7li\u00b7che", "Be\u00b7we\u00b7gung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die die Hertzen r\u00fchrt,", "tokens": ["Die", "die", "Hert\u00b7zen", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Gegen mich versp\u00fchrt.", "tokens": ["Ge\u00b7gen", "mich", "ver\u00b7sp\u00fchrt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "Eine lange Zeit", "tokens": ["Ei\u00b7ne", "lan\u00b7ge", "Zeit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "W\u00e4hrete der Streit.", "tokens": ["W\u00e4h\u00b7re\u00b7te", "der", "Streit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+---+", "measure": "dactylic.init"}, "line.3": {"text": "Eine unverr\u00fcckte Beugung,", "tokens": ["Ei\u00b7ne", "un\u00b7ver\u00b7r\u00fcck\u00b7te", "Beu\u00b7gung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wider alle meine Neigung,", "tokens": ["Wi\u00b7der", "al\u00b7le", "mei\u00b7ne", "Nei\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "That dem eignen Muth", "tokens": ["That", "dem", "eig\u00b7nen", "Muth"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Aeuserlich nicht gut.", "tokens": ["A\u00b7e\u00b7u\u00b7ser\u00b7lich", "nicht", "gut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Mitten in dem Streit,", "tokens": ["Mit\u00b7ten", "in", "dem", "Streit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Mit der Eigenheit,", "tokens": ["Mit", "der", "Ei\u00b7gen\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Hie\u00df mich GOtt, (so mu\u00df ich dencken,)", "tokens": ["Hie\u00df", "mich", "Gott", ",", "(", "so", "mu\u00df", "ich", "den\u00b7cken", ",", ")"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,", "$(", "ADV", "VMFIN", "PPER", "VVINF", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einer meine Liebe schencken,", "tokens": ["Ei\u00b7ner", "mei\u00b7ne", "Lie\u00b7be", "schen\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die voll Tugend zwar,", "tokens": ["Die", "voll", "Tu\u00b7gend", "zwar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Doch nicht lebend war.", "tokens": ["Doch", "nicht", "le\u00b7bend", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADJD", "VAFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "Aber dieses Hertz", "tokens": ["A\u00b7ber", "die\u00b7ses", "Hertz"], "token_info": ["word", "word", "word"], "pos": ["KON", "PDAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Zog er Himmel-werts,", "tokens": ["Zog", "er", "Him\u00b7mel\u00b7werts", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Eben um dieselben Zeiten,", "tokens": ["E\u00b7ben", "um", "die\u00b7sel\u00b7ben", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Da sich andre sonst bereiten", "tokens": ["Da", "sich", "and\u00b7re", "sonst", "be\u00b7rei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "PIS", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jesus gab sich an;", "tokens": ["Je\u00b7sus", "gab", "sich", "an", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Da wars bald gethan.", "tokens": ["Da", "wars", "bald", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.20": {"line.1": {"text": "Unser neues Band", "tokens": ["Un\u00b7ser", "neu\u00b7es", "Band"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Gieng uns aus der Hand:", "tokens": ["Gieng", "uns", "aus", "der", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Denn wir suchten alle beyde", "tokens": ["Denn", "wir", "such\u00b7ten", "al\u00b7le", "bey\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PIAT", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nichts, als unsre Seelen-Weyde,", "tokens": ["Nichts", ",", "als", "uns\u00b7re", "See\u00b7len\u00b7Wey\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Welches Tag und Jahr", "tokens": ["Wel\u00b7ches", "Tag", "und", "Jahr"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAT", "NN", "KON", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Unser alles war.", "tokens": ["Un\u00b7ser", "al\u00b7les", "war", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "Meine liebe Braut", "tokens": ["Mei\u00b7ne", "lie\u00b7be", "Braut"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Ward dem Lamm vertraut;", "tokens": ["Ward", "dem", "Lamm", "ver\u00b7traut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Ubergab ihm ihre Sinnen:", "tokens": ["U\u00b7berg\u00b7ab", "ihm", "ih\u00b7re", "Sin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und di\u00df selige Beginnen", "tokens": ["Und", "di\u00df", "se\u00b7li\u00b7ge", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PDS", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Trieb sie h\u00f6chst erfreut", "tokens": ["Trieb", "sie", "h\u00f6chst", "er\u00b7freut"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "ADJD"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Auf die Ewigkeit.", "tokens": ["Auf", "die", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.22": {"line.1": {"text": "Jtzo kommt der Tag", "tokens": ["Jt\u00b7zo", "kommt", "der", "Tag"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Da ich sagen mag:", "tokens": ["Da", "ich", "sa\u00b7gen", "mag", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Herr, mein K\u00f6nig, du kanst machen;", "tokens": ["Herr", ",", "mein", "K\u00f6\u00b7nig", ",", "du", "kanst", "ma\u00b7chen", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn ich sehe meine Sachen", "tokens": ["Denn", "ich", "se\u00b7he", "mei\u00b7ne", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alle so gemacht,", "tokens": ["Al\u00b7le", "so", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Wie ichs nicht gedacht.", "tokens": ["Wie", "ichs", "nicht", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PTKNEG", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.23": {"line.1": {"text": "Gott erhebt mein Haupt,", "tokens": ["Gott", "er\u00b7hebt", "mein", "Haupt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df ich nie geglaubt,", "tokens": ["Da\u00df", "ich", "nie", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Unter seines Sohnes Glieder,", "tokens": ["Un\u00b7ter", "sei\u00b7nes", "Soh\u00b7nes", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unter eine Wolcke Br\u00fcder;", "tokens": ["Un\u00b7ter", "ei\u00b7ne", "Wol\u00b7cke", "Br\u00fc\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und di\u00df Heer des HErrn", "tokens": ["Und", "di\u00df", "Heer", "des", "Herrn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "NN", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Sieht mich Armen gern.", "tokens": ["Sieht", "mich", "Ar\u00b7men", "gern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.24": {"line.1": {"text": "Meine theure Braut", "tokens": ["Mei\u00b7ne", "theu\u00b7re", "Braut"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Wird mir angetraut,", "tokens": ["Wird", "mir", "an\u00b7ge\u00b7traut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Als ein Pfand von Christi Liebe,", "tokens": ["Als", "ein", "Pfand", "von", "Chris\u00b7ti", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Deren aufgebrachte Triebe,", "tokens": ["De\u00b7ren", "auf\u00b7ge\u00b7brach\u00b7te", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Christo nachzugehn,", "tokens": ["Chris\u00b7to", "nach\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVIZU", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Uns vor Augen stehn.", "tokens": ["Uns", "vor", "Au\u00b7gen", "stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.25": {"line.1": {"text": "Meines Herren Sinn", "tokens": ["Mei\u00b7nes", "Her\u00b7ren", "Sinn"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Gehet blo\u00df dahin,", "tokens": ["Ge\u00b7het", "blo\u00df", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PAV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Sein geheimes Liebes-Neigen", "tokens": ["Sein", "ge\u00b7hei\u00b7mes", "Lie\u00b7bes\u00b7Nei\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu mir \u00f6ffentlich zu zeigen,", "tokens": ["Zu", "mir", "\u00f6f\u00b7fent\u00b7lich", "zu", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und das gantze Hau\u00df", "tokens": ["Und", "das", "gant\u00b7ze", "Hau\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Macht sich Freude draus.", "tokens": ["Macht", "sich", "Freu\u00b7de", "draus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "NN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.26": {"line.1": {"text": "Herr! ich bins nicht werth,", "tokens": ["Herr", "!", "ich", "bins", "nicht", "werth", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Was du mir beschehrt.", "tokens": ["Was", "du", "mir", "be\u00b7schehrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Herr! hie hast du mich Geringen,", "tokens": ["Herr", "!", "hie", "hast", "du", "mich", "Ge\u00b7rin\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "VAFIN", "PPER", "PRF", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wilst du mich zu Stande bringen?", "tokens": ["Wilst", "du", "mich", "zu", "Stan\u00b7de", "brin\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Herr! da hast du mich:", "tokens": ["Herr", "!", "da", "hast", "du", "mich", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "VAFIN", "PPER", "PRF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Denn nun kenn ich dich.", "tokens": ["Denn", "nun", "kenn", "ich", "dich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}