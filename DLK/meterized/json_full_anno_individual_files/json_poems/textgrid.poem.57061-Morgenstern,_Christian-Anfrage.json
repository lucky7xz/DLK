{"textgrid.poem.57061": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Anfrage", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Ichthyologe Berthold Schrauben", "tokens": ["Der", "Ich\u00b7thy\u00b7o\u00b7lo\u00b7ge", "Bert\u00b7hold", "Schrau\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "will Umiges dem Autor glauben.", "tokens": ["will", "U\u00b7mi\u00b7ges", "dem", "Au\u00b7tor", "glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er kennt dergleichen aus Oviden,", "tokens": ["Er", "kennt", "derg\u00b7lei\u00b7chen", "aus", "O\u00b7vi\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "doch eines raubt ihm seinen Frieden:", "tokens": ["doch", "ei\u00b7nes", "raubt", "ihm", "sei\u00b7nen", "Frie\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wo n\u00e4mlich, fragt er, bleibt die Stelle", "tokens": ["Wo", "n\u00e4m\u00b7lich", ",", "fragt", "er", ",", "bleibt", "die", "Stel\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Fischwelt obbenannter Quelle.", "tokens": ["der", "Fischwelt", "ob\u00b7be\u00b7nann\u00b7ter", "Quel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Verk\u00f6rpert sie sich mit zum Raben \u2013", "tokens": ["Ver\u00b7k\u00f6r\u00b7pert", "sie", "sich", "mit", "zum", "Ra\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "APPRART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "oder verbleibt sie tot im Graben?", "tokens": ["o\u00b7der", "ver\u00b7bleibt", "sie", "tot", "im", "Gra\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Pers\u00f6nlich sei er f\u00fcr das Erste,", "tokens": ["Per\u00b7s\u00f6n\u00b7lich", "sei", "er", "f\u00fcr", "das", "Ers\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "dem Zweiten aber sei die mehrste", "tokens": ["dem", "Zwei\u00b7ten", "a\u00b7ber", "sei", "die", "mehrs\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wahrscheinlichkeit zu geben, da,", "tokens": ["Wahr\u00b7schein\u00b7lich\u00b7keit", "zu", "ge\u00b7ben", ",", "da", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,", "KOUS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "als seinerzeit die Tat geschah,", "tokens": ["als", "sei\u00b7ner\u00b7zeit", "die", "Tat", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "die Pica von dem m\u00e4chtigen Feinde", "tokens": ["die", "Pi\u00b7ca", "von", "dem", "m\u00e4ch\u00b7ti\u00b7gen", "Fein\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-----+--+-", "measure": "iambic.di.relaxed"}, "line.2": {"text": "in einen ohne Fischgemeinde", "tokens": ["in", "ei\u00b7nen", "oh\u00b7ne", "Fischge\u00b7mein\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "APPR", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "zun\u00e4chst gedachten Wasserlauf", "tokens": ["zu\u00b7n\u00e4chst", "ge\u00b7dach\u00b7ten", "Was\u00b7ser\u00b7lauf"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "verwandelt worden sei, worauf", "tokens": ["ver\u00b7wan\u00b7delt", "wor\u00b7den", "sei", ",", "wo\u00b7rauf"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["VVPP", "VAPP", "VAFIN", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "erst sp\u00e4ter jene, teils durch Neben\u2013", "tokens": ["erst", "sp\u00e4\u00b7ter", "je\u00b7ne", ",", "teils", "durch", "Ne\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PDS", "$,", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "gew\u00e4sser, teils durch Menschenstreben,", "tokens": ["ge\u00b7w\u00e4s\u00b7ser", ",", "teils", "durch", "Men\u00b7schen\u00b7stre\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "als \u00fcbliche Bewohnersph\u00e4re", "tokens": ["als", "\u00fcb\u00b7li\u00b7che", "Be\u00b7woh\u00b7ner\u00b7sph\u00e4\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ihm eingegliedert worden w\u00e4re.", "tokens": ["ihm", "ein\u00b7ge\u00b7glie\u00b7dert", "wor\u00b7den", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Es sei f\u00fcr einen Fall wie diesen,", "tokens": ["Es", "sei", "f\u00fcr", "ei\u00b7nen", "Fall", "wie", "die\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "KOKOM", "PDS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von Nennwert, nicht unangewiesen,", "tokens": ["von", "Nenn\u00b7wert", ",", "nicht", "un\u00b7an\u00b7ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wenn er, empf\u00e4nd man's gleich als B\u00fcrde,", "tokens": ["wenn", "er", ",", "em\u00b7pf\u00e4nd", "man's", "gleich", "als", "B\u00fcr\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "VVFIN", "PIS", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "bis auf den Grund durchleuchtet w\u00fcrde.", "tokens": ["bis", "auf", "den", "Grund", "durch\u00b7leuch\u00b7tet", "w\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Der Ichthyologe Berthold Schrauben", "tokens": ["Der", "Ich\u00b7thy\u00b7o\u00b7lo\u00b7ge", "Bert\u00b7hold", "Schrau\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "will Umiges dem Autor glauben.", "tokens": ["will", "U\u00b7mi\u00b7ges", "dem", "Au\u00b7tor", "glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er kennt dergleichen aus Oviden,", "tokens": ["Er", "kennt", "derg\u00b7lei\u00b7chen", "aus", "O\u00b7vi\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "doch eines raubt ihm seinen Frieden:", "tokens": ["doch", "ei\u00b7nes", "raubt", "ihm", "sei\u00b7nen", "Frie\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wo n\u00e4mlich, fragt er, bleibt die Stelle", "tokens": ["Wo", "n\u00e4m\u00b7lich", ",", "fragt", "er", ",", "bleibt", "die", "Stel\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Fischwelt obbenannter Quelle.", "tokens": ["der", "Fischwelt", "ob\u00b7be\u00b7nann\u00b7ter", "Quel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Verk\u00f6rpert sie sich mit zum Raben \u2013", "tokens": ["Ver\u00b7k\u00f6r\u00b7pert", "sie", "sich", "mit", "zum", "Ra\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "APPRART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "oder verbleibt sie tot im Graben?", "tokens": ["o\u00b7der", "ver\u00b7bleibt", "sie", "tot", "im", "Gra\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Pers\u00f6nlich sei er f\u00fcr das Erste,", "tokens": ["Per\u00b7s\u00f6n\u00b7lich", "sei", "er", "f\u00fcr", "das", "Ers\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "dem Zweiten aber sei die mehrste", "tokens": ["dem", "Zwei\u00b7ten", "a\u00b7ber", "sei", "die", "mehrs\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wahrscheinlichkeit zu geben, da,", "tokens": ["Wahr\u00b7schein\u00b7lich\u00b7keit", "zu", "ge\u00b7ben", ",", "da", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,", "KOUS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "als seinerzeit die Tat geschah,", "tokens": ["als", "sei\u00b7ner\u00b7zeit", "die", "Tat", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "die Pica von dem m\u00e4chtigen Feinde", "tokens": ["die", "Pi\u00b7ca", "von", "dem", "m\u00e4ch\u00b7ti\u00b7gen", "Fein\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-----+--+-", "measure": "iambic.di.relaxed"}, "line.2": {"text": "in einen ohne Fischgemeinde", "tokens": ["in", "ei\u00b7nen", "oh\u00b7ne", "Fischge\u00b7mein\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "APPR", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "zun\u00e4chst gedachten Wasserlauf", "tokens": ["zu\u00b7n\u00e4chst", "ge\u00b7dach\u00b7ten", "Was\u00b7ser\u00b7lauf"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "verwandelt worden sei, worauf", "tokens": ["ver\u00b7wan\u00b7delt", "wor\u00b7den", "sei", ",", "wo\u00b7rauf"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["VVPP", "VAPP", "VAFIN", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "erst sp\u00e4ter jene, teils durch Neben\u2013", "tokens": ["erst", "sp\u00e4\u00b7ter", "je\u00b7ne", ",", "teils", "durch", "Ne\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PDS", "$,", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "gew\u00e4sser, teils durch Menschenstreben,", "tokens": ["ge\u00b7w\u00e4s\u00b7ser", ",", "teils", "durch", "Men\u00b7schen\u00b7stre\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "als \u00fcbliche Bewohnersph\u00e4re", "tokens": ["als", "\u00fcb\u00b7li\u00b7che", "Be\u00b7woh\u00b7ner\u00b7sph\u00e4\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ihm eingegliedert worden w\u00e4re.", "tokens": ["ihm", "ein\u00b7ge\u00b7glie\u00b7dert", "wor\u00b7den", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Es sei f\u00fcr einen Fall wie diesen,", "tokens": ["Es", "sei", "f\u00fcr", "ei\u00b7nen", "Fall", "wie", "die\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "KOKOM", "PDS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von Nennwert, nicht unangewiesen,", "tokens": ["von", "Nenn\u00b7wert", ",", "nicht", "un\u00b7an\u00b7ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wenn er, empf\u00e4nd man's gleich als B\u00fcrde,", "tokens": ["wenn", "er", ",", "em\u00b7pf\u00e4nd", "man's", "gleich", "als", "B\u00fcr\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "VVFIN", "PIS", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "bis auf den Grund durchleuchtet w\u00fcrde.", "tokens": ["bis", "auf", "den", "Grund", "durch\u00b7leuch\u00b7tet", "w\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}