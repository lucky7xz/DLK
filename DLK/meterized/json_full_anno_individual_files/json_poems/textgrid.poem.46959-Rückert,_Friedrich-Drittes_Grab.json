{"textgrid.poem.46959": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Drittes Grab", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zu Ottensen, von Linden", "tokens": ["Zu", "Ot\u00b7ten\u00b7sen", ",", "von", "Lin\u00b7den"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "$,", "APPR", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Beschattet, auf dem Plan,", "tokens": ["Be\u00b7schat\u00b7tet", ",", "auf", "dem", "Plan", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ist noch ein Grab zu finden,", "tokens": ["Ist", "noch", "ein", "Grab", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dem soll, wer trauert, nahn.", "tokens": ["Dem", "soll", ",", "wer", "trau\u00b7ert", ",", "nahn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VMFIN", "$,", "PWS", "VVFIN", "$,", "ADJA", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Dort in der Linden Schauer", "tokens": ["Dort", "in", "der", "Lin\u00b7den", "Schau\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NE", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Soll lesen er am Stein", "tokens": ["Soll", "le\u00b7sen", "er", "am", "Stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "VVINF", "PPER", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Inschrift, da\u00df die Trauer", "tokens": ["Die", "In\u00b7schrift", ",", "da\u00df", "die", "Trau\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ihm mag gelindert sein.", "tokens": ["Ihm", "mag", "ge\u00b7lin\u00b7dert", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Mit seiner Gattin lieget", "tokens": ["Mit", "sei\u00b7ner", "Gat\u00b7tin", "lie\u00b7get"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und ihrem Sohne dort", "tokens": ["Und", "ih\u00b7rem", "Soh\u00b7ne", "dort"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein S\u00e4nger, der besieget", "tokens": ["Ein", "S\u00e4n\u00b7ger", ",", "der", "be\u00b7sie\u00b7get"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den Tod hat durch ein Wort.", "tokens": ["Den", "Tod", "hat", "durch", "ein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Es ist der fromme S\u00e4nger,", "tokens": ["Es", "ist", "der", "from\u00b7me", "S\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der sang des Heilands Sieg,", "tokens": ["Der", "sang", "des", "Hei\u00b7lands", "Sieg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu dem er, ein Empf\u00e4nger", "tokens": ["Zu", "dem", "er", ",", "ein", "Emp\u00b7f\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "$,", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Palm', im Tod entstieg.", "tokens": ["Der", "Palm'", ",", "im", "Tod", "ent\u00b7stieg", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Es ist derselbe S\u00e4nger,", "tokens": ["Es", "ist", "der\u00b7sel\u00b7be", "S\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der auch die Hermannsschlacht", "tokens": ["Der", "auch", "die", "Her\u00b7manns\u00b7schlacht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sang, eh' vom neuen Dr\u00e4nger", "tokens": ["Sang", ",", "eh'", "vom", "neu\u00b7en", "Dr\u00e4n\u00b7ger"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "APPRART", "ADJA", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Geknickt ward Deutschlands Macht.", "tokens": ["Ge\u00b7knickt", "ward", "Deutschlands", "Macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "NE", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Ich hoffe, da\u00df in Frieden", "tokens": ["Ich", "hof\u00b7fe", ",", "da\u00df", "in", "Frie\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er ruht' indes in Gott,", "tokens": ["Er", "ruht'", "in\u00b7des", "in", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nicht sah bei uns hienieden", "tokens": ["Nicht", "sah", "bei", "uns", "hien\u00b7ie\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVFIN", "APPR", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Des Feinds Gewalt und Spott.", "tokens": ["Des", "Feinds", "Ge\u00b7walt", "und", "Spott", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und so auch ruht' im Grabe", "tokens": ["Und", "so", "auch", "ruht'", "im", "Gra\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sein unverst\u00f6rt' Gebein,", "tokens": ["Sein", "un\u00b7ver\u00b7st\u00f6rt'", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als ob geschirmt es habe", "tokens": ["Als", "ob", "ge\u00b7schirmt", "es", "ha\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "VVPP", "PPER", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Engel vorm Entweihn.", "tokens": ["Ein", "En\u00b7gel", "vorm", "Ent\u00b7weihn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Es sind der Jahre zehen", "tokens": ["Es", "sind", "der", "Jah\u00b7re", "ze\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "CARD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Voll Druck und Tyrannei,", "tokens": ["Voll", "Druck", "und", "Ty\u00b7ran\u00b7nei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Voll ungest\u00fcmer Wehen,", "tokens": ["Voll", "un\u00b7ge\u00b7st\u00fc\u00b7mer", "We\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gegangen dran vorbei.", "tokens": ["Ge\u00b7gan\u00b7gen", "dran", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PAV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Sie haben nicht die Linden", "tokens": ["Sie", "ha\u00b7ben", "nicht", "die", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ART", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Gebrochen, die noch wehn,", "tokens": ["Ge\u00b7bro\u00b7chen", ",", "die", "noch", "wehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und nicht gemacht erblinden", "tokens": ["Und", "nicht", "ge\u00b7macht", "er\u00b7blin\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "VVPP", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Schrift, die noch zu sehn.", "tokens": ["Die", "Schrift", ",", "die", "noch", "zu", "sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Wohl hat, als dumpfer Brodem", "tokens": ["Wohl", "hat", ",", "als", "dum\u00b7pfer", "Bro\u00b7dem"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Knechtschaft uns umgab,", "tokens": ["Der", "Knecht\u00b7schaft", "uns", "um\u00b7gab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein leiser Freiheitsodem", "tokens": ["Ein", "lei\u00b7ser", "Frei\u00b7heit\u00b7so\u00b7dem"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Geweht von diesem Grab.", "tokens": ["Ge\u00b7weht", "von", "die\u00b7sem", "Grab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Wohl ist, als hier den Fl\u00fcgel", "tokens": ["Wohl", "ist", ",", "als", "hier", "den", "Fl\u00fc\u00b7gel"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Freiheit wieder schwang,", "tokens": ["Die", "Frei\u00b7heit", "wie\u00b7der", "schwang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "O Klopstock, deinem H\u00fcgel", "tokens": ["O", "Klops\u00b7tock", ",", "dei\u00b7nem", "H\u00fc\u00b7gel"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Entt\u00f6nt ein Freudenklang.", "tokens": ["Ent\u00b7t\u00f6nt", "ein", "Freu\u00b7den\u00b7klang", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Und wenn ein sinn'ger Waller", "tokens": ["Und", "wenn", "ein", "sinn'\u00b7ger", "Wal\u00b7ler"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Umher die Gr\u00e4ber jetzt", "tokens": ["Um\u00b7her", "die", "Gr\u00e4\u00b7ber", "jetzt"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Beschaut, tret' er nach aller", "tokens": ["Be\u00b7schaut", ",", "tret'", "er", "nach", "al\u00b7ler"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "VVFIN", "PPER", "APPR", "PIAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Beschau'n an dies zuletzt.", "tokens": ["Be\u00b7schau'n", "an", "dies", "zu\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Wenn dort ein tr\u00fcbes St\u00f6hnen", "tokens": ["Wenn", "dort", "ein", "tr\u00fc\u00b7bes", "St\u00f6h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den Busen hat geschwellt,", "tokens": ["Den", "Bu\u00b7sen", "hat", "ge\u00b7schwellt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So ist als zum Vers\u00f6hnen", "tokens": ["So", "ist", "als", "zum", "Ver\u00b7s\u00f6h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "KOKOM", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dies Grab hieher gestellt.", "tokens": ["Dies", "Grab", "hie\u00b7her", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Die Thr\u00e4nen der Vertrieb'nen,", "tokens": ["Die", "Thr\u00e4\u00b7nen", "der", "Ver\u00b7trie\u00b7b'\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Des Feldherrn dumpfe Gruft,", "tokens": ["Des", "Feld\u00b7herrn", "dump\u00b7fe", "Gruft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verschwinden vorm beschrieb'nen", "tokens": ["Ver\u00b7schwin\u00b7den", "vorm", "be\u00b7schrie\u00b7b'\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPRART", "ADJA"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Stein unterm Lindenduft;", "tokens": ["Stein", "un\u00b7term", "Lin\u00b7den\u00b7duft", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.15": {"line.1": {"text": "Wo wie in goldnen Streifen", "tokens": ["Wo", "wie", "in", "gold\u00b7nen", "Strei\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "KOKOM", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das Wort des S\u00e4ngers steht:", "tokens": ["Das", "Wort", "des", "S\u00e4n\u00b7gers", "steht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Saat von Gott ges\u00e4t,", "tokens": ["Saat", "von", "Gott", "ge\u00b7s\u00e4t", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Dem Tag der Garben zu reifen.", "tokens": ["Dem", "Tag", "der", "Gar\u00b7ben", "zu", "rei\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Zu Ottensen, von Linden", "tokens": ["Zu", "Ot\u00b7ten\u00b7sen", ",", "von", "Lin\u00b7den"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "$,", "APPR", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Beschattet, auf dem Plan,", "tokens": ["Be\u00b7schat\u00b7tet", ",", "auf", "dem", "Plan", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ist noch ein Grab zu finden,", "tokens": ["Ist", "noch", "ein", "Grab", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dem soll, wer trauert, nahn.", "tokens": ["Dem", "soll", ",", "wer", "trau\u00b7ert", ",", "nahn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VMFIN", "$,", "PWS", "VVFIN", "$,", "ADJA", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Dort in der Linden Schauer", "tokens": ["Dort", "in", "der", "Lin\u00b7den", "Schau\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NE", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Soll lesen er am Stein", "tokens": ["Soll", "le\u00b7sen", "er", "am", "Stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "VVINF", "PPER", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Inschrift, da\u00df die Trauer", "tokens": ["Die", "In\u00b7schrift", ",", "da\u00df", "die", "Trau\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ihm mag gelindert sein.", "tokens": ["Ihm", "mag", "ge\u00b7lin\u00b7dert", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Mit seiner Gattin lieget", "tokens": ["Mit", "sei\u00b7ner", "Gat\u00b7tin", "lie\u00b7get"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und ihrem Sohne dort", "tokens": ["Und", "ih\u00b7rem", "Soh\u00b7ne", "dort"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein S\u00e4nger, der besieget", "tokens": ["Ein", "S\u00e4n\u00b7ger", ",", "der", "be\u00b7sie\u00b7get"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den Tod hat durch ein Wort.", "tokens": ["Den", "Tod", "hat", "durch", "ein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Es ist der fromme S\u00e4nger,", "tokens": ["Es", "ist", "der", "from\u00b7me", "S\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der sang des Heilands Sieg,", "tokens": ["Der", "sang", "des", "Hei\u00b7lands", "Sieg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu dem er, ein Empf\u00e4nger", "tokens": ["Zu", "dem", "er", ",", "ein", "Emp\u00b7f\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "$,", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Palm', im Tod entstieg.", "tokens": ["Der", "Palm'", ",", "im", "Tod", "ent\u00b7stieg", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Es ist derselbe S\u00e4nger,", "tokens": ["Es", "ist", "der\u00b7sel\u00b7be", "S\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der auch die Hermannsschlacht", "tokens": ["Der", "auch", "die", "Her\u00b7manns\u00b7schlacht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sang, eh' vom neuen Dr\u00e4nger", "tokens": ["Sang", ",", "eh'", "vom", "neu\u00b7en", "Dr\u00e4n\u00b7ger"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "APPRART", "ADJA", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Geknickt ward Deutschlands Macht.", "tokens": ["Ge\u00b7knickt", "ward", "Deutschlands", "Macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "NE", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.21": {"line.1": {"text": "Ich hoffe, da\u00df in Frieden", "tokens": ["Ich", "hof\u00b7fe", ",", "da\u00df", "in", "Frie\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er ruht' indes in Gott,", "tokens": ["Er", "ruht'", "in\u00b7des", "in", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nicht sah bei uns hienieden", "tokens": ["Nicht", "sah", "bei", "uns", "hien\u00b7ie\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVFIN", "APPR", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Des Feinds Gewalt und Spott.", "tokens": ["Des", "Feinds", "Ge\u00b7walt", "und", "Spott", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Und so auch ruht' im Grabe", "tokens": ["Und", "so", "auch", "ruht'", "im", "Gra\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sein unverst\u00f6rt' Gebein,", "tokens": ["Sein", "un\u00b7ver\u00b7st\u00f6rt'", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als ob geschirmt es habe", "tokens": ["Als", "ob", "ge\u00b7schirmt", "es", "ha\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "VVPP", "PPER", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Engel vorm Entweihn.", "tokens": ["Ein", "En\u00b7gel", "vorm", "Ent\u00b7weihn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Es sind der Jahre zehen", "tokens": ["Es", "sind", "der", "Jah\u00b7re", "ze\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "CARD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Voll Druck und Tyrannei,", "tokens": ["Voll", "Druck", "und", "Ty\u00b7ran\u00b7nei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Voll ungest\u00fcmer Wehen,", "tokens": ["Voll", "un\u00b7ge\u00b7st\u00fc\u00b7mer", "We\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gegangen dran vorbei.", "tokens": ["Ge\u00b7gan\u00b7gen", "dran", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PAV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Sie haben nicht die Linden", "tokens": ["Sie", "ha\u00b7ben", "nicht", "die", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ART", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Gebrochen, die noch wehn,", "tokens": ["Ge\u00b7bro\u00b7chen", ",", "die", "noch", "wehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und nicht gemacht erblinden", "tokens": ["Und", "nicht", "ge\u00b7macht", "er\u00b7blin\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "VVPP", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Schrift, die noch zu sehn.", "tokens": ["Die", "Schrift", ",", "die", "noch", "zu", "sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Wohl hat, als dumpfer Brodem", "tokens": ["Wohl", "hat", ",", "als", "dum\u00b7pfer", "Bro\u00b7dem"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Knechtschaft uns umgab,", "tokens": ["Der", "Knecht\u00b7schaft", "uns", "um\u00b7gab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein leiser Freiheitsodem", "tokens": ["Ein", "lei\u00b7ser", "Frei\u00b7heit\u00b7so\u00b7dem"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Geweht von diesem Grab.", "tokens": ["Ge\u00b7weht", "von", "die\u00b7sem", "Grab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Wohl ist, als hier den Fl\u00fcgel", "tokens": ["Wohl", "ist", ",", "als", "hier", "den", "Fl\u00fc\u00b7gel"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Freiheit wieder schwang,", "tokens": ["Die", "Frei\u00b7heit", "wie\u00b7der", "schwang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "O Klopstock, deinem H\u00fcgel", "tokens": ["O", "Klops\u00b7tock", ",", "dei\u00b7nem", "H\u00fc\u00b7gel"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Entt\u00f6nt ein Freudenklang.", "tokens": ["Ent\u00b7t\u00f6nt", "ein", "Freu\u00b7den\u00b7klang", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Und wenn ein sinn'ger Waller", "tokens": ["Und", "wenn", "ein", "sinn'\u00b7ger", "Wal\u00b7ler"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Umher die Gr\u00e4ber jetzt", "tokens": ["Um\u00b7her", "die", "Gr\u00e4\u00b7ber", "jetzt"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Beschaut, tret' er nach aller", "tokens": ["Be\u00b7schaut", ",", "tret'", "er", "nach", "al\u00b7ler"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "VVFIN", "PPER", "APPR", "PIAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Beschau'n an dies zuletzt.", "tokens": ["Be\u00b7schau'n", "an", "dies", "zu\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Wenn dort ein tr\u00fcbes St\u00f6hnen", "tokens": ["Wenn", "dort", "ein", "tr\u00fc\u00b7bes", "St\u00f6h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den Busen hat geschwellt,", "tokens": ["Den", "Bu\u00b7sen", "hat", "ge\u00b7schwellt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So ist als zum Vers\u00f6hnen", "tokens": ["So", "ist", "als", "zum", "Ver\u00b7s\u00f6h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "KOKOM", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dies Grab hieher gestellt.", "tokens": ["Dies", "Grab", "hie\u00b7her", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Die Thr\u00e4nen der Vertrieb'nen,", "tokens": ["Die", "Thr\u00e4\u00b7nen", "der", "Ver\u00b7trie\u00b7b'\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Des Feldherrn dumpfe Gruft,", "tokens": ["Des", "Feld\u00b7herrn", "dump\u00b7fe", "Gruft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verschwinden vorm beschrieb'nen", "tokens": ["Ver\u00b7schwin\u00b7den", "vorm", "be\u00b7schrie\u00b7b'\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPRART", "ADJA"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Stein unterm Lindenduft;", "tokens": ["Stein", "un\u00b7term", "Lin\u00b7den\u00b7duft", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.30": {"line.1": {"text": "Wo wie in goldnen Streifen", "tokens": ["Wo", "wie", "in", "gold\u00b7nen", "Strei\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "KOKOM", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das Wort des S\u00e4ngers steht:", "tokens": ["Das", "Wort", "des", "S\u00e4n\u00b7gers", "steht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Saat von Gott ges\u00e4t,", "tokens": ["Saat", "von", "Gott", "ge\u00b7s\u00e4t", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Dem Tag der Garben zu reifen.", "tokens": ["Dem", "Tag", "der", "Gar\u00b7ben", "zu", "rei\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}