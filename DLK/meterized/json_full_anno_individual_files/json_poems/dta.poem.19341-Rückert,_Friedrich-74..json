{"dta.poem.19341": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "74.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1837", "urn": "urn:nbn:de:kobv:b4-200905195090", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "So sang ein armer Mann, des einz'ger Reichthum lag", "tokens": ["So", "sang", "ein", "ar\u00b7mer", "Mann", ",", "des", "einz'\u00b7ger", "Reicht\u00b7hum", "lag"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "An seinem Bienenstand und seinem Taubenschlag:", "tokens": ["An", "sei\u00b7nem", "Bie\u00b7nen\u00b7stand", "und", "sei\u00b7nem", "Tau\u00b7ben\u00b7schlag", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Sie haben all ihr Gut verz\u00e4unet und verschanzt,", "tokens": ["Sie", "ha\u00b7ben", "all", "ihr", "Gut", "ver\u00b7z\u00e4u\u00b7net", "und", "ver\u00b7schanzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "PPOSAT", "NN", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und was sie pflanzen drin, ist nicht f\u00fcr mich gepflanzt.", "tokens": ["Und", "was", "sie", "pflan\u00b7zen", "drin", ",", "ist", "nicht", "f\u00fcr", "mich", "ge\u00b7pflanzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "PTKVZ", "$,", "VAFIN", "PTKNEG", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich darf und mag auch nicht durchbrechen ihren Zaun,", "tokens": ["Ich", "darf", "und", "mag", "auch", "nicht", "durch\u00b7bre\u00b7chen", "ih\u00b7ren", "Zaun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KON", "VMFIN", "ADV", "PTKNEG", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und n\u00fcchtern ist die Lust, von au\u00dfen drein zu schaun.", "tokens": ["Und", "n\u00fcch\u00b7tern", "ist", "die", "Lust", ",", "von", "au\u00b7\u00dfen", "drein", "zu", "schaun", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "$,", "APPR", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Doch wenn ich selbst sie nicht beraube, so berauben", "tokens": ["Doch", "wenn", "ich", "selbst", "sie", "nicht", "be\u00b7rau\u00b7be", ",", "so", "be\u00b7rau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "PPER", "PTKNEG", "VVFIN", "$,", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nun meine Bienen sie f\u00fcr mich, und meine Tauben.", "tokens": ["Nun", "mei\u00b7ne", "Bie\u00b7nen", "sie", "f\u00fcr", "mich", ",", "und", "mei\u00b7ne", "Tau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PPER", "APPR", "PPER", "$,", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Die Tauben hier und dort aufpickend K\u00f6rnersaat,", "tokens": ["Die", "Tau\u00b7ben", "hier", "und", "dort", "auf\u00b7pi\u00b7ckend", "K\u00f6r\u00b7ner\u00b7saat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "KON", "ADV", "VVPP", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Bienen fort und fort eintragend Mundvorrath.", "tokens": ["Die", "Bie\u00b7nen", "fort", "und", "fort", "ein\u00b7tra\u00b7gend", "Mund\u00b7vor\u00b7rath", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "KON", "PTKVZ", "VVPP", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Die Tauben f\u00fcttern mir ihr Junges aus dem Kropf,", "tokens": ["Die", "Tau\u00b7ben", "f\u00fct\u00b7tern", "mir", "ihr", "Jun\u00b7ges", "aus", "dem", "Kropf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Bienen f\u00fcllen mir mit Flei\u00df den Honigtopf.", "tokens": ["Die", "Bie\u00b7nen", "f\u00fcl\u00b7len", "mir", "mit", "Flei\u00df", "den", "Ho\u00b7nig\u00b7topf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Wenn man vom Acker auch mir scheuchen will die Tauben,", "tokens": ["Wenn", "man", "vom", "A\u00b7cker", "auch", "mir", "scheu\u00b7chen", "will", "die", "Tau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "ADV", "PPER", "VVINF", "VMFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So mu\u00df man freien Flug den Bienen doch erlauben.", "tokens": ["So", "mu\u00df", "man", "frei\u00b7en", "Flug", "den", "Bie\u00b7nen", "doch", "er\u00b7lau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADJA", "NN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Und wenn uns dann im Haus entgeht der fette Braten,", "tokens": ["Und", "wenn", "uns", "dann", "im", "Haus", "ent\u00b7geht", "der", "fet\u00b7te", "Bra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPRART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So werden wir doch nie der S\u00fc\u00dfigkeit entrathen.", "tokens": ["So", "wer\u00b7den", "wir", "doch", "nie", "der", "S\u00fc\u00b7\u00dfig\u00b7keit", "ent\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}