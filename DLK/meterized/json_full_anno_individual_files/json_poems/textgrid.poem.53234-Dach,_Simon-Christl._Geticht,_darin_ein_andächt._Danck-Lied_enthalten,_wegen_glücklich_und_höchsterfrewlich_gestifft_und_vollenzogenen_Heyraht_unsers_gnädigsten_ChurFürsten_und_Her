{"textgrid.poem.53234": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Christl. Geticht, darin ein and\u00e4cht. Danck-Lied enthalten, wegen gl\u00fccklich und h\u00f6chsterfrewlich gestifft und vollenzogenen Heyraht unsers gn\u00e4digsten ChurF\u00fcrsten und Herrn, mit der Durchl. F\u00fcrstin und Fr. Fr. Loysen, gebohrnen Prinze\u00dfin von Rassaw, Orangen etc. etc. von dem Herzogthum Preussen dem Herren Himmels und der Erden dem\u00fchtigst auffzuopfern", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich sah' in hoher Lufft Sorwisen newlich schweben", "tokens": ["Ich", "sah'", "in", "ho\u00b7her", "Lufft", "Sor\u00b7wi\u00b7sen", "new\u00b7lich", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit einer hellen Wolck' an Kleides stat umbgeben,", "tokens": ["Mit", "ei\u00b7ner", "hel\u00b7len", "Wolck'", "an", "Klei\u00b7des", "stat", "umb\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein weit gestirnter Schweiff lag umb sie her gestreckt,", "tokens": ["Ein", "weit", "ge\u00b7stirn\u00b7ter", "Schweiff", "lag", "umb", "sie", "her", "ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "VVFIN", "APPR", "PPER", "APZR", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Strahlen hatten ihr das sch\u00f6ne Haupt bedeckt.", "tokens": ["Und", "Strah\u00b7len", "hat\u00b7ten", "ihr", "das", "sch\u00f6\u00b7ne", "Haupt", "be\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Sie f\u00fchrte zum Geleit viel tausend heilge Knaben", "tokens": ["Sie", "f\u00fchr\u00b7te", "zum", "Ge\u00b7leit", "viel", "tau\u00b7send", "heil\u00b7ge", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und Jungfern, die gesampt der Unschuld Zeugnis haben,", "tokens": ["Und", "Jung\u00b7fern", ",", "die", "ge\u00b7sampt", "der", "Un\u00b7schuld", "Zeug\u00b7nis", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "ADJD", "ART", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Sonne war noch nicht von ihrem Schlaff erwacht,", "tokens": ["Die", "Son\u00b7ne", "war", "noch", "nicht", "von", "ih\u00b7rem", "Schlaff", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Morgenroth brach an, und hie\u00df die dunkle Nacht", "tokens": ["Das", "Mor\u00b7gen\u00b7roth", "brach", "an", ",", "und", "hie\u00df", "die", "dunk\u00b7le", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Gem\u00e4hlich lichter seyn. Der Himmel geht von sammen", "tokens": ["Ge\u00b7m\u00e4h\u00b7lich", "lich\u00b7ter", "seyn", ".", "Der", "Him\u00b7mel", "geht", "von", "sam\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAINF", "$.", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und zeigt sein inner Theil von lauter Glantz und Flammen,", "tokens": ["Und", "zeigt", "sein", "in\u00b7ner", "Theil", "von", "lau\u00b7ter", "Glantz", "und", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie wann man sonst in Kalck- und Ziegel-Ofen sieht,", "tokens": ["Wie", "wann", "man", "sonst", "in", "Kal\u00b7ck", "und", "Zie\u00b7gel\u00b7O\u00b7fen", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PWAV", "PIS", "ADV", "APPR", "TRUNC", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da alles von der Loh und liechtem Brande gl\u00fcet,", "tokens": ["Da", "al\u00b7les", "von", "der", "Loh", "und", "liech\u00b7tem", "Bran\u00b7de", "gl\u00fcet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "So schien auch dieses hier. Ein Stuel von Edel-Steinen,", "tokens": ["So", "schien", "auch", "die\u00b7ses", "hier", ".", "Ein", "Stu\u00b7el", "von", "E\u00b7del\u00b7Stei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PDAT", "ADV", "$.", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die heller als der Mond' und ungleich alle scheinen,", "tokens": ["Die", "hel\u00b7ler", "als", "der", "Mond'", "und", "un\u00b7gleich", "al\u00b7le", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KOKOM", "ART", "NN", "KON", "ADJD", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Steht mitten ein gestellt, umb den viel Wolcken gehn,", "tokens": ["Steht", "mit\u00b7ten", "ein", "ge\u00b7stellt", ",", "umb", "den", "viel", "Wol\u00b7cken", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "VVPP", "$,", "KOUI", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Geister, die umbher theils fliegen, theils auch stehn.", "tokens": ["Und", "Geis\u00b7ter", ",", "die", "um\u00b7bher", "theils", "flie\u00b7gen", ",", "theils", "auch", "stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "ADV", "ADV", "VVINF", "$,", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Der aber auff dem Thron ward f\u00fcr den Seraphinen,", "tokens": ["Der", "a\u00b7ber", "auff", "dem", "Thron", "ward", "f\u00fcr", "den", "Se\u00b7ra\u00b7phi\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Ihm ohn unterla\u00df verdeckt mit Fl\u00fcgeln dienen,", "tokens": ["Die", "Ihm", "ohn", "un\u00b7ter\u00b7la\u00df", "ver\u00b7deckt", "mit", "Fl\u00fc\u00b7geln", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcr die\u00dfmal nicht erkant, nur die\u00df ist kunt allein,", "tokens": ["F\u00fcr", "die\u00df\u00b7mal", "nicht", "er\u00b7kant", ",", "nur", "die\u00df", "ist", "kunt", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PTKNEG", "VVPP", "$,", "ADV", "PDS", "VAFIN", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Er voll Heiligheit und Schrecken m\u00fcsse seyn.", "tokens": ["Da\u00df", "Er", "voll", "Hei\u00b7lig\u00b7heit", "und", "Schre\u00b7cken", "m\u00fcs\u00b7se", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "NN", "KON", "NN", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Sorwiese f\u00e4llt vor Ihm in tieffster Demut nieder", "tokens": ["Sor\u00b7wie\u00b7se", "f\u00e4llt", "vor", "Ihm", "in", "tieffs\u00b7ter", "De\u00b7mut", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "PPER", "APPR", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sampt ihrer kleinen Schaar, und ehrt durch s\u00fcsse Lieder", "tokens": ["Sampt", "ih\u00b7rer", "klei\u00b7nen", "Schaar", ",", "und", "ehrt", "durch", "s\u00fcs\u00b7se", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den, welchen alles ehrt, sie r\u00fchmet seine Trew", "tokens": ["Den", ",", "wel\u00b7chen", "al\u00b7les", "ehrt", ",", "sie", "r\u00fch\u00b7met", "sei\u00b7ne", "Trew"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAT", "PIS", "VVFIN", "$,", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und da\u00df Er ihr noch jetzt f\u00fcr andern gn\u00e4dig sey.", "tokens": ["Und", "da\u00df", "Er", "ihr", "noch", "jetzt", "f\u00fcr", "an\u00b7dern", "gn\u00e4\u00b7dig", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "ADV", "ADV", "APPR", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Sie danckt Ihm alles Gl\u00fcck, und wei\u00df nicht gnug zu melden", "tokens": ["Sie", "danckt", "Ihm", "al\u00b7les", "Gl\u00fcck", ",", "und", "wei\u00df", "nicht", "gnug", "zu", "mel\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "$,", "KON", "VVFIN", "PTKNEG", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von ihrer Sicherheit, vorau\u00df den thewren Helden", "tokens": ["Von", "ih\u00b7rer", "Si\u00b7cher\u00b7heit", ",", "vor\u00b7au\u00df", "den", "thew\u00b7ren", "Hel\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vom Hause Brandenburgk, des Himmels Bild und Pfand,", "tokens": ["Vom", "Hau\u00b7se", "Bran\u00b7den\u00b7burgk", ",", "des", "Him\u00b7mels", "Bild", "und", "Pfand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "$,", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Tr\u00e4gt sie dem H\u00f6chsten vor und fleht f\u00fcr seinen Standt.", "tokens": ["Tr\u00e4gt", "sie", "dem", "H\u00f6chs\u00b7ten", "vor", "und", "fleht", "f\u00fcr", "sei\u00b7nen", "Standt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Sie hat geh\u00f6rt, Er sey die Eh nun eingetretten,", "tokens": ["Sie", "hat", "ge\u00b7h\u00f6rt", ",", "Er", "sey", "die", "Eh", "nun", "ein\u00b7ge\u00b7tret\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PPER", "VAFIN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Warumb sie ihren Gott so \u00e4ngstig offt gebehten,", "tokens": ["Wa\u00b7rumb", "sie", "ih\u00b7ren", "Gott", "so", "\u00e4ngs\u00b7tig", "offt", "ge\u00b7beh\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die\u00df r\u00fchmet sie vorau\u00df so l\u00f6blich, als sie kan,", "tokens": ["Die\u00df", "r\u00fch\u00b7met", "sie", "vor\u00b7au\u00df", "so", "l\u00f6b\u00b7lich", ",", "als", "sie", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und hebt in vollem Chor ein solches Dancklied an:", "tokens": ["Und", "hebt", "in", "vol\u00b7lem", "Chor", "ein", "sol\u00b7ches", "Danck\u00b7lied", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "ART", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Herr aller Himmels-Schaaren,", "tokens": ["Herr", "al\u00b7ler", "Him\u00b7mels\u00b7Schaa\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dein Nahm ist hoch und her,", "tokens": ["Dein", "Nahm", "ist", "hoch", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wie haben ihn erfahren", "tokens": ["Wie", "ha\u00b7ben", "ihn", "er\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auff Erden und im Meer,", "tokens": ["Auff", "Er\u00b7den", "und", "im", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPRART", "NN", "$,"], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.5": {"text": "Kein Abgrund, keine Tieffe,", "tokens": ["Kein", "Ab\u00b7grund", ",", "kei\u00b7ne", "Tief\u00b7fe", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Die Bahn der schnellen Schiffe,", "tokens": ["Die", "Bahn", "der", "schnel\u00b7len", "Schif\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Ist deiner Herrschafft leer.", "tokens": ["Ist", "dei\u00b7ner", "Herr\u00b7schafft", "leer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Du wohnst in einem Glantze,", "tokens": ["Du", "wohnst", "in", "ei\u00b7nem", "Glant\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dem sich kein Mensch getrawt,", "tokens": ["Dem", "sich", "kein", "Mensch", "ge\u00b7trawt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "F\u00fchrst umb dich eine Schantze", "tokens": ["F\u00fchrst", "umb", "dich", "ei\u00b7ne", "Schant\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PRF", "ART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Von Wahrheit auffgebawt,", "tokens": ["Von", "Wahr\u00b7heit", "auff\u00b7ge\u00b7bawt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dich mu\u00df stets Recht begleiten,", "tokens": ["Dich", "mu\u00df", "stets", "Recht", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "NN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Und Trew wird aller Seiten", "tokens": ["Und", "Trew", "wird", "al\u00b7ler", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Umb dein Gezelt geschawt.", "tokens": ["Umb", "dein", "Ge\u00b7zelt", "ge\u00b7schawt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Geliebt dir was zu schaffen,", "tokens": ["Ge\u00b7liebt", "dir", "was", "zu", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So steht dir nach der Reih", "tokens": ["So", "steht", "dir", "nach", "der", "Reih"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Natura in den Waffen,", "tokens": ["Na\u00b7tu\u00b7ra", "in", "den", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und horchet was es sey:", "tokens": ["Und", "hor\u00b7chet", "was", "es", "sey", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dir tretten Hagel, Flammen,", "tokens": ["Dir", "tret\u00b7ten", "Ha\u00b7gel", ",", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sturm, Schnee und Frost zusammen", "tokens": ["Sturm", ",", "Schnee", "und", "Frost", "zu\u00b7sam\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und ungef\u00e4rbte Trew.", "tokens": ["Und", "un\u00b7ge\u00b7f\u00e4rb\u00b7te", "Trew", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Du giebst den Krei\u00df der Erden", "tokens": ["Du", "giebst", "den", "Krei\u00df", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den Menschen-Kindern ein,", "tokens": ["Den", "Men\u00b7schen\u00b7Kin\u00b7dern", "ein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein F\u00fcrst sampt seiner Heerden,", "tokens": ["Ein", "F\u00fcrst", "sampt", "sei\u00b7ner", "Heer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gott, huldigt dir allein,", "tokens": ["Gott", ",", "hul\u00b7digt", "dir", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dich schewt die Macht der Kayser,", "tokens": ["Dich", "schewt", "die", "Macht", "der", "Kay\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Du lessest grosse H\u00e4usser", "tokens": ["Du", "les\u00b7sest", "gros\u00b7se", "H\u00e4us\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Offt gantz ohn Erben seyn.", "tokens": ["Offt", "gantz", "ohn", "Er\u00b7ben", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Nimst du ein Land, O Richter,", "tokens": ["Nimst", "du", "ein", "Land", ",", "O", "Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "NE", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "In deines Eifers Sinn,", "tokens": ["In", "dei\u00b7nes", "Ei\u00b7fers", "Sinn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So raffst du ihm die Lichter", "tokens": ["So", "raffst", "du", "ihm", "die", "Lich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der frommen Herrschafft hin,", "tokens": ["Der", "from\u00b7men", "Herr\u00b7schafft", "hin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und l\u00e4ssest nicht ohn Leiden", "tokens": ["Und", "l\u00e4s\u00b7sest", "nicht", "ohn", "Lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Es andre Herren weiden,", "tokens": ["Es", "and\u00b7re", "Her\u00b7ren", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Die Schuld bringt den Gewinn.", "tokens": ["Die", "Schuld", "bringt", "den", "Ge\u00b7winn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Uns aber wilst du mehren", "tokens": ["Uns", "a\u00b7ber", "wilst", "du", "meh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das Brandenburger-Rei\u00df,", "tokens": ["Das", "Bran\u00b7den\u00b7bur\u00b7ger\u00b7Rei\u00df", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von dem wir jetzund h\u00f6ren", "tokens": ["Von", "dem", "wir", "je\u00b7tzund", "h\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der thewren Heyraht Prei\u00df,", "tokens": ["Der", "thew\u00b7ren", "Hey\u00b7raht", "Prei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der Held folgt deinem Willen,", "tokens": ["Der", "Held", "folgt", "dei\u00b7nem", "Wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Als den Er zu erf\u00fcllen", "tokens": ["Als", "den", "Er", "zu", "er\u00b7f\u00fcl\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "PPER", "PTKZU", "VVINF"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "F\u00fcr allen Dingen wei\u00df.", "tokens": ["F\u00fcr", "al\u00b7len", "Din\u00b7gen", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Du hast, Herr, unser Flehen,", "tokens": ["Du", "hast", ",", "Herr", ",", "un\u00b7ser", "Fle\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So wir f\u00fcr Ihn gethan,", "tokens": ["So", "wir", "f\u00fcr", "Ihn", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nun gn\u00e4dig angesehen,", "tokens": ["Nun", "gn\u00e4\u00b7dig", "an\u00b7ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Suchst unsrer Hoffnung Bahn", "tokens": ["Suchst", "uns\u00b7rer", "Hoff\u00b7nung", "Bahn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und sichern Stand zu machen,", "tokens": ["Und", "si\u00b7chern", "Stand", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und zeigst, worauff in Sachen", "tokens": ["Und", "zeigst", ",", "wo\u00b7rauff", "in", "Sa\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PWAV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sich Preussen gr\u00fcnden kan.", "tokens": ["Sich", "Preus\u00b7sen", "gr\u00fcn\u00b7den", "kan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Die Furcht ist nun verschwunden,", "tokens": ["Die", "Furcht", "ist", "nun", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das Schrecken liegt verheert,", "tokens": ["Das", "Schre\u00b7cken", "liegt", "ver\u00b7heert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Trost ist wieder funden,", "tokens": ["Der", "Trost", "ist", "wie\u00b7der", "fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der reiche Trost, und kehrt", "tokens": ["Der", "rei\u00b7che", "Trost", ",", "und", "kehrt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Gantz zu uns dein Gem\u00fcte,", "tokens": ["Gantz", "zu", "uns", "dein", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PPOSAT", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Sind wir der reichen G\u00fcte,", "tokens": ["Sind", "wir", "der", "rei\u00b7chen", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Getrewer Gott, wol wehrt?", "tokens": ["Ge\u00b7tre\u00b7wer", "Gott", ",", "wol", "wehrt", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Nun wird man Segen schawen,", "tokens": ["Nun", "wird", "man", "Se\u00b7gen", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "NN", "VVINF", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Der Friede wird bestehn,", "tokens": ["Der", "Frie\u00b7de", "wird", "be\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Gottesdienst sich bawen,", "tokens": ["Der", "Got\u00b7tes\u00b7dienst", "sich", "ba\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Das Recht im Schwange gehn,", "tokens": ["Das", "Recht", "im", "Schwan\u00b7ge", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das Feld wird tr\u00e4chtig bl\u00fchen,", "tokens": ["Das", "Feld", "wird", "tr\u00e4ch\u00b7tig", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Der Hau\u00df-Stand Kinder ziehen,", "tokens": ["Der", "Hau\u00df\u00b7Stand", "Kin\u00b7der", "zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Von Gn\u00fcg und Vorraht sch\u00f6n.", "tokens": ["Von", "Gn\u00fcg", "und", "Vor\u00b7raht", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Ist dir so viel gelegen", "tokens": ["Ist", "dir", "so", "viel", "ge\u00b7le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "An diesem Lande? Nein!", "tokens": ["An", "die\u00b7sem", "Lan\u00b7de", "?", "Nein", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$.", "PTKANT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von deines Namens wegen", "tokens": ["Von", "dei\u00b7nes", "Na\u00b7mens", "we\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Liebst du uns, Herr, allein,", "tokens": ["Liebst", "du", "uns", ",", "Herr", ",", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$,", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn soltest du auffb\u00fcrden", "tokens": ["Denn", "sol\u00b7test", "du", "auff\u00b7b\u00fcr\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Uns unsre Schuld, was w\u00fcrden", "tokens": ["Uns", "uns\u00b7re", "Schuld", ",", "was", "w\u00fcr\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "$,", "PWS", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wir arme Leute seyn?", "tokens": ["Wir", "ar\u00b7me", "Leu\u00b7te", "seyn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "O hilff es uns erkennen,", "tokens": ["O", "hilff", "es", "uns", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und la\u00df uns gegen dir", "tokens": ["Und", "la\u00df", "uns", "ge\u00b7gen", "dir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "APPR", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In Wieder-Liebe brennen,", "tokens": ["In", "Wie\u00b7der\u00b7Lie\u00b7be", "bren\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und nimmer mit Begier", "tokens": ["Und", "nim\u00b7mer", "mit", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Des Hertzens von dir wancken,", "tokens": ["Des", "Hert\u00b7zens", "von", "dir", "wan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "F\u00fcr allem la\u00df uns dancken", "tokens": ["F\u00fcr", "al\u00b7lem", "la\u00df", "uns", "dan\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "VVIMP", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Dir solcher Heyraht Zier.", "tokens": ["Dir", "sol\u00b7cher", "Hey\u00b7raht", "Zier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Man m\u00fcsse, Gott, dir halten", "tokens": ["Man", "m\u00fcs\u00b7se", ",", "Gott", ",", "dir", "hal\u00b7ten"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PIS", "VMFIN", "$,", "NN", "$,", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ohn Heucheley und List,", "tokens": ["Ohn", "Heu\u00b7che\u00b7ley", "und", "List", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bey Jungen und bey Alten,", "tokens": ["Bey", "Jun\u00b7gen", "und", "bey", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was dir gelobet ist,", "tokens": ["Was", "dir", "ge\u00b7lo\u00b7bet", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das Land soll vor dir springen", "tokens": ["Das", "Land", "soll", "vor", "dir", "sprin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und gantz einhellig singen:", "tokens": ["Und", "gantz", "ein\u00b7hel\u00b7lig", "sin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df du barmhertzig bist.", "tokens": ["Da\u00df", "du", "barm\u00b7hert\u00b7zig", "bist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Erhalt die Eh' im Segen,", "tokens": ["Er\u00b7halt", "die", "Eh'", "im", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die sich von dir entspinnt,", "tokens": ["Die", "sich", "von", "dir", "ent\u00b7spinnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "La\u00df sie sich, Vater, regen", "tokens": ["La\u00df", "sie", "sich", ",", "Va\u00b7ter", ",", "re\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["VVIMP", "PPER", "PRF", "$,", "NN", "$,", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Durch Kindes-Kindes-Kind,", "tokens": ["Durch", "Kin\u00b7des\u00b7Kin\u00b7des\u00b7Kind", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df ihr soviel auff Erden", "tokens": ["Da\u00df", "ihr", "so\u00b7viel", "auff", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ber\u00fchmter H\u00e4upter werden,", "tokens": ["Be\u00b7r\u00fchm\u00b7ter", "H\u00e4up\u00b7ter", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Als Stern am Himmel sind.", "tokens": ["Als", "Stern", "am", "Him\u00b7mel", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Sorwise hatte kaum die\u00df Danck-Lied vollenzogen,", "tokens": ["Sor\u00b7wi\u00b7se", "hat\u00b7te", "kaum", "die\u00df", "Dan\u00b7ck\u00b7Lied", "vol\u00b7len\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PDS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Als durch des Himmels Saal ein Engel k\u00f6mpt geflogen,", "tokens": ["Als", "durch", "des", "Him\u00b7mels", "Saal", "ein", "En\u00b7gel", "k\u00f6mpt", "ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der in der lincken tr\u00e4gt ein g\u00fcldnes Heyraht-Bandt,", "tokens": ["Der", "in", "der", "lin\u00b7cken", "tr\u00e4gt", "ein", "g\u00fcld\u00b7nes", "Hey\u00b7raht\u00b7Bandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und eine Liebes-Kertz in seiner rechten Hand:", "tokens": ["Und", "ei\u00b7ne", "Lie\u00b7bes\u00b7Kertz", "in", "sei\u00b7ner", "rech\u00b7ten", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Ein ander tr\u00e4gt ihm nach ein Buch, darin verschlossen", "tokens": ["Ein", "an\u00b7der", "tr\u00e4gt", "ihm", "nach", "ein", "Buch", ",", "da\u00b7rin", "ver\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PAV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Sam' enthalten ist der grossen Ehgenossen", "tokens": ["Der", "Sam'", "ent\u00b7hal\u00b7ten", "ist", "der", "gros\u00b7sen", "Eh\u00b7ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vom Hause Brandenburg wie von Orangen auch,", "tokens": ["Vom", "Hau\u00b7se", "Bran\u00b7den\u00b7burg", "wie", "von", "O\u00b7ran\u00b7gen", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "KOKOM", "APPR", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Inmittelst aber wird der Himmel voller Rauch,", "tokens": ["In\u00b7mit\u00b7telst", "a\u00b7ber", "wird", "der", "Him\u00b7mel", "vol\u00b7ler", "Rauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Und ein new Hochzeit-Lied von hundert tausent Zungen,", "tokens": ["Und", "ein", "new", "Hoch\u00b7zeit\u00b7Lied", "von", "hun\u00b7dert", "tau\u00b7sent", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "CARD", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die \u00fcber allen Witz der Menschen gehn, gesungen.", "tokens": ["Die", "\u00fc\u00b7ber", "al\u00b7len", "Witz", "der", "Men\u00b7schen", "gehn", ",", "ge\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "APPR", "PIAT", "NN", "ART", "NN", "VVINF", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sorwi\u00df und ihre Schaar schleust sich den Wolcken ein,", "tokens": ["Sor\u00b7wi\u00df", "und", "ih\u00b7re", "Schaar", "schleust", "sich", "den", "Wol\u00b7cken", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "PPOSAT", "NN", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und darauff k\u00f6mpt die Sonn auch mit dem Tages-Schein.", "tokens": ["Und", "dar\u00b7auff", "k\u00f6mpt", "die", "Sonn", "auch", "mit", "dem", "Ta\u00b7ges\u00b7Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}}, "stanza.25": {"line.1": {"text": "Ger\u00fccht, wie da\u00df du jetzt geschwiegen?", "tokens": ["Ge\u00b7r\u00fccht", ",", "wie", "da\u00df", "du", "jetzt", "ge\u00b7schwie\u00b7gen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOKOM", "KOUS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du schwatzest sonst ohn Ma\u00df und Rhu,", "tokens": ["Du", "schwat\u00b7zest", "sonst", "ohn", "Ma\u00df", "und", "Rhu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kein Argus ist so wach als du,", "tokens": ["Kein", "Ar\u00b7gus", "ist", "so", "wach", "als", "du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "KOKOM", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein West-Sturm wei\u00df dir gleich zu fliegen,", "tokens": ["Kein", "West\u00b7Sturm", "wei\u00df", "dir", "gleich", "zu", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kein Blitz nimmt Wettlauff mit dir an,", "tokens": ["Kein", "Blitz", "nimmt", "Wett\u00b7lauff", "mit", "dir", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "NN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was Ost und West mag thun und sagen,", "tokens": ["Was", "Ost", "und", "West", "mag", "thun", "und", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VMFIN", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wird pl\u00f6tzlich vor dir au\u00dfgetragen,", "tokens": ["Wird", "pl\u00f6tz\u00b7lich", "vor", "dir", "au\u00df\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wo kaum die Sonn hinreisen kan.", "tokens": ["Wo", "kaum", "die", "Sonn", "hin\u00b7rei\u00b7sen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wer hat dir jetzt gel\u00e4hmt die Fl\u00fcgel und die Zungen,", "tokens": ["Wer", "hat", "dir", "jetzt", "ge\u00b7l\u00e4hmt", "die", "Fl\u00fc\u00b7gel", "und", "die", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVPP", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df also sp\u00e4th au\u00df Niederland", "tokens": ["Da\u00df", "al\u00b7so", "sp\u00e4th", "au\u00df", "Nie\u00b7der\u00b7land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADJD", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "In Preussen her das thewre Band", "tokens": ["In", "Preus\u00b7sen", "her", "das", "thew\u00b7re", "Band"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APZR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Der grossen Hewrath kombt gedrungen?", "tokens": ["Der", "gros\u00b7sen", "Hew\u00b7rath", "kombt", "ge\u00b7drun\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Ich sah' in hoher Lufft Sorwisen newlich schweben", "tokens": ["Ich", "sah'", "in", "ho\u00b7her", "Lufft", "Sor\u00b7wi\u00b7sen", "new\u00b7lich", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit einer hellen Wolck' an Kleides stat umbgeben,", "tokens": ["Mit", "ei\u00b7ner", "hel\u00b7len", "Wolck'", "an", "Klei\u00b7des", "stat", "umb\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein weit gestirnter Schweiff lag umb sie her gestreckt,", "tokens": ["Ein", "weit", "ge\u00b7stirn\u00b7ter", "Schweiff", "lag", "umb", "sie", "her", "ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "VVFIN", "APPR", "PPER", "APZR", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Strahlen hatten ihr das sch\u00f6ne Haupt bedeckt.", "tokens": ["Und", "Strah\u00b7len", "hat\u00b7ten", "ihr", "das", "sch\u00f6\u00b7ne", "Haupt", "be\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Sie f\u00fchrte zum Geleit viel tausend heilge Knaben", "tokens": ["Sie", "f\u00fchr\u00b7te", "zum", "Ge\u00b7leit", "viel", "tau\u00b7send", "heil\u00b7ge", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und Jungfern, die gesampt der Unschuld Zeugnis haben,", "tokens": ["Und", "Jung\u00b7fern", ",", "die", "ge\u00b7sampt", "der", "Un\u00b7schuld", "Zeug\u00b7nis", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "ADJD", "ART", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Sonne war noch nicht von ihrem Schlaff erwacht,", "tokens": ["Die", "Son\u00b7ne", "war", "noch", "nicht", "von", "ih\u00b7rem", "Schlaff", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Morgenroth brach an, und hie\u00df die dunkle Nacht", "tokens": ["Das", "Mor\u00b7gen\u00b7roth", "brach", "an", ",", "und", "hie\u00df", "die", "dunk\u00b7le", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Gem\u00e4hlich lichter seyn. Der Himmel geht von sammen", "tokens": ["Ge\u00b7m\u00e4h\u00b7lich", "lich\u00b7ter", "seyn", ".", "Der", "Him\u00b7mel", "geht", "von", "sam\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAINF", "$.", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und zeigt sein inner Theil von lauter Glantz und Flammen,", "tokens": ["Und", "zeigt", "sein", "in\u00b7ner", "Theil", "von", "lau\u00b7ter", "Glantz", "und", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie wann man sonst in Kalck- und Ziegel-Ofen sieht,", "tokens": ["Wie", "wann", "man", "sonst", "in", "Kal\u00b7ck", "und", "Zie\u00b7gel\u00b7O\u00b7fen", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PWAV", "PIS", "ADV", "APPR", "TRUNC", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da alles von der Loh und liechtem Brande gl\u00fcet,", "tokens": ["Da", "al\u00b7les", "von", "der", "Loh", "und", "liech\u00b7tem", "Bran\u00b7de", "gl\u00fcet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "So schien auch dieses hier. Ein Stuel von Edel-Steinen,", "tokens": ["So", "schien", "auch", "die\u00b7ses", "hier", ".", "Ein", "Stu\u00b7el", "von", "E\u00b7del\u00b7Stei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PDAT", "ADV", "$.", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die heller als der Mond' und ungleich alle scheinen,", "tokens": ["Die", "hel\u00b7ler", "als", "der", "Mond'", "und", "un\u00b7gleich", "al\u00b7le", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KOKOM", "ART", "NN", "KON", "ADJD", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Steht mitten ein gestellt, umb den viel Wolcken gehn,", "tokens": ["Steht", "mit\u00b7ten", "ein", "ge\u00b7stellt", ",", "umb", "den", "viel", "Wol\u00b7cken", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "VVPP", "$,", "KOUI", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Geister, die umbher theils fliegen, theils auch stehn.", "tokens": ["Und", "Geis\u00b7ter", ",", "die", "um\u00b7bher", "theils", "flie\u00b7gen", ",", "theils", "auch", "stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "ADV", "ADV", "VVINF", "$,", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Der aber auff dem Thron ward f\u00fcr den Seraphinen,", "tokens": ["Der", "a\u00b7ber", "auff", "dem", "Thron", "ward", "f\u00fcr", "den", "Se\u00b7ra\u00b7phi\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Ihm ohn unterla\u00df verdeckt mit Fl\u00fcgeln dienen,", "tokens": ["Die", "Ihm", "ohn", "un\u00b7ter\u00b7la\u00df", "ver\u00b7deckt", "mit", "Fl\u00fc\u00b7geln", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcr die\u00dfmal nicht erkant, nur die\u00df ist kunt allein,", "tokens": ["F\u00fcr", "die\u00df\u00b7mal", "nicht", "er\u00b7kant", ",", "nur", "die\u00df", "ist", "kunt", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PTKNEG", "VVPP", "$,", "ADV", "PDS", "VAFIN", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Er voll Heiligheit und Schrecken m\u00fcsse seyn.", "tokens": ["Da\u00df", "Er", "voll", "Hei\u00b7lig\u00b7heit", "und", "Schre\u00b7cken", "m\u00fcs\u00b7se", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "NN", "KON", "NN", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Sorwiese f\u00e4llt vor Ihm in tieffster Demut nieder", "tokens": ["Sor\u00b7wie\u00b7se", "f\u00e4llt", "vor", "Ihm", "in", "tieffs\u00b7ter", "De\u00b7mut", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "PPER", "APPR", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sampt ihrer kleinen Schaar, und ehrt durch s\u00fcsse Lieder", "tokens": ["Sampt", "ih\u00b7rer", "klei\u00b7nen", "Schaar", ",", "und", "ehrt", "durch", "s\u00fcs\u00b7se", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den, welchen alles ehrt, sie r\u00fchmet seine Trew", "tokens": ["Den", ",", "wel\u00b7chen", "al\u00b7les", "ehrt", ",", "sie", "r\u00fch\u00b7met", "sei\u00b7ne", "Trew"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAT", "PIS", "VVFIN", "$,", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und da\u00df Er ihr noch jetzt f\u00fcr andern gn\u00e4dig sey.", "tokens": ["Und", "da\u00df", "Er", "ihr", "noch", "jetzt", "f\u00fcr", "an\u00b7dern", "gn\u00e4\u00b7dig", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "ADV", "ADV", "APPR", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Sie danckt Ihm alles Gl\u00fcck, und wei\u00df nicht gnug zu melden", "tokens": ["Sie", "danckt", "Ihm", "al\u00b7les", "Gl\u00fcck", ",", "und", "wei\u00df", "nicht", "gnug", "zu", "mel\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "$,", "KON", "VVFIN", "PTKNEG", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von ihrer Sicherheit, vorau\u00df den thewren Helden", "tokens": ["Von", "ih\u00b7rer", "Si\u00b7cher\u00b7heit", ",", "vor\u00b7au\u00df", "den", "thew\u00b7ren", "Hel\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vom Hause Brandenburgk, des Himmels Bild und Pfand,", "tokens": ["Vom", "Hau\u00b7se", "Bran\u00b7den\u00b7burgk", ",", "des", "Him\u00b7mels", "Bild", "und", "Pfand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "$,", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Tr\u00e4gt sie dem H\u00f6chsten vor und fleht f\u00fcr seinen Standt.", "tokens": ["Tr\u00e4gt", "sie", "dem", "H\u00f6chs\u00b7ten", "vor", "und", "fleht", "f\u00fcr", "sei\u00b7nen", "Standt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Sie hat geh\u00f6rt, Er sey die Eh nun eingetretten,", "tokens": ["Sie", "hat", "ge\u00b7h\u00f6rt", ",", "Er", "sey", "die", "Eh", "nun", "ein\u00b7ge\u00b7tret\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PPER", "VAFIN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Warumb sie ihren Gott so \u00e4ngstig offt gebehten,", "tokens": ["Wa\u00b7rumb", "sie", "ih\u00b7ren", "Gott", "so", "\u00e4ngs\u00b7tig", "offt", "ge\u00b7beh\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die\u00df r\u00fchmet sie vorau\u00df so l\u00f6blich, als sie kan,", "tokens": ["Die\u00df", "r\u00fch\u00b7met", "sie", "vor\u00b7au\u00df", "so", "l\u00f6b\u00b7lich", ",", "als", "sie", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und hebt in vollem Chor ein solches Dancklied an:", "tokens": ["Und", "hebt", "in", "vol\u00b7lem", "Chor", "ein", "sol\u00b7ches", "Danck\u00b7lied", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "ART", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Herr aller Himmels-Schaaren,", "tokens": ["Herr", "al\u00b7ler", "Him\u00b7mels\u00b7Schaa\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dein Nahm ist hoch und her,", "tokens": ["Dein", "Nahm", "ist", "hoch", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wie haben ihn erfahren", "tokens": ["Wie", "ha\u00b7ben", "ihn", "er\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auff Erden und im Meer,", "tokens": ["Auff", "Er\u00b7den", "und", "im", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPRART", "NN", "$,"], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.5": {"text": "Kein Abgrund, keine Tieffe,", "tokens": ["Kein", "Ab\u00b7grund", ",", "kei\u00b7ne", "Tief\u00b7fe", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Die Bahn der schnellen Schiffe,", "tokens": ["Die", "Bahn", "der", "schnel\u00b7len", "Schif\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Ist deiner Herrschafft leer.", "tokens": ["Ist", "dei\u00b7ner", "Herr\u00b7schafft", "leer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Du wohnst in einem Glantze,", "tokens": ["Du", "wohnst", "in", "ei\u00b7nem", "Glant\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dem sich kein Mensch getrawt,", "tokens": ["Dem", "sich", "kein", "Mensch", "ge\u00b7trawt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "F\u00fchrst umb dich eine Schantze", "tokens": ["F\u00fchrst", "umb", "dich", "ei\u00b7ne", "Schant\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PRF", "ART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Von Wahrheit auffgebawt,", "tokens": ["Von", "Wahr\u00b7heit", "auff\u00b7ge\u00b7bawt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dich mu\u00df stets Recht begleiten,", "tokens": ["Dich", "mu\u00df", "stets", "Recht", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "NN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Und Trew wird aller Seiten", "tokens": ["Und", "Trew", "wird", "al\u00b7ler", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Umb dein Gezelt geschawt.", "tokens": ["Umb", "dein", "Ge\u00b7zelt", "ge\u00b7schawt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Geliebt dir was zu schaffen,", "tokens": ["Ge\u00b7liebt", "dir", "was", "zu", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So steht dir nach der Reih", "tokens": ["So", "steht", "dir", "nach", "der", "Reih"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Natura in den Waffen,", "tokens": ["Na\u00b7tu\u00b7ra", "in", "den", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und horchet was es sey:", "tokens": ["Und", "hor\u00b7chet", "was", "es", "sey", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dir tretten Hagel, Flammen,", "tokens": ["Dir", "tret\u00b7ten", "Ha\u00b7gel", ",", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sturm, Schnee und Frost zusammen", "tokens": ["Sturm", ",", "Schnee", "und", "Frost", "zu\u00b7sam\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und ungef\u00e4rbte Trew.", "tokens": ["Und", "un\u00b7ge\u00b7f\u00e4rb\u00b7te", "Trew", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Du giebst den Krei\u00df der Erden", "tokens": ["Du", "giebst", "den", "Krei\u00df", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den Menschen-Kindern ein,", "tokens": ["Den", "Men\u00b7schen\u00b7Kin\u00b7dern", "ein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein F\u00fcrst sampt seiner Heerden,", "tokens": ["Ein", "F\u00fcrst", "sampt", "sei\u00b7ner", "Heer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gott, huldigt dir allein,", "tokens": ["Gott", ",", "hul\u00b7digt", "dir", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dich schewt die Macht der Kayser,", "tokens": ["Dich", "schewt", "die", "Macht", "der", "Kay\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Du lessest grosse H\u00e4usser", "tokens": ["Du", "les\u00b7sest", "gros\u00b7se", "H\u00e4us\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Offt gantz ohn Erben seyn.", "tokens": ["Offt", "gantz", "ohn", "Er\u00b7ben", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Nimst du ein Land, O Richter,", "tokens": ["Nimst", "du", "ein", "Land", ",", "O", "Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "NE", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "In deines Eifers Sinn,", "tokens": ["In", "dei\u00b7nes", "Ei\u00b7fers", "Sinn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So raffst du ihm die Lichter", "tokens": ["So", "raffst", "du", "ihm", "die", "Lich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der frommen Herrschafft hin,", "tokens": ["Der", "from\u00b7men", "Herr\u00b7schafft", "hin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und l\u00e4ssest nicht ohn Leiden", "tokens": ["Und", "l\u00e4s\u00b7sest", "nicht", "ohn", "Lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Es andre Herren weiden,", "tokens": ["Es", "and\u00b7re", "Her\u00b7ren", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Die Schuld bringt den Gewinn.", "tokens": ["Die", "Schuld", "bringt", "den", "Ge\u00b7winn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Uns aber wilst du mehren", "tokens": ["Uns", "a\u00b7ber", "wilst", "du", "meh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das Brandenburger-Rei\u00df,", "tokens": ["Das", "Bran\u00b7den\u00b7bur\u00b7ger\u00b7Rei\u00df", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von dem wir jetzund h\u00f6ren", "tokens": ["Von", "dem", "wir", "je\u00b7tzund", "h\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der thewren Heyraht Prei\u00df,", "tokens": ["Der", "thew\u00b7ren", "Hey\u00b7raht", "Prei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der Held folgt deinem Willen,", "tokens": ["Der", "Held", "folgt", "dei\u00b7nem", "Wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Als den Er zu erf\u00fcllen", "tokens": ["Als", "den", "Er", "zu", "er\u00b7f\u00fcl\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "PPER", "PTKZU", "VVINF"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "F\u00fcr allen Dingen wei\u00df.", "tokens": ["F\u00fcr", "al\u00b7len", "Din\u00b7gen", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Du hast, Herr, unser Flehen,", "tokens": ["Du", "hast", ",", "Herr", ",", "un\u00b7ser", "Fle\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So wir f\u00fcr Ihn gethan,", "tokens": ["So", "wir", "f\u00fcr", "Ihn", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nun gn\u00e4dig angesehen,", "tokens": ["Nun", "gn\u00e4\u00b7dig", "an\u00b7ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Suchst unsrer Hoffnung Bahn", "tokens": ["Suchst", "uns\u00b7rer", "Hoff\u00b7nung", "Bahn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und sichern Stand zu machen,", "tokens": ["Und", "si\u00b7chern", "Stand", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und zeigst, worauff in Sachen", "tokens": ["Und", "zeigst", ",", "wo\u00b7rauff", "in", "Sa\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PWAV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sich Preussen gr\u00fcnden kan.", "tokens": ["Sich", "Preus\u00b7sen", "gr\u00fcn\u00b7den", "kan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.41": {"line.1": {"text": "Die Furcht ist nun verschwunden,", "tokens": ["Die", "Furcht", "ist", "nun", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das Schrecken liegt verheert,", "tokens": ["Das", "Schre\u00b7cken", "liegt", "ver\u00b7heert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Trost ist wieder funden,", "tokens": ["Der", "Trost", "ist", "wie\u00b7der", "fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der reiche Trost, und kehrt", "tokens": ["Der", "rei\u00b7che", "Trost", ",", "und", "kehrt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Gantz zu uns dein Gem\u00fcte,", "tokens": ["Gantz", "zu", "uns", "dein", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PPOSAT", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Sind wir der reichen G\u00fcte,", "tokens": ["Sind", "wir", "der", "rei\u00b7chen", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Getrewer Gott, wol wehrt?", "tokens": ["Ge\u00b7tre\u00b7wer", "Gott", ",", "wol", "wehrt", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "Nun wird man Segen schawen,", "tokens": ["Nun", "wird", "man", "Se\u00b7gen", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "NN", "VVINF", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Der Friede wird bestehn,", "tokens": ["Der", "Frie\u00b7de", "wird", "be\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Gottesdienst sich bawen,", "tokens": ["Der", "Got\u00b7tes\u00b7dienst", "sich", "ba\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Das Recht im Schwange gehn,", "tokens": ["Das", "Recht", "im", "Schwan\u00b7ge", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das Feld wird tr\u00e4chtig bl\u00fchen,", "tokens": ["Das", "Feld", "wird", "tr\u00e4ch\u00b7tig", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Der Hau\u00df-Stand Kinder ziehen,", "tokens": ["Der", "Hau\u00df\u00b7Stand", "Kin\u00b7der", "zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Von Gn\u00fcg und Vorraht sch\u00f6n.", "tokens": ["Von", "Gn\u00fcg", "und", "Vor\u00b7raht", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Ist dir so viel gelegen", "tokens": ["Ist", "dir", "so", "viel", "ge\u00b7le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "An diesem Lande? Nein!", "tokens": ["An", "die\u00b7sem", "Lan\u00b7de", "?", "Nein", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$.", "PTKANT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von deines Namens wegen", "tokens": ["Von", "dei\u00b7nes", "Na\u00b7mens", "we\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Liebst du uns, Herr, allein,", "tokens": ["Liebst", "du", "uns", ",", "Herr", ",", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$,", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn soltest du auffb\u00fcrden", "tokens": ["Denn", "sol\u00b7test", "du", "auff\u00b7b\u00fcr\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Uns unsre Schuld, was w\u00fcrden", "tokens": ["Uns", "uns\u00b7re", "Schuld", ",", "was", "w\u00fcr\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "$,", "PWS", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wir arme Leute seyn?", "tokens": ["Wir", "ar\u00b7me", "Leu\u00b7te", "seyn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "O hilff es uns erkennen,", "tokens": ["O", "hilff", "es", "uns", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und la\u00df uns gegen dir", "tokens": ["Und", "la\u00df", "uns", "ge\u00b7gen", "dir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "APPR", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In Wieder-Liebe brennen,", "tokens": ["In", "Wie\u00b7der\u00b7Lie\u00b7be", "bren\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und nimmer mit Begier", "tokens": ["Und", "nim\u00b7mer", "mit", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Des Hertzens von dir wancken,", "tokens": ["Des", "Hert\u00b7zens", "von", "dir", "wan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "F\u00fcr allem la\u00df uns dancken", "tokens": ["F\u00fcr", "al\u00b7lem", "la\u00df", "uns", "dan\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "VVIMP", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Dir solcher Heyraht Zier.", "tokens": ["Dir", "sol\u00b7cher", "Hey\u00b7raht", "Zier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "Man m\u00fcsse, Gott, dir halten", "tokens": ["Man", "m\u00fcs\u00b7se", ",", "Gott", ",", "dir", "hal\u00b7ten"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PIS", "VMFIN", "$,", "NN", "$,", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ohn Heucheley und List,", "tokens": ["Ohn", "Heu\u00b7che\u00b7ley", "und", "List", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bey Jungen und bey Alten,", "tokens": ["Bey", "Jun\u00b7gen", "und", "bey", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was dir gelobet ist,", "tokens": ["Was", "dir", "ge\u00b7lo\u00b7bet", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das Land soll vor dir springen", "tokens": ["Das", "Land", "soll", "vor", "dir", "sprin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und gantz einhellig singen:", "tokens": ["Und", "gantz", "ein\u00b7hel\u00b7lig", "sin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df du barmhertzig bist.", "tokens": ["Da\u00df", "du", "barm\u00b7hert\u00b7zig", "bist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.46": {"line.1": {"text": "Erhalt die Eh' im Segen,", "tokens": ["Er\u00b7halt", "die", "Eh'", "im", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die sich von dir entspinnt,", "tokens": ["Die", "sich", "von", "dir", "ent\u00b7spinnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "La\u00df sie sich, Vater, regen", "tokens": ["La\u00df", "sie", "sich", ",", "Va\u00b7ter", ",", "re\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["VVIMP", "PPER", "PRF", "$,", "NN", "$,", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Durch Kindes-Kindes-Kind,", "tokens": ["Durch", "Kin\u00b7des\u00b7Kin\u00b7des\u00b7Kind", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df ihr soviel auff Erden", "tokens": ["Da\u00df", "ihr", "so\u00b7viel", "auff", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ber\u00fchmter H\u00e4upter werden,", "tokens": ["Be\u00b7r\u00fchm\u00b7ter", "H\u00e4up\u00b7ter", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Als Stern am Himmel sind.", "tokens": ["Als", "Stern", "am", "Him\u00b7mel", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "Sorwise hatte kaum die\u00df Danck-Lied vollenzogen,", "tokens": ["Sor\u00b7wi\u00b7se", "hat\u00b7te", "kaum", "die\u00df", "Dan\u00b7ck\u00b7Lied", "vol\u00b7len\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PDS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Als durch des Himmels Saal ein Engel k\u00f6mpt geflogen,", "tokens": ["Als", "durch", "des", "Him\u00b7mels", "Saal", "ein", "En\u00b7gel", "k\u00f6mpt", "ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der in der lincken tr\u00e4gt ein g\u00fcldnes Heyraht-Bandt,", "tokens": ["Der", "in", "der", "lin\u00b7cken", "tr\u00e4gt", "ein", "g\u00fcld\u00b7nes", "Hey\u00b7raht\u00b7Bandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und eine Liebes-Kertz in seiner rechten Hand:", "tokens": ["Und", "ei\u00b7ne", "Lie\u00b7bes\u00b7Kertz", "in", "sei\u00b7ner", "rech\u00b7ten", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Ein ander tr\u00e4gt ihm nach ein Buch, darin verschlossen", "tokens": ["Ein", "an\u00b7der", "tr\u00e4gt", "ihm", "nach", "ein", "Buch", ",", "da\u00b7rin", "ver\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PAV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Sam' enthalten ist der grossen Ehgenossen", "tokens": ["Der", "Sam'", "ent\u00b7hal\u00b7ten", "ist", "der", "gros\u00b7sen", "Eh\u00b7ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vom Hause Brandenburg wie von Orangen auch,", "tokens": ["Vom", "Hau\u00b7se", "Bran\u00b7den\u00b7burg", "wie", "von", "O\u00b7ran\u00b7gen", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "KOKOM", "APPR", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Inmittelst aber wird der Himmel voller Rauch,", "tokens": ["In\u00b7mit\u00b7telst", "a\u00b7ber", "wird", "der", "Him\u00b7mel", "vol\u00b7ler", "Rauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "Und ein new Hochzeit-Lied von hundert tausent Zungen,", "tokens": ["Und", "ein", "new", "Hoch\u00b7zeit\u00b7Lied", "von", "hun\u00b7dert", "tau\u00b7sent", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "CARD", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die \u00fcber allen Witz der Menschen gehn, gesungen.", "tokens": ["Die", "\u00fc\u00b7ber", "al\u00b7len", "Witz", "der", "Men\u00b7schen", "gehn", ",", "ge\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "APPR", "PIAT", "NN", "ART", "NN", "VVINF", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sorwi\u00df und ihre Schaar schleust sich den Wolcken ein,", "tokens": ["Sor\u00b7wi\u00df", "und", "ih\u00b7re", "Schaar", "schleust", "sich", "den", "Wol\u00b7cken", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "PPOSAT", "NN", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und darauff k\u00f6mpt die Sonn auch mit dem Tages-Schein.", "tokens": ["Und", "dar\u00b7auff", "k\u00f6mpt", "die", "Sonn", "auch", "mit", "dem", "Ta\u00b7ges\u00b7Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}}, "stanza.50": {"line.1": {"text": "Ger\u00fccht, wie da\u00df du jetzt geschwiegen?", "tokens": ["Ge\u00b7r\u00fccht", ",", "wie", "da\u00df", "du", "jetzt", "ge\u00b7schwie\u00b7gen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOKOM", "KOUS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du schwatzest sonst ohn Ma\u00df und Rhu,", "tokens": ["Du", "schwat\u00b7zest", "sonst", "ohn", "Ma\u00df", "und", "Rhu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kein Argus ist so wach als du,", "tokens": ["Kein", "Ar\u00b7gus", "ist", "so", "wach", "als", "du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "KOKOM", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein West-Sturm wei\u00df dir gleich zu fliegen,", "tokens": ["Kein", "West\u00b7Sturm", "wei\u00df", "dir", "gleich", "zu", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kein Blitz nimmt Wettlauff mit dir an,", "tokens": ["Kein", "Blitz", "nimmt", "Wett\u00b7lauff", "mit", "dir", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "NN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was Ost und West mag thun und sagen,", "tokens": ["Was", "Ost", "und", "West", "mag", "thun", "und", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VMFIN", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wird pl\u00f6tzlich vor dir au\u00dfgetragen,", "tokens": ["Wird", "pl\u00f6tz\u00b7lich", "vor", "dir", "au\u00df\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wo kaum die Sonn hinreisen kan.", "tokens": ["Wo", "kaum", "die", "Sonn", "hin\u00b7rei\u00b7sen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wer hat dir jetzt gel\u00e4hmt die Fl\u00fcgel und die Zungen,", "tokens": ["Wer", "hat", "dir", "jetzt", "ge\u00b7l\u00e4hmt", "die", "Fl\u00fc\u00b7gel", "und", "die", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVPP", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df also sp\u00e4th au\u00df Niederland", "tokens": ["Da\u00df", "al\u00b7so", "sp\u00e4th", "au\u00df", "Nie\u00b7der\u00b7land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADJD", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "In Preussen her das thewre Band", "tokens": ["In", "Preus\u00b7sen", "her", "das", "thew\u00b7re", "Band"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APZR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Der grossen Hewrath kombt gedrungen?", "tokens": ["Der", "gros\u00b7sen", "Hew\u00b7rath", "kombt", "ge\u00b7drun\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}