{"textgrid.poem.36516": {"metadata": {"author": {"name": "Gleim, Johann Wilhelm Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "15. Tamerlan und seine Tochter", "genre": "verse", "period": "N.A.", "pub_year": 1761, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die liebste Tochter Tamerlans,", "tokens": ["Die", "liebs\u00b7te", "Toch\u00b7ter", "Ta\u00b7mer\u00b7lans", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Helden, welcher Furcht und Schrecken", "tokens": ["Des", "Hel\u00b7den", ",", "wel\u00b7cher", "Furcht", "und", "Schre\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Um sich verbreitete, hieb eines sch\u00f6nen Hahns", "tokens": ["Um", "sich", "ver\u00b7brei\u00b7te\u00b7te", ",", "hieb", "ei\u00b7nes", "sch\u00f6\u00b7nen", "Hahns"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUI", "PRF", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Geliebter Henne, (die zu wecken,", "tokens": ["Ge\u00b7lieb\u00b7ter", "Hen\u00b7ne", ",", "(", "die", "zu", "we\u00b7cken", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "$(", "ART", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Hahn sein h\u00e4\u00dfliches Kikri,", "tokens": ["Der", "Hahn", "sein", "h\u00e4\u00df\u00b7li\u00b7ches", "Kik\u00b7ri", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Hochstehend, jeden Morgen schrie,)", "tokens": ["Hoch\u00b7ste\u00b7hend", ",", "je\u00b7den", "Mor\u00b7gen", "schrie", ",", ")"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "$,", "PIAT", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nicht dieses harten Schicksals wert,", "tokens": ["Nicht", "die\u00b7ses", "har\u00b7ten", "Schick\u00b7sals", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PDAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den Kopf ab mit des Vaters Schwert.", "tokens": ["Den", "Kopf", "ab", "mit", "des", "Va\u00b7ters", "Schwert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "APPR", "ART", "NN", "NE", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.2": {"line.1": {"text": "Der Vater sah's. Unschuldigen Gesch\u00f6pfen", "tokens": ["Der", "Va\u00b7ter", "sah'", "s.", "Un\u00b7schul\u00b7di\u00b7gen", "Ge\u00b7sch\u00f6p\u00b7fen"], "token_info": ["word", "word", "word", "abbreviation", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "NN"], "meter": "-+-+++-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Haut man den Kopf nicht ab, sprach er;", "tokens": ["Haut", "man", "den", "Kopf", "nicht", "ab", ",", "sprach", "er", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PIS", "ART", "NN", "PTKNEG", "PTKVZ", "$,", "VVFIN", "PPER", "$."], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.3": {"text": "Wer, Henker! lehrte dich des Hahns Gemahlin k\u00f6pfen?", "tokens": ["Wer", ",", "Hen\u00b7ker", "!", "lehr\u00b7te", "dich", "des", "Hahns", "Ge\u00b7mah\u00b7lin", "k\u00f6p\u00b7fen", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "NN", "$.", "VVFIN", "PRF", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Unmenschliche Tyrannin! wer?", "tokens": ["Un\u00b7menschli\u00b7che", "Ty\u00b7ran\u00b7nin", "!", "wer", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PWS", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "\u00bbherr Vater, Sie!\u00ab \u2013 Tyrannin, kniee nieder!", "tokens": ["\u00bb", "herr", "Va\u00b7ter", ",", "Sie", "!", "\u00ab", "\u2013", "Ty\u00b7ran\u00b7nin", ",", "kni\u00b7ee", "nie\u00b7der", "!"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NN", "NN", "$,", "PPER", "$.", "$(", "$(", "NE", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Gerechtigkeit mu\u00df sein, du bist mir nicht zu lieb!", "tokens": ["Ge\u00b7rech\u00b7tig\u00b7keit", "mu\u00df", "sein", ",", "du", "bist", "mir", "nicht", "zu", "lieb", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VAINF", "$,", "PPER", "VAFIN", "PPER", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Der Tochter zitterten, hinknieend, alle Glieder!", "tokens": ["Der", "Toch\u00b7ter", "zit\u00b7ter\u00b7ten", ",", "hin\u00b7kni\u00b7e\u00b7end", ",", "al\u00b7le", "Glie\u00b7der", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVPP", "$,", "PIAT", "NN", "$."], "meter": "-+-+---+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Vater nahm das Schwert, und hieb", "tokens": ["Der", "Va\u00b7ter", "nahm", "das", "Schwert", ",", "und", "hieb"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den sch\u00f6nsten M\u00e4dchenkopf", "tokens": ["Den", "sch\u00f6ns\u00b7ten", "M\u00e4d\u00b7chen\u00b7kopf"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der liebsten Tochter ab,", "tokens": ["Der", "liebs\u00b7ten", "Toch\u00b7ter", "ab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Fa\u00dft ihn beim Schopf", "tokens": ["Fa\u00dft", "ihn", "beim", "Schopf"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Und legt ihn sanft ins Grab!", "tokens": ["Und", "legt", "ihn", "sanft", "ins", "Grab", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ob wohl mit Menschenblut der gro\u00dfe Tamerlan,", "tokens": ["Ob", "wohl", "mit", "Men\u00b7schen\u00b7blut", "der", "gro\u00b7\u00dfe", "Ta\u00b7mer\u00b7lan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der b\u00f6se Thaten hat gethan,", "tokens": ["Der", "b\u00f6\u00b7se", "Tha\u00b7ten", "hat", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die G\u00f6tter zu vers\u00f6hnen meinte?", "tokens": ["Die", "G\u00f6t\u00b7ter", "zu", "ver\u00b7s\u00f6h\u00b7nen", "mein\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Lehrt's, Menschenlehrer! mich!", "tokens": ["Lehrt's", ",", "Men\u00b7schen\u00b7leh\u00b7rer", "!", "mich", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$.", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Zwo Thr\u00e4nen bitterlich.", "tokens": ["Zwo", "Thr\u00e4\u00b7nen", "bit\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die liebste Tochter Tamerlans,", "tokens": ["Die", "liebs\u00b7te", "Toch\u00b7ter", "Ta\u00b7mer\u00b7lans", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Helden, welcher Furcht und Schrecken", "tokens": ["Des", "Hel\u00b7den", ",", "wel\u00b7cher", "Furcht", "und", "Schre\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Um sich verbreitete, hieb eines sch\u00f6nen Hahns", "tokens": ["Um", "sich", "ver\u00b7brei\u00b7te\u00b7te", ",", "hieb", "ei\u00b7nes", "sch\u00f6\u00b7nen", "Hahns"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUI", "PRF", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Geliebter Henne, (die zu wecken,", "tokens": ["Ge\u00b7lieb\u00b7ter", "Hen\u00b7ne", ",", "(", "die", "zu", "we\u00b7cken", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "$(", "ART", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Hahn sein h\u00e4\u00dfliches Kikri,", "tokens": ["Der", "Hahn", "sein", "h\u00e4\u00df\u00b7li\u00b7ches", "Kik\u00b7ri", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Hochstehend, jeden Morgen schrie,)", "tokens": ["Hoch\u00b7ste\u00b7hend", ",", "je\u00b7den", "Mor\u00b7gen", "schrie", ",", ")"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "$,", "PIAT", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nicht dieses harten Schicksals wert,", "tokens": ["Nicht", "die\u00b7ses", "har\u00b7ten", "Schick\u00b7sals", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PDAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den Kopf ab mit des Vaters Schwert.", "tokens": ["Den", "Kopf", "ab", "mit", "des", "Va\u00b7ters", "Schwert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "APPR", "ART", "NN", "NE", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.7": {"line.1": {"text": "Der Vater sah's. Unschuldigen Gesch\u00f6pfen", "tokens": ["Der", "Va\u00b7ter", "sah'", "s.", "Un\u00b7schul\u00b7di\u00b7gen", "Ge\u00b7sch\u00f6p\u00b7fen"], "token_info": ["word", "word", "word", "abbreviation", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "NN"], "meter": "-+-+++-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Haut man den Kopf nicht ab, sprach er;", "tokens": ["Haut", "man", "den", "Kopf", "nicht", "ab", ",", "sprach", "er", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PIS", "ART", "NN", "PTKNEG", "PTKVZ", "$,", "VVFIN", "PPER", "$."], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.3": {"text": "Wer, Henker! lehrte dich des Hahns Gemahlin k\u00f6pfen?", "tokens": ["Wer", ",", "Hen\u00b7ker", "!", "lehr\u00b7te", "dich", "des", "Hahns", "Ge\u00b7mah\u00b7lin", "k\u00f6p\u00b7fen", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "NN", "$.", "VVFIN", "PRF", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Unmenschliche Tyrannin! wer?", "tokens": ["Un\u00b7menschli\u00b7che", "Ty\u00b7ran\u00b7nin", "!", "wer", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PWS", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "\u00bbherr Vater, Sie!\u00ab \u2013 Tyrannin, kniee nieder!", "tokens": ["\u00bb", "herr", "Va\u00b7ter", ",", "Sie", "!", "\u00ab", "\u2013", "Ty\u00b7ran\u00b7nin", ",", "kni\u00b7ee", "nie\u00b7der", "!"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NN", "NN", "$,", "PPER", "$.", "$(", "$(", "NE", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Gerechtigkeit mu\u00df sein, du bist mir nicht zu lieb!", "tokens": ["Ge\u00b7rech\u00b7tig\u00b7keit", "mu\u00df", "sein", ",", "du", "bist", "mir", "nicht", "zu", "lieb", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VAINF", "$,", "PPER", "VAFIN", "PPER", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Der Tochter zitterten, hinknieend, alle Glieder!", "tokens": ["Der", "Toch\u00b7ter", "zit\u00b7ter\u00b7ten", ",", "hin\u00b7kni\u00b7e\u00b7end", ",", "al\u00b7le", "Glie\u00b7der", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVPP", "$,", "PIAT", "NN", "$."], "meter": "-+-+---+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Vater nahm das Schwert, und hieb", "tokens": ["Der", "Va\u00b7ter", "nahm", "das", "Schwert", ",", "und", "hieb"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den sch\u00f6nsten M\u00e4dchenkopf", "tokens": ["Den", "sch\u00f6ns\u00b7ten", "M\u00e4d\u00b7chen\u00b7kopf"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der liebsten Tochter ab,", "tokens": ["Der", "liebs\u00b7ten", "Toch\u00b7ter", "ab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Fa\u00dft ihn beim Schopf", "tokens": ["Fa\u00dft", "ihn", "beim", "Schopf"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Und legt ihn sanft ins Grab!", "tokens": ["Und", "legt", "ihn", "sanft", "ins", "Grab", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Ob wohl mit Menschenblut der gro\u00dfe Tamerlan,", "tokens": ["Ob", "wohl", "mit", "Men\u00b7schen\u00b7blut", "der", "gro\u00b7\u00dfe", "Ta\u00b7mer\u00b7lan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der b\u00f6se Thaten hat gethan,", "tokens": ["Der", "b\u00f6\u00b7se", "Tha\u00b7ten", "hat", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die G\u00f6tter zu vers\u00f6hnen meinte?", "tokens": ["Die", "G\u00f6t\u00b7ter", "zu", "ver\u00b7s\u00f6h\u00b7nen", "mein\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Lehrt's, Menschenlehrer! mich!", "tokens": ["Lehrt's", ",", "Men\u00b7schen\u00b7leh\u00b7rer", "!", "mich", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$.", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Zwo Thr\u00e4nen bitterlich.", "tokens": ["Zwo", "Thr\u00e4\u00b7nen", "bit\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}