{"textgrid.poem.52801": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Der Brand in K\u00fchbach", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "K\u00fchbach \u2013 dieser Marktfleck zweier Staaten,", "tokens": ["K\u00fch\u00b7bach", "\u2013", "die\u00b7ser", "Markt\u00b7fleck", "zwei\u00b7er", "Staa\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PDAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Abgetheilt an Hessen und an Baden \u2013", "tokens": ["Ab\u00b7ge\u00b7theilt", "an", "Hes\u00b7sen", "und", "an", "Ba\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NE", "KON", "APPR", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Wurde neulich schrecklich heimgesucht;", "tokens": ["Wur\u00b7de", "neu\u00b7lich", "schreck\u00b7lich", "heim\u00b7ge\u00b7sucht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Nebst drei H\u00e4usern fra\u00df ein w\u00fcthend Feuer", "tokens": ["Nebst", "drei", "H\u00e4u\u00b7sern", "fra\u00df", "ein", "w\u00fct\u00b7hend", "Feu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "CARD", "NN", "VVFIN", "ART", "ADJD", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Noch sechs B\u00fcrgern jedem eine Scheuer", "tokens": ["Noch", "sechs", "B\u00fcr\u00b7gern", "je\u00b7dem", "ei\u00b7ne", "Scheu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "NN", "PIS", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Voll von Heu und siebzehn B\u00fcrgern Frucht.", "tokens": ["Voll", "von", "Heu", "und", "sieb\u00b7zehn", "B\u00fcr\u00b7gern", "Frucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "KON", "CARD", "NN", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Welch' ein Jammer, welch' ein H\u00e4nderingen", "tokens": ["Welch'", "ein", "Jam\u00b7mer", ",", "welch'", "ein", "H\u00e4n\u00b7de\u00b7rin\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "ART", "NN", "$,", "PWAT", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Gab es da! \u2013 Die Habe fortzubringen", "tokens": ["Gab", "es", "da", "!", "\u2013", "Die", "Ha\u00b7be", "fort\u00b7zu\u00b7brin\u00b7gen"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$.", "$(", "ART", "NN", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Sprangen Hundert ihren Br\u00fcdern zu;", "tokens": ["Spran\u00b7gen", "Hun\u00b7dert", "ih\u00b7ren", "Br\u00fc\u00b7dern", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Aber wenig, wenig konnt' man retten,", "tokens": ["A\u00b7ber", "we\u00b7nig", ",", "we\u00b7nig", "konnt'", "man", "ret\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PIS", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Fr\u00fcchte, Schreinwerk, Kleider, Wei\u00dfzeug, Betten", "tokens": ["Fr\u00fcch\u00b7te", ",", "Schrein\u00b7werk", ",", "Klei\u00b7der", ",", "Wei\u00df\u00b7zeug", ",", "Bet\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Waren weg beinah' in einem Nu.", "tokens": ["Wa\u00b7ren", "weg", "bei\u00b7nah'", "in", "ei\u00b7nem", "Nu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "APPR", "ART", "ADV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "W\u00e4ren nicht die Grenzer beigesprungen,", "tokens": ["W\u00e4\u00b7ren", "nicht", "die", "Gren\u00b7zer", "bei\u00b7ge\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Weiter w\u00e4r' die Wuth der Brunst gedrungen,", "tokens": ["Wei\u00b7ter", "w\u00e4r'", "die", "Wuth", "der", "Brunst", "ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Und vielleicht der halbe Ort verheert.", "tokens": ["Und", "viel\u00b7leicht", "der", "hal\u00b7be", "Ort", "ver\u00b7heert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Durch die Macht der vielen Feuerspritzen", "tokens": ["Durch", "die", "Macht", "der", "vie\u00b7len", "Feu\u00b7er\u00b7sprit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "PIAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Und durch M\u00e4nner, die Verstand besitzen,", "tokens": ["Und", "durch", "M\u00e4n\u00b7ner", ",", "die", "Ver\u00b7stand", "be\u00b7sit\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Ward dem weiter'n Umgriff abgewehrt.", "tokens": ["Ward", "dem", "wei\u00b7ter'n", "Um\u00b7griff", "ab\u00b7ge\u00b7wehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Ihre Namen will man jetzt nicht melden,", "tokens": ["Ih\u00b7re", "Na\u00b7men", "will", "man", "jetzt", "nicht", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PIS", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Gott wird jedem Biedermann vergelten,", "tokens": ["Gott", "wird", "je\u00b7dem", "Bie\u00b7der\u00b7mann", "ver\u00b7gel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Der bei diesem Brande th\u00e4tig war,", "tokens": ["Der", "bei", "die\u00b7sem", "Bran\u00b7de", "th\u00e4\u00b7tig", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PDAT", "NN", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Wird gewi\u00df die vielen Dienste lohnen,", "tokens": ["Wird", "ge\u00b7wi\u00df", "die", "vie\u00b7len", "Diens\u00b7te", "loh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "So der Mannsleut', wie der Weibspersonen,", "tokens": ["So", "der", "Manns\u00b7leut'", ",", "wie", "der", "Weibs\u00b7per\u00b7so\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Kurz der ganzen braven L\u00f6scherschaar.", "tokens": ["Kurz", "der", "gan\u00b7zen", "bra\u00b7ven", "L\u00f6\u00b7scher\u00b7schaar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Solch ein Ungl\u00fcck hat in hundert Jahren", "tokens": ["Solch", "ein", "Un\u00b7gl\u00fcck", "hat", "in", "hun\u00b7dert", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ART", "NN", "VAFIN", "APPR", "CARD", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Das betr\u00fcbte K\u00fchbach nicht erfahren,", "tokens": ["Das", "be\u00b7tr\u00fcb\u00b7te", "K\u00fch\u00b7bach", "nicht", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Als ihm eins durch dieses Feu'r gescheh'n,", "tokens": ["Als", "ihm", "eins", "durch", "die\u00b7ses", "Feu'r", "ge\u00b7scheh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und zum Unheil traf es lauter Hessen,", "tokens": ["Und", "zum", "Un\u00b7heil", "traf", "es", "lau\u00b7ter", "Hes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Diesen Umstand darf man nicht vergessen,", "tokens": ["Die\u00b7sen", "Um\u00b7stand", "darf", "man", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VMFIN", "PIS", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Weil sie fern von ihrem Lande steh'n.", "tokens": ["Weil", "sie", "fern", "von", "ih\u00b7rem", "Lan\u00b7de", "steh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "M\u00f6cht' mein Lied doch viele Leser r\u00fchren,", "tokens": ["M\u00f6cht'", "mein", "Lied", "doch", "vie\u00b7le", "Le\u00b7ser", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Da\u00df sie gern ein Opfer hier spendiren,", "tokens": ["Da\u00df", "sie", "gern", "ein", "Op\u00b7fer", "hier", "spen\u00b7di\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df die Reichen ihre B\u00f6rsen zieh'n!", "tokens": ["Da\u00df", "die", "Rei\u00b7chen", "ih\u00b7re", "B\u00f6r\u00b7sen", "zieh'n", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Was den Armen aus der Feuerkasse", "tokens": ["Was", "den", "Ar\u00b7men", "aus", "der", "Feu\u00b7er\u00b7kas\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Wird bezahlt, ist eine kleine Masse,", "tokens": ["Wird", "be\u00b7zahlt", ",", "ist", "ei\u00b7ne", "klei\u00b7ne", "Mas\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Reichet kaum zu frischer ", "tokens": ["Rei\u00b7chet", "kaum", "zu", "fri\u00b7scher"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "K\u00fchbach \u2013 dieser Marktfleck zweier Staaten,", "tokens": ["K\u00fch\u00b7bach", "\u2013", "die\u00b7ser", "Markt\u00b7fleck", "zwei\u00b7er", "Staa\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PDAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Abgetheilt an Hessen und an Baden \u2013", "tokens": ["Ab\u00b7ge\u00b7theilt", "an", "Hes\u00b7sen", "und", "an", "Ba\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NE", "KON", "APPR", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Wurde neulich schrecklich heimgesucht;", "tokens": ["Wur\u00b7de", "neu\u00b7lich", "schreck\u00b7lich", "heim\u00b7ge\u00b7sucht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Nebst drei H\u00e4usern fra\u00df ein w\u00fcthend Feuer", "tokens": ["Nebst", "drei", "H\u00e4u\u00b7sern", "fra\u00df", "ein", "w\u00fct\u00b7hend", "Feu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "CARD", "NN", "VVFIN", "ART", "ADJD", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Noch sechs B\u00fcrgern jedem eine Scheuer", "tokens": ["Noch", "sechs", "B\u00fcr\u00b7gern", "je\u00b7dem", "ei\u00b7ne", "Scheu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "NN", "PIS", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Voll von Heu und siebzehn B\u00fcrgern Frucht.", "tokens": ["Voll", "von", "Heu", "und", "sieb\u00b7zehn", "B\u00fcr\u00b7gern", "Frucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "KON", "CARD", "NN", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Welch' ein Jammer, welch' ein H\u00e4nderingen", "tokens": ["Welch'", "ein", "Jam\u00b7mer", ",", "welch'", "ein", "H\u00e4n\u00b7de\u00b7rin\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "ART", "NN", "$,", "PWAT", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Gab es da! \u2013 Die Habe fortzubringen", "tokens": ["Gab", "es", "da", "!", "\u2013", "Die", "Ha\u00b7be", "fort\u00b7zu\u00b7brin\u00b7gen"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$.", "$(", "ART", "NN", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Sprangen Hundert ihren Br\u00fcdern zu;", "tokens": ["Spran\u00b7gen", "Hun\u00b7dert", "ih\u00b7ren", "Br\u00fc\u00b7dern", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Aber wenig, wenig konnt' man retten,", "tokens": ["A\u00b7ber", "we\u00b7nig", ",", "we\u00b7nig", "konnt'", "man", "ret\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PIS", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Fr\u00fcchte, Schreinwerk, Kleider, Wei\u00dfzeug, Betten", "tokens": ["Fr\u00fcch\u00b7te", ",", "Schrein\u00b7werk", ",", "Klei\u00b7der", ",", "Wei\u00df\u00b7zeug", ",", "Bet\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Waren weg beinah' in einem Nu.", "tokens": ["Wa\u00b7ren", "weg", "bei\u00b7nah'", "in", "ei\u00b7nem", "Nu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "APPR", "ART", "ADV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "W\u00e4ren nicht die Grenzer beigesprungen,", "tokens": ["W\u00e4\u00b7ren", "nicht", "die", "Gren\u00b7zer", "bei\u00b7ge\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Weiter w\u00e4r' die Wuth der Brunst gedrungen,", "tokens": ["Wei\u00b7ter", "w\u00e4r'", "die", "Wuth", "der", "Brunst", "ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Und vielleicht der halbe Ort verheert.", "tokens": ["Und", "viel\u00b7leicht", "der", "hal\u00b7be", "Ort", "ver\u00b7heert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Durch die Macht der vielen Feuerspritzen", "tokens": ["Durch", "die", "Macht", "der", "vie\u00b7len", "Feu\u00b7er\u00b7sprit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "PIAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Und durch M\u00e4nner, die Verstand besitzen,", "tokens": ["Und", "durch", "M\u00e4n\u00b7ner", ",", "die", "Ver\u00b7stand", "be\u00b7sit\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Ward dem weiter'n Umgriff abgewehrt.", "tokens": ["Ward", "dem", "wei\u00b7ter'n", "Um\u00b7griff", "ab\u00b7ge\u00b7wehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Ihre Namen will man jetzt nicht melden,", "tokens": ["Ih\u00b7re", "Na\u00b7men", "will", "man", "jetzt", "nicht", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PIS", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Gott wird jedem Biedermann vergelten,", "tokens": ["Gott", "wird", "je\u00b7dem", "Bie\u00b7der\u00b7mann", "ver\u00b7gel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Der bei diesem Brande th\u00e4tig war,", "tokens": ["Der", "bei", "die\u00b7sem", "Bran\u00b7de", "th\u00e4\u00b7tig", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PDAT", "NN", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Wird gewi\u00df die vielen Dienste lohnen,", "tokens": ["Wird", "ge\u00b7wi\u00df", "die", "vie\u00b7len", "Diens\u00b7te", "loh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "So der Mannsleut', wie der Weibspersonen,", "tokens": ["So", "der", "Manns\u00b7leut'", ",", "wie", "der", "Weibs\u00b7per\u00b7so\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Kurz der ganzen braven L\u00f6scherschaar.", "tokens": ["Kurz", "der", "gan\u00b7zen", "bra\u00b7ven", "L\u00f6\u00b7scher\u00b7schaar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.11": {"line.1": {"text": "Solch ein Ungl\u00fcck hat in hundert Jahren", "tokens": ["Solch", "ein", "Un\u00b7gl\u00fcck", "hat", "in", "hun\u00b7dert", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ART", "NN", "VAFIN", "APPR", "CARD", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Das betr\u00fcbte K\u00fchbach nicht erfahren,", "tokens": ["Das", "be\u00b7tr\u00fcb\u00b7te", "K\u00fch\u00b7bach", "nicht", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Als ihm eins durch dieses Feu'r gescheh'n,", "tokens": ["Als", "ihm", "eins", "durch", "die\u00b7ses", "Feu'r", "ge\u00b7scheh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und zum Unheil traf es lauter Hessen,", "tokens": ["Und", "zum", "Un\u00b7heil", "traf", "es", "lau\u00b7ter", "Hes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Diesen Umstand darf man nicht vergessen,", "tokens": ["Die\u00b7sen", "Um\u00b7stand", "darf", "man", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VMFIN", "PIS", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Weil sie fern von ihrem Lande steh'n.", "tokens": ["Weil", "sie", "fern", "von", "ih\u00b7rem", "Lan\u00b7de", "steh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "M\u00f6cht' mein Lied doch viele Leser r\u00fchren,", "tokens": ["M\u00f6cht'", "mein", "Lied", "doch", "vie\u00b7le", "Le\u00b7ser", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Da\u00df sie gern ein Opfer hier spendiren,", "tokens": ["Da\u00df", "sie", "gern", "ein", "Op\u00b7fer", "hier", "spen\u00b7di\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df die Reichen ihre B\u00f6rsen zieh'n!", "tokens": ["Da\u00df", "die", "Rei\u00b7chen", "ih\u00b7re", "B\u00f6r\u00b7sen", "zieh'n", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Was den Armen aus der Feuerkasse", "tokens": ["Was", "den", "Ar\u00b7men", "aus", "der", "Feu\u00b7er\u00b7kas\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Wird bezahlt, ist eine kleine Masse,", "tokens": ["Wird", "be\u00b7zahlt", ",", "ist", "ei\u00b7ne", "klei\u00b7ne", "Mas\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Reichet kaum zu frischer ", "tokens": ["Rei\u00b7chet", "kaum", "zu", "fri\u00b7scher"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}