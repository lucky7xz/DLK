{"dta.poem.19885": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "Mamsel La Regle .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1778", "urn": "urn:nbn:de:kobv:b4-20090519672", "language": ["de:0.99"], "booktitle": "B\u00fcrger, Gottfried August: Gedichte. G\u00f6ttingen, 1778."}, "poem": {"stanza.1": {"line.1": {"text": "Halb griechische, halb auch franz\u00f6sche Donne,               ", "tokens": ["Halb", "grie\u00b7chi\u00b7sche", ",", "halb", "auch", "fran\u00b7z\u00f6\u00b7sche", "Don\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "$,", "ADJD", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Ist Regula die wackerste Ma Bonne;", "tokens": ["Ist", "Re\u00b7gu\u00b7la", "die", "wa\u00b7ckers\u00b7te", "Ma", "Bon\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nimt sorgsam \u00fcberal, nimt Tag und Nacht", "tokens": ["Nimt", "sorg\u00b7sam", "\u00fc\u00b7be\u00b7ral", ",", "nimt", "Tag", "und", "Nacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "ADJD", "$,", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die lieben Kinderchen ganz wol in Acht;", "tokens": ["Die", "lie\u00b7ben", "Kin\u00b7der\u00b7chen", "ganz", "wol", "in", "Acht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "APPR", "CARD", "$."], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.5": {"text": "Weis wolgewandt zu g\u00e4ngeln, weis spaziren", "tokens": ["Weis", "wol\u00b7ge\u00b7wandt", "zu", "g\u00e4n\u00b7geln", ",", "weis", "spa\u00b7zi\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADJD", "PTKZU", "VVINF", "$,", "PTKVZ", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Den kleinen Trup vorsichtiglich zu f\u00fchren;", "tokens": ["Den", "klei\u00b7nen", "Trup", "vor\u00b7sich\u00b7tig\u00b7lich", "zu", "f\u00fch\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und l\u00e4st f\u00fcrwahr! den trauten Kindelein", "tokens": ["Und", "l\u00e4st", "f\u00fcr\u00b7wahr", "!", "den", "trau\u00b7ten", "Kin\u00b7de\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Gefar und Leid nicht eben leicht bedr\u00e4un. \u2014", "tokens": ["Ge\u00b7far", "und", "Leid", "nicht", "e\u00b7ben", "leicht", "be\u00b7dr\u00e4un", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "NN", "PTKNEG", "ADV", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Um\u2019s kleine Volk nicht zu skandalisiren,", "tokens": ["Um's", "klei\u00b7ne", "Volk", "nicht", "zu", "skan\u00b7da\u00b7li\u00b7si\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.10": {"text": "Mag man sich gern ein bischen mit geniren.", "tokens": ["Mag", "man", "sich", "gern", "ein", "bi\u00b7schen", "mit", "ge\u00b7ni\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PRF", "ADV", "ART", "ADV", "APPR", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.11": {"text": "Oft hat\u2019s mich, wann um nichts und wider nichts,", "tokens": ["Oft", "hat's", "mich", ",", "wann", "um", "nichts", "und", "wi\u00b7der", "nichts", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PWAV", "APPR", "PIS", "KON", "APPR", "PIS", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "So Einer da, unartiges Gez\u00fcchts,", "tokens": ["So", "Ei\u00b7ner", "da", ",", "un\u00b7ar\u00b7ti\u00b7ges", "Ge\u00b7z\u00fcchts", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Aus Uebermut, der Bonne blos zum Possen,", "tokens": ["Aus", "Ue\u00b7ber\u00b7mut", ",", "der", "Bon\u00b7ne", "blos", "zum", "Pos\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Nicht folgsam war, oft hat\u2019s mich bald verdrossen.", "tokens": ["Nicht", "folg\u00b7sam", "war", ",", "oft", "hat's", "mich", "bald", "ver\u00b7dros\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VAFIN", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Doch wenn sie gar zu steif, mit Schneckenschrit,", "tokens": ["Doch", "wenn", "sie", "gar", "zu", "steif", ",", "mit", "Schne\u00b7cken\u00b7schrit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PTKA", "ADJD", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Durch nakte G\u00e4ng\u2019 und Sandalleen trit,", "tokens": ["Durch", "nak\u00b7te", "G\u00e4ng'", "und", "San\u00b7dal\u00b7le\u00b7en", "trit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und hin und her hofmeistert: \u201eFein gerade!", "tokens": ["Und", "hin", "und", "her", "hof\u00b7meis\u00b7tert", ":", "\u201e", "Fein", "ge\u00b7ra\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "KON", "ADV", "VVFIN", "$.", "$(", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "H\u00fcbsch F\u00fcschen aus- und einw\u00e4rts h\u00fcbsch die Wade!", "tokens": ["H\u00fcbsch", "F\u00fc\u00b7schen", "aus", "und", "ein\u00b7w\u00e4rts", "h\u00fcbsch", "die", "Wa\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "TRUNC", "KON", "ADV", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Den R\u00fccken schlank! Fein Hals und Kopf empor!", "tokens": ["Den", "R\u00fc\u00b7cken", "schlank", "!", "Fein", "Hals", "und", "Kopf", "em\u00b7por", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "NN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Zur\u00fck die Schultern! Bauch ein! Brust hervor!\u201e", "tokens": ["Zu\u00b7r\u00fck", "die", "Schul\u00b7tern", "!", "Bauch", "ein", "!", "Brust", "her\u00b7vor", "!", "\u201e"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "$.", "NN", "PTKVZ", "$.", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wehren wil, zur Linken oder Rechten,", "tokens": ["Und", "weh\u00b7ren", "wil", ",", "zur", "Lin\u00b7ken", "o\u00b7der", "Rech\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "$,", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Eins auszutraben, Straus und Kranz zu flechten,", "tokens": ["Eins", "aus\u00b7zu\u00b7tra\u00b7ben", ",", "Straus", "und", "Kranz", "zu", "flech\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVIZU", "$,", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Das last hier ein und aus zum Ohr dort wehn!", "tokens": ["Das", "last", "hier", "ein", "und", "aus", "zum", "Ohr", "dort", "wehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PTKVZ", "KON", "APPR", "APPRART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Last, Br\u00fcderchen, die alte Strunsel gehn!", "tokens": ["Last", ",", "Br\u00fc\u00b7der\u00b7chen", ",", "die", "al\u00b7te", "Strun\u00b7sel", "gehn", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.11": {"text": "Nur Kinder mag also ihr Laufzaum sch\u00fcrzen!", "tokens": ["Nur", "Kin\u00b7der", "mag", "al\u00b7so", "ihr", "Lauf\u00b7zaum", "sch\u00fcr\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VMFIN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Was thut\u2019s, ob wir mal stolpern oder st\u00fcrzen.", "tokens": ["Was", "thut's", ",", "ob", "wir", "mal", "stol\u00b7pern", "o\u00b7der", "st\u00fcr\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}