{"textgrid.poem.49828": {"metadata": {"author": {"name": "Sachs, Hans", "birth": "N.A.", "death": "N.A."}, "title": "Historia: Bapst Sylvester der ander ergab sich dem teufel", "genre": "verse", "period": "N.A.", "pub_year": 1558, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die chronica sagen f\u00fcrwar,", "tokens": ["Die", "chro\u00b7ni\u00b7ca", "sa\u00b7gen", "f\u00fcr\u00b7war", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "FM", "FM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "als man zelet neunhundert jar", "tokens": ["als", "man", "ze\u00b7let", "neun\u00b7hun\u00b7dert", "jar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVFIN", "CARD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und vier und neunzig on gefer,", "tokens": ["und", "vier", "und", "neun\u00b7zig", "on", "ge\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "KON", "CARD", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da regieret bapst Sylvester,", "tokens": ["da", "re\u00b7gie\u00b7ret", "bapst", "Syl\u00b7ves\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "der ander dises namens da.", "tokens": ["der", "an\u00b7der", "di\u00b7ses", "na\u00b7mens", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der war b\u00fcrtig aus Gallia", "tokens": ["der", "war", "b\u00fcr\u00b7tig", "aus", "Gal\u00b7lia"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "VAFIN", "ADJD", "APPR", "NE"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "und vormals Gilbertus genant,", "tokens": ["und", "vor\u00b7mals", "Gil\u00b7ber\u00b7tus", "ge\u00b7nant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "kam in seiner jugent zuhant", "tokens": ["kam", "in", "sei\u00b7ner", "ju\u00b7gent", "zu\u00b7hant"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "in ein kloster, zu werden frum,", "tokens": ["in", "ein", "klos\u00b7ter", ",", "zu", "wer\u00b7den", "frum", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "PTKZU", "VAINF", "PTKVZ", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.10": {"text": "im aurelianischen bistum,", "tokens": ["im", "au\u00b7re\u00b7li\u00b7a\u00b7ni\u00b7schen", "bis\u00b7tum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.11": {"text": "doch wider aus dem kloster sprung", "tokens": ["doch", "wi\u00b7der", "aus", "dem", "klos\u00b7ter", "sprung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "und ergab sich noch also jung", "tokens": ["und", "er\u00b7gab", "sich", "noch", "al\u00b7so", "jung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADV", "ADJD"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.13": {"text": "dem teufel und auf schwarze kunst,", "tokens": ["dem", "teu\u00b7fel", "und", "auf", "schwar\u00b7ze", "kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "dardurch zu erlangen die gunst,", "tokens": ["dar\u00b7durch", "zu", "er\u00b7lan\u00b7gen", "die", "gunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PTKZU", "VVINF", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.15": {"text": "zu herschen das r\u00f6misch bapsttum.", "tokens": ["zu", "her\u00b7schen", "das", "r\u00f6\u00b7misch", "bapst\u00b7tum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "ADJD", "PTKVZ", "$."], "meter": "-+--+---", "measure": "iambic.di.relaxed"}, "line.16": {"text": "der teufel das mit im aufnum,", "tokens": ["der", "teu\u00b7fel", "das", "mit", "im", "auf\u00b7num", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "APPR", "APPRART", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.17": {"text": "doch das er sein wer nach seim tot.", "tokens": ["doch", "das", "er", "sein", "wer", "nach", "seim", "tot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PPER", "PPOSAT", "PWS", "APPR", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "das verschrib er mit seim blut rot.", "tokens": ["das", "ver\u00b7schrib", "er", "mit", "seim", "blut", "rot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.19": {"text": "doch fraget in Gilbertus eben,", "tokens": ["doch", "fra\u00b7get", "in", "Gil\u00b7ber\u00b7tus", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "ADV", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.20": {"text": "wie lang er w\u00fcrt auf erden leben.", "tokens": ["wie", "lang", "er", "w\u00fcrt", "auf", "er\u00b7den", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "der teufel sprach: du stirbst nach dem,", "tokens": ["der", "teu\u00b7fel", "sprach", ":", "du", "stirbst", "nach", "dem", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "ART", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.22": {"text": "wenn du ber\u00fcrst Jerusalem.", "tokens": ["wenn", "du", "be\u00b7r\u00fcrst", "Je\u00b7ru\u00b7sa\u00b7lem", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "NE", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.23": {"text": "Gilbertus dacht in seim gem\u00fct;", "tokens": ["Gil\u00b7ber\u00b7tus", "dacht", "in", "seim", "ge\u00b7m\u00fct", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NE", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.24": {"text": "vor Jerusalem ich mich h\u00fct,", "tokens": ["vor", "Je\u00b7ru\u00b7sa\u00b7lem", "ich", "mich", "h\u00fct", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PPER", "PRF", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "das ich kom nimmermer dahin.", "tokens": ["das", "ich", "kom", "nim\u00b7mer\u00b7mer", "da\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "VVFIN", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "nach dem so zug Gilbertus hin", "tokens": ["nach", "dem", "so", "zug", "Gil\u00b7ber\u00b7tus", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "ADV", "NE", "PTKVZ"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.27": {"text": "fr\u00f6lich in Hispanier lant,", "tokens": ["fr\u00f6\u00b7lich", "in", "His\u00b7pa\u00b7nier", "lant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "ADJD", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.28": {"text": "in die stat, Hispalim genant,", "tokens": ["in", "die", "stat", ",", "His\u00b7pa\u00b7lim", "ge\u00b7nant", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "$,", "NE", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "und studiert auf der hohen schul.", "tokens": ["und", "stu\u00b7diert", "auf", "der", "ho\u00b7hen", "schul", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "da er besa\u00df der k\u00fcnsten stul", "tokens": ["da", "er", "be\u00b7sa\u00df", "der", "k\u00fcns\u00b7ten", "stul"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "f\u00fcr all doctores kurzer zeit", "tokens": ["f\u00fcr", "all", "doc\u00b7to\u00b7res", "kur\u00b7zer", "zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "und wurt ber\u00fcmet weit und breit,", "tokens": ["und", "wurt", "be\u00b7r\u00fc\u00b7met", "weit", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "das er den keiser Ottonem,", "tokens": ["das", "er", "den", "kei\u00b7ser", "Ot\u00b7to\u00b7nem", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ART", "PIAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.34": {"text": "darzu auch Robertum nach dem,", "tokens": ["dar\u00b7zu", "auch", "Ro\u00b7ber\u00b7tum", "nach", "dem", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "NE", "APPR", "ART", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "welcher k\u00fcnig wurt in Frankreich,", "tokens": ["wel\u00b7cher", "k\u00fc\u00b7nig", "wurt", "in", "Fran\u00b7kreich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "ADJD", "VVFIN", "APPR", "NE", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.36": {"text": "zu schulern het und auch dergleich", "tokens": ["zu", "schu\u00b7lern", "het", "und", "auch", "derg\u00b7leich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "VAFIN", "KON", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "ander vil hoch ber\u00fcmte mender", "tokens": ["an\u00b7der", "vil", "hoch", "be\u00b7r\u00fcm\u00b7te", "men\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "ADJD", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.38": {"text": "allerlei nation und lender.", "tokens": ["al\u00b7ler\u00b7lei", "na\u00b7ti\u00b7on", "und", "len\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$."], "meter": "+--+--+--", "measure": "dactylic.tri"}, "line.39": {"text": "nach dem durch ergeiz er annum", "tokens": ["nach", "dem", "durch", "er\u00b7geiz", "er", "an\u00b7num"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "APPR", "NE", "PPER", "NE"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.40": {"text": "das gro\u00df remensisch erzbistum", "tokens": ["das", "gro\u00df", "re\u00b7men\u00b7sisch", "erz\u00b7bis\u00b7tum"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJD", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "und auch darzu das ravenisch", "tokens": ["und", "auch", "dar\u00b7zu", "das", "ra\u00b7ve\u00b7nisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PAV", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.42": {"text": "aus teufelischer h\u00fclf ganz frisch.", "tokens": ["aus", "teu\u00b7fe\u00b7li\u00b7scher", "h\u00fclf", "ganz", "frisch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADJD", "$."], "meter": "+----+-+", "measure": "dactylic.init"}, "line.43": {"text": "da er ein zeitlang bischof was,", "tokens": ["da", "er", "ein", "zeit\u00b7lang", "bi\u00b7schof", "was", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PRELS", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.44": {"text": "ganz begierig \u00fcber die ma\u00df,", "tokens": ["ganz", "be\u00b7gie\u00b7rig", "\u00fc\u00b7ber", "die", "ma\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.45": {"text": "das r\u00f6misch bapsttum zu erwerben.", "tokens": ["das", "r\u00f6\u00b7misch", "bapst\u00b7tum", "zu", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "als nun bapst Johannes tet sterben,", "tokens": ["als", "nun", "bapst", "Jo\u00b7han\u00b7nes", "tet", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "NE", "VVFIN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.47": {"text": "der sibenzehent dises namen,", "tokens": ["der", "si\u00b7ben\u00b7ze\u00b7hent", "di\u00b7ses", "na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.48": {"text": "die cardinel zusamen kamen,", "tokens": ["die", "car\u00b7di\u00b7nel", "zu\u00b7sa\u00b7men", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "einen anderen bapst zu stellen,", "tokens": ["ei\u00b7nen", "an\u00b7de\u00b7ren", "bapst", "zu", "stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.50": {"text": "und teten den Gilbertum welen,", "tokens": ["und", "te\u00b7ten", "den", "Gil\u00b7ber\u00b7tum", "we\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NE", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.51": {"text": "aus eingab des satans anfengnus", "tokens": ["aus", "ein\u00b7gab", "des", "sa\u00b7tans", "an\u00b7feng\u00b7nus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.52": {"text": "und aus der g\u00f6tlichen verhengnus,", "tokens": ["und", "aus", "der", "g\u00f6t\u00b7li\u00b7chen", "ver\u00b7heng\u00b7nus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.53": {"text": "tetens in f\u00fcr ein bapst erkennen", "tokens": ["te\u00b7tens", "in", "f\u00fcr", "ein", "bapst", "er\u00b7ken\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.54": {"text": "und Sylvester den andern nennen.", "tokens": ["und", "Syl\u00b7ves\u00b7ter", "den", "an\u00b7dern", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.55": {"text": "als er nun sa\u00df in dem bapsttum,", "tokens": ["als", "er", "nun", "sa\u00df", "in", "dem", "bapst\u00b7tum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.56": {"text": "hielt er sich andechtig und frum;", "tokens": ["hielt", "er", "sich", "an\u00b7dech\u00b7tig", "und", "frum", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "KON", "ADJD", "$."], "meter": "+--+---+", "measure": "dactylic.di.plus"}, "line.57": {"text": "als er aber im f\u00fcnften jar", "tokens": ["als", "er", "a\u00b7ber", "im", "f\u00fcnf\u00b7ten", "jar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.58": {"text": "seines bapsttums auf eim altar", "tokens": ["sei\u00b7nes", "bapst\u00b7tums", "auf", "eim", "al\u00b7tar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.59": {"text": "in der kirchen des heiling kreuz", "tokens": ["in", "der", "kir\u00b7chen", "des", "hei\u00b7ling", "kreuz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.60": {"text": "mess hielt mit vil prenks und geleuz,", "tokens": ["mess", "hielt", "mit", "vil", "prenks", "und", "ge\u00b7leuz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "----+--+", "measure": "iambic.di.chol"}, "line.61": {"text": "samt cardinelen und hofgsint,", "tokens": ["samt", "car\u00b7di\u00b7ne\u00b7len", "und", "hof\u00b7gsint", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "KON", "VVFIN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.62": {"text": "das im alles zu altar dint,", "tokens": ["das", "im", "al\u00b7les", "zu", "al\u00b7tar", "dint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPRART", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.63": {"text": "als er gleich wolt sacrificieren", "tokens": ["als", "er", "gleich", "wolt", "sa\u00b7cri\u00b7fi\u00b7cie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.64": {"text": "und das sacrament elevieren,", "tokens": ["und", "das", "sa\u00b7cra\u00b7ment", "e\u00b7le\u00b7vie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.65": {"text": "da fieng es an dunkel zu weren,", "tokens": ["da", "fi\u00b7eng", "es", "an", "dun\u00b7kel", "zu", "we\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.66": {"text": "und vor der kirchen nach und feren", "tokens": ["und", "vor", "der", "kir\u00b7chen", "nach", "und", "fe\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.67": {"text": "da flug es als vol schwarzer raben,", "tokens": ["da", "flug", "es", "als", "vol", "schwar\u00b7zer", "ra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.68": {"text": "die zun kirchfenstern gstochen haben", "tokens": ["die", "zun", "kirch\u00b7fens\u00b7tern", "gs\u00b7to\u00b7chen", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPRART", "NN", "VVINF", "VAFIN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.69": {"text": "mit einem ser gro\u00dfen geschrei,", "tokens": ["mit", "ei\u00b7nem", "ser", "gro\u00b7\u00dfen", "ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.70": {"text": "und stachen lenger mer herbei,", "tokens": ["und", "sta\u00b7chen", "len\u00b7ger", "mer", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "sam woltens die fenster aussto\u00dfen.", "tokens": ["sam", "wol\u00b7tens", "die", "fens\u00b7ter", "aus\u00b7sto\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.72": {"text": "darob het alles volk ein gro\u00dfen", "tokens": ["da\u00b7rob", "het", "al\u00b7les", "volk", "ein", "gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PIS", "ADJD", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.73": {"text": "schrecken und forcht ob disem wunder,", "tokens": ["schre\u00b7cken", "und", "forcht", "ob", "di\u00b7sem", "wun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "KOUS", "PDAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.74": {"text": "und Sylvester der bapst besunder", "tokens": ["und", "Syl\u00b7ves\u00b7ter", "der", "bapst", "be\u00b7sun\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "ART", "VVFIN", "ADJD"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.75": {"text": "der fraget sein hofgsint zuhant,", "tokens": ["der", "fra\u00b7get", "sein", "hof\u00b7gsint", "zu\u00b7hant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "VAINF", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.76": {"text": "wie diser altar wer genant.", "tokens": ["wie", "di\u00b7ser", "al\u00b7tar", "wer", "ge\u00b7nant", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NN", "PWS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "da gaben sie zu antwort dem,", "tokens": ["da", "ga\u00b7ben", "sie", "zu", "ant\u00b7wort", "dem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "ART", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.78": {"text": "der altar hie\u00df Jerusalem.", "tokens": ["der", "al\u00b7tar", "hie\u00df", "Je\u00b7ru\u00b7sa\u00b7lem", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.79": {"text": "der bapst erschrak, gedacht wol, das", "tokens": ["der", "bapst", "er\u00b7schrak", ",", "ge\u00b7dacht", "wol", ",", "das"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "VVPP", "ADV", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.80": {"text": "seins sterbens zeit vorhanden was,", "tokens": ["seins", "ster\u00b7bens", "zeit", "vor\u00b7han\u00b7den", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "PWS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.81": {"text": "fiel auf sein knie in reu und leid", "tokens": ["fiel", "auf", "sein", "knie", "in", "reu", "und", "leid"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.82": {"text": "und bekennet on underscheid", "tokens": ["und", "be\u00b7ken\u00b7net", "on", "un\u00b7der\u00b7scheid"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.83": {"text": "sein irrtum und s\u00fcndiges leben,", "tokens": ["sein", "irr\u00b7tum", "und", "s\u00fcn\u00b7di\u00b7ges", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.84": {"text": "und wie er sich auch het ergeben", "tokens": ["und", "wie", "er", "sich", "auch", "het", "er\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "PRF", "ADV", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.85": {"text": "dem teufl in seiner jugent zeit,", "tokens": ["dem", "teufl", "in", "sei\u00b7ner", "ju\u00b7gent", "zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.86": {"text": "begert von got barmherzigkeit,", "tokens": ["be\u00b7gert", "von", "got", "barm\u00b7her\u00b7zig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.87": {"text": "sein schwere s\u00fcnt im zu vergeben,", "tokens": ["sein", "schwe\u00b7re", "s\u00fcnt", "im", "zu", "ver\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VVFIN", "APPRART", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.88": {"text": "und warnet alles volk darneben,", "tokens": ["und", "war\u00b7net", "al\u00b7les", "volk", "dar\u00b7ne\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.89": {"text": "zu meiden die ergeizigkeit,", "tokens": ["zu", "mei\u00b7den", "die", "er\u00b7gei\u00b7zig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "die wurzel aller grundbosheit;", "tokens": ["die", "wur\u00b7zel", "al\u00b7ler", "grund\u00b7bos\u00b7heit", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.91": {"text": "warnet auch alles volk darbei", "tokens": ["war\u00b7net", "auch", "al\u00b7les", "volk", "dar\u00b7bei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PIS", "ADJD", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.92": {"text": "vor teufels gspenst und triegerei,", "tokens": ["vor", "teu\u00b7fels", "gs\u00b7penst", "und", "trie\u00b7ge\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.93": {"text": "der durch sein t\u00fcck und hinderlist", "tokens": ["der", "durch", "sein", "t\u00fcck", "und", "hin\u00b7der\u00b7list"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.94": {"text": "allen christen aufsetzig ist.", "tokens": ["al\u00b7len", "chris\u00b7ten", "auf\u00b7set\u00b7zig", "ist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "ADJD", "VAFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.95": {"text": "nach dem bat er sie allesam,", "tokens": ["nach", "dem", "bat", "er", "sie", "al\u00b7le\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "PPER", "PPER", "ADJD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.96": {"text": "das man nach dem tot seim leichnam", "tokens": ["das", "man", "nach", "dem", "tot", "seim", "leich\u00b7nam"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "ART", "ADJD", "APPRART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.97": {"text": "solt abschneiden all sein gelider,", "tokens": ["solt", "ab\u00b7schnei\u00b7den", "all", "sein", "ge\u00b7li\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "PIAT", "PPOSAT", "ADJA", "$,"], "meter": "-++-+-+--", "measure": "unknown.measure.tetra"}, "line.98": {"text": "auf ein wagen zsam legen nider", "tokens": ["auf", "ein", "wa\u00b7gen", "zsam", "le\u00b7gen", "ni\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "VVINF", "ADJD", "VVFIN", "PTKVZ"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.99": {"text": "und vier ross darnach daran spannen,", "tokens": ["und", "vier", "ross", "dar\u00b7nach", "da\u00b7ran", "span\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "VVFIN", "PAV", "PAV", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.100": {"text": "die ungeleit in zugen dannen;", "tokens": ["die", "un\u00b7ge\u00b7leit", "in", "zu\u00b7gen", "dan\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.101": {"text": "wo die st\u00fcnden, solt man acht haben,", "tokens": ["wo", "die", "st\u00fcn\u00b7den", ",", "solt", "man", "acht", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "$,", "VMFIN", "PIS", "CARD", "VAFIN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.102": {"text": "an der stat solt man in begraben.", "tokens": ["an", "der", "stat", "solt", "man", "in", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PIS", "APPR", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.103": {"text": "nach dem und als der bapst verschiet,", "tokens": ["nach", "dem", "und", "als", "der", "bapst", "ver\u00b7schiet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "KON", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.104": {"text": "auf gut hoffnung sein ent erliet,", "tokens": ["auf", "gut", "hoff\u00b7nung", "sein", "ent", "er\u00b7liet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "NN", "PPOSAT", "ADJD", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.105": {"text": "darnach zerschnitten auf ein wagen", "tokens": ["dar\u00b7nach", "zer\u00b7schnit\u00b7ten", "auf", "ein", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "APPR", "ART", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.106": {"text": "legtens sein leib nach seim ansagen.", "tokens": ["leg\u00b7tens", "sein", "leib", "nach", "seim", "an\u00b7sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "NE", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.107": {"text": "da in die pfert gezogen haben", "tokens": ["da", "in", "die", "pfert", "ge\u00b7zo\u00b7gen", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "VVFIN", "VVPP", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.108": {"text": "in sanct Johanns kirchen, begraben", "tokens": ["in", "sanct", "Jo\u00b7hanns", "kir\u00b7chen", ",", "be\u00b7gra\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "VVFIN", "NE", "VVINF", "$,", "VVPP"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.109": {"text": "wurt er; das war ein gutes zeichen,", "tokens": ["wurt", "er", ";", "das", "war", "ein", "gu\u00b7tes", "zei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.110": {"text": "das er gots gnad het tun erreichen", "tokens": ["das", "er", "gots", "gnad", "het", "tun", "er\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PPER", "ADJA", "NN", "VAFIN", "VVINF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.111": {"text": "durch sein warhafte reu und bu\u00df.", "tokens": ["durch", "sein", "war\u00b7haf\u00b7te", "reu", "und", "bu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Die chronica sagen f\u00fcrwar,", "tokens": ["Die", "chro\u00b7ni\u00b7ca", "sa\u00b7gen", "f\u00fcr\u00b7war", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "FM", "FM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "als man zelet neunhundert jar", "tokens": ["als", "man", "ze\u00b7let", "neun\u00b7hun\u00b7dert", "jar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVFIN", "CARD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und vier und neunzig on gefer,", "tokens": ["und", "vier", "und", "neun\u00b7zig", "on", "ge\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "KON", "CARD", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da regieret bapst Sylvester,", "tokens": ["da", "re\u00b7gie\u00b7ret", "bapst", "Syl\u00b7ves\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "der ander dises namens da.", "tokens": ["der", "an\u00b7der", "di\u00b7ses", "na\u00b7mens", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der war b\u00fcrtig aus Gallia", "tokens": ["der", "war", "b\u00fcr\u00b7tig", "aus", "Gal\u00b7lia"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "VAFIN", "ADJD", "APPR", "NE"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "und vormals Gilbertus genant,", "tokens": ["und", "vor\u00b7mals", "Gil\u00b7ber\u00b7tus", "ge\u00b7nant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "kam in seiner jugent zuhant", "tokens": ["kam", "in", "sei\u00b7ner", "ju\u00b7gent", "zu\u00b7hant"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "in ein kloster, zu werden frum,", "tokens": ["in", "ein", "klos\u00b7ter", ",", "zu", "wer\u00b7den", "frum", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "PTKZU", "VAINF", "PTKVZ", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.10": {"text": "im aurelianischen bistum,", "tokens": ["im", "au\u00b7re\u00b7li\u00b7a\u00b7ni\u00b7schen", "bis\u00b7tum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.11": {"text": "doch wider aus dem kloster sprung", "tokens": ["doch", "wi\u00b7der", "aus", "dem", "klos\u00b7ter", "sprung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "und ergab sich noch also jung", "tokens": ["und", "er\u00b7gab", "sich", "noch", "al\u00b7so", "jung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADV", "ADJD"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.13": {"text": "dem teufel und auf schwarze kunst,", "tokens": ["dem", "teu\u00b7fel", "und", "auf", "schwar\u00b7ze", "kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "dardurch zu erlangen die gunst,", "tokens": ["dar\u00b7durch", "zu", "er\u00b7lan\u00b7gen", "die", "gunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PTKZU", "VVINF", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.15": {"text": "zu herschen das r\u00f6misch bapsttum.", "tokens": ["zu", "her\u00b7schen", "das", "r\u00f6\u00b7misch", "bapst\u00b7tum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "ADJD", "PTKVZ", "$."], "meter": "-+--+---", "measure": "iambic.di.relaxed"}, "line.16": {"text": "der teufel das mit im aufnum,", "tokens": ["der", "teu\u00b7fel", "das", "mit", "im", "auf\u00b7num", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "APPR", "APPRART", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.17": {"text": "doch das er sein wer nach seim tot.", "tokens": ["doch", "das", "er", "sein", "wer", "nach", "seim", "tot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PPER", "PPOSAT", "PWS", "APPR", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "das verschrib er mit seim blut rot.", "tokens": ["das", "ver\u00b7schrib", "er", "mit", "seim", "blut", "rot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.19": {"text": "doch fraget in Gilbertus eben,", "tokens": ["doch", "fra\u00b7get", "in", "Gil\u00b7ber\u00b7tus", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "ADV", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.20": {"text": "wie lang er w\u00fcrt auf erden leben.", "tokens": ["wie", "lang", "er", "w\u00fcrt", "auf", "er\u00b7den", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "der teufel sprach: du stirbst nach dem,", "tokens": ["der", "teu\u00b7fel", "sprach", ":", "du", "stirbst", "nach", "dem", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "ART", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.22": {"text": "wenn du ber\u00fcrst Jerusalem.", "tokens": ["wenn", "du", "be\u00b7r\u00fcrst", "Je\u00b7ru\u00b7sa\u00b7lem", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "NE", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.23": {"text": "Gilbertus dacht in seim gem\u00fct;", "tokens": ["Gil\u00b7ber\u00b7tus", "dacht", "in", "seim", "ge\u00b7m\u00fct", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NE", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.24": {"text": "vor Jerusalem ich mich h\u00fct,", "tokens": ["vor", "Je\u00b7ru\u00b7sa\u00b7lem", "ich", "mich", "h\u00fct", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PPER", "PRF", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "das ich kom nimmermer dahin.", "tokens": ["das", "ich", "kom", "nim\u00b7mer\u00b7mer", "da\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "VVFIN", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "nach dem so zug Gilbertus hin", "tokens": ["nach", "dem", "so", "zug", "Gil\u00b7ber\u00b7tus", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "ADV", "NE", "PTKVZ"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.27": {"text": "fr\u00f6lich in Hispanier lant,", "tokens": ["fr\u00f6\u00b7lich", "in", "His\u00b7pa\u00b7nier", "lant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "ADJD", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.28": {"text": "in die stat, Hispalim genant,", "tokens": ["in", "die", "stat", ",", "His\u00b7pa\u00b7lim", "ge\u00b7nant", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "$,", "NE", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "und studiert auf der hohen schul.", "tokens": ["und", "stu\u00b7diert", "auf", "der", "ho\u00b7hen", "schul", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "da er besa\u00df der k\u00fcnsten stul", "tokens": ["da", "er", "be\u00b7sa\u00df", "der", "k\u00fcns\u00b7ten", "stul"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "f\u00fcr all doctores kurzer zeit", "tokens": ["f\u00fcr", "all", "doc\u00b7to\u00b7res", "kur\u00b7zer", "zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "und wurt ber\u00fcmet weit und breit,", "tokens": ["und", "wurt", "be\u00b7r\u00fc\u00b7met", "weit", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "das er den keiser Ottonem,", "tokens": ["das", "er", "den", "kei\u00b7ser", "Ot\u00b7to\u00b7nem", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ART", "PIAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.34": {"text": "darzu auch Robertum nach dem,", "tokens": ["dar\u00b7zu", "auch", "Ro\u00b7ber\u00b7tum", "nach", "dem", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "NE", "APPR", "ART", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "welcher k\u00fcnig wurt in Frankreich,", "tokens": ["wel\u00b7cher", "k\u00fc\u00b7nig", "wurt", "in", "Fran\u00b7kreich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "ADJD", "VVFIN", "APPR", "NE", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.36": {"text": "zu schulern het und auch dergleich", "tokens": ["zu", "schu\u00b7lern", "het", "und", "auch", "derg\u00b7leich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "VAFIN", "KON", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "ander vil hoch ber\u00fcmte mender", "tokens": ["an\u00b7der", "vil", "hoch", "be\u00b7r\u00fcm\u00b7te", "men\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "ADJD", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.38": {"text": "allerlei nation und lender.", "tokens": ["al\u00b7ler\u00b7lei", "na\u00b7ti\u00b7on", "und", "len\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$."], "meter": "+--+--+--", "measure": "dactylic.tri"}, "line.39": {"text": "nach dem durch ergeiz er annum", "tokens": ["nach", "dem", "durch", "er\u00b7geiz", "er", "an\u00b7num"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "APPR", "NE", "PPER", "NE"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.40": {"text": "das gro\u00df remensisch erzbistum", "tokens": ["das", "gro\u00df", "re\u00b7men\u00b7sisch", "erz\u00b7bis\u00b7tum"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJD", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "und auch darzu das ravenisch", "tokens": ["und", "auch", "dar\u00b7zu", "das", "ra\u00b7ve\u00b7nisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PAV", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.42": {"text": "aus teufelischer h\u00fclf ganz frisch.", "tokens": ["aus", "teu\u00b7fe\u00b7li\u00b7scher", "h\u00fclf", "ganz", "frisch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADJD", "$."], "meter": "+----+-+", "measure": "dactylic.init"}, "line.43": {"text": "da er ein zeitlang bischof was,", "tokens": ["da", "er", "ein", "zeit\u00b7lang", "bi\u00b7schof", "was", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PRELS", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.44": {"text": "ganz begierig \u00fcber die ma\u00df,", "tokens": ["ganz", "be\u00b7gie\u00b7rig", "\u00fc\u00b7ber", "die", "ma\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.45": {"text": "das r\u00f6misch bapsttum zu erwerben.", "tokens": ["das", "r\u00f6\u00b7misch", "bapst\u00b7tum", "zu", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "als nun bapst Johannes tet sterben,", "tokens": ["als", "nun", "bapst", "Jo\u00b7han\u00b7nes", "tet", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "NE", "VVFIN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.47": {"text": "der sibenzehent dises namen,", "tokens": ["der", "si\u00b7ben\u00b7ze\u00b7hent", "di\u00b7ses", "na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.48": {"text": "die cardinel zusamen kamen,", "tokens": ["die", "car\u00b7di\u00b7nel", "zu\u00b7sa\u00b7men", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "einen anderen bapst zu stellen,", "tokens": ["ei\u00b7nen", "an\u00b7de\u00b7ren", "bapst", "zu", "stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.50": {"text": "und teten den Gilbertum welen,", "tokens": ["und", "te\u00b7ten", "den", "Gil\u00b7ber\u00b7tum", "we\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NE", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.51": {"text": "aus eingab des satans anfengnus", "tokens": ["aus", "ein\u00b7gab", "des", "sa\u00b7tans", "an\u00b7feng\u00b7nus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.52": {"text": "und aus der g\u00f6tlichen verhengnus,", "tokens": ["und", "aus", "der", "g\u00f6t\u00b7li\u00b7chen", "ver\u00b7heng\u00b7nus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.53": {"text": "tetens in f\u00fcr ein bapst erkennen", "tokens": ["te\u00b7tens", "in", "f\u00fcr", "ein", "bapst", "er\u00b7ken\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.54": {"text": "und Sylvester den andern nennen.", "tokens": ["und", "Syl\u00b7ves\u00b7ter", "den", "an\u00b7dern", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.55": {"text": "als er nun sa\u00df in dem bapsttum,", "tokens": ["als", "er", "nun", "sa\u00df", "in", "dem", "bapst\u00b7tum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.56": {"text": "hielt er sich andechtig und frum;", "tokens": ["hielt", "er", "sich", "an\u00b7dech\u00b7tig", "und", "frum", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "KON", "ADJD", "$."], "meter": "+--+---+", "measure": "dactylic.di.plus"}, "line.57": {"text": "als er aber im f\u00fcnften jar", "tokens": ["als", "er", "a\u00b7ber", "im", "f\u00fcnf\u00b7ten", "jar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.58": {"text": "seines bapsttums auf eim altar", "tokens": ["sei\u00b7nes", "bapst\u00b7tums", "auf", "eim", "al\u00b7tar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.59": {"text": "in der kirchen des heiling kreuz", "tokens": ["in", "der", "kir\u00b7chen", "des", "hei\u00b7ling", "kreuz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.60": {"text": "mess hielt mit vil prenks und geleuz,", "tokens": ["mess", "hielt", "mit", "vil", "prenks", "und", "ge\u00b7leuz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "----+--+", "measure": "iambic.di.chol"}, "line.61": {"text": "samt cardinelen und hofgsint,", "tokens": ["samt", "car\u00b7di\u00b7ne\u00b7len", "und", "hof\u00b7gsint", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "KON", "VVFIN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.62": {"text": "das im alles zu altar dint,", "tokens": ["das", "im", "al\u00b7les", "zu", "al\u00b7tar", "dint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPRART", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.63": {"text": "als er gleich wolt sacrificieren", "tokens": ["als", "er", "gleich", "wolt", "sa\u00b7cri\u00b7fi\u00b7cie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.64": {"text": "und das sacrament elevieren,", "tokens": ["und", "das", "sa\u00b7cra\u00b7ment", "e\u00b7le\u00b7vie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.65": {"text": "da fieng es an dunkel zu weren,", "tokens": ["da", "fi\u00b7eng", "es", "an", "dun\u00b7kel", "zu", "we\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.66": {"text": "und vor der kirchen nach und feren", "tokens": ["und", "vor", "der", "kir\u00b7chen", "nach", "und", "fe\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.67": {"text": "da flug es als vol schwarzer raben,", "tokens": ["da", "flug", "es", "als", "vol", "schwar\u00b7zer", "ra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.68": {"text": "die zun kirchfenstern gstochen haben", "tokens": ["die", "zun", "kirch\u00b7fens\u00b7tern", "gs\u00b7to\u00b7chen", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPRART", "NN", "VVINF", "VAFIN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.69": {"text": "mit einem ser gro\u00dfen geschrei,", "tokens": ["mit", "ei\u00b7nem", "ser", "gro\u00b7\u00dfen", "ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.70": {"text": "und stachen lenger mer herbei,", "tokens": ["und", "sta\u00b7chen", "len\u00b7ger", "mer", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "sam woltens die fenster aussto\u00dfen.", "tokens": ["sam", "wol\u00b7tens", "die", "fens\u00b7ter", "aus\u00b7sto\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.72": {"text": "darob het alles volk ein gro\u00dfen", "tokens": ["da\u00b7rob", "het", "al\u00b7les", "volk", "ein", "gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PIS", "ADJD", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.73": {"text": "schrecken und forcht ob disem wunder,", "tokens": ["schre\u00b7cken", "und", "forcht", "ob", "di\u00b7sem", "wun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "KOUS", "PDAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.74": {"text": "und Sylvester der bapst besunder", "tokens": ["und", "Syl\u00b7ves\u00b7ter", "der", "bapst", "be\u00b7sun\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "ART", "VVFIN", "ADJD"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.75": {"text": "der fraget sein hofgsint zuhant,", "tokens": ["der", "fra\u00b7get", "sein", "hof\u00b7gsint", "zu\u00b7hant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "VAINF", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.76": {"text": "wie diser altar wer genant.", "tokens": ["wie", "di\u00b7ser", "al\u00b7tar", "wer", "ge\u00b7nant", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NN", "PWS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "da gaben sie zu antwort dem,", "tokens": ["da", "ga\u00b7ben", "sie", "zu", "ant\u00b7wort", "dem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "ART", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.78": {"text": "der altar hie\u00df Jerusalem.", "tokens": ["der", "al\u00b7tar", "hie\u00df", "Je\u00b7ru\u00b7sa\u00b7lem", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.79": {"text": "der bapst erschrak, gedacht wol, das", "tokens": ["der", "bapst", "er\u00b7schrak", ",", "ge\u00b7dacht", "wol", ",", "das"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "VVPP", "ADV", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.80": {"text": "seins sterbens zeit vorhanden was,", "tokens": ["seins", "ster\u00b7bens", "zeit", "vor\u00b7han\u00b7den", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "PWS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.81": {"text": "fiel auf sein knie in reu und leid", "tokens": ["fiel", "auf", "sein", "knie", "in", "reu", "und", "leid"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.82": {"text": "und bekennet on underscheid", "tokens": ["und", "be\u00b7ken\u00b7net", "on", "un\u00b7der\u00b7scheid"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.83": {"text": "sein irrtum und s\u00fcndiges leben,", "tokens": ["sein", "irr\u00b7tum", "und", "s\u00fcn\u00b7di\u00b7ges", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.84": {"text": "und wie er sich auch het ergeben", "tokens": ["und", "wie", "er", "sich", "auch", "het", "er\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "PRF", "ADV", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.85": {"text": "dem teufl in seiner jugent zeit,", "tokens": ["dem", "teufl", "in", "sei\u00b7ner", "ju\u00b7gent", "zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.86": {"text": "begert von got barmherzigkeit,", "tokens": ["be\u00b7gert", "von", "got", "barm\u00b7her\u00b7zig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.87": {"text": "sein schwere s\u00fcnt im zu vergeben,", "tokens": ["sein", "schwe\u00b7re", "s\u00fcnt", "im", "zu", "ver\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VVFIN", "APPRART", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.88": {"text": "und warnet alles volk darneben,", "tokens": ["und", "war\u00b7net", "al\u00b7les", "volk", "dar\u00b7ne\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.89": {"text": "zu meiden die ergeizigkeit,", "tokens": ["zu", "mei\u00b7den", "die", "er\u00b7gei\u00b7zig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "die wurzel aller grundbosheit;", "tokens": ["die", "wur\u00b7zel", "al\u00b7ler", "grund\u00b7bos\u00b7heit", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.91": {"text": "warnet auch alles volk darbei", "tokens": ["war\u00b7net", "auch", "al\u00b7les", "volk", "dar\u00b7bei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PIS", "ADJD", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.92": {"text": "vor teufels gspenst und triegerei,", "tokens": ["vor", "teu\u00b7fels", "gs\u00b7penst", "und", "trie\u00b7ge\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.93": {"text": "der durch sein t\u00fcck und hinderlist", "tokens": ["der", "durch", "sein", "t\u00fcck", "und", "hin\u00b7der\u00b7list"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.94": {"text": "allen christen aufsetzig ist.", "tokens": ["al\u00b7len", "chris\u00b7ten", "auf\u00b7set\u00b7zig", "ist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "ADJD", "VAFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.95": {"text": "nach dem bat er sie allesam,", "tokens": ["nach", "dem", "bat", "er", "sie", "al\u00b7le\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "PPER", "PPER", "ADJD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.96": {"text": "das man nach dem tot seim leichnam", "tokens": ["das", "man", "nach", "dem", "tot", "seim", "leich\u00b7nam"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "ART", "ADJD", "APPRART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.97": {"text": "solt abschneiden all sein gelider,", "tokens": ["solt", "ab\u00b7schnei\u00b7den", "all", "sein", "ge\u00b7li\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "PIAT", "PPOSAT", "ADJA", "$,"], "meter": "-++-+-+--", "measure": "unknown.measure.tetra"}, "line.98": {"text": "auf ein wagen zsam legen nider", "tokens": ["auf", "ein", "wa\u00b7gen", "zsam", "le\u00b7gen", "ni\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "VVINF", "ADJD", "VVFIN", "PTKVZ"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.99": {"text": "und vier ross darnach daran spannen,", "tokens": ["und", "vier", "ross", "dar\u00b7nach", "da\u00b7ran", "span\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "VVFIN", "PAV", "PAV", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.100": {"text": "die ungeleit in zugen dannen;", "tokens": ["die", "un\u00b7ge\u00b7leit", "in", "zu\u00b7gen", "dan\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.101": {"text": "wo die st\u00fcnden, solt man acht haben,", "tokens": ["wo", "die", "st\u00fcn\u00b7den", ",", "solt", "man", "acht", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "$,", "VMFIN", "PIS", "CARD", "VAFIN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.102": {"text": "an der stat solt man in begraben.", "tokens": ["an", "der", "stat", "solt", "man", "in", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PIS", "APPR", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.103": {"text": "nach dem und als der bapst verschiet,", "tokens": ["nach", "dem", "und", "als", "der", "bapst", "ver\u00b7schiet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "KON", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.104": {"text": "auf gut hoffnung sein ent erliet,", "tokens": ["auf", "gut", "hoff\u00b7nung", "sein", "ent", "er\u00b7liet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "NN", "PPOSAT", "ADJD", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.105": {"text": "darnach zerschnitten auf ein wagen", "tokens": ["dar\u00b7nach", "zer\u00b7schnit\u00b7ten", "auf", "ein", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "APPR", "ART", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.106": {"text": "legtens sein leib nach seim ansagen.", "tokens": ["leg\u00b7tens", "sein", "leib", "nach", "seim", "an\u00b7sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "NE", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.107": {"text": "da in die pfert gezogen haben", "tokens": ["da", "in", "die", "pfert", "ge\u00b7zo\u00b7gen", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "VVFIN", "VVPP", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.108": {"text": "in sanct Johanns kirchen, begraben", "tokens": ["in", "sanct", "Jo\u00b7hanns", "kir\u00b7chen", ",", "be\u00b7gra\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "VVFIN", "NE", "VVINF", "$,", "VVPP"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.109": {"text": "wurt er; das war ein gutes zeichen,", "tokens": ["wurt", "er", ";", "das", "war", "ein", "gu\u00b7tes", "zei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.110": {"text": "das er gots gnad het tun erreichen", "tokens": ["das", "er", "gots", "gnad", "het", "tun", "er\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PPER", "ADJA", "NN", "VAFIN", "VVINF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.111": {"text": "durch sein warhafte reu und bu\u00df.", "tokens": ["durch", "sein", "war\u00b7haf\u00b7te", "reu", "und", "bu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}