{"dta.poem.23750": {"metadata": {"author": {"name": "Wei\u00dfe, Christian Felix", "birth": "N.A.", "death": "N.A."}, "title": "Der Sperling und das Tur-  \n telt\u00e4ubchen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1767", "urn": "urn:nbn:de:kobv:b4-20643-5", "language": ["de:0.99"], "booktitle": "Wei\u00dfe, Christian Felix: Lieder f\u00fcr Kinder. Leipzig, 1767."}, "poem": {"stanza.1": {"line.1": {"text": "Ich armer Schelm! wie geht es mir!", "tokens": ["Ich", "ar\u00b7mer", "Schelm", "!", "wie", "geht", "es", "mir", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$.", "PWAV", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du bist geliebt: ich bin verachtet!", "tokens": ["Du", "bist", "ge\u00b7liebt", ":", "ich", "bin", "ver\u00b7ach\u00b7tet", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was denkt der Mensch wohl, da\u00df er dir", "tokens": ["Was", "denkt", "der", "Mensch", "wohl", ",", "da\u00df", "er", "dir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN", "ADV", "$,", "KOUS", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weit ", "tokens": ["Weit"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Bin ich, gesteh es mir nur zu,", "tokens": ["Bin", "ich", ",", "ge\u00b7steh", "es", "mir", "nur", "zu", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "VVFIN", "PPER", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht zehnmal listiger, als du?", "tokens": ["Nicht", "zehn\u00b7mal", "lis\u00b7ti\u00b7ger", ",", "als", "du", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "$,", "KOUS", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Das macht, da\u00df du ein R\u00e4uber bist;", "tokens": ["Das", "macht", ",", "da\u00df", "du", "ein", "R\u00e4u\u00b7ber", "bist", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich nehme blo\u00df, was er mir schenket,", "tokens": ["Ich", "neh\u00b7me", "blo\u00df", ",", "was", "er", "mir", "schen\u00b7ket", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und habe noch durch Trug und List", "tokens": ["Und", "ha\u00b7be", "noch", "durch", "Trug", "und", "List"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jhn nie an seinem Gut gekr\u00e4nket.", "tokens": ["Jhn", "nie", "an", "sei\u00b7nem", "Gut", "ge\u00b7kr\u00e4n\u00b7ket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was hilfts, wenn man Verstand besitzt,", "tokens": ["Was", "hilfts", ",", "wenn", "man", "Ver\u00b7stand", "be\u00b7sitzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PIS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und nicht zu guten Thaten n\u00fctzt!", "tokens": ["Und", "nicht", "zu", "gu\u00b7ten", "Tha\u00b7ten", "n\u00fctzt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}