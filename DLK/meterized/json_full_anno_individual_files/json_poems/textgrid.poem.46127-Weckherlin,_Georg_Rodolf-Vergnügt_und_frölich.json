{"textgrid.poem.46127": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Vergn\u00fcgt und fr\u00f6lich", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ha! kom, gut geschirr zu machen", "tokens": ["Ha", "!", "kom", ",", "gut", "ge\u00b7schirr", "zu", "ma\u00b7chen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VVFIN", "$,", "ADJD", "ADJD", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "weil wir die gelegenheit;", "tokens": ["weil", "wir", "die", "ge\u00b7le\u00b7gen\u00b7heit", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "la\u00df uns singen, springen, lachen", "tokens": ["la\u00df", "uns", "sin\u00b7gen", ",", "sprin\u00b7gen", ",", "la\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["VVIMP", "PPER", "VVFIN", "$,", "VVFIN", "$,", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ohn f\u00fcrsorg und traurigkeit;", "tokens": ["ohn", "f\u00fcr\u00b7sorg", "und", "trau\u00b7rig\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "la\u00df uns sorg und m\u00fch betriegen,", "tokens": ["la\u00df", "uns", "sorg", "und", "m\u00fch", "be\u00b7trie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die uns unsre freud bekriegen.", "tokens": ["die", "uns", "uns\u00b7re", "freud", "be\u00b7krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "La\u00df erfrischend uns purgieren", "tokens": ["La\u00df", "er\u00b7fri\u00b7schend", "uns", "pur\u00b7gie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "VVPP", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "alle d\u00e4mpf, so unser hirn", "tokens": ["al\u00b7le", "d\u00e4mpf", ",", "so", "un\u00b7ser", "hirn"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "mit geiz und ehrgeiz beschmieren", "tokens": ["mit", "geiz", "und", "ehr\u00b7geiz", "be\u00b7schmie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADJD", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "und mit r\u00fcnzlen unsre stirn,", "tokens": ["und", "mit", "r\u00fcnz\u00b7len", "uns\u00b7re", "stirn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und die uns den kopf zurei\u00dfen", "tokens": ["und", "die", "uns", "den", "kopf", "zu\u00b7rei\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PPER", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und das haar, vor alter, wei\u00dfen.", "tokens": ["und", "das", "haar", ",", "vor", "al\u00b7ter", ",", "wei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "APPR", "ADJA", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "La\u00df uns unverdr\u00fc\u00dflich leben", "tokens": ["La\u00df", "uns", "un\u00b7ver\u00b7dr\u00fc\u00df\u00b7lich", "le\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "recht auf gut philosophisch,", "tokens": ["recht", "auf", "gut", "phi\u00b7lo\u00b7so\u00b7phisch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "unsre seelen nicht verweben", "tokens": ["uns\u00b7re", "see\u00b7len", "nicht", "ver\u00b7we\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "melankolisch wie stockfisch,", "tokens": ["me\u00b7lan\u00b7ko\u00b7lisch", "wie", "stock\u00b7fisch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ADJD", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "sondern fliehen und vermeiden,", "tokens": ["son\u00b7dern", "flie\u00b7hen", "und", "ver\u00b7mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "KON", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "so vil m\u00f6glich, alles leiden.", "tokens": ["so", "vil", "m\u00f6g\u00b7lich", ",", "al\u00b7les", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$,", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbein gem\u00fct, das nach gut trachtet,", "tokens": ["\u00bb", "ein", "ge\u00b7m\u00fct", ",", "das", "nach", "gut", "trach\u00b7tet", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "VVPP", "$,", "PRELS", "APPR", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ist ohn ruh, ohn wohn, ohn witz;", "tokens": ["ist", "ohn", "ruh", ",", "ohn", "wohn", ",", "ohn", "witz", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "$,", "KOUI", "ADJD", "$,", "KOUI", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Charon der den reichtum achtet", "tokens": ["Cha\u00b7ron", "der", "den", "reich\u00b7tum", "ach\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ART", "ART", "XY", "XY"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "als einer spinadeln spitz,", "tokens": ["als", "ei\u00b7ner", "spi\u00b7na\u00b7deln", "spitz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "lasset sich die arme bauren,", "tokens": ["las\u00b7set", "sich", "die", "ar\u00b7me", "bau\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wie die herren selbs, betauren.\u00ab", "tokens": ["wie", "die", "her\u00b7ren", "selbs", ",", "be\u00b7tau\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "$,", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Darum la\u00dft uns nu vergessen", "tokens": ["Da\u00b7rum", "la\u00dft", "uns", "nu", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "aller sorg, angst und gedichts,", "tokens": ["al\u00b7ler", "sorg", ",", "angst", "und", "ge\u00b7dichts", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "VVPP", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "fr\u00f6lich an dem tisch gesessen", "tokens": ["fr\u00f6\u00b7lich", "an", "dem", "tisch", "ge\u00b7ses\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "vern\u00fcget mit unserm nichts,", "tokens": ["ver\u00b7n\u00fc\u00b7get", "mit", "un\u00b7serm", "nichts", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "PIS", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "dan den schedel wir zerbrechen,", "tokens": ["dan", "den", "sche\u00b7del", "wir", "zer\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wan wir geld zusamen rechen.", "tokens": ["wan", "wir", "geld", "zu\u00b7sa\u00b7men", "re\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wan mein Musa mich gewehret,", "tokens": ["Wan", "mein", "Mu\u00b7sa", "mich", "ge\u00b7weh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wan ich will, der poesie,", "tokens": ["wan", "ich", "will", ",", "der", "po\u00b7e\u00b7sie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VMFIN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ist das, so mein herz begehret", "tokens": ["ist", "das", ",", "so", "mein", "herz", "be\u00b7ge\u00b7hret"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "$,", "ADV", "PPOSAT", "NN", "VVFIN"], "meter": "+---+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "ohn andere fantasie.", "tokens": ["ohn", "an\u00b7de\u00b7re", "fan\u00b7ta\u00b7sie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "\u00bbein frei wol vergn\u00fcgtes leben", "tokens": ["\u00bb", "ein", "frei", "wol", "ver\u00b7gn\u00fcg\u00b7tes", "le\u00b7ben"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADJD", "ADV", "ADJA", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "ist nicht um ein land zu geben.\u00ab", "tokens": ["ist", "nicht", "um", "ein", "land", "zu", "ge\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "ART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.7": {"line.1": {"text": "Ha! kom, gut geschirr zu machen", "tokens": ["Ha", "!", "kom", ",", "gut", "ge\u00b7schirr", "zu", "ma\u00b7chen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VVFIN", "$,", "ADJD", "ADJD", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "weil wir die gelegenheit;", "tokens": ["weil", "wir", "die", "ge\u00b7le\u00b7gen\u00b7heit", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "la\u00df uns singen, springen, lachen", "tokens": ["la\u00df", "uns", "sin\u00b7gen", ",", "sprin\u00b7gen", ",", "la\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["VVIMP", "PPER", "VVFIN", "$,", "VVFIN", "$,", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ohn f\u00fcrsorg und traurigkeit;", "tokens": ["ohn", "f\u00fcr\u00b7sorg", "und", "trau\u00b7rig\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "la\u00df uns sorg und m\u00fch betriegen,", "tokens": ["la\u00df", "uns", "sorg", "und", "m\u00fch", "be\u00b7trie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die uns unsre freud bekriegen.", "tokens": ["die", "uns", "uns\u00b7re", "freud", "be\u00b7krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "La\u00df erfrischend uns purgieren", "tokens": ["La\u00df", "er\u00b7fri\u00b7schend", "uns", "pur\u00b7gie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "VVPP", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "alle d\u00e4mpf, so unser hirn", "tokens": ["al\u00b7le", "d\u00e4mpf", ",", "so", "un\u00b7ser", "hirn"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "mit geiz und ehrgeiz beschmieren", "tokens": ["mit", "geiz", "und", "ehr\u00b7geiz", "be\u00b7schmie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADJD", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "und mit r\u00fcnzlen unsre stirn,", "tokens": ["und", "mit", "r\u00fcnz\u00b7len", "uns\u00b7re", "stirn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und die uns den kopf zurei\u00dfen", "tokens": ["und", "die", "uns", "den", "kopf", "zu\u00b7rei\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PPER", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und das haar, vor alter, wei\u00dfen.", "tokens": ["und", "das", "haar", ",", "vor", "al\u00b7ter", ",", "wei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "APPR", "ADJA", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "La\u00df uns unverdr\u00fc\u00dflich leben", "tokens": ["La\u00df", "uns", "un\u00b7ver\u00b7dr\u00fc\u00df\u00b7lich", "le\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "recht auf gut philosophisch,", "tokens": ["recht", "auf", "gut", "phi\u00b7lo\u00b7so\u00b7phisch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "unsre seelen nicht verweben", "tokens": ["uns\u00b7re", "see\u00b7len", "nicht", "ver\u00b7we\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "melankolisch wie stockfisch,", "tokens": ["me\u00b7lan\u00b7ko\u00b7lisch", "wie", "stock\u00b7fisch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ADJD", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "sondern fliehen und vermeiden,", "tokens": ["son\u00b7dern", "flie\u00b7hen", "und", "ver\u00b7mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "KON", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "so vil m\u00f6glich, alles leiden.", "tokens": ["so", "vil", "m\u00f6g\u00b7lich", ",", "al\u00b7les", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$,", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "\u00bbein gem\u00fct, das nach gut trachtet,", "tokens": ["\u00bb", "ein", "ge\u00b7m\u00fct", ",", "das", "nach", "gut", "trach\u00b7tet", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "VVPP", "$,", "PRELS", "APPR", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ist ohn ruh, ohn wohn, ohn witz;", "tokens": ["ist", "ohn", "ruh", ",", "ohn", "wohn", ",", "ohn", "witz", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "$,", "KOUI", "ADJD", "$,", "KOUI", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Charon der den reichtum achtet", "tokens": ["Cha\u00b7ron", "der", "den", "reich\u00b7tum", "ach\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ART", "ART", "XY", "XY"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "als einer spinadeln spitz,", "tokens": ["als", "ei\u00b7ner", "spi\u00b7na\u00b7deln", "spitz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "lasset sich die arme bauren,", "tokens": ["las\u00b7set", "sich", "die", "ar\u00b7me", "bau\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wie die herren selbs, betauren.\u00ab", "tokens": ["wie", "die", "her\u00b7ren", "selbs", ",", "be\u00b7tau\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "$,", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Darum la\u00dft uns nu vergessen", "tokens": ["Da\u00b7rum", "la\u00dft", "uns", "nu", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "aller sorg, angst und gedichts,", "tokens": ["al\u00b7ler", "sorg", ",", "angst", "und", "ge\u00b7dichts", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "VVPP", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "fr\u00f6lich an dem tisch gesessen", "tokens": ["fr\u00f6\u00b7lich", "an", "dem", "tisch", "ge\u00b7ses\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "vern\u00fcget mit unserm nichts,", "tokens": ["ver\u00b7n\u00fc\u00b7get", "mit", "un\u00b7serm", "nichts", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "PIS", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "dan den schedel wir zerbrechen,", "tokens": ["dan", "den", "sche\u00b7del", "wir", "zer\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wan wir geld zusamen rechen.", "tokens": ["wan", "wir", "geld", "zu\u00b7sa\u00b7men", "re\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Wan mein Musa mich gewehret,", "tokens": ["Wan", "mein", "Mu\u00b7sa", "mich", "ge\u00b7weh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wan ich will, der poesie,", "tokens": ["wan", "ich", "will", ",", "der", "po\u00b7e\u00b7sie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VMFIN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ist das, so mein herz begehret", "tokens": ["ist", "das", ",", "so", "mein", "herz", "be\u00b7ge\u00b7hret"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "$,", "ADV", "PPOSAT", "NN", "VVFIN"], "meter": "+---+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "ohn andere fantasie.", "tokens": ["ohn", "an\u00b7de\u00b7re", "fan\u00b7ta\u00b7sie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "\u00bbein frei wol vergn\u00fcgtes leben", "tokens": ["\u00bb", "ein", "frei", "wol", "ver\u00b7gn\u00fcg\u00b7tes", "le\u00b7ben"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADJD", "ADV", "ADJA", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "ist nicht um ein land zu geben.\u00ab", "tokens": ["ist", "nicht", "um", "ein", "land", "zu", "ge\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "ART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}}}}}