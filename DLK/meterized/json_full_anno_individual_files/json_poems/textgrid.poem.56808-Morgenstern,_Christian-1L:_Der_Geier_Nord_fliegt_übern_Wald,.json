{"textgrid.poem.56808": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Geier Nord fliegt \u00fcbern Wald,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Geier Nord fliegt \u00fcbern Wald,", "tokens": ["Der", "Gei\u00b7er", "Nord", "fliegt", "\u00fc\u00b7bern", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in einen grauen Sack gekrallt,", "tokens": ["in", "ei\u00b7nen", "grau\u00b7en", "Sack", "ge\u00b7krallt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "er hat nicht leicht zu tragen.", "tokens": ["er", "hat", "nicht", "leicht", "zu", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er fliegt zu niedrig ob der Erd',", "tokens": ["Er", "fliegt", "zu", "nied\u00b7rig", "ob", "der", "Erd'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKA", "ADJD", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die Fichten drohen ihm Gef\u00e4hrd',", "tokens": ["die", "Fich\u00b7ten", "dro\u00b7hen", "ihm", "Ge\u00b7f\u00e4hrd'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die dort so spitzig ragen.", "tokens": ["die", "dort", "so", "spit\u00b7zig", "ra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Da ... schon ... da h\u00e4ngt das Wolkentuch!", "tokens": ["Da", "...", "schon", "...", "da", "h\u00e4ngt", "das", "Wol\u00b7ken\u00b7tuch", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "ADV", "$(", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00f6rst du des Geiers grausen Fluch?", "tokens": ["H\u00f6rst", "du", "des", "Gei\u00b7ers", "grau\u00b7sen", "Fluch", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er mu\u00df es fahren lassen:", "tokens": ["Er", "mu\u00df", "es", "fah\u00b7ren", "las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und aus dem aufgeri\u00dfnen Sack", "tokens": ["Und", "aus", "dem", "auf\u00b7ge\u00b7ri\u00df\u00b7nen", "Sack"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "spreun lustig sich auf Tann und Hag", "tokens": ["spreun", "lus\u00b7tig", "sich", "auf", "Tann", "und", "Hag"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PRF", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Frau Holles wei\u00dfe Massen.", "tokens": ["Frau", "Hol\u00b7les", "wei\u00b7\u00dfe", "Mas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Erdm\u00e4nnlein halten hohle Hand", "tokens": ["Erd\u00b7m\u00e4nn\u00b7lein", "hal\u00b7ten", "hoh\u00b7le", "Hand"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "und schm\u00fccken mit dem Glitzer-Tand", "tokens": ["und", "schm\u00fc\u00b7cken", "mit", "dem", "Glit\u00b7zer\u00b7Tand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "laut kichernd ihre Weiblein.", "tokens": ["laut", "ki\u00b7chernd", "ih\u00b7re", "Weib\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "PPOSAT", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Die stelzen hoch daher, doch weh!", "tokens": ["Die", "stel\u00b7zen", "hoch", "da\u00b7her", ",", "doch", "weh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PAV", "$,", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "schon schmelzen die Geschmeid' aus Schnee,", "tokens": ["schon", "schmel\u00b7zen", "die", "Ge\u00b7schmeid'", "aus", "Schnee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und na\u00df sind alle Leiblein.", "tokens": ["und", "na\u00df", "sind", "al\u00b7le", "Leib\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Am Himmel kommt der Nord zur\u00fcck", "tokens": ["Am", "Him\u00b7mel", "kommt", "der", "Nord", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit einem neuen Wolkenst\u00fcck, \u2013", "tokens": ["mit", "ei\u00b7nem", "neu\u00b7en", "Wol\u00b7ken\u00b7st\u00fcck", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "doch wieder bleibt es h\u00e4ngen.", "tokens": ["doch", "wie\u00b7der", "bleibt", "es", "h\u00e4n\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wenn das so fort geht \u2013, Leutlein, rennt", "tokens": ["Wenn", "das", "so", "fort", "geht", "\u2013", ",", "Leut\u00b7lein", ",", "rennt"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word"], "pos": ["KOUS", "PDS", "ADV", "PTKVZ", "VVFIN", "$(", "$,", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "nach Haus, sonst wird das Element", "tokens": ["nach", "Haus", ",", "sonst", "wird", "das", "E\u00b7le\u00b7ment"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "euch ernstlich noch bedr\u00e4ngen!", "tokens": ["euch", "ernst\u00b7lich", "noch", "be\u00b7dr\u00e4n\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Das V\u00f6lklein l\u00e4uft. Der Geier gibt's", "tokens": ["Das", "V\u00f6l\u00b7klein", "l\u00e4uft", ".", "Der", "Gei\u00b7er", "gibt's"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "voll Trotz nicht auf \u2013 und endlos stiebt's", "tokens": ["voll", "Trotz", "nicht", "auf", "\u2013", "und", "end\u00b7los", "stiebt's"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "NN", "PTKNEG", "APPR", "$(", "KON", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "aus aufgespie\u00dften S\u00e4cken ...", "tokens": ["aus", "auf\u00b7ge\u00b7spie\u00df\u00b7ten", "S\u00e4\u00b7cken", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den ganzen Tag, die ganze Nacht ...", "tokens": ["Den", "gan\u00b7zen", "Tag", ",", "die", "gan\u00b7ze", "Nacht", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wohl tausend St\u00fcck, von ihm gebracht,", "tokens": ["Wohl", "tau\u00b7send", "St\u00fcck", ",", "von", "ihm", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "$,", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "den Waldgrund nun bedecken.", "tokens": ["den", "Wald\u00b7grund", "nun", "be\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Der Geier Nord fliegt \u00fcbern Wald,", "tokens": ["Der", "Gei\u00b7er", "Nord", "fliegt", "\u00fc\u00b7bern", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in einen grauen Sack gekrallt,", "tokens": ["in", "ei\u00b7nen", "grau\u00b7en", "Sack", "ge\u00b7krallt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "er hat nicht leicht zu tragen.", "tokens": ["er", "hat", "nicht", "leicht", "zu", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er fliegt zu niedrig ob der Erd',", "tokens": ["Er", "fliegt", "zu", "nied\u00b7rig", "ob", "der", "Erd'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKA", "ADJD", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die Fichten drohen ihm Gef\u00e4hrd',", "tokens": ["die", "Fich\u00b7ten", "dro\u00b7hen", "ihm", "Ge\u00b7f\u00e4hrd'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die dort so spitzig ragen.", "tokens": ["die", "dort", "so", "spit\u00b7zig", "ra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Da ... schon ... da h\u00e4ngt das Wolkentuch!", "tokens": ["Da", "...", "schon", "...", "da", "h\u00e4ngt", "das", "Wol\u00b7ken\u00b7tuch", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "ADV", "$(", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00f6rst du des Geiers grausen Fluch?", "tokens": ["H\u00f6rst", "du", "des", "Gei\u00b7ers", "grau\u00b7sen", "Fluch", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er mu\u00df es fahren lassen:", "tokens": ["Er", "mu\u00df", "es", "fah\u00b7ren", "las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und aus dem aufgeri\u00dfnen Sack", "tokens": ["Und", "aus", "dem", "auf\u00b7ge\u00b7ri\u00df\u00b7nen", "Sack"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "spreun lustig sich auf Tann und Hag", "tokens": ["spreun", "lus\u00b7tig", "sich", "auf", "Tann", "und", "Hag"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PRF", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Frau Holles wei\u00dfe Massen.", "tokens": ["Frau", "Hol\u00b7les", "wei\u00b7\u00dfe", "Mas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Erdm\u00e4nnlein halten hohle Hand", "tokens": ["Erd\u00b7m\u00e4nn\u00b7lein", "hal\u00b7ten", "hoh\u00b7le", "Hand"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "und schm\u00fccken mit dem Glitzer-Tand", "tokens": ["und", "schm\u00fc\u00b7cken", "mit", "dem", "Glit\u00b7zer\u00b7Tand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "laut kichernd ihre Weiblein.", "tokens": ["laut", "ki\u00b7chernd", "ih\u00b7re", "Weib\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "PPOSAT", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Die stelzen hoch daher, doch weh!", "tokens": ["Die", "stel\u00b7zen", "hoch", "da\u00b7her", ",", "doch", "weh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PAV", "$,", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "schon schmelzen die Geschmeid' aus Schnee,", "tokens": ["schon", "schmel\u00b7zen", "die", "Ge\u00b7schmeid'", "aus", "Schnee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und na\u00df sind alle Leiblein.", "tokens": ["und", "na\u00df", "sind", "al\u00b7le", "Leib\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Am Himmel kommt der Nord zur\u00fcck", "tokens": ["Am", "Him\u00b7mel", "kommt", "der", "Nord", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit einem neuen Wolkenst\u00fcck, \u2013", "tokens": ["mit", "ei\u00b7nem", "neu\u00b7en", "Wol\u00b7ken\u00b7st\u00fcck", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "doch wieder bleibt es h\u00e4ngen.", "tokens": ["doch", "wie\u00b7der", "bleibt", "es", "h\u00e4n\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wenn das so fort geht \u2013, Leutlein, rennt", "tokens": ["Wenn", "das", "so", "fort", "geht", "\u2013", ",", "Leut\u00b7lein", ",", "rennt"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word"], "pos": ["KOUS", "PDS", "ADV", "PTKVZ", "VVFIN", "$(", "$,", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "nach Haus, sonst wird das Element", "tokens": ["nach", "Haus", ",", "sonst", "wird", "das", "E\u00b7le\u00b7ment"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "euch ernstlich noch bedr\u00e4ngen!", "tokens": ["euch", "ernst\u00b7lich", "noch", "be\u00b7dr\u00e4n\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Das V\u00f6lklein l\u00e4uft. Der Geier gibt's", "tokens": ["Das", "V\u00f6l\u00b7klein", "l\u00e4uft", ".", "Der", "Gei\u00b7er", "gibt's"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "voll Trotz nicht auf \u2013 und endlos stiebt's", "tokens": ["voll", "Trotz", "nicht", "auf", "\u2013", "und", "end\u00b7los", "stiebt's"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "NN", "PTKNEG", "APPR", "$(", "KON", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "aus aufgespie\u00dften S\u00e4cken ...", "tokens": ["aus", "auf\u00b7ge\u00b7spie\u00df\u00b7ten", "S\u00e4\u00b7cken", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den ganzen Tag, die ganze Nacht ...", "tokens": ["Den", "gan\u00b7zen", "Tag", ",", "die", "gan\u00b7ze", "Nacht", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wohl tausend St\u00fcck, von ihm gebracht,", "tokens": ["Wohl", "tau\u00b7send", "St\u00fcck", ",", "von", "ihm", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "$,", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "den Waldgrund nun bedecken.", "tokens": ["den", "Wald\u00b7grund", "nun", "be\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}