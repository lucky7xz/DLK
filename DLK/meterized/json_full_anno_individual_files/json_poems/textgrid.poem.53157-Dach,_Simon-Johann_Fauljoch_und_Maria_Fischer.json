{"textgrid.poem.53157": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Johann Fauljoch und Maria Fischer", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir gehen gern zu gast,", "tokens": ["Wir", "ge\u00b7hen", "gern", "zu", "gast", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Auch ausserhalb der Fast", "tokens": ["Auch", "aus\u00b7ser\u00b7halb", "der", "Fast"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vns ehrlich zu ergetzen.", "tokens": ["Vns", "ehr\u00b7lich", "zu", "er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wer ladet uns doch ein,", "tokens": ["Wer", "la\u00b7det", "uns", "doch", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df wir durch Bier und Wein", "tokens": ["Da\u00df", "wir", "durch", "Bier", "und", "Wein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Die d\u00fcrren Sinne netzen?", "tokens": ["Die", "d\u00fcr\u00b7ren", "Sin\u00b7ne", "net\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "O Jauchloff, das thust du,", "tokens": ["O", "Jauch\u00b7loff", ",", "das", "thust", "du", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PDS", "VVFIN", "PPER", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wir sprechen dir auch zu,", "tokens": ["Wir", "spre\u00b7chen", "dir", "auch", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wir trewes Volck der Hirten:", "tokens": ["Wir", "tre\u00b7wes", "Volck", "der", "Hir\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wir gehn gesampt mit Dir", "tokens": ["Wir", "gehn", "ge\u00b7sampt", "mit", "Dir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Zu deiner Hochzeit Zier", "tokens": ["Zu", "dei\u00b7ner", "Hoch\u00b7zeit", "Zier"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Vnd lassen uns bewirten.", "tokens": ["Vnd", "las\u00b7sen", "uns", "be\u00b7wir\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Du aber giebst den Sinn", "tokens": ["Du", "a\u00b7ber", "giebst", "den", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Der Heyraht gleichwol hin?", "tokens": ["Der", "Hey\u00b7raht", "gleich\u00b7wol", "hin", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wol dir, wol auch uns allen!", "tokens": ["Wol", "dir", ",", "wol", "auch", "uns", "al\u00b7len", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "ADV", "ADV", "PPER", "PIAT", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Denn weil auch dich zuletzt", "tokens": ["Denn", "weil", "auch", "dich", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der Liebe Werck ergetzt,", "tokens": ["Der", "Lie\u00b7be", "Werck", "er\u00b7getzt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Was kan uns ba\u00df gefallen?", "tokens": ["Was", "kan", "uns", "ba\u00df", "ge\u00b7fal\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ich, Damon, Celadon", "tokens": ["Ich", ",", "Da\u00b7mon", ",", "Ce\u00b7la\u00b7don"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["PPER", "$,", "NE", "$,", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Erfrewen l\u00e4ngst uns schon", "tokens": ["Er\u00b7fre\u00b7wen", "l\u00e4ngst", "uns", "schon"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Am s\u00fcssen Vater-Nahmen:", "tokens": ["Am", "s\u00fcs\u00b7sen", "Va\u00b7ter\u00b7Nah\u00b7men", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Du fragtest nichts darnach,", "tokens": ["Du", "frag\u00b7test", "nichts", "dar\u00b7nach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PAV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dir war es schlechte Sach,", "tokens": ["Dir", "war", "es", "schlech\u00b7te", "Sach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Sich sehn in seinem Samen.", "tokens": ["Sich", "sehn", "in", "sei\u00b7nem", "Sa\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Jetzt hat dich Amor auch", "tokens": ["Jetzt", "hat", "dich", "A\u00b7mor", "auch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NE", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Zu seinem Dienst und Brauch,", "tokens": ["Zu", "sei\u00b7nem", "Dienst", "und", "Brauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Geh nun, und fleuch zu lieben!", "tokens": ["Geh", "nun", ",", "und", "fleuch", "zu", "lie\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bring, Venus, ein den Streit,", "tokens": ["Bring", ",", "Ve\u00b7nus", ",", "ein", "den", "Streit", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "ART", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Den er so lange Zeit", "tokens": ["Den", "er", "so", "lan\u00b7ge", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Gewust hat auffzuschieben.", "tokens": ["Ge\u00b7wust", "hat", "auff\u00b7zu\u00b7schie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ihr G\u00f6tter, wann jhr wisst,", "tokens": ["Ihr", "G\u00f6t\u00b7ter", ",", "wann", "jhr", "wisst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das Jauchloff w\u00fcrdig ist", "tokens": ["Das", "Jauch\u00b7loff", "w\u00fcr\u00b7dig", "ist"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zum Beystand euch zu haben,", "tokens": ["Zum", "Beys\u00b7tand", "euch", "zu", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So seyd uns zugesellt,", "tokens": ["So", "seyd", "uns", "zu\u00b7ge\u00b7sellt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Kr\u00f6hnt h\u00e4uffig dieses Feld", "tokens": ["Kr\u00b7\u00f6hnt", "h\u00e4uf\u00b7fig", "die\u00b7ses", "Feld"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd jhn mit ewren Gaben!", "tokens": ["Vnd", "jhn", "mit", "ew\u00b7ren", "Ga\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Wir, Jauchloff, sind bem\u00fcht", "tokens": ["Wir", ",", "Jauch\u00b7loff", ",", "sind", "be\u00b7m\u00fcht"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "NN", "$,", "VAFIN", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Zu singen jetzt dein Lied", "tokens": ["Zu", "sin\u00b7gen", "jetzt", "dein", "Lied"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auff jenen zw\u00f6lff Trompeten,", "tokens": ["Auff", "je\u00b7nen", "zw\u00f6lff", "Trom\u00b7pe\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Fehlt uns der Athem dann,", "tokens": ["Fehlt", "uns", "der", "A\u00b7them", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So h\u00f6r es gleich wol an", "tokens": ["So", "h\u00f6r", "es", "gleich", "wol", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Auff unsern Hirten-Fl\u00f6ten.", "tokens": ["Auff", "un\u00b7sern", "Hir\u00b7ten\u00b7Fl\u00f6\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Wir gehen gern zu gast,", "tokens": ["Wir", "ge\u00b7hen", "gern", "zu", "gast", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Auch ausserhalb der Fast", "tokens": ["Auch", "aus\u00b7ser\u00b7halb", "der", "Fast"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vns ehrlich zu ergetzen.", "tokens": ["Vns", "ehr\u00b7lich", "zu", "er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wer ladet uns doch ein,", "tokens": ["Wer", "la\u00b7det", "uns", "doch", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df wir durch Bier und Wein", "tokens": ["Da\u00df", "wir", "durch", "Bier", "und", "Wein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Die d\u00fcrren Sinne netzen?", "tokens": ["Die", "d\u00fcr\u00b7ren", "Sin\u00b7ne", "net\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "O Jauchloff, das thust du,", "tokens": ["O", "Jauch\u00b7loff", ",", "das", "thust", "du", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PDS", "VVFIN", "PPER", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wir sprechen dir auch zu,", "tokens": ["Wir", "spre\u00b7chen", "dir", "auch", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wir trewes Volck der Hirten:", "tokens": ["Wir", "tre\u00b7wes", "Volck", "der", "Hir\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wir gehn gesampt mit Dir", "tokens": ["Wir", "gehn", "ge\u00b7sampt", "mit", "Dir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Zu deiner Hochzeit Zier", "tokens": ["Zu", "dei\u00b7ner", "Hoch\u00b7zeit", "Zier"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Vnd lassen uns bewirten.", "tokens": ["Vnd", "las\u00b7sen", "uns", "be\u00b7wir\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Du aber giebst den Sinn", "tokens": ["Du", "a\u00b7ber", "giebst", "den", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Der Heyraht gleichwol hin?", "tokens": ["Der", "Hey\u00b7raht", "gleich\u00b7wol", "hin", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wol dir, wol auch uns allen!", "tokens": ["Wol", "dir", ",", "wol", "auch", "uns", "al\u00b7len", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "ADV", "ADV", "PPER", "PIAT", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Denn weil auch dich zuletzt", "tokens": ["Denn", "weil", "auch", "dich", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der Liebe Werck ergetzt,", "tokens": ["Der", "Lie\u00b7be", "Werck", "er\u00b7getzt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Was kan uns ba\u00df gefallen?", "tokens": ["Was", "kan", "uns", "ba\u00df", "ge\u00b7fal\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Ich, Damon, Celadon", "tokens": ["Ich", ",", "Da\u00b7mon", ",", "Ce\u00b7la\u00b7don"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["PPER", "$,", "NE", "$,", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Erfrewen l\u00e4ngst uns schon", "tokens": ["Er\u00b7fre\u00b7wen", "l\u00e4ngst", "uns", "schon"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Am s\u00fcssen Vater-Nahmen:", "tokens": ["Am", "s\u00fcs\u00b7sen", "Va\u00b7ter\u00b7Nah\u00b7men", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Du fragtest nichts darnach,", "tokens": ["Du", "frag\u00b7test", "nichts", "dar\u00b7nach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PAV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dir war es schlechte Sach,", "tokens": ["Dir", "war", "es", "schlech\u00b7te", "Sach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Sich sehn in seinem Samen.", "tokens": ["Sich", "sehn", "in", "sei\u00b7nem", "Sa\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Jetzt hat dich Amor auch", "tokens": ["Jetzt", "hat", "dich", "A\u00b7mor", "auch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NE", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Zu seinem Dienst und Brauch,", "tokens": ["Zu", "sei\u00b7nem", "Dienst", "und", "Brauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Geh nun, und fleuch zu lieben!", "tokens": ["Geh", "nun", ",", "und", "fleuch", "zu", "lie\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bring, Venus, ein den Streit,", "tokens": ["Bring", ",", "Ve\u00b7nus", ",", "ein", "den", "Streit", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "ART", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Den er so lange Zeit", "tokens": ["Den", "er", "so", "lan\u00b7ge", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Gewust hat auffzuschieben.", "tokens": ["Ge\u00b7wust", "hat", "auff\u00b7zu\u00b7schie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Ihr G\u00f6tter, wann jhr wisst,", "tokens": ["Ihr", "G\u00f6t\u00b7ter", ",", "wann", "jhr", "wisst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das Jauchloff w\u00fcrdig ist", "tokens": ["Das", "Jauch\u00b7loff", "w\u00fcr\u00b7dig", "ist"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zum Beystand euch zu haben,", "tokens": ["Zum", "Beys\u00b7tand", "euch", "zu", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So seyd uns zugesellt,", "tokens": ["So", "seyd", "uns", "zu\u00b7ge\u00b7sellt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Kr\u00f6hnt h\u00e4uffig dieses Feld", "tokens": ["Kr\u00b7\u00f6hnt", "h\u00e4uf\u00b7fig", "die\u00b7ses", "Feld"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd jhn mit ewren Gaben!", "tokens": ["Vnd", "jhn", "mit", "ew\u00b7ren", "Ga\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Wir, Jauchloff, sind bem\u00fcht", "tokens": ["Wir", ",", "Jauch\u00b7loff", ",", "sind", "be\u00b7m\u00fcht"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "NN", "$,", "VAFIN", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Zu singen jetzt dein Lied", "tokens": ["Zu", "sin\u00b7gen", "jetzt", "dein", "Lied"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auff jenen zw\u00f6lff Trompeten,", "tokens": ["Auff", "je\u00b7nen", "zw\u00f6lff", "Trom\u00b7pe\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Fehlt uns der Athem dann,", "tokens": ["Fehlt", "uns", "der", "A\u00b7them", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So h\u00f6r es gleich wol an", "tokens": ["So", "h\u00f6r", "es", "gleich", "wol", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Auff unsern Hirten-Fl\u00f6ten.", "tokens": ["Auff", "un\u00b7sern", "Hir\u00b7ten\u00b7Fl\u00f6\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}