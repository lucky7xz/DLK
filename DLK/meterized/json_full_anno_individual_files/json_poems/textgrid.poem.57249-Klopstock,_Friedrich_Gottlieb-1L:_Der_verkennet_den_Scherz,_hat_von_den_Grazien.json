{"textgrid.poem.57249": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der verkennet den Scherz, hat von den Grazien", "genre": "verse", "period": "N.A.", "pub_year": 1752, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der verkennet den Scherz, hat von den Grazien", "tokens": ["Der", "ver\u00b7ken\u00b7net", "den", "Scherz", ",", "hat", "von", "den", "Gra\u00b7zi\u00b7en"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "$,", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Keine Mine belauscht, der es nicht fassen kann,", "tokens": ["Kei\u00b7ne", "Mi\u00b7ne", "be\u00b7lauscht", ",", "der", "es", "nicht", "fas\u00b7sen", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$,", "PRELS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Dass der Liebling der Freude", "tokens": ["Dass", "der", "Lieb\u00b7ling", "der", "Freu\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Nur mit Sokrates Freunden lacht.", "tokens": ["Nur", "mit", "Sok\u00b7ra\u00b7tes", "Freun\u00b7den", "lacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.2": {"line.1": {"text": "Du verkennest ihn nicht, wenn du dem Abendstern,", "tokens": ["Du", "ver\u00b7ken\u00b7nest", "ihn", "nicht", ",", "wenn", "du", "dem", "A\u00b7bends\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "ART", "NN", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Nach den Pflichten des Tags, schnellere Fl\u00fcgel giebst,", "tokens": ["Nach", "den", "Pflich\u00b7ten", "des", "Tags", ",", "schnel\u00b7le\u00b7re", "Fl\u00fc\u00b7gel", "giebst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--++--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und dem Ernste der Weisheit", "tokens": ["Und", "dem", "Erns\u00b7te", "der", "Weis\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Deine Blumen entgegen streust.", "tokens": ["Dei\u00b7ne", "Blu\u00b7men", "ent\u00b7ge\u00b7gen", "streust", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.3": {"line.1": {"text": "Lass den Lacher, o Gleim, lauter dein Lied entweihn!", "tokens": ["Lass", "den", "La\u00b7cher", ",", "o", "Gleim", ",", "lau\u00b7ter", "dein", "Lied", "ent\u00b7weihn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "FM", "NN", "$,", "PIAT", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+---+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Deine Freunde verstehns. Wenige kennest du;", "tokens": ["Dei\u00b7ne", "Freun\u00b7de", "ver\u00b7stehns", ".", "We\u00b7ni\u00b7ge", "ken\u00b7nest", "du", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "$.", "PIAT", "VVFIN", "PPER", "$."], "meter": "+-+--+---+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Und manch lesbisches M\u00e4dchen", "tokens": ["Und", "manch", "les\u00b7bi\u00b7sches", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Straft des Liedes Entweihungen!", "tokens": ["Straft", "des", "Lie\u00b7des", "Ent\u00b7wei\u00b7hun\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Lacht dem J\u00fcnglinge nicht, welcher den Flatterer", "tokens": ["Lacht", "dem", "J\u00fcng\u00b7lin\u00b7ge", "nicht", ",", "wel\u00b7cher", "den", "Flat\u00b7te\u00b7rer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "$,", "PRELS", "ART", "NN"], "meter": "+-++--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Zu buchst\u00e4blich, erkl\u00e4rt! weiss es, wie sch\u00f6n sie ist!", "tokens": ["Zu", "buch\u00b7st\u00e4b\u00b7lich", ",", "er\u00b7kl\u00e4rt", "!", "weiss", "es", ",", "wie", "sch\u00f6n", "sie", "ist", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$,", "VVPP", "$.", "KOUS", "PPER", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Z\u00fcrnt ihn weiser, und lehrt ihn,", "tokens": ["Z\u00fcrnt", "ihn", "wei\u00b7ser", ",", "und", "lehrt", "ihn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Wie ihr L\u00e4cheln, dein Lied verstehn!", "tokens": ["Wie", "ihr", "L\u00e4\u00b7cheln", ",", "dein", "Lied", "ver\u00b7stehn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "VVINF", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.5": {"line.1": {"text": "Nun versteht ers; sie mehr. Aber so sch\u00f6n sie ist,", "tokens": ["Nun", "ver\u00b7steht", "ers", ";", "sie", "mehr", ".", "A\u00b7ber", "so", "sch\u00f6n", "sie", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$.", "PPER", "ADV", "$.", "KON", "ADV", "ADJD", "PPER", "VAFIN", "$,"], "meter": "--+--+---+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "So emp\u00f6rt auch ihr Herz deinem Gesange schl\u00e4gt:", "tokens": ["So", "em\u00b7p\u00f6rt", "auch", "ihr", "Herz", "dei\u00b7nem", "Ge\u00b7san\u00b7ge", "schl\u00e4gt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "--+--++--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "O so kennt sie doch Gleimen,", "tokens": ["O", "so", "kennt", "sie", "doch", "Glei\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und sein, feuriges Herz nicht ganz!", "tokens": ["Und", "sein", ",", "feu\u00b7ri\u00b7ges", "Herz", "nicht", "ganz", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAINF", "$,", "ADJA", "NN", "PTKNEG", "ADV", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Seinen brennenden Durst, Freunden ein Freund zu seyn!", "tokens": ["Sei\u00b7nen", "bren\u00b7nen\u00b7den", "Durst", ",", "Freun\u00b7den", "ein", "Freund", "zu", "seyn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "NN", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "+-+--++--+-+", "measure": "asklepiade"}, "line.2": {"text": "Wie er auf das Verdienst dess, den er liebet, stolz,", "tokens": ["Wie", "er", "auf", "das", "Ver\u00b7dienst", "dess", ",", "den", "er", "lie\u00b7bet", ",", "stolz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "PDS", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADJD", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Edel stolz ist, vom halben,", "tokens": ["E\u00b7del", "stolz", "ist", ",", "vom", "hal\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAFIN", "$,", "APPRART", "ADJA", "$,"], "meter": "+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Kalten Lobe beleidiget!", "tokens": ["Kal\u00b7ten", "Lo\u00b7be", "be\u00b7lei\u00b7di\u00b7get", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.7": {"line.1": {"text": "Liebend, Liebe gebeut! hier nur die z\u00f6gernde", "tokens": ["Lie\u00b7bend", ",", "Lie\u00b7be", "ge\u00b7beut", "!", "hier", "nur", "die", "z\u00f6\u00b7gern\u00b7de"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "NN", "VVFIN", "$.", "ADV", "ADV", "ART", "ADJA"], "meter": "+-+--+-++-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Sanfte M\u00e4ssigung hasst, oder, von Friederichs,", "tokens": ["Sanf\u00b7te", "M\u00e4s\u00b7si\u00b7gung", "hasst", ",", "o\u00b7der", ",", "von", "Frie\u00b7de\u00b7richs", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,", "KON", "$,", "APPR", "NE", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Wenn, von Friederichs Preise!", "tokens": ["Wenn", ",", "von", "Frie\u00b7de\u00b7richs", "Prei\u00b7se", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "NE", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ihm die trunknere Lippe trieft,", "tokens": ["Ihm", "die", "trunk\u00b7ne\u00b7re", "Lip\u00b7pe", "trieft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.8": {"line.1": {"text": "Ohne W\u00fcnsche nach Lohn; aber auch unbelohnt!", "tokens": ["Oh\u00b7ne", "W\u00fcn\u00b7sche", "nach", "Lohn", ";", "a\u00b7ber", "auch", "un\u00b7be\u00b7lohnt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$.", "ADV", "ADV", "ADJD", "$."], "meter": "+-+--+---+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Sprich nur wider dich selbst edel, und ungerecht!", "tokens": ["Sprich", "nur", "wi\u00b7der", "dich", "selbst", "e\u00b7del", ",", "und", "un\u00b7ge\u00b7recht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPR", "PPER", "ADV", "ADJD", "$,", "KON", "ADJD", "$."], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Dennoch beuget, o Gleim, dir", "tokens": ["Den\u00b7noch", "beu\u00b7get", ",", "o", "Gleim", ",", "dir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "$,", "FM", "NN", "$,", "PPER"], "meter": "+-+-++-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Ihren stolzeren Nacken nicht", "tokens": ["Ih\u00b7ren", "stol\u00b7ze\u00b7ren", "Na\u00b7cken", "nicht"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "PTKNEG"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.9": {"line.1": {"text": "Deutschlands Muse! In Flug' eilend zum hohen Ziel,", "tokens": ["Deutschlands", "Mu\u00b7se", "!", "In", "Flug'", "ei\u00b7lend", "zum", "ho\u00b7hen", "Ziel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "APPR", "NN", "VVPP", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das mit heiligem Spross Barden umschatteten,", "tokens": ["Das", "mit", "hei\u00b7li\u00b7gem", "Spross", "Bar\u00b7den", "um\u00b7schat\u00b7te\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ADJA", "NN", "NN", "VVFIN", "$,"], "meter": "--+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Hin zum h\u00f6heren Ziele,", "tokens": ["Hin", "zum", "h\u00f6\u00b7he\u00b7ren", "Zie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Das der Himlischen Palm' umweht,", "tokens": ["Das", "der", "Him\u00b7li\u00b7schen", "Palm'", "um\u00b7weht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.10": {"line.1": {"text": "Sang die z\u00fcrnende mir; t\u00f6nend entschl\u00fcpfete", "tokens": ["Sang", "die", "z\u00fcr\u00b7nen\u00b7de", "mir", ";", "t\u00f6\u00b7nend", "ent\u00b7schl\u00fcp\u00b7fe\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "PPER", "$.", "ADJD", "VVFIN"], "meter": "+-+---+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Mir die Laute, da ich drohend die Priesterin,", "tokens": ["Mir", "die", "Lau\u00b7te", ",", "da", "ich", "dro\u00b7hend", "die", "Pries\u00b7te\u00b7rin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,", "KOUS", "PPER", "VVPP", "ART", "NN", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Und mit fliegendem Haar sah,", "tokens": ["Und", "mit", "flie\u00b7gen\u00b7dem", "Haar", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und entscheidendem Ernst! sie sang:", "tokens": ["Und", "ent\u00b7schei\u00b7den\u00b7dem", "Ernst", "!", "sie", "sang", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$.", "PPER", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.11": {"line.1": {"text": "Lern des innersten Hains Ausspruch, und lehre den", "tokens": ["Lern", "des", "in\u00b7ners\u00b7ten", "Hains", "Aus\u00b7spruch", ",", "und", "leh\u00b7re", "den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "NN", "$,", "KON", "NN", "ART"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.2": {"text": "Jeden G\u00fcnstling der Kunst; oder ich nehme dir", "tokens": ["Je\u00b7den", "G\u00fcnst\u00b7ling", "der", "Kunst", ";", "o\u00b7der", "ich", "neh\u00b7me", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "ART", "NN", "$.", "KON", "PPER", "VVFIN", "PPER"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Deine Laute, zerreisse", "tokens": ["Dei\u00b7ne", "Lau\u00b7te", ",", "zer\u00b7reis\u00b7se"], "token_info": ["word", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Ihre Nerven, und hasse dich!", "tokens": ["Ih\u00b7re", "Ner\u00b7ven", ",", "und", "has\u00b7se", "dich", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "VVFIN", "PPER", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.12": {"line.1": {"text": "W\u00fcrdig war er, uns mehr, als dein begl\u00fccktester", "tokens": ["W\u00fcr\u00b7dig", "war", "er", ",", "uns", "mehr", ",", "als", "dein", "be\u00b7gl\u00fcck\u00b7tes\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "PPER", "ADV", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+--+-+-+--", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Freyheitshasser, o Rom, Octavian zu seyn!", "tokens": ["Frey\u00b7he\u00b7its\u00b7has\u00b7ser", ",", "o", "Rom", ",", "Oc\u00b7ta\u00b7vi\u00b7an", "zu", "seyn", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "FM", "NE", "$,", "NE", "PTKZU", "VAINF", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Mehr als Ludewig, den uns", "tokens": ["Mehr", "als", "Lu\u00b7de\u00b7wig", ",", "den", "uns"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "KOKOM", "NE", "$,", "PRELS", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sein Jahrhundert mit aufbewahrt:", "tokens": ["Sein", "Jahr\u00b7hun\u00b7dert", "mit", "auf\u00b7be\u00b7wahrt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "VVPP", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.13": {"line.1": {"text": "So verk\u00fcndigte ihn, als er noch J\u00fcngling war,", "tokens": ["So", "ver\u00b7k\u00fcn\u00b7dig\u00b7te", "ihn", ",", "als", "er", "noch", "J\u00fcng\u00b7ling", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "NN", "VAFIN", "$,"], "meter": "--+--++--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Sein aufsteigender Geist! Noch, da der Lorber ihm", "tokens": ["Sein", "auf\u00b7stei\u00b7gen\u00b7der", "Geist", "!", "Noch", ",", "da", "der", "Lor\u00b7ber", "ihm"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "ADV", "$,", "KOUS", "ART", "NN", "PPER"], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Schon vom Blute der Schlacht trof,", "tokens": ["Schon", "vom", "Blu\u00b7te", "der", "Schlacht", "trof", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und der Denker gepanzert ging,", "tokens": ["Und", "der", "Den\u00b7ker", "ge\u00b7pan\u00b7zert", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.14": {"line.1": {"text": "Floss der dichtrische Quell Friedrich entgegen, ihm", "tokens": ["Floss", "der", "dich\u00b7tri\u00b7sche", "Quell", "Fried\u00b7rich", "ent\u00b7ge\u00b7gen", ",", "ihm"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["NN", "ART", "ADJA", "NN", "NE", "PTKVZ", "$,", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Abzuwaschen die Schlacht! Aber er wandte sich,", "tokens": ["Ab\u00b7zu\u00b7wa\u00b7schen", "die", "Schlacht", "!", "A\u00b7ber", "er", "wand\u00b7te", "sich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$.", "KON", "PPER", "VVFIN", "PRF", "$,"], "meter": "+-+--+---+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Str\u00f6mt' in Haine, wohin ihm", "tokens": ["Str\u00f6mt'", "in", "Hai\u00b7ne", ",", "wo\u00b7hin", "ihm"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "APPR", "NE", "$,", "PWAV", "PPER"], "meter": "+-+-++-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Heinrichs S\u00e4nger nicht folgen wird!", "tokens": ["Hein\u00b7richs", "S\u00e4n\u00b7ger", "nicht", "fol\u00b7gen", "wird", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKNEG", "VVINF", "VAFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.15": {"line.1": {"text": "Sagts der Nachwelt nicht an, dass er nicht achtete,", "tokens": ["Sagts", "der", "Nach\u00b7welt", "nicht", "an", ",", "dass", "er", "nicht", "ach\u00b7te\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PTKNEG", "PTKVZ", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Was er werth war, zu seyn! Aber sie h\u00f6rt es doch:", "tokens": ["Was", "er", "werth", "war", ",", "zu", "seyn", "!", "A\u00b7ber", "sie", "h\u00f6rt", "es", "doch", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VAFIN", "$,", "PTKZU", "VAINF", "$.", "KON", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sagts ihr traurig, und fordert", "tokens": ["Sagts", "ihr", "trau\u00b7rig", ",", "und", "for\u00b7dert"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "KON", "VVFIN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Ihre S\u00f6hne zu Richtern auf!", "tokens": ["Ih\u00b7re", "S\u00f6h\u00b7ne", "zu", "Rich\u00b7tern", "auf", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.16": {"line.1": {"text": "Der verkennet den Scherz, hat von den Grazien", "tokens": ["Der", "ver\u00b7ken\u00b7net", "den", "Scherz", ",", "hat", "von", "den", "Gra\u00b7zi\u00b7en"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "$,", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Keine Mine belauscht, der es nicht fassen kann,", "tokens": ["Kei\u00b7ne", "Mi\u00b7ne", "be\u00b7lauscht", ",", "der", "es", "nicht", "fas\u00b7sen", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$,", "PRELS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Dass der Liebling der Freude", "tokens": ["Dass", "der", "Lieb\u00b7ling", "der", "Freu\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Nur mit Sokrates Freunden lacht.", "tokens": ["Nur", "mit", "Sok\u00b7ra\u00b7tes", "Freun\u00b7den", "lacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.17": {"line.1": {"text": "Du verkennest ihn nicht, wenn du dem Abendstern,", "tokens": ["Du", "ver\u00b7ken\u00b7nest", "ihn", "nicht", ",", "wenn", "du", "dem", "A\u00b7bends\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "ART", "NN", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Nach den Pflichten des Tags, schnellere Fl\u00fcgel giebst,", "tokens": ["Nach", "den", "Pflich\u00b7ten", "des", "Tags", ",", "schnel\u00b7le\u00b7re", "Fl\u00fc\u00b7gel", "giebst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--++--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und dem Ernste der Weisheit", "tokens": ["Und", "dem", "Erns\u00b7te", "der", "Weis\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Deine Blumen entgegen streust.", "tokens": ["Dei\u00b7ne", "Blu\u00b7men", "ent\u00b7ge\u00b7gen", "streust", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.18": {"line.1": {"text": "Lass den Lacher, o Gleim, lauter dein Lied entweihn!", "tokens": ["Lass", "den", "La\u00b7cher", ",", "o", "Gleim", ",", "lau\u00b7ter", "dein", "Lied", "ent\u00b7weihn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "FM", "NN", "$,", "PIAT", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+---+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Deine Freunde verstehns. Wenige kennest du;", "tokens": ["Dei\u00b7ne", "Freun\u00b7de", "ver\u00b7stehns", ".", "We\u00b7ni\u00b7ge", "ken\u00b7nest", "du", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "$.", "PIAT", "VVFIN", "PPER", "$."], "meter": "+-+--+---+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Und manch lesbisches M\u00e4dchen", "tokens": ["Und", "manch", "les\u00b7bi\u00b7sches", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Straft des Liedes Entweihungen!", "tokens": ["Straft", "des", "Lie\u00b7des", "Ent\u00b7wei\u00b7hun\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Lacht dem J\u00fcnglinge nicht, welcher den Flatterer", "tokens": ["Lacht", "dem", "J\u00fcng\u00b7lin\u00b7ge", "nicht", ",", "wel\u00b7cher", "den", "Flat\u00b7te\u00b7rer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "$,", "PRELS", "ART", "NN"], "meter": "+-++--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Zu buchst\u00e4blich, erkl\u00e4rt! weiss es, wie sch\u00f6n sie ist!", "tokens": ["Zu", "buch\u00b7st\u00e4b\u00b7lich", ",", "er\u00b7kl\u00e4rt", "!", "weiss", "es", ",", "wie", "sch\u00f6n", "sie", "ist", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$,", "VVPP", "$.", "KOUS", "PPER", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Z\u00fcrnt ihn weiser, und lehrt ihn,", "tokens": ["Z\u00fcrnt", "ihn", "wei\u00b7ser", ",", "und", "lehrt", "ihn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Wie ihr L\u00e4cheln, dein Lied verstehn!", "tokens": ["Wie", "ihr", "L\u00e4\u00b7cheln", ",", "dein", "Lied", "ver\u00b7stehn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "VVINF", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.20": {"line.1": {"text": "Nun versteht ers; sie mehr. Aber so sch\u00f6n sie ist,", "tokens": ["Nun", "ver\u00b7steht", "ers", ";", "sie", "mehr", ".", "A\u00b7ber", "so", "sch\u00f6n", "sie", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$.", "PPER", "ADV", "$.", "KON", "ADV", "ADJD", "PPER", "VAFIN", "$,"], "meter": "--+--+---+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "So emp\u00f6rt auch ihr Herz deinem Gesange schl\u00e4gt:", "tokens": ["So", "em\u00b7p\u00f6rt", "auch", "ihr", "Herz", "dei\u00b7nem", "Ge\u00b7san\u00b7ge", "schl\u00e4gt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "--+--++--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "O so kennt sie doch Gleimen,", "tokens": ["O", "so", "kennt", "sie", "doch", "Glei\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und sein, feuriges Herz nicht ganz!", "tokens": ["Und", "sein", ",", "feu\u00b7ri\u00b7ges", "Herz", "nicht", "ganz", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAINF", "$,", "ADJA", "NN", "PTKNEG", "ADV", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.21": {"line.1": {"text": "Seinen brennenden Durst, Freunden ein Freund zu seyn!", "tokens": ["Sei\u00b7nen", "bren\u00b7nen\u00b7den", "Durst", ",", "Freun\u00b7den", "ein", "Freund", "zu", "seyn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "NN", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "+-+--++--+-+", "measure": "asklepiade"}, "line.2": {"text": "Wie er auf das Verdienst dess, den er liebet, stolz,", "tokens": ["Wie", "er", "auf", "das", "Ver\u00b7dienst", "dess", ",", "den", "er", "lie\u00b7bet", ",", "stolz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "PDS", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADJD", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Edel stolz ist, vom halben,", "tokens": ["E\u00b7del", "stolz", "ist", ",", "vom", "hal\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAFIN", "$,", "APPRART", "ADJA", "$,"], "meter": "+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Kalten Lobe beleidiget!", "tokens": ["Kal\u00b7ten", "Lo\u00b7be", "be\u00b7lei\u00b7di\u00b7get", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.22": {"line.1": {"text": "Liebend, Liebe gebeut! hier nur die z\u00f6gernde", "tokens": ["Lie\u00b7bend", ",", "Lie\u00b7be", "ge\u00b7beut", "!", "hier", "nur", "die", "z\u00f6\u00b7gern\u00b7de"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "NN", "VVFIN", "$.", "ADV", "ADV", "ART", "ADJA"], "meter": "+-+--+-++-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Sanfte M\u00e4ssigung hasst, oder, von Friederichs,", "tokens": ["Sanf\u00b7te", "M\u00e4s\u00b7si\u00b7gung", "hasst", ",", "o\u00b7der", ",", "von", "Frie\u00b7de\u00b7richs", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,", "KON", "$,", "APPR", "NE", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Wenn, von Friederichs Preise!", "tokens": ["Wenn", ",", "von", "Frie\u00b7de\u00b7richs", "Prei\u00b7se", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "NE", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ihm die trunknere Lippe trieft,", "tokens": ["Ihm", "die", "trunk\u00b7ne\u00b7re", "Lip\u00b7pe", "trieft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.23": {"line.1": {"text": "Ohne W\u00fcnsche nach Lohn; aber auch unbelohnt!", "tokens": ["Oh\u00b7ne", "W\u00fcn\u00b7sche", "nach", "Lohn", ";", "a\u00b7ber", "auch", "un\u00b7be\u00b7lohnt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$.", "ADV", "ADV", "ADJD", "$."], "meter": "+-+--+---+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Sprich nur wider dich selbst edel, und ungerecht!", "tokens": ["Sprich", "nur", "wi\u00b7der", "dich", "selbst", "e\u00b7del", ",", "und", "un\u00b7ge\u00b7recht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPR", "PPER", "ADV", "ADJD", "$,", "KON", "ADJD", "$."], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Dennoch beuget, o Gleim, dir", "tokens": ["Den\u00b7noch", "beu\u00b7get", ",", "o", "Gleim", ",", "dir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "$,", "FM", "NN", "$,", "PPER"], "meter": "+-+-++-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Ihren stolzeren Nacken nicht", "tokens": ["Ih\u00b7ren", "stol\u00b7ze\u00b7ren", "Na\u00b7cken", "nicht"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "PTKNEG"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.24": {"line.1": {"text": "Deutschlands Muse! In Flug' eilend zum hohen Ziel,", "tokens": ["Deutschlands", "Mu\u00b7se", "!", "In", "Flug'", "ei\u00b7lend", "zum", "ho\u00b7hen", "Ziel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "APPR", "NN", "VVPP", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das mit heiligem Spross Barden umschatteten,", "tokens": ["Das", "mit", "hei\u00b7li\u00b7gem", "Spross", "Bar\u00b7den", "um\u00b7schat\u00b7te\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ADJA", "NN", "NN", "VVFIN", "$,"], "meter": "--+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Hin zum h\u00f6heren Ziele,", "tokens": ["Hin", "zum", "h\u00f6\u00b7he\u00b7ren", "Zie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Das der Himlischen Palm' umweht,", "tokens": ["Das", "der", "Him\u00b7li\u00b7schen", "Palm'", "um\u00b7weht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.25": {"line.1": {"text": "Sang die z\u00fcrnende mir; t\u00f6nend entschl\u00fcpfete", "tokens": ["Sang", "die", "z\u00fcr\u00b7nen\u00b7de", "mir", ";", "t\u00f6\u00b7nend", "ent\u00b7schl\u00fcp\u00b7fe\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "PPER", "$.", "ADJD", "VVFIN"], "meter": "+-+---+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Mir die Laute, da ich drohend die Priesterin,", "tokens": ["Mir", "die", "Lau\u00b7te", ",", "da", "ich", "dro\u00b7hend", "die", "Pries\u00b7te\u00b7rin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,", "KOUS", "PPER", "VVPP", "ART", "NN", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Und mit fliegendem Haar sah,", "tokens": ["Und", "mit", "flie\u00b7gen\u00b7dem", "Haar", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und entscheidendem Ernst! sie sang:", "tokens": ["Und", "ent\u00b7schei\u00b7den\u00b7dem", "Ernst", "!", "sie", "sang", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$.", "PPER", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.26": {"line.1": {"text": "Lern des innersten Hains Ausspruch, und lehre den", "tokens": ["Lern", "des", "in\u00b7ners\u00b7ten", "Hains", "Aus\u00b7spruch", ",", "und", "leh\u00b7re", "den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "NN", "$,", "KON", "NN", "ART"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.2": {"text": "Jeden G\u00fcnstling der Kunst; oder ich nehme dir", "tokens": ["Je\u00b7den", "G\u00fcnst\u00b7ling", "der", "Kunst", ";", "o\u00b7der", "ich", "neh\u00b7me", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "ART", "NN", "$.", "KON", "PPER", "VVFIN", "PPER"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Deine Laute, zerreisse", "tokens": ["Dei\u00b7ne", "Lau\u00b7te", ",", "zer\u00b7reis\u00b7se"], "token_info": ["word", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Ihre Nerven, und hasse dich!", "tokens": ["Ih\u00b7re", "Ner\u00b7ven", ",", "und", "has\u00b7se", "dich", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "VVFIN", "PPER", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.27": {"line.1": {"text": "W\u00fcrdig war er, uns mehr, als dein begl\u00fccktester", "tokens": ["W\u00fcr\u00b7dig", "war", "er", ",", "uns", "mehr", ",", "als", "dein", "be\u00b7gl\u00fcck\u00b7tes\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "PPER", "ADV", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+--+-+-+--", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Freyheitshasser, o Rom, Octavian zu seyn!", "tokens": ["Frey\u00b7he\u00b7its\u00b7has\u00b7ser", ",", "o", "Rom", ",", "Oc\u00b7ta\u00b7vi\u00b7an", "zu", "seyn", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "FM", "NE", "$,", "NE", "PTKZU", "VAINF", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Mehr als Ludewig, den uns", "tokens": ["Mehr", "als", "Lu\u00b7de\u00b7wig", ",", "den", "uns"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "KOKOM", "NE", "$,", "PRELS", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sein Jahrhundert mit aufbewahrt:", "tokens": ["Sein", "Jahr\u00b7hun\u00b7dert", "mit", "auf\u00b7be\u00b7wahrt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "VVPP", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.28": {"line.1": {"text": "So verk\u00fcndigte ihn, als er noch J\u00fcngling war,", "tokens": ["So", "ver\u00b7k\u00fcn\u00b7dig\u00b7te", "ihn", ",", "als", "er", "noch", "J\u00fcng\u00b7ling", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "NN", "VAFIN", "$,"], "meter": "--+--++--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Sein aufsteigender Geist! Noch, da der Lorber ihm", "tokens": ["Sein", "auf\u00b7stei\u00b7gen\u00b7der", "Geist", "!", "Noch", ",", "da", "der", "Lor\u00b7ber", "ihm"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "ADV", "$,", "KOUS", "ART", "NN", "PPER"], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Schon vom Blute der Schlacht trof,", "tokens": ["Schon", "vom", "Blu\u00b7te", "der", "Schlacht", "trof", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und der Denker gepanzert ging,", "tokens": ["Und", "der", "Den\u00b7ker", "ge\u00b7pan\u00b7zert", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.29": {"line.1": {"text": "Floss der dichtrische Quell Friedrich entgegen, ihm", "tokens": ["Floss", "der", "dich\u00b7tri\u00b7sche", "Quell", "Fried\u00b7rich", "ent\u00b7ge\u00b7gen", ",", "ihm"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["NN", "ART", "ADJA", "NN", "NE", "PTKVZ", "$,", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Abzuwaschen die Schlacht! Aber er wandte sich,", "tokens": ["Ab\u00b7zu\u00b7wa\u00b7schen", "die", "Schlacht", "!", "A\u00b7ber", "er", "wand\u00b7te", "sich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$.", "KON", "PPER", "VVFIN", "PRF", "$,"], "meter": "+-+--+---+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Str\u00f6mt' in Haine, wohin ihm", "tokens": ["Str\u00f6mt'", "in", "Hai\u00b7ne", ",", "wo\u00b7hin", "ihm"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "APPR", "NE", "$,", "PWAV", "PPER"], "meter": "+-+-++-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Heinrichs S\u00e4nger nicht folgen wird!", "tokens": ["Hein\u00b7richs", "S\u00e4n\u00b7ger", "nicht", "fol\u00b7gen", "wird", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKNEG", "VVINF", "VAFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.30": {"line.1": {"text": "Sagts der Nachwelt nicht an, dass er nicht achtete,", "tokens": ["Sagts", "der", "Nach\u00b7welt", "nicht", "an", ",", "dass", "er", "nicht", "ach\u00b7te\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PTKNEG", "PTKVZ", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Was er werth war, zu seyn! Aber sie h\u00f6rt es doch:", "tokens": ["Was", "er", "werth", "war", ",", "zu", "seyn", "!", "A\u00b7ber", "sie", "h\u00f6rt", "es", "doch", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VAFIN", "$,", "PTKZU", "VAINF", "$.", "KON", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sagts ihr traurig, und fordert", "tokens": ["Sagts", "ihr", "trau\u00b7rig", ",", "und", "for\u00b7dert"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "KON", "VVFIN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Ihre S\u00f6hne zu Richtern auf!", "tokens": ["Ih\u00b7re", "S\u00f6h\u00b7ne", "zu", "Rich\u00b7tern", "auf", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}