{"textgrid.poem.66660": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "1L: Was will der Geist? Wie wechselt das Betrachten!", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was will der Geist? Wie wechselt das Betrachten!", "tokens": ["Was", "will", "der", "Geist", "?", "Wie", "wech\u00b7selt", "das", "Be\u00b7trach\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "$.", "PWAV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zehn J\u00e4hrchen mehr \u2013 wir scheinen wie vertauscht.", "tokens": ["Zehn", "J\u00e4hr\u00b7chen", "mehr", "\u2013", "wir", "schei\u00b7nen", "wie", "ver\u00b7tauscht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "$(", "PPER", "VVFIN", "KOKOM", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Was hei\u00dfes Draufgehn in der Jugend Schlachten,", "tokens": ["Was", "hei\u00b7\u00dfes", "Drauf\u00b7gehn", "in", "der", "Ju\u00b7gend", "Schlach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ist wie vergangne Form des Seins verrauscht.", "tokens": ["Ist", "wie", "ver\u00b7gang\u00b7ne", "Form", "des", "Seins", "ver\u00b7rauscht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch nur der Lump wird, was er war, verachten,", "tokens": ["Doch", "nur", "der", "Lump", "wird", ",", "was", "er", "war", ",", "ver\u00b7ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "$,", "PWS", "PPER", "VAFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Zu Parven\u00fcs sind wir nicht aufgebauscht,", "tokens": ["Zu", "Par\u00b7ve\u00b7n\u00fcs", "sind", "wir", "nicht", "auf\u00b7ge\u00b7bauscht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wenn wir andern Schnitt des Geistes tragen,", "tokens": ["Und", "wenn", "wir", "an\u00b7dern", "Schnitt", "des", "Geis\u00b7tes", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Verschm\u00e4hn wir's doch, uns auf die Brust zu schlagen.", "tokens": ["Ver\u00b7schm\u00e4hn", "wir's", "doch", ",", "uns", "auf", "die", "Brust", "zu", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "$,", "PPER", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wir haben einst den Mund recht voll genommen,", "tokens": ["Wir", "ha\u00b7ben", "einst", "den", "Mund", "recht", "voll", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Herz von Riesenhoffnungen geschwellt,", "tokens": ["Das", "Herz", "von", "Rie\u00b7sen\u00b7hoff\u00b7nun\u00b7gen", "ge\u00b7schwellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Jetzt sind wir langsam auf den Punkt gekommen,", "tokens": ["Jetzt", "sind", "wir", "lang\u00b7sam", "auf", "den", "Punkt", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wo sich die Seele zu der Stunde stellt.", "tokens": ["Wo", "sich", "die", "See\u00b7le", "zu", "der", "Stun\u00b7de", "stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Was kann denn auch die sch\u00f6nste Zukunft frommen,", "tokens": ["Was", "kann", "denn", "auch", "die", "sch\u00f6ns\u00b7te", "Zu\u00b7kunft", "from\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "ADV", "ART", "ADJA", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wenn des Momentes Zauberkelch zerschellt?", "tokens": ["Wenn", "des", "Mo\u00b7men\u00b7tes", "Zau\u00b7ber\u00b7kelch", "zer\u00b7schellt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Wir klammern uns nicht mehr an k\u00fcnftige Zeiten,", "tokens": ["Wir", "klam\u00b7mern", "uns", "nicht", "mehr", "an", "k\u00fcnf\u00b7ti\u00b7ge", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "Der n\u00e4chste Augenblick birgt Ewigkeiten.", "tokens": ["Der", "n\u00e4chs\u00b7te", "Au\u00b7gen\u00b7blick", "birgt", "E\u00b7wig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Bescheidner sind wir und sind anspruchsvoller,", "tokens": ["Be\u00b7scheid\u00b7ner", "sind", "wir", "und", "sind", "an\u00b7spruchs\u00b7vol\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "KON", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Man kann es nehmen, wie man eben will,", "tokens": ["Man", "kann", "es", "neh\u00b7men", ",", "wie", "man", "e\u00b7ben", "will", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,", "PWAV", "PIS", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wenn wir verzichten auf den Zukunftskoller,", "tokens": ["Wenn", "wir", "ver\u00b7zich\u00b7ten", "auf", "den", "Zu\u00b7kunfts\u00b7kol\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zum Heute schweigen wir darum nicht still.", "tokens": ["Zum", "Heu\u00b7te", "schwei\u00b7gen", "wir", "da\u00b7rum", "nicht", "still", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PAV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Kein souver\u00e4nes Volk, kein Hohenzoller,", "tokens": ["Kein", "sou\u00b7ve\u00b7r\u00e4\u00b7nes", "Volk", ",", "kein", "Ho\u00b7hen\u00b7zol\u00b7ler", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Kein Geldtyrann schickt uns in den April,", "tokens": ["Kein", "Geld\u00b7ty\u00b7rann", "schickt", "uns", "in", "den", "Ap\u00b7ril", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Da\u00df wir statt gro\u00dfer Menschen, echter Weisen", "tokens": ["Da\u00df", "wir", "statt", "gro\u00b7\u00dfer", "Men\u00b7schen", ",", "ech\u00b7ter", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sie als der Menschheit h\u00f6chste Helden preisen.", "tokens": ["Sie", "als", "der", "Menschheit", "h\u00f6chs\u00b7te", "Hel\u00b7den", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Man wird den Herren nicht zu nahe treten,", "tokens": ["Man", "wird", "den", "Her\u00b7ren", "nicht", "zu", "na\u00b7he", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "PTKNEG", "PTKA", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die sich direkt von Gott ihr Wams beziehn,", "tokens": ["Die", "sich", "di\u00b7rekt", "von", "Gott", "ihr", "Wams", "be\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADJD", "APPR", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gef\u00e4llt's uns nicht, dem\u00fctig anzubeten", "tokens": ["Ge\u00b7f\u00e4llt's", "uns", "nicht", ",", "de\u00b7m\u00fc\u00b7tig", "an\u00b7zu\u00b7be\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "PPER", "PTKNEG", "$,", "ADJD", "VVIZU"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und vor den W\u00fcrdewundern hinzuknien,", "tokens": ["Und", "vor", "den", "W\u00fcr\u00b7de\u00b7wun\u00b7dern", "hin\u00b7zu\u00b7kni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die sich ", "tokens": ["Die", "sich"], "token_info": ["word", "word"], "pos": ["ART", "PRF"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Die \u00bbWelt\u00abgeschichte \u2013 seit die Sonne schien,", "tokens": ["Die", "\u00bb", "Welt", "\u00ab", "ge\u00b7schich\u00b7te", "\u2013", "seit", "die", "Son\u00b7ne", "schien", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "NN", "$(", "VVFIN", "$(", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ist alles auf die Gro\u00dfmark zugeschnitten,", "tokens": ["Ist", "al\u00b7les", "auf", "die", "Gro\u00df\u00b7mark", "zu\u00b7ge\u00b7schnit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Selbst Goethes Glaubensgeist wird vorgeritten.", "tokens": ["Selbst", "Goe\u00b7thes", "Glau\u00b7bens\u00b7geist", "wird", "vor\u00b7ge\u00b7rit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Wer n\u00f6rgelt denn, wenn sie ihr M\u00fctchen k\u00fchlen?", "tokens": ["Wer", "n\u00f6r\u00b7gelt", "denn", ",", "wenn", "sie", "ihr", "M\u00fct\u00b7chen", "k\u00fch\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der P\u00f6bel will's \u2013 ihn blendet der Popanz.", "tokens": ["Der", "P\u00f6\u00b7bel", "will's", "\u2013", "ihn", "blen\u00b7det", "der", "Po\u00b7panz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "$(", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Hermelin mu\u00df sakrosankt sich f\u00fchlen,", "tokens": ["Der", "Her\u00b7me\u00b7lin", "mu\u00df", "sak\u00b7ro\u00b7sankt", "sich", "f\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Verketzert man das Wort des freien Manns.", "tokens": ["Ver\u00b7ket\u00b7zert", "man", "das", "Wort", "des", "frei\u00b7en", "Manns", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Herrscht \u00bbunbedingtes\u00ab Recht auf Richterst\u00fchlen?", "tokens": ["Herrscht", "\u00bb", "un\u00b7be\u00b7ding\u00b7tes", "\u00ab", "Recht", "auf", "Rich\u00b7ter\u00b7st\u00fch\u00b7len", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJA", "$(", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die Monarchie zeigt ihren Hexenschwanz.", "tokens": ["Die", "Mon\u00b7ar\u00b7chie", "zeigt", "ih\u00b7ren", "He\u00b7xen\u00b7schwanz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Tr\u00e4uft ihr noch Gift in deutscher Treue Becher,", "tokens": ["Tr\u00e4uft", "ihr", "noch", "Gift", "in", "deut\u00b7scher", "Treu\u00b7e", "Be\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NN", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wird selbst ein Engel Majest\u00e4tsverbrecher.", "tokens": ["Wird", "selbst", "ein", "En\u00b7gel", "Ma\u00b7jes\u00b7t\u00e4ts\u00b7ver\u00b7bre\u00b7cher", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Man will kein Schattenkaiser sein \u2013 versteht sich!", "tokens": ["Man", "will", "kein", "Schat\u00b7ten\u00b7kai\u00b7ser", "sein", "\u2013", "ver\u00b7steht", "sich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PIAT", "NN", "VAINF", "$(", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von hundert Vetos kreuz und quer bedingt.", "tokens": ["Von", "hun\u00b7dert", "Ve\u00b7tos", "kreuz", "und", "quer", "be\u00b7dingt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "NN", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Will Sonne sein \u2013 die Nebelmasse dreht sich", "tokens": ["Will", "Son\u00b7ne", "sein", "\u2013", "die", "Ne\u00b7bel\u00b7mas\u00b7se", "dreht", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "NN", "VAINF", "$(", "ART", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Trabantenhaft, wenn man sich t\u00fcchtig schwingt.", "tokens": ["Tra\u00b7ban\u00b7ten\u00b7haft", ",", "wenn", "man", "sich", "t\u00fcch\u00b7tig", "schwingt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PIS", "PRF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Man ist sein Komponist und selbst Poet sich,", "tokens": ["Man", "ist", "sein", "Kom\u00b7po\u00b7nist", "und", "selbst", "Po\u00b7et", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPOSAT", "NN", "KON", "ADV", "NN", "PRF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nach dessen Wort und Weise ", "tokens": ["Nach", "des\u00b7sen", "Wort", "und", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sch\u00f6n war Byzanz! Wilhelm der Absolute!", "tokens": ["Sch\u00f6n", "war", "By\u00b7zanz", "!", "Wil\u00b7helm", "der", "Ab\u00b7so\u00b7lu\u00b7te", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NE", "$.", "NE", "ART", "NN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.8": {"text": "Mir wird ganz mittelalterlich zumute.", "tokens": ["Mir", "wird", "ganz", "mit\u00b7tel\u00b7al\u00b7ter\u00b7lich", "zu\u00b7mu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Wo glorreich weithin glei\u00dft ihr falsches Licht,", "tokens": ["Wo", "glor\u00b7reich", "weit\u00b7hin", "glei\u00dft", "ihr", "fal\u00b7sches", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie kann in jedem Zuckerb\u00e4cker wohnen,", "tokens": ["Sie", "kann", "in", "je\u00b7dem", "Zu\u00b7cker\u00b7b\u00e4\u00b7cker", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der seine s\u00fc\u00dfe W\u00fcrde heilig spricht.", "tokens": ["Der", "sei\u00b7ne", "s\u00fc\u00b7\u00dfe", "W\u00fcr\u00b7de", "hei\u00b7lig", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Fakire, Dichter wird sie kaum verschonen,", "tokens": ["Fa\u00b7ki\u00b7re", ",", "Dich\u00b7ter", "wird", "sie", "kaum", "ver\u00b7scho\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "Der Gr\u00f6\u00dfenwahn fragt nach dem Stammbaum nicht,", "tokens": ["Der", "Gr\u00f6\u00b7\u00dfen\u00b7wahn", "fragt", "nach", "dem", "Stamm\u00b7baum", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Als Schwester soll mit allen ihren Reizen", "tokens": ["Als", "Schwes\u00b7ter", "soll", "mit", "al\u00b7len", "ih\u00b7ren", "Rei\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "VMFIN", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die Arroganz sich auf dem Geldsack spreizen.", "tokens": ["Die", "Ar\u00b7ro\u00b7ganz", "sich", "auf", "dem", "Geld\u00b7sack", "sprei\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Wir waren gr\u00fcn, als wir die Spie\u00dfe rannten", "tokens": ["Wir", "wa\u00b7ren", "gr\u00fcn", ",", "als", "wir", "die", "Spie\u00b7\u00dfe", "rann\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf alles, was des Blutes Puls emp\u00f6rt,", "tokens": ["Auf", "al\u00b7les", ",", "was", "des", "Blu\u00b7tes", "Puls", "em\u00b7p\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PRELS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wenn uns des Unrechts Qualen \u00fcbermannten,", "tokens": ["Wenn", "uns", "des", "Un\u00b7rechts", "Qua\u00b7len", "\u00fc\u00b7berm\u00b7ann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir glaubten fest, da\u00df uns der Sieg geh\u00f6rt.", "tokens": ["Wir", "glaub\u00b7ten", "fest", ",", "da\u00df", "uns", "der", "Sieg", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nie werden lieben wir die alten Tanten,", "tokens": ["Nie", "wer\u00b7den", "lie\u00b7ben", "wir", "die", "al\u00b7ten", "Tan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAINF", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die nichts in ihrem Mittagsschl\u00e4fchen st\u00f6rt \u2013", "tokens": ["Die", "nichts", "in", "ih\u00b7rem", "Mit\u00b7tags\u00b7schl\u00e4f\u00b7chen", "st\u00f6rt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Doch da\u00df wir reifer werden, das gewahren", "tokens": ["Doch", "da\u00df", "wir", "rei\u00b7fer", "wer\u00b7den", ",", "das", "ge\u00b7wah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VAINF", "$,", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wir an der Weisheit, die wir schwer erfahren.", "tokens": ["Wir", "an", "der", "Weis\u00b7heit", ",", "die", "wir", "schwer", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Und ist Erkenntnis \u00fcber uns gekommen,", "tokens": ["Und", "ist", "Er\u00b7kennt\u00b7nis", "\u00fc\u00b7ber", "uns", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df Satan allem Weltlauf immanent,", "tokens": ["Da\u00df", "Sa\u00b7tan", "al\u00b7lem", "Welt\u00b7lauf", "im\u00b7ma\u00b7nent", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PIS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df wei\u00dfe Raben sind die wahren Frommen,", "tokens": ["Da\u00df", "wei\u00b7\u00dfe", "Ra\u00b7ben", "sind", "die", "wah\u00b7ren", "From\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die man am reinen Herzen nur erkennt,", "tokens": ["Die", "man", "am", "rei\u00b7nen", "Her\u00b7zen", "nur", "er\u00b7kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPRART", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und da\u00df der Schwindel eher zugenommen,", "tokens": ["Und", "da\u00df", "der", "Schwin\u00b7del", "e\u00b7her", "zu\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Als da\u00df er weicht dem lautern Element,", "tokens": ["Als", "da\u00df", "er", "weicht", "dem", "lau\u00b7tern", "E\u00b7le\u00b7ment", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Dann wird man, ging man vorher nicht ins Wasser,", "tokens": ["Dann", "wird", "man", ",", "ging", "man", "vor\u00b7her", "nicht", "ins", "Was\u00b7ser", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "$,", "VVFIN", "PIS", "ADV", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Gelassener, wenn auch kein Gehenlasser.", "tokens": ["Ge\u00b7las\u00b7se\u00b7ner", ",", "wenn", "auch", "kein", "Ge\u00b7hen\u00b7las\u00b7ser", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ADV", "PIAT", "NN", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}}, "stanza.10": {"line.1": {"text": "Was will der Geist? Wie wechselt das Betrachten!", "tokens": ["Was", "will", "der", "Geist", "?", "Wie", "wech\u00b7selt", "das", "Be\u00b7trach\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "$.", "PWAV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zehn J\u00e4hrchen mehr \u2013 wir scheinen wie vertauscht.", "tokens": ["Zehn", "J\u00e4hr\u00b7chen", "mehr", "\u2013", "wir", "schei\u00b7nen", "wie", "ver\u00b7tauscht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "$(", "PPER", "VVFIN", "KOKOM", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Was hei\u00dfes Draufgehn in der Jugend Schlachten,", "tokens": ["Was", "hei\u00b7\u00dfes", "Drauf\u00b7gehn", "in", "der", "Ju\u00b7gend", "Schlach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ist wie vergangne Form des Seins verrauscht.", "tokens": ["Ist", "wie", "ver\u00b7gang\u00b7ne", "Form", "des", "Seins", "ver\u00b7rauscht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch nur der Lump wird, was er war, verachten,", "tokens": ["Doch", "nur", "der", "Lump", "wird", ",", "was", "er", "war", ",", "ver\u00b7ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "$,", "PWS", "PPER", "VAFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Zu Parven\u00fcs sind wir nicht aufgebauscht,", "tokens": ["Zu", "Par\u00b7ve\u00b7n\u00fcs", "sind", "wir", "nicht", "auf\u00b7ge\u00b7bauscht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wenn wir andern Schnitt des Geistes tragen,", "tokens": ["Und", "wenn", "wir", "an\u00b7dern", "Schnitt", "des", "Geis\u00b7tes", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Verschm\u00e4hn wir's doch, uns auf die Brust zu schlagen.", "tokens": ["Ver\u00b7schm\u00e4hn", "wir's", "doch", ",", "uns", "auf", "die", "Brust", "zu", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "$,", "PPER", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Wir haben einst den Mund recht voll genommen,", "tokens": ["Wir", "ha\u00b7ben", "einst", "den", "Mund", "recht", "voll", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Herz von Riesenhoffnungen geschwellt,", "tokens": ["Das", "Herz", "von", "Rie\u00b7sen\u00b7hoff\u00b7nun\u00b7gen", "ge\u00b7schwellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Jetzt sind wir langsam auf den Punkt gekommen,", "tokens": ["Jetzt", "sind", "wir", "lang\u00b7sam", "auf", "den", "Punkt", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wo sich die Seele zu der Stunde stellt.", "tokens": ["Wo", "sich", "die", "See\u00b7le", "zu", "der", "Stun\u00b7de", "stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Was kann denn auch die sch\u00f6nste Zukunft frommen,", "tokens": ["Was", "kann", "denn", "auch", "die", "sch\u00f6ns\u00b7te", "Zu\u00b7kunft", "from\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "ADV", "ART", "ADJA", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wenn des Momentes Zauberkelch zerschellt?", "tokens": ["Wenn", "des", "Mo\u00b7men\u00b7tes", "Zau\u00b7ber\u00b7kelch", "zer\u00b7schellt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Wir klammern uns nicht mehr an k\u00fcnftige Zeiten,", "tokens": ["Wir", "klam\u00b7mern", "uns", "nicht", "mehr", "an", "k\u00fcnf\u00b7ti\u00b7ge", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "Der n\u00e4chste Augenblick birgt Ewigkeiten.", "tokens": ["Der", "n\u00e4chs\u00b7te", "Au\u00b7gen\u00b7blick", "birgt", "E\u00b7wig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Bescheidner sind wir und sind anspruchsvoller,", "tokens": ["Be\u00b7scheid\u00b7ner", "sind", "wir", "und", "sind", "an\u00b7spruchs\u00b7vol\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "KON", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Man kann es nehmen, wie man eben will,", "tokens": ["Man", "kann", "es", "neh\u00b7men", ",", "wie", "man", "e\u00b7ben", "will", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,", "PWAV", "PIS", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wenn wir verzichten auf den Zukunftskoller,", "tokens": ["Wenn", "wir", "ver\u00b7zich\u00b7ten", "auf", "den", "Zu\u00b7kunfts\u00b7kol\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zum Heute schweigen wir darum nicht still.", "tokens": ["Zum", "Heu\u00b7te", "schwei\u00b7gen", "wir", "da\u00b7rum", "nicht", "still", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PAV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Kein souver\u00e4nes Volk, kein Hohenzoller,", "tokens": ["Kein", "sou\u00b7ve\u00b7r\u00e4\u00b7nes", "Volk", ",", "kein", "Ho\u00b7hen\u00b7zol\u00b7ler", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Kein Geldtyrann schickt uns in den April,", "tokens": ["Kein", "Geld\u00b7ty\u00b7rann", "schickt", "uns", "in", "den", "Ap\u00b7ril", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Da\u00df wir statt gro\u00dfer Menschen, echter Weisen", "tokens": ["Da\u00df", "wir", "statt", "gro\u00b7\u00dfer", "Men\u00b7schen", ",", "ech\u00b7ter", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sie als der Menschheit h\u00f6chste Helden preisen.", "tokens": ["Sie", "als", "der", "Menschheit", "h\u00f6chs\u00b7te", "Hel\u00b7den", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Man wird den Herren nicht zu nahe treten,", "tokens": ["Man", "wird", "den", "Her\u00b7ren", "nicht", "zu", "na\u00b7he", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "PTKNEG", "PTKA", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die sich direkt von Gott ihr Wams beziehn,", "tokens": ["Die", "sich", "di\u00b7rekt", "von", "Gott", "ihr", "Wams", "be\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADJD", "APPR", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gef\u00e4llt's uns nicht, dem\u00fctig anzubeten", "tokens": ["Ge\u00b7f\u00e4llt's", "uns", "nicht", ",", "de\u00b7m\u00fc\u00b7tig", "an\u00b7zu\u00b7be\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "PPER", "PTKNEG", "$,", "ADJD", "VVIZU"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und vor den W\u00fcrdewundern hinzuknien,", "tokens": ["Und", "vor", "den", "W\u00fcr\u00b7de\u00b7wun\u00b7dern", "hin\u00b7zu\u00b7kni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die sich ", "tokens": ["Die", "sich"], "token_info": ["word", "word"], "pos": ["ART", "PRF"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Die \u00bbWelt\u00abgeschichte \u2013 seit die Sonne schien,", "tokens": ["Die", "\u00bb", "Welt", "\u00ab", "ge\u00b7schich\u00b7te", "\u2013", "seit", "die", "Son\u00b7ne", "schien", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "NN", "$(", "VVFIN", "$(", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ist alles auf die Gro\u00dfmark zugeschnitten,", "tokens": ["Ist", "al\u00b7les", "auf", "die", "Gro\u00df\u00b7mark", "zu\u00b7ge\u00b7schnit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Selbst Goethes Glaubensgeist wird vorgeritten.", "tokens": ["Selbst", "Goe\u00b7thes", "Glau\u00b7bens\u00b7geist", "wird", "vor\u00b7ge\u00b7rit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Wer n\u00f6rgelt denn, wenn sie ihr M\u00fctchen k\u00fchlen?", "tokens": ["Wer", "n\u00f6r\u00b7gelt", "denn", ",", "wenn", "sie", "ihr", "M\u00fct\u00b7chen", "k\u00fch\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der P\u00f6bel will's \u2013 ihn blendet der Popanz.", "tokens": ["Der", "P\u00f6\u00b7bel", "will's", "\u2013", "ihn", "blen\u00b7det", "der", "Po\u00b7panz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "$(", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Hermelin mu\u00df sakrosankt sich f\u00fchlen,", "tokens": ["Der", "Her\u00b7me\u00b7lin", "mu\u00df", "sak\u00b7ro\u00b7sankt", "sich", "f\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Verketzert man das Wort des freien Manns.", "tokens": ["Ver\u00b7ket\u00b7zert", "man", "das", "Wort", "des", "frei\u00b7en", "Manns", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Herrscht \u00bbunbedingtes\u00ab Recht auf Richterst\u00fchlen?", "tokens": ["Herrscht", "\u00bb", "un\u00b7be\u00b7ding\u00b7tes", "\u00ab", "Recht", "auf", "Rich\u00b7ter\u00b7st\u00fch\u00b7len", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJA", "$(", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die Monarchie zeigt ihren Hexenschwanz.", "tokens": ["Die", "Mon\u00b7ar\u00b7chie", "zeigt", "ih\u00b7ren", "He\u00b7xen\u00b7schwanz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Tr\u00e4uft ihr noch Gift in deutscher Treue Becher,", "tokens": ["Tr\u00e4uft", "ihr", "noch", "Gift", "in", "deut\u00b7scher", "Treu\u00b7e", "Be\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NN", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wird selbst ein Engel Majest\u00e4tsverbrecher.", "tokens": ["Wird", "selbst", "ein", "En\u00b7gel", "Ma\u00b7jes\u00b7t\u00e4ts\u00b7ver\u00b7bre\u00b7cher", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Man will kein Schattenkaiser sein \u2013 versteht sich!", "tokens": ["Man", "will", "kein", "Schat\u00b7ten\u00b7kai\u00b7ser", "sein", "\u2013", "ver\u00b7steht", "sich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PIAT", "NN", "VAINF", "$(", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von hundert Vetos kreuz und quer bedingt.", "tokens": ["Von", "hun\u00b7dert", "Ve\u00b7tos", "kreuz", "und", "quer", "be\u00b7dingt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "NN", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Will Sonne sein \u2013 die Nebelmasse dreht sich", "tokens": ["Will", "Son\u00b7ne", "sein", "\u2013", "die", "Ne\u00b7bel\u00b7mas\u00b7se", "dreht", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "NN", "VAINF", "$(", "ART", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Trabantenhaft, wenn man sich t\u00fcchtig schwingt.", "tokens": ["Tra\u00b7ban\u00b7ten\u00b7haft", ",", "wenn", "man", "sich", "t\u00fcch\u00b7tig", "schwingt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PIS", "PRF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Man ist sein Komponist und selbst Poet sich,", "tokens": ["Man", "ist", "sein", "Kom\u00b7po\u00b7nist", "und", "selbst", "Po\u00b7et", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPOSAT", "NN", "KON", "ADV", "NN", "PRF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nach dessen Wort und Weise ", "tokens": ["Nach", "des\u00b7sen", "Wort", "und", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sch\u00f6n war Byzanz! Wilhelm der Absolute!", "tokens": ["Sch\u00f6n", "war", "By\u00b7zanz", "!", "Wil\u00b7helm", "der", "Ab\u00b7so\u00b7lu\u00b7te", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NE", "$.", "NE", "ART", "NN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.8": {"text": "Mir wird ganz mittelalterlich zumute.", "tokens": ["Mir", "wird", "ganz", "mit\u00b7tel\u00b7al\u00b7ter\u00b7lich", "zu\u00b7mu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Wo glorreich weithin glei\u00dft ihr falsches Licht,", "tokens": ["Wo", "glor\u00b7reich", "weit\u00b7hin", "glei\u00dft", "ihr", "fal\u00b7sches", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie kann in jedem Zuckerb\u00e4cker wohnen,", "tokens": ["Sie", "kann", "in", "je\u00b7dem", "Zu\u00b7cker\u00b7b\u00e4\u00b7cker", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der seine s\u00fc\u00dfe W\u00fcrde heilig spricht.", "tokens": ["Der", "sei\u00b7ne", "s\u00fc\u00b7\u00dfe", "W\u00fcr\u00b7de", "hei\u00b7lig", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Fakire, Dichter wird sie kaum verschonen,", "tokens": ["Fa\u00b7ki\u00b7re", ",", "Dich\u00b7ter", "wird", "sie", "kaum", "ver\u00b7scho\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "Der Gr\u00f6\u00dfenwahn fragt nach dem Stammbaum nicht,", "tokens": ["Der", "Gr\u00f6\u00b7\u00dfen\u00b7wahn", "fragt", "nach", "dem", "Stamm\u00b7baum", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Als Schwester soll mit allen ihren Reizen", "tokens": ["Als", "Schwes\u00b7ter", "soll", "mit", "al\u00b7len", "ih\u00b7ren", "Rei\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "VMFIN", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die Arroganz sich auf dem Geldsack spreizen.", "tokens": ["Die", "Ar\u00b7ro\u00b7ganz", "sich", "auf", "dem", "Geld\u00b7sack", "sprei\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Wir waren gr\u00fcn, als wir die Spie\u00dfe rannten", "tokens": ["Wir", "wa\u00b7ren", "gr\u00fcn", ",", "als", "wir", "die", "Spie\u00b7\u00dfe", "rann\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf alles, was des Blutes Puls emp\u00f6rt,", "tokens": ["Auf", "al\u00b7les", ",", "was", "des", "Blu\u00b7tes", "Puls", "em\u00b7p\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PRELS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wenn uns des Unrechts Qualen \u00fcbermannten,", "tokens": ["Wenn", "uns", "des", "Un\u00b7rechts", "Qua\u00b7len", "\u00fc\u00b7berm\u00b7ann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir glaubten fest, da\u00df uns der Sieg geh\u00f6rt.", "tokens": ["Wir", "glaub\u00b7ten", "fest", ",", "da\u00df", "uns", "der", "Sieg", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nie werden lieben wir die alten Tanten,", "tokens": ["Nie", "wer\u00b7den", "lie\u00b7ben", "wir", "die", "al\u00b7ten", "Tan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAINF", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die nichts in ihrem Mittagsschl\u00e4fchen st\u00f6rt \u2013", "tokens": ["Die", "nichts", "in", "ih\u00b7rem", "Mit\u00b7tags\u00b7schl\u00e4f\u00b7chen", "st\u00f6rt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Doch da\u00df wir reifer werden, das gewahren", "tokens": ["Doch", "da\u00df", "wir", "rei\u00b7fer", "wer\u00b7den", ",", "das", "ge\u00b7wah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VAINF", "$,", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wir an der Weisheit, die wir schwer erfahren.", "tokens": ["Wir", "an", "der", "Weis\u00b7heit", ",", "die", "wir", "schwer", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Und ist Erkenntnis \u00fcber uns gekommen,", "tokens": ["Und", "ist", "Er\u00b7kennt\u00b7nis", "\u00fc\u00b7ber", "uns", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df Satan allem Weltlauf immanent,", "tokens": ["Da\u00df", "Sa\u00b7tan", "al\u00b7lem", "Welt\u00b7lauf", "im\u00b7ma\u00b7nent", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PIS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df wei\u00dfe Raben sind die wahren Frommen,", "tokens": ["Da\u00df", "wei\u00b7\u00dfe", "Ra\u00b7ben", "sind", "die", "wah\u00b7ren", "From\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die man am reinen Herzen nur erkennt,", "tokens": ["Die", "man", "am", "rei\u00b7nen", "Her\u00b7zen", "nur", "er\u00b7kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPRART", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und da\u00df der Schwindel eher zugenommen,", "tokens": ["Und", "da\u00df", "der", "Schwin\u00b7del", "e\u00b7her", "zu\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Als da\u00df er weicht dem lautern Element,", "tokens": ["Als", "da\u00df", "er", "weicht", "dem", "lau\u00b7tern", "E\u00b7le\u00b7ment", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Dann wird man, ging man vorher nicht ins Wasser,", "tokens": ["Dann", "wird", "man", ",", "ging", "man", "vor\u00b7her", "nicht", "ins", "Was\u00b7ser", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "$,", "VVFIN", "PIS", "ADV", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Gelassener, wenn auch kein Gehenlasser.", "tokens": ["Ge\u00b7las\u00b7se\u00b7ner", ",", "wenn", "auch", "kein", "Ge\u00b7hen\u00b7las\u00b7ser", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ADV", "PIAT", "NN", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}}}}}