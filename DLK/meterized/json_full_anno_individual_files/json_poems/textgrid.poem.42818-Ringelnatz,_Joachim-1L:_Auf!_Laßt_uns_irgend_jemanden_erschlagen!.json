{"textgrid.poem.42818": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: Auf! La\u00dft uns irgend jemanden erschlagen!", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf! La\u00dft uns irgend jemanden erschlagen!", "tokens": ["Auf", "!", "La\u00dft", "uns", "ir\u00b7gend", "je\u00b7man\u00b7den", "er\u00b7schla\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVIMP", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie fragen: Wen?", "tokens": ["Sie", "fra\u00b7gen", ":", "Wen", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVINF", "$.", "PWS", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Wie feig schon, \u00fcberhaupt zu fragen.", "tokens": ["Wie", "feig", "schon", ",", "\u00fc\u00b7ber\u00b7haupt", "zu", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADV", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Halt irgendwen, den oder den.", "tokens": ["Halt", "ir\u00b7gend\u00b7wen", ",", "den", "o\u00b7der", "den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$,", "ART", "KON", "ART", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "So irgend jemand mitten aus der Mitte", "tokens": ["So", "ir\u00b7gend", "je\u00b7mand", "mit\u00b7ten", "aus", "der", "Mit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Urpl\u00f6tzlich t\u00f6ten, hei, wie das belebt!", "tokens": ["Ur\u00b7pl\u00f6tz\u00b7lich", "t\u00f6\u00b7ten", ",", "hei", ",", "wie", "das", "be\u00b7lebt", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,", "ITJ", "$,", "PWAV", "PDS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Weil's Aufsehn macht.", "tokens": ["Weil's", "Auf\u00b7sehn", "macht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Denn T\u00f6ten ist nicht Sitte,", "tokens": ["Denn", "T\u00f6\u00b7ten", "ist", "nicht", "Sit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sondern ein Sport, vor dem die Mehrheit bebt.", "tokens": ["Son\u00b7dern", "ein", "Sport", ",", "vor", "dem", "die", "Mehr\u00b7heit", "bebt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "APPR", "ART", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.3": {"line.1": {"text": "Nicht solche t\u00f6ten, die uns Grund gegeben,", "tokens": ["Nicht", "sol\u00b7che", "t\u00f6\u00b7ten", ",", "die", "uns", "Grund", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "ADJA", "$,", "PRELS", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Noch etwa Greise oder Weib und Kind,", "tokens": ["Noch", "et\u00b7wa", "Grei\u00b7se", "o\u00b7der", "Weib", "und", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auch la\u00dft uns T\u00f6ter gegenseitig leben,", "tokens": ["Auch", "la\u00dft", "uns", "T\u00f6\u00b7ter", "ge\u00b7gen\u00b7sei\u00b7tig", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil wir doch schlie\u00dflich keine Henker sind.", "tokens": ["Weil", "wir", "doch", "schlie\u00df\u00b7lich", "kei\u00b7ne", "Hen\u00b7ker", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Was \u00fcber achtzig Jahr und unter zehn", "tokens": ["Was", "\u00fc\u00b7ber", "acht\u00b7zig", "Jahr", "und", "un\u00b7ter", "zehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "CARD", "NN", "KON", "APPR", "CARD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Jahr ist, sind faule, unbrauchbare Drohnen.", "tokens": ["Jahr", "ist", ",", "sind", "fau\u00b7le", ",", "un\u00b7brauch\u00b7ba\u00b7re", "Droh\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "VAFIN", "NE", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Den andern aber mu\u00df man zugestehn,", "tokens": ["Den", "an\u00b7dern", "a\u00b7ber", "mu\u00df", "man", "zu\u00b7ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df sie was leisten, und die la\u00dft uns schonen.", "tokens": ["Da\u00df", "sie", "was", "leis\u00b7ten", ",", "und", "die", "la\u00dft", "uns", "scho\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVINF", "$,", "KON", "ART", "VVIMP", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Auf! La\u00dft uns all mitnander Ei-ei machen!", "tokens": ["Auf", "!", "La\u00dft", "uns", "all", "mit\u00b7nan\u00b7der", "Ei\u00b7ei", "ma\u00b7chen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVIMP", "PPER", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf! Fistet Pazi und seid friedlich froh!", "tokens": ["Auf", "!", "Fis\u00b7tet", "Pa\u00b7zi", "und", "seid", "fried\u00b7lich", "froh", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "NE", "NE", "KON", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verklebt aus Liebe unter heitrem Lachen", "tokens": ["Ver\u00b7klebt", "aus", "Lie\u00b7be", "un\u00b7ter", "heit\u00b7rem", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit Bruderku\u00df den feindlichsten Popo.", "tokens": ["Mit", "Bru\u00b7der\u00b7ku\u00df", "den", "feind\u00b7lichs\u00b7ten", "Po\u00b7po", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Krieg, Ha\u00df und Neid und alle widrigen", "tokens": ["Krieg", ",", "Ha\u00df", "und", "Neid", "und", "al\u00b7le", "wid\u00b7ri\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Gef\u00fchle fort! Dem Herzen gebt Geh\u00f6r!", "tokens": ["Ge\u00b7f\u00fch\u00b7le", "fort", "!", "Dem", "Her\u00b7zen", "gebt", "Ge\u00b7h\u00f6r", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir wollen uns freiwillig selbst erniedrigen.", "tokens": ["Wir", "wol\u00b7len", "uns", "frei\u00b7wil\u00b7lig", "selbst", "er\u00b7nied\u00b7ri\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wer uns anspeit, sei uns Parfumeur.", "tokens": ["Und", "wer", "uns", "an\u00b7speit", ",", "sei", "uns", "Par\u00b7fu\u00b7meur", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "NN", "$,", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Ein Reich zu gr\u00fcnden und daf\u00fcr zu werben", "tokens": ["Ein", "Reich", "zu", "gr\u00fcn\u00b7den", "und", "da\u00b7f\u00fcr", "zu", "wer\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "KON", "PAV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gilt es, das ganz und gar dem Himmel gleicht.", "tokens": ["Gilt", "es", ",", "das", "ganz", "und", "gar", "dem", "Him\u00b7mel", "gleicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "ADV", "KON", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Seid \u00fcberzeugt: Wir werden dr\u00fcber sterben.", "tokens": ["Seid", "\u00fc\u00b7berz\u00b7eugt", ":", "Wir", "wer\u00b7den", "dr\u00fc\u00b7ber", "ster\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "VVPP", "$.", "PPER", "VAFIN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch, wenn wir leben blieben, w\u00e4r's erreicht.", "tokens": ["Doch", ",", "wenn", "wir", "le\u00b7ben", "blie\u00b7ben", ",", "w\u00e4r's", "er\u00b7reicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "VVINF", "VVFIN", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Warum denn immer alles \u00fcbertreiben?", "tokens": ["Wa\u00b7rum", "denn", "im\u00b7mer", "al\u00b7les", "\u00fc\u00b7bert\u00b7rei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Warum denn links? Warum denn rechts?", "tokens": ["Wa\u00b7rum", "denn", "links", "?", "Wa\u00b7rum", "denn", "rechts", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "$.", "PWAV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um Gottes willen, la\u00dft uns m\u00e4\u00dfig bleiben,", "tokens": ["Um", "Got\u00b7tes", "wil\u00b7len", ",", "la\u00dft", "uns", "m\u00e4\u00b7\u00dfig", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "NN", "$,", "VVIMP", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht m\u00e4nnlichen, nicht weiblichen Geschlechts.", "tokens": ["Nicht", "m\u00e4nn\u00b7li\u00b7chen", ",", "nicht", "weib\u00b7li\u00b7chen", "Ge\u00b7schlechts", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$,", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "H\u00fcbsch angepa\u00dft und jede Reibung meiden!", "tokens": ["H\u00fcbsch", "an\u00b7ge\u00b7pa\u00dft", "und", "je\u00b7de", "Rei\u00b7bung", "mei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht hart, nicht weich! Nicht Ja, nicht Nein!", "tokens": ["Nicht", "hart", ",", "nicht", "weich", "!", "Nicht", "Ja", ",", "nicht", "Nein", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "PTKNEG", "ADJD", "$.", "PTKNEG", "PTKANT", "$,", "PTKNEG", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf alles h\u00f6ren und sich nie entscheiden.", "tokens": ["Auf", "al\u00b7les", "h\u00f6\u00b7ren", "und", "sich", "nie", "ent\u00b7schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVINF", "KON", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wer wei\u00df, wie's kommt. Man mu\u00df gewappnet sein.", "tokens": ["Wer", "wei\u00df", ",", "wie's", "kommt", ".", "Man", "mu\u00df", "ge\u00b7wapp\u00b7net", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PWAV", "VVFIN", "$.", "PIS", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Denn golden ist der goldne Weg der Mitte.", "tokens": ["Denn", "gol\u00b7den", "ist", "der", "gold\u00b7ne", "Weg", "der", "Mit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Man i\u00dft und zeugt und schl\u00e4ft sch\u00f6n ungest\u00f6rt,", "tokens": ["Man", "i\u00dft", "und", "zeugt", "und", "schl\u00e4ft", "sch\u00f6n", "un\u00b7ge\u00b7st\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Regt sich nicht auf um \u00bbdanke\u00ab oder \u00bbbitte\u00ab", "tokens": ["Regt", "sich", "nicht", "auf", "um", "\u00bb", "dan\u00b7ke", "\u00ab", "o\u00b7der", "\u00bb", "bit\u00b7te", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKNEG", "APPR", "APPR", "$(", "VVFIN", "$(", "KON", "$(", "PTKANT", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Und wei\u00df und lebt und stirbt, wie sich's geh\u00f6rt.", "tokens": ["Und", "wei\u00df", "und", "lebt", "und", "stirbt", ",", "wie", "sich's", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Auf! La\u00dft uns irgend jemanden erschlagen!", "tokens": ["Auf", "!", "La\u00dft", "uns", "ir\u00b7gend", "je\u00b7man\u00b7den", "er\u00b7schla\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVIMP", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie fragen: Wen?", "tokens": ["Sie", "fra\u00b7gen", ":", "Wen", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVINF", "$.", "PWS", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Wie feig schon, \u00fcberhaupt zu fragen.", "tokens": ["Wie", "feig", "schon", ",", "\u00fc\u00b7ber\u00b7haupt", "zu", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADV", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Halt irgendwen, den oder den.", "tokens": ["Halt", "ir\u00b7gend\u00b7wen", ",", "den", "o\u00b7der", "den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$,", "ART", "KON", "ART", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "So irgend jemand mitten aus der Mitte", "tokens": ["So", "ir\u00b7gend", "je\u00b7mand", "mit\u00b7ten", "aus", "der", "Mit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Urpl\u00f6tzlich t\u00f6ten, hei, wie das belebt!", "tokens": ["Ur\u00b7pl\u00f6tz\u00b7lich", "t\u00f6\u00b7ten", ",", "hei", ",", "wie", "das", "be\u00b7lebt", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,", "ITJ", "$,", "PWAV", "PDS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Weil's Aufsehn macht.", "tokens": ["Weil's", "Auf\u00b7sehn", "macht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Denn T\u00f6ten ist nicht Sitte,", "tokens": ["Denn", "T\u00f6\u00b7ten", "ist", "nicht", "Sit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sondern ein Sport, vor dem die Mehrheit bebt.", "tokens": ["Son\u00b7dern", "ein", "Sport", ",", "vor", "dem", "die", "Mehr\u00b7heit", "bebt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "APPR", "ART", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.13": {"line.1": {"text": "Nicht solche t\u00f6ten, die uns Grund gegeben,", "tokens": ["Nicht", "sol\u00b7che", "t\u00f6\u00b7ten", ",", "die", "uns", "Grund", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "ADJA", "$,", "PRELS", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Noch etwa Greise oder Weib und Kind,", "tokens": ["Noch", "et\u00b7wa", "Grei\u00b7se", "o\u00b7der", "Weib", "und", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auch la\u00dft uns T\u00f6ter gegenseitig leben,", "tokens": ["Auch", "la\u00dft", "uns", "T\u00f6\u00b7ter", "ge\u00b7gen\u00b7sei\u00b7tig", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil wir doch schlie\u00dflich keine Henker sind.", "tokens": ["Weil", "wir", "doch", "schlie\u00df\u00b7lich", "kei\u00b7ne", "Hen\u00b7ker", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Was \u00fcber achtzig Jahr und unter zehn", "tokens": ["Was", "\u00fc\u00b7ber", "acht\u00b7zig", "Jahr", "und", "un\u00b7ter", "zehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "CARD", "NN", "KON", "APPR", "CARD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Jahr ist, sind faule, unbrauchbare Drohnen.", "tokens": ["Jahr", "ist", ",", "sind", "fau\u00b7le", ",", "un\u00b7brauch\u00b7ba\u00b7re", "Droh\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "VAFIN", "NE", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Den andern aber mu\u00df man zugestehn,", "tokens": ["Den", "an\u00b7dern", "a\u00b7ber", "mu\u00df", "man", "zu\u00b7ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df sie was leisten, und die la\u00dft uns schonen.", "tokens": ["Da\u00df", "sie", "was", "leis\u00b7ten", ",", "und", "die", "la\u00dft", "uns", "scho\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVINF", "$,", "KON", "ART", "VVIMP", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Auf! La\u00dft uns all mitnander Ei-ei machen!", "tokens": ["Auf", "!", "La\u00dft", "uns", "all", "mit\u00b7nan\u00b7der", "Ei\u00b7ei", "ma\u00b7chen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVIMP", "PPER", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf! Fistet Pazi und seid friedlich froh!", "tokens": ["Auf", "!", "Fis\u00b7tet", "Pa\u00b7zi", "und", "seid", "fried\u00b7lich", "froh", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "NE", "NE", "KON", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verklebt aus Liebe unter heitrem Lachen", "tokens": ["Ver\u00b7klebt", "aus", "Lie\u00b7be", "un\u00b7ter", "heit\u00b7rem", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit Bruderku\u00df den feindlichsten Popo.", "tokens": ["Mit", "Bru\u00b7der\u00b7ku\u00df", "den", "feind\u00b7lichs\u00b7ten", "Po\u00b7po", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Krieg, Ha\u00df und Neid und alle widrigen", "tokens": ["Krieg", ",", "Ha\u00df", "und", "Neid", "und", "al\u00b7le", "wid\u00b7ri\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Gef\u00fchle fort! Dem Herzen gebt Geh\u00f6r!", "tokens": ["Ge\u00b7f\u00fch\u00b7le", "fort", "!", "Dem", "Her\u00b7zen", "gebt", "Ge\u00b7h\u00f6r", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir wollen uns freiwillig selbst erniedrigen.", "tokens": ["Wir", "wol\u00b7len", "uns", "frei\u00b7wil\u00b7lig", "selbst", "er\u00b7nied\u00b7ri\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wer uns anspeit, sei uns Parfumeur.", "tokens": ["Und", "wer", "uns", "an\u00b7speit", ",", "sei", "uns", "Par\u00b7fu\u00b7meur", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "NN", "$,", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Ein Reich zu gr\u00fcnden und daf\u00fcr zu werben", "tokens": ["Ein", "Reich", "zu", "gr\u00fcn\u00b7den", "und", "da\u00b7f\u00fcr", "zu", "wer\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "KON", "PAV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gilt es, das ganz und gar dem Himmel gleicht.", "tokens": ["Gilt", "es", ",", "das", "ganz", "und", "gar", "dem", "Him\u00b7mel", "gleicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "ADV", "KON", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Seid \u00fcberzeugt: Wir werden dr\u00fcber sterben.", "tokens": ["Seid", "\u00fc\u00b7berz\u00b7eugt", ":", "Wir", "wer\u00b7den", "dr\u00fc\u00b7ber", "ster\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "VVPP", "$.", "PPER", "VAFIN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch, wenn wir leben blieben, w\u00e4r's erreicht.", "tokens": ["Doch", ",", "wenn", "wir", "le\u00b7ben", "blie\u00b7ben", ",", "w\u00e4r's", "er\u00b7reicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "VVINF", "VVFIN", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Warum denn immer alles \u00fcbertreiben?", "tokens": ["Wa\u00b7rum", "denn", "im\u00b7mer", "al\u00b7les", "\u00fc\u00b7bert\u00b7rei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Warum denn links? Warum denn rechts?", "tokens": ["Wa\u00b7rum", "denn", "links", "?", "Wa\u00b7rum", "denn", "rechts", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "$.", "PWAV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um Gottes willen, la\u00dft uns m\u00e4\u00dfig bleiben,", "tokens": ["Um", "Got\u00b7tes", "wil\u00b7len", ",", "la\u00dft", "uns", "m\u00e4\u00b7\u00dfig", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "NN", "$,", "VVIMP", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht m\u00e4nnlichen, nicht weiblichen Geschlechts.", "tokens": ["Nicht", "m\u00e4nn\u00b7li\u00b7chen", ",", "nicht", "weib\u00b7li\u00b7chen", "Ge\u00b7schlechts", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$,", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "H\u00fcbsch angepa\u00dft und jede Reibung meiden!", "tokens": ["H\u00fcbsch", "an\u00b7ge\u00b7pa\u00dft", "und", "je\u00b7de", "Rei\u00b7bung", "mei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht hart, nicht weich! Nicht Ja, nicht Nein!", "tokens": ["Nicht", "hart", ",", "nicht", "weich", "!", "Nicht", "Ja", ",", "nicht", "Nein", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "PTKNEG", "ADJD", "$.", "PTKNEG", "PTKANT", "$,", "PTKNEG", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf alles h\u00f6ren und sich nie entscheiden.", "tokens": ["Auf", "al\u00b7les", "h\u00f6\u00b7ren", "und", "sich", "nie", "ent\u00b7schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVINF", "KON", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wer wei\u00df, wie's kommt. Man mu\u00df gewappnet sein.", "tokens": ["Wer", "wei\u00df", ",", "wie's", "kommt", ".", "Man", "mu\u00df", "ge\u00b7wapp\u00b7net", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PWAV", "VVFIN", "$.", "PIS", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Denn golden ist der goldne Weg der Mitte.", "tokens": ["Denn", "gol\u00b7den", "ist", "der", "gold\u00b7ne", "Weg", "der", "Mit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Man i\u00dft und zeugt und schl\u00e4ft sch\u00f6n ungest\u00f6rt,", "tokens": ["Man", "i\u00dft", "und", "zeugt", "und", "schl\u00e4ft", "sch\u00f6n", "un\u00b7ge\u00b7st\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Regt sich nicht auf um \u00bbdanke\u00ab oder \u00bbbitte\u00ab", "tokens": ["Regt", "sich", "nicht", "auf", "um", "\u00bb", "dan\u00b7ke", "\u00ab", "o\u00b7der", "\u00bb", "bit\u00b7te", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKNEG", "APPR", "APPR", "$(", "VVFIN", "$(", "KON", "$(", "PTKANT", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Und wei\u00df und lebt und stirbt, wie sich's geh\u00f6rt.", "tokens": ["Und", "wei\u00df", "und", "lebt", "und", "stirbt", ",", "wie", "sich's", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}