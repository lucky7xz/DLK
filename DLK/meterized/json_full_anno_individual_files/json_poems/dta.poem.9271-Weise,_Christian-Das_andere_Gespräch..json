{"dta.poem.9271": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Das andere Gespr\u00e4ch.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.85", "af:0.14"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Marindgen/ was soll di\u00df bedeuten/", "tokens": ["Ma\u00b7rind\u00b7gen", "/", "was", "soll", "di\u00df", "be\u00b7deu\u00b7ten", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PWS", "VMFIN", "PDS", "VVINF", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Was nimmt dich vor ein irrthum ein/", "tokens": ["Was", "nimmt", "dich", "vor", "ein", "irr\u00b7thum", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "ART", "NN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df du von lauter sch\u00f6nen leuten", "tokens": ["Da\u00df", "du", "von", "lau\u00b7ter", "sch\u00f6\u00b7nen", "leu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wilst nach der kunst bedienet seyn/", "tokens": ["Wilst", "nach", "der", "kunst", "be\u00b7die\u00b7net", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und deine wangen sehen aus", "tokens": ["Und", "dei\u00b7ne", "wan\u00b7gen", "se\u00b7hen", "aus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie ein verdorrter nelcken-strau\u00df.", "tokens": ["Wie", "ein", "ver\u00b7dorr\u00b7ter", "nel\u00b7cken\u00b7strau\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Du richtest gar zu frey von allen/", "tokens": ["Du", "rich\u00b7test", "gar", "zu", "frey", "von", "al\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKA", "ADJD", "APPR", "PIAT", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da ist kein kerle gut genung/", "tokens": ["Da", "ist", "kein", "ker\u00b7le", "gut", "ge\u00b7nung", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADJD", "NN", "$("], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Dem sind die backen eingefallen/", "tokens": ["Dem", "sind", "die", "ba\u00b7cken", "ein\u00b7ge\u00b7fal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der ist zu alt und der zu jung.", "tokens": ["Der", "ist", "zu", "alt", "und", "der", "zu", "jung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKA", "ADJD", "KON", "ART", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hingegen schaustu di\u00df nicht an", "tokens": ["Hin\u00b7ge\u00b7gen", "schaus\u00b7tu", "di\u00df", "nicht", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PDS", "PTKNEG", "PTKVZ"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Was man von dir gedencken kan.", "tokens": ["Was", "man", "von", "dir", "ge\u00b7den\u00b7cken", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Es hat sich wol/ die feinen dinger", "tokens": ["Es", "hat", "sich", "wol", "/", "die", "fei\u00b7nen", "din\u00b7ger"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die warten gar gewi\u00df auff dich:", "tokens": ["Die", "war\u00b7ten", "gar", "ge\u00b7wi\u00df", "auff", "dich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ach nein/ du nimmst es wol geringer/", "tokens": ["Ach", "nein", "/", "du", "nimmst", "es", "wol", "ge\u00b7rin\u00b7ger", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$(", "PPER", "VVFIN", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo nicht/ so bistu wunderlich.", "tokens": ["Wo", "nicht", "/", "so", "bis\u00b7tu", "wun\u00b7der\u00b7lich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$(", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn weistu nicht da\u00df in der welt", "tokens": ["Denn", "weis\u00b7tu", "nicht", "da\u00df", "in", "der", "welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich allzeit gleich und gleich gesellt.", "tokens": ["Sich", "all\u00b7zeit", "gleich", "und", "gleich", "ge\u00b7sellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADV", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Derhalben dencke nach du stoltze/", "tokens": ["Der\u00b7hal\u00b7ben", "den\u00b7cke", "nach", "du", "stolt\u00b7ze", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du hast unm\u00fcglich ding begehrt:", "tokens": ["Du", "hast", "un\u00b7m\u00fcg\u00b7lich", "ding", "be\u00b7gehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das wei\u00df ich wol ein bock von holtze/", "tokens": ["Das", "wei\u00df", "ich", "wol", "ein", "bock", "von", "holt\u00b7ze", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist einer g\u00fcldnen ziege wehrt/", "tokens": ["Ist", "ei\u00b7ner", "g\u00fcld\u00b7nen", "zie\u00b7ge", "wehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein degen ohne glantz und schein", "tokens": ["Ein", "de\u00b7gen", "oh\u00b7ne", "glantz", "und", "schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Kan in der sch\u00f6nsten scheide seyn.", "tokens": ["Kan", "in", "der", "sch\u00f6ns\u00b7ten", "schei\u00b7de", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "ADJA", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Hingegen gibt es schlechte gn\u00fcge", "tokens": ["Hin\u00b7ge\u00b7gen", "gibt", "es", "schlech\u00b7te", "gn\u00fc\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und wird ein blosses narrenspiel/", "tokens": ["Und", "wird", "ein", "blos\u00b7ses", "nar\u00b7ren\u00b7spiel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wann etwa eine d\u00fcrre ziege", "tokens": ["Wann", "et\u00b7wa", "ei\u00b7ne", "d\u00fcr\u00b7re", "zie\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den besten bock erwischen will/", "tokens": ["Den", "bes\u00b7ten", "bock", "er\u00b7wi\u00b7schen", "will", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wenn ein unvergleichlich schwerdt", "tokens": ["Und", "wenn", "ein", "un\u00b7ver\u00b7gleich\u00b7lich", "schwerdt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In eine kahle scheide f\u00e4hrt.", "tokens": ["In", "ei\u00b7ne", "kah\u00b7le", "schei\u00b7de", "f\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "6. Ich nehme stets vor lieb/ und richte", "tokens": ["Ich", "neh\u00b7me", "stets", "vor", "lieb", "/", "und", "rich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ADJD", "$(", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das schlimmste m\u00e4dgen nicht zu scharff/", "tokens": ["Das", "schlimms\u00b7te", "m\u00e4d\u00b7gen", "nicht", "zu", "scharff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indem ich doch mein angesichte", "tokens": ["In\u00b7dem", "ich", "doch", "mein", "an\u00b7ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von keiner sch\u00f6nheit r\u00fchmen darff/", "tokens": ["Von", "kei\u00b7ner", "sch\u00f6n\u00b7heit", "r\u00fch\u00b7men", "darff", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Drum schrieb ich dir/ du n\u00e4rrgen du/", "tokens": ["Drum", "schrieb", "ich", "dir", "/", "du", "n\u00e4rr\u00b7gen", "du", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "$(", "PPER", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auch eine solche demuth zu.", "tokens": ["Auch", "ei\u00b7ne", "sol\u00b7che", "de\u00b7muth", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "7. Wenn alle so gedencken solten/", "tokens": ["Wenn", "al\u00b7le", "so", "ge\u00b7den\u00b7cken", "sol\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und wenn die schlechten b\u00fcfgen hier", "tokens": ["Und", "wenn", "die", "schlech\u00b7ten", "b\u00fcf\u00b7gen", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur auff die sch\u00f6nste warten wolten/", "tokens": ["Nur", "auff", "die", "sch\u00f6ns\u00b7te", "war\u00b7ten", "wol\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer k\u00e4me dann hernach zu dir?", "tokens": ["Wer", "k\u00e4\u00b7me", "dann", "her\u00b7nach", "zu", "dir", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn niemand als ein blinder mann", "tokens": ["Denn", "nie\u00b7mand", "als", "ein", "blin\u00b7der", "mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Siht dich der sch\u00f6nheit halben an.", "tokens": ["Siht", "dich", "der", "sch\u00f6n\u00b7heit", "hal\u00b7ben", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "8. Marindgen nun du hast die fl\u00fcgel", "tokens": ["Ma\u00b7rind\u00b7gen", "nun", "du", "hast", "die", "fl\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein bi\u00dfgen hoch hinauff gethan/", "tokens": ["Ein", "bi\u00df\u00b7gen", "hoch", "hin\u00b7auff", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein ander mahl trit vor den spiegel/", "tokens": ["Ein", "an\u00b7der", "mahl", "trit", "vor", "den", "spie\u00b7gel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Und schaue mich darneben an.", "tokens": ["Und", "schau\u00b7e", "mich", "dar\u00b7ne\u00b7ben", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PAV", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Alsdann so frage deinen sinn/", "tokens": ["Als\u00b7dann", "so", "fra\u00b7ge", "dei\u00b7nen", "sinn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ob ich dir zu geringe bin.", "tokens": ["Ob", "ich", "dir", "zu", "ge\u00b7rin\u00b7ge", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}