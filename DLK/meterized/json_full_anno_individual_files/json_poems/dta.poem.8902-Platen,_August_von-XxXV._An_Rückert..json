{"dta.poem.8902": {"metadata": {"author": {"name": "Platen, August von", "birth": "N.A.", "death": "N.A."}, "title": "XxXV.  \n  An R\u00fcckert.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1828", "urn": "urn:nbn:de:kobv:b4-200905194597", "language": ["de:0.99"], "booktitle": "Platen, August von: Gedichte. Stuttgart, 1828."}, "poem": {"stanza.1": {"line.1": {"text": "Das von der Kunst Hariri's zeugt und deiner,", "tokens": ["Das", "von", "der", "Kunst", "Har\u00b7i\u00b7ri's", "zeugt", "und", "dei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "NE", "VVFIN", "KON", "PPOSAT", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und schon erschein' ich der Entz\u00fcckten einer,", "tokens": ["Und", "schon", "er\u00b7schein'", "ich", "der", "Ent\u00b7z\u00fcck\u00b7ten", "ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART", "NN", "ART", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der's ohne Hehl bestaunt und ohne Krittel.", "tokens": ["Der's", "oh\u00b7ne", "Hehl", "be\u00b7staunt", "und", "oh\u00b7ne", "Krit\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "NN", "ADJD", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wenn das Genie so ganz auf eigne Mittel", "tokens": ["Wenn", "das", "Ge\u00b7nie", "so", "ganz", "auf", "eig\u00b7ne", "Mit\u00b7tel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Welt durchbetteln mu\u00df, bew\u00e4hrt sich's reiner", "tokens": ["Die", "Welt", "durch\u00b7bet\u00b7teln", "mu\u00df", ",", "be\u00b7w\u00e4hrt", "sich's", "rei\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$,", "VVFIN", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als je, verg\u00f6ttlichter und ungemeiner,", "tokens": ["Als", "je", ",", "ver\u00b7g\u00f6tt\u00b7lich\u00b7ter", "und", "un\u00b7ge\u00b7mei\u00b7ner", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "ADJA", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn auch verkappt in einen Gaunerkittel.", "tokens": ["Wenn", "auch", "ver\u00b7kappt", "in", "ei\u00b7nen", "Gau\u00b7ner\u00b7kit\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Mit einem Andern aber soll ich losen,", "tokens": ["Mit", "ei\u00b7nem", "An\u00b7dern", "a\u00b7ber", "soll", "ich", "lo\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So willst du, statt zu schicken uns ein P\u00e4rchen,", "tokens": ["So", "willst", "du", ",", "statt", "zu", "schi\u00b7cken", "uns", "ein", "P\u00e4r\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "KOUI", "PTKZU", "VVINF", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Um deines Ebu Seids Metamorphosen?", "tokens": ["Um", "dei\u00b7nes", "E\u00b7bu", "Seids", "Me\u00b7ta\u00b7mor\u00b7pho\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "NE", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Dar\u00fcber wachse mir kein graues H\u00e4rchen:", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "wach\u00b7se", "mir", "kein", "grau\u00b7es", "H\u00e4r\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nie trenn' ich mich von deinem Virtuosen,", "tokens": ["Nie", "trenn'", "ich", "mich", "von", "dei\u00b7nem", "Vir\u00b7tu\u00b7o\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "D'rum sende lieber noch ein Exempl\u00e4rchen!", "tokens": ["D'\u00b7rum", "sen\u00b7de", "lie\u00b7ber", "noch", "ein", "Ex\u00b7emp\u00b7l\u00e4r\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}}}}