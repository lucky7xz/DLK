{"textgrid.poem.53524": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Namens\u00e4nderung", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich mu\u00df mir einen neuen Namen geben.", "tokens": ["Ich", "mu\u00df", "mir", "ei\u00b7nen", "neu\u00b7en", "Na\u00b7men", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mein Gott, wer \u00e4ndert nicht in gro\u00dfer Zeit!", "tokens": ["Mein", "Gott", ",", "wer", "\u00e4n\u00b7dert", "nicht", "in", "gro\u00b7\u00dfer", "Zeit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWS", "VVFIN", "PTKNEG", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man kann ja auch als Kaspar Hauser leben,", "tokens": ["Man", "kann", "ja", "auch", "als", "Kas\u00b7par", "Hau\u00b7ser", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "KOUS", "NE", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wie er war ich von aller Welt so weit.", "tokens": ["wie", "er", "war", "ich", "von", "al\u00b7ler", "Welt", "so", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "PPER", "APPR", "PIAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ich Menschenfremdling dacht in meiner Klause:", "tokens": ["Ich", "Men\u00b7schen\u00b7fremd\u00b7ling", "dacht", "in", "mei\u00b7ner", "Klau\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ist ein Professor einmal Monarchist,", "tokens": ["Ist", "ein", "Pro\u00b7fes\u00b7sor", "ein\u00b7mal", "Mon\u00b7ar\u00b7chist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "weht einmal Schwarz-Wei\u00df-Rot von seinem Hause,", "tokens": ["weht", "ein\u00b7mal", "Schwa\u00b7rz\u00b7Wei\u00df\u00b7Rot", "von", "sei\u00b7nem", "Hau\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "dann, dacht ich, bleibt er eben, was er ist.", "tokens": ["dann", ",", "dacht", "ich", ",", "bleibt", "er", "e\u00b7ben", ",", "was", "er", "ist", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ich Kind! Da lebt ich so im frommen Wahne.", "tokens": ["Ich", "Kind", "!", "Da", "lebt", "ich", "so", "im", "from\u00b7men", "Wah\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der hat ja gar nicht jenen Thron gemeint!", "tokens": ["Der", "hat", "ja", "gar", "nicht", "je\u00b7nen", "Thron", "ge\u00b7meint", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "PTKNEG", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sein Banner ist die kleine Wetterfahne:", "tokens": ["Sein", "Ban\u00b7ner", "ist", "die", "klei\u00b7ne", "Wet\u00b7ter\u00b7fah\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zahlst du Pension? Wenn nicht, bist du der Feind.", "tokens": ["Zahlst", "du", "Pen\u00b7si\u00b7on", "?", "Wenn", "nicht", ",", "bist", "du", "der", "Feind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$.", "KOUS", "PTKNEG", "$,", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.4": {"line.1": {"text": "Und flugs und flink hat er sich umgewandelt.", "tokens": ["Und", "flugs", "und", "flink", "hat", "er", "sich", "um\u00b7ge\u00b7wan\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADJD", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Man \u00e4ndert seinen Namen, nicht das Herz.", "tokens": ["Man", "\u00e4n\u00b7dert", "sei\u00b7nen", "Na\u00b7men", ",", "nicht", "das", "Herz", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "$,", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man lernt die neuen Worte, und man handelt", "tokens": ["Man", "lernt", "die", "neu\u00b7en", "Wor\u00b7te", ",", "und", "man", "han\u00b7delt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "$,", "KON", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die \u00dcberzeugung nunmehr anderw\u00e4rts.", "tokens": ["die", "\u00dc\u00b7berz\u00b7eu\u00b7gung", "nun\u00b7mehr", "an\u00b7der\u00b7w\u00e4rts", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "So zeigt sich denn beim Leben und beim Schreiben:", "tokens": ["So", "zeigt", "sich", "denn", "beim", "Le\u00b7ben", "und", "beim", "Schrei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "die Reaktion ist alt \u2013 die Phrase neu.", "tokens": ["die", "Re\u00b7ak\u00b7ti\u00b7on", "ist", "alt", "\u2013", "die", "Phra\u00b7se", "neu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$(", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Ich aber will gern euer Alter bleiben,", "tokens": ["Ich", "a\u00b7ber", "will", "gern", "eu\u00b7er", "Al\u00b7ter", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "als Kaspar Hauser.", "tokens": ["als", "Kas\u00b7par", "Hau\u00b7ser", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Bleibt mir weiter treu!", "tokens": ["Bleibt", "mir", "wei\u00b7ter", "treu", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Ich mu\u00df mir einen neuen Namen geben.", "tokens": ["Ich", "mu\u00df", "mir", "ei\u00b7nen", "neu\u00b7en", "Na\u00b7men", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mein Gott, wer \u00e4ndert nicht in gro\u00dfer Zeit!", "tokens": ["Mein", "Gott", ",", "wer", "\u00e4n\u00b7dert", "nicht", "in", "gro\u00b7\u00dfer", "Zeit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWS", "VVFIN", "PTKNEG", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man kann ja auch als Kaspar Hauser leben,", "tokens": ["Man", "kann", "ja", "auch", "als", "Kas\u00b7par", "Hau\u00b7ser", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "KOUS", "NE", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wie er war ich von aller Welt so weit.", "tokens": ["wie", "er", "war", "ich", "von", "al\u00b7ler", "Welt", "so", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "PPER", "APPR", "PIAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Ich Menschenfremdling dacht in meiner Klause:", "tokens": ["Ich", "Men\u00b7schen\u00b7fremd\u00b7ling", "dacht", "in", "mei\u00b7ner", "Klau\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ist ein Professor einmal Monarchist,", "tokens": ["Ist", "ein", "Pro\u00b7fes\u00b7sor", "ein\u00b7mal", "Mon\u00b7ar\u00b7chist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "weht einmal Schwarz-Wei\u00df-Rot von seinem Hause,", "tokens": ["weht", "ein\u00b7mal", "Schwa\u00b7rz\u00b7Wei\u00df\u00b7Rot", "von", "sei\u00b7nem", "Hau\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "dann, dacht ich, bleibt er eben, was er ist.", "tokens": ["dann", ",", "dacht", "ich", ",", "bleibt", "er", "e\u00b7ben", ",", "was", "er", "ist", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ich Kind! Da lebt ich so im frommen Wahne.", "tokens": ["Ich", "Kind", "!", "Da", "lebt", "ich", "so", "im", "from\u00b7men", "Wah\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der hat ja gar nicht jenen Thron gemeint!", "tokens": ["Der", "hat", "ja", "gar", "nicht", "je\u00b7nen", "Thron", "ge\u00b7meint", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "PTKNEG", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sein Banner ist die kleine Wetterfahne:", "tokens": ["Sein", "Ban\u00b7ner", "ist", "die", "klei\u00b7ne", "Wet\u00b7ter\u00b7fah\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zahlst du Pension? Wenn nicht, bist du der Feind.", "tokens": ["Zahlst", "du", "Pen\u00b7si\u00b7on", "?", "Wenn", "nicht", ",", "bist", "du", "der", "Feind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$.", "KOUS", "PTKNEG", "$,", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.9": {"line.1": {"text": "Und flugs und flink hat er sich umgewandelt.", "tokens": ["Und", "flugs", "und", "flink", "hat", "er", "sich", "um\u00b7ge\u00b7wan\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADJD", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Man \u00e4ndert seinen Namen, nicht das Herz.", "tokens": ["Man", "\u00e4n\u00b7dert", "sei\u00b7nen", "Na\u00b7men", ",", "nicht", "das", "Herz", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "$,", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man lernt die neuen Worte, und man handelt", "tokens": ["Man", "lernt", "die", "neu\u00b7en", "Wor\u00b7te", ",", "und", "man", "han\u00b7delt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "$,", "KON", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die \u00dcberzeugung nunmehr anderw\u00e4rts.", "tokens": ["die", "\u00dc\u00b7berz\u00b7eu\u00b7gung", "nun\u00b7mehr", "an\u00b7der\u00b7w\u00e4rts", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "So zeigt sich denn beim Leben und beim Schreiben:", "tokens": ["So", "zeigt", "sich", "denn", "beim", "Le\u00b7ben", "und", "beim", "Schrei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "die Reaktion ist alt \u2013 die Phrase neu.", "tokens": ["die", "Re\u00b7ak\u00b7ti\u00b7on", "ist", "alt", "\u2013", "die", "Phra\u00b7se", "neu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$(", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Ich aber will gern euer Alter bleiben,", "tokens": ["Ich", "a\u00b7ber", "will", "gern", "eu\u00b7er", "Al\u00b7ter", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "als Kaspar Hauser.", "tokens": ["als", "Kas\u00b7par", "Hau\u00b7ser", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Bleibt mir weiter treu!", "tokens": ["Bleibt", "mir", "wei\u00b7ter", "treu", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}