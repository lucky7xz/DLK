{"dta.poem.19750": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Die Herzogin von Orlam\u00fcnde .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Albert Graf von N\u00fcrnberg spricht:               ", "tokens": ["Al\u00b7bert", "Graf", "von", "N\u00fcrn\u00b7berg", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201eherzogin ich liebe nicht;", "tokens": ["\u201e", "her\u00b7zo\u00b7gin", "ich", "lie\u00b7be", "nicht", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "\u201ebin ein Kind von achtzehn Jahren", "tokens": ["\u201e", "bin", "ein", "Kind", "von", "acht\u00b7zehn", "Jah\u00b7ren"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "ART", "NN", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201eund im Lieben unerfahren,", "tokens": ["\u201e", "und", "im", "Lie\u00b7ben", "un\u00b7er\u00b7fah\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "APPRART", "ADJA", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "\u201ew\u00fcrde doch zum Weib dich nehmen,", "tokens": ["\u201e", "w\u00fcr\u00b7de", "doch", "zum", "Weib", "dich", "neh\u00b7men", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADV", "APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201edoch vier Augen mich besch\u00e4men;", "tokens": ["\u201e", "doch", "vier", "Au\u00b7gen", "mich", "be\u00b7sch\u00e4\u00b7men", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "CARD", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "\u201ewenn nicht hier vier Augen w\u00e4ren,", "tokens": ["\u201e", "wenn", "nicht", "hier", "vier", "Au\u00b7gen", "w\u00e4\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PTKNEG", "ADV", "CARD", "NN", "VAFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u201edie das Herze mein beschweren.\u201c", "tokens": ["\u201e", "die", "das", "Her\u00b7ze", "mein", "be\u00b7schwe\u00b7ren", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PRELS", "PDS", "VVFIN", "PPOSAT", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Orlam\u00fcndens Herzogin", "tokens": ["Or\u00b7la\u00b7m\u00fcn\u00b7dens", "Her\u00b7zo\u00b7gin"], "token_info": ["word", "word"], "pos": ["NE", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Spricht zu sich in ihrem Sinn:", "tokens": ["Spricht", "zu", "sich", "in", "ih\u00b7rem", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "\u201ewitwe bin ich sch\u00f6n vor allen,", "tokens": ["\u201e", "wit\u00b7we", "bin", "ich", "sch\u00f6n", "vor", "al\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "VAFIN", "PPER", "ADJD", "APPR", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201ealler F\u00fcrsten Wohlgefallen;", "tokens": ["\u201e", "al\u00b7ler", "F\u00fcrs\u00b7ten", "Wohl\u00b7ge\u00b7fal\u00b7len", ";"], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "PIAT", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "\u201ewenn nicht hier vier Augen w\u00e4ren,", "tokens": ["\u201e", "wenn", "nicht", "hier", "vier", "Au\u00b7gen", "w\u00e4\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PTKNEG", "ADV", "CARD", "NN", "VAFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u201ew\u00fcrde seine Lieb mich ehren.\u201c", "tokens": ["\u201e", "w\u00fcr\u00b7de", "sei\u00b7ne", "Lieb", "mich", "eh\u00b7ren", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PPOSAT", "NN", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "\u201ekinder ihr vom schlechten Mann,", "tokens": ["\u201e", "kin\u00b7der", "ihr", "vom", "schlech\u00b7ten", "Mann", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201eder mich hielt in strengem Bann;", "tokens": ["\u201e", "der", "mich", "hielt", "in", "stren\u00b7gem", "Bann", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PRELS", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "\u201eweil ihr meine Land ererbet", "tokens": ["\u201e", "weil", "ihr", "mei\u00b7ne", "Land", "er\u00b7er\u00b7bet"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201ewenn ihr nicht unm\u00fcndig sterbet.\u201c", "tokens": ["\u201e", "wenn", "ihr", "nicht", "un\u00b7m\u00fcn\u00b7dig", "ster\u00b7bet", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "PTKNEG", "ADJD", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Also Oehl in Flammen w\u00fcthet,", "tokens": ["Al\u00b7so", "O\u00b7ehl", "in", "Flam\u00b7men", "w\u00fct\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das statt Wasser aufgesch\u00fcttet.", "tokens": ["Das", "statt", "Was\u00b7ser", "auf\u00b7ge\u00b7sch\u00fct\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Also deutet sie die Rede", "tokens": ["Al\u00b7so", "deu\u00b7tet", "sie", "die", "Re\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf zwey eigne Kinder schn\u00f6de,", "tokens": ["Auf", "zwey", "eig\u00b7ne", "Kin\u00b7der", "schn\u00f6\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Die im Saal zum Spiel abz\u00e4hlen,", "tokens": ["Die", "im", "Saal", "zum", "Spiel", "ab\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "APPRART", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unter sich den Engel w\u00e4hlen:", "tokens": ["Un\u00b7ter", "sich", "den", "En\u00b7gel", "w\u00e4h\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "\u201eengel, Bengel, la\u00df mich leben,", "tokens": ["\u201e", "en\u00b7gel", ",", "Ben\u00b7gel", ",", "la\u00df", "mich", "le\u00b7ben", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NN", "$,", "VVIMP", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201eich will dir den Vogel geben.\u201c", "tokens": ["\u201e", "ich", "will", "dir", "den", "Vo\u00b7gel", "ge\u00b7ben", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Nadeln aus dem Wittibschleyer", "tokens": ["Na\u00b7deln", "aus", "dem", "Wit\u00b7tib\u00b7schle\u00b7yer"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Zieht sie, da\u00df er falle freyer,", "tokens": ["Zieht", "sie", ",", "da\u00df", "er", "fal\u00b7le", "frey\u00b7er", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Zu dem wilden Hager spricht:", "tokens": ["Zu", "dem", "wil\u00b7den", "Ha\u00b7ger", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201enimm die Nadeln und verricht,", "tokens": ["\u201e", "nimm", "die", "Na\u00b7deln", "und", "ver\u00b7richt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "ART", "NN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "\u201eschwarzer Hager, du mein Freyer", "tokens": ["\u201e", "schwar\u00b7zer", "Ha\u00b7ger", ",", "du", "mein", "Frey\u00b7er"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADJA", "NN", "$,", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201ef\u00fcrchtest nicht den schwarzen Schleyer,", "tokens": ["\u201e", "f\u00fcrch\u00b7test", "nicht", "den", "schwar\u00b7zen", "Schle\u00b7yer", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.17": {"line.1": {"text": "\u201ef\u00fcrchtest du nicht auch vier Augen,", "tokens": ["\u201e", "f\u00fcrch\u00b7test", "du", "nicht", "auch", "vier", "Au\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKNEG", "ADV", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201edie zum Zusehn hier nicht taugen,", "tokens": ["\u201e", "die", "zum", "Zu\u00b7sehn", "hier", "nicht", "tau\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "APPRART", "NN", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.18": {"line.1": {"text": "\u201esetz' dich mit zu ihren Spielen,", "tokens": ["\u201e", "setz'", "dich", "mit", "zu", "ih\u00b7ren", "Spie\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PRF", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201eda\u00df sie keine Schmerzen f\u00fchlen,", "tokens": ["\u201e", "da\u00df", "sie", "kei\u00b7ne", "Schmer\u00b7zen", "f\u00fch\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "\u201eda\u00df die Wunden niemals sprechen,", "tokens": ["\u201e", "da\u00df", "die", "Wun\u00b7den", "nie\u00b7mals", "spre\u00b7chen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201emust du in das Hirn sie stechen,\u201c", "tokens": ["\u201e", "must", "du", "in", "das", "Hirn", "sie", "ste\u00b7chen", ",", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "PPER", "APPR", "ART", "NN", "PPER", "VVINF", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Herulus zum Hager spricht,", "tokens": ["He\u00b7ru\u00b7lus", "zum", "Ha\u00b7ger", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eh der ihm das Hirn einsticht:", "tokens": ["Eh", "der", "ihm", "das", "Hirn", "ein\u00b7sticht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "\u201elieber Hager, la\u00df mich leben,", "tokens": ["\u201e", "lie\u00b7ber", "Ha\u00b7ger", ",", "la\u00df", "mich", "le\u00b7ben", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "NE", "$,", "VVIMP", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201ewill dir Orlam\u00fcnde geben,", "tokens": ["\u201e", "will", "dir", "Or\u00b7la\u00b7m\u00fcn\u00b7de", "ge\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "\u201eauch die Plassenburg die neue,", "tokens": ["\u201e", "auch", "die", "Plas\u00b7sen\u00b7burg", "die", "neu\u00b7e", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201eund es soll mich nicht gereuen.\u201c", "tokens": ["\u201e", "und", "es", "soll", "mich", "nicht", "ge\u00b7reu\u00b7en", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Herula zum Hager spricht,", "tokens": ["He\u00b7ru\u00b7la", "zum", "Ha\u00b7ger", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eh er ihr das Hirn einsticht:", "tokens": ["Eh", "er", "ihr", "das", "Hirn", "ein\u00b7sticht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "\u201elieber Hager la\u00df mich leben,", "tokens": ["\u201e", "lie\u00b7ber", "Ha\u00b7ger", "la\u00df", "mich", "le\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "NE", "VVIMP", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201ewill dir meine Docken geben,", "tokens": ["\u201e", "will", "dir", "mei\u00b7ne", "Do\u00b7cken", "ge\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "\u201eengel, Bengel la\u00df mich leben,", "tokens": ["\u201e", "en\u00b7gel", ",", "Ben\u00b7gel", "la\u00df", "mich", "le\u00b7ben", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NN", "VVIMP", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201ewill dir meinen Vogel geben.\u201c", "tokens": ["\u201e", "will", "dir", "mei\u00b7nen", "Vo\u00b7gel", "ge\u00b7ben", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Hager sich als M\u00f6rder nennt,", "tokens": ["Ha\u00b7ger", "sich", "als", "M\u00f6r\u00b7der", "nennt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "KOUS", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eh er sich das Hirn einrennt.", "tokens": ["Eh", "er", "sich", "das", "Hirn", "ein\u00b7rennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "\u201egott ach Gott, wo werd ich ruhen,", "tokens": ["\u201e", "gott", "ach", "Gott", ",", "wo", "werd", "ich", "ru\u00b7hen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "XY", "NN", "$,", "PWAV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201eh\u00f6re schon den Vogel rufen,", "tokens": ["\u201e", "h\u00f6\u00b7re", "schon", "den", "Vo\u00b7gel", "ru\u00b7fen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "\u201egott ach Gott, wo soll ich fliehen,", "tokens": ["\u201e", "gott", "ach", "Gott", ",", "wo", "soll", "ich", "flie\u00b7hen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "XY", "NN", "$,", "PWAV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201esehe schon den Vogel ziehen.\u201c", "tokens": ["\u201e", "se\u00b7he", "schon", "den", "Vo\u00b7gel", "zie\u00b7hen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ADV", "ART", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Albert spricht zur Herzogin:", "tokens": ["Al\u00b7bert", "spricht", "zur", "Her\u00b7zo\u00b7gin", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201edas war nicht der Rede Sinn,", "tokens": ["\u201e", "das", "war", "nicht", "der", "Re\u00b7de", "Sinn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.30": {"line.1": {"text": "\u201emeinte unsre eignen Augen,", "tokens": ["\u201e", "mein\u00b7te", "uns\u00b7re", "eig\u00b7nen", "Au\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201ewie wir nicht zusammen taugen.\u201c", "tokens": ["\u201e", "wie", "wir", "nicht", "zu\u00b7sam\u00b7men", "tau\u00b7gen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "PPER", "PTKNEG", "ADV", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Beyde Kinder unverweset", "tokens": ["Bey\u00b7de", "Kin\u00b7der", "un\u00b7ver\u00b7we\u00b7set"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liegen noch im Marmorsarge,", "tokens": ["Lie\u00b7gen", "noch", "im", "Mar\u00b7mor\u00b7sar\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als w\u00e4r heut der Mord gewesen,", "tokens": ["Als", "w\u00e4r", "heut", "der", "Mord", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ADV", "ART", "NN", "VAPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Recht zum Trotze allem Argen.", "tokens": ["Recht", "zum", "Trot\u00b7ze", "al\u00b7lem", "Ar\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PIS", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}