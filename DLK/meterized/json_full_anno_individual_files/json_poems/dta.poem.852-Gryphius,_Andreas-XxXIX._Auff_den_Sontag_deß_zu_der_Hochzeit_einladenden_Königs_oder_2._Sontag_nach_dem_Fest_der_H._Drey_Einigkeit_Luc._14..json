{"dta.poem.852": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "XxXIX.  Auff den Sontag de\u00df zu der Hochzeit  \n einladenden K\u00f6nigs oder 2. Sontag nach  \n dem Fest der H. Drey Einigkeit/  \n Luc. 14.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.71", "nl:0.28"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "GoTT hat sein Gnadenmal vorlangst anrichten lassen ", "tokens": ["GoTT", "hat", "sein", "Gna\u00b7den\u00b7mal", "vor\u00b7langst", "an\u00b7rich\u00b7ten", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "ADV", "VVINF", "VVINF"], "meter": "-+-+--++-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Vnd die verstockte Welt von anbeginn der zeit", "tokens": ["Vnd", "die", "ver\u00b7stock\u00b7te", "Welt", "von", "an\u00b7be\u00b7ginn", "der", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Geruffen zu der lust/ Es ist vmbsonst bereit/", "tokens": ["Ge\u00b7ruf\u00b7fen", "zu", "der", "lust", "/", "Es", "ist", "vmbsonst", "be\u00b7reit", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Er findet hohn f\u00fcr gunst/ f\u00fcr liebe rasend hass\u1ebdn!", "tokens": ["Er", "fin\u00b7det", "hohn", "f\u00fcr", "gunst", "/", "f\u00fcr", "lie\u00b7be", "ra\u00b7send", "hass\u1ebdn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NN", "$(", "APPR", "ADJA", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Die h\u00e4lt der Acker ab/ die kan das Weib anfassen", "tokens": ["Die", "h\u00e4lt", "der", "A\u00b7cker", "ab", "/", "die", "kan", "das", "Weib", "an\u00b7fas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "PTKVZ", "$(", "PDS", "VMFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vnd der/ O Vih! O Schmach! Hohn \u00fcber alles Leid!", "tokens": ["Vnd", "der", "/", "O", "Vih", "!", "O", "Schmach", "!", "Hohn", "\u00fc\u00b7ber", "al\u00b7les", "Leid", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$(", "NE", "NE", "$.", "NE", "NN", "$.", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Sch\u00f6pfft aus den Ochsen mehr/ denn GOtt/ beh\u00e4gligkeit.", "tokens": ["Sch\u00f6pfft", "aus", "den", "Och\u00b7sen", "mehr", "/", "denn", "Gott", "/", "be\u00b7h\u00e4g\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ADV", "$(", "KON", "NN", "$(", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er rufft: Er schickt noch au\u00df durch aller V\u00f6lcker gassen.", "tokens": ["Er", "rufft", ":", "Er", "schickt", "noch", "au\u00df", "durch", "al\u00b7ler", "V\u00f6l\u00b7cker", "gas\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "ADV", "APPR", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Doch bleibt sein Gast Saal leer/ drumb steckt der heisse", "tokens": ["Doch", "bleibt", "sein", "Gast", "Saal", "leer", "/", "drumb", "steckt", "der", "heis\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "NN", "ADJD", "$(", "PAV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "grim ", "tokens": ["grim"], "token_info": ["word"], "pos": ["XY"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Jhm Rach vnd Eyver an vnd st\u00f6st die Donnerstim", "tokens": ["Jhm", "Rach", "vnd", "Ey\u00b7ver", "an", "vnd", "st\u00f6st", "die", "Don\u00b7ner\u00b7stim"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "KON", "NN", "PTKVZ", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch seine Lippen vor. Verflucht die mich nicht h\u00f6ren", "tokens": ["Durch", "sei\u00b7ne", "Lip\u00b7pen", "vor", ".", "Ver\u00b7flucht", "die", "mich", "nicht", "h\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$.", "NN", "ART", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wer nicht mein bitten acht/ sol/ schwer ich/ f\u00fcr vnd f\u00fcr", "tokens": ["Wer", "nicht", "mein", "bit\u00b7ten", "acht", "/", "sol", "/", "schwer", "ich", "/", "f\u00fcr", "vnd", "f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "PPOSAT", "ADJA", "CARD", "$(", "VMFIN", "$(", "PWS", "PPER", "$(", "APPR", "KON", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In h\u00f6chste noth vnd schmach verbannet seyn von mir", "tokens": ["In", "h\u00f6chs\u00b7te", "noth", "vnd", "schmach", "ver\u00b7ban\u00b7net", "seyn", "von", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJD", "VVPP", "VAINF", "APPR", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich wil in ewigkeit/ die mich verlacht/ nicht ehren.", "tokens": ["Ich", "wil", "in", "e\u00b7wig\u00b7keit", "/", "die", "mich", "ver\u00b7lacht", "/", "nicht", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "$(", "PRELS", "PPER", "VVPP", "$(", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}