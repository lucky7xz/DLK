{"textgrid.poem.40582": {"metadata": {"author": {"name": "Gr\u00fcn, Anastasius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Vorhang rauscht und fliegt empor,", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Vorhang rauscht und fliegt empor,", "tokens": ["Der", "Vor\u00b7hang", "rauscht", "und", "fliegt", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein alter Gaukler tritt hervor,", "tokens": ["Ein", "al\u00b7ter", "Gauk\u00b7ler", "tritt", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Flitter sattsam ausstaffirt,", "tokens": ["Mit", "Flit\u00b7ter", "satt\u00b7sam", "aus\u00b7staf\u00b7firt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein ehrlich Antlitz roth beschmiert.", "tokens": ["Sein", "ehr\u00b7lich", "Ant\u00b7litz", "roth", "be\u00b7schmiert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Du alter Mann mit dem wei\u00dfen Haar,", "tokens": ["Du", "al\u00b7ter", "Mann", "mit", "dem", "wei\u00b7\u00dfen", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie dauerst du mich im Herzen gar,", "tokens": ["Wie", "dau\u00b7erst", "du", "mich", "im", "Her\u00b7zen", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "APPRART", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der du vorm Grabe gaukelnd springst,", "tokens": ["Der", "du", "vorm", "Gra\u00b7be", "gau\u00b7kelnd", "springst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPRART", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit du vom P\u00f6bel ein L\u00e4cheln erzwingst!", "tokens": ["Da\u00b7mit", "du", "vom", "P\u00f6\u00b7bel", "ein", "L\u00e4\u00b7cheln", "er\u00b7zwingst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.3": {"line.1": {"text": "Ein L\u00e4cheln \u00fcber ein greises Haar", "tokens": ["Ein", "L\u00e4\u00b7cheln", "\u00fc\u00b7ber", "ein", "grei\u00b7ses", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und \u00fcber die nahe Todtenbahr'!", "tokens": ["Und", "\u00fc\u00b7ber", "die", "na\u00b7he", "Tod\u00b7ten\u00b7bahr'", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die\u00df eines Lebens h\u00f6chster Preis!", "tokens": ["Die\u00df", "ei\u00b7nes", "Le\u00b7bens", "h\u00f6chs\u00b7ter", "Preis", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des deinen, armer, armer Greis!", "tokens": ["Des", "dei\u00b7nen", ",", "ar\u00b7mer", ",", "ar\u00b7mer", "Greis", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "$,", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Des Greises Hirn ist schwach und alt,", "tokens": ["Des", "Grei\u00b7ses", "Hirn", "ist", "schwach", "und", "alt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Liebsten selbst vergi\u00dft er bald;", "tokens": ["Der", "Liebs\u00b7ten", "selbst", "ver\u00b7gi\u00dft", "er", "bald", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du aber zw\u00e4ngst mit M\u00fch' und Pein", "tokens": ["Du", "a\u00b7ber", "zw\u00e4ngst", "mit", "M\u00fch'", "und", "Pein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch eitlen Floskelkram hinein.", "tokens": ["Noch", "eit\u00b7len", "Flos\u00b7kel\u00b7kram", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Des Greises Arm ist abgespannt,", "tokens": ["Des", "Grei\u00b7ses", "Arm", "ist", "ab\u00b7ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man sieht nur noch die m\u00fcde Hand", "tokens": ["Man", "sieht", "nur", "noch", "die", "m\u00fc\u00b7de", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum Segen f\u00fcr Kind und Enkel erh\u00f6ht", "tokens": ["Zum", "Se\u00b7gen", "f\u00fcr", "Kind", "und", "En\u00b7kel", "er\u00b7h\u00f6ht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "VVPP"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und fromm gefaltet zum Gebet.", "tokens": ["Und", "fromm", "ge\u00b7fal\u00b7tet", "zum", "Ge\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Doch deine Hand schl\u00e4gt fort und fort", "tokens": ["Doch", "dei\u00b7ne", "Hand", "schl\u00e4gt", "fort", "und", "fort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den tollen Takt zu w\u00fcstem Wort,", "tokens": ["Den", "tol\u00b7len", "Takt", "zu", "w\u00fcs\u00b7tem", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und all' die M\u00fche, armer Mann,", "tokens": ["Und", "all'", "die", "M\u00fc\u00b7he", ",", "ar\u00b7mer", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PIS", "ART", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit der P\u00f6bel lachen kann.", "tokens": ["Da\u00b7mit", "der", "P\u00f6\u00b7bel", "la\u00b7chen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Und schmerzt dich auch dein morsch Gebein,", "tokens": ["Und", "schmerzt", "dich", "auch", "dein", "morsch", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ei was, 's ist l\u00e4ngst ja nimmer dein!", "tokens": ["Ei", "was", ",", "'s", "ist", "l\u00e4ngst", "ja", "nim\u00b7mer", "dein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWS", "$,", "PPER", "VAFIN", "ADV", "ADV", "ADV", "PPOSAT", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Du magst wohl weinen, alter Mann,", "tokens": ["Du", "magst", "wohl", "wei\u00b7nen", ",", "al\u00b7ter", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn nur die Menge lachen kann!", "tokens": ["Wenn", "nur", "die", "Men\u00b7ge", "la\u00b7chen", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Der Greis sich in den Lehnstuhl setzt,", "tokens": ["Der", "Greis", "sich", "in", "den", "Lehn\u00b7stuhl", "setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ei, wie das seine Glieder letzt!", "tokens": ["Ei", ",", "wie", "das", "sei\u00b7ne", "Glie\u00b7der", "letzt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PDS", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbder macht sich's auch bequem, f\u00fcrwahr!\u00ab", "tokens": ["\u00bb", "der", "macht", "sich's", "auch", "be\u00b7quem", ",", "f\u00fcr\u00b7wahr", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "ART", "VVFIN", "PIS", "ADV", "ADJD", "$,", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So murmelt's sp\u00f6ttisch durch die Schaar.", "tokens": ["So", "mur\u00b7melt's", "sp\u00f6t\u00b7tisch", "durch", "die", "Schaar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Mit leisem abgebrochnen Ton", "tokens": ["Mit", "lei\u00b7sem", "ab\u00b7ge\u00b7broch\u00b7nen", "Ton"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beginnt er m\u00fchsam seinen Sermon.", "tokens": ["Be\u00b7ginnt", "er", "m\u00fch\u00b7sam", "sei\u00b7nen", "Ser\u00b7mon", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbder h\u00e4lt nun auch kein Schlagwort mehr!\u00ab", "tokens": ["\u00bb", "der", "h\u00e4lt", "nun", "auch", "kein", "Schlag\u00b7wort", "mehr", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "VVFIN", "ADV", "ADV", "PIAT", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So z\u00fcrnt es strafend ringsumher.", "tokens": ["So", "z\u00fcrnt", "es", "stra\u00b7fend", "rings\u00b7um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der Greis lallt nur manch tonlos Wort,", "tokens": ["Der", "Greis", "lallt", "nur", "manch", "ton\u00b7los", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIAT", "ADJD", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Die Stimme bebt, es will nicht fort;", "tokens": ["Die", "Stim\u00b7me", "bebt", ",", "es", "will", "nicht", "fort", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Noch ist sein Spruch nicht ganz heraus", "tokens": ["Noch", "ist", "sein", "Spruch", "nicht", "ganz", "he\u00b7raus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da schweigt er, als ging sein Athem aus.", "tokens": ["Da", "schweigt", "er", ",", "als", "ging", "sein", "A\u00b7them", "aus", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Das Gl\u00f6cklein schellt, der Vorhang sinkt,", "tokens": ["Das", "Gl\u00f6c\u00b7klein", "schellt", ",", "der", "Vor\u00b7hang", "sinkt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ahnt's, da\u00df ein Todtengl\u00f6cklein klingt?", "tokens": ["Wer", "ahnt's", ",", "da\u00df", "ein", "Tod\u00b7ten\u00b7gl\u00f6c\u00b7klein", "klingt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Menge trommelt und pfeift dabei,", "tokens": ["Die", "Men\u00b7ge", "trom\u00b7melt", "und", "pfeift", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "PAV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wer ahnt's da\u00df ein Leichenlied die\u00df sei?", "tokens": ["Wer", "ahnt's", "da\u00df", "ein", "Lei\u00b7chen\u00b7lied", "die\u00df", "sei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KOUS", "ART", "NN", "PDS", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Der Alte lehnt im Stuhle todt,", "tokens": ["Der", "Al\u00b7te", "lehnt", "im", "Stuh\u00b7le", "todt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch Leben heuchelt der Schminke Roth,", "tokens": ["Doch", "Le\u00b7ben", "heu\u00b7chelt", "der", "Schmin\u00b7ke", "Roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die auf dem Antlitz bla\u00df und kalt,", "tokens": ["Die", "auf", "dem", "Ant\u00b7litz", "bla\u00df", "und", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie eine gro\u00dfe L\u00fcge, prahlt.", "tokens": ["Wie", "ei\u00b7ne", "gro\u00b7\u00dfe", "L\u00fc\u00b7ge", ",", "prahlt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Sie blieb auf des Alten Angesicht,", "tokens": ["Sie", "blieb", "auf", "des", "Al\u00b7ten", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie eine Grabschrift, die da spricht,", "tokens": ["Wie", "ei\u00b7ne", "Grab\u00b7schrift", ",", "die", "da", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df Alles Lug und Trug und Dunst,", "tokens": ["Da\u00df", "Al\u00b7les", "Lug", "und", "Trug", "und", "Dunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NE", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Leben, Treiben, seine Kunst!", "tokens": ["Sein", "Le\u00b7ben", ",", "Trei\u00b7ben", ",", "sei\u00b7ne", "Kunst", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Sein Wald, gemalt auf Leinwand gr\u00fcn,", "tokens": ["Sein", "Wald", ",", "ge\u00b7malt", "auf", "Lein\u00b7wand", "gr\u00fcn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVPP", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rauscht \u00fcber sein Grab nicht klagend hin!", "tokens": ["Rauscht", "\u00fc\u00b7ber", "sein", "Grab", "nicht", "kla\u00b7gend", "hin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es ist sein \u00f6lgetr\u00e4nkter Mond", "tokens": ["Es", "ist", "sein", "\u00f6l\u00b7ge\u00b7tr\u00e4nk\u00b7ter", "Mond"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um Todte zu weinen nicht gewohnt.", "tokens": ["Um", "Tod\u00b7te", "zu", "wei\u00b7nen", "nicht", "ge\u00b7wohnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "PTKZU", "VVINF", "PTKNEG", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Die Kunstgenossen umstehn den Greis,", "tokens": ["Die", "Kunst\u00b7ge\u00b7nos\u00b7sen", "um\u00b7stehn", "den", "Greis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und Einer spricht zu seinem Preis:", "tokens": ["Und", "Ei\u00b7ner", "spricht", "zu", "sei\u00b7nem", "Preis", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbheil ihm, denn, traun, ein Held ist der,", "tokens": ["\u00bb", "heil", "ihm", ",", "denn", ",", "traun", ",", "ein", "Held", "ist", "der", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "$,", "KON", "$,", "VVINF", "$,", "ART", "NN", "VAFIN", "ART", "$,"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.4": {"text": "Der auf dem Schlachtfeld fiel, wie er!\u00ab", "tokens": ["Der", "auf", "dem", "Schlacht\u00b7feld", "fiel", ",", "wie", "er", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "$.", "$("], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.16": {"line.1": {"text": "Ein Gauklerdirnlein als Muse gar", "tokens": ["Ein", "Gauk\u00b7ler\u00b7dirn\u00b7lein", "als", "Mu\u00b7se", "gar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KOUS", "NN", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Legt dann dem Greis ins Silberhaar", "tokens": ["Legt", "dann", "dem", "Greis", "ins", "Sil\u00b7ber\u00b7haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den gr\u00fcnpapiernen Lorbeerkranz,", "tokens": ["Den", "gr\u00fcn\u00b7pa\u00b7pier\u00b7nen", "Lor\u00b7beer\u00b7kranz", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom vielen Gebrauch zerknittert ganz.", "tokens": ["Vom", "vie\u00b7len", "Ge\u00b7brauch", "zer\u00b7knit\u00b7tert", "ganz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "PIAT", "NN", "VVFIN", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Zwei M\u00e4nner sind sein Leichenzug,", "tokens": ["Zwei", "M\u00e4n\u00b7ner", "sind", "sein", "Lei\u00b7chen\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die sind, den Sarg zu tragen, genug;", "tokens": ["Die", "sind", ",", "den", "Sarg", "zu", "tra\u00b7gen", ",", "ge\u00b7nug", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,", "ADV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und als sie ihn zu Grabe gebracht,", "tokens": ["Und", "als", "sie", "ihn", "zu", "Gra\u00b7be", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Hat Niemand geweint und Niemand gelacht.", "tokens": ["Hat", "Nie\u00b7mand", "ge\u00b7weint", "und", "Nie\u00b7mand", "ge\u00b7lacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVPP", "KON", "PIS", "VVPP", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Der Vorhang rauscht und fliegt empor,", "tokens": ["Der", "Vor\u00b7hang", "rauscht", "und", "fliegt", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein alter Gaukler tritt hervor,", "tokens": ["Ein", "al\u00b7ter", "Gauk\u00b7ler", "tritt", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Flitter sattsam ausstaffirt,", "tokens": ["Mit", "Flit\u00b7ter", "satt\u00b7sam", "aus\u00b7staf\u00b7firt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein ehrlich Antlitz roth beschmiert.", "tokens": ["Sein", "ehr\u00b7lich", "Ant\u00b7litz", "roth", "be\u00b7schmiert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Du alter Mann mit dem wei\u00dfen Haar,", "tokens": ["Du", "al\u00b7ter", "Mann", "mit", "dem", "wei\u00b7\u00dfen", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie dauerst du mich im Herzen gar,", "tokens": ["Wie", "dau\u00b7erst", "du", "mich", "im", "Her\u00b7zen", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "APPRART", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der du vorm Grabe gaukelnd springst,", "tokens": ["Der", "du", "vorm", "Gra\u00b7be", "gau\u00b7kelnd", "springst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPRART", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit du vom P\u00f6bel ein L\u00e4cheln erzwingst!", "tokens": ["Da\u00b7mit", "du", "vom", "P\u00f6\u00b7bel", "ein", "L\u00e4\u00b7cheln", "er\u00b7zwingst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.20": {"line.1": {"text": "Ein L\u00e4cheln \u00fcber ein greises Haar", "tokens": ["Ein", "L\u00e4\u00b7cheln", "\u00fc\u00b7ber", "ein", "grei\u00b7ses", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und \u00fcber die nahe Todtenbahr'!", "tokens": ["Und", "\u00fc\u00b7ber", "die", "na\u00b7he", "Tod\u00b7ten\u00b7bahr'", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die\u00df eines Lebens h\u00f6chster Preis!", "tokens": ["Die\u00df", "ei\u00b7nes", "Le\u00b7bens", "h\u00f6chs\u00b7ter", "Preis", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des deinen, armer, armer Greis!", "tokens": ["Des", "dei\u00b7nen", ",", "ar\u00b7mer", ",", "ar\u00b7mer", "Greis", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "$,", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Des Greises Hirn ist schwach und alt,", "tokens": ["Des", "Grei\u00b7ses", "Hirn", "ist", "schwach", "und", "alt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Liebsten selbst vergi\u00dft er bald;", "tokens": ["Der", "Liebs\u00b7ten", "selbst", "ver\u00b7gi\u00dft", "er", "bald", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du aber zw\u00e4ngst mit M\u00fch' und Pein", "tokens": ["Du", "a\u00b7ber", "zw\u00e4ngst", "mit", "M\u00fch'", "und", "Pein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch eitlen Floskelkram hinein.", "tokens": ["Noch", "eit\u00b7len", "Flos\u00b7kel\u00b7kram", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Des Greises Arm ist abgespannt,", "tokens": ["Des", "Grei\u00b7ses", "Arm", "ist", "ab\u00b7ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man sieht nur noch die m\u00fcde Hand", "tokens": ["Man", "sieht", "nur", "noch", "die", "m\u00fc\u00b7de", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum Segen f\u00fcr Kind und Enkel erh\u00f6ht", "tokens": ["Zum", "Se\u00b7gen", "f\u00fcr", "Kind", "und", "En\u00b7kel", "er\u00b7h\u00f6ht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "VVPP"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und fromm gefaltet zum Gebet.", "tokens": ["Und", "fromm", "ge\u00b7fal\u00b7tet", "zum", "Ge\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.23": {"line.1": {"text": "Doch deine Hand schl\u00e4gt fort und fort", "tokens": ["Doch", "dei\u00b7ne", "Hand", "schl\u00e4gt", "fort", "und", "fort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den tollen Takt zu w\u00fcstem Wort,", "tokens": ["Den", "tol\u00b7len", "Takt", "zu", "w\u00fcs\u00b7tem", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und all' die M\u00fche, armer Mann,", "tokens": ["Und", "all'", "die", "M\u00fc\u00b7he", ",", "ar\u00b7mer", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PIS", "ART", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit der P\u00f6bel lachen kann.", "tokens": ["Da\u00b7mit", "der", "P\u00f6\u00b7bel", "la\u00b7chen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.24": {"line.1": {"text": "Und schmerzt dich auch dein morsch Gebein,", "tokens": ["Und", "schmerzt", "dich", "auch", "dein", "morsch", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ei was, 's ist l\u00e4ngst ja nimmer dein!", "tokens": ["Ei", "was", ",", "'s", "ist", "l\u00e4ngst", "ja", "nim\u00b7mer", "dein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWS", "$,", "PPER", "VAFIN", "ADV", "ADV", "ADV", "PPOSAT", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Du magst wohl weinen, alter Mann,", "tokens": ["Du", "magst", "wohl", "wei\u00b7nen", ",", "al\u00b7ter", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn nur die Menge lachen kann!", "tokens": ["Wenn", "nur", "die", "Men\u00b7ge", "la\u00b7chen", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Der Greis sich in den Lehnstuhl setzt,", "tokens": ["Der", "Greis", "sich", "in", "den", "Lehn\u00b7stuhl", "setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ei, wie das seine Glieder letzt!", "tokens": ["Ei", ",", "wie", "das", "sei\u00b7ne", "Glie\u00b7der", "letzt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PDS", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbder macht sich's auch bequem, f\u00fcrwahr!\u00ab", "tokens": ["\u00bb", "der", "macht", "sich's", "auch", "be\u00b7quem", ",", "f\u00fcr\u00b7wahr", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "ART", "VVFIN", "PIS", "ADV", "ADJD", "$,", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So murmelt's sp\u00f6ttisch durch die Schaar.", "tokens": ["So", "mur\u00b7melt's", "sp\u00f6t\u00b7tisch", "durch", "die", "Schaar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Mit leisem abgebrochnen Ton", "tokens": ["Mit", "lei\u00b7sem", "ab\u00b7ge\u00b7broch\u00b7nen", "Ton"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beginnt er m\u00fchsam seinen Sermon.", "tokens": ["Be\u00b7ginnt", "er", "m\u00fch\u00b7sam", "sei\u00b7nen", "Ser\u00b7mon", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbder h\u00e4lt nun auch kein Schlagwort mehr!\u00ab", "tokens": ["\u00bb", "der", "h\u00e4lt", "nun", "auch", "kein", "Schlag\u00b7wort", "mehr", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "VVFIN", "ADV", "ADV", "PIAT", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So z\u00fcrnt es strafend ringsumher.", "tokens": ["So", "z\u00fcrnt", "es", "stra\u00b7fend", "rings\u00b7um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Der Greis lallt nur manch tonlos Wort,", "tokens": ["Der", "Greis", "lallt", "nur", "manch", "ton\u00b7los", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIAT", "ADJD", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Die Stimme bebt, es will nicht fort;", "tokens": ["Die", "Stim\u00b7me", "bebt", ",", "es", "will", "nicht", "fort", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Noch ist sein Spruch nicht ganz heraus", "tokens": ["Noch", "ist", "sein", "Spruch", "nicht", "ganz", "he\u00b7raus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da schweigt er, als ging sein Athem aus.", "tokens": ["Da", "schweigt", "er", ",", "als", "ging", "sein", "A\u00b7them", "aus", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.28": {"line.1": {"text": "Das Gl\u00f6cklein schellt, der Vorhang sinkt,", "tokens": ["Das", "Gl\u00f6c\u00b7klein", "schellt", ",", "der", "Vor\u00b7hang", "sinkt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ahnt's, da\u00df ein Todtengl\u00f6cklein klingt?", "tokens": ["Wer", "ahnt's", ",", "da\u00df", "ein", "Tod\u00b7ten\u00b7gl\u00f6c\u00b7klein", "klingt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Menge trommelt und pfeift dabei,", "tokens": ["Die", "Men\u00b7ge", "trom\u00b7melt", "und", "pfeift", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "PAV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wer ahnt's da\u00df ein Leichenlied die\u00df sei?", "tokens": ["Wer", "ahnt's", "da\u00df", "ein", "Lei\u00b7chen\u00b7lied", "die\u00df", "sei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KOUS", "ART", "NN", "PDS", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.29": {"line.1": {"text": "Der Alte lehnt im Stuhle todt,", "tokens": ["Der", "Al\u00b7te", "lehnt", "im", "Stuh\u00b7le", "todt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch Leben heuchelt der Schminke Roth,", "tokens": ["Doch", "Le\u00b7ben", "heu\u00b7chelt", "der", "Schmin\u00b7ke", "Roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die auf dem Antlitz bla\u00df und kalt,", "tokens": ["Die", "auf", "dem", "Ant\u00b7litz", "bla\u00df", "und", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie eine gro\u00dfe L\u00fcge, prahlt.", "tokens": ["Wie", "ei\u00b7ne", "gro\u00b7\u00dfe", "L\u00fc\u00b7ge", ",", "prahlt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Sie blieb auf des Alten Angesicht,", "tokens": ["Sie", "blieb", "auf", "des", "Al\u00b7ten", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie eine Grabschrift, die da spricht,", "tokens": ["Wie", "ei\u00b7ne", "Grab\u00b7schrift", ",", "die", "da", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df Alles Lug und Trug und Dunst,", "tokens": ["Da\u00df", "Al\u00b7les", "Lug", "und", "Trug", "und", "Dunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NE", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Leben, Treiben, seine Kunst!", "tokens": ["Sein", "Le\u00b7ben", ",", "Trei\u00b7ben", ",", "sei\u00b7ne", "Kunst", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Sein Wald, gemalt auf Leinwand gr\u00fcn,", "tokens": ["Sein", "Wald", ",", "ge\u00b7malt", "auf", "Lein\u00b7wand", "gr\u00fcn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVPP", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rauscht \u00fcber sein Grab nicht klagend hin!", "tokens": ["Rauscht", "\u00fc\u00b7ber", "sein", "Grab", "nicht", "kla\u00b7gend", "hin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es ist sein \u00f6lgetr\u00e4nkter Mond", "tokens": ["Es", "ist", "sein", "\u00f6l\u00b7ge\u00b7tr\u00e4nk\u00b7ter", "Mond"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um Todte zu weinen nicht gewohnt.", "tokens": ["Um", "Tod\u00b7te", "zu", "wei\u00b7nen", "nicht", "ge\u00b7wohnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "PTKZU", "VVINF", "PTKNEG", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.32": {"line.1": {"text": "Die Kunstgenossen umstehn den Greis,", "tokens": ["Die", "Kunst\u00b7ge\u00b7nos\u00b7sen", "um\u00b7stehn", "den", "Greis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und Einer spricht zu seinem Preis:", "tokens": ["Und", "Ei\u00b7ner", "spricht", "zu", "sei\u00b7nem", "Preis", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbheil ihm, denn, traun, ein Held ist der,", "tokens": ["\u00bb", "heil", "ihm", ",", "denn", ",", "traun", ",", "ein", "Held", "ist", "der", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "$,", "KON", "$,", "VVINF", "$,", "ART", "NN", "VAFIN", "ART", "$,"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.4": {"text": "Der auf dem Schlachtfeld fiel, wie er!\u00ab", "tokens": ["Der", "auf", "dem", "Schlacht\u00b7feld", "fiel", ",", "wie", "er", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "$.", "$("], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.33": {"line.1": {"text": "Ein Gauklerdirnlein als Muse gar", "tokens": ["Ein", "Gauk\u00b7ler\u00b7dirn\u00b7lein", "als", "Mu\u00b7se", "gar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KOUS", "NN", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Legt dann dem Greis ins Silberhaar", "tokens": ["Legt", "dann", "dem", "Greis", "ins", "Sil\u00b7ber\u00b7haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den gr\u00fcnpapiernen Lorbeerkranz,", "tokens": ["Den", "gr\u00fcn\u00b7pa\u00b7pier\u00b7nen", "Lor\u00b7beer\u00b7kranz", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom vielen Gebrauch zerknittert ganz.", "tokens": ["Vom", "vie\u00b7len", "Ge\u00b7brauch", "zer\u00b7knit\u00b7tert", "ganz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "PIAT", "NN", "VVFIN", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.34": {"line.1": {"text": "Zwei M\u00e4nner sind sein Leichenzug,", "tokens": ["Zwei", "M\u00e4n\u00b7ner", "sind", "sein", "Lei\u00b7chen\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die sind, den Sarg zu tragen, genug;", "tokens": ["Die", "sind", ",", "den", "Sarg", "zu", "tra\u00b7gen", ",", "ge\u00b7nug", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,", "ADV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und als sie ihn zu Grabe gebracht,", "tokens": ["Und", "als", "sie", "ihn", "zu", "Gra\u00b7be", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Hat Niemand geweint und Niemand gelacht.", "tokens": ["Hat", "Nie\u00b7mand", "ge\u00b7weint", "und", "Nie\u00b7mand", "ge\u00b7lacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVPP", "KON", "PIS", "VVPP", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}}}}