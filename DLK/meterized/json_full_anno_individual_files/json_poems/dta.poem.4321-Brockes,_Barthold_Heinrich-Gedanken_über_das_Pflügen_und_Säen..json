{"dta.poem.4321": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Gedanken \u00fcber das Pfl\u00fcgen und  \n S\u00e4en.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jm Herbst, an einem sch\u00f6nen Tage, sah ich, mit innigem", "tokens": ["Jm", "Herbst", ",", "an", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Ta\u00b7ge", ",", "sah", "ich", ",", "mit", "in\u00b7ni\u00b7gem"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,", "VVFIN", "PPER", "$,", "APPR", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Vergn\u00fcgen,", "tokens": ["Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Den Bauknecht mit vier starken Pferden gesch\u00e4ftig meinen", "tokens": ["Den", "Bauk\u00b7necht", "mit", "vier", "star\u00b7ken", "Pfer\u00b7den", "ge\u00b7sch\u00e4f\u00b7tig", "mei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "CARD", "ADJA", "NN", "ADJD", "PPOSAT"], "meter": "-+--++-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Acker pfl\u00fcgen,", "tokens": ["A\u00b7cker", "pfl\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Ich sah ihn lange Furchen zieh\u2019n, und sah den Pflug, wie", "tokens": ["Ich", "sah", "ihn", "lan\u00b7ge", "Fur\u00b7chen", "zieh'n", ",", "und", "sah", "den", "Pflug", ",", "wie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "NN", "VVINF", "$,", "KON", "VVFIN", "ART", "NN", "$,", "PWAV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "sanft er glitte,", "tokens": ["sanft", "er", "glit\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Den Boden von einander theilt\u2019, den fest- und fetten", "tokens": ["Den", "Bo\u00b7den", "von", "ein\u00b7an\u00b7der", "theilt'", ",", "den", "fest", "und", "fet\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PRF", "VVFIN", "$,", "ART", "TRUNC", "KON", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Grund durchschnitte,", "tokens": ["Grund", "durch\u00b7schnit\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Besch\u00e4ftigt alles umzust\u00fcrzen, und kleine Wellen zu er-", "tokens": ["Be\u00b7sch\u00e4f\u00b7tigt", "al\u00b7les", "um\u00b7zus\u00b7t\u00fcr\u00b7zen", ",", "und", "klei\u00b7ne", "Wel\u00b7len", "zu", "er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "VVIZU", "$,", "KON", "ADJA", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "h\u00f6h'n,", "tokens": ["h\u00f6h'n", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.11": {"text": "Die in geraden Strichen all\u2019, ohn\u2019 einige Bewegung,", "tokens": ["Die", "in", "ge\u00b7ra\u00b7den", "Stri\u00b7chen", "all'", ",", "ohn'", "ei\u00b7ni\u00b7ge", "Be\u00b7we\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "PIS", "$,", "KOUI", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.12": {"text": "steh'n,", "tokens": ["steh'n", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-", "measure": "single.down"}, "line.13": {"text": "Und \u00fcberall das Feld erf\u00fcllen. Ich sah dadurch das", "tokens": ["Und", "\u00fc\u00b7be\u00b7rall", "das", "Feld", "er\u00b7f\u00fcl\u00b7len", ".", "Ich", "sah", "da\u00b7durch", "das"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VVINF", "$.", "PPER", "VVFIN", "PAV", "ART"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Grau der Erden,", "tokens": ["Grau", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.15": {"text": "Jm kurzen, in ein sch\u00f6nes Braun verkehrt und lieblich", "tokens": ["Jm", "kur\u00b7zen", ",", "in", "ein", "sch\u00f6\u00b7nes", "Braun", "ver\u00b7kehrt", "und", "lieb\u00b7lich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "$,", "APPR", "ART", "ADJA", "NN", "VVPP", "KON", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "dunkel werden.", "tokens": ["dun\u00b7kel", "wer\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VAINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.17": {"text": "Ich setzte mich an einen H\u00fcgel, der Arbeit, die so n\u00fctz", "tokens": ["Ich", "setz\u00b7te", "mich", "an", "ei\u00b7nen", "H\u00fc\u00b7gel", ",", "der", "Ar\u00b7beit", ",", "die", "so", "n\u00fctz"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "ART", "NN", "$,", "PRELS", "ADV", "ADJD"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.18": {"text": "als sch\u00f6n,", "tokens": ["als", "sch\u00f6n", ","], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "ADJD", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.19": {"text": "Mit einigen Betrachtungen, zu GOttes Ehren, zuzu-", "tokens": ["Mit", "ei\u00b7ni\u00b7gen", "Be\u00b7trach\u00b7tun\u00b7gen", ",", "zu", "Got\u00b7tes", "Eh\u00b7ren", ",", "zu\u00b7zu"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "NN", "NN", "$,", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.20": {"text": "seh'n.", "tokens": ["seh'", "n."], "token_info": ["word", "abbreviation"], "pos": ["XY", "XY"], "meter": "+", "measure": "single.up"}, "line.21": {"text": "Ich dachte: Welche Weisheit liegt in diesem so geringen", "tokens": ["Ich", "dach\u00b7te", ":", "Wel\u00b7che", "Weis\u00b7heit", "liegt", "in", "die\u00b7sem", "so", "ge\u00b7rin\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "PWAT", "NN", "VVFIN", "APPR", "PDAT", "ADV", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.22": {"text": "Werke,", "tokens": ["Wer\u00b7ke", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.23": {"text": "Welch ein erstaunlich grosser Nutz! Je mehr ich mit Be-", "tokens": ["Welch", "ein", "er\u00b7staun\u00b7lich", "gros\u00b7ser", "Nutz", "!", "Je", "mehr", "ich", "mit", "Be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ART", "ADJD", "ADJA", "NN", "$.", "ADV", "ADV", "PPER", "APPR", "TRUNC"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.24": {"text": "dacht bemerke,", "tokens": ["dacht", "be\u00b7mer\u00b7ke", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.25": {"text": "Je mehr erblick ich in demselben, bey g\u00f6ttlicher Gewo-", "tokens": ["Je", "mehr", "er\u00b7blick", "ich", "in", "dem\u00b7sel\u00b7ben", ",", "bey", "g\u00f6tt\u00b7li\u00b7cher", "Ge\u00b7wo"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "PDAT", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.26": {"text": "genheit,", "tokens": ["ge\u00b7nheit", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.27": {"text": "Abseiten unser, abermahl unleidlich\u2019 Unerkenntlichkeit.", "tokens": ["Ab\u00b7sei\u00b7ten", "un\u00b7ser", ",", "a\u00b7ber\u00b7mahl", "un\u00b7leid\u00b7lich'", "Un\u00b7er\u00b7kennt\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "$,", "ADV", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.2": {"line.1": {"text": "Wer w\u00fcrdigt doch wohl einen Pflug des Anblicks! wer", "tokens": ["Wer", "w\u00fcr\u00b7digt", "doch", "wohl", "ei\u00b7nen", "Pflug", "des", "An\u00b7blicks", "!", "wer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "ART", "NN", "ART", "NN", "$.", "PWS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "betrachtet ihn!", "tokens": ["be\u00b7trach\u00b7tet", "ihn", "!"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Man h\u00e4lt ihn f\u00fcr ein plumpes Werkzeug, man zieht von", "tokens": ["Man", "h\u00e4lt", "ihn", "f\u00fcr", "ein", "plum\u00b7pes", "Werk\u00b7zeug", ",", "man", "zieht", "von"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,", "PIS", "VVFIN", "APPR"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "ihm so gleich den Blick", "tokens": ["ihm", "so", "gleich", "den", "Blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "(als w\u00e4r es schimpflich ihn zu seh\u2019n, man mag ihn stehen,", "tokens": ["(", "als", "w\u00e4r", "es", "schimpf\u00b7lich", "ihn", "zu", "seh'n", ",", "man", "mag", "ihn", "ste\u00b7hen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "VAFIN", "PPER", "ADJD", "PPER", "PTKZU", "VVINF", "$,", "PIS", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "oder zieh'n,", "tokens": ["o\u00b7der", "zieh'n", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Zu Haus, und auf dem Felde, seh\u2019n) ver\u00e4chtlich mehren-", "tokens": ["Zu", "Haus", ",", "und", "auf", "dem", "Fel\u00b7de", ",", "seh'n", ")", "ver\u00b7\u00e4cht\u00b7lich", "meh\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$,", "KON", "APPR", "ART", "NN", "$,", "VVINF", "$(", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "theils zur\u00fcck.", "tokens": ["theils", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Da er doch nicht allein so n\u00fctzlich und n\u00f6htig; da er in", "tokens": ["Da", "er", "doch", "nicht", "al\u00b7lein", "so", "n\u00fctz\u00b7lich", "und", "n\u00f6h\u00b7tig", ";", "da", "er", "in"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "ADV", "ADV", "ADJD", "KON", "ADJD", "$.", "KOUS", "PPER", "APPR"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "der That", "tokens": ["der", "That"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "Weit mehr, als wie man glauben sollte, viel k\u00fcnstliches", "tokens": ["Weit", "mehr", ",", "als", "wie", "man", "glau\u00b7ben", "soll\u00b7te", ",", "viel", "k\u00fcnst\u00b7li\u00b7ches"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "ADV", "$,", "KOUS", "PWAV", "PIS", "VVINF", "VMFIN", "$,", "PIAT", "ADJA"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "noch an sich hat.", "tokens": ["noch", "an", "sich", "hat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PRF", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "Ich lie\u00df mir alle St\u00fccke nennen, und alle seine Theil", "tokens": ["Ich", "lie\u00df", "mir", "al\u00b7le", "St\u00fc\u00b7cke", "nen\u00b7nen", ",", "und", "al\u00b7le", "sei\u00b7ne", "Theil"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "VVINF", "$,", "KON", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.14": {"text": "weisen,", "tokens": ["wei\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.15": {"text": "Und fand ", "tokens": ["Und", "fand"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.16": {"text": "Pflug-Baum, Vorder-Eisen,", "tokens": ["Pflug\u00b7Baum", ",", "Vor\u00b7der\u00b7Ei\u00b7sen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.17": {"text": "Den Nagel, Gradsuhl, Grad, den Sterz, die Unter-", "tokens": ["Den", "Na\u00b7gel", ",", "Grad\u00b7suhl", ",", "Grad", ",", "den", "Sterz", ",", "die", "Un\u00b7ter"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NE", "$,", "NN", "$,", "NN", "$,", "ART", "NN", "$,", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Sahl, die Seiten-Sahl,", "tokens": ["Sahl", ",", "die", "Sei\u00b7ten\u00b7Sahl", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.19": {"text": "Das Ruster-Brett, das Seiten-Eisen, die Pflug-", "tokens": ["Das", "Rus\u00b7ter\u00b7Brett", ",", "das", "Sei\u00b7ten\u00b7Ei\u00b7sen", ",", "die", "Pflug"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "TRUNC"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.20": {"text": "Butt, Pfiug-Schaar, Welle-Stecher,", "tokens": ["Butt", ",", "Pfiug\u00b7Schaar", ",", "Wel\u00b7le\u00b7Ste\u00b7cher", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Den der, so pfl\u00fcgt, in H\u00e4nden f\u00fchrt, mit welchen er auch", "tokens": ["Den", "der", ",", "so", "pfl\u00fcgt", ",", "in", "H\u00e4n\u00b7den", "f\u00fchrt", ",", "mit", "wel\u00b7chen", "er", "auch"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ART", "$,", "ADV", "VVFIN", "$,", "APPR", "NN", "VVFIN", "$,", "APPR", "PWAT", "PPER", "ADV"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.22": {"text": "\u00f6ftermahl", "tokens": ["\u00f6f\u00b7ter\u00b7mahl"], "token_info": ["word"], "pos": ["ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.23": {"text": "Die Pflug-Schaar reinigt, und zugleich den Pflug zurecht", "tokens": ["Die", "Pflug\u00b7Schaar", "rei\u00b7nigt", ",", "und", "zu\u00b7gleich", "den", "Pflug", "zu\u00b7recht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "ADV", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "setzt, welchen man,", "tokens": ["setzt", ",", "wel\u00b7chen", "man", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAT", "PIS", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.25": {"text": "Durch L\u00f6cher in dem Baum, erh\u00f6h\u2019n, und ihn, wenns", "tokens": ["Durch", "L\u00f6\u00b7cher", "in", "dem", "Baum", ",", "er\u00b7h\u00f6h'n", ",", "und", "ihn", ",", "wenns"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$,", "VVFIN", "$,", "KON", "PPER", "$,", "KOUS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "noht ist, senken kann.", "tokens": ["noht", "ist", ",", "sen\u00b7ken", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "VVINF", "VMFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Wie lange kannte wohl die Welt ein solches n\u00fctzlichs", "tokens": ["Wie", "lan\u00b7ge", "kann\u00b7te", "wohl", "die", "Welt", "ein", "sol\u00b7ches", "n\u00fctz\u00b7lichs"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN", "ADV", "ART", "NN", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Werkzeug nicht?", "tokens": ["Werk\u00b7zeug", "nicht", "?"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKNEG", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Wer war es, welcher es zuerst so ausgedacht und zuge-", "tokens": ["Wer", "war", "es", ",", "wel\u00b7cher", "es", "zu\u00b7erst", "so", "aus\u00b7ge\u00b7dacht", "und", "zu\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "ADV", "ADV", "VVPP", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "richt?", "tokens": ["richt", "?"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.5": {"text": "So viel man Nachricht davon wei\u00df, ist der Erfinder in", "tokens": ["So", "viel", "man", "Nach\u00b7richt", "da\u00b7von", "wei\u00df", ",", "ist", "der", "Er\u00b7fin\u00b7der", "in"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIS", "NN", "PAV", "VVFIN", "$,", "VAFIN", "ART", "NN", "APPR"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "den Orden", "tokens": ["den", "Or\u00b7den"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.4": {"line.1": {"text": "Der G\u00f6tter, aus Erkenntlichkeit, so gar daf\u00fcr versetzet", "tokens": ["Der", "G\u00f6t\u00b7ter", ",", "aus", "Er\u00b7kennt\u00b7lich\u00b7keit", ",", "so", "gar", "da\u00b7f\u00fcr", "ver\u00b7set\u00b7zet"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "NN", "$,", "ADV", "ADV", "PAV", "VVFIN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "worden.", "tokens": ["wor\u00b7den", "."], "token_info": ["word", "punct"], "pos": ["VAPP", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "So weit sah man die Dankbarkeit f\u00fcr die\u00df so n\u00fctzlichs", "tokens": ["So", "weit", "sah", "man", "die", "Dank\u00b7bar\u00b7keit", "f\u00fcr", "die\u00df", "so", "n\u00fctz\u00b7lichs"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "PIS", "ART", "NN", "APPR", "PDS", "ADV", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Werkzeug geh'n,", "tokens": ["Werk\u00b7zeug", "geh'n", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+--", "measure": "dactylic.init"}, "line.5": {"text": "Das wir itzt, durch Gewohnheit blind, kaum w\u00fcrdigen", "tokens": ["Das", "wir", "itzt", ",", "durch", "Ge\u00b7wohn\u00b7heit", "blind", ",", "kaum", "w\u00fcr\u00b7di\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PPER", "ADV", "$,", "APPR", "NN", "ADJD", "$,", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "recht anzuseh'n.", "tokens": ["recht", "an\u00b7zu\u00b7seh'", "n."], "token_info": ["word", "word", "abbreviation"], "pos": ["ADV", "VVFIN", "NE"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Nachdem ich dieses \u00fcberdacht\u2019; erhub ich mich, das", "tokens": ["Nach\u00b7dem", "ich", "die\u00b7ses", "\u00fc\u00b7ber\u00b7dacht'", ";", "er\u00b7hub", "ich", "mich", ",", "das"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "PDS", "VVFIN", "$.", "VVFIN", "PPER", "PRF", "$,", "PRELS"], "meter": "-+-+-+-+-+-++", "measure": "unknown.measure.septa"}, "line.2": {"text": "S\u00e4en und Egen,", "tokens": ["S\u00e4\u00b7en", "und", "E\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Mit ebenm\u00e4\u00dfiger Betrachtung, zu sehen und zu \u00fcber-", "tokens": ["Mit", "e\u00b7ben\u00b7m\u00e4\u00b7\u00dfi\u00b7ger", "Be\u00b7trach\u00b7tung", ",", "zu", "se\u00b7hen", "und", "zu", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "PTKZU", "VVINF", "KON", "APPR", "TRUNC"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "legen.", "tokens": ["le\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Da ich denn, mit vergn\u00fcgten Blicken, des S\u00e4\u2019manns", "tokens": ["Da", "ich", "denn", ",", "mit", "ver\u00b7gn\u00fcg\u00b7ten", "Bli\u00b7cken", ",", "des", "S\u00e4'\u00b7manns"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "$,", "APPR", "ADJA", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "abgeme\u00dfnen Tritt", "tokens": ["ab\u00b7ge\u00b7me\u00df\u00b7nen", "Tritt"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "In stets gerader Linie, und wie die Hand den festen", "tokens": ["In", "stets", "ge\u00b7ra\u00b7der", "Li\u00b7nie", ",", "und", "wie", "die", "Hand", "den", "fes\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,", "KON", "PWAV", "ART", "NN", "ART", "ADJA"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Schritt,", "tokens": ["Schritt", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Ohn\u2019 allen Fehl, begleitete, das aus dem Sack gegriffne", "tokens": ["Ohn'", "al\u00b7len", "Fehl", ",", "be\u00b7glei\u00b7te\u00b7te", ",", "das", "aus", "dem", "Sack", "ge\u00b7griff\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "VVFIN", "$,", "PRELS", "APPR", "ART", "NN", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.10": {"text": "Korn", "tokens": ["Korn"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.11": {"text": "In richt\u2019ger Ebenmaasse streute, da\u00df nicht zu wenig, nicht", "tokens": ["In", "richt'\u00b7ger", "E\u00b7ben\u00b7maas\u00b7se", "streu\u00b7te", ",", "da\u00df", "nicht", "zu", "we\u00b7nig", ",", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,", "KOUS", "PTKNEG", "PTKA", "PIS", "$,", "PTKNEG"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "zu viel,", "tokens": ["zu", "viel", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKA", "PIS", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.13": {"text": "Da\u00df nicht zu dicht, und nicht zu weit, der scharf geworfn", "tokens": ["Da\u00df", "nicht", "zu", "dicht", ",", "und", "nicht", "zu", "weit", ",", "der", "scharf", "ge\u00b7worfn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "PTKA", "ADJD", "$,", "KON", "PTKNEG", "PTKA", "ADJD", "$,", "PRELS", "ADJD", "VAPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Saame fiel.", "tokens": ["Saa\u00b7me", "fiel", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "Oft f\u00fcllet er von seinem R\u00fccken das weisse S\u00e4\u2019tuch, das", "tokens": ["Oft", "f\u00fcl\u00b7let", "er", "von", "sei\u00b7nem", "R\u00fc\u00b7cken", "das", "weis\u00b7se", "S\u00e4'\u00b7tuch", ",", "das"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,", "PRELS"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.16": {"text": "ihm vorn,", "tokens": ["ihm", "vorn", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "ADV", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.17": {"text": "Zum schnellen Griff, er\u00f6ffnet hing. Mir schien das", "tokens": ["Zum", "schnel\u00b7len", "Griff", ",", "er\u00b7\u00f6ff\u00b7net", "hing", ".", "Mir", "schien", "das"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$,", "VVPP", "VVFIN", "$.", "PPER", "VVFIN", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "S\u00e4en leicht zu seyn,", "tokens": ["S\u00e4\u00b7en", "leicht", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.19": {"text": "Und nicht so schwehr, als wie das Pfl\u00fcgen, und anders", "tokens": ["Und", "nicht", "so", "schwehr", ",", "als", "wie", "das", "Pfl\u00fc\u00b7gen", ",", "und", "an\u00b7ders"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PTKNEG", "ADV", "ADJD", "$,", "KOUS", "KOKOM", "ART", "NN", "$,", "KON", "ADV"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Ackerwerk; allein,", "tokens": ["A\u00b7cker\u00b7werk", ";", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.21": {"text": "Wie ich dar\u00fcber mich befragte, ward mir ein anders bald", "tokens": ["Wie", "ich", "da\u00b7r\u00fc\u00b7ber", "mich", "be\u00b7frag\u00b7te", ",", "ward", "mir", "ein", "an\u00b7ders", "bald"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PAV", "PPER", "VVFIN", "$,", "VAFIN", "PPER", "ART", "ADV", "ADV"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.22": {"text": "belehret,", "tokens": ["be\u00b7leh\u00b7ret", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.23": {"text": "Da\u00df auch zu dieser Arbeit Kraft und viele Wissenschaf", "tokens": ["Da\u00df", "auch", "zu", "die\u00b7ser", "Ar\u00b7beit", "Kraft", "und", "vie\u00b7le", "Wis\u00b7sen\u00b7schaf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PDAT", "NN", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.24": {"text": "geh\u00f6ret.", "tokens": ["ge\u00b7h\u00f6\u00b7ret", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.6": {"line.1": {"text": "Dem S\u00e4en sah ich emsig zu: und weil der helle Sonnen-", "tokens": ["Dem", "S\u00e4\u00b7en", "sah", "ich", "em\u00b7sig", "zu", ":", "und", "weil", "der", "hel\u00b7le", "Son\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "KON", "KOUS", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "schein", "tokens": ["schein"], "token_info": ["word"], "pos": ["ADJD"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Auf den geworfnen Saamen fiel, den auch der dunkle Grund", "tokens": ["Auf", "den", "ge\u00b7worf\u00b7nen", "Saa\u00b7men", "fiel", ",", "den", "auch", "der", "dunk\u00b7le", "Grund"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "erh\u00f6hte;", "tokens": ["er\u00b7h\u00f6h\u00b7te", ";"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "So schien es wahrlich anders nicht, als ob er g\u00fcldne", "tokens": ["So", "schien", "es", "wahr\u00b7lich", "an\u00b7ders", "nicht", ",", "als", "ob", "er", "g\u00fcld\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "$,", "KOKOM", "KOUS", "PPER", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "K\u00f6rner s\u00e4te.", "tokens": ["K\u00f6r\u00b7ner", "s\u00e4\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Doch nein, es lie\u00df noch \u00e4hnlicher, und recht als wenn", "tokens": ["Doch", "nein", ",", "es", "lie\u00df", "noch", "\u00e4hn\u00b7li\u00b7cher", ",", "und", "recht", "als", "wenn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PTKANT", "$,", "PPER", "VVFIN", "ADV", "ADJA", "$,", "KON", "ADJD", "KOKOM", "KOUS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "ein strenger Regen", "tokens": ["ein", "stren\u00b7ger", "Re\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Von grossen Tropfen \u00fcberall, und im best\u00e4ndigen Bewegen,", "tokens": ["Von", "gros\u00b7sen", "Trop\u00b7fen", "\u00fc\u00b7be\u00b7rall", ",", "und", "im", "be\u00b7st\u00e4n\u00b7di\u00b7gen", "Be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "$,", "KON", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.10": {"text": "Vom Winde stark getrieben, fiel. Die Erd\u2019, als w\u00e4r", "tokens": ["Vom", "Win\u00b7de", "stark", "ge\u00b7trie\u00b7ben", ",", "fiel", ".", "Die", "Erd'", ",", "als", "w\u00e4r"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "VVPP", "$,", "VVFIN", "$.", "ART", "NN", "$,", "KOKOM", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "sie hei\u00df und trucken,", "tokens": ["sie", "hei\u00df", "und", "tru\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.12": {"text": "Schien die empfangne Tropfen schnell, als wie im Sommer,", "tokens": ["Schien", "die", "emp\u00b7fang\u00b7ne", "Trop\u00b7fen", "schnell", ",", "als", "wie", "im", "Som\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ADJD", "$,", "KOUS", "KOKOM", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "einzuschlucken.", "tokens": ["ein\u00b7zu\u00b7schlu\u00b7cken", "."], "token_info": ["word", "punct"], "pos": ["VVIZU", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.14": {"text": "Indem ich dieses, mit Bedacht, noch ferner sehe, f\u00e4llt mir", "tokens": ["In\u00b7dem", "ich", "die\u00b7ses", ",", "mit", "Be\u00b7dacht", ",", "noch", "fer\u00b7ner", "se\u00b7he", ",", "f\u00e4llt", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "$,", "APPR", "NN", "$,", "ADV", "ADV", "VVFIN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.15": {"text": "bey,", "tokens": ["bey", ","], "token_info": ["word", "punct"], "pos": ["PTKVZ", "$,"], "meter": "+", "measure": "single.up"}, "line.16": {"text": "Da\u00df ein fast nicht gesp\u00fchrtes Wunder im Saamen noch", "tokens": ["Da\u00df", "ein", "fast", "nicht", "ge\u00b7sp\u00fchr\u00b7tes", "Wun\u00b7der", "im", "Saa\u00b7men", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADV", "PTKNEG", "ADJA", "NN", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "verborgen sey,", "tokens": ["ver\u00b7bor\u00b7gen", "sey", ","], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.18": {"text": "Da, ob er gleich nicht nach der Ordnung, und wirklich", "tokens": ["Da", ",", "ob", "er", "gleich", "nicht", "nach", "der", "Ord\u00b7nung", ",", "und", "wirk\u00b7lich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "PTKNEG", "APPR", "ART", "NN", "$,", "KON", "ADJD"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "recht von ungefehr,", "tokens": ["recht", "von", "un\u00b7ge\u00b7fehr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.20": {"text": "Bald auf-bald unterwerts, bald platt, gerade bald, bald in", "tokens": ["Bald", "auf\u00b7bald", "un\u00b7ter\u00b7werts", ",", "bald", "platt", ",", "ge\u00b7ra\u00b7de", "bald", ",", "bald", "in"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "ADV", "$,", "ADV", "ADJD", "$,", "ADV", "ADV", "$,", "ADV", "APPR"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.21": {"text": "die Queer,", "tokens": ["die", "Que\u00b7er", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.22": {"text": "So wie er f\u00e4llt, zu liegen kommt, es doch Bewunderns", "tokens": ["So", "wie", "er", "f\u00e4llt", ",", "zu", "lie\u00b7gen", "kommt", ",", "es", "doch", "Be\u00b7wun\u00b7derns"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "KOKOM", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "VVFIN", "$,", "PPER", "ADV", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "wehrt sich zeiget,", "tokens": ["wehrt", "sich", "zei\u00b7get", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.24": {"text": "Da\u00df unterwerts die kleine Wurzel, das H\u00e4lmchen in die", "tokens": ["Da\u00df", "un\u00b7ter\u00b7werts", "die", "klei\u00b7ne", "Wur\u00b7zel", ",", "das", "H\u00e4lm\u00b7chen", "in", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "$,", "ART", "NN", "APPR", "ART"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "H\u00f6he steiget.", "tokens": ["H\u00f6\u00b7he", "stei\u00b7get", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.26": {"text": "Wenn nun die eine von sich selbst sich abwerts, jene in die", "tokens": ["Wenn", "nun", "die", "ei\u00b7ne", "von", "sich", "selbst", "sich", "ab\u00b7werts", ",", "je\u00b7ne", "in", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ART", "APPR", "PRF", "ADV", "PRF", "ADV", "$,", "PDS", "APPR", "ART"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.27": {"text": "H\u00f6h',", "tokens": ["H\u00f6h'", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.28": {"text": "Durch einen uns verborgnen Trieb, nicht, fast vern\u00fcnftig,", "tokens": ["Durch", "ei\u00b7nen", "uns", "ver\u00b7borg\u00b7nen", "Trieb", ",", "nicht", ",", "fast", "ver\u00b7n\u00fcnf\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "PPER", "ADJA", "NN", "$,", "PTKNEG", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "wendete;", "tokens": ["wen\u00b7de\u00b7te", ";"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.30": {"text": "W\u00fcrd\u2019 es f\u00fcr uns unm\u00f6glich seyn, mit aller unsrer Kunst,", "tokens": ["W\u00fcrd'", "es", "f\u00fcr", "uns", "un\u00b7m\u00f6g\u00b7lich", "seyn", ",", "mit", "al\u00b7ler", "uns\u00b7rer", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "ADJD", "VAINF", "$,", "APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.31": {"text": "zu s\u00e4'n.", "tokens": ["zu", "s\u00e4'", "n."], "token_info": ["word", "word", "abbreviation"], "pos": ["APPR", "NE", "NE"], "meter": "++", "measure": "spondeus"}, "line.32": {"text": "Denn welcher Mensch k\u00f6nnt\u2019 jedes Korn nach seiner rech-", "tokens": ["Denn", "wel\u00b7cher", "Mensch", "k\u00f6nnt'", "je\u00b7des", "Korn", "nach", "sei\u00b7ner", "rech"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "NN", "VMFIN", "PIAT", "NN", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "ten Lage dreh'n?", "tokens": ["ten", "La\u00b7ge", "dreh'n", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Erkennet denn, geliebte Menschen! auch hieraus eine neue", "tokens": ["Er\u00b7ken\u00b7net", "denn", ",", "ge\u00b7lieb\u00b7te", "Men\u00b7schen", "!", "auch", "hier\u00b7aus", "ei\u00b7ne", "neu\u00b7e"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "ADJA", "NN", "$.", "ADV", "PAV", "ART", "ADJA"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Spur", "tokens": ["Spur"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Von einer m\u00e4chtig-weisen Lieb\u2019 in der uns n\u00e4hrenden", "tokens": ["Von", "ei\u00b7ner", "m\u00e4ch\u00b7tig\u00b7wei\u00b7sen", "Lieb'", "in", "der", "uns", "n\u00e4h\u00b7ren\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+--", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Natur.", "tokens": ["Na\u00b7tur", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.8": {"line.1": {"text": "So bald der edle Saame nun dem Schoo\u00df der Erden", "tokens": ["So", "bald", "der", "ed\u00b7le", "Saa\u00b7me", "nun", "dem", "Schoo\u00df", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "anvertraut;", "tokens": ["an\u00b7ver\u00b7traut", ";"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Wird ein nicht minder n\u00fctzlichs Werkzeug, im emsigen", "tokens": ["Wird", "ein", "nicht", "min\u00b7der", "n\u00fctz\u00b7lichs", "Werk\u00b7zeug", ",", "im", "em\u00b7si\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ART", "PTKNEG", "ADV", "ADJA", "NN", "$,", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gebrauch, geschaut.", "tokens": ["Ge\u00b7brauch", ",", "ge\u00b7schaut", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Die zackigten geeckten Egen, die theils voll Holz, theils", "tokens": ["Die", "za\u00b7ckig\u00b7ten", "ge\u00b7eck\u00b7ten", "E\u00b7gen", ",", "die", "theils", "voll", "Holz", ",", "theils"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,", "PRELS", "ADV", "ADJD", "NN", "$,", "ADV"], "meter": "--+--+-+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Eisen stecken,", "tokens": ["Ei\u00b7sen", "ste\u00b7cken", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Sind mit bespannten Pferden fertig, den k\u00fcnft\u2019gen Segen", "tokens": ["Sind", "mit", "be\u00b7spann\u00b7ten", "Pfer\u00b7den", "fer\u00b7tig", ",", "den", "k\u00fcnft'\u00b7gen", "Se\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "ADJD", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "zuzudecken.", "tokens": ["zu\u00b7zu\u00b7de\u00b7cken", "."], "token_info": ["word", "punct"], "pos": ["VVIZU", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Sie bringen den gestreuten Saamen nun v\u00f6llig erst zu", "tokens": ["Sie", "brin\u00b7gen", "den", "ge\u00b7streu\u00b7ten", "Saa\u00b7men", "nun", "v\u00f6l\u00b7lig", "erst", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ADV", "ADJD", "ADV", "APPR"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "seiner Ruh,", "tokens": ["sei\u00b7ner", "Ruh", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.11": {"text": "Und ziehen vor dem grossen Schauplatz, so wie es scheint,", "tokens": ["Und", "zie\u00b7hen", "vor", "dem", "gros\u00b7sen", "Schau\u00b7platz", ",", "so", "wie", "es", "scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,", "ADV", "KOKOM", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "die Decke zu.", "tokens": ["die", "De\u00b7cke", "zu", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Gesegne Du es nun, o GOtt! Du Segens-Quell\u2019! Der", "tokens": ["Ge\u00b7seg\u00b7ne", "Du", "es", "nun", ",", "o", "Gott", "!", "Du", "Se\u00b7gens\u00b7Quell'", "!", "Der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "$,", "FM", "NN", "$.", "PPER", "NE", "$.", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ackersmann", "tokens": ["A\u00b7ckers\u00b7mann"], "token_info": ["word"], "pos": ["NN"], "meter": "+--", "measure": "dactylic.init"}, "line.3": {"text": "Hat bey dem grossen Nahrungs-Werk nunmehr das", "tokens": ["Hat", "bey", "dem", "gros\u00b7sen", "Nah\u00b7rungs\u00b7Werk", "nun\u00b7mehr", "das"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ADV", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Seinige gethan.", "tokens": ["Sei\u00b7ni\u00b7ge", "ge\u00b7than", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Ein mehrers kann er nicht. So la\u00df, was er der Erden", "tokens": ["Ein", "meh\u00b7rers", "kann", "er", "nicht", ".", "So", "la\u00df", ",", "was", "er", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VMFIN", "PPER", "PTKNEG", "$.", "ADV", "PTKVZ", "$,", "PWS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "anvertrauet,", "tokens": ["an\u00b7ver\u00b7trau\u00b7et", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Blo\u00df durch Dein gn\u00e4diges Gedeyen, im Regen, Sonnen-", "tokens": ["Blo\u00df", "durch", "Dein", "gn\u00e4\u00b7di\u00b7ges", "Ge\u00b7de\u00b7yen", ",", "im", "Re\u00b7gen", ",", "Son\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,", "APPRART", "NN", "$,", "TRUNC"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "schein und Winden,", "tokens": ["schein", "und", "Win\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Zu rechter Zeit, in rechter Maasse, Kraft, N\u00e4sse, W\u00e4rm\u2019", "tokens": ["Zu", "rech\u00b7ter", "Zeit", ",", "in", "rech\u00b7ter", "Maas\u00b7se", ",", "Kraft", ",", "N\u00e4s\u00b7se", ",", "W\u00e4rm'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.10": {"text": "und Wachsthum finden!", "tokens": ["und", "Wach\u00b7sthum", "fin\u00b7den", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Gieb auch, da\u00df wir mit Preis und Dank den uns von", "tokens": ["Gieb", "auch", ",", "da\u00df", "wir", "mit", "Preis", "und", "Dank", "den", "uns", "von"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "$,", "KOUS", "PPER", "APPR", "NN", "KON", "APPR", "ART", "PPER", "APPR"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "Dir geschenkten Segen,", "tokens": ["Dir", "ge\u00b7schenk\u00b7ten", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "Wenn er gereifet und gem\u00e4ht, vergn\u00fcgt in unsre Scheu-", "tokens": ["Wenn", "er", "ge\u00b7rei\u00b7fet", "und", "ge\u00b7m\u00e4ht", ",", "ver\u00b7gn\u00fcgt", "in", "uns\u00b7re", "Scheu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVPP", "KON", "VVPP", "$,", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.14": {"text": "ren legen!", "tokens": ["ren", "le\u00b7gen", "!"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}}}}