{"dta.poem.20655": {"metadata": {"author": {"name": "Karsch, Anna Luise", "birth": "N.A.", "death": "N.A."}, "title": "Ueber  \n  den Unbestand des Ruhms.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1792", "urn": "urn:nbn:de:kobv:b4-200905193016", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Sollt' ich, vom Stolz verblendet, glauben,                 ", "tokens": ["Sollt'", "ich", ",", "vom", "Stolz", "ver\u00b7blen\u00b7det", ",", "glau\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "APPRART", "NN", "VVPP", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df mich einst loben wird die sp\u00e4tgeborne Welt?", "tokens": ["Da\u00df", "mich", "einst", "lo\u00b7ben", "wird", "die", "sp\u00e4t\u00b7ge\u00b7bor\u00b7ne", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sprich, Freundin! ob Dir noch das Muster an den", "tokens": ["Sprich", ",", "Freun\u00b7din", "!", "ob", "Dir", "noch", "das", "Mus\u00b7ter", "an", "den"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "$,", "NN", "$.", "KOUS", "PPER", "ADV", "ART", "NN", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hauben", "tokens": ["Hau\u00b7ben"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Der Aelterm\u00fctter wohlgef\u00e4llt?", "tokens": ["Der", "A\u00b7el\u00b7ter\u00b7m\u00fct\u00b7ter", "wohl\u00b7ge\u00b7f\u00e4llt", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Im Putz und Hausrath herrscht die Mode,", "tokens": ["Im", "Putz", "und", "Haus\u00b7rath", "herrscht", "die", "Mo\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie herrscht nicht minder in dem Reich der Wissenschaft;", "tokens": ["Sie", "herrscht", "nicht", "min\u00b7der", "in", "dem", "Reich", "der", "Wis\u00b7sen\u00b7schaft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Kenner lobte vormals G\u00fcnthers Heldenode,", "tokens": ["Der", "Ken\u00b7ner", "lob\u00b7te", "vor\u00b7mals", "G\u00fcn\u00b7thers", "Hel\u00b7de\u00b7no\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "NE", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und jezt nennt er sie p\u00f6belhaft.", "tokens": ["Und", "jezt", "nennt", "er", "sie", "p\u00f6\u00b7bel\u00b7haft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "ADJD", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.3": {"line.1": {"text": "Ber\u00fchmt war Neukirch, und bewundert", "tokens": ["Be\u00b7r\u00fchmt", "war", "Neu\u00b7kirch", ",", "und", "be\u00b7wun\u00b7dert"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "VAFIN", "NE", "$,", "KON", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ward Broks, der Laub und Gras, Insekt und Blumen", "tokens": ["Ward", "Broks", ",", "der", "Laub", "und", "Gras", ",", "In\u00b7sekt", "und", "Blu\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NN", "$,", "ART", "NN", "KON", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "sang:", "tokens": ["sang", ":"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Und Beider Ansehn fiel, eh noch ein ganz Jahrhundert", "tokens": ["Und", "Bei\u00b7der", "An\u00b7sehn", "fiel", ",", "eh", "noch", "ein", "ganz", "Jahr\u00b7hun\u00b7dert"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$,", "KOUS", "ADV", "ART", "ADV", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vollf\u00fchrt den fl\u00fcgelschnellen Gang.", "tokens": ["Voll\u00b7f\u00fchrt", "den", "fl\u00fc\u00b7gel\u00b7schnel\u00b7len", "Gang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die Zieglerin, im Lorbeerkranze", "tokens": ["Die", "Zieg\u00b7le\u00b7rin", ",", "im", "Lor\u00b7beer\u00b7kran\u00b7ze"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sch\u00f6n abgebildet, war ber\u00fchmt, als kaum an mir", "tokens": ["Sch\u00f6n", "ab\u00b7ge\u00b7bil\u00b7det", ",", "war", "be\u00b7r\u00fchmt", ",", "als", "kaum", "an", "mir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVPP", "$,", "VAFIN", "ADJD", "$,", "KOUS", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das Auge ward gebaut; und jetzo spricht die ganze", "tokens": ["Das", "Au\u00b7ge", "ward", "ge\u00b7baut", ";", "und", "jet\u00b7zo", "spricht", "die", "gan\u00b7ze"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "KON", "ADV", "VVFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gelehrte Welt nicht mehr von ihr.", "tokens": ["Ge\u00b7lehr\u00b7te", "Welt", "nicht", "mehr", "von", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKNEG", "ADV", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Nur Pindar und Horatz, und jener", "tokens": ["Nur", "Pin\u00b7dar", "und", "Ho\u00b7ratz", ",", "und", "je\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "NN", "KON", "NN", "$,", "KON", "PDS"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Unnachahmbare Mann, der Trojens Untergang", "tokens": ["Un\u00b7nac\u00b7hahm\u00b7ba\u00b7re", "Mann", ",", "der", "Tro\u00b7jens", "Un\u00b7ter\u00b7gang"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "ART", "NN", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Beschrieben, und auch der, den von dem Gottvers\u00f6hner", "tokens": ["Be\u00b7schrie\u00b7ben", ",", "und", "auch", "der", ",", "den", "von", "dem", "Gott\u00b7ver\u00b7s\u00f6h\u00b7ner"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KON", "ADV", "ART", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein Engel lehrte den Gesang;", "tokens": ["Ein", "En\u00b7gel", "lehr\u00b7te", "den", "Ge\u00b7sang", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Kleist, Ramler, Hagedorn und Haller,", "tokens": ["Kleist", ",", "Ram\u00b7ler", ",", "Ha\u00b7ge\u00b7dorn", "und", "Hal\u00b7ler", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gleim, Gellert, Wei\u00dfe, Utz, Dusch, Bodmer, Pope,", "tokens": ["Gleim", ",", "Gel\u00b7lert", ",", "Wei\u00b7\u00dfe", ",", "Utz", ",", "Dusch", ",", "Bod\u00b7mer", ",", "Po\u00b7pe", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "VVPP", "$,", "NN", "$,", "NE", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Young:", "tokens": ["Y\u00b7o\u00b7ung", ":"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Die trotzen dem Geschmack der strengsten Kunst, und", "tokens": ["Die", "trot\u00b7zen", "dem", "Ge\u00b7schmack", "der", "strengs\u00b7ten", "Kunst", ",", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ART", "NN", "ART", "ADJA", "NN", "$,", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "aller", "tokens": ["al\u00b7ler"], "token_info": ["word"], "pos": ["PIAT"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Verfeinerten Ver\u00e4nderung.", "tokens": ["Ver\u00b7fei\u00b7ner\u00b7ten", "Ver\u00b7\u00e4n\u00b7de\u00b7rung", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ich aber bin vielleicht vergessen,", "tokens": ["Ich", "a\u00b7ber", "bin", "viel\u00b7leicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn unsrer Enkelinnen Kopfputz dem Gesicht,", "tokens": ["Wenn", "uns\u00b7rer", "En\u00b7ke\u00b7lin\u00b7nen", "Kopf\u00b7putz", "dem", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den Schl\u00e4fen und der Stirn ist besser angemessen,", "tokens": ["Den", "Schl\u00e4\u00b7fen", "und", "der", "Stirn", "ist", "bes\u00b7ser", "an\u00b7ge\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und der Karkasse widerspricht.", "tokens": ["Und", "der", "Kar\u00b7kas\u00b7se", "wi\u00b7der\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ob ich ein l\u00e4ngres Lob erstrebet,", "tokens": ["Ob", "ich", "ein", "l\u00e4ng\u00b7res", "Lob", "er\u00b7stre\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das ist mein Kummer nicht; die Freundschaft sey mein", "tokens": ["Das", "ist", "mein", "Kum\u00b7mer", "nicht", ";", "die", "Freund\u00b7schaft", "sey", "mein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "PTKNEG", "$.", "ART", "NN", "VAFIN", "PPOSAT"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Stolz,", "tokens": ["Stolz", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Sie weinet, wenn ich gnug gesungen und gelebet,", "tokens": ["Sie", "wei\u00b7net", ",", "wenn", "ich", "gnug", "ge\u00b7sun\u00b7gen", "und", "ge\u00b7le\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Noch Ruhm auf meines Sarges Holz.", "tokens": ["Noch", "Ruhm", "auf", "mei\u00b7nes", "Sar\u00b7ges", "Holz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}