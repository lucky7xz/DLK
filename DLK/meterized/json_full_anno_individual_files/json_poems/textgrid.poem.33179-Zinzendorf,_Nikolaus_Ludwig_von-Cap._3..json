{"textgrid.poem.33179": {"metadata": {"author": {"name": "Zinzendorf, Nikolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "Cap. 3.", "genre": "verse", "period": "N.A.", "pub_year": 1730, "urn": "N.A.", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun, lieben! wir sind Gottes kind; und Gott wei\u00df, was wir k\u00fcnftig sind.", "tokens": ["Nun", ",", "lie\u00b7ben", "!", "wir", "sind", "Got\u00b7tes", "kind", ";", "und", "Gott", "wei\u00df", ",", "was", "wir", "k\u00fcnf\u00b7tig", "sind", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVINF", "$.", "PPER", "VAFIN", "NN", "NN", "$.", "KON", "NN", "VVFIN", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.2": {"line.1": {"text": "(dem Lamm sey ewig dank gebracht! das hat uns Gott zu was gemacht.)", "tokens": ["(", "dem", "Lamm", "sey", "e\u00b7wig", "dank", "ge\u00b7bracht", "!", "das", "hat", "uns", "Gott", "zu", "was", "ge\u00b7macht", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "APPR", "VVPP", "$.", "PDS", "VAFIN", "PPER", "NN", "APPR", "PRELS", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.3": {"line.1": {"text": "3.", "tokens": [], "token_info": [], "pos": []}}, "stanza.4": {"line.1": {"text": "Der ist gewi\u00df von Gott nicht her; denn das ist die uralte lehr:", "tokens": ["Der", "ist", "ge\u00b7wi\u00df", "von", "Gott", "nicht", "her", ";", "denn", "das", "ist", "die", "ur\u00b7al\u00b7te", "lehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "NN", "PTKNEG", "PTKVZ", "$.", "KON", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.5": {"line.1": {"text": "Er sagt sein'n j\u00fcngern unverhol'n, da\u00df sie zusamm'n sich lieben soll'n.", "tokens": ["Er", "sagt", "sein'n", "j\u00fcn\u00b7gern", "un\u00b7ver\u00b7hol'n", ",", "da\u00df", "sie", "zu\u00b7sam\u00b7m'n", "sich", "lie\u00b7ben", "soll'", "n."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,", "KOUS", "PPER", "VVFIN", "PRF", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.6": {"line.1": {"text": "13.", "tokens": [], "token_info": [], "pos": []}}, "stanza.7": {"line.1": {"text": "Wie Christus uns geliebet hat.", "tokens": ["Wie", "Chris\u00b7tus", "uns", "ge\u00b7lie\u00b7bet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "(durch sein' heilge f\u00fcnf wunden roth!)", "tokens": ["(", "durch", "sein'", "heil\u00b7ge", "f\u00fcnf", "wun\u00b7den", "roth", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "CARD", "ADJA", "ADJD", "$.", "$("], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Sein haupt-gebot ist:", "tokens": ["Sein", "haup\u00b7tge\u00b7bot", "ist", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "(lieben leut! h\u00f6rt das gesetz mit innigkeit:)", "tokens": ["(", "lie\u00b7ben", "leut", "!", "h\u00f6rt", "das", "ge\u00b7setz", "mit", "in\u00b7nig\u00b7keit", ":)"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "emoticon"], "pos": ["$(", "VVINF", "VVFIN", "$.", "VVFIN", "ART", "NN", "APPR", "ADJD", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Da\u00df wir glauben an die person von Jesu Christo, seinem Sohn;", "tokens": ["Da\u00df", "wir", "glau\u00b7ben", "an", "die", "per\u00b7son", "von", "Je\u00b7su", "Chris\u00b7to", ",", "sei\u00b7nem", "Sohn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "NE", "NE", "$,", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.11": {"line.1": {"text": "Nun, lieben! wir sind Gottes kind; und Gott wei\u00df, was wir k\u00fcnftig sind.", "tokens": ["Nun", ",", "lie\u00b7ben", "!", "wir", "sind", "Got\u00b7tes", "kind", ";", "und", "Gott", "wei\u00df", ",", "was", "wir", "k\u00fcnf\u00b7tig", "sind", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVINF", "$.", "PPER", "VAFIN", "NN", "NN", "$.", "KON", "NN", "VVFIN", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.12": {"line.1": {"text": "(dem Lamm sey ewig dank gebracht! das hat uns Gott zu was gemacht.)", "tokens": ["(", "dem", "Lamm", "sey", "e\u00b7wig", "dank", "ge\u00b7bracht", "!", "das", "hat", "uns", "Gott", "zu", "was", "ge\u00b7macht", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "APPR", "VVPP", "$.", "PDS", "VAFIN", "PPER", "NN", "APPR", "PRELS", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.13": {"line.1": {"text": "3.", "tokens": [], "token_info": [], "pos": []}}, "stanza.14": {"line.1": {"text": "Der ist gewi\u00df von Gott nicht her; denn das ist die uralte lehr:", "tokens": ["Der", "ist", "ge\u00b7wi\u00df", "von", "Gott", "nicht", "her", ";", "denn", "das", "ist", "die", "ur\u00b7al\u00b7te", "lehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "NN", "PTKNEG", "PTKVZ", "$.", "KON", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.15": {"line.1": {"text": "Er sagt sein'n j\u00fcngern unverhol'n, da\u00df sie zusamm'n sich lieben soll'n.", "tokens": ["Er", "sagt", "sein'n", "j\u00fcn\u00b7gern", "un\u00b7ver\u00b7hol'n", ",", "da\u00df", "sie", "zu\u00b7sam\u00b7m'n", "sich", "lie\u00b7ben", "soll'", "n."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,", "KOUS", "PPER", "VVFIN", "PRF", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.16": {"line.1": {"text": "13.", "tokens": [], "token_info": [], "pos": []}}, "stanza.17": {"line.1": {"text": "Wie Christus uns geliebet hat.", "tokens": ["Wie", "Chris\u00b7tus", "uns", "ge\u00b7lie\u00b7bet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "(durch sein' heilge f\u00fcnf wunden roth!)", "tokens": ["(", "durch", "sein'", "heil\u00b7ge", "f\u00fcnf", "wun\u00b7den", "roth", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "CARD", "ADJA", "ADJD", "$.", "$("], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "Sein haupt-gebot ist:", "tokens": ["Sein", "haup\u00b7tge\u00b7bot", "ist", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.20": {"line.1": {"text": "(lieben leut! h\u00f6rt das gesetz mit innigkeit:)", "tokens": ["(", "lie\u00b7ben", "leut", "!", "h\u00f6rt", "das", "ge\u00b7setz", "mit", "in\u00b7nig\u00b7keit", ":)"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "emoticon"], "pos": ["$(", "VVINF", "VVFIN", "$.", "VVFIN", "ART", "NN", "APPR", "ADJD", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Da\u00df wir glauben an die person von Jesu Christo, seinem Sohn;", "tokens": ["Da\u00df", "wir", "glau\u00b7ben", "an", "die", "per\u00b7son", "von", "Je\u00b7su", "Chris\u00b7to", ",", "sei\u00b7nem", "Sohn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "NE", "NE", "$,", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}}}}