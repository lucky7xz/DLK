{"textgrid.poem.51048": {"metadata": {"author": {"name": "Keller, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Eidgenossenschaft", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie ist denn einst der Diamant entstanden", "tokens": ["Wie", "ist", "denn", "einst", "der", "Di\u00b7a\u00b7mant", "ent\u00b7stan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ADV", "ADV", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu unzerst\u00f6rlich alldurchdrungner Einheit,", "tokens": ["Zu", "un\u00b7zer\u00b7st\u00f6r\u00b7lich", "all\u00b7durch\u00b7drung\u00b7ner", "Ein\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zu ungetr\u00fcbter, strahlenheller Reinheit,", "tokens": ["Zu", "un\u00b7ge\u00b7tr\u00fcb\u00b7ter", ",", "strah\u00b7len\u00b7hel\u00b7ler", "Rein\u00b7heit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gefestiget von unsichtbaren Banden?", "tokens": ["Ge\u00b7fes\u00b7ti\u00b7get", "von", "un\u00b7sicht\u00b7ba\u00b7ren", "Ban\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wenn aus der V\u00f6lker Schwellen und Versanden", "tokens": ["Wenn", "aus", "der", "V\u00f6l\u00b7ker", "Schwel\u00b7len", "und", "Ver\u00b7san\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Neues sich zu einem Ganzen einreiht,", "tokens": ["Ein", "Neu\u00b7es", "sich", "zu", "ei\u00b7nem", "Gan\u00b7zen", "ein\u00b7reiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Wenn Freiheitslieb zum Volke dann es einweiht,", "tokens": ["Wenn", "Frei\u00b7heits\u00b7lieb", "zum", "Vol\u00b7ke", "dann", "es", "ein\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NN", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Wo Gleichgesinnte ihre Heimat fanden:", "tokens": ["Wo", "Gleich\u00b7ge\u00b7sinn\u00b7te", "ih\u00b7re", "Hei\u00b7mat", "fan\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wer will da wohl noch r\u00fctteln dran und feilen?", "tokens": ["Wer", "will", "da", "wohl", "noch", "r\u00fct\u00b7teln", "dran", "und", "fei\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "ADV", "ADV", "VVFIN", "PAV", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu sp\u00e4t, ihr Herrn! schon ist's ein Diamant,", "tokens": ["Zu", "sp\u00e4t", ",", "ihr", "Herrn", "!", "schon", "ist's", "ein", "Di\u00b7a\u00b7mant", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$,", "PPOSAT", "NN", "$.", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der nicht mehr ist zu tr\u00fcben und zu teilen!", "tokens": ["Der", "nicht", "mehr", "ist", "zu", "tr\u00fc\u00b7ben", "und", "zu", "tei\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "VAFIN", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und wenn, wie man im Edelstein erkannt,", "tokens": ["Und", "wenn", ",", "wie", "man", "im", "E\u00b7del\u00b7stein", "er\u00b7kannt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "PWAV", "PIS", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Darin noch kleine dunkle K\u00f6rper weilen,", "tokens": ["Da\u00b7rin", "noch", "klei\u00b7ne", "dunk\u00b7le", "K\u00f6r\u00b7per", "wei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ADJA", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So sind sie fest umschlossen und gebannt.", "tokens": ["So", "sind", "sie", "fest", "um\u00b7schlos\u00b7sen", "und", "ge\u00b7bannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Wie ist denn einst der Diamant entstanden", "tokens": ["Wie", "ist", "denn", "einst", "der", "Di\u00b7a\u00b7mant", "ent\u00b7stan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ADV", "ADV", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu unzerst\u00f6rlich alldurchdrungner Einheit,", "tokens": ["Zu", "un\u00b7zer\u00b7st\u00f6r\u00b7lich", "all\u00b7durch\u00b7drung\u00b7ner", "Ein\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zu ungetr\u00fcbter, strahlenheller Reinheit,", "tokens": ["Zu", "un\u00b7ge\u00b7tr\u00fcb\u00b7ter", ",", "strah\u00b7len\u00b7hel\u00b7ler", "Rein\u00b7heit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gefestiget von unsichtbaren Banden?", "tokens": ["Ge\u00b7fes\u00b7ti\u00b7get", "von", "un\u00b7sicht\u00b7ba\u00b7ren", "Ban\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Wenn aus der V\u00f6lker Schwellen und Versanden", "tokens": ["Wenn", "aus", "der", "V\u00f6l\u00b7ker", "Schwel\u00b7len", "und", "Ver\u00b7san\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Neues sich zu einem Ganzen einreiht,", "tokens": ["Ein", "Neu\u00b7es", "sich", "zu", "ei\u00b7nem", "Gan\u00b7zen", "ein\u00b7reiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Wenn Freiheitslieb zum Volke dann es einweiht,", "tokens": ["Wenn", "Frei\u00b7heits\u00b7lieb", "zum", "Vol\u00b7ke", "dann", "es", "ein\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NN", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Wo Gleichgesinnte ihre Heimat fanden:", "tokens": ["Wo", "Gleich\u00b7ge\u00b7sinn\u00b7te", "ih\u00b7re", "Hei\u00b7mat", "fan\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Wer will da wohl noch r\u00fctteln dran und feilen?", "tokens": ["Wer", "will", "da", "wohl", "noch", "r\u00fct\u00b7teln", "dran", "und", "fei\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "ADV", "ADV", "VVFIN", "PAV", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu sp\u00e4t, ihr Herrn! schon ist's ein Diamant,", "tokens": ["Zu", "sp\u00e4t", ",", "ihr", "Herrn", "!", "schon", "ist's", "ein", "Di\u00b7a\u00b7mant", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$,", "PPOSAT", "NN", "$.", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der nicht mehr ist zu tr\u00fcben und zu teilen!", "tokens": ["Der", "nicht", "mehr", "ist", "zu", "tr\u00fc\u00b7ben", "und", "zu", "tei\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "VAFIN", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Und wenn, wie man im Edelstein erkannt,", "tokens": ["Und", "wenn", ",", "wie", "man", "im", "E\u00b7del\u00b7stein", "er\u00b7kannt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "PWAV", "PIS", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Darin noch kleine dunkle K\u00f6rper weilen,", "tokens": ["Da\u00b7rin", "noch", "klei\u00b7ne", "dunk\u00b7le", "K\u00f6r\u00b7per", "wei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ADJA", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So sind sie fest umschlossen und gebannt.", "tokens": ["So", "sind", "sie", "fest", "um\u00b7schlos\u00b7sen", "und", "ge\u00b7bannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}