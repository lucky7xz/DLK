{"dta.poem.9149": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Ii.  \n Der ungedultige liebhaber.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Ich hab ein bi\u00dfgen lieb gehabt/", "tokens": ["Ich", "hab", "ein", "bi\u00df\u00b7gen", "lieb", "ge\u00b7habt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADV", "ADJD", "VAPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und habe meinen sinn gelabt/", "tokens": ["Und", "ha\u00b7be", "mei\u00b7nen", "sinn", "ge\u00b7labt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch nun will ich mich selbst verst\u00f6hren.", "tokens": ["Doch", "nun", "will", "ich", "mich", "selbst", "ver\u00b7st\u00f6h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Denn weil es gleich am besten schm\u00e4ckt/", "tokens": ["Denn", "weil", "es", "gleich", "am", "bes\u00b7ten", "schm\u00e4ckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PTKA", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wann man noch die finger leckt/", "tokens": ["Und", "wann", "man", "noch", "die", "fin\u00b7ger", "leckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "ADV", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da ists am besten auffzuh\u00f6ren.", "tokens": ["Da", "ists", "am", "bes\u00b7ten", "auff\u00b7zu\u00b7h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Es ist doch lauter kinderey", "tokens": ["Es", "ist", "doch", "lau\u00b7ter", "kin\u00b7de\u00b7rey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit der verliebten l\u00f6ffeley:", "tokens": ["Mit", "der", "ver\u00b7lieb\u00b7ten", "l\u00f6f\u00b7fe\u00b7ley", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie m\u00fcssen wir die zeit verderben/", "tokens": ["Wie", "m\u00fcs\u00b7sen", "wir", "die", "zeit", "ver\u00b7der\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In leerer furcht und hoffnung stehn/", "tokens": ["In", "lee\u00b7rer", "furcht", "und", "hoff\u00b7nung", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und manchen gang vergebens gehn/", "tokens": ["Und", "man\u00b7chen", "gang", "ver\u00b7ge\u00b7bens", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Eh wir ein bi\u00dfgen gunst erwerben.", "tokens": ["Eh", "wir", "ein", "bi\u00df\u00b7gen", "gunst", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Und wann sie nun erworben ist/", "tokens": ["Und", "wann", "sie", "nun", "er\u00b7wor\u00b7ben", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So w\u00e4hrt es eine kurtze frist/", "tokens": ["So", "w\u00e4hrt", "es", "ei\u00b7ne", "kurt\u00b7ze", "frist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bi\u00df wir sie wiederum versch\u00fctten/", "tokens": ["Bi\u00df", "wir", "sie", "wie\u00b7de\u00b7rum", "ver\u00b7sch\u00fct\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein schritt/ ein wort/ ein eintzig blick", "tokens": ["Ein", "schritt", "/", "ein", "wort", "/", "ein", "eint\u00b7zig", "blick"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "VVFIN", "$(", "ART", "NN", "$(", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Treibt alle freundlichkeit zur\u00fcck/", "tokens": ["Treibt", "al\u00b7le", "freund\u00b7lich\u00b7keit", "zu\u00b7r\u00fcck", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und da hilfft kein genade bitten.", "tokens": ["Und", "da", "hilfft", "kein", "ge\u00b7na\u00b7de", "bit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Die m\u00e4dgen wollen lustig seyn/", "tokens": ["Die", "m\u00e4d\u00b7gen", "wol\u00b7len", "lus\u00b7tig", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Drum lieben sie nur auff den schein/", "tokens": ["Drum", "lie\u00b7ben", "sie", "nur", "auff", "den", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der blossen zeit vertreibung wegen:", "tokens": ["Der", "blos\u00b7sen", "zeit", "ver\u00b7trei\u00b7bung", "we\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "APPR", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch weil es nur am gl\u00fccke liegt/", "tokens": ["Doch", "weil", "es", "nur", "am", "gl\u00fc\u00b7cke", "liegt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPRART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df man sie bey der laune kriegt/", "tokens": ["Da\u00df", "man", "sie", "bey", "der", "lau\u00b7ne", "kriegt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So k\u00f6mmt man offt gar ungelegen.", "tokens": ["So", "k\u00f6mmt", "man", "offt", "gar", "un\u00b7ge\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Und wann wir noch so sicher seyn/", "tokens": ["Und", "wann", "wir", "noch", "so", "si\u00b7cher", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So stellt sich gar ein ander ein/", "tokens": ["So", "stellt", "sich", "gar", "ein", "an\u00b7der", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "ART", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der lernt zu erst die bahne brechen/", "tokens": ["Der", "lernt", "zu", "erst", "die", "bah\u00b7ne", "bre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hernach sucht er gelegenheit", "tokens": ["Her\u00b7nach", "sucht", "er", "ge\u00b7le\u00b7gen\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.5": {"text": "Durch seine schlaue freundlichkeit", "tokens": ["Durch", "sei\u00b7ne", "schlau\u00b7e", "freund\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Uns unvermercket abzustechen.", "tokens": ["Uns", "un\u00b7ver\u00b7mer\u00b7cket", "ab\u00b7zu\u00b7ste\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "6. Da geht das grillen-fangen an", "tokens": ["Da", "geht", "das", "gril\u00b7len\u00b7fan\u00b7gen", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie man den causenmacher kan/", "tokens": ["Wie", "man", "den", "cau\u00b7sen\u00b7ma\u00b7cher", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "ADJA", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bey guter zeit zur\u00fccke treiben/", "tokens": ["Bey", "gu\u00b7ter", "zeit", "zu\u00b7r\u00fc\u00b7cke", "trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch dessen allen ungeacht/", "tokens": ["Doch", "des\u00b7sen", "al\u00b7len", "un\u00b7ge\u00b7acht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ob man sich noch so mausig macht/", "tokens": ["Ob", "man", "sich", "noch", "so", "mau\u00b7sig", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ADV", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mu\u00df er im sattel sitzen bleiben.", "tokens": ["Mu\u00df", "er", "im", "sat\u00b7tel", "sit\u00b7zen", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "7. Was hat man dann nunmehr darvon", "tokens": ["Was", "hat", "man", "dann", "nun\u00b7mehr", "dar\u00b7von"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PIS", "ADV", "ADV", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als allenthalben spott und hohn/", "tokens": ["Als", "al\u00b7len\u00b7thal\u00b7ben", "spott", "und", "hohn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und tausend sorgen in dem hertzen?", "tokens": ["Und", "tau\u00b7send", "sor\u00b7gen", "in", "dem", "hert\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ade du lebendiger tod/", "tokens": ["A\u00b7de", "du", "le\u00b7ben\u00b7di\u00b7ger", "tod", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJA", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Ich will hinfort mit deiner noth", "tokens": ["Ich", "will", "hin\u00b7fort", "mit", "dei\u00b7ner", "noth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In meiner vollen freyheit schertzen!", "tokens": ["In", "mei\u00b7ner", "vol\u00b7len", "frey\u00b7heit", "schert\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "8. Drum lob ich eine compagnie/", "tokens": ["Drum", "lob", "ich", "ei\u00b7ne", "com\u00b7pag\u00b7nie", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da wir bi\u00df an den morgen fr\u00fch", "tokens": ["Da", "wir", "bi\u00df", "an", "den", "mor\u00b7gen", "fr\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auff gute treu und freundschafft sauffen/", "tokens": ["Auff", "gu\u00b7te", "treu", "und", "freund\u00b7schafft", "sauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJD", "KON", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcrwahr eh ich das liebes-spiel", "tokens": ["F\u00fcr\u00b7wahr", "eh", "ich", "das", "lie\u00b7bes\u00b7spiel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So eyffrig wieder spielen will/", "tokens": ["So", "eyf\u00b7frig", "wie\u00b7der", "spie\u00b7len", "will", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Eh will ich aus der stadt entlauffen.", "tokens": ["Eh", "will", "ich", "aus", "der", "stadt", "ent\u00b7lauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}