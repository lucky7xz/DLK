{"textgrid.poem.37504": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Vorwort", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ach, ja, ja! \u2013 so seufz' ich immer \u2013;", "tokens": ["Ach", ",", "ja", ",", "ja", "!", "\u2013", "so", "seuf\u00b7z'", "ich", "im\u00b7mer", "\u2013", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "PTKANT", "$,", "ADV", "$.", "$(", "ADV", "VVFIN", "PPER", "ADV", "$(", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Denn die Zeit wird schlimm und schlimmer.", "tokens": ["Denn", "die", "Zeit", "wird", "schlimm", "und", "schlim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder kann in unsern Tagen", "tokens": ["O\u00b7der", "kann", "in", "un\u00b7sern", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einer wagen, nein! zu sagen,", "tokens": ["Ei\u00b7ner", "wa\u00b7gen", ",", "nein", "!", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVINF", "$,", "PTKANT", "$.", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der mit kindlichem Gem\u00fct", "tokens": ["Der", "mit", "kind\u00b7li\u00b7chem", "Ge\u00b7m\u00fct"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Morgens in die Zeitung sieht?", "tokens": ["Mor\u00b7gens", "in", "die", "Zei\u00b7tung", "sieht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Hier Romane, dort Gedichte,", "tokens": ["Hier", "Ro\u00b7ma\u00b7ne", ",", "dort", "Ge\u00b7dich\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "ADV", "NN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Malzextrakt und Kursberichte,", "tokens": ["Mal\u00b7zext\u00b7rakt", "und", "Kurs\u00b7be\u00b7rich\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "N\u00e4h- und M\u00e4h- und Waschmaschinen,", "tokens": ["N\u00e4h", "und", "M\u00e4h", "und", "Waschma\u00b7schi\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-++-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Klauenseuche und Trichinen \u2013 \u2013", "tokens": ["Klau\u00b7en\u00b7seu\u00b7che", "und", "Tri\u00b7chi\u00b7nen", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "NN", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieses druckt man gro\u00df und breit \u2013", "tokens": ["Die\u00b7ses", "druckt", "man", "gro\u00df", "und", "breit", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Aber wo ist Fr\u00f6mmigkeit??? \u2013", "tokens": ["A\u00b7ber", "wo", "ist", "Fr\u00f6m\u00b7mig\u00b7keit", "???", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWAV", "VAFIN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "H\u00e4lt denn nicht, o S\u00fcnd und Schand,", "tokens": ["H\u00e4lt", "denn", "nicht", ",", "o", "S\u00fcnd", "und", "Schand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "$,", "FM", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Weltlicher Arm die geistliche Hand,", "tokens": ["Welt\u00b7li\u00b7cher", "Arm", "die", "geist\u00b7li\u00b7che", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Da\u00df man also frech und frei", "tokens": ["Da\u00df", "man", "al\u00b7so", "frech", "und", "frei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Greife den Beutel der Klerisei?!", "tokens": ["Grei\u00b7fe", "den", "Beu\u00b7tel", "der", "Kle\u00b7ri\u00b7sei", "?!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Wehe! Selbst im guten \u00d6ster-", "tokens": ["We\u00b7he", "!", "Selbst", "im", "gu\u00b7ten", "\u00d6s\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "ADV", "APPRART", "ADJA", "TRUNC"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Reiche tadelt man die Kl\u00f6ster \u2013 \u2013", "tokens": ["Rei\u00b7che", "ta\u00b7delt", "man", "die", "Kl\u00f6s\u00b7ter", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "PIS", "ART", "NN", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und so weiter und so weiter \u2013 \u2013 \u2013", "tokens": ["Und", "so", "wei\u00b7ter", "und", "so", "wei\u00b7ter", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "ADV", "KON", "ADV", "ADV", "$(", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch das Ende ist nicht heiter!!!", "tokens": ["Doch", "das", "En\u00b7de", "ist", "nicht", "hei\u00b7ter", "!!!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ja, es ist abscheulich, greulich!!", "tokens": ["Ja", ",", "es", "ist", "ab\u00b7scheu\u00b7lich", ",", "greu\u00b7lich", "!!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADJD", "$,", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber siehe! wie erfreulich", "tokens": ["A\u00b7ber", "sie\u00b7he", "!", "wie", "er\u00b7freu\u00b7lich"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "VVIMP", "$.", "PWAV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist's dagegen, wenn wir lesen,", "tokens": ["Ist's", "da\u00b7ge\u00b7gen", ",", "wenn", "wir", "le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PAV", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie man sonsten fromm gewesen;", "tokens": ["Wie", "man", "sons\u00b7ten", "fromm", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ADJD", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie z.B. Sankt Anton,", "tokens": ["Wie", "z.", "B.", "Sankt", "An\u00b7ton", ","], "token_info": ["word", "abbreviation", "abbreviation", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "VVFIN", "NE", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Unsrer Kirche gro\u00dfer Sohn,", "tokens": ["Uns\u00b7rer", "Kir\u00b7che", "gro\u00b7\u00dfer", "Sohn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Litt und stritt und triumphierte \u2013", "tokens": ["Litt", "und", "stritt", "und", "tri\u00b7um\u00b7phier\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "KON", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Kurz! \u2013 ein christlich Leben f\u00fchrte \u2013", "tokens": ["Kurz", "!", "\u2013", "ein", "christ\u00b7lich", "Le\u00b7ben", "f\u00fchr\u00b7te", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "$(", "ART", "ADJD", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Dieses la\u00dft uns mit Bem\u00fchn", "tokens": ["Die\u00b7ses", "la\u00dft", "uns", "mit", "Be\u00b7m\u00fchn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Heute in Erw\u00e4gung ziehn.", "tokens": ["Heu\u00b7te", "in", "Er\u00b7w\u00e4\u00b7gung", "ziehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ach, ja, ja! \u2013 so seufz' ich immer \u2013;", "tokens": ["Ach", ",", "ja", ",", "ja", "!", "\u2013", "so", "seuf\u00b7z'", "ich", "im\u00b7mer", "\u2013", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "PTKANT", "$,", "ADV", "$.", "$(", "ADV", "VVFIN", "PPER", "ADV", "$(", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Denn die Zeit wird schlimm und schlimmer.", "tokens": ["Denn", "die", "Zeit", "wird", "schlimm", "und", "schlim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder kann in unsern Tagen", "tokens": ["O\u00b7der", "kann", "in", "un\u00b7sern", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einer wagen, nein! zu sagen,", "tokens": ["Ei\u00b7ner", "wa\u00b7gen", ",", "nein", "!", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVINF", "$,", "PTKANT", "$.", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der mit kindlichem Gem\u00fct", "tokens": ["Der", "mit", "kind\u00b7li\u00b7chem", "Ge\u00b7m\u00fct"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Morgens in die Zeitung sieht?", "tokens": ["Mor\u00b7gens", "in", "die", "Zei\u00b7tung", "sieht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Hier Romane, dort Gedichte,", "tokens": ["Hier", "Ro\u00b7ma\u00b7ne", ",", "dort", "Ge\u00b7dich\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "ADV", "NN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Malzextrakt und Kursberichte,", "tokens": ["Mal\u00b7zext\u00b7rakt", "und", "Kurs\u00b7be\u00b7rich\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "N\u00e4h- und M\u00e4h- und Waschmaschinen,", "tokens": ["N\u00e4h", "und", "M\u00e4h", "und", "Waschma\u00b7schi\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-++-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Klauenseuche und Trichinen \u2013 \u2013", "tokens": ["Klau\u00b7en\u00b7seu\u00b7che", "und", "Tri\u00b7chi\u00b7nen", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "NN", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieses druckt man gro\u00df und breit \u2013", "tokens": ["Die\u00b7ses", "druckt", "man", "gro\u00df", "und", "breit", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Aber wo ist Fr\u00f6mmigkeit??? \u2013", "tokens": ["A\u00b7ber", "wo", "ist", "Fr\u00f6m\u00b7mig\u00b7keit", "???", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWAV", "VAFIN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "H\u00e4lt denn nicht, o S\u00fcnd und Schand,", "tokens": ["H\u00e4lt", "denn", "nicht", ",", "o", "S\u00fcnd", "und", "Schand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "$,", "FM", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Weltlicher Arm die geistliche Hand,", "tokens": ["Welt\u00b7li\u00b7cher", "Arm", "die", "geist\u00b7li\u00b7che", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Da\u00df man also frech und frei", "tokens": ["Da\u00df", "man", "al\u00b7so", "frech", "und", "frei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Greife den Beutel der Klerisei?!", "tokens": ["Grei\u00b7fe", "den", "Beu\u00b7tel", "der", "Kle\u00b7ri\u00b7sei", "?!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.7": {"line.1": {"text": "Wehe! Selbst im guten \u00d6ster-", "tokens": ["We\u00b7he", "!", "Selbst", "im", "gu\u00b7ten", "\u00d6s\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "ADV", "APPRART", "ADJA", "TRUNC"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Reiche tadelt man die Kl\u00f6ster \u2013 \u2013", "tokens": ["Rei\u00b7che", "ta\u00b7delt", "man", "die", "Kl\u00f6s\u00b7ter", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "PIS", "ART", "NN", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und so weiter und so weiter \u2013 \u2013 \u2013", "tokens": ["Und", "so", "wei\u00b7ter", "und", "so", "wei\u00b7ter", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "ADV", "KON", "ADV", "ADV", "$(", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch das Ende ist nicht heiter!!!", "tokens": ["Doch", "das", "En\u00b7de", "ist", "nicht", "hei\u00b7ter", "!!!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Ja, es ist abscheulich, greulich!!", "tokens": ["Ja", ",", "es", "ist", "ab\u00b7scheu\u00b7lich", ",", "greu\u00b7lich", "!!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADJD", "$,", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber siehe! wie erfreulich", "tokens": ["A\u00b7ber", "sie\u00b7he", "!", "wie", "er\u00b7freu\u00b7lich"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "VVIMP", "$.", "PWAV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist's dagegen, wenn wir lesen,", "tokens": ["Ist's", "da\u00b7ge\u00b7gen", ",", "wenn", "wir", "le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PAV", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie man sonsten fromm gewesen;", "tokens": ["Wie", "man", "sons\u00b7ten", "fromm", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ADJD", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie z.B. Sankt Anton,", "tokens": ["Wie", "z.", "B.", "Sankt", "An\u00b7ton", ","], "token_info": ["word", "abbreviation", "abbreviation", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "VVFIN", "NE", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Unsrer Kirche gro\u00dfer Sohn,", "tokens": ["Uns\u00b7rer", "Kir\u00b7che", "gro\u00b7\u00dfer", "Sohn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Litt und stritt und triumphierte \u2013", "tokens": ["Litt", "und", "stritt", "und", "tri\u00b7um\u00b7phier\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "KON", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Kurz! \u2013 ein christlich Leben f\u00fchrte \u2013", "tokens": ["Kurz", "!", "\u2013", "ein", "christ\u00b7lich", "Le\u00b7ben", "f\u00fchr\u00b7te", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "$(", "ART", "ADJD", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Dieses la\u00dft uns mit Bem\u00fchn", "tokens": ["Die\u00b7ses", "la\u00dft", "uns", "mit", "Be\u00b7m\u00fchn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Heute in Erw\u00e4gung ziehn.", "tokens": ["Heu\u00b7te", "in", "Er\u00b7w\u00e4\u00b7gung", "ziehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}