{"textgrid.poem.44414": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "Der Heilige am Wege", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sankt Erasmus, dort am Hange", "tokens": ["Sankt", "Er\u00b7as\u00b7mus", ",", "dort", "am", "Han\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "NE", "$,", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Scheinst, ein Mahner, du zu stehn.", "tokens": ["Scheinst", ",", "ein", "Mah\u00b7ner", ",", "du", "zu", "stehn", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, wir kennen uns schon lange,", "tokens": ["Ach", ",", "wir", "ken\u00b7nen", "uns", "schon", "lan\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hast ja oft mich einst gesehn,", "tokens": ["Hast", "ja", "oft", "mich", "einst", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Rasch zu Pferd, in hastger Eile,", "tokens": ["Rasch", "zu", "Pferd", ",", "in", "hast\u00b7ger", "Ei\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hoffnung schnaubend und Genu\u00df.", "tokens": ["Hoff\u00b7nung", "schnau\u00b7bend", "und", "Ge\u00b7nu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun ein Bild der langen Weile,", "tokens": ["Nun", "ein", "Bild", "der", "lan\u00b7gen", "Wei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sankt Erasmus \u2013 und zu Fu\u00df.", "tokens": ["Sankt", "Er\u00b7as\u00b7mus", "\u2013", "und", "zu", "Fu\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$(", "KON", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Sankt Erasmus, dort am Hange", "tokens": ["Sankt", "Er\u00b7as\u00b7mus", ",", "dort", "am", "Han\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "NE", "$,", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Scheinst, ein Mahner, du zu stehn.", "tokens": ["Scheinst", ",", "ein", "Mah\u00b7ner", ",", "du", "zu", "stehn", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, wir kennen uns schon lange,", "tokens": ["Ach", ",", "wir", "ken\u00b7nen", "uns", "schon", "lan\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hast ja oft mich einst gesehn,", "tokens": ["Hast", "ja", "oft", "mich", "einst", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Rasch zu Pferd, in hastger Eile,", "tokens": ["Rasch", "zu", "Pferd", ",", "in", "hast\u00b7ger", "Ei\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hoffnung schnaubend und Genu\u00df.", "tokens": ["Hoff\u00b7nung", "schnau\u00b7bend", "und", "Ge\u00b7nu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun ein Bild der langen Weile,", "tokens": ["Nun", "ein", "Bild", "der", "lan\u00b7gen", "Wei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sankt Erasmus \u2013 und zu Fu\u00df.", "tokens": ["Sankt", "Er\u00b7as\u00b7mus", "\u2013", "und", "zu", "Fu\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$(", "KON", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}