{"textgrid.poem.31764": {"metadata": {"author": {"name": "Weerth, Georg", "birth": "N.A.", "death": "N.A."}, "title": "2.", "genre": "verse", "period": "N.A.", "pub_year": 1839, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Herr Soherr wohnt im wei\u00dfen Ro\u00df \u2013", "tokens": ["Herr", "So\u00b7herr", "wohnt", "im", "wei\u00b7\u00dfen", "Ro\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "(da\u00df ich je ihn verlie\u00df, ich bereu es) \u2013", "tokens": ["(", "da\u00df", "ich", "je", "ihn", "ver\u00b7lie\u00df", ",", "ich", "be\u00b7reu", "es", ")", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "PPER", "VVFIN", "$,", "PPER", "ADJD", "PPER", "$(", "$("], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "\u00bbwillkommen!\u00ab so sprach er, \u00bbmein lieber Herr Weerth,", "tokens": ["\u00bb", "will\u00b7kom\u00b7men", "!", "\u00ab", "so", "sprach", "er", ",", "\u00bb", "mein", "lie\u00b7ber", "Herr", "Weerth", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$.", "$(", "ADV", "VVFIN", "PPER", "$,", "$(", "PPOSAT", "ADJA", "NN", "NE", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Willkommen! was haben Sie Neues?", "tokens": ["Will\u00b7kom\u00b7men", "!", "was", "ha\u00b7ben", "Sie", "Neu\u00b7es", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "VAFIN", "PPER", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "Sie sehn so verst\u00f6rt und so fl\u00fcchtig aus", "tokens": ["Sie", "sehn", "so", "ver\u00b7st\u00f6rt", "und", "so", "fl\u00fcch\u00b7tig", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "VVPP", "KON", "ADV", "ADJD", "PTKVZ"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wie ein Mann ohne Geld und Courage.", "tokens": ["Wie", "ein", "Mann", "oh\u00b7ne", "Geld", "und", "Cou\u00b7ra\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wie kommt's, da\u00df Sie reisen im schwarzen Frack?", "tokens": ["Wie", "kommt's", ",", "da\u00df", "Sie", "rei\u00b7sen", "im", "schwar\u00b7zen", "Frack", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Wo lie\u00dfen Sie Ihre Bagage?", "tokens": ["Wo", "lie\u00b7\u00dfen", "Sie", "Ih\u00b7re", "Ba\u00b7ga\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "Sie haben gewi\u00df in Ems gespielt!", "tokens": ["Sie", "ha\u00b7ben", "ge\u00b7wi\u00df", "in", "Ems", "ge\u00b7spielt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NE", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Oder haben Sie sich duellieret?", "tokens": ["O\u00b7der", "ha\u00b7ben", "Sie", "sich", "du\u00b7el\u00b7lie\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Oder haben Sie gar zu K\u00f6ln am Rhein", "tokens": ["O\u00b7der", "ha\u00b7ben", "Sie", "gar", "zu", "K\u00f6ln", "am", "Rhein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "NE", "APPRART", "NE"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Sich ", "tokens": ["Sich"], "token_info": ["word"], "pos": ["PRF"], "meter": "-", "measure": "single.down"}}, "stanza.4": {"line.1": {"text": "\u00bbmein Vater Soherr!\u00ab versetzte ich da,", "tokens": ["\u00bb", "mein", "Va\u00b7ter", "So\u00b7herr", "!", "\u00ab", "ver\u00b7setz\u00b7te", "ich", "da", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "NN", "$.", "$(", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bberb\u00e4rmlich sind die Zeiten.", "tokens": ["\u00bb", "er\u00b7b\u00e4rm\u00b7lich", "sind", "die", "Zei\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch kompromittier ich mich nie, denn das", "tokens": ["Doch", "kom\u00b7pro\u00b7mit\u00b7tier", "ich", "mich", "nie", ",", "denn", "das"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "$,", "KON", "ART"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "\u00dcberla\u00df ich anderen Leuten.", "tokens": ["\u00dc\u00b7berl\u00b7a\u00df", "ich", "an\u00b7de\u00b7ren", "Leu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Mit sch\u00f6nen Fraun hab ich lieber zu tun", "tokens": ["Mit", "sch\u00f6\u00b7nen", "Fraun", "hab", "ich", "lie\u00b7ber", "zu", "tun"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Als mit sch\u00f6nen preu\u00df'schen Soldaten.", "tokens": ["Als", "mit", "sch\u00f6\u00b7nen", "preu\u00df'\u00b7schen", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "ADJA", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und als ich am Lurlei vor\u00fcberkam:", "tokens": ["Und", "als", "ich", "am", "Lur\u00b7lei", "vor\u00b7\u00fc\u00b7ber\u00b7kam", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da war ich verkauft und verraten.", "tokens": ["Da", "war", "ich", "ver\u00b7kauft", "und", "ver\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "KON", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.6": {"line.1": {"text": "Ich sah sie sitzen, die nackte Fee,", "tokens": ["Ich", "sah", "sie", "sit\u00b7zen", ",", "die", "nack\u00b7te", "Fee", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVINF", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und ich h\u00f6rte ihr l\u00fcsternes Singen;", "tokens": ["Und", "ich", "h\u00f6r\u00b7te", "ihr", "l\u00fcs\u00b7ter\u00b7nes", "Sin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und mit Koffer und Reisesack sank ich hinab,", "tokens": ["Und", "mit", "Kof\u00b7fer", "und", "Rei\u00b7se\u00b7sack", "sank", "ich", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ihren wonnigen Leib zu umschlingen.", "tokens": ["Ih\u00b7ren", "won\u00b7ni\u00b7gen", "Leib", "zu", "um\u00b7schlin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Das war eine Barrikadenschlacht", "tokens": ["Das", "war", "ei\u00b7ne", "Bar\u00b7ri\u00b7ka\u00b7den\u00b7schlacht"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Auf ihren schneewei\u00dfen Br\u00fcsten!", "tokens": ["Auf", "ih\u00b7ren", "schnee\u00b7wei\u00b7\u00dfen", "Br\u00fcs\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Mit heiler Haut kam ich eben davon,", "tokens": ["Mit", "hei\u00b7ler", "Haut", "kam", "ich", "e\u00b7ben", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV", "PAV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch verlor ich Koffer und Kisten \u2013\u00ab", "tokens": ["Doch", "ver\u00b7lor", "ich", "Kof\u00b7fer", "und", "Kis\u00b7ten", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "KON", "NN", "$(", "$("], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Da lachte Herr Soherr und zeigte mir", "tokens": ["Da", "lach\u00b7te", "Herr", "So\u00b7herr", "und", "zeig\u00b7te", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "NN", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Seinen letzten Zahn \u2013 alleine", "tokens": ["Sei\u00b7nen", "letz\u00b7ten", "Zahn", "\u2013", "al\u00b7lei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Steht der in seiner Kinnlade wie", "tokens": ["Steht", "der", "in", "sei\u00b7ner", "Kinn\u00b7la\u00b7de", "wie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "APPR", "PPOSAT", "NN", "KOKOM"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Der M\u00e4useturm im Rheine.", "tokens": ["Der", "M\u00e4u\u00b7se\u00b7turm", "im", "Rhei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Herr Soherr wohnt im wei\u00dfen Ro\u00df \u2013", "tokens": ["Herr", "So\u00b7herr", "wohnt", "im", "wei\u00b7\u00dfen", "Ro\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "(da\u00df ich je ihn verlie\u00df, ich bereu es) \u2013", "tokens": ["(", "da\u00df", "ich", "je", "ihn", "ver\u00b7lie\u00df", ",", "ich", "be\u00b7reu", "es", ")", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "PPER", "VVFIN", "$,", "PPER", "ADJD", "PPER", "$(", "$("], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "\u00bbwillkommen!\u00ab so sprach er, \u00bbmein lieber Herr Weerth,", "tokens": ["\u00bb", "will\u00b7kom\u00b7men", "!", "\u00ab", "so", "sprach", "er", ",", "\u00bb", "mein", "lie\u00b7ber", "Herr", "Weerth", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$.", "$(", "ADV", "VVFIN", "PPER", "$,", "$(", "PPOSAT", "ADJA", "NN", "NE", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Willkommen! was haben Sie Neues?", "tokens": ["Will\u00b7kom\u00b7men", "!", "was", "ha\u00b7ben", "Sie", "Neu\u00b7es", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "VAFIN", "PPER", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.10": {"line.1": {"text": "Sie sehn so verst\u00f6rt und so fl\u00fcchtig aus", "tokens": ["Sie", "sehn", "so", "ver\u00b7st\u00f6rt", "und", "so", "fl\u00fcch\u00b7tig", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "VVPP", "KON", "ADV", "ADJD", "PTKVZ"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wie ein Mann ohne Geld und Courage.", "tokens": ["Wie", "ein", "Mann", "oh\u00b7ne", "Geld", "und", "Cou\u00b7ra\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wie kommt's, da\u00df Sie reisen im schwarzen Frack?", "tokens": ["Wie", "kommt's", ",", "da\u00df", "Sie", "rei\u00b7sen", "im", "schwar\u00b7zen", "Frack", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Wo lie\u00dfen Sie Ihre Bagage?", "tokens": ["Wo", "lie\u00b7\u00dfen", "Sie", "Ih\u00b7re", "Ba\u00b7ga\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.11": {"line.1": {"text": "Sie haben gewi\u00df in Ems gespielt!", "tokens": ["Sie", "ha\u00b7ben", "ge\u00b7wi\u00df", "in", "Ems", "ge\u00b7spielt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NE", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Oder haben Sie sich duellieret?", "tokens": ["O\u00b7der", "ha\u00b7ben", "Sie", "sich", "du\u00b7el\u00b7lie\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Oder haben Sie gar zu K\u00f6ln am Rhein", "tokens": ["O\u00b7der", "ha\u00b7ben", "Sie", "gar", "zu", "K\u00f6ln", "am", "Rhein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "NE", "APPRART", "NE"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Sich ", "tokens": ["Sich"], "token_info": ["word"], "pos": ["PRF"], "meter": "-", "measure": "single.down"}}, "stanza.12": {"line.1": {"text": "\u00bbmein Vater Soherr!\u00ab versetzte ich da,", "tokens": ["\u00bb", "mein", "Va\u00b7ter", "So\u00b7herr", "!", "\u00ab", "ver\u00b7setz\u00b7te", "ich", "da", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "NN", "$.", "$(", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bberb\u00e4rmlich sind die Zeiten.", "tokens": ["\u00bb", "er\u00b7b\u00e4rm\u00b7lich", "sind", "die", "Zei\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch kompromittier ich mich nie, denn das", "tokens": ["Doch", "kom\u00b7pro\u00b7mit\u00b7tier", "ich", "mich", "nie", ",", "denn", "das"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "$,", "KON", "ART"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "\u00dcberla\u00df ich anderen Leuten.", "tokens": ["\u00dc\u00b7berl\u00b7a\u00df", "ich", "an\u00b7de\u00b7ren", "Leu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Mit sch\u00f6nen Fraun hab ich lieber zu tun", "tokens": ["Mit", "sch\u00f6\u00b7nen", "Fraun", "hab", "ich", "lie\u00b7ber", "zu", "tun"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Als mit sch\u00f6nen preu\u00df'schen Soldaten.", "tokens": ["Als", "mit", "sch\u00f6\u00b7nen", "preu\u00df'\u00b7schen", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "ADJA", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und als ich am Lurlei vor\u00fcberkam:", "tokens": ["Und", "als", "ich", "am", "Lur\u00b7lei", "vor\u00b7\u00fc\u00b7ber\u00b7kam", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da war ich verkauft und verraten.", "tokens": ["Da", "war", "ich", "ver\u00b7kauft", "und", "ver\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "KON", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.14": {"line.1": {"text": "Ich sah sie sitzen, die nackte Fee,", "tokens": ["Ich", "sah", "sie", "sit\u00b7zen", ",", "die", "nack\u00b7te", "Fee", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVINF", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und ich h\u00f6rte ihr l\u00fcsternes Singen;", "tokens": ["Und", "ich", "h\u00f6r\u00b7te", "ihr", "l\u00fcs\u00b7ter\u00b7nes", "Sin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und mit Koffer und Reisesack sank ich hinab,", "tokens": ["Und", "mit", "Kof\u00b7fer", "und", "Rei\u00b7se\u00b7sack", "sank", "ich", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ihren wonnigen Leib zu umschlingen.", "tokens": ["Ih\u00b7ren", "won\u00b7ni\u00b7gen", "Leib", "zu", "um\u00b7schlin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Das war eine Barrikadenschlacht", "tokens": ["Das", "war", "ei\u00b7ne", "Bar\u00b7ri\u00b7ka\u00b7den\u00b7schlacht"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Auf ihren schneewei\u00dfen Br\u00fcsten!", "tokens": ["Auf", "ih\u00b7ren", "schnee\u00b7wei\u00b7\u00dfen", "Br\u00fcs\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Mit heiler Haut kam ich eben davon,", "tokens": ["Mit", "hei\u00b7ler", "Haut", "kam", "ich", "e\u00b7ben", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV", "PAV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch verlor ich Koffer und Kisten \u2013\u00ab", "tokens": ["Doch", "ver\u00b7lor", "ich", "Kof\u00b7fer", "und", "Kis\u00b7ten", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "KON", "NN", "$(", "$("], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Da lachte Herr Soherr und zeigte mir", "tokens": ["Da", "lach\u00b7te", "Herr", "So\u00b7herr", "und", "zeig\u00b7te", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "NN", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Seinen letzten Zahn \u2013 alleine", "tokens": ["Sei\u00b7nen", "letz\u00b7ten", "Zahn", "\u2013", "al\u00b7lei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Steht der in seiner Kinnlade wie", "tokens": ["Steht", "der", "in", "sei\u00b7ner", "Kinn\u00b7la\u00b7de", "wie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "APPR", "PPOSAT", "NN", "KOKOM"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Der M\u00e4useturm im Rheine.", "tokens": ["Der", "M\u00e4u\u00b7se\u00b7turm", "im", "Rhei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}