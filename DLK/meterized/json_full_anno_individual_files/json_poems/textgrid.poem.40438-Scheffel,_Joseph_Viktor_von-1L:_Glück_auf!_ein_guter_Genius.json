{"textgrid.poem.40438": {"metadata": {"author": {"name": "Scheffel, Joseph Viktor von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Gl\u00fcck auf! ein guter Genius", "genre": "verse", "period": "N.A.", "pub_year": 1856, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gl\u00fcck auf! ein guter Genius", "tokens": ["Gl\u00fcck", "auf", "!", "ein", "gu\u00b7ter", "Ge\u00b7nius"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Kommt heut zum Schlo\u00df gezogen,", "tokens": ["Kommt", "heut", "zum", "Schlo\u00df", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Kollegialisch dr\u00f6hnt mein Gru\u00df", "tokens": ["Kol\u00b7le\u00b7gi\u00b7a\u00b7lisch", "dr\u00f6hnt", "mein", "Gru\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPOSAT", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Euch deutschen Philologen:", "tokens": ["Euch", "deut\u00b7schen", "Phi\u00b7lo\u00b7lo\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn ihr durchforscht mit Blick und Gl\u00fcck", "tokens": ["Denn", "ihr", "durch\u00b7forscht", "mit", "Blick", "und", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Vorzeit Schicht' um Schichte,", "tokens": ["Die", "Vor\u00b7zeit", "Schicht'", "um", "Schich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und ich, durchmorscht, bin selbst ein St\u00fcck", "tokens": ["Und", "ich", ",", "durch\u00b7morscht", ",", "bin", "selbst", "ein", "St\u00fcck"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "VVFIN", "$,", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Kultur und Sprachgeschichte.", "tokens": ["Kul\u00b7tur", "und", "Sprach\u00b7ge\u00b7schich\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Den Geist schlimm aufgehoben", "tokens": ["Den", "Geist", "schlimm", "auf\u00b7ge\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und sog des Palmsafts heil'ge Flut", "tokens": ["Und", "sog", "des", "Palm\u00b7safts", "heil'\u00b7ge", "Flut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aus dicken ", "tokens": ["Aus", "di\u00b7cken"], "token_info": ["word", "word"], "pos": ["APPR", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Auch dem ", "tokens": ["Auch", "dem"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Getr\u00e4nk zu \u00fcberwintern,", "tokens": ["Ge\u00b7tr\u00e4nk", "zu", "\u00fc\u00b7berw\u00b7in\u00b7tern", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Verschimmelt stand sein Dattelwein", "tokens": ["Ver\u00b7schim\u00b7melt", "stand", "sein", "Dat\u00b7tel\u00b7wein"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.3": {"line.1": {"text": "Der Stoff des weisen ", "tokens": ["Der", "Stoff", "des", "wei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Kam nie zu feinem Hauche,", "tokens": ["Kam", "nie", "zu", "fei\u00b7nem", "Hau\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn sein Bukett blieb immer roh", "tokens": ["Denn", "sein", "Bu\u00b7kett", "blieb", "im\u00b7mer", "roh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im dunkeln ", "tokens": ["Im", "dun\u00b7keln"], "token_info": ["word", "word"], "pos": ["APPRART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Erst als ", "tokens": ["Erst", "als"], "token_info": ["word", "word"], "pos": ["ADV", "KOKOM"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Umschmolzen in den Aschen,", "tokens": ["Um\u00b7schmol\u00b7zen", "in", "den", "A\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sah Israel ... zwar noch kein Fa\u00df,", "tokens": ["Sah", "Is\u00b7rael", "...", "zwar", "noch", "kein", "Fa\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$(", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Doch schon ... ", "tokens": ["Doch", "schon", "..."], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$("], "meter": "-+", "measure": "iambic.single"}}, "stanza.4": {"line.1": {"text": "Lie\u00df wild die Rebe treiben,", "tokens": ["Lie\u00df", "wild", "die", "Re\u00b7be", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Salamander drohten sehr", "tokens": ["Die", "Sa\u00b7la\u00b7man\u00b7der", "droh\u00b7ten", "sehr"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Menschen aufzureiben.", "tokens": ["Den", "Men\u00b7schen", "auf\u00b7zu\u00b7rei\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der erste, der im Urwald keck", "tokens": ["Der", "ers\u00b7te", ",", "der", "im", "Ur\u00b7wald", "keck"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "PRELS", "APPRART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sich briet den Urstierschlegel,", "tokens": ["Sich", "briet", "den", "Ur\u00b7stier\u00b7schle\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Trug seinen Meth als Handgep\u00e4ck", "tokens": ["Trug", "sei\u00b7nen", "Me\u00b7th", "als", "Hand\u00b7ge\u00b7p\u00e4ck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "KOUS", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "In einem schmalen ", "tokens": ["In", "ei\u00b7nem", "schma\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Und niedrer Bildungsstufe,", "tokens": ["Und", "nie\u00b7drer", "Bil\u00b7dungs\u00b7stu\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Barg ein sehr zweifelhaftes Na\u00df", "tokens": ["Barg", "ein", "sehr", "zwei\u00b7fel\u00b7haf\u00b7tes", "Na\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In zweifelhafter ", "tokens": ["In", "zwei\u00b7fel\u00b7haf\u00b7ter"], "token_info": ["word", "word"], "pos": ["APPR", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "In der ", "tokens": ["In", "der"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Bei V\u00f6lkern rauh und zottig,", "tokens": ["Bei", "V\u00f6l\u00b7kern", "rauh", "und", "zot\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Kam auch kein gro\u00dfes Fa\u00df zum Bau,", "tokens": ["Kam", "auch", "kein", "gro\u00b7\u00dfes", "Fa\u00df", "zum", "Bau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PIAT", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nur ", "tokens": ["Nur"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}}, "stanza.6": {"line.1": {"text": "Doch nicht f\u00fcr Bacchos Wonnen;", "tokens": ["Doch", "nicht", "f\u00fcr", "Bac\u00b7chos", "Won\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Man pflag statt Weins Philosophie", "tokens": ["Man", "pflag", "statt", "Weins", "Phi\u00b7lo\u00b7so\u00b7phie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In leeren hohlen ", "tokens": ["In", "lee\u00b7ren", "hoh\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Das zweckbewu\u00dfte ", "tokens": ["Das", "zweck\u00b7be\u00b7wu\u00df\u00b7te"], "token_info": ["word", "word"], "pos": ["PDS", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Bedurfte starker ", "tokens": ["Be\u00b7durf\u00b7te", "star\u00b7ker"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Zum ", "tokens": ["Zum"], "token_info": ["word"], "pos": ["APPRART"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Schlich Plinius schon als Knabe.", "tokens": ["Schlich", "Pli\u00b7nius", "schon", "als", "Kna\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "KOUS", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Doch das antike ", "tokens": ["Doch", "das", "an\u00b7ti\u00b7ke"], "token_info": ["word", "word", "word"], "pos": ["KON", "PDS", "VVFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Von Ton und spitz nach unten,", "tokens": ["Von", "Ton", "und", "spitz", "nach", "un\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJD", "APPR", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und auch vom ", "tokens": ["Und", "auch", "vom"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "APPRART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Ob Reif er trug und Spunten.", "tokens": ["Ob", "Reif", "er", "trug", "und", "Spun\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das echte Fa\u00df zeigt deutschen Schwung,", "tokens": ["Das", "ech\u00b7te", "Fa\u00df", "zeigt", "deut\u00b7schen", "Schwung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es gingen die Germanen", "tokens": ["Es", "gin\u00b7gen", "die", "Ger\u00b7ma\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Schon auf die V\u00f6lkerwanderung", "tokens": ["Schon", "auf", "die", "V\u00f6l\u00b7ker\u00b7wan\u00b7de\u00b7rung"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.8": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.8": {"line.1": {"text": "Im Keller seines Schlosses:", "tokens": ["Im", "Kel\u00b7ler", "sei\u00b7nes", "Schlos\u00b7ses", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Du liebes Fa\u00df, du gro\u00dfes!\u00ab", "tokens": ["Du", "lie\u00b7bes", "Fa\u00df", ",", "du", "gro\u00b7\u00dfes", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und oft sah ihn der ", "tokens": ["Und", "oft", "sah", "ihn", "der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Vergn\u00fcgt dem Reichsschenk winken:", "tokens": ["Ver\u00b7gn\u00fcgt", "dem", "Reichs\u00b7schenk", "win\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbschafft eine Ma\u00df zu trinken her!", "tokens": ["\u00bb", "schafft", "ei\u00b7ne", "Ma\u00df", "zu", "trin\u00b7ken", "her", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Des ", "tokens": ["Des"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Den Reichstag gern beim Fasse", "tokens": ["Den", "Reichs\u00b7tag", "gern", "beim", "Fas\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sang, wenn's auf die Neige ging,", "tokens": ["Und", "sang", ",", "wenn's", "auf", "die", "Nei\u00b7ge", "ging", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.10": {"line.1": {"text": "Als edler Bildungsdurst die Welt", "tokens": ["Als", "ed\u00b7ler", "Bil\u00b7dungs\u00b7durst", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erf\u00fcllt mit edlem Streben,", "tokens": ["Er\u00b7f\u00fcllt", "mit", "ed\u00b7lem", "Stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Rief mich ein Kurf\u00fcrst und ein Held", "tokens": ["Rief", "mich", "ein", "Kur\u00b7f\u00fcrst", "und", "ein", "Held"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Burgfa\u00df hier ins Leben.", "tokens": ["Als", "Burg\u00b7fa\u00df", "hier", "ins", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Noch steh' ich fest, wo alles fiel,", "tokens": ["Noch", "steh'", "ich", "fest", ",", "wo", "al\u00b7les", "fiel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des Pf\u00e4lzer Geists ein Funken:", "tokens": ["Des", "Pf\u00e4l\u00b7zer", "Geists", "ein", "Fun\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Gro\u00df im Gedanken, flott im Stil", "tokens": ["Gro\u00df", "im", "Ge\u00b7dan\u00b7ken", ",", "flott", "im", "Stil"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "APPRART", "NN", "$,", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und g\u00e4nzlich \u2013 leergetrunken.", "tokens": ["Und", "g\u00e4nz\u00b7lich", "\u2013", "leer\u00b7ge\u00b7trun\u00b7ken", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "$(", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "O w\u00e4r' ich voll heut, Mann und Glas", "tokens": ["O", "w\u00e4r'", "ich", "voll", "heut", ",", "Mann", "und", "Glas"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "ADJD", "ADV", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcllt' ich mit Rheinweinmassen!", "tokens": ["F\u00fcllt'", "ich", "mit", "Rhein\u00b7wein\u00b7mas\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch weh und ach!... dem Hauptwort \u00bbFa\u00df\u00ab", "tokens": ["Doch", "weh", "und", "ach", "!", "...", "dem", "Haupt\u00b7wort", "\u00bb", "Fa\u00df", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "KON", "XY", "$.", "$(", "ART", "NN", "$(", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fehlt l\u00e4ngst sein Zeitwort \u00bb", "tokens": ["Fehlt", "l\u00e4ngst", "sein", "Zeit\u00b7wort", "\u00bb"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.6": {"text": "Zu bacchischem Gedichte ...", "tokens": ["Zu", "bac\u00b7chi\u00b7schem", "Ge\u00b7dich\u00b7te", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "... Ich bitt' nur um die Note \u00bbgut\u00ab", "tokens": ["...", "Ich", "bitt'", "nur", "um", "die", "No\u00b7te", "\u00bb", "gut", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$(", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In \u00bbSprache und Geschichte\u00ab.", "tokens": ["In", "\u00bb", "Spra\u00b7che", "und", "Ge\u00b7schich\u00b7te", "\u00ab", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "$(", "NN", "KON", "NN", "$(", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Gl\u00fcck auf! ein guter Genius", "tokens": ["Gl\u00fcck", "auf", "!", "ein", "gu\u00b7ter", "Ge\u00b7nius"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Kommt heut zum Schlo\u00df gezogen,", "tokens": ["Kommt", "heut", "zum", "Schlo\u00df", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Kollegialisch dr\u00f6hnt mein Gru\u00df", "tokens": ["Kol\u00b7le\u00b7gi\u00b7a\u00b7lisch", "dr\u00f6hnt", "mein", "Gru\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPOSAT", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Euch deutschen Philologen:", "tokens": ["Euch", "deut\u00b7schen", "Phi\u00b7lo\u00b7lo\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn ihr durchforscht mit Blick und Gl\u00fcck", "tokens": ["Denn", "ihr", "durch\u00b7forscht", "mit", "Blick", "und", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Vorzeit Schicht' um Schichte,", "tokens": ["Die", "Vor\u00b7zeit", "Schicht'", "um", "Schich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und ich, durchmorscht, bin selbst ein St\u00fcck", "tokens": ["Und", "ich", ",", "durch\u00b7morscht", ",", "bin", "selbst", "ein", "St\u00fcck"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "VVFIN", "$,", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Kultur und Sprachgeschichte.", "tokens": ["Kul\u00b7tur", "und", "Sprach\u00b7ge\u00b7schich\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Den Geist schlimm aufgehoben", "tokens": ["Den", "Geist", "schlimm", "auf\u00b7ge\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und sog des Palmsafts heil'ge Flut", "tokens": ["Und", "sog", "des", "Palm\u00b7safts", "heil'\u00b7ge", "Flut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aus dicken ", "tokens": ["Aus", "di\u00b7cken"], "token_info": ["word", "word"], "pos": ["APPR", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Auch dem ", "tokens": ["Auch", "dem"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Getr\u00e4nk zu \u00fcberwintern,", "tokens": ["Ge\u00b7tr\u00e4nk", "zu", "\u00fc\u00b7berw\u00b7in\u00b7tern", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Verschimmelt stand sein Dattelwein", "tokens": ["Ver\u00b7schim\u00b7melt", "stand", "sein", "Dat\u00b7tel\u00b7wein"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.14": {"line.1": {"text": "Der Stoff des weisen ", "tokens": ["Der", "Stoff", "des", "wei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Kam nie zu feinem Hauche,", "tokens": ["Kam", "nie", "zu", "fei\u00b7nem", "Hau\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn sein Bukett blieb immer roh", "tokens": ["Denn", "sein", "Bu\u00b7kett", "blieb", "im\u00b7mer", "roh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im dunkeln ", "tokens": ["Im", "dun\u00b7keln"], "token_info": ["word", "word"], "pos": ["APPRART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Erst als ", "tokens": ["Erst", "als"], "token_info": ["word", "word"], "pos": ["ADV", "KOKOM"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Umschmolzen in den Aschen,", "tokens": ["Um\u00b7schmol\u00b7zen", "in", "den", "A\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sah Israel ... zwar noch kein Fa\u00df,", "tokens": ["Sah", "Is\u00b7rael", "...", "zwar", "noch", "kein", "Fa\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$(", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Doch schon ... ", "tokens": ["Doch", "schon", "..."], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$("], "meter": "-+", "measure": "iambic.single"}}, "stanza.15": {"line.1": {"text": "Lie\u00df wild die Rebe treiben,", "tokens": ["Lie\u00df", "wild", "die", "Re\u00b7be", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Salamander drohten sehr", "tokens": ["Die", "Sa\u00b7la\u00b7man\u00b7der", "droh\u00b7ten", "sehr"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Menschen aufzureiben.", "tokens": ["Den", "Men\u00b7schen", "auf\u00b7zu\u00b7rei\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der erste, der im Urwald keck", "tokens": ["Der", "ers\u00b7te", ",", "der", "im", "Ur\u00b7wald", "keck"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "PRELS", "APPRART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sich briet den Urstierschlegel,", "tokens": ["Sich", "briet", "den", "Ur\u00b7stier\u00b7schle\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Trug seinen Meth als Handgep\u00e4ck", "tokens": ["Trug", "sei\u00b7nen", "Me\u00b7th", "als", "Hand\u00b7ge\u00b7p\u00e4ck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "KOUS", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "In einem schmalen ", "tokens": ["In", "ei\u00b7nem", "schma\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Und niedrer Bildungsstufe,", "tokens": ["Und", "nie\u00b7drer", "Bil\u00b7dungs\u00b7stu\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Barg ein sehr zweifelhaftes Na\u00df", "tokens": ["Barg", "ein", "sehr", "zwei\u00b7fel\u00b7haf\u00b7tes", "Na\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In zweifelhafter ", "tokens": ["In", "zwei\u00b7fel\u00b7haf\u00b7ter"], "token_info": ["word", "word"], "pos": ["APPR", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "In der ", "tokens": ["In", "der"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Bei V\u00f6lkern rauh und zottig,", "tokens": ["Bei", "V\u00f6l\u00b7kern", "rauh", "und", "zot\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Kam auch kein gro\u00dfes Fa\u00df zum Bau,", "tokens": ["Kam", "auch", "kein", "gro\u00b7\u00dfes", "Fa\u00df", "zum", "Bau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PIAT", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nur ", "tokens": ["Nur"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}}, "stanza.17": {"line.1": {"text": "Doch nicht f\u00fcr Bacchos Wonnen;", "tokens": ["Doch", "nicht", "f\u00fcr", "Bac\u00b7chos", "Won\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Man pflag statt Weins Philosophie", "tokens": ["Man", "pflag", "statt", "Weins", "Phi\u00b7lo\u00b7so\u00b7phie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In leeren hohlen ", "tokens": ["In", "lee\u00b7ren", "hoh\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Das zweckbewu\u00dfte ", "tokens": ["Das", "zweck\u00b7be\u00b7wu\u00df\u00b7te"], "token_info": ["word", "word"], "pos": ["PDS", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Bedurfte starker ", "tokens": ["Be\u00b7durf\u00b7te", "star\u00b7ker"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Zum ", "tokens": ["Zum"], "token_info": ["word"], "pos": ["APPRART"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Schlich Plinius schon als Knabe.", "tokens": ["Schlich", "Pli\u00b7nius", "schon", "als", "Kna\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "KOUS", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Doch das antike ", "tokens": ["Doch", "das", "an\u00b7ti\u00b7ke"], "token_info": ["word", "word", "word"], "pos": ["KON", "PDS", "VVFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Von Ton und spitz nach unten,", "tokens": ["Von", "Ton", "und", "spitz", "nach", "un\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJD", "APPR", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und auch vom ", "tokens": ["Und", "auch", "vom"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "APPRART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Ob Reif er trug und Spunten.", "tokens": ["Ob", "Reif", "er", "trug", "und", "Spun\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das echte Fa\u00df zeigt deutschen Schwung,", "tokens": ["Das", "ech\u00b7te", "Fa\u00df", "zeigt", "deut\u00b7schen", "Schwung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es gingen die Germanen", "tokens": ["Es", "gin\u00b7gen", "die", "Ger\u00b7ma\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Schon auf die V\u00f6lkerwanderung", "tokens": ["Schon", "auf", "die", "V\u00f6l\u00b7ker\u00b7wan\u00b7de\u00b7rung"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.8": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.19": {"line.1": {"text": "Im Keller seines Schlosses:", "tokens": ["Im", "Kel\u00b7ler", "sei\u00b7nes", "Schlos\u00b7ses", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Du liebes Fa\u00df, du gro\u00dfes!\u00ab", "tokens": ["Du", "lie\u00b7bes", "Fa\u00df", ",", "du", "gro\u00b7\u00dfes", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und oft sah ihn der ", "tokens": ["Und", "oft", "sah", "ihn", "der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Vergn\u00fcgt dem Reichsschenk winken:", "tokens": ["Ver\u00b7gn\u00fcgt", "dem", "Reichs\u00b7schenk", "win\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbschafft eine Ma\u00df zu trinken her!", "tokens": ["\u00bb", "schafft", "ei\u00b7ne", "Ma\u00df", "zu", "trin\u00b7ken", "her", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Des ", "tokens": ["Des"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Den Reichstag gern beim Fasse", "tokens": ["Den", "Reichs\u00b7tag", "gern", "beim", "Fas\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sang, wenn's auf die Neige ging,", "tokens": ["Und", "sang", ",", "wenn's", "auf", "die", "Nei\u00b7ge", "ging", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.21": {"line.1": {"text": "Als edler Bildungsdurst die Welt", "tokens": ["Als", "ed\u00b7ler", "Bil\u00b7dungs\u00b7durst", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erf\u00fcllt mit edlem Streben,", "tokens": ["Er\u00b7f\u00fcllt", "mit", "ed\u00b7lem", "Stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Rief mich ein Kurf\u00fcrst und ein Held", "tokens": ["Rief", "mich", "ein", "Kur\u00b7f\u00fcrst", "und", "ein", "Held"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Burgfa\u00df hier ins Leben.", "tokens": ["Als", "Burg\u00b7fa\u00df", "hier", "ins", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Noch steh' ich fest, wo alles fiel,", "tokens": ["Noch", "steh'", "ich", "fest", ",", "wo", "al\u00b7les", "fiel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des Pf\u00e4lzer Geists ein Funken:", "tokens": ["Des", "Pf\u00e4l\u00b7zer", "Geists", "ein", "Fun\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Gro\u00df im Gedanken, flott im Stil", "tokens": ["Gro\u00df", "im", "Ge\u00b7dan\u00b7ken", ",", "flott", "im", "Stil"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "APPRART", "NN", "$,", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und g\u00e4nzlich \u2013 leergetrunken.", "tokens": ["Und", "g\u00e4nz\u00b7lich", "\u2013", "leer\u00b7ge\u00b7trun\u00b7ken", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "$(", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "O w\u00e4r' ich voll heut, Mann und Glas", "tokens": ["O", "w\u00e4r'", "ich", "voll", "heut", ",", "Mann", "und", "Glas"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "ADJD", "ADV", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcllt' ich mit Rheinweinmassen!", "tokens": ["F\u00fcllt'", "ich", "mit", "Rhein\u00b7wein\u00b7mas\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch weh und ach!... dem Hauptwort \u00bbFa\u00df\u00ab", "tokens": ["Doch", "weh", "und", "ach", "!", "...", "dem", "Haupt\u00b7wort", "\u00bb", "Fa\u00df", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "KON", "XY", "$.", "$(", "ART", "NN", "$(", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fehlt l\u00e4ngst sein Zeitwort \u00bb", "tokens": ["Fehlt", "l\u00e4ngst", "sein", "Zeit\u00b7wort", "\u00bb"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.6": {"text": "Zu bacchischem Gedichte ...", "tokens": ["Zu", "bac\u00b7chi\u00b7schem", "Ge\u00b7dich\u00b7te", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "... Ich bitt' nur um die Note \u00bbgut\u00ab", "tokens": ["...", "Ich", "bitt'", "nur", "um", "die", "No\u00b7te", "\u00bb", "gut", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$(", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In \u00bbSprache und Geschichte\u00ab.", "tokens": ["In", "\u00bb", "Spra\u00b7che", "und", "Ge\u00b7schich\u00b7te", "\u00ab", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "$(", "NN", "KON", "NN", "$(", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}