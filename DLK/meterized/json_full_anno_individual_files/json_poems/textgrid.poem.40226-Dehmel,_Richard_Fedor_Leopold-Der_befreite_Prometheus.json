{"textgrid.poem.40226": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "Der befreite Prometheus", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vom Kaukasus herniederschritt Prometheus:", "tokens": ["Vom", "Kau\u00b7ka\u00b7sus", "her\u00b7nie\u00b7der\u00b7schritt", "Pro\u00b7me\u00b7theus", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.2": {"text": "er war erl\u00f6st, Zeus gab ihn frei.", "tokens": ["er", "war", "er\u00b7l\u00f6st", ",", "Zeus", "gab", "ihn", "frei", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "NE", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Riese durfte wieder sich ", "tokens": ["Der", "Rie\u00b7se", "durf\u00b7te", "wie\u00b7der", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ADV", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "vom Felsen, dran er b\u00fc\u00dfend hing:", "tokens": ["vom", "Fel\u00b7sen", ",", "dran", "er", "b\u00fc\u00b7\u00dfend", "hing", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PAV", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "er durfte nun ", "tokens": ["er", "durf\u00b7te", "nun"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "da\u00df er der eignen Seligkeit vergessen", "tokens": ["da\u00df", "er", "der", "eig\u00b7nen", "Se\u00b7lig\u00b7keit", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "und f\u00fcr sie stahl das Feuer vom Olymp.", "tokens": ["und", "f\u00fcr", "sie", "stahl", "das", "Feu\u00b7er", "vom", "O\u00b7lymp", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Nicht dauerte den G\u00f6tterk\u00f6nig", "tokens": ["Nicht", "dau\u00b7er\u00b7te", "den", "G\u00f6t\u00b7ter\u00b7k\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKNEG", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "des Himmelssohnes, des abtr\u00fcnnigen.", "tokens": ["des", "Him\u00b7mels\u00b7soh\u00b7nes", ",", "des", "ab\u00b7tr\u00fcn\u00b7ni\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Warum auch ", "tokens": ["Wa\u00b7rum", "auch"], "token_info": ["word", "word"], "pos": ["PWAV", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "den Menschen G\u00f6ttergut hinabzutragen?", "tokens": ["den", "Men\u00b7schen", "G\u00f6t\u00b7ter\u00b7gut", "hin\u00b7ab\u00b7zu\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Er hatte seinen ", "tokens": ["Er", "hat\u00b7te", "sei\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "den Dulderlohn,", "tokens": ["den", "Dul\u00b7der\u00b7lohn", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "nach der Olympier unerbittlichem Gesetz! \u2013", "tokens": ["nach", "der", "O\u00b7lym\u00b7pier", "un\u00b7er\u00b7bitt\u00b7li\u00b7chem", "Ge\u00b7setz", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Verraucht nur endlich war der ", "tokens": ["Ver\u00b7raucht", "nur", "end\u00b7lich", "war", "der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "VAFIN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "und Laune war's und Gnade, da\u00df sein Blitz", "tokens": ["und", "Lau\u00b7ne", "wa\u00b7r's", "und", "Gna\u00b7de", ",", "da\u00df", "sein", "Blitz"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "KON", "NN", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "vom Leib des M\u00e4rtyrers die Fesseln ", "tokens": ["vom", "Leib", "des", "M\u00e4r\u00b7ty\u00b7rers", "die", "Fes\u00b7seln"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "die donnerkeilgeschmiedeten ...", "tokens": ["die", "don\u00b7ner\u00b7keil\u00b7ge\u00b7schmie\u00b7de\u00b7ten", "..."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$("], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.3": {"line.1": {"text": "O lange Qual! oh Leib \u2013 zerfleischt, entstellt!", "tokens": ["O", "lan\u00b7ge", "Qual", "!", "oh", "Leib", "\u2013", "zer\u00b7fleischt", ",", "ent\u00b7stellt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "FM", "NN", "$(", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Noch deckten Schw\u00e4ren die zerschundnen Kn\u00f6chel;", "tokens": ["Noch", "deck\u00b7ten", "Schw\u00e4\u00b7ren", "die", "zer\u00b7schund\u00b7nen", "Kn\u00f6\u00b7chel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "kaum konnten die verkr\u00fcmmten Finger ", "tokens": ["kaum", "konn\u00b7ten", "die", "ver\u00b7kr\u00fcmm\u00b7ten", "Fin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die roten Male all, die frisch noch gl\u00e4nzten, \u2013", "tokens": ["die", "ro\u00b7ten", "Ma\u00b7le", "all", ",", "die", "frisch", "noch", "gl\u00e4nz\u00b7ten", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "PIAT", "$,", "PRELS", "ADJD", "ADV", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "auf all den Wunden, die ihm Tag um Tag", "tokens": ["auf", "all", "den", "Wun\u00b7den", ",", "die", "ihm", "Tag", "um", "Tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ART", "NN", "$,", "PRELS", "PPER", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "der Geier gierige Schnabelschl\u00e4ge rissen.", "tokens": ["der", "Gei\u00b7er", "gie\u00b7ri\u00b7ge", "Schna\u00b7bel\u00b7schl\u00e4\u00b7ge", "ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "O Tage voller Wut und Ohnmacht!", "tokens": ["O", "Ta\u00b7ge", "vol\u00b7ler", "Wut", "und", "Ohn\u00b7macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "oh Tag der Bitternis, da ihm die Kraft,", "tokens": ["oh", "Tag", "der", "Bit\u00b7ter\u00b7nis", ",", "da", "ihm", "die", "Kraft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ART", "NN", "$,", "KOUS", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "die einst mit Bergen wie mit W\u00fcrfeln spielte,", "tokens": ["die", "einst", "mit", "Ber\u00b7gen", "wie", "mit", "W\u00fcr\u00b7feln", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "KOKOM", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "zum Ersten Male", "tokens": ["zum", "Ers\u00b7ten", "Ma\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "versagte vor der Uebermacht des Neides,", "tokens": ["ver\u00b7sag\u00b7te", "vor", "der", "Ue\u00b7ber\u00b7macht", "des", "Nei\u00b7des", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "des weltbeschattenden, der alten G\u00f6tter!", "tokens": ["des", "welt\u00b7be\u00b7schat\u00b7ten\u00b7den", ",", "der", "al\u00b7ten", "G\u00f6t\u00b7ter", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "oh Tag, als in Verzweiflung starb sein Mut! \u2013", "tokens": ["oh", "Tag", ",", "als", "in", "Ver\u00b7zwei\u00b7flung", "starb", "sein", "Mut", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "NN", "$,", "KOUS", "APPR", "NN", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Doch ", "tokens": ["Doch"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Verspr\u00fcht die Kampfglut in den tiefen Augen;", "tokens": ["Ver\u00b7spr\u00fcht", "die", "Kampf\u00b7glut", "in", "den", "tie\u00b7fen", "Au\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "erloschner Groll, verlohte Leidenschaft", "tokens": ["er\u00b7lo\u00b7schner", "Groll", ",", "ver\u00b7loh\u00b7te", "Lei\u00b7den\u00b7schaft"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "die einz'ge Saat der tiefzerfurchten Z\u00fcge, \u2013", "tokens": ["die", "einz'\u00b7ge", "Saat", "der", "tief\u00b7zer\u00b7furch\u00b7ten", "Z\u00fc\u00b7ge", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "so tief, als sollten tausend Thr\u00e4nen drin", "tokens": ["so", "tief", ",", "als", "soll\u00b7ten", "tau\u00b7send", "Thr\u00e4\u00b7nen", "drin"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "VMFIN", "CARD", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "zu den verdorrten Wurzeln seiner Seele,", "tokens": ["zu", "den", "ver\u00b7dorr\u00b7ten", "Wur\u00b7zeln", "sei\u00b7ner", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "zum Grabe eines ", "tokens": ["zum", "Gra\u00b7be", "ei\u00b7nes"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Um seine schmerzvernarbte Stirne zauste", "tokens": ["Um", "sei\u00b7ne", "schmerz\u00b7ver\u00b7narb\u00b7te", "Stir\u00b7ne", "zaus\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "der kalte Wind des Haars ergraute B\u00fcschel.", "tokens": ["der", "kal\u00b7te", "Wind", "des", "Haars", "er\u00b7grau\u00b7te", "B\u00fc\u00b7schel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "So schritt er abw\u00e4rts, der gebeugte Riese ...", "tokens": ["So", "schritt", "er", "ab\u00b7w\u00e4rts", ",", "der", "ge\u00b7beug\u00b7te", "Rie\u00b7se", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Nur ", "tokens": ["Nur"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "sie um sich sammeln wie ein alter Vater seine Kinder, \u2013", "tokens": ["sie", "um", "sich", "sam\u00b7meln", "wie", "ein", "al\u00b7ter", "Va\u00b7ter", "sei\u00b7ne", "Kin\u00b7der", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "APPR", "PRF", "VVINF", "KOKOM", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.3": {"text": "ihr Gl\u00fcck genie\u00dfen, das sie ", "tokens": ["ihr", "Gl\u00fcck", "ge\u00b7nie\u00b7\u00dfen", ",", "das", "sie"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VVINF", "$,", "PRELS", "PPER"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "den Frieden ", "tokens": ["den", "Frie\u00b7den"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "seit er den Himmelsfunken ihnen schenkte,", "tokens": ["seit", "er", "den", "Him\u00b7mels\u00b7fun\u00b7ken", "ih\u00b7nen", "schenk\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "seit er den unst\u00e4t Irrenden", "tokens": ["seit", "er", "den", "un\u00b7st\u00e4t", "Ir\u00b7ren\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.7": {"text": "gebaut den ersten warmen, festen Herd, \u2013", "tokens": ["ge\u00b7baut", "den", "ers\u00b7ten", "war\u00b7men", ",", "fes\u00b7ten", "Herd", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVPP", "ART", "ADJA", "VVINF", "$,", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "sich ", "tokens": ["sich"], "token_info": ["word"], "pos": ["PRF"], "meter": "-", "measure": "single.down"}, "line.9": {"text": "die tierischwild in Hader, Ha\u00df und Habgier", "tokens": ["die", "tie\u00b7ri\u00b7schwild", "in", "Ha\u00b7der", ",", "Ha\u00df", "und", "Hab\u00b7gier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJD", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "sich um das nackte Leben schlugen einst,", "tokens": ["sich", "um", "das", "nack\u00b7te", "Le\u00b7ben", "schlu\u00b7gen", "einst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "die ", "tokens": ["die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.6": {"line.1": {"text": "Und nieder kam er in die mildern L\u00fcfte,", "tokens": ["Und", "nie\u00b7der", "kam", "er", "in", "die", "mil\u00b7dern", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ins ", "tokens": ["ins"], "token_info": ["word"], "pos": ["APPRART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "bebaute Aecker, wohlgehegte G\u00e4rten,", "tokens": ["be\u00b7bau\u00b7te", "A\u00b7e\u00b7cker", ",", "wohl\u00b7ge\u00b7heg\u00b7te", "G\u00e4r\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und ringsum lugten D\u00f6rfer aus dem Gr\u00fcn,", "tokens": ["und", "ring\u00b7sum", "lug\u00b7ten", "D\u00f6r\u00b7fer", "aus", "dem", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und weither prangten Zinnen sichrer St\u00e4dte.", "tokens": ["und", "weit\u00b7her", "prang\u00b7ten", "Zin\u00b7nen", "sich\u00b7rer", "St\u00e4d\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da ", "tokens": ["Da"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "war Das nicht ", "tokens": ["war", "Das", "nicht"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PDS", "PTKNEG"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "ja, meine Menschen will ich wiedersehn! \u2013 \u2013", "tokens": ["ja", ",", "mei\u00b7ne", "Men\u00b7schen", "will", "ich", "wie\u00b7der\u00b7sehn", "!", "\u2013", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und in die D\u00f6rfer ging er, in die St\u00e4dte \u2013", "tokens": ["Und", "in", "die", "D\u00f6r\u00b7fer", "ging", "er", ",", "in", "die", "St\u00e4d\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und ging und ging \u2013 und suchte hin und her", "tokens": ["und", "ging", "und", "ging", "\u2013", "und", "such\u00b7te", "hin", "und", "her"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$(", "KON", "VVFIN", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und fand \u2013", "tokens": ["und", "fand", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "weh, wehe, wehe \u2013 ", "tokens": ["weh", ",", "we\u00b7he", ",", "we\u00b7he", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["PTKVZ", "$,", "ADJD", "$,", "ADJD", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Ha\u00df, Hader, Habgier schlugen sich im Streit", "tokens": ["Ha\u00df", ",", "Ha\u00b7der", ",", "Hab\u00b7gier", "schlu\u00b7gen", "sich", "im", "Streit"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "mit andrer Habgier, anderm Hader, anderm Ha\u00df, \u2013", "tokens": ["mit", "an\u00b7drer", "Hab\u00b7gier", ",", "an\u00b7derm", "Ha\u00b7der", ",", "an\u00b7derm", "Ha\u00df", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "nur Eines fand er auf der Erde neu,", "tokens": ["nur", "Ei\u00b7nes", "fand", "er", "auf", "der", "Er\u00b7de", "neu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "den Neid: den ", "tokens": ["den", "Neid", ":", "den"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$.", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "den Neid der ", "tokens": ["den", "Neid", "der"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "und war doch da Genug, genug f\u00fcr ", "tokens": ["und", "war", "doch", "da", "Ge\u00b7nug", ",", "ge\u00b7nug", "f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ADV", "$,", "ADV", "APPR"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "In H\u00fctten sah er, in die Burgen sah er;", "tokens": ["In", "H\u00fct\u00b7ten", "sah", "er", ",", "in", "die", "Bur\u00b7gen", "sah", "er", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "doch es war Alles Eines,", "tokens": ["doch", "es", "war", "Al\u00b7les", "Ei\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIS", "PIS", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.13": {"text": "war Alles wie ", "tokens": ["war", "Al\u00b7les", "wie"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PIS", "KOKOM"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Zuletzt in eines Priesters reiches Haus", "tokens": ["Zu\u00b7letzt", "in", "ei\u00b7nes", "Pries\u00b7ters", "rei\u00b7ches", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "trat matt er ein. Dort ", "tokens": ["trat", "matt", "er", "ein", ".", "Dort"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "ADJD", "PPER", "PTKVZ", "$.", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "den er vergebens bei den Andern suchte;", "tokens": ["den", "er", "ver\u00b7ge\u00b7bens", "bei", "den", "An\u00b7dern", "such\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "dort wo des Dankes stilles Sinnbild ihm", "tokens": ["dort", "wo", "des", "Dan\u00b7kes", "stil\u00b7les", "Sinn\u00b7bild", "ihm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PWAV", "ART", "NN", "ADJA", "NN", "PPER"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "in heil'ger Lampe glomm die ew'ge Flamme,", "tokens": ["in", "heil'\u00b7ger", "Lam\u00b7pe", "glomm", "die", "ew'\u00b7ge", "Flam\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "dort auf ", "tokens": ["dort", "auf"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "noch Einmal unter Menschen \u2013 und sich dann", "tokens": ["noch", "Ein\u00b7mal", "un\u00b7ter", "Men\u00b7schen", "\u2013", "und", "sich", "dann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "NN", "$(", "KON", "PRF", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "auf immer in die Einsamkeit verbergen.", "tokens": ["auf", "im\u00b7mer", "in", "die", "Ein\u00b7sam\u00b7keit", "ver\u00b7ber\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Zum Hausherrn sprach er, der im Hofe stand:", "tokens": ["Zum", "Haus\u00b7herrn", "sprach", "er", ",", "der", "im", "Ho\u00b7fe", "stand", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ich bin Prometheus, la\u00df mich ein bei dir! \u2013", "tokens": ["Ich", "bin", "Pro\u00b7me\u00b7theus", ",", "la\u00df", "mich", "ein", "bei", "dir", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "NE", "$,", "VVIMP", "PPER", "ART", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Der wandte sich erschrocken, blickte scheu", "tokens": ["Der", "wand\u00b7te", "sich", "er\u00b7schro\u00b7cken", ",", "blick\u00b7te", "scheu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "PRF", "VVINF", "$,", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "dem gro\u00dfen Mann ins d\u00fcstre Angesicht,", "tokens": ["dem", "gro\u00b7\u00dfen", "Mann", "ins", "d\u00fcst\u00b7re", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und schlich geduckt davon, und schlo\u00df sich ein,", "tokens": ["und", "schlich", "ge\u00b7duckt", "da\u00b7von", ",", "und", "schlo\u00df", "sich", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "PAV", "$,", "KON", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und durch die Th\u00fcr quoll eine fette Stimme:", "tokens": ["und", "durch", "die", "Th\u00fcr", "quoll", "ei\u00b7ne", "fet\u00b7te", "Stim\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich habe selber nichts; geh weiter, Narr!", "tokens": ["Ich", "ha\u00b7be", "sel\u00b7ber", "nichts", ";", "geh", "wei\u00b7ter", ",", "Narr", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "$.", "VVFIN", "PTKVZ", "$,", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Prometheus, der ist ", "tokens": ["Pro\u00b7me\u00b7theus", ",", "der", "ist"], "token_info": ["word", "punct", "word", "word"], "pos": ["NE", "$,", "PRELS", "VAFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "ja, damals waren bess're Zeiten noch", "tokens": ["ja", ",", "da\u00b7mals", "wa\u00b7ren", "bess'\u00b7re", "Zei\u00b7ten", "noch"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "VAFIN", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "als heute \u2013!", "tokens": ["als", "heu\u00b7te", "\u2013", "!"], "token_info": ["word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "$(", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Dann schlurften Schritte tiefer ins Gemach.", "tokens": ["Dann", "schlurf\u00b7ten", "Schrit\u00b7te", "tie\u00b7fer", "ins", "Ge\u00b7mach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Noch stand der Wandrer. Da: ein Wanken fa\u00dfte", "tokens": ["Noch", "stand", "der", "Wand\u00b7rer", ".", "Da", ":", "ein", "Wan\u00b7ken", "fa\u00df\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ADV", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "den Qualgewohnten, auf die heil'ge Schwelle", "tokens": ["den", "Qual\u00b7ge\u00b7wohn\u00b7ten", ",", "auf", "die", "heil'\u00b7ge", "Schwel\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "schlug er ", "tokens": ["schlug", "er"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "zum Himmel auf: Oh Zeus! ", "tokens": ["zum", "Him\u00b7mel", "auf", ":", "Oh", "Zeus", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$.", "NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "so nicht, so brauchtest du dich ", "tokens": ["so", "nicht", ",", "so", "brauch\u00b7test", "du", "dich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "PRF"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Das war das Letzte! ich will sterben gehn! \u2013", "tokens": ["Das", "war", "das", "Letz\u00b7te", "!", "ich", "will", "ster\u00b7ben", "gehn", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "$.", "PPER", "VMFIN", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und gellend j\u00e4hlings brach", "tokens": ["Und", "gel\u00b7lend", "j\u00e4h\u00b7lings", "brach"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVPP", "ADV", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "ein Lachen hoch aus der zerri\u00dfnen Brust,", "tokens": ["ein", "La\u00b7chen", "hoch", "aus", "der", "zer\u00b7ri\u00df\u00b7nen", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "und rasend sprang er auf,", "tokens": ["und", "ra\u00b7send", "sprang", "er", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "und br\u00fcllend rannte er dahin, dahin der Riese:", "tokens": ["und", "br\u00fcl\u00b7lend", "rann\u00b7te", "er", "da\u00b7hin", ",", "da\u00b7hin", "der", "Rie\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PAV", "$,", "PAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "im Meer, da find' ich Ruhe! endlich Ruhe! \u2013 \u2013", "tokens": ["im", "Meer", ",", "da", "find'", "ich", "Ru\u00b7he", "!", "end\u00b7lich", "Ru\u00b7he", "!", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["APPRART", "NN", "$,", "ADV", "VVFIN", "PPER", "NN", "$.", "ADV", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Und wieder sah im ebnen Lande unten", "tokens": ["Und", "wie\u00b7der", "sah", "im", "eb\u00b7nen", "Lan\u00b7de", "un\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPRART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "die sch\u00f6nen Fluren er, die bl\u00fchenden Triften,", "tokens": ["die", "sch\u00f6\u00b7nen", "Flu\u00b7ren", "er", ",", "die", "bl\u00fc\u00b7hen\u00b7den", "Trif\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "bebaute Aecker, wohlgehegte G\u00e4rten,", "tokens": ["be\u00b7bau\u00b7te", "A\u00b7e\u00b7cker", ",", "wohl\u00b7ge\u00b7heg\u00b7te", "G\u00e4r\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und ringsum lugten D\u00f6rfer aus dem Gr\u00fcn,", "tokens": ["und", "ring\u00b7sum", "lug\u00b7ten", "D\u00f6r\u00b7fer", "aus", "dem", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und weither prangten Zinnen sichrer St\u00e4dte.", "tokens": ["und", "weit\u00b7her", "prang\u00b7ten", "Zin\u00b7nen", "sich\u00b7rer", "St\u00e4d\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da g\u00e4rte ", "tokens": ["Da", "g\u00e4r\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "da kochte ", "tokens": ["da", "koch\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "vom Felsen \u00e4chzend ri\u00df er St\u00fcck um St\u00fcck,", "tokens": ["vom", "Fel\u00b7sen", "\u00e4ch\u00b7zend", "ri\u00df", "er", "St\u00fcck", "um", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "VVFIN", "PPER", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "und St\u00fcck um St\u00fcck in toller Blindheit schmi\u00df er", "tokens": ["und", "St\u00fcck", "um", "St\u00fcck", "in", "tol\u00b7ler", "Blind\u00b7heit", "schmi\u00df", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "APPR", "NN", "APPR", "ADJA", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "br\u00fcllend ins Meer,", "tokens": ["br\u00fcl\u00b7lend", "ins", "Meer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "gell durch den Sturm", "tokens": ["gell", "durch", "den", "Sturm"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.12": {"text": "mit weinendem Gel\u00e4chter flog sein Jammer:", "tokens": ["mit", "wei\u00b7nen\u00b7dem", "Ge\u00b7l\u00e4ch\u00b7ter", "flog", "sein", "Jam\u00b7mer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "O k\u00f6nnt' ich gleich die ", "tokens": ["O", "k\u00f6nnt'", "ich", "gleich", "die"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "ADV", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.14": {"text": "die so mein Gut, mein g\u00f6ttliches, ", "tokens": ["die", "so", "mein", "Gut", ",", "mein", "g\u00f6tt\u00b7li\u00b7ches", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ha, ", "tokens": ["Ha", ","], "token_info": ["word", "punct"], "pos": ["ITJ", "$,"], "meter": "+", "measure": "single.up"}}, "stanza.12": {"line.1": {"text": "Da horch, was klang da? schwoll da nicht ein Schrei,", "tokens": ["Da", "horch", ",", "was", "klang", "da", "?", "schwoll", "da", "nicht", "ein", "Schrei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "PWS", "VVFIN", "ADV", "$.", "ADJD", "ADV", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ein ", "tokens": ["ein"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Hinab er stierte: rollend ging die See,", "tokens": ["Hin\u00b7ab", "er", "stier\u00b7te", ":", "rol\u00b7lend", "ging", "die", "See", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$.", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "von seinen W\u00fcrfen zischend aufger\u00fchrt,", "tokens": ["von", "sei\u00b7nen", "W\u00fcr\u00b7fen", "zi\u00b7schend", "auf\u00b7ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und auf dem Gischte trieb zerschellt ein Kahn,", "tokens": ["und", "auf", "dem", "Gischte", "trieb", "zer\u00b7schellt", "ein", "Kahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "und in den Wogen rang ein Mensch ums ", "tokens": ["und", "in", "den", "Wo\u00b7gen", "rang", "ein", "Mensch", "ums"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "APPRART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch jetzt: schon sch\u00e4umte von der stiller'n Flut", "tokens": ["Doch", "jetzt", ":", "schon", "sch\u00e4um\u00b7te", "von", "der", "stil\u00b7ler'n", "Flut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "ADV", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "ein ", "tokens": ["ein"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.9": {"text": "ein ", "tokens": ["ein"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.13": {"line.1": {"text": "Und oben auf der Klippe stand Prometheus", "tokens": ["Und", "o\u00b7ben", "auf", "der", "Klip\u00b7pe", "stand", "Pro\u00b7me\u00b7theus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.2": {"text": "und stierte, \u2013 stierte und ", "tokens": ["und", "stier\u00b7te", ",", "\u2013", "stier\u00b7te", "und"], "token_info": ["word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "VVFIN", "$,", "$(", "VVFIN", "KON"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "auf seiner Wandrung hatt' er sie gesehen,", "tokens": ["auf", "sei\u00b7ner", "Wand\u00b7rung", "hatt'", "er", "sie", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die ersten Menschen waren's die er traf:", "tokens": ["die", "ers\u00b7ten", "Men\u00b7schen", "wa\u00b7ren's", "die", "er", "traf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "der Feind dem Feind vereint um Feindes Leben! \u2013", "tokens": ["der", "Feind", "dem", "Feind", "ver\u00b7eint", "um", "Fein\u00b7des", "Le\u00b7ben", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "APPR", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und endlich ", "tokens": ["Und", "end\u00b7lich"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "und schleppten keuchend sich zum kahlen Strand", "tokens": ["und", "schlepp\u00b7ten", "keu\u00b7chend", "sich", "zum", "kah\u00b7len", "Strand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "PRF", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "und schauten in die Augen sich", "tokens": ["und", "schau\u00b7ten", "in", "die", "Au\u00b7gen", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "und sanken in die Arme sich,", "tokens": ["und", "san\u00b7ken", "in", "die", "Ar\u00b7me", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "sprachlosen Gl\u00fcckes, stummer Liebe voll.", "tokens": ["sprach\u00b7lo\u00b7sen", "Gl\u00fc\u00b7ckes", ",", "stum\u00b7mer", "Lie\u00b7be", "voll", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Und oben auf der Klippe stand Prometheus", "tokens": ["Und", "o\u00b7ben", "auf", "der", "Klip\u00b7pe", "stand", "Pro\u00b7me\u00b7theus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.2": {"text": "und sah ihr Hab und Gut im Meer versinken", "tokens": ["und", "sah", "ihr", "Hab", "und", "Gut", "im", "Meer", "ver\u00b7sin\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "KON", "ADJD", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und \u2013 sah sie lachen, h\u00f6rte jauchzen sie.", "tokens": ["und", "\u2013", "sah", "sie", "la\u00b7chen", ",", "h\u00f6r\u00b7te", "jauch\u00b7zen", "sie", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$(", "VVFIN", "PPER", "VVINF", "$,", "VVFIN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Da gl\u00fchte auf in ihm verge\u00dfner ", "tokens": ["Da", "gl\u00fch\u00b7te", "auf", "in", "ihm", "ver\u00b7ge\u00df\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "APPR", "PPER", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da lohte auf in ihm verlernter ", "tokens": ["da", "loh\u00b7te", "auf", "in", "ihm", "ver\u00b7lern\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "APPR", "PPER", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und in die Kniee nieder brach Prometheus", "tokens": ["und", "in", "die", "Kni\u00b7ee", "nie\u00b7der", "brach", "Pro\u00b7me\u00b7theus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "PTKVZ", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und auf zum Himmel stammelte Prometheus:", "tokens": ["und", "auf", "zum", "Him\u00b7mel", "stam\u00b7mel\u00b7te", "Pro\u00b7me\u00b7theus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "APPRART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Oh Zeus! ich ", "tokens": ["Oh", "Zeus", "!", "ich"], "token_info": ["word", "word", "punct", "word"], "pos": ["NE", "NE", "$.", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "ich bin so reich! ", "tokens": ["ich", "bin", "so", "reich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "o la\u00df mich leben \u2013 ewig leben:", "tokens": ["o", "la\u00df", "mich", "le\u00b7ben", "\u2013", "e\u00b7wig", "le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["FM", "VVIMP", "PPER", "VVINF", "$(", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "ich will \u2013 ", "tokens": ["ich", "will", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VMFIN", "$("], "meter": "-+", "measure": "iambic.single"}}, "stanza.16": {"line.1": {"text": "Vom Kaukasus herniederschritt Prometheus:", "tokens": ["Vom", "Kau\u00b7ka\u00b7sus", "her\u00b7nie\u00b7der\u00b7schritt", "Pro\u00b7me\u00b7theus", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.2": {"text": "er war erl\u00f6st, Zeus gab ihn frei.", "tokens": ["er", "war", "er\u00b7l\u00f6st", ",", "Zeus", "gab", "ihn", "frei", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "NE", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Riese durfte wieder sich ", "tokens": ["Der", "Rie\u00b7se", "durf\u00b7te", "wie\u00b7der", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ADV", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "vom Felsen, dran er b\u00fc\u00dfend hing:", "tokens": ["vom", "Fel\u00b7sen", ",", "dran", "er", "b\u00fc\u00b7\u00dfend", "hing", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PAV", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "er durfte nun ", "tokens": ["er", "durf\u00b7te", "nun"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "da\u00df er der eignen Seligkeit vergessen", "tokens": ["da\u00df", "er", "der", "eig\u00b7nen", "Se\u00b7lig\u00b7keit", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "und f\u00fcr sie stahl das Feuer vom Olymp.", "tokens": ["und", "f\u00fcr", "sie", "stahl", "das", "Feu\u00b7er", "vom", "O\u00b7lymp", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Nicht dauerte den G\u00f6tterk\u00f6nig", "tokens": ["Nicht", "dau\u00b7er\u00b7te", "den", "G\u00f6t\u00b7ter\u00b7k\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKNEG", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "des Himmelssohnes, des abtr\u00fcnnigen.", "tokens": ["des", "Him\u00b7mels\u00b7soh\u00b7nes", ",", "des", "ab\u00b7tr\u00fcn\u00b7ni\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Warum auch ", "tokens": ["Wa\u00b7rum", "auch"], "token_info": ["word", "word"], "pos": ["PWAV", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "den Menschen G\u00f6ttergut hinabzutragen?", "tokens": ["den", "Men\u00b7schen", "G\u00f6t\u00b7ter\u00b7gut", "hin\u00b7ab\u00b7zu\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Er hatte seinen ", "tokens": ["Er", "hat\u00b7te", "sei\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "den Dulderlohn,", "tokens": ["den", "Dul\u00b7der\u00b7lohn", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "nach der Olympier unerbittlichem Gesetz! \u2013", "tokens": ["nach", "der", "O\u00b7lym\u00b7pier", "un\u00b7er\u00b7bitt\u00b7li\u00b7chem", "Ge\u00b7setz", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Verraucht nur endlich war der ", "tokens": ["Ver\u00b7raucht", "nur", "end\u00b7lich", "war", "der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "VAFIN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "und Laune war's und Gnade, da\u00df sein Blitz", "tokens": ["und", "Lau\u00b7ne", "wa\u00b7r's", "und", "Gna\u00b7de", ",", "da\u00df", "sein", "Blitz"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "KON", "NN", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "vom Leib des M\u00e4rtyrers die Fesseln ", "tokens": ["vom", "Leib", "des", "M\u00e4r\u00b7ty\u00b7rers", "die", "Fes\u00b7seln"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "die donnerkeilgeschmiedeten ...", "tokens": ["die", "don\u00b7ner\u00b7keil\u00b7ge\u00b7schmie\u00b7de\u00b7ten", "..."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$("], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.18": {"line.1": {"text": "O lange Qual! oh Leib \u2013 zerfleischt, entstellt!", "tokens": ["O", "lan\u00b7ge", "Qual", "!", "oh", "Leib", "\u2013", "zer\u00b7fleischt", ",", "ent\u00b7stellt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "FM", "NN", "$(", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Noch deckten Schw\u00e4ren die zerschundnen Kn\u00f6chel;", "tokens": ["Noch", "deck\u00b7ten", "Schw\u00e4\u00b7ren", "die", "zer\u00b7schund\u00b7nen", "Kn\u00f6\u00b7chel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "kaum konnten die verkr\u00fcmmten Finger ", "tokens": ["kaum", "konn\u00b7ten", "die", "ver\u00b7kr\u00fcmm\u00b7ten", "Fin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die roten Male all, die frisch noch gl\u00e4nzten, \u2013", "tokens": ["die", "ro\u00b7ten", "Ma\u00b7le", "all", ",", "die", "frisch", "noch", "gl\u00e4nz\u00b7ten", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "PIAT", "$,", "PRELS", "ADJD", "ADV", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "auf all den Wunden, die ihm Tag um Tag", "tokens": ["auf", "all", "den", "Wun\u00b7den", ",", "die", "ihm", "Tag", "um", "Tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ART", "NN", "$,", "PRELS", "PPER", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "der Geier gierige Schnabelschl\u00e4ge rissen.", "tokens": ["der", "Gei\u00b7er", "gie\u00b7ri\u00b7ge", "Schna\u00b7bel\u00b7schl\u00e4\u00b7ge", "ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "O Tage voller Wut und Ohnmacht!", "tokens": ["O", "Ta\u00b7ge", "vol\u00b7ler", "Wut", "und", "Ohn\u00b7macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "oh Tag der Bitternis, da ihm die Kraft,", "tokens": ["oh", "Tag", "der", "Bit\u00b7ter\u00b7nis", ",", "da", "ihm", "die", "Kraft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ART", "NN", "$,", "KOUS", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "die einst mit Bergen wie mit W\u00fcrfeln spielte,", "tokens": ["die", "einst", "mit", "Ber\u00b7gen", "wie", "mit", "W\u00fcr\u00b7feln", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "KOKOM", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "zum Ersten Male", "tokens": ["zum", "Ers\u00b7ten", "Ma\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "versagte vor der Uebermacht des Neides,", "tokens": ["ver\u00b7sag\u00b7te", "vor", "der", "Ue\u00b7ber\u00b7macht", "des", "Nei\u00b7des", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "des weltbeschattenden, der alten G\u00f6tter!", "tokens": ["des", "welt\u00b7be\u00b7schat\u00b7ten\u00b7den", ",", "der", "al\u00b7ten", "G\u00f6t\u00b7ter", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "oh Tag, als in Verzweiflung starb sein Mut! \u2013", "tokens": ["oh", "Tag", ",", "als", "in", "Ver\u00b7zwei\u00b7flung", "starb", "sein", "Mut", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "NN", "$,", "KOUS", "APPR", "NN", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Doch ", "tokens": ["Doch"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Verspr\u00fcht die Kampfglut in den tiefen Augen;", "tokens": ["Ver\u00b7spr\u00fcht", "die", "Kampf\u00b7glut", "in", "den", "tie\u00b7fen", "Au\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "erloschner Groll, verlohte Leidenschaft", "tokens": ["er\u00b7lo\u00b7schner", "Groll", ",", "ver\u00b7loh\u00b7te", "Lei\u00b7den\u00b7schaft"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "die einz'ge Saat der tiefzerfurchten Z\u00fcge, \u2013", "tokens": ["die", "einz'\u00b7ge", "Saat", "der", "tief\u00b7zer\u00b7furch\u00b7ten", "Z\u00fc\u00b7ge", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "so tief, als sollten tausend Thr\u00e4nen drin", "tokens": ["so", "tief", ",", "als", "soll\u00b7ten", "tau\u00b7send", "Thr\u00e4\u00b7nen", "drin"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "VMFIN", "CARD", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "zu den verdorrten Wurzeln seiner Seele,", "tokens": ["zu", "den", "ver\u00b7dorr\u00b7ten", "Wur\u00b7zeln", "sei\u00b7ner", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "zum Grabe eines ", "tokens": ["zum", "Gra\u00b7be", "ei\u00b7nes"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Um seine schmerzvernarbte Stirne zauste", "tokens": ["Um", "sei\u00b7ne", "schmerz\u00b7ver\u00b7narb\u00b7te", "Stir\u00b7ne", "zaus\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "der kalte Wind des Haars ergraute B\u00fcschel.", "tokens": ["der", "kal\u00b7te", "Wind", "des", "Haars", "er\u00b7grau\u00b7te", "B\u00fc\u00b7schel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "So schritt er abw\u00e4rts, der gebeugte Riese ...", "tokens": ["So", "schritt", "er", "ab\u00b7w\u00e4rts", ",", "der", "ge\u00b7beug\u00b7te", "Rie\u00b7se", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Nur ", "tokens": ["Nur"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "sie um sich sammeln wie ein alter Vater seine Kinder, \u2013", "tokens": ["sie", "um", "sich", "sam\u00b7meln", "wie", "ein", "al\u00b7ter", "Va\u00b7ter", "sei\u00b7ne", "Kin\u00b7der", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "APPR", "PRF", "VVINF", "KOKOM", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.3": {"text": "ihr Gl\u00fcck genie\u00dfen, das sie ", "tokens": ["ihr", "Gl\u00fcck", "ge\u00b7nie\u00b7\u00dfen", ",", "das", "sie"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VVINF", "$,", "PRELS", "PPER"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "den Frieden ", "tokens": ["den", "Frie\u00b7den"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "seit er den Himmelsfunken ihnen schenkte,", "tokens": ["seit", "er", "den", "Him\u00b7mels\u00b7fun\u00b7ken", "ih\u00b7nen", "schenk\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "seit er den unst\u00e4t Irrenden", "tokens": ["seit", "er", "den", "un\u00b7st\u00e4t", "Ir\u00b7ren\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.7": {"text": "gebaut den ersten warmen, festen Herd, \u2013", "tokens": ["ge\u00b7baut", "den", "ers\u00b7ten", "war\u00b7men", ",", "fes\u00b7ten", "Herd", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVPP", "ART", "ADJA", "VVINF", "$,", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "sich ", "tokens": ["sich"], "token_info": ["word"], "pos": ["PRF"], "meter": "-", "measure": "single.down"}, "line.9": {"text": "die tierischwild in Hader, Ha\u00df und Habgier", "tokens": ["die", "tie\u00b7ri\u00b7schwild", "in", "Ha\u00b7der", ",", "Ha\u00df", "und", "Hab\u00b7gier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJD", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "sich um das nackte Leben schlugen einst,", "tokens": ["sich", "um", "das", "nack\u00b7te", "Le\u00b7ben", "schlu\u00b7gen", "einst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "die ", "tokens": ["die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.21": {"line.1": {"text": "Und nieder kam er in die mildern L\u00fcfte,", "tokens": ["Und", "nie\u00b7der", "kam", "er", "in", "die", "mil\u00b7dern", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ins ", "tokens": ["ins"], "token_info": ["word"], "pos": ["APPRART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "bebaute Aecker, wohlgehegte G\u00e4rten,", "tokens": ["be\u00b7bau\u00b7te", "A\u00b7e\u00b7cker", ",", "wohl\u00b7ge\u00b7heg\u00b7te", "G\u00e4r\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und ringsum lugten D\u00f6rfer aus dem Gr\u00fcn,", "tokens": ["und", "ring\u00b7sum", "lug\u00b7ten", "D\u00f6r\u00b7fer", "aus", "dem", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und weither prangten Zinnen sichrer St\u00e4dte.", "tokens": ["und", "weit\u00b7her", "prang\u00b7ten", "Zin\u00b7nen", "sich\u00b7rer", "St\u00e4d\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da ", "tokens": ["Da"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "war Das nicht ", "tokens": ["war", "Das", "nicht"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PDS", "PTKNEG"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "ja, meine Menschen will ich wiedersehn! \u2013 \u2013", "tokens": ["ja", ",", "mei\u00b7ne", "Men\u00b7schen", "will", "ich", "wie\u00b7der\u00b7sehn", "!", "\u2013", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Und in die D\u00f6rfer ging er, in die St\u00e4dte \u2013", "tokens": ["Und", "in", "die", "D\u00f6r\u00b7fer", "ging", "er", ",", "in", "die", "St\u00e4d\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und ging und ging \u2013 und suchte hin und her", "tokens": ["und", "ging", "und", "ging", "\u2013", "und", "such\u00b7te", "hin", "und", "her"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$(", "KON", "VVFIN", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und fand \u2013", "tokens": ["und", "fand", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "weh, wehe, wehe \u2013 ", "tokens": ["weh", ",", "we\u00b7he", ",", "we\u00b7he", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["PTKVZ", "$,", "ADJD", "$,", "ADJD", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Ha\u00df, Hader, Habgier schlugen sich im Streit", "tokens": ["Ha\u00df", ",", "Ha\u00b7der", ",", "Hab\u00b7gier", "schlu\u00b7gen", "sich", "im", "Streit"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "mit andrer Habgier, anderm Hader, anderm Ha\u00df, \u2013", "tokens": ["mit", "an\u00b7drer", "Hab\u00b7gier", ",", "an\u00b7derm", "Ha\u00b7der", ",", "an\u00b7derm", "Ha\u00df", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "nur Eines fand er auf der Erde neu,", "tokens": ["nur", "Ei\u00b7nes", "fand", "er", "auf", "der", "Er\u00b7de", "neu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "den Neid: den ", "tokens": ["den", "Neid", ":", "den"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$.", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "den Neid der ", "tokens": ["den", "Neid", "der"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "und war doch da Genug, genug f\u00fcr ", "tokens": ["und", "war", "doch", "da", "Ge\u00b7nug", ",", "ge\u00b7nug", "f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ADV", "$,", "ADV", "APPR"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "In H\u00fctten sah er, in die Burgen sah er;", "tokens": ["In", "H\u00fct\u00b7ten", "sah", "er", ",", "in", "die", "Bur\u00b7gen", "sah", "er", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "doch es war Alles Eines,", "tokens": ["doch", "es", "war", "Al\u00b7les", "Ei\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIS", "PIS", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.13": {"text": "war Alles wie ", "tokens": ["war", "Al\u00b7les", "wie"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PIS", "KOKOM"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.23": {"line.1": {"text": "Zuletzt in eines Priesters reiches Haus", "tokens": ["Zu\u00b7letzt", "in", "ei\u00b7nes", "Pries\u00b7ters", "rei\u00b7ches", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "trat matt er ein. Dort ", "tokens": ["trat", "matt", "er", "ein", ".", "Dort"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "ADJD", "PPER", "PTKVZ", "$.", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "den er vergebens bei den Andern suchte;", "tokens": ["den", "er", "ver\u00b7ge\u00b7bens", "bei", "den", "An\u00b7dern", "such\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "dort wo des Dankes stilles Sinnbild ihm", "tokens": ["dort", "wo", "des", "Dan\u00b7kes", "stil\u00b7les", "Sinn\u00b7bild", "ihm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PWAV", "ART", "NN", "ADJA", "NN", "PPER"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "in heil'ger Lampe glomm die ew'ge Flamme,", "tokens": ["in", "heil'\u00b7ger", "Lam\u00b7pe", "glomm", "die", "ew'\u00b7ge", "Flam\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "dort auf ", "tokens": ["dort", "auf"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "noch Einmal unter Menschen \u2013 und sich dann", "tokens": ["noch", "Ein\u00b7mal", "un\u00b7ter", "Men\u00b7schen", "\u2013", "und", "sich", "dann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "NN", "$(", "KON", "PRF", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "auf immer in die Einsamkeit verbergen.", "tokens": ["auf", "im\u00b7mer", "in", "die", "Ein\u00b7sam\u00b7keit", "ver\u00b7ber\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Zum Hausherrn sprach er, der im Hofe stand:", "tokens": ["Zum", "Haus\u00b7herrn", "sprach", "er", ",", "der", "im", "Ho\u00b7fe", "stand", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ich bin Prometheus, la\u00df mich ein bei dir! \u2013", "tokens": ["Ich", "bin", "Pro\u00b7me\u00b7theus", ",", "la\u00df", "mich", "ein", "bei", "dir", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "NE", "$,", "VVIMP", "PPER", "ART", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Der wandte sich erschrocken, blickte scheu", "tokens": ["Der", "wand\u00b7te", "sich", "er\u00b7schro\u00b7cken", ",", "blick\u00b7te", "scheu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "PRF", "VVINF", "$,", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "dem gro\u00dfen Mann ins d\u00fcstre Angesicht,", "tokens": ["dem", "gro\u00b7\u00dfen", "Mann", "ins", "d\u00fcst\u00b7re", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und schlich geduckt davon, und schlo\u00df sich ein,", "tokens": ["und", "schlich", "ge\u00b7duckt", "da\u00b7von", ",", "und", "schlo\u00df", "sich", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "PAV", "$,", "KON", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und durch die Th\u00fcr quoll eine fette Stimme:", "tokens": ["und", "durch", "die", "Th\u00fcr", "quoll", "ei\u00b7ne", "fet\u00b7te", "Stim\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich habe selber nichts; geh weiter, Narr!", "tokens": ["Ich", "ha\u00b7be", "sel\u00b7ber", "nichts", ";", "geh", "wei\u00b7ter", ",", "Narr", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "$.", "VVFIN", "PTKVZ", "$,", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Prometheus, der ist ", "tokens": ["Pro\u00b7me\u00b7theus", ",", "der", "ist"], "token_info": ["word", "punct", "word", "word"], "pos": ["NE", "$,", "PRELS", "VAFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "ja, damals waren bess're Zeiten noch", "tokens": ["ja", ",", "da\u00b7mals", "wa\u00b7ren", "bess'\u00b7re", "Zei\u00b7ten", "noch"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "VAFIN", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "als heute \u2013!", "tokens": ["als", "heu\u00b7te", "\u2013", "!"], "token_info": ["word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "$(", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Dann schlurften Schritte tiefer ins Gemach.", "tokens": ["Dann", "schlurf\u00b7ten", "Schrit\u00b7te", "tie\u00b7fer", "ins", "Ge\u00b7mach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Noch stand der Wandrer. Da: ein Wanken fa\u00dfte", "tokens": ["Noch", "stand", "der", "Wand\u00b7rer", ".", "Da", ":", "ein", "Wan\u00b7ken", "fa\u00df\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ADV", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "den Qualgewohnten, auf die heil'ge Schwelle", "tokens": ["den", "Qual\u00b7ge\u00b7wohn\u00b7ten", ",", "auf", "die", "heil'\u00b7ge", "Schwel\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "schlug er ", "tokens": ["schlug", "er"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "zum Himmel auf: Oh Zeus! ", "tokens": ["zum", "Him\u00b7mel", "auf", ":", "Oh", "Zeus", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$.", "NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "so nicht, so brauchtest du dich ", "tokens": ["so", "nicht", ",", "so", "brauch\u00b7test", "du", "dich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "PRF"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Das war das Letzte! ich will sterben gehn! \u2013", "tokens": ["Das", "war", "das", "Letz\u00b7te", "!", "ich", "will", "ster\u00b7ben", "gehn", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "$.", "PPER", "VMFIN", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und gellend j\u00e4hlings brach", "tokens": ["Und", "gel\u00b7lend", "j\u00e4h\u00b7lings", "brach"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVPP", "ADV", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "ein Lachen hoch aus der zerri\u00dfnen Brust,", "tokens": ["ein", "La\u00b7chen", "hoch", "aus", "der", "zer\u00b7ri\u00df\u00b7nen", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "und rasend sprang er auf,", "tokens": ["und", "ra\u00b7send", "sprang", "er", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "und br\u00fcllend rannte er dahin, dahin der Riese:", "tokens": ["und", "br\u00fcl\u00b7lend", "rann\u00b7te", "er", "da\u00b7hin", ",", "da\u00b7hin", "der", "Rie\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PAV", "$,", "PAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "im Meer, da find' ich Ruhe! endlich Ruhe! \u2013 \u2013", "tokens": ["im", "Meer", ",", "da", "find'", "ich", "Ru\u00b7he", "!", "end\u00b7lich", "Ru\u00b7he", "!", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["APPRART", "NN", "$,", "ADV", "VVFIN", "PPER", "NN", "$.", "ADV", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Und wieder sah im ebnen Lande unten", "tokens": ["Und", "wie\u00b7der", "sah", "im", "eb\u00b7nen", "Lan\u00b7de", "un\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPRART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "die sch\u00f6nen Fluren er, die bl\u00fchenden Triften,", "tokens": ["die", "sch\u00f6\u00b7nen", "Flu\u00b7ren", "er", ",", "die", "bl\u00fc\u00b7hen\u00b7den", "Trif\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "bebaute Aecker, wohlgehegte G\u00e4rten,", "tokens": ["be\u00b7bau\u00b7te", "A\u00b7e\u00b7cker", ",", "wohl\u00b7ge\u00b7heg\u00b7te", "G\u00e4r\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und ringsum lugten D\u00f6rfer aus dem Gr\u00fcn,", "tokens": ["und", "ring\u00b7sum", "lug\u00b7ten", "D\u00f6r\u00b7fer", "aus", "dem", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und weither prangten Zinnen sichrer St\u00e4dte.", "tokens": ["und", "weit\u00b7her", "prang\u00b7ten", "Zin\u00b7nen", "sich\u00b7rer", "St\u00e4d\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da g\u00e4rte ", "tokens": ["Da", "g\u00e4r\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "da kochte ", "tokens": ["da", "koch\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "vom Felsen \u00e4chzend ri\u00df er St\u00fcck um St\u00fcck,", "tokens": ["vom", "Fel\u00b7sen", "\u00e4ch\u00b7zend", "ri\u00df", "er", "St\u00fcck", "um", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "VVFIN", "PPER", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "und St\u00fcck um St\u00fcck in toller Blindheit schmi\u00df er", "tokens": ["und", "St\u00fcck", "um", "St\u00fcck", "in", "tol\u00b7ler", "Blind\u00b7heit", "schmi\u00df", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "APPR", "NN", "APPR", "ADJA", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "br\u00fcllend ins Meer,", "tokens": ["br\u00fcl\u00b7lend", "ins", "Meer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "gell durch den Sturm", "tokens": ["gell", "durch", "den", "Sturm"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.12": {"text": "mit weinendem Gel\u00e4chter flog sein Jammer:", "tokens": ["mit", "wei\u00b7nen\u00b7dem", "Ge\u00b7l\u00e4ch\u00b7ter", "flog", "sein", "Jam\u00b7mer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "O k\u00f6nnt' ich gleich die ", "tokens": ["O", "k\u00f6nnt'", "ich", "gleich", "die"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "ADV", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.14": {"text": "die so mein Gut, mein g\u00f6ttliches, ", "tokens": ["die", "so", "mein", "Gut", ",", "mein", "g\u00f6tt\u00b7li\u00b7ches", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ha, ", "tokens": ["Ha", ","], "token_info": ["word", "punct"], "pos": ["ITJ", "$,"], "meter": "+", "measure": "single.up"}}, "stanza.27": {"line.1": {"text": "Da horch, was klang da? schwoll da nicht ein Schrei,", "tokens": ["Da", "horch", ",", "was", "klang", "da", "?", "schwoll", "da", "nicht", "ein", "Schrei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "PWS", "VVFIN", "ADV", "$.", "ADJD", "ADV", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ein ", "tokens": ["ein"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Hinab er stierte: rollend ging die See,", "tokens": ["Hin\u00b7ab", "er", "stier\u00b7te", ":", "rol\u00b7lend", "ging", "die", "See", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$.", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "von seinen W\u00fcrfen zischend aufger\u00fchrt,", "tokens": ["von", "sei\u00b7nen", "W\u00fcr\u00b7fen", "zi\u00b7schend", "auf\u00b7ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und auf dem Gischte trieb zerschellt ein Kahn,", "tokens": ["und", "auf", "dem", "Gischte", "trieb", "zer\u00b7schellt", "ein", "Kahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "und in den Wogen rang ein Mensch ums ", "tokens": ["und", "in", "den", "Wo\u00b7gen", "rang", "ein", "Mensch", "ums"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "APPRART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch jetzt: schon sch\u00e4umte von der stiller'n Flut", "tokens": ["Doch", "jetzt", ":", "schon", "sch\u00e4um\u00b7te", "von", "der", "stil\u00b7ler'n", "Flut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "ADV", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "ein ", "tokens": ["ein"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.9": {"text": "ein ", "tokens": ["ein"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.28": {"line.1": {"text": "Und oben auf der Klippe stand Prometheus", "tokens": ["Und", "o\u00b7ben", "auf", "der", "Klip\u00b7pe", "stand", "Pro\u00b7me\u00b7theus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.2": {"text": "und stierte, \u2013 stierte und ", "tokens": ["und", "stier\u00b7te", ",", "\u2013", "stier\u00b7te", "und"], "token_info": ["word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "VVFIN", "$,", "$(", "VVFIN", "KON"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "auf seiner Wandrung hatt' er sie gesehen,", "tokens": ["auf", "sei\u00b7ner", "Wand\u00b7rung", "hatt'", "er", "sie", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die ersten Menschen waren's die er traf:", "tokens": ["die", "ers\u00b7ten", "Men\u00b7schen", "wa\u00b7ren's", "die", "er", "traf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "der Feind dem Feind vereint um Feindes Leben! \u2013", "tokens": ["der", "Feind", "dem", "Feind", "ver\u00b7eint", "um", "Fein\u00b7des", "Le\u00b7ben", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "APPR", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und endlich ", "tokens": ["Und", "end\u00b7lich"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "und schleppten keuchend sich zum kahlen Strand", "tokens": ["und", "schlepp\u00b7ten", "keu\u00b7chend", "sich", "zum", "kah\u00b7len", "Strand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "PRF", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "und schauten in die Augen sich", "tokens": ["und", "schau\u00b7ten", "in", "die", "Au\u00b7gen", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "und sanken in die Arme sich,", "tokens": ["und", "san\u00b7ken", "in", "die", "Ar\u00b7me", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "sprachlosen Gl\u00fcckes, stummer Liebe voll.", "tokens": ["sprach\u00b7lo\u00b7sen", "Gl\u00fc\u00b7ckes", ",", "stum\u00b7mer", "Lie\u00b7be", "voll", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Und oben auf der Klippe stand Prometheus", "tokens": ["Und", "o\u00b7ben", "auf", "der", "Klip\u00b7pe", "stand", "Pro\u00b7me\u00b7theus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.2": {"text": "und sah ihr Hab und Gut im Meer versinken", "tokens": ["und", "sah", "ihr", "Hab", "und", "Gut", "im", "Meer", "ver\u00b7sin\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "KON", "ADJD", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und \u2013 sah sie lachen, h\u00f6rte jauchzen sie.", "tokens": ["und", "\u2013", "sah", "sie", "la\u00b7chen", ",", "h\u00f6r\u00b7te", "jauch\u00b7zen", "sie", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$(", "VVFIN", "PPER", "VVINF", "$,", "VVFIN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Da gl\u00fchte auf in ihm verge\u00dfner ", "tokens": ["Da", "gl\u00fch\u00b7te", "auf", "in", "ihm", "ver\u00b7ge\u00df\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "APPR", "PPER", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da lohte auf in ihm verlernter ", "tokens": ["da", "loh\u00b7te", "auf", "in", "ihm", "ver\u00b7lern\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "APPR", "PPER", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und in die Kniee nieder brach Prometheus", "tokens": ["und", "in", "die", "Kni\u00b7ee", "nie\u00b7der", "brach", "Pro\u00b7me\u00b7theus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "PTKVZ", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und auf zum Himmel stammelte Prometheus:", "tokens": ["und", "auf", "zum", "Him\u00b7mel", "stam\u00b7mel\u00b7te", "Pro\u00b7me\u00b7theus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "APPRART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Oh Zeus! ich ", "tokens": ["Oh", "Zeus", "!", "ich"], "token_info": ["word", "word", "punct", "word"], "pos": ["NE", "NE", "$.", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "ich bin so reich! ", "tokens": ["ich", "bin", "so", "reich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "o la\u00df mich leben \u2013 ewig leben:", "tokens": ["o", "la\u00df", "mich", "le\u00b7ben", "\u2013", "e\u00b7wig", "le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["FM", "VVIMP", "PPER", "VVINF", "$(", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "ich will \u2013 ", "tokens": ["ich", "will", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VMFIN", "$("], "meter": "-+", "measure": "iambic.single"}}}}}