{"textgrid.poem.35339": {"metadata": {"author": {"name": "Dranmor, (Schmid, Ludwig Ferdinand)", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wiedersehn, dich wiedersehn?", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wiedersehn, dich wiedersehn?", "tokens": ["Wie\u00b7der\u00b7sehn", ",", "dich", "wie\u00b7der\u00b7sehn", "?"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRF", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "So bin ich versucht zu fragen,", "tokens": ["So", "bin", "ich", "ver\u00b7sucht", "zu", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wenn an schw\u00fclen Nachmittagen", "tokens": ["Wenn", "an", "schw\u00fc\u00b7len", "Nach\u00b7mit\u00b7ta\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "B\u00f6se Geister auferstehn;", "tokens": ["B\u00f6\u00b7se", "Geis\u00b7ter", "auf\u00b7er\u00b7stehn", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wenn Erinnerung mich st\u00f6rt,", "tokens": ["Wenn", "E\u00b7rin\u00b7ne\u00b7rung", "mich", "st\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die von dir nicht abzulenken,", "tokens": ["Die", "von", "dir", "nicht", "ab\u00b7zu\u00b7len\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "PTKNEG", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zauberin! wenn all mein Denken,", "tokens": ["Zau\u00b7be\u00b7rin", "!", "wenn", "all", "mein", "Den\u00b7ken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KOUS", "PIAT", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "All mein W\u00fcnschen dir geh\u00f6rt;", "tokens": ["All", "mein", "W\u00fcn\u00b7schen", "dir", "ge\u00b7h\u00f6rt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Bis des jungen Tages Ku\u00df", "tokens": ["Bis", "des", "jun\u00b7gen", "Ta\u00b7ges", "Ku\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mich vergessen l\u00e4\u00dft die deinen,", "tokens": ["Mich", "ver\u00b7ges\u00b7sen", "l\u00e4\u00dft", "die", "dei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VVFIN", "ART", "PPOSAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich, statt um dich zu weinen,", "tokens": ["Da\u00df", "ich", ",", "statt", "um", "dich", "zu", "wei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KOUI", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsre Trennung segnen mu\u00df.", "tokens": ["Uns\u00b7re", "Tren\u00b7nung", "seg\u00b7nen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ist das Schlimmste jetzt vorbei,", "tokens": ["Ist", "das", "Schlimms\u00b7te", "jetzt", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, nur wenig atm' ich freier!", "tokens": ["Ach", ",", "nur", "we\u00b7nig", "atm'", "ich", "frei\u00b7er", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "PIS", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem G\u00fcrtel, mit dem Schleier", "tokens": ["Mit", "dem", "G\u00fcr\u00b7tel", ",", "mit", "dem", "Schlei\u00b7er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rei\u00dft nicht jeder Wahn entzwei.", "tokens": ["Rei\u00dft", "nicht", "je\u00b7der", "Wahn", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wei\u00df nicht, wie dies alles kam,", "tokens": ["Wei\u00df", "nicht", ",", "wie", "dies", "al\u00b7les", "kam", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PWAV", "PDS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df du so mich \u00fcberwunden;", "tokens": ["Da\u00df", "du", "so", "mich", "\u00fc\u00b7berw\u00b7un\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch es waren gute Stunden", "tokens": ["Doch", "es", "wa\u00b7ren", "gu\u00b7te", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ich bin dir nimmer gram.", "tokens": ["Und", "ich", "bin", "dir", "nim\u00b7mer", "gram", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ADV", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Denn mich reut nicht, was geschehn;", "tokens": ["Denn", "mich", "reut", "nicht", ",", "was", "ge\u00b7schehn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "$,", "PRELS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber soll mir's je gelingen,", "tokens": ["A\u00b7ber", "soll", "mir's", "je", "ge\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NE", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ganz von dir mich loszuringen,", "tokens": ["Ganz", "von", "dir", "mich", "los\u00b7zu\u00b7rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Darf ich nie dich wiedersehn.", "tokens": ["Darf", "ich", "nie", "dich", "wie\u00b7der\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wiedersehn, dich wiedersehn?", "tokens": ["Wie\u00b7der\u00b7sehn", ",", "dich", "wie\u00b7der\u00b7sehn", "?"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRF", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "So bin ich versucht zu fragen,", "tokens": ["So", "bin", "ich", "ver\u00b7sucht", "zu", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wenn an schw\u00fclen Nachmittagen", "tokens": ["Wenn", "an", "schw\u00fc\u00b7len", "Nach\u00b7mit\u00b7ta\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "B\u00f6se Geister auferstehn;", "tokens": ["B\u00f6\u00b7se", "Geis\u00b7ter", "auf\u00b7er\u00b7stehn", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wenn Erinnerung mich st\u00f6rt,", "tokens": ["Wenn", "E\u00b7rin\u00b7ne\u00b7rung", "mich", "st\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die von dir nicht abzulenken,", "tokens": ["Die", "von", "dir", "nicht", "ab\u00b7zu\u00b7len\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "PTKNEG", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zauberin! wenn all mein Denken,", "tokens": ["Zau\u00b7be\u00b7rin", "!", "wenn", "all", "mein", "Den\u00b7ken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KOUS", "PIAT", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "All mein W\u00fcnschen dir geh\u00f6rt;", "tokens": ["All", "mein", "W\u00fcn\u00b7schen", "dir", "ge\u00b7h\u00f6rt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Bis des jungen Tages Ku\u00df", "tokens": ["Bis", "des", "jun\u00b7gen", "Ta\u00b7ges", "Ku\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mich vergessen l\u00e4\u00dft die deinen,", "tokens": ["Mich", "ver\u00b7ges\u00b7sen", "l\u00e4\u00dft", "die", "dei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VVFIN", "ART", "PPOSAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich, statt um dich zu weinen,", "tokens": ["Da\u00df", "ich", ",", "statt", "um", "dich", "zu", "wei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KOUI", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsre Trennung segnen mu\u00df.", "tokens": ["Uns\u00b7re", "Tren\u00b7nung", "seg\u00b7nen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Ist das Schlimmste jetzt vorbei,", "tokens": ["Ist", "das", "Schlimms\u00b7te", "jetzt", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, nur wenig atm' ich freier!", "tokens": ["Ach", ",", "nur", "we\u00b7nig", "atm'", "ich", "frei\u00b7er", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "PIS", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem G\u00fcrtel, mit dem Schleier", "tokens": ["Mit", "dem", "G\u00fcr\u00b7tel", ",", "mit", "dem", "Schlei\u00b7er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rei\u00dft nicht jeder Wahn entzwei.", "tokens": ["Rei\u00dft", "nicht", "je\u00b7der", "Wahn", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Wei\u00df nicht, wie dies alles kam,", "tokens": ["Wei\u00df", "nicht", ",", "wie", "dies", "al\u00b7les", "kam", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PWAV", "PDS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df du so mich \u00fcberwunden;", "tokens": ["Da\u00df", "du", "so", "mich", "\u00fc\u00b7berw\u00b7un\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch es waren gute Stunden", "tokens": ["Doch", "es", "wa\u00b7ren", "gu\u00b7te", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ich bin dir nimmer gram.", "tokens": ["Und", "ich", "bin", "dir", "nim\u00b7mer", "gram", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ADV", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Denn mich reut nicht, was geschehn;", "tokens": ["Denn", "mich", "reut", "nicht", ",", "was", "ge\u00b7schehn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "$,", "PRELS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber soll mir's je gelingen,", "tokens": ["A\u00b7ber", "soll", "mir's", "je", "ge\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NE", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ganz von dir mich loszuringen,", "tokens": ["Ganz", "von", "dir", "mich", "los\u00b7zu\u00b7rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Darf ich nie dich wiedersehn.", "tokens": ["Darf", "ich", "nie", "dich", "wie\u00b7der\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}