{"textgrid.poem.33227": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "[2] Schreiben aus Rom nach Jena, an den dermahligen Hochf\u00fcrstl. Sachsen-Gothaischen Hoff- und Gr\u00e4ntz-Raht Herrn Nickl. Zapfen", "genre": "verse", "period": "N.A.", "pub_year": 1676, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dich gr\u00fc\u00dft ein schlechter Kiel am Tyber-Strand geschnitten,", "tokens": ["Dich", "gr\u00fc\u00dft", "ein", "schlech\u00b7ter", "Kiel", "am", "Ty\u00b7ber\u00b7Strand", "ge\u00b7schnit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und klagt, da\u00df er nicht eh bezahlet seine Schuld;", "tokens": ["Und", "klagt", ",", "da\u00df", "er", "nicht", "eh", "be\u00b7zah\u00b7let", "sei\u00b7ne", "Schuld", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er zittert in der Hand, die gantz von Schaam bestritten,", "tokens": ["Er", "zit\u00b7tert", "in", "der", "Hand", ",", "die", "gantz", "von", "Schaam", "be\u00b7strit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wartet auf den Spruch des Richters mit Gedult.", "tokens": ["Und", "war\u00b7tet", "auf", "den", "Spruch", "des", "Rich\u00b7ters", "mit", "Ge\u00b7dult", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich bins, mein Pylades, der diese Zeilen sendet", "tokens": ["Ich", "bins", ",", "mein", "Py\u00b7la\u00b7des", ",", "der", "die\u00b7se", "Zei\u00b7len", "sen\u00b7det"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PPOSAT", "NN", "$,", "PRELS", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Aus unbekanntem Ort, doch unverf\u00e4lschtem Sinn,", "tokens": ["Aus", "un\u00b7be\u00b7kann\u00b7tem", "Ort", ",", "doch", "un\u00b7ver\u00b7f\u00e4lschtem", "Sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Der ich, seit Cynthia sich zweymahl umgewendet,", "tokens": ["Der", "ich", ",", "seit", "Cyn\u00b7thia", "sich", "zwey\u00b7mahl", "um\u00b7ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "APPR", "NE", "PRF", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "In dieser Romuls-Stadt ein B\u00fcrger worden bin.", "tokens": ["In", "die\u00b7ser", "Ro\u00b7muls\u00b7Stadt", "ein", "B\u00fcr\u00b7ger", "wor\u00b7den", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ART", "NN", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du sprichst: was Kiel? was Brieff? hei\u00dft das sich so verbunden?", "tokens": ["Du", "sprichst", ":", "was", "Kiel", "?", "was", "Brieff", "?", "hei\u00dft", "das", "sich", "so", "ver\u00b7bun\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "NE", "$.", "PWS", "NN", "$.", "VVFIN", "PDS", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Hei\u00dft das gewisse Zeit zum Schreiben angesetzt,", "tokens": ["Hei\u00dft", "das", "ge\u00b7wis\u00b7se", "Zeit", "zum", "Schrei\u00b7ben", "an\u00b7ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie ich am Saal-Athen auf meinem Tisch gefunden?", "tokens": ["Wie", "ich", "am", "Saa\u00b7lA\u00b7then", "auf", "mei\u00b7nem", "Tisch", "ge\u00b7fun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wird Siegel, Hand und Schrifft und Wort so schlecht gesch\u00e4tzt?", "tokens": ["Wird", "Sie\u00b7gel", ",", "Hand", "und", "Schrifft", "und", "Wort", "so", "schlecht", "ge\u00b7sch\u00e4tzt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "NN", "KON", "NN", "KON", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was man in jenem Jahr so feyerlich versprochen,", "tokens": ["Was", "man", "in", "je\u00b7nem", "Jahr", "so", "fey\u00b7er\u00b7lich", "ver\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PDAT", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Das wird in diesem kaum ans Tagelicht gebracht.", "tokens": ["Das", "wird", "in", "die\u00b7sem", "kaum", "ans", "Ta\u00b7ge\u00b7licht", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PDAT", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So bald die Jugend nur in fremde Lufft gerochen,", "tokens": ["So", "bald", "die", "Ju\u00b7gend", "nur", "in", "frem\u00b7de", "Lufft", "ge\u00b7ro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wird im geringsten nicht der Freundschafft mehr gedacht.", "tokens": ["Wird", "im", "ge\u00b7rings\u00b7ten", "nicht", "der", "Freund\u00b7schafft", "mehr", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "ADJA", "PTKNEG", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ich sage nichts dazu. Ich straffe mein Verbrechen,", "tokens": ["Ich", "sa\u00b7ge", "nichts", "da\u00b7zu", ".", "Ich", "straf\u00b7fe", "mein", "Ver\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PAV", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und mag kein Vormund hier der bl\u00f6den Faulheit seyn,", "tokens": ["Und", "mag", "kein", "Vor\u00b7mund", "hier", "der", "bl\u00f6\u00b7den", "Faul\u00b7heit", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIAT", "NN", "ADV", "ART", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ich finde mich verpflicht, mir selbst zu widersprechen,", "tokens": ["Ich", "fin\u00b7de", "mich", "ver\u00b7pflicht", ",", "mir", "selbst", "zu", "wi\u00b7der\u00b7spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und stelle, wieder mich, mich selbst als Kl\u00e4ger ein.", "tokens": ["Und", "stel\u00b7le", ",", "wie\u00b7der", "mich", ",", "mich", "selbst", "als", "Kl\u00e4\u00b7ger", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "PPER", "$,", "PPER", "ADV", "KOUS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Zur Ausflucht k\u00f6nnt' ich zwar hier leichtlich etwas finden,", "tokens": ["Zur", "Aus\u00b7flucht", "k\u00f6nnt'", "ich", "zwar", "hier", "leicht\u00b7lich", "et\u00b7was", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Auf Reisen sind wir ja nicht Meister unsrer Ruh,", "tokens": ["Auf", "Rei\u00b7sen", "sind", "wir", "ja", "nicht", "Meis\u00b7ter", "uns\u00b7rer", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "PTKNEG", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Das Wollen mu\u00df sich da blo\u00df an das K\u00f6nnen binden;", "tokens": ["Das", "Wol\u00b7len", "mu\u00df", "sich", "da", "blo\u00df", "an", "das", "K\u00f6n\u00b7nen", "bin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Doch Worte decken nicht dergleichen Fehler zu.", "tokens": ["Doch", "Wor\u00b7te", "de\u00b7cken", "nicht", "derg\u00b7lei\u00b7chen", "Feh\u00b7ler", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PTKNEG", "PIS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Nur wisse, da\u00df ich nie des Lasters schuldig worden,", "tokens": ["Nur", "wis\u00b7se", ",", "da\u00df", "ich", "nie", "des", "Las\u00b7ters", "schul\u00b7dig", "wor\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Das einen treuen Freund aus dem Ged\u00e4chtni\u00df schlie\u00dft,", "tokens": ["Das", "ei\u00b7nen", "treu\u00b7en", "Freund", "aus", "dem", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", "schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ich habe stets geha\u00dft, und hasse solchen Orden,", "tokens": ["Ich", "ha\u00b7be", "stets", "ge\u00b7ha\u00dft", ",", "und", "has\u00b7se", "sol\u00b7chen", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "So lange noch das Blut durch Leib und Adern flie\u00dft.", "tokens": ["So", "lan\u00b7ge", "noch", "das", "Blut", "durch", "Leib", "und", "A\u00b7dern", "flie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ist mir gleich dann und wann Gelegenheit verstrichen,", "tokens": ["Ist", "mir", "gleich", "dann", "und", "wann", "Ge\u00b7le\u00b7gen\u00b7heit", "ver\u00b7stri\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "KON", "PWAV", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.30": {"text": "Auch manchmahl eine Brut in der Geburt erstickt,", "tokens": ["Auch", "manch\u00b7mahl", "ei\u00b7ne", "Brut", "in", "der", "Ge\u00b7burt", "er\u00b7stickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Hab ich gleich manche Post mit M\u00fc\u00dfiggehn verschlichen,", "tokens": ["Hab", "ich", "gleich", "man\u00b7che", "Post", "mit", "M\u00fc\u00b7\u00dfig\u00b7gehn", "ver\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PIAT", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Sind die Gedancken doch als Bothen abgeschickt.", "tokens": ["Sind", "die", "Ge\u00b7dan\u00b7cken", "doch", "als", "Bo\u00b7then", "ab\u00b7ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ach! k\u00f6nten sie den Flug nach meinem Willen kehren,", "tokens": ["Ach", "!", "k\u00f6n\u00b7ten", "sie", "den", "Flug", "nach", "mei\u00b7nem", "Wil\u00b7len", "keh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VMFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Wohin mein heisser Wunsch sie eigentlich begehrt,", "tokens": ["Wo\u00b7hin", "mein", "heis\u00b7ser", "Wunsch", "sie", "ei\u00b7gent\u00b7lich", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.35": {"text": "Du w\u00fcrdest Tag vor Tag die schnelle Zeitung h\u00f6ren:", "tokens": ["Du", "w\u00fcr\u00b7dest", "Tag", "vor", "Tag", "die", "schnel\u00b7le", "Zei\u00b7tung", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Sey tausend mahl gegr\u00fc\u00dft!", "tokens": ["Sey", "tau\u00b7send", "mahl", "ge\u00b7gr\u00fc\u00dft", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Dich gr\u00fc\u00dft ein schlechter Kiel am Tyber-Strand geschnitten,", "tokens": ["Dich", "gr\u00fc\u00dft", "ein", "schlech\u00b7ter", "Kiel", "am", "Ty\u00b7ber\u00b7Strand", "ge\u00b7schnit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und klagt, da\u00df er nicht eh bezahlet seine Schuld;", "tokens": ["Und", "klagt", ",", "da\u00df", "er", "nicht", "eh", "be\u00b7zah\u00b7let", "sei\u00b7ne", "Schuld", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er zittert in der Hand, die gantz von Schaam bestritten,", "tokens": ["Er", "zit\u00b7tert", "in", "der", "Hand", ",", "die", "gantz", "von", "Schaam", "be\u00b7strit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wartet auf den Spruch des Richters mit Gedult.", "tokens": ["Und", "war\u00b7tet", "auf", "den", "Spruch", "des", "Rich\u00b7ters", "mit", "Ge\u00b7dult", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich bins, mein Pylades, der diese Zeilen sendet", "tokens": ["Ich", "bins", ",", "mein", "Py\u00b7la\u00b7des", ",", "der", "die\u00b7se", "Zei\u00b7len", "sen\u00b7det"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PPOSAT", "NN", "$,", "PRELS", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Aus unbekanntem Ort, doch unverf\u00e4lschtem Sinn,", "tokens": ["Aus", "un\u00b7be\u00b7kann\u00b7tem", "Ort", ",", "doch", "un\u00b7ver\u00b7f\u00e4lschtem", "Sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Der ich, seit Cynthia sich zweymahl umgewendet,", "tokens": ["Der", "ich", ",", "seit", "Cyn\u00b7thia", "sich", "zwey\u00b7mahl", "um\u00b7ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "APPR", "NE", "PRF", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "In dieser Romuls-Stadt ein B\u00fcrger worden bin.", "tokens": ["In", "die\u00b7ser", "Ro\u00b7muls\u00b7Stadt", "ein", "B\u00fcr\u00b7ger", "wor\u00b7den", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ART", "NN", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du sprichst: was Kiel? was Brieff? hei\u00dft das sich so verbunden?", "tokens": ["Du", "sprichst", ":", "was", "Kiel", "?", "was", "Brieff", "?", "hei\u00dft", "das", "sich", "so", "ver\u00b7bun\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "NE", "$.", "PWS", "NN", "$.", "VVFIN", "PDS", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Hei\u00dft das gewisse Zeit zum Schreiben angesetzt,", "tokens": ["Hei\u00dft", "das", "ge\u00b7wis\u00b7se", "Zeit", "zum", "Schrei\u00b7ben", "an\u00b7ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie ich am Saal-Athen auf meinem Tisch gefunden?", "tokens": ["Wie", "ich", "am", "Saa\u00b7lA\u00b7then", "auf", "mei\u00b7nem", "Tisch", "ge\u00b7fun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wird Siegel, Hand und Schrifft und Wort so schlecht gesch\u00e4tzt?", "tokens": ["Wird", "Sie\u00b7gel", ",", "Hand", "und", "Schrifft", "und", "Wort", "so", "schlecht", "ge\u00b7sch\u00e4tzt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "NN", "KON", "NN", "KON", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was man in jenem Jahr so feyerlich versprochen,", "tokens": ["Was", "man", "in", "je\u00b7nem", "Jahr", "so", "fey\u00b7er\u00b7lich", "ver\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PDAT", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Das wird in diesem kaum ans Tagelicht gebracht.", "tokens": ["Das", "wird", "in", "die\u00b7sem", "kaum", "ans", "Ta\u00b7ge\u00b7licht", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PDAT", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So bald die Jugend nur in fremde Lufft gerochen,", "tokens": ["So", "bald", "die", "Ju\u00b7gend", "nur", "in", "frem\u00b7de", "Lufft", "ge\u00b7ro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wird im geringsten nicht der Freundschafft mehr gedacht.", "tokens": ["Wird", "im", "ge\u00b7rings\u00b7ten", "nicht", "der", "Freund\u00b7schafft", "mehr", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "ADJA", "PTKNEG", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ich sage nichts dazu. Ich straffe mein Verbrechen,", "tokens": ["Ich", "sa\u00b7ge", "nichts", "da\u00b7zu", ".", "Ich", "straf\u00b7fe", "mein", "Ver\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PAV", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und mag kein Vormund hier der bl\u00f6den Faulheit seyn,", "tokens": ["Und", "mag", "kein", "Vor\u00b7mund", "hier", "der", "bl\u00f6\u00b7den", "Faul\u00b7heit", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIAT", "NN", "ADV", "ART", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ich finde mich verpflicht, mir selbst zu widersprechen,", "tokens": ["Ich", "fin\u00b7de", "mich", "ver\u00b7pflicht", ",", "mir", "selbst", "zu", "wi\u00b7der\u00b7spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und stelle, wieder mich, mich selbst als Kl\u00e4ger ein.", "tokens": ["Und", "stel\u00b7le", ",", "wie\u00b7der", "mich", ",", "mich", "selbst", "als", "Kl\u00e4\u00b7ger", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "PPER", "$,", "PPER", "ADV", "KOUS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Zur Ausflucht k\u00f6nnt' ich zwar hier leichtlich etwas finden,", "tokens": ["Zur", "Aus\u00b7flucht", "k\u00f6nnt'", "ich", "zwar", "hier", "leicht\u00b7lich", "et\u00b7was", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Auf Reisen sind wir ja nicht Meister unsrer Ruh,", "tokens": ["Auf", "Rei\u00b7sen", "sind", "wir", "ja", "nicht", "Meis\u00b7ter", "uns\u00b7rer", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "PTKNEG", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Das Wollen mu\u00df sich da blo\u00df an das K\u00f6nnen binden;", "tokens": ["Das", "Wol\u00b7len", "mu\u00df", "sich", "da", "blo\u00df", "an", "das", "K\u00f6n\u00b7nen", "bin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Doch Worte decken nicht dergleichen Fehler zu.", "tokens": ["Doch", "Wor\u00b7te", "de\u00b7cken", "nicht", "derg\u00b7lei\u00b7chen", "Feh\u00b7ler", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PTKNEG", "PIS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Nur wisse, da\u00df ich nie des Lasters schuldig worden,", "tokens": ["Nur", "wis\u00b7se", ",", "da\u00df", "ich", "nie", "des", "Las\u00b7ters", "schul\u00b7dig", "wor\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Das einen treuen Freund aus dem Ged\u00e4chtni\u00df schlie\u00dft,", "tokens": ["Das", "ei\u00b7nen", "treu\u00b7en", "Freund", "aus", "dem", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", "schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ich habe stets geha\u00dft, und hasse solchen Orden,", "tokens": ["Ich", "ha\u00b7be", "stets", "ge\u00b7ha\u00dft", ",", "und", "has\u00b7se", "sol\u00b7chen", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "So lange noch das Blut durch Leib und Adern flie\u00dft.", "tokens": ["So", "lan\u00b7ge", "noch", "das", "Blut", "durch", "Leib", "und", "A\u00b7dern", "flie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ist mir gleich dann und wann Gelegenheit verstrichen,", "tokens": ["Ist", "mir", "gleich", "dann", "und", "wann", "Ge\u00b7le\u00b7gen\u00b7heit", "ver\u00b7stri\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "KON", "PWAV", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.30": {"text": "Auch manchmahl eine Brut in der Geburt erstickt,", "tokens": ["Auch", "manch\u00b7mahl", "ei\u00b7ne", "Brut", "in", "der", "Ge\u00b7burt", "er\u00b7stickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Hab ich gleich manche Post mit M\u00fc\u00dfiggehn verschlichen,", "tokens": ["Hab", "ich", "gleich", "man\u00b7che", "Post", "mit", "M\u00fc\u00b7\u00dfig\u00b7gehn", "ver\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PIAT", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Sind die Gedancken doch als Bothen abgeschickt.", "tokens": ["Sind", "die", "Ge\u00b7dan\u00b7cken", "doch", "als", "Bo\u00b7then", "ab\u00b7ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ach! k\u00f6nten sie den Flug nach meinem Willen kehren,", "tokens": ["Ach", "!", "k\u00f6n\u00b7ten", "sie", "den", "Flug", "nach", "mei\u00b7nem", "Wil\u00b7len", "keh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VMFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Wohin mein heisser Wunsch sie eigentlich begehrt,", "tokens": ["Wo\u00b7hin", "mein", "heis\u00b7ser", "Wunsch", "sie", "ei\u00b7gent\u00b7lich", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.35": {"text": "Du w\u00fcrdest Tag vor Tag die schnelle Zeitung h\u00f6ren:", "tokens": ["Du", "w\u00fcr\u00b7dest", "Tag", "vor", "Tag", "die", "schnel\u00b7le", "Zei\u00b7tung", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Sey tausend mahl gegr\u00fc\u00dft!", "tokens": ["Sey", "tau\u00b7send", "mahl", "ge\u00b7gr\u00fc\u00dft", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}