{"textgrid.poem.44024": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Man mu\u00df doch mit den W\u00f6lfen heulen,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Man mu\u00df doch mit den W\u00f6lfen heulen,", "tokens": ["Man", "mu\u00df", "doch", "mit", "den", "W\u00f6l\u00b7fen", "heu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Drum fort, beth\u00f6rter Eigensinn!", "tokens": ["Drum", "fort", ",", "be\u00b7th\u00f6r\u00b7ter", "Ei\u00b7gen\u00b7sinn", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "PTKVZ", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will mich in die Leute theilen", "tokens": ["Ich", "will", "mich", "in", "die", "Leu\u00b7te", "thei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und lachen, wie und wo ich bin.", "tokens": ["Und", "la\u00b7chen", ",", "wie", "und", "wo", "ich", "bin", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "PWAV", "KON", "PWAV", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Sauertopf mag immer schelten", "tokens": ["Ein", "Sau\u00b7er\u00b7topf", "mag", "im\u00b7mer", "schel\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und unsre Zeit dem Satan weihn,", "tokens": ["Und", "uns\u00b7re", "Zeit", "dem", "Sa\u00b7tan", "weihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Denn untersucht er tausend Welten,", "tokens": ["Denn", "un\u00b7ter\u00b7sucht", "er", "tau\u00b7send", "Wel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wird keine sonder Mangel seyn.", "tokens": ["Wird", "kei\u00b7ne", "son\u00b7der", "Man\u00b7gel", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Das ist wohl wahr: es giebt viel Thoren.", "tokens": ["Das", "ist", "wohl", "wahr", ":", "es", "giebt", "viel", "Tho\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$.", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das macht, sie wachsen unges\u00e4t,", "tokens": ["Das", "macht", ",", "sie", "wach\u00b7sen", "un\u00b7ge\u00b7s\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wer nicht schiert, der wird geschoren,", "tokens": ["Und", "wer", "nicht", "schiert", ",", "der", "wird", "ge\u00b7scho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "VVFIN", "$,", "PRELS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So bald er nur den R\u00fccken dreht.", "tokens": ["So", "bald", "er", "nur", "den", "R\u00fc\u00b7cken", "dreht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Aus Complimenten und Flattiren", "tokens": ["Aus", "Com\u00b7pli\u00b7men\u00b7ten", "und", "Flat\u00b7ti\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Erkennt man den Politicum,", "tokens": ["Er\u00b7kennt", "man", "den", "Po\u00b7li\u00b7ti\u00b7cum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Will einer nun nicht Hunde f\u00fchren,", "tokens": ["Will", "ei\u00b7ner", "nun", "nicht", "Hun\u00b7de", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "PTKNEG", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So kehr er stets den Mantel um.", "tokens": ["So", "kehr", "er", "stets", "den", "Man\u00b7tel", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Bey H\u00f6fen sinnt man nur auf Mittel,", "tokens": ["Bey", "H\u00f6\u00b7fen", "sinnt", "man", "nur", "auf", "Mit\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Einander klug zu hintergehn;", "tokens": ["Ein\u00b7an\u00b7der", "klug", "zu", "hin\u00b7ter\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der flickt fast st\u00fcndlich an dem Tittel,", "tokens": ["Der", "flickt", "fast", "st\u00fcnd\u00b7lich", "an", "dem", "Tit\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der lehrt die H\u00f6rner zierlich stehn,", "tokens": ["Der", "lehrt", "die", "H\u00f6r\u00b7ner", "zier\u00b7lich", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Dritte wird bey Wild und Jagen", "tokens": ["Der", "Drit\u00b7te", "wird", "bey", "Wild", "und", "Ja\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch viel Beschwerde selbst zum Vieh,", "tokens": ["Durch", "viel", "Be\u00b7schwer\u00b7de", "selbst", "zum", "Vieh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und k\u00f6mmt ein Unterthan zum Klagen,", "tokens": ["Und", "k\u00f6mmt", "ein", "Un\u00b7ter\u00b7than", "zum", "Kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So sp(uckt) der F\u00fcnfte vor das Knie,", "tokens": ["So", "sp", "(", "uckt", ")", "der", "F\u00fcnf\u00b7te", "vor", "das", "Knie", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$(", "VVPP", "$(", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "In St\u00e4dten steht es nicht viel be\u00dfer,", "tokens": ["In", "St\u00e4d\u00b7ten", "steht", "es", "nicht", "viel", "be\u00b7\u00dfer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da herrschen Schwelgerey und Neid,", "tokens": ["Da", "herr\u00b7schen", "Schwel\u00b7ge\u00b7rey", "und", "Neid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man schneidet mit dem gro\u00dfen Me\u00dfer", "tokens": ["Man", "schnei\u00b7det", "mit", "dem", "gro\u00b7\u00dfen", "Me\u00b7\u00dfer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Nechsten in sein Ehrenkleid;", "tokens": ["Dem", "Nechs\u00b7ten", "in", "sein", "Eh\u00b7ren\u00b7kleid", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer uns von vorne gr\u00fc\u00dft und lecket,", "tokens": ["Wer", "uns", "von", "vor\u00b7ne", "gr\u00fc\u00dft", "und", "le\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der spuckt uns \u00fcber Achseln nach,", "tokens": ["Der", "spuckt", "uns", "\u00fc\u00b7ber", "Ach\u00b7seln", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und wer sich nach der Decke strecket,", "tokens": ["Und", "wer", "sich", "nach", "der", "De\u00b7cke", "stre\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den schimpft ein jegliches Gelach.", "tokens": ["Den", "schimpft", "ein", "jeg\u00b7li\u00b7ches", "Ge\u00b7lach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die Weiber sind gar ausgela\u00dfen,", "tokens": ["Die", "Wei\u00b7ber", "sind", "gar", "aus\u00b7ge\u00b7la\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie thun es frey beym Mondenschein,", "tokens": ["Sie", "thun", "es", "frey", "beym", "Mon\u00b7den\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So hizig, da\u00df auf allen Ga\u00dfen", "tokens": ["So", "hi\u00b7zig", ",", "da\u00df", "auf", "al\u00b7len", "Ga\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Pflaster ausgeritten seyn.", "tokens": ["Die", "Pflas\u00b7ter", "aus\u00b7ge\u00b7rit\u00b7ten", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die M\u00e4nner folgen dem Exempel,", "tokens": ["Die", "M\u00e4n\u00b7ner", "fol\u00b7gen", "dem", "Ex\u00b7em\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Kaum riecht was Junges in die Stadt,", "tokens": ["Kaum", "riecht", "was", "Jun\u00b7ges", "in", "die", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So lauft man pl\u00f6zlich aus dem Tempel,", "tokens": ["So", "lauft", "man", "pl\u00f6z\u00b7lich", "aus", "dem", "Tem\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zu sehn, wie viel es Keuschheit hat.", "tokens": ["Zu", "sehn", ",", "wie", "viel", "es", "Keuschheit", "hat", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PWAV", "PIS", "PPER", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Was soll ich von den M\u00e4gdgen sagen?", "tokens": ["Was", "soll", "ich", "von", "den", "M\u00e4gd\u00b7gen", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sind vorwahr zu tugendreich,", "tokens": ["Sie", "sind", "vor\u00b7wahr", "zu", "tu\u00b7gen\u00b7dreich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie lernen viel aus Demuth tragen", "tokens": ["Sie", "ler\u00b7nen", "viel", "aus", "De\u00b7muth", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sch\u00e4men sich so kranck als bleich.", "tokens": ["Und", "sch\u00e4\u00b7men", "sich", "so", "kranck", "als", "bleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADJD", "KOKOM", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das macht vielleicht der schlimme Winter,", "tokens": ["Das", "macht", "viel\u00b7leicht", "der", "schlim\u00b7me", "Win\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der alles in den Gliedern regt.", "tokens": ["Der", "al\u00b7les", "in", "den", "Glie\u00b7dern", "reg\u00b7t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Doch nein, es steckt noch was darhinter.", "tokens": ["Doch", "nein", ",", "es", "steckt", "noch", "was", "dar\u00b7hin\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$,", "PPER", "VVFIN", "ADV", "PWS", "PAV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und was denn? Was der Kirchknecht tr\u00e4gt.", "tokens": ["Und", "was", "denn", "?", "Was", "der", "Kirch\u00b7knecht", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "$.", "PWS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Nun sagt mir, soll ich anders leben,", "tokens": ["Nun", "sagt", "mir", ",", "soll", "ich", "an\u00b7ders", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So lacht mich jeder Pinsel aus:", "tokens": ["So", "lacht", "mich", "je\u00b7der", "Pin\u00b7sel", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nach Warheit, Zucht und Tugend streben", "tokens": ["Nach", "War\u00b7heit", ",", "Zucht", "und", "Tu\u00b7gend", "stre\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Baut jezt vorwahr kein steinern Haus.", "tokens": ["Baut", "jezt", "vor\u00b7wahr", "kein", "stei\u00b7nern", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich mach es so wie meines gleichen,", "tokens": ["Ich", "mach", "es", "so", "wie", "mei\u00b7nes", "glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KOKOM", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und wer mich drum verdencken will,", "tokens": ["Und", "wer", "mich", "drum", "ver\u00b7den\u00b7cken", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PAV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der h\u00f6re diesen guten streichen", "tokens": ["Der", "h\u00f6\u00b7re", "die\u00b7sen", "gu\u00b7ten", "strei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und nehm ihn mit und schweige still.", "tokens": ["Und", "nehm", "ihn", "mit", "und", "schwei\u00b7ge", "still", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Man mu\u00df doch mit den W\u00f6lfen heulen,", "tokens": ["Man", "mu\u00df", "doch", "mit", "den", "W\u00f6l\u00b7fen", "heu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Drum fort, beth\u00f6rter Eigensinn!", "tokens": ["Drum", "fort", ",", "be\u00b7th\u00f6r\u00b7ter", "Ei\u00b7gen\u00b7sinn", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "PTKVZ", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will mich in die Leute theilen", "tokens": ["Ich", "will", "mich", "in", "die", "Leu\u00b7te", "thei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und lachen, wie und wo ich bin.", "tokens": ["Und", "la\u00b7chen", ",", "wie", "und", "wo", "ich", "bin", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "PWAV", "KON", "PWAV", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Sauertopf mag immer schelten", "tokens": ["Ein", "Sau\u00b7er\u00b7topf", "mag", "im\u00b7mer", "schel\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und unsre Zeit dem Satan weihn,", "tokens": ["Und", "uns\u00b7re", "Zeit", "dem", "Sa\u00b7tan", "weihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Denn untersucht er tausend Welten,", "tokens": ["Denn", "un\u00b7ter\u00b7sucht", "er", "tau\u00b7send", "Wel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wird keine sonder Mangel seyn.", "tokens": ["Wird", "kei\u00b7ne", "son\u00b7der", "Man\u00b7gel", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Das ist wohl wahr: es giebt viel Thoren.", "tokens": ["Das", "ist", "wohl", "wahr", ":", "es", "giebt", "viel", "Tho\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$.", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das macht, sie wachsen unges\u00e4t,", "tokens": ["Das", "macht", ",", "sie", "wach\u00b7sen", "un\u00b7ge\u00b7s\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wer nicht schiert, der wird geschoren,", "tokens": ["Und", "wer", "nicht", "schiert", ",", "der", "wird", "ge\u00b7scho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "VVFIN", "$,", "PRELS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So bald er nur den R\u00fccken dreht.", "tokens": ["So", "bald", "er", "nur", "den", "R\u00fc\u00b7cken", "dreht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Aus Complimenten und Flattiren", "tokens": ["Aus", "Com\u00b7pli\u00b7men\u00b7ten", "und", "Flat\u00b7ti\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Erkennt man den Politicum,", "tokens": ["Er\u00b7kennt", "man", "den", "Po\u00b7li\u00b7ti\u00b7cum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Will einer nun nicht Hunde f\u00fchren,", "tokens": ["Will", "ei\u00b7ner", "nun", "nicht", "Hun\u00b7de", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "PTKNEG", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So kehr er stets den Mantel um.", "tokens": ["So", "kehr", "er", "stets", "den", "Man\u00b7tel", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Bey H\u00f6fen sinnt man nur auf Mittel,", "tokens": ["Bey", "H\u00f6\u00b7fen", "sinnt", "man", "nur", "auf", "Mit\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Einander klug zu hintergehn;", "tokens": ["Ein\u00b7an\u00b7der", "klug", "zu", "hin\u00b7ter\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der flickt fast st\u00fcndlich an dem Tittel,", "tokens": ["Der", "flickt", "fast", "st\u00fcnd\u00b7lich", "an", "dem", "Tit\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der lehrt die H\u00f6rner zierlich stehn,", "tokens": ["Der", "lehrt", "die", "H\u00f6r\u00b7ner", "zier\u00b7lich", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Dritte wird bey Wild und Jagen", "tokens": ["Der", "Drit\u00b7te", "wird", "bey", "Wild", "und", "Ja\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch viel Beschwerde selbst zum Vieh,", "tokens": ["Durch", "viel", "Be\u00b7schwer\u00b7de", "selbst", "zum", "Vieh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und k\u00f6mmt ein Unterthan zum Klagen,", "tokens": ["Und", "k\u00f6mmt", "ein", "Un\u00b7ter\u00b7than", "zum", "Kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So sp(uckt) der F\u00fcnfte vor das Knie,", "tokens": ["So", "sp", "(", "uckt", ")", "der", "F\u00fcnf\u00b7te", "vor", "das", "Knie", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$(", "VVPP", "$(", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "In St\u00e4dten steht es nicht viel be\u00dfer,", "tokens": ["In", "St\u00e4d\u00b7ten", "steht", "es", "nicht", "viel", "be\u00b7\u00dfer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da herrschen Schwelgerey und Neid,", "tokens": ["Da", "herr\u00b7schen", "Schwel\u00b7ge\u00b7rey", "und", "Neid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man schneidet mit dem gro\u00dfen Me\u00dfer", "tokens": ["Man", "schnei\u00b7det", "mit", "dem", "gro\u00b7\u00dfen", "Me\u00b7\u00dfer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Nechsten in sein Ehrenkleid;", "tokens": ["Dem", "Nechs\u00b7ten", "in", "sein", "Eh\u00b7ren\u00b7kleid", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer uns von vorne gr\u00fc\u00dft und lecket,", "tokens": ["Wer", "uns", "von", "vor\u00b7ne", "gr\u00fc\u00dft", "und", "le\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der spuckt uns \u00fcber Achseln nach,", "tokens": ["Der", "spuckt", "uns", "\u00fc\u00b7ber", "Ach\u00b7seln", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und wer sich nach der Decke strecket,", "tokens": ["Und", "wer", "sich", "nach", "der", "De\u00b7cke", "stre\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den schimpft ein jegliches Gelach.", "tokens": ["Den", "schimpft", "ein", "jeg\u00b7li\u00b7ches", "Ge\u00b7lach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Die Weiber sind gar ausgela\u00dfen,", "tokens": ["Die", "Wei\u00b7ber", "sind", "gar", "aus\u00b7ge\u00b7la\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie thun es frey beym Mondenschein,", "tokens": ["Sie", "thun", "es", "frey", "beym", "Mon\u00b7den\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So hizig, da\u00df auf allen Ga\u00dfen", "tokens": ["So", "hi\u00b7zig", ",", "da\u00df", "auf", "al\u00b7len", "Ga\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Pflaster ausgeritten seyn.", "tokens": ["Die", "Pflas\u00b7ter", "aus\u00b7ge\u00b7rit\u00b7ten", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die M\u00e4nner folgen dem Exempel,", "tokens": ["Die", "M\u00e4n\u00b7ner", "fol\u00b7gen", "dem", "Ex\u00b7em\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Kaum riecht was Junges in die Stadt,", "tokens": ["Kaum", "riecht", "was", "Jun\u00b7ges", "in", "die", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So lauft man pl\u00f6zlich aus dem Tempel,", "tokens": ["So", "lauft", "man", "pl\u00f6z\u00b7lich", "aus", "dem", "Tem\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zu sehn, wie viel es Keuschheit hat.", "tokens": ["Zu", "sehn", ",", "wie", "viel", "es", "Keuschheit", "hat", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PWAV", "PIS", "PPER", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Was soll ich von den M\u00e4gdgen sagen?", "tokens": ["Was", "soll", "ich", "von", "den", "M\u00e4gd\u00b7gen", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sind vorwahr zu tugendreich,", "tokens": ["Sie", "sind", "vor\u00b7wahr", "zu", "tu\u00b7gen\u00b7dreich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie lernen viel aus Demuth tragen", "tokens": ["Sie", "ler\u00b7nen", "viel", "aus", "De\u00b7muth", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sch\u00e4men sich so kranck als bleich.", "tokens": ["Und", "sch\u00e4\u00b7men", "sich", "so", "kranck", "als", "bleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADJD", "KOKOM", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das macht vielleicht der schlimme Winter,", "tokens": ["Das", "macht", "viel\u00b7leicht", "der", "schlim\u00b7me", "Win\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der alles in den Gliedern regt.", "tokens": ["Der", "al\u00b7les", "in", "den", "Glie\u00b7dern", "reg\u00b7t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Doch nein, es steckt noch was darhinter.", "tokens": ["Doch", "nein", ",", "es", "steckt", "noch", "was", "dar\u00b7hin\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$,", "PPER", "VVFIN", "ADV", "PWS", "PAV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und was denn? Was der Kirchknecht tr\u00e4gt.", "tokens": ["Und", "was", "denn", "?", "Was", "der", "Kirch\u00b7knecht", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "$.", "PWS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Nun sagt mir, soll ich anders leben,", "tokens": ["Nun", "sagt", "mir", ",", "soll", "ich", "an\u00b7ders", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So lacht mich jeder Pinsel aus:", "tokens": ["So", "lacht", "mich", "je\u00b7der", "Pin\u00b7sel", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nach Warheit, Zucht und Tugend streben", "tokens": ["Nach", "War\u00b7heit", ",", "Zucht", "und", "Tu\u00b7gend", "stre\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Baut jezt vorwahr kein steinern Haus.", "tokens": ["Baut", "jezt", "vor\u00b7wahr", "kein", "stei\u00b7nern", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich mach es so wie meines gleichen,", "tokens": ["Ich", "mach", "es", "so", "wie", "mei\u00b7nes", "glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KOKOM", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und wer mich drum verdencken will,", "tokens": ["Und", "wer", "mich", "drum", "ver\u00b7den\u00b7cken", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PAV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der h\u00f6re diesen guten streichen", "tokens": ["Der", "h\u00f6\u00b7re", "die\u00b7sen", "gu\u00b7ten", "strei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und nehm ihn mit und schweige still.", "tokens": ["Und", "nehm", "ihn", "mit", "und", "schwei\u00b7ge", "still", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}