{"textgrid.poem.32533": {"metadata": {"author": {"name": "Lessing, Gotthold Ephraim", "birth": "N.A.", "death": "N.A."}, "title": "XiV. Nix Bodenstrom", "genre": "verse", "period": "N.A.", "pub_year": 1755, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nix Bodenstrom, ein Schiffer, nahm -", "tokens": ["Nix", "Bo\u00b7dens\u00b7trom", ",", "ein", "Schif\u00b7fer", ",", "nahm"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "$,", "ART", "NN", "$,", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War es in Hamburg oder Amsterdam,", "tokens": ["War", "es", "in", "Ham\u00b7burg", "o\u00b7der", "A\u00b7mster\u00b7dam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NE", "KON", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Daran ist wenig oder nichts gelegen -", "tokens": ["Da\u00b7ran", "ist", "we\u00b7nig", "o\u00b7der", "nichts", "ge\u00b7le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PIS", "KON", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein junges Weib.", "tokens": ["Ein", "jun\u00b7ges", "Weib", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "\u00bbdas ist auch sehr verwegen,", "tokens": ["\u00bb", "das", "ist", "auch", "sehr", "ver\u00b7we\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Freund!\u00ab sprach ein Kaufherr, den zum Hochzeitschmause", "tokens": ["Freund", "!", "\u00ab", "sprach", "ein", "Kauf\u00b7herr", ",", "den", "zum", "Hoch\u00b7zeit\u00b7schmau\u00b7se"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "$(", "VVFIN", "ART", "NN", "$,", "PRELS", "APPRART", "NN"], "meter": "+--++--+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Der Schiffer bat. \u00bbDu bist so lang' und oft von Hause;", "tokens": ["Der", "Schif\u00b7fer", "bat", ".", "\u00bb", "Du", "bist", "so", "lang'", "und", "oft", "von", "Hau\u00b7se", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ADV", "ADV", "KON", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dein Weibchen bleibt indes allein:", "tokens": ["Dein", "Weib\u00b7chen", "bleibt", "in\u00b7des", "al\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und dennoch - willst du mit Gewalt denn Hahnrei sein?", "tokens": ["Und", "den\u00b7noch", "willst", "du", "mit", "Ge\u00b7walt", "denn", "Hahn\u00b7rei", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "VMFIN", "PPER", "APPR", "NN", "KON", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.10": {"text": "Indes, da\u00df du zur See dein Leben wagst,", "tokens": ["In\u00b7des", ",", "da\u00df", "du", "zur", "See", "dein", "Le\u00b7ben", "wagst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "APPRART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Indes, da\u00df du in Surinam, am Amazonenflusse,", "tokens": ["In\u00b7des", ",", "da\u00df", "du", "in", "Su\u00b7ri\u00b7nam", ",", "am", "A\u00b7maz\u00b7o\u00b7nen\u00b7flus\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "NE", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.12": {"text": "Dich bei den Hottentotten, Kannibalen plagst:", "tokens": ["Dich", "bei", "den", "Hot\u00b7ten\u00b7tot\u00b7ten", ",", "Kan\u00b7ni\u00b7ba\u00b7len", "plagst", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$,", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Indes wird sie - -\u00ab", "tokens": ["In\u00b7des", "wird", "sie", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$(", "$(", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.15": {"text": "Versetzte Nix. \u00bb", "tokens": ["Ver\u00b7setz\u00b7te", "Nix", ".", "\u00bb"], "token_info": ["word", "word", "punct", "punct"], "pos": ["VVFIN", "NE", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Nix Bodenstrom, ein Schiffer, nahm -", "tokens": ["Nix", "Bo\u00b7dens\u00b7trom", ",", "ein", "Schif\u00b7fer", ",", "nahm"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "$,", "ART", "NN", "$,", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War es in Hamburg oder Amsterdam,", "tokens": ["War", "es", "in", "Ham\u00b7burg", "o\u00b7der", "A\u00b7mster\u00b7dam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NE", "KON", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Daran ist wenig oder nichts gelegen -", "tokens": ["Da\u00b7ran", "ist", "we\u00b7nig", "o\u00b7der", "nichts", "ge\u00b7le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PIS", "KON", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein junges Weib.", "tokens": ["Ein", "jun\u00b7ges", "Weib", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "\u00bbdas ist auch sehr verwegen,", "tokens": ["\u00bb", "das", "ist", "auch", "sehr", "ver\u00b7we\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Freund!\u00ab sprach ein Kaufherr, den zum Hochzeitschmause", "tokens": ["Freund", "!", "\u00ab", "sprach", "ein", "Kauf\u00b7herr", ",", "den", "zum", "Hoch\u00b7zeit\u00b7schmau\u00b7se"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "$(", "VVFIN", "ART", "NN", "$,", "PRELS", "APPRART", "NN"], "meter": "+--++--+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Der Schiffer bat. \u00bbDu bist so lang' und oft von Hause;", "tokens": ["Der", "Schif\u00b7fer", "bat", ".", "\u00bb", "Du", "bist", "so", "lang'", "und", "oft", "von", "Hau\u00b7se", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ADV", "ADV", "KON", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dein Weibchen bleibt indes allein:", "tokens": ["Dein", "Weib\u00b7chen", "bleibt", "in\u00b7des", "al\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und dennoch - willst du mit Gewalt denn Hahnrei sein?", "tokens": ["Und", "den\u00b7noch", "willst", "du", "mit", "Ge\u00b7walt", "denn", "Hahn\u00b7rei", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "VMFIN", "PPER", "APPR", "NN", "KON", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.10": {"text": "Indes, da\u00df du zur See dein Leben wagst,", "tokens": ["In\u00b7des", ",", "da\u00df", "du", "zur", "See", "dein", "Le\u00b7ben", "wagst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "APPRART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Indes, da\u00df du in Surinam, am Amazonenflusse,", "tokens": ["In\u00b7des", ",", "da\u00df", "du", "in", "Su\u00b7ri\u00b7nam", ",", "am", "A\u00b7maz\u00b7o\u00b7nen\u00b7flus\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "NE", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.12": {"text": "Dich bei den Hottentotten, Kannibalen plagst:", "tokens": ["Dich", "bei", "den", "Hot\u00b7ten\u00b7tot\u00b7ten", ",", "Kan\u00b7ni\u00b7ba\u00b7len", "plagst", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$,", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Indes wird sie - -\u00ab", "tokens": ["In\u00b7des", "wird", "sie", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$(", "$(", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.15": {"text": "Versetzte Nix. \u00bb", "tokens": ["Ver\u00b7setz\u00b7te", "Nix", ".", "\u00bb"], "token_info": ["word", "word", "punct", "punct"], "pos": ["VVFIN", "NE", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}}}}