{"dta.poem.21149": {"metadata": {"author": {"name": "Zachariae, Justus Friedrich Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Die Aufmunterung .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1764", "urn": "urn:nbn:de:kobv:b4-20676-2", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es ist sonst nicht meine Sache,", "tokens": ["Es", "ist", "sonst", "nicht", "mei\u00b7ne", "Sa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich Complimente mache;", "tokens": ["Da\u00df", "ich", "Com\u00b7pli\u00b7men\u00b7te", "ma\u00b7che", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch ietzt f\u00e4llt mir manchmal bey,", "tokens": ["Doch", "ietzt", "f\u00e4llt", "mir", "manch\u00b7mal", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "Ob ich nicht zu furchtsam sey.", "tokens": ["Ob", "ich", "nicht", "zu", "furcht\u00b7sam", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PTKA", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Meinem Freund darf ichs nicht sagen,", "tokens": ["Mei\u00b7nem", "Freund", "darf", "ichs", "nicht", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Denn der predigt so genug:", "tokens": ["Denn", "der", "pre\u00b7digt", "so", "ge\u00b7nug", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Junger Mensch, werd einmal klug.", "tokens": ["Jun\u00b7ger", "Mensch", ",", "werd", "ein\u00b7mal", "klug", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Freylich mu\u00df man etwas wagen.", "tokens": ["Frey\u00b7lich", "mu\u00df", "man", "et\u00b7was", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Wer wird lange fragen?", "tokens": ["Wer", "wird", "lan\u00b7ge", "fra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "VVINF", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.2": {"line.1": {"text": "Neulich sagt ich, mir ist bange,", "tokens": ["Neu\u00b7lich", "sagt", "ich", ",", "mir", "ist", "ban\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich Doris nie erlange;", "tokens": ["Da\u00df", "ich", "Do\u00b7ris", "nie", "er\u00b7lan\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie ist so voll kleiner List,", "tokens": ["Sie", "ist", "so", "voll", "klei\u00b7ner", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Da\u00df es nicht zu sagen ist.", "tokens": ["Da\u00df", "es", "nicht", "zu", "sa\u00b7gen", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ey, (sprach er,) wer wird verzagen?", "tokens": ["Ey", ",", "(", "sprach", "er", ",", ")", "wer", "wird", "ver\u00b7za\u00b7gen", "?"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "PWS", "VAFIN", "VVINF", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Sagt ihr z\u00e4rtlich Auge nicht", "tokens": ["Sagt", "ihr", "z\u00e4rt\u00b7lich", "Au\u00b7ge", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "NN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Alles das, was sie nicht spricht?", "tokens": ["Al\u00b7les", "das", ",", "was", "sie", "nicht", "spricht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PDS", "$,", "PRELS", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Soll sie denn ausdr\u00fccklich sagen:", "tokens": ["Soll", "sie", "denn", "aus\u00b7dr\u00fcck\u00b7lich", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Wer wird lange fragen?", "tokens": ["Wer", "wird", "lan\u00b7ge", "fra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "VVINF", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.3": {"line.1": {"text": "Liebes M\u00e4dchen, la\u00df dich k\u00fcssen,", "tokens": ["Lie\u00b7bes", "M\u00e4d\u00b7chen", ",", "la\u00df", "dich", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVIMP", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagt ich z\u00e4rtlich zu Clarissen,", "tokens": ["Sagt", "ich", "z\u00e4rt\u00b7lich", "zu", "Cla\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch das M\u00e4dchen that ganz breit;", "tokens": ["Doch", "das", "M\u00e4d\u00b7chen", "that", "ganz", "breit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ey, wer k\u00fc\u00dft die ganze Zeit?", "tokens": ["Ey", ",", "wer", "k\u00fc\u00dft", "die", "gan\u00b7ze", "Zeit", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gleich drauf, ohn ein Wort zu sagen,", "tokens": ["Gleich", "drauf", ",", "ohn", "ein", "Wort", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "KOUI", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Macht ich mir von neuem Muth,", "tokens": ["Macht", "ich", "mir", "von", "neu\u00b7em", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "K\u00fc\u00dfte sie; und es war gut.", "tokens": ["K\u00fc\u00df\u00b7te", "sie", ";", "und", "es", "war", "gut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "KON", "PPER", "VAFIN", "ADJD", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.8": {"text": "Und ihr Auge schien zu sagen:", "tokens": ["Und", "ihr", "Au\u00b7ge", "schien", "zu", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Wer wird lange fragen?", "tokens": ["Wer", "wird", "lan\u00b7ge", "fra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "VVINF", "$."], "meter": "+---+-", "measure": "dactylic.init"}}}}}