{"textgrid.poem.42439": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Einst nach vielen Jahren fand in einem Brief ich,", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Einst nach vielen Jahren fand in einem Brief ich,", "tokens": ["Einst", "nach", "vie\u00b7len", "Jah\u00b7ren", "fand", "in", "ei\u00b7nem", "Brief", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "VVFIN", "APPR", "ART", "NN", "PPER", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Der beim Suchen in die H\u00e4nde mir gefallen,", "tokens": ["Der", "beim", "Su\u00b7chen", "in", "die", "H\u00e4n\u00b7de", "mir", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "APPR", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Eine Haarnadel. Sie stak am Schlu\u00df: \u00bbSeffinka\u00ab.", "tokens": ["Ei\u00b7ne", "Haar\u00b7na\u00b7del", ".", "Sie", "stak", "am", "Schlu\u00df", ":", "\u00bb", "Sef\u00b7fin\u00b7ka", "\u00ab", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "$.", "PPER", "VVFIN", "APPRART", "NN", "$.", "$(", "NE", "$(", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "\u00bbtausend K\u00fcsse, Gr\u00fc\u00dfe sendet Dir Seffinka\u00ab.", "tokens": ["\u00bb", "tau\u00b7send", "K\u00fcs\u00b7se", ",", "Gr\u00fc\u00b7\u00dfe", "sen\u00b7det", "Dir", "Sef\u00b7fin\u00b7ka", "\u00ab", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "CARD", "NN", "$,", "NN", "VVFIN", "PPER", "NE", "$(", "$."], "meter": "+-+-+-+-+---", "measure": "unknown.measure.penta"}, "line.5": {"text": "Ach, Seffinka! Und nun stand das M\u00e4dchen wieder", "tokens": ["Ach", ",", "Sef\u00b7fin\u00b7ka", "!", "Und", "nun", "stand", "das", "M\u00e4d\u00b7chen", "wie\u00b7der"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "NE", "$.", "KON", "ADV", "VVFIN", "ART", "NN", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Vor mir: Ueber ihre beiden Daumen glitten", "tokens": ["Vor", "mir", ":", "Ue\u00b7ber", "ih\u00b7re", "bei\u00b7den", "Dau\u00b7men", "glit\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$.", "APPR", "PPOSAT", "PIAT", "NN", "VVFIN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "R\u00fcckw\u00e4rts wundervolle rabenschwarze Flechten,", "tokens": ["R\u00fcck\u00b7w\u00e4rts", "wun\u00b7der\u00b7vol\u00b7le", "ra\u00b7ben\u00b7schwar\u00b7ze", "Flech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Die, entflutend, sich in breite Str\u00f6me l\u00f6sten.", "tokens": ["Die", ",", "ent\u00b7flu\u00b7tend", ",", "sich", "in", "brei\u00b7te", "Str\u00f6\u00b7me", "l\u00f6s\u00b7ten", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VVPP", "$,", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "Und die Nadel zwischen ihren Lippen haltend,", "tokens": ["Und", "die", "Na\u00b7del", "zwi\u00b7schen", "ih\u00b7ren", "Lip\u00b7pen", "hal\u00b7tend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Mit der Rechten m\u00fcheschwer den Kamm gebrauchend,", "tokens": ["Mit", "der", "Rech\u00b7ten", "m\u00fc\u00b7he\u00b7schwer", "den", "Kamm", "ge\u00b7brau\u00b7chend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Ordnet sie, mit schr\u00e4ggebognem Haupt, die Haare,", "tokens": ["Ord\u00b7net", "sie", ",", "mit", "schr\u00e4g\u00b7ge\u00b7bog\u00b7nem", "Haupt", ",", "die", "Haa\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Schelmisch sich im gro\u00dfen Spiegelglas betrachtend.", "tokens": ["Schel\u00b7misch", "sich", "im", "gro\u00b7\u00dfen", "Spie\u00b7gel\u00b7glas", "be\u00b7trach\u00b7tend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "Einem Henkelkrug entnahm ich rote Nelken,", "tokens": ["Ei\u00b7nem", "Hen\u00b7kel\u00b7krug", "ent\u00b7nahm", "ich", "ro\u00b7te", "Nel\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "Und ich warf den Blumenraub ihr um den Scheitel.", "tokens": ["Und", "ich", "warf", "den", "Blu\u00b7men\u00b7raub", "ihr", "um", "den", "Schei\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.15": {"text": "W\u00e4hrend lachend sie den Mund zum Schelten \u00f6ffnet,", "tokens": ["W\u00e4h\u00b7rend", "la\u00b7chend", "sie", "den", "Mund", "zum", "Schel\u00b7ten", "\u00f6ff\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.16": {"text": "F\u00e4llt die Nadel; und ich bog mich und verbarg sie.", "tokens": ["F\u00e4llt", "die", "Na\u00b7del", ";", "und", "ich", "bog", "mich", "und", "ver\u00b7barg", "sie", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "KON", "PPER", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.17": {"text": "\u00bbtausend K\u00fcsse, Gr\u00fc\u00dfe sendet Dir Seffinka\u00ab.", "tokens": ["\u00bb", "tau\u00b7send", "K\u00fcs\u00b7se", ",", "Gr\u00fc\u00b7\u00dfe", "sen\u00b7det", "Dir", "Sef\u00b7fin\u00b7ka", "\u00ab", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "CARD", "NN", "$,", "NN", "VVFIN", "PPER", "NE", "$(", "$."], "meter": "+-+-+-+-+---", "measure": "unknown.measure.penta"}}, "stanza.2": {"line.1": {"text": "Einst nach vielen Jahren fand in einem Brief ich,", "tokens": ["Einst", "nach", "vie\u00b7len", "Jah\u00b7ren", "fand", "in", "ei\u00b7nem", "Brief", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "VVFIN", "APPR", "ART", "NN", "PPER", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Der beim Suchen in die H\u00e4nde mir gefallen,", "tokens": ["Der", "beim", "Su\u00b7chen", "in", "die", "H\u00e4n\u00b7de", "mir", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "APPR", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Eine Haarnadel. Sie stak am Schlu\u00df: \u00bbSeffinka\u00ab.", "tokens": ["Ei\u00b7ne", "Haar\u00b7na\u00b7del", ".", "Sie", "stak", "am", "Schlu\u00df", ":", "\u00bb", "Sef\u00b7fin\u00b7ka", "\u00ab", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "$.", "PPER", "VVFIN", "APPRART", "NN", "$.", "$(", "NE", "$(", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "\u00bbtausend K\u00fcsse, Gr\u00fc\u00dfe sendet Dir Seffinka\u00ab.", "tokens": ["\u00bb", "tau\u00b7send", "K\u00fcs\u00b7se", ",", "Gr\u00fc\u00b7\u00dfe", "sen\u00b7det", "Dir", "Sef\u00b7fin\u00b7ka", "\u00ab", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "CARD", "NN", "$,", "NN", "VVFIN", "PPER", "NE", "$(", "$."], "meter": "+-+-+-+-+---", "measure": "unknown.measure.penta"}, "line.5": {"text": "Ach, Seffinka! Und nun stand das M\u00e4dchen wieder", "tokens": ["Ach", ",", "Sef\u00b7fin\u00b7ka", "!", "Und", "nun", "stand", "das", "M\u00e4d\u00b7chen", "wie\u00b7der"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "NE", "$.", "KON", "ADV", "VVFIN", "ART", "NN", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Vor mir: Ueber ihre beiden Daumen glitten", "tokens": ["Vor", "mir", ":", "Ue\u00b7ber", "ih\u00b7re", "bei\u00b7den", "Dau\u00b7men", "glit\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$.", "APPR", "PPOSAT", "PIAT", "NN", "VVFIN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "R\u00fcckw\u00e4rts wundervolle rabenschwarze Flechten,", "tokens": ["R\u00fcck\u00b7w\u00e4rts", "wun\u00b7der\u00b7vol\u00b7le", "ra\u00b7ben\u00b7schwar\u00b7ze", "Flech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Die, entflutend, sich in breite Str\u00f6me l\u00f6sten.", "tokens": ["Die", ",", "ent\u00b7flu\u00b7tend", ",", "sich", "in", "brei\u00b7te", "Str\u00f6\u00b7me", "l\u00f6s\u00b7ten", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VVPP", "$,", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "Und die Nadel zwischen ihren Lippen haltend,", "tokens": ["Und", "die", "Na\u00b7del", "zwi\u00b7schen", "ih\u00b7ren", "Lip\u00b7pen", "hal\u00b7tend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Mit der Rechten m\u00fcheschwer den Kamm gebrauchend,", "tokens": ["Mit", "der", "Rech\u00b7ten", "m\u00fc\u00b7he\u00b7schwer", "den", "Kamm", "ge\u00b7brau\u00b7chend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Ordnet sie, mit schr\u00e4ggebognem Haupt, die Haare,", "tokens": ["Ord\u00b7net", "sie", ",", "mit", "schr\u00e4g\u00b7ge\u00b7bog\u00b7nem", "Haupt", ",", "die", "Haa\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Schelmisch sich im gro\u00dfen Spiegelglas betrachtend.", "tokens": ["Schel\u00b7misch", "sich", "im", "gro\u00b7\u00dfen", "Spie\u00b7gel\u00b7glas", "be\u00b7trach\u00b7tend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "Einem Henkelkrug entnahm ich rote Nelken,", "tokens": ["Ei\u00b7nem", "Hen\u00b7kel\u00b7krug", "ent\u00b7nahm", "ich", "ro\u00b7te", "Nel\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "Und ich warf den Blumenraub ihr um den Scheitel.", "tokens": ["Und", "ich", "warf", "den", "Blu\u00b7men\u00b7raub", "ihr", "um", "den", "Schei\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.15": {"text": "W\u00e4hrend lachend sie den Mund zum Schelten \u00f6ffnet,", "tokens": ["W\u00e4h\u00b7rend", "la\u00b7chend", "sie", "den", "Mund", "zum", "Schel\u00b7ten", "\u00f6ff\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.16": {"text": "F\u00e4llt die Nadel; und ich bog mich und verbarg sie.", "tokens": ["F\u00e4llt", "die", "Na\u00b7del", ";", "und", "ich", "bog", "mich", "und", "ver\u00b7barg", "sie", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "KON", "PPER", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.17": {"text": "\u00bbtausend K\u00fcsse, Gr\u00fc\u00dfe sendet Dir Seffinka\u00ab.", "tokens": ["\u00bb", "tau\u00b7send", "K\u00fcs\u00b7se", ",", "Gr\u00fc\u00b7\u00dfe", "sen\u00b7det", "Dir", "Sef\u00b7fin\u00b7ka", "\u00ab", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "CARD", "NN", "$,", "NN", "VVFIN", "PPER", "NE", "$(", "$."], "meter": "+-+-+-+-+---", "measure": "unknown.measure.penta"}}}}}