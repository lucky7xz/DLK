{"textgrid.poem.53216": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Schuldigste Dienst-Erweisung Churf\u00fcrstl. Durchl. von denen s\u00e4mptlichen Studiosis dero Churf\u00fcrstl. Durchl. Universitaet durch einen Musicalischen Auffzug unterth\u00e4nigst bezeuget", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was ist, Clio, dein Beginnen", "tokens": ["Was", "ist", ",", "Clio", ",", "dein", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PWS", "VAFIN", "$,", "NE", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sampt den andern Pierinnen?", "tokens": ["Sampt", "den", "an\u00b7dern", "Pie\u00b7rin\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Was k\u00f6mpt unsern Seiten an?", "tokens": ["Was", "k\u00f6mpt", "un\u00b7sern", "Sei\u00b7ten", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Welcher Held ist, dem zu Ehren", "tokens": ["Wel\u00b7cher", "Held", "ist", ",", "dem", "zu", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAT", "NN", "VAFIN", "$,", "PRELS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ph\u00f6bus sich so scharff lesst h\u00f6ren,", "tokens": ["Ph\u00f6\u00b7bus", "sich", "so", "scharff", "lesst", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "ADV", "ADJD", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und so k\u00fcnstlich als er kan?", "tokens": ["Und", "so", "k\u00fcnst\u00b7lich", "als", "er", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "KOKOM", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Das bist Du, Trost unsrer Zeiten,", "tokens": ["Das", "bist", "Du", ",", "Trost", "uns\u00b7rer", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dich erhebet theils der Seiten,", "tokens": ["Dich", "er\u00b7he\u00b7bet", "theils", "der", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Theils der Stimmen voller Thon,", "tokens": ["Theils", "der", "Stim\u00b7men", "vol\u00b7ler", "Thon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Held Georg, Dir zu gefallen", "tokens": ["Held", "Ge\u00b7org", ",", "Dir", "zu", "ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$,", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Lesset Cynthius erschallen", "tokens": ["Les\u00b7set", "Cyn\u00b7thi\u00b7us", "er\u00b7schal\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["NE", "NE", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Seinen gantzen Helicon.", "tokens": ["Sei\u00b7nen", "gant\u00b7zen", "He\u00b7li\u00b7con", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Mein Lob, sagt er, Meine Wonne", "tokens": ["Mein", "Lob", ",", "sagt", "er", ",", "Mei\u00b7ne", "Won\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gr\u00fcnt durch Dessen Gnaden-Sonne,", "tokens": ["Gr\u00fcnt", "durch", "Des\u00b7sen", "Gna\u00b7den\u00b7Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird durch Dessen Gunst gehegt,", "tokens": ["Wird", "durch", "Des\u00b7sen", "Gunst", "ge\u00b7hegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Den ihm Brandenburgk gebohren", "tokens": ["Den", "ihm", "Bran\u00b7den\u00b7burgk", "ge\u00b7boh\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und zum F\u00fcrsten-Liecht erkohren,", "tokens": ["Und", "zum", "F\u00fcrs\u00b7ten\u00b7Liecht", "er\u00b7koh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der des Reiches Scepter tr\u00e4gt.", "tokens": ["Der", "des", "Rei\u00b7ches", "Scep\u00b7ter", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Deutschland ist f\u00fcr meinen Orden", "tokens": ["Deutschland", "ist", "f\u00fcr", "mei\u00b7nen", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Jetzt zu Rauch und Asche worden,", "tokens": ["Jetzt", "zu", "Rauch", "und", "A\u00b7sche", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwingt die Kunst, verjagt zu seyn,", "tokens": ["Zwingt", "die", "Kunst", ",", "ver\u00b7jagt", "zu", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hie in Seinem werthen Lande,", "tokens": ["Hie", "in", "Sei\u00b7nem", "wert\u00b7hen", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "An des k\u00fchlen Pregels Rande", "tokens": ["An", "des", "k\u00fch\u00b7len", "Pre\u00b7gels", "Ran\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "R\u00e4umt Er ihr ein Ort noch ein.", "tokens": ["R\u00e4umt", "Er", "ihr", "ein", "Ort", "noch", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Die\u00df Sein K\u00f6nigsberg und Preussen", "tokens": ["Die\u00df", "Sein", "K\u00f6\u00b7nigs\u00b7berg", "und", "Preus\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan der Musen Wohnhau\u00df heissen,", "tokens": ["Kan", "der", "Mu\u00b7sen", "Wohn\u00b7hau\u00df", "heis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seiner Gnaden linder Ost", "tokens": ["Sei\u00b7ner", "Gna\u00b7den", "lin\u00b7der", "Ost"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lesst hie durch ein sanfftes wehen", "tokens": ["Lesst", "hie", "durch", "ein", "sanff\u00b7tes", "we\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unser rechtes Wachsthumb sehen,", "tokens": ["Un\u00b7ser", "rech\u00b7tes", "Wach\u00b7sthumb", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schafft uns Nahrung, H\u00fclff und Trost.", "tokens": ["Schafft", "uns", "Nah\u00b7rung", ",", "H\u00fclff", "und", "Trost", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Hie mu\u00df sich mit sch\u00f6nen Fl\u00fcssen", "tokens": ["Hie", "mu\u00df", "sich", "mit", "sch\u00f6\u00b7nen", "Fl\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Hippocrene selbst ergiessen,", "tokens": ["Hip\u00b7po\u00b7cre\u00b7ne", "selbst", "er\u00b7gies\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein Parna\u00df ragt hie hervor,", "tokens": ["Mein", "Par\u00b7na\u00df", "ragt", "hie", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Hie kan Socrates gebieten,", "tokens": ["Hie", "kan", "So\u00b7cra\u00b7tes", "ge\u00b7bie\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und die Kunst des Stagiriten", "tokens": ["Und", "die", "Kunst", "des", "Sta\u00b7gi\u00b7ri\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hebet hie das Haupt empor.", "tokens": ["He\u00b7bet", "hie", "das", "Haupt", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Plato, Tullius, Euclides,", "tokens": ["Pla\u00b7to", ",", "Tul\u00b7li\u00b7us", ",", "Eu\u00b7cli\u00b7des", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Maro, Flaccus, Aristides,", "tokens": ["Ma\u00b7ro", ",", "Flac\u00b7cus", ",", "A\u00b7ris\u00b7ti\u00b7des", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Und der Artzte F\u00fcrst Galen", "tokens": ["Und", "der", "Artz\u00b7te", "F\u00fcrst", "Ga\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Kriegen hie ein newes Leben,", "tokens": ["Krie\u00b7gen", "hie", "ein", "ne\u00b7wes", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Ja man sieht sich hie erheben", "tokens": ["Ja", "man", "sieht", "sich", "hie", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PIS", "VVFIN", "PRF", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Palestinen, Rom, Athen.", "tokens": ["Pa\u00b7les\u00b7ti\u00b7nen", ",", "Rom", ",", "A\u00b7then", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NE", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.8": {"line.1": {"text": "Nun, f\u00fcr solche Huld und Gnade,", "tokens": ["Nun", ",", "f\u00fcr", "sol\u00b7che", "Huld", "und", "Gna\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die mein Schiff an das Gestade", "tokens": ["Die", "mein", "Schiff", "an", "das", "Ge\u00b7sta\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Aus dem Sturm und Wellen nimpt,", "tokens": ["Aus", "dem", "Sturm", "und", "Wel\u00b7len", "nimpt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird Ihm billich Lob gesungen,", "tokens": ["Wird", "Ihm", "bil\u00b7lich", "Lob", "ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Billich wird von unsrer Zungen", "tokens": ["Bil\u00b7lich", "wird", "von", "uns\u00b7rer", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihm ein Dancklied angestimmt.", "tokens": ["Ihm", "ein", "Danck\u00b7lied", "an\u00b7ge\u00b7stimmt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "La\u00df in Einfalt unsern Willen,", "tokens": ["La\u00df", "in", "Ein\u00b7falt", "un\u00b7sern", "Wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Held, Dir Dein Gem\u00fcte stillen,", "tokens": ["Held", ",", "Dir", "Dein", "Ge\u00b7m\u00fc\u00b7te", "stil\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schaw uns die\u00dffals gn\u00e4digst an:", "tokens": ["Schaw", "uns", "die\u00df\u00b7fals", "gn\u00e4\u00b7digst", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "G\u00f6tter, die schon alles haben,", "tokens": ["G\u00f6t\u00b7ter", ",", "die", "schon", "al\u00b7les", "ha\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADV", "PIS", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sind vergn\u00fcgt mit solchen Gaben,", "tokens": ["Sind", "ver\u00b7gn\u00fcgt", "mit", "sol\u00b7chen", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die das Hertz erzwingen kan.", "tokens": ["Die", "das", "Hertz", "er\u00b7zwin\u00b7gen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Was ist, Clio, dein Beginnen", "tokens": ["Was", "ist", ",", "Clio", ",", "dein", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PWS", "VAFIN", "$,", "NE", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sampt den andern Pierinnen?", "tokens": ["Sampt", "den", "an\u00b7dern", "Pie\u00b7rin\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Was k\u00f6mpt unsern Seiten an?", "tokens": ["Was", "k\u00f6mpt", "un\u00b7sern", "Sei\u00b7ten", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Welcher Held ist, dem zu Ehren", "tokens": ["Wel\u00b7cher", "Held", "ist", ",", "dem", "zu", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAT", "NN", "VAFIN", "$,", "PRELS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ph\u00f6bus sich so scharff lesst h\u00f6ren,", "tokens": ["Ph\u00f6\u00b7bus", "sich", "so", "scharff", "lesst", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "ADV", "ADJD", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und so k\u00fcnstlich als er kan?", "tokens": ["Und", "so", "k\u00fcnst\u00b7lich", "als", "er", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "KOKOM", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Das bist Du, Trost unsrer Zeiten,", "tokens": ["Das", "bist", "Du", ",", "Trost", "uns\u00b7rer", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dich erhebet theils der Seiten,", "tokens": ["Dich", "er\u00b7he\u00b7bet", "theils", "der", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Theils der Stimmen voller Thon,", "tokens": ["Theils", "der", "Stim\u00b7men", "vol\u00b7ler", "Thon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Held Georg, Dir zu gefallen", "tokens": ["Held", "Ge\u00b7org", ",", "Dir", "zu", "ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$,", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Lesset Cynthius erschallen", "tokens": ["Les\u00b7set", "Cyn\u00b7thi\u00b7us", "er\u00b7schal\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["NE", "NE", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Seinen gantzen Helicon.", "tokens": ["Sei\u00b7nen", "gant\u00b7zen", "He\u00b7li\u00b7con", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Mein Lob, sagt er, Meine Wonne", "tokens": ["Mein", "Lob", ",", "sagt", "er", ",", "Mei\u00b7ne", "Won\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gr\u00fcnt durch Dessen Gnaden-Sonne,", "tokens": ["Gr\u00fcnt", "durch", "Des\u00b7sen", "Gna\u00b7den\u00b7Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird durch Dessen Gunst gehegt,", "tokens": ["Wird", "durch", "Des\u00b7sen", "Gunst", "ge\u00b7hegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Den ihm Brandenburgk gebohren", "tokens": ["Den", "ihm", "Bran\u00b7den\u00b7burgk", "ge\u00b7boh\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und zum F\u00fcrsten-Liecht erkohren,", "tokens": ["Und", "zum", "F\u00fcrs\u00b7ten\u00b7Liecht", "er\u00b7koh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der des Reiches Scepter tr\u00e4gt.", "tokens": ["Der", "des", "Rei\u00b7ches", "Scep\u00b7ter", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Deutschland ist f\u00fcr meinen Orden", "tokens": ["Deutschland", "ist", "f\u00fcr", "mei\u00b7nen", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Jetzt zu Rauch und Asche worden,", "tokens": ["Jetzt", "zu", "Rauch", "und", "A\u00b7sche", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwingt die Kunst, verjagt zu seyn,", "tokens": ["Zwingt", "die", "Kunst", ",", "ver\u00b7jagt", "zu", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hie in Seinem werthen Lande,", "tokens": ["Hie", "in", "Sei\u00b7nem", "wert\u00b7hen", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "An des k\u00fchlen Pregels Rande", "tokens": ["An", "des", "k\u00fch\u00b7len", "Pre\u00b7gels", "Ran\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "R\u00e4umt Er ihr ein Ort noch ein.", "tokens": ["R\u00e4umt", "Er", "ihr", "ein", "Ort", "noch", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Die\u00df Sein K\u00f6nigsberg und Preussen", "tokens": ["Die\u00df", "Sein", "K\u00f6\u00b7nigs\u00b7berg", "und", "Preus\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan der Musen Wohnhau\u00df heissen,", "tokens": ["Kan", "der", "Mu\u00b7sen", "Wohn\u00b7hau\u00df", "heis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seiner Gnaden linder Ost", "tokens": ["Sei\u00b7ner", "Gna\u00b7den", "lin\u00b7der", "Ost"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lesst hie durch ein sanfftes wehen", "tokens": ["Lesst", "hie", "durch", "ein", "sanff\u00b7tes", "we\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unser rechtes Wachsthumb sehen,", "tokens": ["Un\u00b7ser", "rech\u00b7tes", "Wach\u00b7sthumb", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schafft uns Nahrung, H\u00fclff und Trost.", "tokens": ["Schafft", "uns", "Nah\u00b7rung", ",", "H\u00fclff", "und", "Trost", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Hie mu\u00df sich mit sch\u00f6nen Fl\u00fcssen", "tokens": ["Hie", "mu\u00df", "sich", "mit", "sch\u00f6\u00b7nen", "Fl\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Hippocrene selbst ergiessen,", "tokens": ["Hip\u00b7po\u00b7cre\u00b7ne", "selbst", "er\u00b7gies\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein Parna\u00df ragt hie hervor,", "tokens": ["Mein", "Par\u00b7na\u00df", "ragt", "hie", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Hie kan Socrates gebieten,", "tokens": ["Hie", "kan", "So\u00b7cra\u00b7tes", "ge\u00b7bie\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und die Kunst des Stagiriten", "tokens": ["Und", "die", "Kunst", "des", "Sta\u00b7gi\u00b7ri\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hebet hie das Haupt empor.", "tokens": ["He\u00b7bet", "hie", "das", "Haupt", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Plato, Tullius, Euclides,", "tokens": ["Pla\u00b7to", ",", "Tul\u00b7li\u00b7us", ",", "Eu\u00b7cli\u00b7des", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Maro, Flaccus, Aristides,", "tokens": ["Ma\u00b7ro", ",", "Flac\u00b7cus", ",", "A\u00b7ris\u00b7ti\u00b7des", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Und der Artzte F\u00fcrst Galen", "tokens": ["Und", "der", "Artz\u00b7te", "F\u00fcrst", "Ga\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Kriegen hie ein newes Leben,", "tokens": ["Krie\u00b7gen", "hie", "ein", "ne\u00b7wes", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Ja man sieht sich hie erheben", "tokens": ["Ja", "man", "sieht", "sich", "hie", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PIS", "VVFIN", "PRF", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Palestinen, Rom, Athen.", "tokens": ["Pa\u00b7les\u00b7ti\u00b7nen", ",", "Rom", ",", "A\u00b7then", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NE", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.17": {"line.1": {"text": "Nun, f\u00fcr solche Huld und Gnade,", "tokens": ["Nun", ",", "f\u00fcr", "sol\u00b7che", "Huld", "und", "Gna\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die mein Schiff an das Gestade", "tokens": ["Die", "mein", "Schiff", "an", "das", "Ge\u00b7sta\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Aus dem Sturm und Wellen nimpt,", "tokens": ["Aus", "dem", "Sturm", "und", "Wel\u00b7len", "nimpt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird Ihm billich Lob gesungen,", "tokens": ["Wird", "Ihm", "bil\u00b7lich", "Lob", "ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Billich wird von unsrer Zungen", "tokens": ["Bil\u00b7lich", "wird", "von", "uns\u00b7rer", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihm ein Dancklied angestimmt.", "tokens": ["Ihm", "ein", "Danck\u00b7lied", "an\u00b7ge\u00b7stimmt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "La\u00df in Einfalt unsern Willen,", "tokens": ["La\u00df", "in", "Ein\u00b7falt", "un\u00b7sern", "Wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Held, Dir Dein Gem\u00fcte stillen,", "tokens": ["Held", ",", "Dir", "Dein", "Ge\u00b7m\u00fc\u00b7te", "stil\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schaw uns die\u00dffals gn\u00e4digst an:", "tokens": ["Schaw", "uns", "die\u00df\u00b7fals", "gn\u00e4\u00b7digst", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "G\u00f6tter, die schon alles haben,", "tokens": ["G\u00f6t\u00b7ter", ",", "die", "schon", "al\u00b7les", "ha\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADV", "PIS", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sind vergn\u00fcgt mit solchen Gaben,", "tokens": ["Sind", "ver\u00b7gn\u00fcgt", "mit", "sol\u00b7chen", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die das Hertz erzwingen kan.", "tokens": ["Die", "das", "Hertz", "er\u00b7zwin\u00b7gen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}