{"textgrid.poem.60635": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: In gr\u00fcnem Lager tr\u00e4umt ein Hase.", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In gr\u00fcnem Lager tr\u00e4umt ein Hase.", "tokens": ["In", "gr\u00fc\u00b7nem", "La\u00b7ger", "tr\u00e4umt", "ein", "Ha\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gewi\u00df, es tr\u00e4umt sich sch\u00f6n im Grase,", "tokens": ["Ge\u00b7wi\u00df", ",", "es", "tr\u00e4umt", "sich", "sch\u00f6n", "im", "Gra\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PRF", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch unsern Hasen qu\u00e4lt es nur.", "tokens": ["Doch", "un\u00b7sern", "Ha\u00b7sen", "qu\u00e4lt", "es", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er lag betr\u00fcbt, von Angst gehetzt,", "tokens": ["Er", "lag", "be\u00b7tr\u00fcbt", ",", "von", "Angst", "ge\u00b7hetzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sinnend sagte er zuletzt:", "tokens": ["Und", "sin\u00b7nend", "sag\u00b7te", "er", "zu\u00b7letzt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbtiere, die furchtsam von Natur,", "tokens": ["\u00bb", "tie\u00b7re", ",", "die", "furcht\u00b7sam", "von", "Na\u00b7tur", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "$,", "PRELS", "ADJD", "APPR", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Unselig sind sie, denn sie wissen", "tokens": ["Un\u00b7se\u00b7lig", "sind", "sie", ",", "denn", "sie", "wis\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "KON", "PPER", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "In Ruh zu essen keinen Bissen.", "tokens": ["In", "Ruh", "zu", "es\u00b7sen", "kei\u00b7nen", "Bis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Nie reine Freude, ewige Hatz \u2013", "tokens": ["Nie", "rei\u00b7ne", "Freu\u00b7de", ",", "e\u00b7wi\u00b7ge", "Hatz", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "So ist mein Leben. Bangigkeit", "tokens": ["So", "ist", "mein", "Le\u00b7ben", ".", "Ban\u00b7gig\u00b7keit"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Treibt fort und fort von Platz zu Platz,", "tokens": ["Treibt", "fort", "und", "fort", "von", "Platz", "zu", "Platz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "PTKVZ", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Da\u00df nicht einmal der Schlaf gedeiht:", "tokens": ["Da\u00df", "nicht", "ein\u00b7mal", "der", "Schlaf", "ge\u00b7deiht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Mit offnen Augen mu\u00df ich liegen.", "tokens": ["Mit", "off\u00b7nen", "Au\u00b7gen", "mu\u00df", "ich", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "\u203aso\u00e4ndre dich,\u2039 vielleicht ein Weiser zu mir spricht.", "tokens": ["\u203a", "so\u00b7\u00e4nd\u00b7re", "dich", ",", "\u2039", "viel\u00b7leicht", "ein", "Wei\u00b7ser", "zu", "mir", "spricht", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "$(", "ADV", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ja, l\u00e4\u00dft sich Furcht denn je besiegen?", "tokens": ["Ja", ",", "l\u00e4\u00dft", "sich", "Furcht", "denn", "je", "be\u00b7sie\u00b7gen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PRF", "NN", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Ich glaub sogar mit Zuversicht,", "tokens": ["Ich", "glaub", "so\u00b7gar", "mit", "Zu\u00b7ver\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Da\u00df selbst die Menschen so dem F\u00fcrchten unterliegen.\u00ab", "tokens": ["Da\u00df", "selbst", "die", "Men\u00b7schen", "so", "dem", "F\u00fcrch\u00b7ten", "un\u00b7ter\u00b7lie\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Also philosophierte unser Hase,", "tokens": ["Al\u00b7so", "phi\u00b7lo\u00b7so\u00b7phier\u00b7te", "un\u00b7ser", "Ha\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.19": {"text": "Stets auf der Wacht mit Aug und Nase.", "tokens": ["Stets", "auf", "der", "Wacht", "mit", "Aug", "und", "Na\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Ein Hauch, ein Schatten l\u00e4\u00dft Gefahr ihn wittern,", "tokens": ["Ein", "Hauch", ",", "ein", "Schat\u00b7ten", "l\u00e4\u00dft", "Ge\u00b7fahr", "ihn", "wit\u00b7tern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Ein Nichts macht ihn erzittern.", "tokens": ["Ein", "Nichts", "macht", "ihn", "er\u00b7zit\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.2": {"line.1": {"text": "Das arme Tier, voll Qual", "tokens": ["Das", "ar\u00b7me", "Tier", ",", "voll", "Qual"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADJD", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Nachh\u00e4ngend diesen Dingen,", "tokens": ["Nach\u00b7h\u00e4n\u00b7gend", "die\u00b7sen", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vernahm ein leis Ger\u00e4usch; das war ihm ein Signal,", "tokens": ["Ver\u00b7nahm", "ein", "leis", "Ge\u00b7r\u00e4usch", ";", "das", "war", "ihm", "ein", "Sig\u00b7nal", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$.", "PDS", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aus dem Versteck emporzuspringen,", "tokens": ["Aus", "dem", "Ver\u00b7steck", "em\u00b7por\u00b7zu\u00b7sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zu fl\u00fcchten bis zum Teich im Tal.", "tokens": ["Zu", "fl\u00fcch\u00b7ten", "bis", "zum", "Teich", "im", "Tal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "APPRART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da! Fr\u00f6sche, die ins Wasser h\u00fcpfen,", "tokens": ["Da", "!", "Fr\u00f6\u00b7sche", ",", "die", "ins", "Was\u00b7ser", "h\u00fcp\u00b7fen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "NN", "$,", "PRELS", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Fr\u00f6sche, die schnell in ihre Grotten schl\u00fcpfen!", "tokens": ["Fr\u00f6\u00b7sche", ",", "die", "schnell", "in", "ih\u00b7re", "Grot\u00b7ten", "schl\u00fcp\u00b7fen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "\u00bboh,\u00ab sprach der Has, \u00bbich richte hier", "tokens": ["\u00bb", "oh", ",", "\u00ab", "sprach", "der", "Has", ",", "\u00bb", "ich", "rich\u00b7te", "hier"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "FM", "$,", "$(", "VVFIN", "ART", "NN", "$,", "$(", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Anrichtet. Meine Gegenwart", "tokens": ["An\u00b7rich\u00b7tet", ".", "Mei\u00b7ne", "Ge\u00b7gen\u00b7wart"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVPP", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Verursacht Schrecken gleicher Art,", "tokens": ["Ver\u00b7ur\u00b7sacht", "Schre\u00b7cken", "glei\u00b7cher", "Art", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Verbreitet Aufruhr weit und breit.", "tokens": ["Ver\u00b7brei\u00b7tet", "Auf\u00b7ruhr", "weit", "und", "breit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wie kommt mir diese Tapferkeit?", "tokens": ["Wie", "kommt", "mir", "die\u00b7se", "Tap\u00b7fer\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Man zittert, fege ich durchs Feld.", "tokens": ["Man", "zit\u00b7tert", ",", "fe\u00b7ge", "ich", "durchs", "Feld", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "So bin ich also doch ein Held!\u00ab", "tokens": ["So", "bin", "ich", "al\u00b7so", "doch", "ein", "Held", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich aber sag zum guten Ende,", "tokens": ["Ich", "a\u00b7ber", "sag", "zum", "gu\u00b7ten", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was ihr wohl selber wi\u00dft:", "tokens": ["Was", "ihr", "wohl", "sel\u00b7ber", "wi\u00dft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kein Feigling, der nicht einen f\u00e4nde,", "tokens": ["Kein", "Feig\u00b7ling", ",", "der", "nicht", "ei\u00b7nen", "f\u00e4n\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "PTKNEG", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der nicht noch feiger ist!", "tokens": ["Der", "nicht", "noch", "fei\u00b7ger", "ist", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "In gr\u00fcnem Lager tr\u00e4umt ein Hase.", "tokens": ["In", "gr\u00fc\u00b7nem", "La\u00b7ger", "tr\u00e4umt", "ein", "Ha\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gewi\u00df, es tr\u00e4umt sich sch\u00f6n im Grase,", "tokens": ["Ge\u00b7wi\u00df", ",", "es", "tr\u00e4umt", "sich", "sch\u00f6n", "im", "Gra\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PRF", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch unsern Hasen qu\u00e4lt es nur.", "tokens": ["Doch", "un\u00b7sern", "Ha\u00b7sen", "qu\u00e4lt", "es", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er lag betr\u00fcbt, von Angst gehetzt,", "tokens": ["Er", "lag", "be\u00b7tr\u00fcbt", ",", "von", "Angst", "ge\u00b7hetzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sinnend sagte er zuletzt:", "tokens": ["Und", "sin\u00b7nend", "sag\u00b7te", "er", "zu\u00b7letzt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbtiere, die furchtsam von Natur,", "tokens": ["\u00bb", "tie\u00b7re", ",", "die", "furcht\u00b7sam", "von", "Na\u00b7tur", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "$,", "PRELS", "ADJD", "APPR", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Unselig sind sie, denn sie wissen", "tokens": ["Un\u00b7se\u00b7lig", "sind", "sie", ",", "denn", "sie", "wis\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "KON", "PPER", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "In Ruh zu essen keinen Bissen.", "tokens": ["In", "Ruh", "zu", "es\u00b7sen", "kei\u00b7nen", "Bis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Nie reine Freude, ewige Hatz \u2013", "tokens": ["Nie", "rei\u00b7ne", "Freu\u00b7de", ",", "e\u00b7wi\u00b7ge", "Hatz", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "So ist mein Leben. Bangigkeit", "tokens": ["So", "ist", "mein", "Le\u00b7ben", ".", "Ban\u00b7gig\u00b7keit"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Treibt fort und fort von Platz zu Platz,", "tokens": ["Treibt", "fort", "und", "fort", "von", "Platz", "zu", "Platz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "PTKVZ", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Da\u00df nicht einmal der Schlaf gedeiht:", "tokens": ["Da\u00df", "nicht", "ein\u00b7mal", "der", "Schlaf", "ge\u00b7deiht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Mit offnen Augen mu\u00df ich liegen.", "tokens": ["Mit", "off\u00b7nen", "Au\u00b7gen", "mu\u00df", "ich", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "\u203aso\u00e4ndre dich,\u2039 vielleicht ein Weiser zu mir spricht.", "tokens": ["\u203a", "so\u00b7\u00e4nd\u00b7re", "dich", ",", "\u2039", "viel\u00b7leicht", "ein", "Wei\u00b7ser", "zu", "mir", "spricht", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "$(", "ADV", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ja, l\u00e4\u00dft sich Furcht denn je besiegen?", "tokens": ["Ja", ",", "l\u00e4\u00dft", "sich", "Furcht", "denn", "je", "be\u00b7sie\u00b7gen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PRF", "NN", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Ich glaub sogar mit Zuversicht,", "tokens": ["Ich", "glaub", "so\u00b7gar", "mit", "Zu\u00b7ver\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Da\u00df selbst die Menschen so dem F\u00fcrchten unterliegen.\u00ab", "tokens": ["Da\u00df", "selbst", "die", "Men\u00b7schen", "so", "dem", "F\u00fcrch\u00b7ten", "un\u00b7ter\u00b7lie\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Also philosophierte unser Hase,", "tokens": ["Al\u00b7so", "phi\u00b7lo\u00b7so\u00b7phier\u00b7te", "un\u00b7ser", "Ha\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.19": {"text": "Stets auf der Wacht mit Aug und Nase.", "tokens": ["Stets", "auf", "der", "Wacht", "mit", "Aug", "und", "Na\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Ein Hauch, ein Schatten l\u00e4\u00dft Gefahr ihn wittern,", "tokens": ["Ein", "Hauch", ",", "ein", "Schat\u00b7ten", "l\u00e4\u00dft", "Ge\u00b7fahr", "ihn", "wit\u00b7tern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Ein Nichts macht ihn erzittern.", "tokens": ["Ein", "Nichts", "macht", "ihn", "er\u00b7zit\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.5": {"line.1": {"text": "Das arme Tier, voll Qual", "tokens": ["Das", "ar\u00b7me", "Tier", ",", "voll", "Qual"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADJD", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Nachh\u00e4ngend diesen Dingen,", "tokens": ["Nach\u00b7h\u00e4n\u00b7gend", "die\u00b7sen", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vernahm ein leis Ger\u00e4usch; das war ihm ein Signal,", "tokens": ["Ver\u00b7nahm", "ein", "leis", "Ge\u00b7r\u00e4usch", ";", "das", "war", "ihm", "ein", "Sig\u00b7nal", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$.", "PDS", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aus dem Versteck emporzuspringen,", "tokens": ["Aus", "dem", "Ver\u00b7steck", "em\u00b7por\u00b7zu\u00b7sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zu fl\u00fcchten bis zum Teich im Tal.", "tokens": ["Zu", "fl\u00fcch\u00b7ten", "bis", "zum", "Teich", "im", "Tal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "APPRART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da! Fr\u00f6sche, die ins Wasser h\u00fcpfen,", "tokens": ["Da", "!", "Fr\u00f6\u00b7sche", ",", "die", "ins", "Was\u00b7ser", "h\u00fcp\u00b7fen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "NN", "$,", "PRELS", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Fr\u00f6sche, die schnell in ihre Grotten schl\u00fcpfen!", "tokens": ["Fr\u00f6\u00b7sche", ",", "die", "schnell", "in", "ih\u00b7re", "Grot\u00b7ten", "schl\u00fcp\u00b7fen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "\u00bboh,\u00ab sprach der Has, \u00bbich richte hier", "tokens": ["\u00bb", "oh", ",", "\u00ab", "sprach", "der", "Has", ",", "\u00bb", "ich", "rich\u00b7te", "hier"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "FM", "$,", "$(", "VVFIN", "ART", "NN", "$,", "$(", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Anrichtet. Meine Gegenwart", "tokens": ["An\u00b7rich\u00b7tet", ".", "Mei\u00b7ne", "Ge\u00b7gen\u00b7wart"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVPP", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Verursacht Schrecken gleicher Art,", "tokens": ["Ver\u00b7ur\u00b7sacht", "Schre\u00b7cken", "glei\u00b7cher", "Art", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Verbreitet Aufruhr weit und breit.", "tokens": ["Ver\u00b7brei\u00b7tet", "Auf\u00b7ruhr", "weit", "und", "breit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wie kommt mir diese Tapferkeit?", "tokens": ["Wie", "kommt", "mir", "die\u00b7se", "Tap\u00b7fer\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Man zittert, fege ich durchs Feld.", "tokens": ["Man", "zit\u00b7tert", ",", "fe\u00b7ge", "ich", "durchs", "Feld", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "So bin ich also doch ein Held!\u00ab", "tokens": ["So", "bin", "ich", "al\u00b7so", "doch", "ein", "Held", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich aber sag zum guten Ende,", "tokens": ["Ich", "a\u00b7ber", "sag", "zum", "gu\u00b7ten", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was ihr wohl selber wi\u00dft:", "tokens": ["Was", "ihr", "wohl", "sel\u00b7ber", "wi\u00dft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kein Feigling, der nicht einen f\u00e4nde,", "tokens": ["Kein", "Feig\u00b7ling", ",", "der", "nicht", "ei\u00b7nen", "f\u00e4n\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "PTKNEG", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der nicht noch feiger ist!", "tokens": ["Der", "nicht", "noch", "fei\u00b7ger", "ist", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}