{"textgrid.poem.66128": {"metadata": {"author": {"name": "Falke, Gustav", "birth": "N.A.", "death": "N.A."}, "title": "In tiefer Scham", "genre": "verse", "period": "N.A.", "pub_year": 1884, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich weinte auf mein Brot und w\u00fcrgte dran", "tokens": ["Ich", "wein\u00b7te", "auf", "mein", "Brot", "und", "w\u00fcrg\u00b7te", "dran"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und konnts nicht w\u00fcrgen und stand auf vom Mahl", "tokens": ["Und", "konnts", "nicht", "w\u00fcr\u00b7gen", "und", "stand", "auf", "vom", "Mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PTKNEG", "VVINF", "KON", "VVFIN", "APPR", "APPRART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und ging hinaus ins kalte, kahle Feld", "tokens": ["Und", "ging", "hin\u00b7aus", "ins", "kal\u00b7te", ",", "kah\u00b7le", "Feld"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und bot dem M\u00e4rzwind meine hei\u00dfe Qual.", "tokens": ["Und", "bot", "dem", "M\u00e4r\u00b7zwind", "mei\u00b7ne", "hei\u00b7\u00dfe", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "An einem Dornbusch hing ein Fetzen Tuch.", "tokens": ["An", "ei\u00b7nem", "Dorn\u00b7busch", "hing", "ein", "Fet\u00b7zen", "Tuch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wer warf es weg, wen w\u00e4rmte es zuletzt?", "tokens": ["Wer", "warf", "es", "weg", ",", "wen", "w\u00e4rm\u00b7te", "es", "zu\u00b7letzt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PTKVZ", "$,", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vielleicht wie er bin ich ein Bettler nun,", "tokens": ["Viel\u00b7leicht", "wie", "er", "bin", "ich", "ein", "Bett\u00b7ler", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "VAFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und was so warm mich hielt, ist ganz zerfetzt.", "tokens": ["Und", "was", "so", "warm", "mich", "hielt", ",", "ist", "ganz", "zer\u00b7fetzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADJD", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wenn du dein Herz in deine H\u00e4nde nimmst", "tokens": ["Wenn", "du", "dein", "Herz", "in", "dei\u00b7ne", "H\u00e4n\u00b7de", "nimmst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und gibst es hin, da, nimms, und ohn Entgelt,", "tokens": ["Und", "gibst", "es", "hin", ",", "da", ",", "nimms", ",", "und", "ohn", "Ent\u00b7gelt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "$,", "ADV", "$,", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Man nimmt es, dankt und wirft dirs pl\u00f6tzlich hin:", "tokens": ["Man", "nimmt", "es", ",", "dankt", "und", "wirft", "dirs", "pl\u00f6tz\u00b7lich", "hin", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$,", "VVFIN", "KON", "VVFIN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich mags nicht mehr! dann stirbt dir eine Welt.", "tokens": ["Ich", "mags", "nicht", "mehr", "!", "dann", "stirbt", "dir", "ei\u00b7ne", "Welt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "$.", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Dann stehst du da, entbl\u00f6\u00dft und bettelarm", "tokens": ["Dann", "stehst", "du", "da", ",", "ent\u00b7bl\u00f6\u00dft", "und", "bet\u00b7tel\u00b7arm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und wei\u00dft nicht hin vor Scham, vor nackter Scham.", "tokens": ["Und", "wei\u00dft", "nicht", "hin", "vor", "Scham", ",", "vor", "nack\u00b7ter", "Scham", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "APPR", "NN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}}, "stanza.5": {"line.1": {"text": "Ich weinte auf mein Brot und w\u00fcrgte dran", "tokens": ["Ich", "wein\u00b7te", "auf", "mein", "Brot", "und", "w\u00fcrg\u00b7te", "dran"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und konnts nicht w\u00fcrgen und stand auf vom Mahl", "tokens": ["Und", "konnts", "nicht", "w\u00fcr\u00b7gen", "und", "stand", "auf", "vom", "Mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PTKNEG", "VVINF", "KON", "VVFIN", "APPR", "APPRART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und ging hinaus ins kalte, kahle Feld", "tokens": ["Und", "ging", "hin\u00b7aus", "ins", "kal\u00b7te", ",", "kah\u00b7le", "Feld"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und bot dem M\u00e4rzwind meine hei\u00dfe Qual.", "tokens": ["Und", "bot", "dem", "M\u00e4r\u00b7zwind", "mei\u00b7ne", "hei\u00b7\u00dfe", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "An einem Dornbusch hing ein Fetzen Tuch.", "tokens": ["An", "ei\u00b7nem", "Dorn\u00b7busch", "hing", "ein", "Fet\u00b7zen", "Tuch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wer warf es weg, wen w\u00e4rmte es zuletzt?", "tokens": ["Wer", "warf", "es", "weg", ",", "wen", "w\u00e4rm\u00b7te", "es", "zu\u00b7letzt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PTKVZ", "$,", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vielleicht wie er bin ich ein Bettler nun,", "tokens": ["Viel\u00b7leicht", "wie", "er", "bin", "ich", "ein", "Bett\u00b7ler", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "VAFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und was so warm mich hielt, ist ganz zerfetzt.", "tokens": ["Und", "was", "so", "warm", "mich", "hielt", ",", "ist", "ganz", "zer\u00b7fetzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADJD", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Wenn du dein Herz in deine H\u00e4nde nimmst", "tokens": ["Wenn", "du", "dein", "Herz", "in", "dei\u00b7ne", "H\u00e4n\u00b7de", "nimmst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und gibst es hin, da, nimms, und ohn Entgelt,", "tokens": ["Und", "gibst", "es", "hin", ",", "da", ",", "nimms", ",", "und", "ohn", "Ent\u00b7gelt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "$,", "ADV", "$,", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Man nimmt es, dankt und wirft dirs pl\u00f6tzlich hin:", "tokens": ["Man", "nimmt", "es", ",", "dankt", "und", "wirft", "dirs", "pl\u00f6tz\u00b7lich", "hin", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$,", "VVFIN", "KON", "VVFIN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich mags nicht mehr! dann stirbt dir eine Welt.", "tokens": ["Ich", "mags", "nicht", "mehr", "!", "dann", "stirbt", "dir", "ei\u00b7ne", "Welt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "$.", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Dann stehst du da, entbl\u00f6\u00dft und bettelarm", "tokens": ["Dann", "stehst", "du", "da", ",", "ent\u00b7bl\u00f6\u00dft", "und", "bet\u00b7tel\u00b7arm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und wei\u00dft nicht hin vor Scham, vor nackter Scham.", "tokens": ["Und", "wei\u00dft", "nicht", "hin", "vor", "Scham", ",", "vor", "nack\u00b7ter", "Scham", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "APPR", "NN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}}}}}