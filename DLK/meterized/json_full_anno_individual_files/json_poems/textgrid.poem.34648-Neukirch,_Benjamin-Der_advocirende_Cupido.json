{"textgrid.poem.34648": {"metadata": {"author": {"name": "Neukirch, Benjamin", "birth": "N.A.", "death": "N.A."}, "title": "Der advocirende Cupido", "genre": "verse", "period": "N.A.", "pub_year": 1697, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als neulich L\u00e4lia vor ihrem spiegel stund/", "tokens": ["Als", "neu\u00b7lich", "L\u00e4\u00b7lia", "vor", "ih\u00b7rem", "spie\u00b7gel", "stund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und bald die augen lie\u00df auff ihre marmel-ballen/", "tokens": ["Und", "bald", "die", "au\u00b7gen", "lie\u00df", "auff", "ih\u00b7re", "mar\u00b7mel\u00b7bal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bald auff der wangen pracht/ und ihren purpur-mund/", "tokens": ["Bald", "auff", "der", "wan\u00b7gen", "pracht", "/", "und", "ih\u00b7ren", "pur\u00b7pur\u00b7mund", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$(", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bald wieder auff den schnee der rundten nase fallen;", "tokens": ["Bald", "wie\u00b7der", "auff", "den", "schnee", "der", "rund\u00b7ten", "na\u00b7se", "fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da warff sie voller zorn den spiegel aus der hand/", "tokens": ["Da", "warff", "sie", "vol\u00b7ler", "zorn", "den", "spie\u00b7gel", "aus", "der", "hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und sprach: Was helffen mich die rosen meiner wangen?", "tokens": ["Und", "sprach", ":", "Was", "helf\u00b7fen", "mich", "die", "ro\u00b7sen", "mei\u00b7ner", "wan\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PWS", "VVFIN", "PPER", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was nutzt der rothe mund? was meiner augen brand?", "tokens": ["Was", "nutzt", "der", "ro\u00b7the", "mund", "?", "was", "mei\u00b7ner", "au\u00b7gen", "brand", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "$.", "PWS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn mund und nase nicht in gleicher zierde prangen.", "tokens": ["Wenn", "mund", "und", "na\u00b7se", "nicht", "in", "glei\u00b7cher", "zier\u00b7de", "pran\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "VVFIN", "PTKNEG", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Geh/ l\u00fcgner/ bilde mir nur keine sch\u00f6nheit ein/", "tokens": ["Geh", "/", "l\u00fcg\u00b7ner", "/", "bil\u00b7de", "mir", "nur", "kei\u00b7ne", "sch\u00f6n\u00b7heit", "ein", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "VVFIN", "PPER", "ADV", "PIAT", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Denn meine nase macht/ da\u00df ich mich mu\u00df betr\u00fcben/", "tokens": ["Denn", "mei\u00b7ne", "na\u00b7se", "macht", "/", "da\u00df", "ich", "mich", "mu\u00df", "be\u00b7tr\u00fc\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$(", "KOUS", "PPER", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Weil heut ein frauen-bild soll nach der mode seyn/", "tokens": ["Weil", "heut", "ein", "frau\u00b7en\u00b7bild", "soll", "nach", "der", "mo\u00b7de", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VMFIN", "APPR", "ART", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und kaum der tausende kan grosse nasen lieben.", "tokens": ["Und", "kaum", "der", "tau\u00b7sen\u00b7de", "kan", "gros\u00b7se", "na\u00b7sen", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "VMFIN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "So klagte L\u00e4lia/ und sanck vor grosser qual", "tokens": ["So", "klag\u00b7te", "L\u00e4\u00b7lia", "/", "und", "san\u00b7ck", "vor", "gros\u00b7ser", "qual"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "$(", "KON", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Auff einen lager-zeug von schwanen-federn nieder.", "tokens": ["Auff", "ei\u00b7nen", "la\u00b7ger\u00b7zeug", "von", "schwa\u00b7nen\u00b7fe\u00b7dern", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Indessen brach der zorn der augen hellen strahl/", "tokens": ["In\u00b7des\u00b7sen", "brach", "der", "zorn", "der", "au\u00b7gen", "hel\u00b7len", "strahl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der eyffer theilte sich durch alle leibes-glieder/", "tokens": ["Der", "eyf\u00b7fer", "theil\u00b7te", "sich", "durch", "al\u00b7le", "lei\u00b7bes\u00b7glie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und endlich fing der mund mit diesen worten an:", "tokens": ["Und", "end\u00b7lich", "fing", "der", "mund", "mit", "die\u00b7sen", "wor\u00b7ten", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "So h\u00f6r ich \u00e4rmster wohl/ wir sollen alle b\u00fcssen/", "tokens": ["So", "h\u00f6r", "ich", "\u00e4rms\u00b7ter", "wohl", "/", "wir", "sol\u00b7len", "al\u00b7le", "b\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADV", "$(", "PPER", "VMFIN", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Da\u00df die natur zu viel an L\u00e4lien gethan/", "tokens": ["Da\u00df", "die", "na\u00b7tur", "zu", "viel", "an", "L\u00e4\u00b7li\u00b7en", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PIS", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und ihr die nase nicht nach frantzen-art gerissen.", "tokens": ["Und", "ihr", "die", "na\u00b7se", "nicht", "nach", "frant\u00b7zen\u00b7art", "ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "PTKNEG", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ich habe l\u00e4ngsten schon der sache nachgedacht/", "tokens": ["Ich", "ha\u00b7be", "l\u00e4ngs\u00b7ten", "schon", "der", "sa\u00b7che", "nach\u00b7ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Warum die k\u00fcsse sich so sparsam eingefunden/", "tokens": ["Wa\u00b7rum", "die", "k\u00fcs\u00b7se", "sich", "so", "spar\u00b7sam", "ein\u00b7ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "VVFIN", "PRF", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "So hat das lumpen-ding/ die nase/ blo\u00df gemacht/", "tokens": ["So", "hat", "das", "lum\u00b7pen\u00b7ding", "/", "die", "na\u00b7se", "/", "blo\u00df", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$(", "ART", "NN", "$(", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Da\u00df mir bey m\u00e4nnern auch ist alle gunst verschwunden.", "tokens": ["Da\u00df", "mir", "bey", "m\u00e4n\u00b7nern", "auch", "ist", "al\u00b7le", "gunst", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "ADV", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Beschimpfftes nasenloch! wie reimt sich nacht und schein?", "tokens": ["Be\u00b7schimpff\u00b7tes", "na\u00b7sen\u00b7loch", "!", "wie", "reimt", "sich", "nacht", "und", "schein", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$.", "PWAV", "VVFIN", "PRF", "NN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Wie schickt sich mist und koth zu purpur und rubinen?", "tokens": ["Wie", "schickt", "sich", "mist", "und", "koth", "zu", "pur\u00b7pur", "und", "ru\u00b7bi\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "ADJD", "KON", "ADJD", "PTKA", "ADJD", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Und dennoch soll dein schlam der liebe zunder seyn/", "tokens": ["Und", "den\u00b7noch", "soll", "dein", "schlam", "der", "lie\u00b7be", "zun\u00b7der", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPOSAT", "VVFIN", "ART", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und L\u00e4lien ihr ruhm aus deinem rotze gr\u00fcnen.", "tokens": ["Und", "L\u00e4\u00b7li\u00b7en", "ihr", "ruhm", "aus", "dei\u00b7nem", "rot\u00b7ze", "gr\u00fc\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPOSAT", "NN", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Er h\u00e4tte noch weit mehr vor eyffer ausgespien/", "tokens": ["Er", "h\u00e4t\u00b7te", "noch", "weit", "mehr", "vor", "eyf\u00b7fer", "aus\u00b7ge\u00b7spi\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADV", "APPR", "NN", "VVIZU", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.30": {"text": "Gleich aber fiengen auch die augen an zu blitzen/", "tokens": ["Gleich", "a\u00b7ber", "fi\u00b7en\u00b7gen", "auch", "die", "au\u00b7gen", "an", "zu", "blit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ADV", "ART", "NN", "APZR", "PTKZU", "VVINF", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Und sprachen: unsre glut soll eisen an sich ziehn/", "tokens": ["Und", "spra\u00b7chen", ":", "uns\u00b7re", "glut", "soll", "ei\u00b7sen", "an", "sich", "ziehn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPOSAT", "NN", "VMFIN", "ADV", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die sonne selber mu\u00df vor unsern flammen schwitzen;", "tokens": ["Die", "son\u00b7ne", "sel\u00b7ber", "mu\u00df", "vor", "un\u00b7sern", "flam\u00b7men", "schwit\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VMFIN", "APPR", "PPOSAT", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und darum haben wir offt thr\u00e4nend angesehn/", "tokens": ["Und", "da\u00b7rum", "ha\u00b7ben", "wir", "offt", "thr\u00e4\u00b7nend", "an\u00b7ge\u00b7sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Warum doch lieb und gunst so selten auff uns blicket?", "tokens": ["Wa\u00b7rum", "doch", "lieb", "und", "gunst", "so", "sel\u00b7ten", "auff", "uns", "bli\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJD", "KON", "ADV", "ADV", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Warum die meisten offt als stumme bilder gehn/", "tokens": ["Wa\u00b7rum", "die", "meis\u00b7ten", "offt", "als", "stum\u00b7me", "bil\u00b7der", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "VVFIN", "ADV", "KOUS", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und mancher flegel kaum das schmale h\u00fctgen r\u00fccket.", "tokens": ["Und", "man\u00b7cher", "fle\u00b7gel", "kaum", "das", "schma\u00b7le", "h\u00fct\u00b7gen", "r\u00fc\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "ART", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Nun aber hat die zeit den knoten auffgel\u00f6st;", "tokens": ["Nun", "a\u00b7ber", "hat", "die", "zeit", "den", "kno\u00b7ten", "auff\u00b7ge\u00b7l\u00f6st", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Denn wie der sonnen-glantz/ wenn wind und wolcken steigen/", "tokens": ["Denn", "wie", "der", "son\u00b7nen\u00b7glantz", "/", "wenn", "wind", "und", "wol\u00b7cken", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "$(", "KOUS", "NE", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Die strahlen nur umsonst aus seinem circkel st\u00f6st/", "tokens": ["Die", "strah\u00b7len", "nur", "um\u00b7sonst", "aus", "sei\u00b7nem", "cir\u00b7ckel", "st\u00f6st", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Und auch bey voller glut kan keinen schimmer zeigen/", "tokens": ["Und", "auch", "bey", "vol\u00b7ler", "glut", "kan", "kei\u00b7nen", "schim\u00b7mer", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "VMFIN", "PIAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "So brennet unser feur auch nur vergebens an:", "tokens": ["So", "bren\u00b7net", "un\u00b7ser", "feur", "auch", "nur", "ver\u00b7ge\u00b7bens", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "So lange L\u00e4lia der nase will erlauben/", "tokens": ["So", "lan\u00b7ge", "L\u00e4\u00b7lia", "der", "na\u00b7se", "will", "er\u00b7lau\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.43": {"text": "Da\u00df sie den freyen lauff uns unterbrechen kan/", "tokens": ["Da\u00df", "sie", "den", "frey\u00b7en", "lauff", "uns", "un\u00b7ter\u00b7bre\u00b7chen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PPER", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Und unsrer sonnen-glut macht licht und flamme rauben.", "tokens": ["Und", "uns\u00b7rer", "son\u00b7nen\u00b7glut", "macht", "licht", "und", "flam\u00b7me", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "NN", "KON", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wolt ihr nun dieses nicht/ was unsre kr\u00e4ffte dr\u00fcckt/", "tokens": ["Wolt", "ihr", "nun", "die\u00b7ses", "nicht", "/", "was", "uns\u00b7re", "kr\u00e4ff\u00b7te", "dr\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PDS", "PTKNEG", "$(", "PWS", "PPOSAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Ihr glieder ingesamt mit eurem schimpffe leiden;", "tokens": ["Ihr", "glie\u00b7der", "in\u00b7ge\u00b7samt", "mit", "eu\u00b7rem", "schimpf\u00b7fe", "lei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "So schafft/ da\u00df L\u00e4lia bald nach dem artzte schickt/", "tokens": ["So", "schafft", "/", "da\u00df", "L\u00e4\u00b7lia", "bald", "nach", "dem", "artz\u00b7te", "schickt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "KOUS", "NE", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.48": {"text": "Und ihr das dritte theil l\u00e4st von der nase schneiden.", "tokens": ["Und", "ihr", "das", "drit\u00b7te", "theil", "l\u00e4st", "von", "der", "na\u00b7se", "schnei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Ha possen! fielen hier die wangen ihnen ein/", "tokens": ["Ha", "pos\u00b7sen", "!", "fie\u00b7len", "hier", "die", "wan\u00b7gen", "ih\u00b7nen", "ein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVINF", "$.", "VVFIN", "ADV", "ART", "NN", "PPER", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Da\u00df unser fr\u00fchlings-feld soll vor der zeit erbleichen/", "tokens": ["Da\u00df", "un\u00b7ser", "fr\u00fch\u00b7lings\u00b7feld", "soll", "vor", "der", "zeit", "er\u00b7blei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Da\u00df thau und zucker nicht vor unsre rosen seyn/", "tokens": ["Da\u00df", "thau", "und", "zu\u00b7cker", "nicht", "vor", "uns\u00b7re", "ro\u00b7sen", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "KON", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Und uns die liebe nicht will sanffte pflaumen streichen/", "tokens": ["Und", "uns", "die", "lie\u00b7be", "nicht", "will", "sanff\u00b7te", "pflau\u00b7men", "strei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "VVFIN", "PTKNEG", "VMFIN", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Giebt eurem schmertze wohl/ ihr augen/ wenig nach;", "tokens": ["Giebt", "eu\u00b7rem", "schmert\u00b7ze", "wohl", "/", "ihr", "au\u00b7gen", "/", "we\u00b7nig", "nach", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "VVFIN", "ADV", "$(", "PPOSAT", "NN", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Da\u00df aber L\u00e4lia soll euren rath vollstrecken/", "tokens": ["Da\u00df", "a\u00b7ber", "L\u00e4\u00b7lia", "soll", "eu\u00b7ren", "rath", "voll\u00b7stre\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.55": {"text": "Wird ihrer marmel-haut nur wieder fleck und schmach/", "tokens": ["Wird", "ih\u00b7rer", "mar\u00b7mel\u00b7haut", "nur", "wie\u00b7der", "fleck", "und", "schmach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "ADV", "PTKVZ", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Uns aber allerseits nur neuen schimpff erwecken;", "tokens": ["Uns", "a\u00b7ber", "al\u00b7ler\u00b7seits", "nur", "neu\u00b7en", "schimpff", "er\u00b7we\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Aus wunden/ schnitt und blut qvillt warlich schlechte cur;", "tokens": ["Aus", "wun\u00b7den", "/", "schnitt", "und", "blut", "qvillt", "war\u00b7lich", "schlech\u00b7te", "cur", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$(", "VVFIN", "KON", "NN", "VVFIN", "ADV", "VVFIN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Ein artzt ist nicht genug hier mittel auszutheilen;", "tokens": ["Ein", "artzt", "ist", "nicht", "ge\u00b7nug", "hier", "mit\u00b7tel", "aus\u00b7zu\u00b7thei\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "PTKNEG", "ADV", "ADV", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Denn grosse nasen sind ein fehler der natur/", "tokens": ["Denn", "gros\u00b7se", "na\u00b7sen", "sind", "ein", "feh\u00b7ler", "der", "na\u00b7tur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Und lassen sich nicht so/ wie junge k\u00e4lber/ heilen.", "tokens": ["Und", "las\u00b7sen", "sich", "nicht", "so", "/", "wie", "jun\u00b7ge", "k\u00e4l\u00b7ber", "/", "hei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKNEG", "ADV", "$(", "KOKOM", "ADJA", "NN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Wohlan! versetzte drauff die auffgeschwellte brust/", "tokens": ["Wo\u00b7hlan", "!", "ver\u00b7setz\u00b7te", "drauff", "die", "auff\u00b7ge\u00b7schwell\u00b7te", "brust", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "PAV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "So mu\u00df man gleichwohl auch ein mittel ausersinnen;", "tokens": ["So", "mu\u00df", "man", "gleich\u00b7wohl", "auch", "ein", "mit\u00b7tel", "aus\u00b7er\u00b7sin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Denn da\u00df mein zucker-ei\u00df soll ohne brand und lust/", "tokens": ["Denn", "da\u00df", "mein", "zu\u00b7cke\u00b7rei\u00df", "soll", "oh\u00b7ne", "brand", "und", "lust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "VMFIN", "APPR", "NN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Und dieser perlen-schnee ohn alle glut zerrinnen/", "tokens": ["Und", "die\u00b7ser", "per\u00b7len\u00b7schnee", "ohn", "al\u00b7le", "glut", "zer\u00b7rin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Will mir und meiner haut noch keines weges ein.", "tokens": ["Will", "mir", "und", "mei\u00b7ner", "haut", "noch", "kei\u00b7nes", "we\u00b7ges", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KON", "PPOSAT", "VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Ein berg mu\u00df seine krafft aus thau und sonne saugen/", "tokens": ["Ein", "berg", "mu\u00df", "sei\u00b7ne", "krafft", "aus", "thau", "und", "son\u00b7ne", "sau\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPOSAT", "NN", "APPR", "NE", "KON", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Ein sch\u00f6ner garten mu\u00df stets voller h\u00e4nde seyn/", "tokens": ["Ein", "sch\u00f6\u00b7ner", "gar\u00b7ten", "mu\u00df", "stets", "vol\u00b7ler", "h\u00e4n\u00b7de", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "VMFIN", "ADV", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Und \u00e4pffel/ die nur bl\u00fchn/ und nicht zu brechen taugen/", "tokens": ["Und", "\u00e4pf\u00b7fel", "/", "die", "nur", "bl\u00fchn", "/", "und", "nicht", "zu", "bre\u00b7chen", "tau\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$(", "PRELS", "ADV", "VVINF", "$(", "KON", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Sind keiner augen werth. Ist nun mein liebes-feld", "tokens": ["Sind", "kei\u00b7ner", "au\u00b7gen", "werth", ".", "Ist", "nun", "mein", "lie\u00b7bes\u00b7feld"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "ADJD", "$.", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "So/ wie ihr alle wi\u00dft/ mit bergen zu vergleichen/", "tokens": ["So", "/", "wie", "ihr", "al\u00b7le", "wi\u00dft", "/", "mit", "ber\u00b7gen", "zu", "ver\u00b7glei\u00b7chen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "PWAV", "PPER", "PIS", "VVFIN", "$(", "APPR", "VVINF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Wo schwimmt der balsam-thau/ der ihre krafft erh\u00e4lt?", "tokens": ["Wo", "schwimmt", "der", "bal\u00b7sam\u00b7\u00b7thau", "/", "der", "ih\u00b7re", "krafft", "er\u00b7h\u00e4lt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Wo l\u00e4st mein sonnenschein die s\u00fcsse strahlen streichen?", "tokens": ["Wo", "l\u00e4st", "mein", "son\u00b7nen\u00b7schein", "die", "s\u00fcs\u00b7se", "strah\u00b7len", "strei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Sind meine fr\u00fcchte reiff? wo bleibt die edle hand?", "tokens": ["Sind", "mei\u00b7ne", "fr\u00fcch\u00b7te", "reiff", "?", "wo", "bleibt", "die", "ed\u00b7le", "hand", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "VVFIN", "$.", "PWAV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Dir mir den zucker soll von meinen \u00e4pffeln lesen/", "tokens": ["Dir", "mir", "den", "zu\u00b7cker", "soll", "von", "mei\u00b7nen", "\u00e4pf\u00b7feln", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ART", "NN", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Und zeigen/ da\u00df mein grund nicht ausgedorrter sand/", "tokens": ["Und", "zei\u00b7gen", "/", "da\u00df", "mein", "grund", "nicht", "aus\u00b7ge\u00b7dorr\u00b7ter", "sand", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "KOUS", "PPOSAT", "NN", "PTKNEG", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Und meine spitzen nicht von stein und holtz gewesen?", "tokens": ["Und", "mei\u00b7ne", "spit\u00b7zen", "nicht", "von", "stein", "und", "holtz", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKNEG", "APPR", "ADJD", "KON", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Ich schwere bey der krafft/ die dieser purpur f\u00fchrt/", "tokens": ["Ich", "schwe\u00b7re", "bey", "der", "krafft", "/", "die", "die\u00b7ser", "pur\u00b7pur", "f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$(", "ART", "PDAT", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Und solt ich einen gleich aus Engelland verschreiben/", "tokens": ["Und", "solt", "ich", "ei\u00b7nen", "gleich", "aus", "En\u00b7gel\u00b7land", "ver\u00b7schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "ADV", "APPR", "NE", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Da\u00df doch ein garten eh' von h\u00e4nden unber\u00fchrt/", "tokens": ["Da\u00df", "doch", "ein", "gar\u00b7ten", "eh'", "von", "h\u00e4n\u00b7den", "un\u00b7be\u00b7r\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Als meine liebes-frucht soll ungebrochen bleiben.", "tokens": ["Als", "mei\u00b7ne", "lie\u00b7bes\u00b7frucht", "soll", "un\u00b7ge\u00b7bro\u00b7chen", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Doch weil der schaden hier mich nicht alleine trifft/", "tokens": ["Doch", "weil", "der", "scha\u00b7den", "hier", "mich", "nicht", "al\u00b7lei\u00b7ne", "trifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "ADV", "PPER", "PTKNEG", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "So hab ich dieses nur euch allen vorzutragen/", "tokens": ["So", "hab", "ich", "die\u00b7ses", "nur", "euch", "al\u00b7len", "vor\u00b7zu\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "ADV", "PPER", "PIS", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Da\u00df unser gantzer wunsch auff tr\u00fcbem sande schifft/", "tokens": ["Da\u00df", "un\u00b7ser", "gant\u00b7zer", "wunsch", "auff", "tr\u00fc\u00b7bem", "san\u00b7de", "schifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Wo wir die nase nicht beym Jupiter verklagen.", "tokens": ["Wo", "wir", "die", "na\u00b7se", "nicht", "beym", "Ju\u00b7pi\u00b7ter", "ver\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "PTKNEG", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.85": {"text": "Eh! nicht beym Jupiter/ bey leibe/ sprach der mund:", "tokens": ["Eh", "!", "nicht", "beym", "Ju\u00b7pi\u00b7ter", "/", "bey", "lei\u00b7be", "/", "sprach", "der", "mund", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PTKNEG", "APPRART", "NN", "$(", "APPR", "VVFIN", "$(", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.86": {"text": "Verliebte k\u00f6nnen nicht von liebes-fehlern richten;", "tokens": ["Ver\u00b7lieb\u00b7te", "k\u00f6n\u00b7nen", "nicht", "von", "lie\u00b7bes\u00b7feh\u00b7lern", "rich\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PTKNEG", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Die liebe Jupiters ist allenthalben kund/", "tokens": ["Die", "lie\u00b7be", "Ju\u00b7pi\u00b7ters", "ist", "al\u00b7len\u00b7thal\u00b7ben", "kund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Wie soll sein blinder geist denn unsre h\u00e4ndel schlichten?", "tokens": ["Wie", "soll", "sein", "blin\u00b7der", "geist", "denn", "uns\u00b7re", "h\u00e4n\u00b7del", "schlich\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPOSAT", "ADJA", "NN", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "So soll Apollo denn hierinnen richter seyn/", "tokens": ["So", "soll", "A\u00b7pol\u00b7lo", "denn", "hie\u00b7rin\u00b7nen", "rich\u00b7ter", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "KON", "PAV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Erwiederte die brust: denn klugheit/ recht und leben/", "tokens": ["Er\u00b7wie\u00b7der\u00b7te", "die", "brust", ":", "denn", "klug\u00b7heit", "/", "recht", "und", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "KON", "NN", "$(", "ADJD", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Di\u00df alles trifft bey ihm in gleicher wagen ein/", "tokens": ["Di\u00df", "al\u00b7les", "trifft", "bey", "ihm", "in", "glei\u00b7cher", "wa\u00b7gen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "APPR", "PPER", "APPR", "ADJA", "VVFIN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Und wird nach seiner art den besten ausschlag geben.", "tokens": ["Und", "wird", "nach", "sei\u00b7ner", "art", "den", "bes\u00b7ten", "aus\u00b7schlag", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Hier fielen sie der brust mit vollen stimmen bey:", "tokens": ["Hier", "fie\u00b7len", "sie", "der", "brust", "mit", "vol\u00b7len", "stim\u00b7men", "bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ADJA", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Wer aber/ fiengen bald die augen an zu fragen/", "tokens": ["Wer", "a\u00b7ber", "/", "fi\u00b7en\u00b7gen", "bald", "die", "au\u00b7gen", "an", "zu", "fra\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$(", "VVFIN", "ADV", "ART", "NN", "APZR", "PTKZU", "VVINF", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.95": {"text": "Tritt unter uns hervor/ der am bequemsten sey/", "tokens": ["Tritt", "un\u00b7ter", "uns", "her\u00b7vor", "/", "der", "am", "be\u00b7quems\u00b7ten", "sey", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "PTKVZ", "$(", "ART", "APPRART", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Die klage f\u00f6rmiglich dem richter vorzutragen?", "tokens": ["Die", "kla\u00b7ge", "f\u00f6r\u00b7mig\u00b7lich", "dem", "rich\u00b7ter", "vor\u00b7zu\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "ART", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Ich/ sprach der bleiche mund; denn weil mein corallin", "tokens": ["Ich", "/", "sprach", "der", "blei\u00b7che", "mund", ";", "denn", "weil", "mein", "co\u00b7ral\u00b7lin"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$(", "VVFIN", "ART", "ADJA", "NN", "$.", "KON", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Vor grosser hitze fast in st\u00fccke will zerspringen/", "tokens": ["Vor", "gros\u00b7ser", "hit\u00b7ze", "fast", "in", "st\u00fc\u00b7cke", "will", "zer\u00b7sprin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "APPR", "VVFIN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "So werd ich desto mehr mit reden mich bem\u00fchn/", "tokens": ["So", "werd", "ich", "des\u00b7to", "mehr", "mit", "re\u00b7den", "mich", "be\u00b7m\u00fchn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "APPR", "VVFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Und bey dem richter scharff auff frische k\u00fchlung dringen.", "tokens": ["Und", "bey", "dem", "rich\u00b7ter", "scharff", "auff", "fri\u00b7sche", "k\u00fch\u00b7lung", "drin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "VVFIN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Es sey drum/ huben drauff die wangen wieder an/", "tokens": ["Es", "sey", "drum", "/", "hu\u00b7ben", "drauff", "die", "wan\u00b7gen", "wie\u00b7der", "an", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "$(", "VVFIN", "PAV", "ART", "NN", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Vergi\u00df nur aber nicht den schaden einzuschliessen/", "tokens": ["Ver\u00b7gi\u00df", "nur", "a\u00b7ber", "nicht", "den", "scha\u00b7den", "ein\u00b7zu\u00b7schlies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "PTKNEG", "ART", "ADJA", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Den uns das plumpe loch der nasen angethan/", "tokens": ["Den", "uns", "das", "plum\u00b7pe", "loch", "der", "na\u00b7sen", "an\u00b7ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Und unsre liljen noch mit ihrem schimpffe b\u00fcssen.", "tokens": ["Und", "uns\u00b7re", "lil\u00b7jen", "noch", "mit", "ih\u00b7rem", "schimpf\u00b7fe", "b\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Was unsrer sonnen-glantz vor grosse wunder schafft/", "tokens": ["Was", "uns\u00b7rer", "son\u00b7nen\u00b7glantz", "vor", "gros\u00b7se", "wun\u00b7der", "schafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Das weist du selber wol/ versetzten hier die augen:", "tokens": ["Das", "weist", "du", "sel\u00b7ber", "wol", "/", "ver\u00b7setz\u00b7ten", "hier", "die", "au\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "$(", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Denn ein verliebter geist mu\u00df seine lebens-krafft/", "tokens": ["Denn", "ein", "ver\u00b7lieb\u00b7ter", "geist", "mu\u00df", "sei\u00b7ne", "le\u00b7bens\u00b7krafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VMFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Und seiner flammen oel aus diesen ampeln saugen.", "tokens": ["Und", "sei\u00b7ner", "flam\u00b7men", "o\u00b7el", "aus", "die\u00b7sen", "am\u00b7peln", "sau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+--+-+--++-", "measure": "iambic.hexa.relaxed"}, "line.109": {"text": "Drum pr\u00e4ge dir den punct vor allen dingen ein/", "tokens": ["Drum", "pr\u00e4\u00b7ge", "dir", "den", "punct", "vor", "al\u00b7len", "din\u00b7gen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "VVFIN", "APPR", "PIAT", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Da\u00df wir nur todten blitz aus unserm himmel schiessen/", "tokens": ["Da\u00df", "wir", "nur", "tod\u00b7ten", "blitz", "aus", "un\u00b7serm", "him\u00b7mel", "schies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "So lange die natur nicht L\u00e4lien befreyn/", "tokens": ["So", "lan\u00b7ge", "die", "na\u00b7tur", "nicht", "L\u00e4\u00b7li\u00b7en", "be\u00b7freyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PTKNEG", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Und ihr die nase mu\u00df in andre formen giessen.", "tokens": ["Und", "ihr", "die", "na\u00b7se", "mu\u00df", "in", "and\u00b7re", "for\u00b7men", "gies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VMFIN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Ha! sprach die sch\u00f6ne brust/ h\u00e4lt dieses auch nicht platz/", "tokens": ["Ha", "!", "sprach", "die", "sch\u00f6\u00b7ne", "brust", "/", "h\u00e4lt", "die\u00b7ses", "auch", "nicht", "platz", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "ART", "ADJA", "NN", "$(", "VVFIN", "PDS", "ADV", "PTKNEG", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "So wird mein marmel-blick doch deine zunge sch\u00e4rffen;", "tokens": ["So", "wird", "mein", "mar\u00b7mel\u00b7blick", "doch", "dei\u00b7ne", "zun\u00b7ge", "sch\u00e4rf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Denn wo di\u00df paradie\u00df/ wo dieser garten-schatz", "tokens": ["Denn", "wo", "di\u00df", "pa\u00b7ra\u00b7die\u00df", "/", "wo", "die\u00b7ser", "gar\u00b7ten\u00b7schatz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWAV", "PDS", "VVFIN", "$(", "PWAV", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Die lebens-fr\u00fcchte soll der s\u00e4ulung unterwerffen/", "tokens": ["Die", "le\u00b7bens\u00b7fr\u00fcch\u00b7te", "soll", "der", "s\u00e4u\u00b7lung", "un\u00b7ter\u00b7werf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "So m\u00f6gt ihr auch nur bald nach eurem grabe gehn.", "tokens": ["So", "m\u00f6gt", "ihr", "auch", "nur", "bald", "nach", "eu\u00b7rem", "gra\u00b7be", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Denn was der strenge blitz der muschel-runden augen/", "tokens": ["Denn", "was", "der", "stren\u00b7ge", "blitz", "der", "mu\u00b7schel\u00b7run\u00b7den", "au\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Was mund und wange hei\u00dft in tausend flammen stehn/", "tokens": ["Was", "mund", "und", "wan\u00b7ge", "hei\u00dft", "in", "tau\u00b7send", "flam\u00b7men", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "NN", "VVFIN", "APPR", "CARD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Mu\u00df wieder perlen-milch aus diesen \u00e4pffeln saugen.", "tokens": ["Mu\u00df", "wie\u00b7der", "per\u00b7len\u00b7milch", "aus", "die\u00b7sen", "\u00e4pf\u00b7feln", "sau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "APPR", "PDAT", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Ich brauche/ sprach der mund/ so vieler lehren nicht.", "tokens": ["Ich", "brau\u00b7che", "/", "sprach", "der", "mund", "/", "so", "vie\u00b7ler", "leh\u00b7ren", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "ART", "NN", "$(", "ADV", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Schickt nur zum richter hin/ und last die nase laden;", "tokens": ["Schickt", "nur", "zum", "rich\u00b7ter", "hin", "/", "und", "last", "die", "na\u00b7se", "la\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$(", "KON", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Denn red ich \u00e4rmster nicht nach meiner schuld und pflicht/", "tokens": ["Denn", "red", "ich", "\u00e4rms\u00b7ter", "nicht", "nach", "mei\u00b7ner", "schuld", "und", "pflicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKNEG", "APPR", "PPOSAT", "ADJD", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "So wird der ausgang mir am allermeisten schaden.", "tokens": ["So", "wird", "der", "aus\u00b7gang", "mir", "am", "al\u00b7ler\u00b7meis\u00b7ten", "scha\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "VVFIN", "PPER", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Drauff ward den augenblick das ruder fortger\u00fcckt/", "tokens": ["Drauff", "ward", "den", "au\u00b7gen\u00b7blick", "das", "ru\u00b7der", "fort\u00b7ge\u00b7r\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Und das erz\u00f6rnte schiff in freye see getrieben;", "tokens": ["Und", "das", "er\u00b7z\u00f6rn\u00b7te", "schiff", "in", "frey\u00b7e", "see", "ge\u00b7trie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VVFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Apollo nahm es an. Die nase ward beschickt/", "tokens": ["A\u00b7pol\u00b7lo", "nahm", "es", "an", ".", "Die", "na\u00b7se", "ward", "be\u00b7schickt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Und eine tagefarth zum klagen ausgeschrieben.", "tokens": ["Und", "ei\u00b7ne", "ta\u00b7ge\u00b7farth", "zum", "kla\u00b7gen", "aus\u00b7ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Als nun der liebe tag nach vieler angst erschien/", "tokens": ["Als", "nun", "der", "lie\u00b7be", "tag", "nach", "vie\u00b7ler", "angst", "er\u00b7schien", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Und schon Apollo war auff seinen thron gestiegen/", "tokens": ["Und", "schon", "A\u00b7pol\u00b7lo", "war", "auff", "sei\u00b7nen", "thron", "ge\u00b7stie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Von dem hier diamant/ dort jaspis und rubin", "tokens": ["Von", "dem", "hier", "di\u00b7a\u00b7mant", "/", "dort", "jas\u00b7pis", "und", "ru\u00b7bin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "ADJD", "$(", "ADV", "ADJD", "KON", "NE"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.132": {"text": "Auff das gesamte volck lie\u00df tausend blicke fliegen:", "tokens": ["Auff", "das", "ge\u00b7sam\u00b7te", "volck", "lie\u00df", "tau\u00b7send", "bli\u00b7cke", "flie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "ADJD", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Als/ sag' ich/ sich nunmehr die kl\u00e4ger eingestellt/", "tokens": ["Als", "/", "sag'", "ich", "/", "sich", "nun\u00b7mehr", "die", "kl\u00e4\u00b7ger", "ein\u00b7ge\u00b7stellt", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "VVFIN", "PPER", "$(", "PRF", "ADV", "ART", "ADJA", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Kam endlich auch zuletzt die nase vorgetreten/", "tokens": ["Kam", "end\u00b7lich", "auch", "zu\u00b7letzt", "die", "na\u00b7se", "vor\u00b7ge\u00b7tre\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Und hatt' ihr/ weil ein weib im reden leicht verf\u00e4llt/", "tokens": ["Und", "hatt'", "ihr", "/", "weil", "ein", "weib", "im", "re\u00b7den", "leicht", "ver\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "$(", "KOUS", "ART", "NN", "APPRART", "VVINF", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Der Venus kleinen sohn zum beystand auserbeten.", "tokens": ["Der", "Ve\u00b7nus", "klei\u00b7nen", "sohn", "zum", "beys\u00b7tand", "au\u00b7ser\u00b7be\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPRART", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Sein leib war diesesmahl mit sammet angelegt/", "tokens": ["Sein", "leib", "war", "die\u00b7ses\u00b7mahl", "mit", "sam\u00b7met", "an\u00b7ge\u00b7legt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "APPR", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Die hand trug buch und schrifft vor k\u00f6cher/ pfeil und bogen/", "tokens": ["Die", "hand", "trug", "buch", "und", "schrifft", "vor", "k\u00f6\u00b7cher", "/", "pfeil", "und", "bo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "VVFIN", "APPR", "ADJA", "$(", "VVIMP", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "Auff jenes war das bild der mutter abgepr\u00e4gt/", "tokens": ["Auff", "je\u00b7nes", "war", "das", "bild", "der", "mut\u00b7ter", "ab\u00b7ge\u00b7pr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.140": {"text": "Und dieses war zur pracht mit scharlach \u00fcberzogen.", "tokens": ["Und", "die\u00b7ses", "war", "zur", "pracht", "mit", "schar\u00b7lach", "\u00fc\u00b7berz\u00b7o\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "APPRART", "NN", "APPR", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Als dieses auch geschehn/ da trat der mund herf\u00fcr/", "tokens": ["Als", "die\u00b7ses", "auch", "ge\u00b7schehn", "/", "da", "trat", "der", "mund", "her\u00b7f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "VVPP", "$(", "ADV", "VVFIN", "ART", "NN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "Und brachte voller zorn sein eyfriges verlangen", "tokens": ["Und", "brach\u00b7te", "vol\u00b7ler", "zorn", "sein", "ey\u00b7fri\u00b7ges", "ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJA", "NN", "PPOSAT", "ADJA", "VVINF"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.143": {"text": "Mit diesen worten an: Gerechter f\u00fcrst/ vor dir", "tokens": ["Mit", "die\u00b7sen", "wor\u00b7ten", "an", ":", "Ge\u00b7rech\u00b7ter", "f\u00fcrst", "/", "vor", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PDAT", "NN", "PTKVZ", "$.", "NN", "ADV", "$(", "APPR", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "Erscheinen wir anitzt/ mund/ auge/ brust und wangen/", "tokens": ["Er\u00b7schei\u00b7nen", "wir", "a\u00b7nitzt", "/", "mund", "/", "au\u00b7ge", "/", "brust", "und", "wan\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$(", "NN", "$(", "NN", "$(", "VVFIN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Und klagen ingesammt: Was massen die natur/", "tokens": ["Und", "kla\u00b7gen", "in\u00b7ge\u00b7sammt", ":", "Was", "mas\u00b7sen", "die", "na\u00b7tur", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "PWS", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Als sie der L\u00e4lien die geister eingegossen/", "tokens": ["Als", "sie", "der", "L\u00e4\u00b7li\u00b7en", "die", "geis\u00b7ter", "ein\u00b7ge\u00b7gos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Und milch und honigseim in ihre lippen fuhr/", "tokens": ["Und", "milch", "und", "ho\u00b7ni\u00b7gseim", "in", "ih\u00b7re", "lip\u00b7pen", "fuhr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "Zwar endlich ihren leib mit grosser kunst geschlossen;", "tokens": ["Zwar", "end\u00b7lich", "ih\u00b7ren", "leib", "mit", "gros\u00b7ser", "kunst", "ge\u00b7schlos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Als aber nach der zeit die glieder sich gestreckt/", "tokens": ["Als", "a\u00b7ber", "nach", "der", "zeit", "die", "glie\u00b7der", "sich", "ge\u00b7streckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "ART", "NN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Hat sich die nase dort ie mehr und mehr erhoben/", "tokens": ["Hat", "sich", "die", "na\u00b7se", "dort", "ie", "mehr", "und", "mehr", "er\u00b7ho\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ART", "NN", "ADV", "ADV", "ADV", "KON", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Bi\u00df sie der augen licht/ wie nebel/ \u00fcberdeckt/", "tokens": ["Bi\u00df", "sie", "der", "au\u00b7gen", "licht", "/", "wie", "ne\u00b7bel", "/", "\u00fc\u00b7berd\u00b7eckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "$(", "KOKOM", "NE", "$(", "VVPP", "$("], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.152": {"text": "Und wie ein fichten-baum in kurtzem auffgeschoben.", "tokens": ["Und", "wie", "ein", "fich\u00b7ten\u00b7baum", "in", "kurt\u00b7zem", "auff\u00b7ge\u00b7scho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "APPR", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Wann dann nun scheinbar ist/ da\u00df diese frevel-that", "tokens": ["Wann", "dann", "nun", "schein\u00b7bar", "ist", "/", "da\u00df", "die\u00b7se", "fre\u00b7vel\u00b7that"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "ADJD", "VAFIN", "$(", "KOUS", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Uns allen bey der welt zum schimpffe mu\u00df gereichen/", "tokens": ["Uns", "al\u00b7len", "bey", "der", "welt", "zum", "schimpf\u00b7fe", "mu\u00df", "ge\u00b7rei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "APPR", "ART", "NN", "APPRART", "VVFIN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Indem mein carmasin sich fast verfinstert hat/", "tokens": ["In\u00b7dem", "mein", "car\u00b7ma\u00b7sin", "sich", "fast", "ver\u00b7fins\u00b7tert", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "Und meiner rosen blut vor kummer will erbleichen;", "tokens": ["Und", "mei\u00b7ner", "ro\u00b7sen", "blut", "vor", "kum\u00b7mer", "will", "er\u00b7blei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "APPR", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "Indem der augen blitz vergebens sich bem\u00fcht", "tokens": ["In\u00b7dem", "der", "au\u00b7gen", "blitz", "ver\u00b7ge\u00b7bens", "sich", "be\u00b7m\u00fcht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVIMP", "ADV", "PRF", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Durch strahlen reiner gunst ein treues hertz zu fangen;", "tokens": ["Durch", "strah\u00b7len", "rei\u00b7ner", "gunst", "ein", "treu\u00b7es", "hertz", "zu", "fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Der purpur nur umsonst auff beyden wangen bl\u00fcht/", "tokens": ["Der", "pur\u00b7pur", "nur", "um\u00b7sonst", "auff", "bey\u00b7den", "wan\u00b7gen", "bl\u00fcht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Und schon die br\u00fcste selbst mit leerem k\u00f6cher prangen;", "tokens": ["Und", "schon", "die", "br\u00fcs\u00b7te", "selbst", "mit", "lee\u00b7rem", "k\u00f6\u00b7cher", "pran\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Indem wir/ kurtz gesagt/ der m\u00e4nner lust-spiel seyn/", "tokens": ["In\u00b7dem", "wir", "/", "kurtz", "ge\u00b7sagt", "/", "der", "m\u00e4n\u00b7ner", "lust\u00b7spiel", "seyn", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "ADJD", "VVPP", "$(", "ART", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Und tausendfachen schimpff/ auch sonder ursach/ leiden/", "tokens": ["Und", "tau\u00b7send\u00b7fa\u00b7chen", "schimpff", "/", "auch", "son\u00b7der", "ur\u00b7sach", "/", "lei\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$(", "ADV", "ADV", "ADJD", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "Wenn sie nach ihrer art uns \u00fcberall beschreyn/", "tokens": ["Wenn", "sie", "nach", "ih\u00b7rer", "art", "uns", "\u00fc\u00b7be\u00b7rall", "be\u00b7schreyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Man k\u00f6nte speck und wurst von unsrer nase schneiden:", "tokens": ["Man", "k\u00f6n\u00b7te", "speck", "und", "wurst", "von", "uns\u00b7rer", "na\u00b7se", "schnei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "NE", "KON", "VAFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Als suchen wir bey dir/ Apollo/ schutz und rath/", "tokens": ["Als", "su\u00b7chen", "wir", "bey", "dir", "/", "A\u00b7pol\u00b7lo", "/", "schutz", "und", "rath", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPR", "PPER", "$(", "NE", "$(", "ADJD", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "Und bitten ingesammt/ in rechten auszusprechen/", "tokens": ["Und", "bit\u00b7ten", "in\u00b7ge\u00b7sammt", "/", "in", "rech\u00b7ten", "aus\u00b7zu\u00b7spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$(", "APPR", "ADJA", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Da\u00df gleich den augenblick/ von wegen dieser that/", "tokens": ["Da\u00df", "gleich", "den", "au\u00b7gen\u00b7blick", "/", "von", "we\u00b7gen", "die\u00b7ser", "that", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "$(", "APPR", "APPR", "PDAT", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "Becklagte m\u00f6ge sich der L\u00e4lien entbrechen/", "tokens": ["Beck\u00b7lag\u00b7te", "m\u00f6\u00b7ge", "sich", "der", "L\u00e4\u00b7li\u00b7en", "ent\u00b7bre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VMFIN", "PRF", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Bi\u00df da\u00df ihr die natur den fehler ausgewetzt/", "tokens": ["Bi\u00df", "da\u00df", "ihr", "die", "na\u00b7tur", "den", "feh\u00b7ler", "aus\u00b7ge\u00b7wetzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.170": {"text": "Und das verwachsne fleisch vom neuen umgegossen;", "tokens": ["Und", "das", "ver\u00b7wachs\u00b7ne", "fleisch", "vom", "neu\u00b7en", "um\u00b7ge\u00b7gos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Sie aber uns/ wie recht/ den schaden hat ersetzt/", "tokens": ["Sie", "a\u00b7ber", "uns", "/", "wie", "recht", "/", "den", "scha\u00b7den", "hat", "er\u00b7setzt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPER", "$(", "PWAV", "ADJD", "$(", "ART", "ADJA", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "Der uns so lange zeit aus ihrer haut geflossen.", "tokens": ["Der", "uns", "so", "lan\u00b7ge", "zeit", "aus", "ih\u00b7rer", "haut", "ge\u00b7flos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Cupido fieng hierauff mit diesen worten an:", "tokens": ["Cu\u00b7pi\u00b7do", "fi\u00b7eng", "hier\u00b7auff", "mit", "die\u00b7sen", "wor\u00b7ten", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PAV", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.174": {"text": "Vor dir/ Apollo/ ist die nase hier erschienen/", "tokens": ["Vor", "dir", "/", "A\u00b7pol\u00b7lo", "/", "ist", "die", "na\u00b7se", "hier", "er\u00b7schie\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$(", "NE", "$(", "VAFIN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Und dingt ihr alles aus/ was etwan k\u00fcnfftig kan", "tokens": ["Und", "dingt", "ihr", "al\u00b7les", "aus", "/", "was", "et\u00b7wan", "k\u00fcnff\u00b7tig", "kan"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PIS", "PTKVZ", "$(", "PWS", "ADV", "ADJD", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Ihr/ als beklagten/ noch zu ihrer nothdurfft dienen.", "tokens": ["Ihr", "/", "als", "be\u00b7klag\u00b7ten", "/", "noch", "zu", "ih\u00b7rer", "noth\u00b7durfft", "die\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "KOKOM", "VVFIN", "$(", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Nechst diesem hat sie itzt mit mehrerm angeh\u00f6rt/", "tokens": ["Nechst", "die\u00b7sem", "hat", "sie", "itzt", "mit", "meh\u00b7rerm", "an\u00b7ge\u00b7h\u00f6rt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "VAFIN", "PPER", "ADV", "APPR", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Was massen gegentheil zu klagen sich nicht sch\u00e4met/", "tokens": ["Was", "mas\u00b7sen", "ge\u00b7gen\u00b7theil", "zu", "kla\u00b7gen", "sich", "nicht", "sch\u00e4\u00b7met", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "PTKZU", "VVINF", "PRF", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Ob h\u00e4tte sich ihr fleisch so freventlich gemehrt/", "tokens": ["Ob", "h\u00e4t\u00b7te", "sich", "ihr", "fleisch", "so", "fre\u00b7vent\u00b7lich", "ge\u00b7mehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PRF", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "Da\u00df es den augen selbst den freyen lauff gel\u00e4hmet/", "tokens": ["Da\u00df", "es", "den", "au\u00b7gen", "selbst", "den", "frey\u00b7en", "lauff", "ge\u00b7l\u00e4h\u00b7met", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Den annoch rothen mund um seine rosen bracht/", "tokens": ["Den", "an\u00b7noch", "ro\u00b7then", "mund", "um", "sei\u00b7ne", "ro\u00b7sen", "bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Den wangen und der brust die liebes-krafft benommen/", "tokens": ["Den", "wan\u00b7gen", "und", "der", "brust", "die", "lie\u00b7bes\u00b7krafft", "be\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.183": {"text": "Und endlich gar zuletzt durch seinen schimpff gemacht/", "tokens": ["Und", "end\u00b7lich", "gar", "zu\u00b7letzt", "durch", "sei\u00b7nen", "schimpff", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "Da\u00df sie bey m\u00e4nnern auch um ihre wohlfahrt kommen.", "tokens": ["Da\u00df", "sie", "bey", "m\u00e4n\u00b7nern", "auch", "um", "ih\u00b7re", "wohl\u00b7fahrt", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "ADV", "APPR", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Nun stellt beklagte di\u00df zu freyem urtheil dar:", "tokens": ["Nun", "stellt", "be\u00b7klag\u00b7te", "di\u00df", "zu", "frey\u00b7em", "ur\u00b7theil", "dar", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVFIN", "PDS", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Ob grosse nasen stets der augen glantz verr\u00fccken/", "tokens": ["Ob", "gros\u00b7se", "na\u00b7sen", "stets", "der", "au\u00b7gen", "glantz", "ver\u00b7r\u00fc\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADV", "ART", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Indem ja wohlbekandt/ und allzu offenbar/", "tokens": ["In\u00b7dem", "ja", "wohl\u00b7be\u00b7kandt", "/", "und", "all\u00b7zu", "of\u00b7fen\u00b7bar", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "$(", "KON", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.188": {"text": "Da\u00df jungfern mehrentheils nach grossen nasen blicken?", "tokens": ["Da\u00df", "jung\u00b7fern", "meh\u00b7ren\u00b7theils", "nach", "gros\u00b7sen", "na\u00b7sen", "bli\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "Und herentgegen offt sich mancher st\u00fcmper qv\u00e4lt/", "tokens": ["Und", "he\u00b7rent\u00b7ge\u00b7gen", "offt", "sich", "man\u00b7cher", "st\u00fcm\u00b7per", "qv\u00e4lt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PRF", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "Da\u00df er in lieb und pein mu\u00df ohne k\u00fchlung brennen/", "tokens": ["Da\u00df", "er", "in", "lieb", "und", "pein", "mu\u00df", "oh\u00b7ne", "k\u00fch\u00b7lung", "bren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJD", "KON", "NN", "VMFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "Weil seinem kopffe blo\u00df ein gr\u00f6sser n\u00e4\u00dfgen fehlt/", "tokens": ["Weil", "sei\u00b7nem", "kopf\u00b7fe", "blo\u00df", "ein", "gr\u00f6s\u00b7ser", "n\u00e4\u00df\u00b7gen", "fehlt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.192": {"text": "Und ihn die jungfern noch vor keinen mann erkennen.", "tokens": ["Und", "ihn", "die", "jung\u00b7fern", "noch", "vor", "kei\u00b7nen", "mann", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "ADV", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "So will sie auch nicht erst zu forschen sich bem\u00fchn/", "tokens": ["So", "will", "sie", "auch", "nicht", "erst", "zu", "for\u00b7schen", "sich", "be\u00b7m\u00fchn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "ADV", "PTKZU", "VVFIN", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.194": {"text": "Ob nicht ein einig wort die lippen offt verg\u00e4llen/", "tokens": ["Ob", "nicht", "ein", "ei\u00b7nig", "wort", "die", "lip\u00b7pen", "offt", "ver\u00b7g\u00e4l\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJD", "NN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Ein eyfrig wange kan aus sonne regen ziehn/", "tokens": ["Ein", "ey\u00b7frig", "wan\u00b7ge", "kan", "aus", "son\u00b7ne", "re\u00b7gen", "ziehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "VMFIN", "APPR", "ADJA", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Und ein erz\u00fcrnter blick den gantzen leib verstellen.", "tokens": ["Und", "ein", "er\u00b7z\u00fcrn\u00b7ter", "blick", "den", "gant\u00b7zen", "leib", "ver\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.197": {"text": "Bringt aber dieses nur entgegen-sch\u00fctzend ein/", "tokens": ["Bringt", "a\u00b7ber", "die\u00b7ses", "nur", "ent\u00b7ge\u00b7gen\u00b7sch\u00fct\u00b7zend", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PDAT", "ADV", "ADJD", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.198": {"text": "Da\u00df kl\u00e4gere sich blo\u00df aus \u00fcbermuth beschweren/", "tokens": ["Da\u00df", "kl\u00e4\u00b7ge\u00b7re", "sich", "blo\u00df", "aus", "\u00fc\u00b7ber\u00b7muth", "be\u00b7schwe\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "PRF", "ADV", "APPR", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.199": {"text": "Da\u00df sie in keiner gunst bey junggesellen seyn/", "tokens": ["Da\u00df", "sie", "in", "kei\u00b7ner", "gunst", "bey", "jung\u00b7ge\u00b7sel\u00b7len", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "NN", "APPR", "ADJA", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Und ihre lebens-krafft durch stille glut verzehren.", "tokens": ["Und", "ih\u00b7re", "le\u00b7bens\u00b7krafft", "durch", "stil\u00b7le", "glut", "ver\u00b7zeh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "Immassen sich denn schon die zeugen eingestellt/", "tokens": ["Im\u00b7mas\u00b7sen", "sich", "denn", "schon", "die", "zeu\u00b7gen", "ein\u00b7ge\u00b7stellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "ADV", "ADV", "ART", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Die ehmahls L\u00e4lien den r\u00fccken halten m\u00fcssen;", "tokens": ["Die", "eh\u00b7mahls", "L\u00e4\u00b7li\u00b7en", "den", "r\u00fc\u00b7cken", "hal\u00b7ten", "m\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.203": {"text": "Wenn Polidorens mund zu ihrem sich gesellt/", "tokens": ["Wenn", "Po\u00b7li\u00b7do\u00b7rens", "mund", "zu", "ih\u00b7rem", "sich", "ge\u00b7sellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "APPR", "PPOSAT", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.204": {"text": "Und seine seele lie\u00df in ihren purpur fliessen.", "tokens": ["Und", "sei\u00b7ne", "see\u00b7le", "lie\u00df", "in", "ih\u00b7ren", "pur\u00b7pur", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.205": {"text": "So ist zum andern falsch und irrig angebracht:", "tokens": ["So", "ist", "zum", "an\u00b7dern", "falsch", "und", "ir\u00b7rig", "an\u00b7ge\u00b7bracht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "ADJA", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.206": {"text": "Ob m\u00fcsten gegentheil der m\u00e4nner urtheil leiden/", "tokens": ["Ob", "m\u00fcs\u00b7ten", "ge\u00b7gen\u00b7theil", "der", "m\u00e4n\u00b7ner", "ur\u00b7theil", "lei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.207": {"text": "Und w\u00fcrden \u00f6ffentlich durch diesen schimpff verlacht:", "tokens": ["Und", "w\u00fcr\u00b7den", "\u00f6f\u00b7fent\u00b7lich", "durch", "die\u00b7sen", "schimpff", "ver\u00b7lacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.208": {"text": "Man k\u00f6nte speck und wurst von ihrer nase schneiden.", "tokens": ["Man", "k\u00f6n\u00b7te", "speck", "und", "wurst", "von", "ih\u00b7rer", "na\u00b7se", "schnei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "NE", "KON", "VAFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "Denn wie das gringste wort nicht zu erweisen steht.", "tokens": ["Denn", "wie", "das", "grings\u00b7te", "wort", "nicht", "zu", "er\u00b7wei\u00b7sen", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.210": {"text": "So ist ja drittens falsch/ und freventlich ersonnen/", "tokens": ["So", "ist", "ja", "drit\u00b7tens", "falsch", "/", "und", "fre\u00b7vent\u00b7lich", "er\u00b7son\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ADJD", "$(", "KON", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.211": {"text": "Da\u00df sich die nase mehr/ als rechtens ist/ erh\u00f6ht/", "tokens": ["Da\u00df", "sich", "die", "na\u00b7se", "mehr", "/", "als", "rech\u00b7tens", "ist", "/", "er\u00b7h\u00f6ht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "ADV", "$(", "KOKOM", "ADV", "VAFIN", "$(", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.212": {"text": "Und wider die natur zu grossen platz gewonnen/", "tokens": ["Und", "wi\u00b7der", "die", "na\u00b7tur", "zu", "gros\u00b7sen", "platz", "ge\u00b7won\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.213": {"text": "Indem sie/ uneracht schon mercklich dargethan/", "tokens": ["In\u00b7dem", "sie", "/", "un\u00b7e\u00b7racht", "schon", "merck\u00b7lich", "dar\u00b7ge\u00b7than", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "ADJD", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.214": {"text": "Da\u00df alle klagen sich auff schwache steltzen gr\u00fcnden/", "tokens": ["Da\u00df", "al\u00b7le", "kla\u00b7gen", "sich", "auff", "schwa\u00b7che", "stelt\u00b7zen", "gr\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "PRF", "APPR", "ADJA", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.215": {"text": "Auch noch durch diese schrifft mit ruhme zeigen kan/", "tokens": ["Auch", "noch", "durch", "die\u00b7se", "schrifft", "mit", "ruh\u00b7me", "zei\u00b7gen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PDS", "VVFIN", "APPR", "ADJA", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.216": {"text": "Da\u00df Venus selbst an ihr kan keinen tadel finden.", "tokens": ["Da\u00df", "Ve\u00b7nus", "selbst", "an", "ihr", "kan", "kei\u00b7nen", "ta\u00b7del", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "APPR", "PPER", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Weil denn nun sonnenklar aus obigen erhellt/", "tokens": ["Weil", "denn", "nun", "son\u00b7nen\u00b7klar", "aus", "o\u00b7bi\u00b7gen", "er\u00b7hellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ADJD", "APPR", "ADJA", "VVFIN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.218": {"text": "Da\u00df mehrgedachtes theil/ mund/ auge/ brust und wangen/", "tokens": ["Da\u00df", "mehr\u00b7ge\u00b7dach\u00b7tes", "theil", "/", "mund", "/", "au\u00b7ge", "/", "brust", "und", "wan\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$(", "NN", "$(", "NN", "$(", "VVFIN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.219": {"text": "Weil etwan L\u00e4lien der spiegel nicht gef\u00e4llt/", "tokens": ["Weil", "et\u00b7wan", "L\u00e4\u00b7li\u00b7en", "der", "spie\u00b7gel", "nicht", "ge\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "ART", "NN", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.220": {"text": "Aus blossem \u00fcbermuth zu rechten angefangen;", "tokens": ["Aus", "blos\u00b7sem", "\u00fc\u00b7ber\u00b7muth", "zu", "rech\u00b7ten", "an\u00b7ge\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.221": {"text": "Und aber dieser schimpff beklagter ehre kr\u00e4nckt/", "tokens": ["Und", "a\u00b7ber", "die\u00b7ser", "schimpff", "be\u00b7klag\u00b7ter", "eh\u00b7re", "kr\u00e4nckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PDS", "VVFIN", "ADJD", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "Und ieder kerl auff sie das maul noch w\u00fcrde r\u00fcmpffen;", "tokens": ["Und", "ie\u00b7der", "kerl", "auff", "sie", "das", "maul", "noch", "w\u00fcr\u00b7de", "r\u00fcmpf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "PPER", "ART", "NN", "ADV", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.223": {"text": "Hingegen die natur und alles recht gedenckt/", "tokens": ["Hin\u00b7ge\u00b7gen", "die", "na\u00b7tur", "und", "al\u00b7les", "recht", "ge\u00b7denckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "PIS", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Da\u00df keiner andre soll an seinen ehren schimpffen.", "tokens": ["Da\u00df", "kei\u00b7ner", "and\u00b7re", "soll", "an", "sei\u00b7nen", "eh\u00b7ren", "schimpf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIS", "VMFIN", "APPR", "PPOSAT", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.225": {"text": "Als fleht/ Apollo/ sie dich gantz gehorsamst an/", "tokens": ["Als", "fleht", "/", "A\u00b7pol\u00b7lo", "/", "sie", "dich", "gantz", "ge\u00b7hor\u00b7samst", "an", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "$(", "NE", "$(", "PPER", "PRF", "ADV", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "Und bittet/ kl\u00e4gere nicht lassen abzutreten/", "tokens": ["Und", "bit\u00b7tet", "/", "kl\u00e4\u00b7ge\u00b7re", "nicht", "las\u00b7sen", "ab\u00b7zu\u00b7tre\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "VVFIN", "PTKNEG", "VVINF", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Bi\u00df da\u00df sie allerseits den schaden gut gethan/", "tokens": ["Bi\u00df", "da\u00df", "sie", "al\u00b7ler\u00b7seits", "den", "scha\u00b7den", "gut", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADV", "ART", "ADJA", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "Und ihr hier \u00f6ffentlich den frevel abgebeten.", "tokens": ["Und", "ihr", "hier", "\u00f6f\u00b7fent\u00b7lich", "den", "fre\u00b7vel", "ab\u00b7ge\u00b7be\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.229": {"text": "Was aber gegentheil de\u00dfwegen w\u00fcrdig sey/", "tokens": ["Was", "a\u00b7ber", "ge\u00b7gen\u00b7theil", "de\u00df\u00b7we\u00b7gen", "w\u00fcr\u00b7dig", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "PAV", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.230": {"text": "Di\u00df alles will sie dir/ als richtern/ \u00fcberlassen/", "tokens": ["Di\u00df", "al\u00b7les", "will", "sie", "dir", "/", "als", "rich\u00b7tern", "/", "\u00fc\u00b7ber\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "PIS", "VMFIN", "PPER", "PPER", "$(", "KOKOM", "VVINF", "$(", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.231": {"text": "Und stellet/ grosser f\u00fcrst/ es deinem willen frey/", "tokens": ["Und", "stel\u00b7let", "/", "gros\u00b7ser", "f\u00fcrst", "/", "es", "dei\u00b7nem", "wil\u00b7len", "frey", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "ADJA", "NN", "$(", "PPER", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.232": {"text": "Was du vor straffen denckst im urthel abzufassen.", "tokens": ["Was", "du", "vor", "straf\u00b7fen", "denckst", "im", "ur\u00b7thel", "ab\u00b7zu\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "VVFIN", "ADV", "APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.233": {"text": "Wir bleiben (warff der mund dagegen wieder ein)", "tokens": ["Wir", "blei\u00b7ben", "(", "warff", "der", "mund", "da\u00b7ge\u00b7gen", "wie\u00b7der", "ein", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "ART", "NN", "PAV", "ADV", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.234": {"text": "Bey dem/ was wir bereits mit mehrerm vorgetragen/", "tokens": ["Bey", "dem", "/", "was", "wir", "be\u00b7reits", "mit", "meh\u00b7rerm", "vor\u00b7ge\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$(", "PWS", "PPER", "ADV", "APPR", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Und w\u00fcrde wohl so schwer nicht zu behaupten seyn/", "tokens": ["Und", "w\u00fcr\u00b7de", "wohl", "so", "schwer", "nicht", "zu", "be\u00b7haup\u00b7ten", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ADJD", "PTKNEG", "PTKZU", "VVINF", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.236": {"text": "Da\u00df grosse nasen offt bey m\u00e4nnern fehl geschlagen;", "tokens": ["Da\u00df", "gros\u00b7se", "na\u00b7sen", "offt", "bey", "m\u00e4n\u00b7nern", "fehl", "ge\u00b7schla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Doch weil beklagte sich auff blosses nein gelegt/", "tokens": ["Doch", "weil", "be\u00b7klag\u00b7te", "sich", "auff", "blos\u00b7ses", "nein", "ge\u00b7legt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "VVFIN", "PRF", "APPR", "ADJA", "PTKANT", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.238": {"text": "Und ihre m\u00e4ngel denckt mit worten auszuschmieren/", "tokens": ["Und", "ih\u00b7re", "m\u00e4n\u00b7gel", "denckt", "mit", "wor\u00b7ten", "aus\u00b7zu\u00b7schmie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.239": {"text": "So sind wir/ was die stadt von ihr zu reden pflegt/", "tokens": ["So", "sind", "wir", "/", "was", "die", "stadt", "von", "ihr", "zu", "re\u00b7den", "pflegt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$(", "PWS", "ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.240": {"text": "Auch allerseits bereit durch zeugen auszuf\u00fchren.", "tokens": ["Auch", "al\u00b7ler\u00b7seits", "be\u00b7reit", "durch", "zeu\u00b7gen", "aus\u00b7zu\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "APPR", "VVFIN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.241": {"text": "Cupido sprach hierauff: Beklagte nimmt es an/", "tokens": ["Cu\u00b7pi\u00b7do", "sprach", "hier\u00b7auff", ":", "Be\u00b7klag\u00b7te", "nimmt", "es", "an", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PAV", "$.", "NN", "VVFIN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.242": {"text": "Und bittet selber/ nur die zeugen vorzulassen.", "tokens": ["Und", "bit\u00b7tet", "sel\u00b7ber", "/", "nur", "die", "zeu\u00b7gen", "vor\u00b7zu\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$(", "ADV", "ART", "VVFIN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.243": {"text": "Gleich ward den augenblick ein rauchfa\u00df auffgethan/", "tokens": ["Gleich", "ward", "den", "au\u00b7gen\u00b7blick", "ein", "rauch\u00b7fa\u00df", "auff\u00b7ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.244": {"text": "Vor dessen reiner glut die sterne selbst erblassen.", "tokens": ["Vor", "des\u00b7sen", "rei\u00b7ner", "glut", "die", "ster\u00b7ne", "selbst", "er\u00b7blas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "ADJA", "NN", "ART", "ADJA", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.245": {"text": "Inzwischen stellten sich zwey menschen-ohren dar/", "tokens": ["I\u00b7nzwi\u00b7schen", "stell\u00b7ten", "sich", "zwey", "men\u00b7schen\u00b7oh\u00b7ren", "dar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "CARD", "NN", "PTKVZ", "$("], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.246": {"text": "Apollo aber rieff: Ich schwere bey den flammen;", "tokens": ["A\u00b7pol\u00b7lo", "a\u00b7ber", "rieff", ":", "Ich", "schwe\u00b7re", "bey", "den", "flam\u00b7men", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.247": {"text": "Macht heut' ein zeuge nicht die warheit offenbahr/", "tokens": ["Macht", "heut'", "ein", "zeu\u00b7ge", "nicht", "die", "war\u00b7heit", "of\u00b7fen\u00b7bahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "VVFIN", "PTKNEG", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.248": {"text": "Da\u00df er sich selber soll zu feur und glut verdammen.", "tokens": ["Da\u00df", "er", "sich", "sel\u00b7ber", "soll", "zu", "feur", "und", "glut", "ver\u00b7dam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VMFIN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.249": {"text": "Und hiemit fieng er an: Wem steht ihr ohren zu?", "tokens": ["Und", "hie\u00b7mit", "fi\u00b7eng", "er", "an", ":", "Wem", "steht", "ihr", "oh\u00b7ren", "zu", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.250": {"text": "Der sch\u00f6nen L\u00e4lie/ versetzten ihm die ohren.", "tokens": ["Der", "sch\u00f6\u00b7nen", "L\u00e4\u00b7lie", "/", "ver\u00b7setz\u00b7ten", "ihm", "die", "oh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.251": {"text": "Was st\u00f6ret/ sprach er/ denn der L\u00e4lien die ruh/", "tokens": ["Was", "st\u00f6\u00b7ret", "/", "sprach", "er", "/", "denn", "der", "L\u00e4\u00b7li\u00b7en", "die", "ruh", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "VVFIN", "PPER", "$(", "KON", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.252": {"text": "Und warum hat ihr mund der sch\u00f6nheit glantz verlohren?", "tokens": ["Und", "wa\u00b7rum", "hat", "ihr", "mund", "der", "sch\u00f6n\u00b7heit", "glantz", "ver\u00b7loh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "PPOSAT", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.253": {"text": "Streut etwan ha\u00df und neid verg\u00e4llte reden aus?", "tokens": ["Streut", "et\u00b7wan", "ha\u00df", "und", "neid", "ver\u00b7g\u00e4ll\u00b7te", "re\u00b7den", "aus", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVIMP", "KON", "NN", "VVFIN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.254": {"text": "Ach nein! Begegneten ihm hier die ohren wieder:", "tokens": ["Ach", "nein", "!", "Be\u00b7ge\u00b7gne\u00b7ten", "ihm", "hier", "die", "oh\u00b7ren", "wie\u00b7der", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$.", "NN", "PPER", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.255": {"text": "Der L\u00e4lien ihr muth ist wie ein lorbeer-strau\u00df;", "tokens": ["Der", "L\u00e4\u00b7li\u00b7en", "ihr", "muth", "ist", "wie", "ein", "lor\u00b7beer\u00b7strau\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.256": {"text": "Und legt die zweige nicht vor blitz und donner nieder.", "tokens": ["Und", "legt", "die", "zwei\u00b7ge", "nicht", "vor", "blitz", "und", "don\u00b7ner", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "PTKNEG", "APPR", "NE", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.257": {"text": "So mu\u00df denn/ fuhr er fort/ ein leibes-mangel seyn/", "tokens": ["So", "mu\u00df", "denn", "/", "fuhr", "er", "fort", "/", "ein", "lei\u00b7bes\u00b7man\u00b7gel", "seyn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "$(", "VVFIN", "PPER", "PTKVZ", "$(", "ART", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.258": {"text": "Um den sich L\u00e4lie mu\u00df ingeheim betr\u00fcben?", "tokens": ["Um", "den", "sich", "L\u00e4\u00b7lie", "mu\u00df", "in\u00b7ge\u00b7heim", "be\u00b7tr\u00fc\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PRF", "NE", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.259": {"text": "Ach! fielen ihm hierauff die ohren wieder ein:", "tokens": ["Ach", "!", "fie\u00b7len", "ihm", "hier\u00b7auff", "die", "oh\u00b7ren", "wie\u00b7der", "ein", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "PAV", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.260": {"text": "Welch unmensch solte wohl nicht ihre glieder lieben?", "tokens": ["Welch", "un\u00b7mensch", "sol\u00b7te", "wohl", "nicht", "ih\u00b7re", "glie\u00b7der", "lie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "VMFIN", "ADV", "PTKNEG", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.261": {"text": "Welch Momus hat iemahls hier fehler ausgesetzt?", "tokens": ["Welch", "Mo\u00b7mus", "hat", "ie\u00b7mahls", "hier", "feh\u00b7ler", "aus\u00b7ge\u00b7setzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.262": {"text": "Und wer will der natur noch pfuscher-striche weisen/", "tokens": ["Und", "wer", "will", "der", "na\u00b7tur", "noch", "pfu\u00b7scher\u00b7stri\u00b7che", "wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "ART", "NN", "ADV", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.263": {"text": "Wo selber Polidor die farben hochgesch\u00e4tzt/", "tokens": ["Wo", "sel\u00b7ber", "Po\u00b7li\u00b7dor", "die", "far\u00b7ben", "hoch\u00b7ge\u00b7sch\u00e4tzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.264": {"text": "Und tausend andre noch das meister-st\u00fccke preisen?", "tokens": ["Und", "tau\u00b7send", "and\u00b7re", "noch", "das", "meis\u00b7ter\u00b7st\u00fc\u00b7cke", "prei\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "PIS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.265": {"text": "Und gleichwohl/ sprach er/ soll die nase nicht bestehn.", "tokens": ["Und", "gleich\u00b7wohl", "/", "sprach", "er", "/", "soll", "die", "na\u00b7se", "nicht", "be\u00b7stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "VVFIN", "PPER", "$(", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.266": {"text": "Ha! widersetzten sie/ die leute sind betrogen:", "tokens": ["Ha", "!", "wi\u00b7der\u00b7setz\u00b7ten", "sie", "/", "die", "leu\u00b7te", "sind", "be\u00b7tro\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "$(", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.267": {"text": "Weil neulich L\u00e4lia sich ohngefehr versehn/", "tokens": ["Weil", "neu\u00b7lich", "L\u00e4\u00b7lia", "sich", "ohn\u00b7ge\u00b7fehr", "ver\u00b7sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "PRF", "ADJD", "VVINF", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.268": {"text": "Und durch ein falsches gla\u00df ihr selber vorgelogen.", "tokens": ["Und", "durch", "ein", "fal\u00b7sches", "gla\u00df", "ihr", "sel\u00b7ber", "vor\u00b7ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.269": {"text": "So ist sie/ fragt' er fort/ von allem tadel frey?", "tokens": ["So", "ist", "sie", "/", "fragt'", "er", "fort", "/", "von", "al\u00b7lem", "ta\u00b7del", "frey", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$(", "VVFIN", "PPER", "PTKVZ", "$(", "APPR", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.270": {"text": "Von allem/ sprachen sie; und wer es nicht will glauben/", "tokens": ["Von", "al\u00b7lem", "/", "spra\u00b7chen", "sie", ";", "und", "wer", "es", "nicht", "will", "glau\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$(", "VVFIN", "PPER", "$.", "KON", "PWS", "PPER", "PTKNEG", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.271": {"text": "Und trifft/ da\u00df L\u00e4lia deswegen traurig sey/", "tokens": ["Und", "trifft", "/", "da\u00df", "L\u00e4\u00b7lia", "des\u00b7we\u00b7gen", "trau\u00b7rig", "sey", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "NE", "PAV", "ADJD", "VAFIN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.272": {"text": "Der mag uns/ wie er will/ auff tausend foltern schrauben.", "tokens": ["Der", "mag", "uns", "/", "wie", "er", "will", "/", "auff", "tau\u00b7send", "fol\u00b7tern", "schrau\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "$(", "PWAV", "PPER", "VMFIN", "$(", "APPR", "CARD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.273": {"text": "Drauff traten beyderseits nach seinem wincken ab/", "tokens": ["Drauff", "tra\u00b7ten", "bey\u00b7der\u00b7seits", "nach", "sei\u00b7nem", "win\u00b7cken", "ab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "APPR", "PPOSAT", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.274": {"text": "Und ward den augenblick der gegenpart befohlen/", "tokens": ["Und", "ward", "den", "au\u00b7gen\u00b7blick", "der", "ge\u00b7gen\u00b7part", "be\u00b7foh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.275": {"text": "Sie solte/ weil es noch weit mehr zu richten gab/", "tokens": ["Sie", "sol\u00b7te", "/", "weil", "es", "noch", "weit", "mehr", "zu", "rich\u00b7ten", "gab", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$(", "KOUS", "PPER", "ADV", "ADJD", "ADV", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.276": {"text": "Zu besserm unterricht auch ihre zeugen holen;", "tokens": ["Zu", "bes\u00b7serm", "un\u00b7ter\u00b7richt", "auch", "ih\u00b7re", "zeu\u00b7gen", "ho\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VVFIN", "ADV", "PPOSAT", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.277": {"text": "Gleich aber brachte sie Cupido schon gef\u00fchrt/", "tokens": ["Gleich", "a\u00b7ber", "brach\u00b7te", "sie", "Cu\u00b7pi\u00b7do", "schon", "ge\u00b7f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "NE", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.278": {"text": "Und war ein gr\u00fcner stul und zinnern hand-gef\u00e4sse.", "tokens": ["Und", "war", "ein", "gr\u00fc\u00b7ner", "stul", "und", "zin\u00b7nern", "han\u00b7dge\u00b7f\u00e4s\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.279": {"text": "Nun dachte iederman/ er h\u00e4tte sich vexirt/", "tokens": ["Nun", "dach\u00b7te", "ie\u00b7der\u00b7man", "/", "er", "h\u00e4t\u00b7te", "sich", "ve\u00b7xirt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$(", "PPER", "VAFIN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.280": {"text": "Und da\u00df sein tummer kopff auff narren-balcken s\u00e4sse:", "tokens": ["Und", "da\u00df", "sein", "tum\u00b7mer", "kopff", "auff", "nar\u00b7ren\u00b7bal\u00b7cken", "s\u00e4s\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "ADJA", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.281": {"text": "Als aber bald darauff Apollo sie besprach/", "tokens": ["Als", "a\u00b7ber", "bald", "dar\u00b7auff", "A\u00b7pol\u00b7lo", "sie", "be\u00b7sprach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PAV", "NE", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.282": {"text": "Und fragt: Ob beyderseits die L\u00e4lie wohl kennten?", "tokens": ["Und", "fragt", ":", "Ob", "bey\u00b7der\u00b7seits", "die", "L\u00e4\u00b7lie", "wohl", "kenn\u00b7ten", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "KOUS", "APPR", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.283": {"text": "Da lie\u00df ein ieder auch im lachen wieder nach/", "tokens": ["Da", "lie\u00df", "ein", "ie\u00b7der", "auch", "im", "la\u00b7chen", "wie\u00b7der", "nach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PIAT", "ADV", "APPRART", "VVFIN", "ADV", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.284": {"text": "Als ihm der gr\u00fcne stuhl mit hundert complimenten", "tokens": ["Als", "ihm", "der", "gr\u00fc\u00b7ne", "stuhl", "mit", "hun\u00b7dert", "com\u00b7pli\u00b7men\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.285": {"text": "Di\u00df zu der antwort gab: Ach! kennt ich diese nicht/", "tokens": ["Di\u00df", "zu", "der", "ant\u00b7wort", "gab", ":", "Ach", "!", "kennt", "ich", "die\u00b7se", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "VVFIN", "$.", "ITJ", "$.", "VVFIN", "PPER", "PDS", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.286": {"text": "So w\u00e4re nicht zur zeit mein polster eingedr\u00fccket;", "tokens": ["So", "w\u00e4\u00b7re", "nicht", "zur", "zeit", "mein", "pols\u00b7ter", "ein\u00b7ge\u00b7dr\u00fc\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "APPRART", "NN", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.287": {"text": "Denn eben sie hat mich so sch\u00e4ndlich zugericht/", "tokens": ["Denn", "e\u00b7ben", "sie", "hat", "mich", "so", "sch\u00e4nd\u00b7lich", "zu\u00b7ge\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.288": {"text": "Wenn sie den Polidor durch k\u00fcssen gantz entz\u00fccket/", "tokens": ["Wenn", "sie", "den", "Po\u00b7li\u00b7dor", "durch", "k\u00fcs\u00b7sen", "gantz", "ent\u00b7z\u00fc\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "VVFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.289": {"text": "Den rundgew\u00f6lbten mund in seinen mund gesteckt/", "tokens": ["Den", "rund\u00b7ge\u00b7w\u00f6lb\u00b7ten", "mund", "in", "sei\u00b7nen", "mund", "ge\u00b7steckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.290": {"text": "Der lippen s\u00fcsse milch wie kinder angesogen/", "tokens": ["Der", "lip\u00b7pen", "s\u00fcs\u00b7se", "milch", "wie", "kin\u00b7der", "an\u00b7ge\u00b7so\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KOKOM", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.291": {"text": "Der wangen liebes-schnee wie zucker abgeleckt/", "tokens": ["Der", "wan\u00b7gen", "lie\u00b7bes\u00b7schnee", "wie", "zu\u00b7cker", "ab\u00b7ge\u00b7leckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KOKOM", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.292": {"text": "Und seinen schwachen geist dem hertzen nachgezogen.", "tokens": ["Und", "sei\u00b7nen", "schwa\u00b7chen", "geist", "dem", "hert\u00b7zen", "nach\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.293": {"text": "Und kennt ich diese nicht/ fieng auch das handfa\u00df an/", "tokens": ["Und", "kennt", "ich", "die\u00b7se", "nicht", "/", "fi\u00b7eng", "auch", "das", "hand\u00b7fa\u00df", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PDS", "PTKNEG", "$(", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.294": {"text": "So w\u00e4re nicht mein zinn so voller holer ballen;", "tokens": ["So", "w\u00e4\u00b7re", "nicht", "mein", "zinn", "so", "vol\u00b7ler", "ho\u00b7ler", "bal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "PPOSAT", "NN", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.295": {"text": "Denn wenn ihr \u00f6ffters schon der r\u00fccken weh gethan/", "tokens": ["Denn", "wenn", "ihr", "\u00f6ff\u00b7ters", "schon", "der", "r\u00fc\u00b7cken", "weh", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.296": {"text": "Und sie vor k\u00fcssen fast in ohnmacht wollen fallen;", "tokens": ["Und", "sie", "vor", "k\u00fcs\u00b7sen", "fast", "in", "ohn\u00b7macht", "wol\u00b7len", "fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "VVFIN", "ADV", "APPR", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.297": {"text": "So hab ich \u00e4rmstes denn die st\u00fctze m\u00fcssen seyn.", "tokens": ["So", "hab", "ich", "\u00e4rms\u00b7tes", "denn", "die", "st\u00fct\u00b7ze", "m\u00fcs\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJA", "KON", "ART", "VVFIN", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.298": {"text": "Ach! w\u00fcrde mir so viel nur wasser eingegossen/", "tokens": ["Ach", "!", "w\u00fcr\u00b7de", "mir", "so", "viel", "nur", "was\u00b7ser", "ein\u00b7ge\u00b7gos\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.299": {"text": "Als t\u00e4glich L\u00e4lien ambrirter liebes-wein", "tokens": ["Als", "t\u00e4g\u00b7lich", "L\u00e4\u00b7li\u00b7en", "am\u00b7br\u00b7ir\u00b7ter", "lie\u00b7bes\u00b7wein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "NN", "ADJA", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.300": {"text": "Von Polydoren ist in ihren mund geflossen/", "tokens": ["Von", "Po\u00b7ly\u00b7do\u00b7ren", "ist", "in", "ih\u00b7ren", "mund", "ge\u00b7flos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.301": {"text": "Hier traten sie zur\u00fcck. Und/ sprach Cupido drauff/", "tokens": ["Hier", "tra\u00b7ten", "sie", "zu\u00b7r\u00fcck", ".", "Und", "/", "sprach", "Cu\u00b7pi\u00b7do", "drauff", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "KON", "$(", "VVFIN", "NE", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.302": {"text": "Nun sieht man wo der grund der klagen ist geblieben/", "tokens": ["Nun", "sieht", "man", "wo", "der", "grund", "der", "kla\u00b7gen", "ist", "ge\u00b7blie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PWAV", "ART", "NN", "ART", "ADJA", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.303": {"text": "Doch weist beklagte noch auch dieses zeugni\u00df auff/", "tokens": ["Doch", "weist", "be\u00b7klag\u00b7te", "noch", "auch", "die\u00b7ses", "zeug\u00b7ni\u00df", "auff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVFIN", "ADV", "ADV", "PDAT", "NN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.304": {"text": "Das ihr die Venus selbst mit eigner hand geschrieben.", "tokens": ["Das", "ihr", "die", "Ve\u00b7nus", "selbst", "mit", "eig\u00b7ner", "hand", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.305": {"text": "Aus diesem buche wird ein ieder aber sehn/", "tokens": ["Aus", "die\u00b7sem", "bu\u00b7che", "wird", "ein", "ie\u00b7der", "a\u00b7ber", "sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "ART", "PIS", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.306": {"text": "Wie L\u00e4liens gesicht und Polidor sich k\u00fcssen/", "tokens": ["Wie", "L\u00e4\u00b7li\u00b7ens", "ge\u00b7sicht", "und", "Po\u00b7li\u00b7dor", "sich", "k\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVPP", "KON", "NN", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.307": {"text": "Wie artig mund auff mund zusammen buhlen stehn;", "tokens": ["Wie", "ar\u00b7tig", "mund", "auff", "mund", "zu\u00b7sam\u00b7men", "buh\u00b7len", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "NN", "APPR", "NN", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.308": {"text": "Indem die mutter sie hierinnen abgerissen.", "tokens": ["In\u00b7dem", "die", "mut\u00b7ter", "sie", "hie\u00b7rin\u00b7nen", "ab\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.309": {"text": "Hier \u00fcbergab er nun dem richter schrifft und buch/", "tokens": ["Hier", "\u00fc\u00b7berg\u00b7ab", "er", "nun", "dem", "rich\u00b7ter", "schrifft", "und", "buch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "VVFIN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.310": {"text": "Wer aber war wohl mehr als L\u00e4lia gewesen?", "tokens": ["Wer", "a\u00b7ber", "war", "wohl", "mehr", "als", "L\u00e4\u00b7lia", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "PIAT", "KOKOM", "NE", "VAPP", "$."], "meter": "-+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.311": {"text": "Apollo l\u00f6ste selbst das rothe scharlach-tuch/", "tokens": ["A\u00b7pol\u00b7lo", "l\u00f6s\u00b7te", "selbst", "das", "ro\u00b7the", "scha\u00b7rlach\u00b7tuch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.312": {"text": "Und gab die edle schrifft/ wie folget/ abzulesen:", "tokens": ["Und", "gab", "die", "ed\u00b7le", "schrifft", "/", "wie", "fol\u00b7get", "/", "ab\u00b7zu\u00b7le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "VVFIN", "$(", "PWAV", "VVFIN", "$(", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.313": {"text": "Wir Venus zeugen hier mit unsrer eignen hand/", "tokens": ["Wir", "Ve\u00b7nus", "zeu\u00b7gen", "hier", "mit", "uns\u00b7rer", "eig\u00b7nen", "hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.314": {"text": "Da\u00df wir die L\u00e4lie vor v\u00f6llig sch\u00f6n erkennen;", "tokens": ["Da\u00df", "wir", "die", "L\u00e4\u00b7lie", "vor", "v\u00f6l\u00b7lig", "sch\u00f6n", "er\u00b7ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ADJD", "ADJD", "VVINF", "$."], "meter": "----+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.315": {"text": "Und machen durch di\u00df blat der gantzen welt bekandt/", "tokens": ["Und", "ma\u00b7chen", "durch", "di\u00df", "blat", "der", "gant\u00b7zen", "welt", "be\u00b7kandt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDS", "VVFIN", "ART", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.316": {"text": "Da\u00df keiner/ der sie schimpfft/ soll unserm zorn entrennen.", "tokens": ["Da\u00df", "kei\u00b7ner", "/", "der", "sie", "schimpfft", "/", "soll", "un\u00b7serm", "zorn", "en\u00b7tren\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$(", "PRELS", "PPER", "VVFIN", "$(", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.317": {"text": "Drauff sah er in das buch/ auff Polidorens mund/", "tokens": ["Drauff", "sah", "er", "in", "das", "buch", "/", "auff", "Po\u00b7li\u00b7do\u00b7rens", "mund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "APPR", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.318": {"text": "Und sprach: wir solten wohl nun straff und urthel h\u00e4uffen:", "tokens": ["Und", "sprach", ":", "wir", "sol\u00b7ten", "wohl", "nun", "straff", "und", "ur\u00b7thel", "h\u00e4uf\u00b7fen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VMFIN", "ADV", "ADV", "VVFIN", "KON", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.319": {"text": "Allein durch dieses thut die liebes-g\u00f6ttin kund/", "tokens": ["Al\u00b7lein", "durch", "die\u00b7ses", "thut", "die", "lie\u00b7bes\u00b7g\u00f6t\u00b7tin", "kund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.320": {"text": "Da\u00df sich kein andrer soll an L\u00e4lien vergreiffen.", "tokens": ["Da\u00df", "sich", "kein", "an\u00b7drer", "soll", "an", "L\u00e4\u00b7li\u00b7en", "ver\u00b7greif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PIAT", "PIS", "VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.321": {"text": "Nun aber kan ja nicht die straffe so ergehn/", "tokens": ["Nun", "a\u00b7ber", "kan", "ja", "nicht", "die", "straf\u00b7fe", "so", "er\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "ADV", "PTKNEG", "ART", "VVFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.322": {"text": "Da\u00df nicht auch L\u00e4lia den Schaden m\u00fcste b\u00fcssen:", "tokens": ["Da\u00df", "nicht", "auch", "L\u00e4\u00b7lia", "den", "Scha\u00b7den", "m\u00fcs\u00b7te", "b\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADV", "NE", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.323": {"text": "Denn wo die glieder schon im blut und thr\u00e4nen stehn/", "tokens": ["Denn", "wo", "die", "glie\u00b7der", "schon", "im", "blut", "und", "thr\u00e4\u00b7nen", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADV", "APPRART", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.324": {"text": "Da kan das hertze nicht in muscateller fliessen.", "tokens": ["Da", "kan", "das", "hert\u00b7ze", "nicht", "in", "mus\u00b7ca\u00b7tel\u00b7ler", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PTKNEG", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.325": {"text": "Genug da\u00df Venus selbst die nase sch\u00f6n erkannt;", "tokens": ["Ge\u00b7nug", "da\u00df", "Ve\u00b7nus", "selbst", "die", "na\u00b7se", "sch\u00f6n", "er\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NN", "ADV", "ART", "ADJA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.326": {"text": "Und darum sollen sie der straffe seyn entnommen/", "tokens": ["Und", "da\u00b7rum", "sol\u00b7len", "sie", "der", "straf\u00b7fe", "seyn", "ent\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VMFIN", "PPER", "ART", "VVFIN", "PPOSAT", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.327": {"text": "Bi\u00df da\u00df ihr Polidor aus Hol- und Engeland/", "tokens": ["Bi\u00df", "da\u00df", "ihr", "Po\u00b7li\u00b7dor", "aus", "Hol", "und", "En\u00b7ge\u00b7land", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPOSAT", "NN", "APPR", "TRUNC", "KON", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.328": {"text": "Wird wieder voller lust zu seiner sonne kommen.", "tokens": ["Wird", "wie\u00b7der", "vol\u00b7ler", "lust", "zu", "sei\u00b7ner", "son\u00b7ne", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.329": {"text": "Inzwischen soll hiemit euch fest befohlen seyn/", "tokens": ["I\u00b7nzwi\u00b7schen", "soll", "hie\u00b7mit", "euch", "fest", "be\u00b7foh\u00b7len", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PAV", "PPER", "ADJD", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.330": {"text": "Da\u00df ieder k\u00fcnfftig wird dergleichen schimpff vermeiden;", "tokens": ["Da\u00df", "ie\u00b7der", "k\u00fcnff\u00b7tig", "wird", "derg\u00b7lei\u00b7chen", "schimpff", "ver\u00b7mei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VAFIN", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.331": {"text": "Im fall er nicht von uns gerechte straff und pein/", "tokens": ["Im", "fall", "er", "nicht", "von", "uns", "ge\u00b7rech\u00b7te", "straff", "und", "pein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PTKNEG", "APPR", "PPER", "ADJA", "VVFIN", "KON", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.332": {"text": "Und tausend urthel will von Polidoren leiden.", "tokens": ["Und", "tau\u00b7send", "ur\u00b7thel", "will", "von", "Po\u00b7li\u00b7do\u00b7ren", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.333": {"text": "Zuletzt bringt L\u00e4lien noch diese lehren heim:", "tokens": ["Zu\u00b7letzt", "bringt", "L\u00e4\u00b7li\u00b7en", "noch", "die\u00b7se", "leh\u00b7ren", "heim", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ADV", "PDS", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.334": {"text": "Da\u00df auch die kl\u00fcgsten wohl in ihren augen fehlen/", "tokens": ["Da\u00df", "auch", "die", "kl\u00fcgs\u00b7ten", "wohl", "in", "ih\u00b7ren", "au\u00b7gen", "feh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.335": {"text": "Und kinder offtermahls vor butter honigseim/", "tokens": ["Und", "kin\u00b7der", "off\u00b7ter\u00b7mahls", "vor", "but\u00b7ter", "ho\u00b7ni\u00b7gseim", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.336": {"text": "Die jungfern aber offt vor rosen dornen w\u00e4hlen.", "tokens": ["Die", "jung\u00b7fern", "a\u00b7ber", "offt", "vor", "ro\u00b7sen", "dor\u00b7nen", "w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Als neulich L\u00e4lia vor ihrem spiegel stund/", "tokens": ["Als", "neu\u00b7lich", "L\u00e4\u00b7lia", "vor", "ih\u00b7rem", "spie\u00b7gel", "stund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und bald die augen lie\u00df auff ihre marmel-ballen/", "tokens": ["Und", "bald", "die", "au\u00b7gen", "lie\u00df", "auff", "ih\u00b7re", "mar\u00b7mel\u00b7bal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bald auff der wangen pracht/ und ihren purpur-mund/", "tokens": ["Bald", "auff", "der", "wan\u00b7gen", "pracht", "/", "und", "ih\u00b7ren", "pur\u00b7pur\u00b7mund", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$(", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bald wieder auff den schnee der rundten nase fallen;", "tokens": ["Bald", "wie\u00b7der", "auff", "den", "schnee", "der", "rund\u00b7ten", "na\u00b7se", "fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da warff sie voller zorn den spiegel aus der hand/", "tokens": ["Da", "warff", "sie", "vol\u00b7ler", "zorn", "den", "spie\u00b7gel", "aus", "der", "hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und sprach: Was helffen mich die rosen meiner wangen?", "tokens": ["Und", "sprach", ":", "Was", "helf\u00b7fen", "mich", "die", "ro\u00b7sen", "mei\u00b7ner", "wan\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PWS", "VVFIN", "PPER", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was nutzt der rothe mund? was meiner augen brand?", "tokens": ["Was", "nutzt", "der", "ro\u00b7the", "mund", "?", "was", "mei\u00b7ner", "au\u00b7gen", "brand", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "$.", "PWS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn mund und nase nicht in gleicher zierde prangen.", "tokens": ["Wenn", "mund", "und", "na\u00b7se", "nicht", "in", "glei\u00b7cher", "zier\u00b7de", "pran\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "VVFIN", "PTKNEG", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Geh/ l\u00fcgner/ bilde mir nur keine sch\u00f6nheit ein/", "tokens": ["Geh", "/", "l\u00fcg\u00b7ner", "/", "bil\u00b7de", "mir", "nur", "kei\u00b7ne", "sch\u00f6n\u00b7heit", "ein", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "VVFIN", "PPER", "ADV", "PIAT", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Denn meine nase macht/ da\u00df ich mich mu\u00df betr\u00fcben/", "tokens": ["Denn", "mei\u00b7ne", "na\u00b7se", "macht", "/", "da\u00df", "ich", "mich", "mu\u00df", "be\u00b7tr\u00fc\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$(", "KOUS", "PPER", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Weil heut ein frauen-bild soll nach der mode seyn/", "tokens": ["Weil", "heut", "ein", "frau\u00b7en\u00b7bild", "soll", "nach", "der", "mo\u00b7de", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VMFIN", "APPR", "ART", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und kaum der tausende kan grosse nasen lieben.", "tokens": ["Und", "kaum", "der", "tau\u00b7sen\u00b7de", "kan", "gros\u00b7se", "na\u00b7sen", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "VMFIN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "So klagte L\u00e4lia/ und sanck vor grosser qual", "tokens": ["So", "klag\u00b7te", "L\u00e4\u00b7lia", "/", "und", "san\u00b7ck", "vor", "gros\u00b7ser", "qual"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "$(", "KON", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Auff einen lager-zeug von schwanen-federn nieder.", "tokens": ["Auff", "ei\u00b7nen", "la\u00b7ger\u00b7zeug", "von", "schwa\u00b7nen\u00b7fe\u00b7dern", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Indessen brach der zorn der augen hellen strahl/", "tokens": ["In\u00b7des\u00b7sen", "brach", "der", "zorn", "der", "au\u00b7gen", "hel\u00b7len", "strahl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der eyffer theilte sich durch alle leibes-glieder/", "tokens": ["Der", "eyf\u00b7fer", "theil\u00b7te", "sich", "durch", "al\u00b7le", "lei\u00b7bes\u00b7glie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und endlich fing der mund mit diesen worten an:", "tokens": ["Und", "end\u00b7lich", "fing", "der", "mund", "mit", "die\u00b7sen", "wor\u00b7ten", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "So h\u00f6r ich \u00e4rmster wohl/ wir sollen alle b\u00fcssen/", "tokens": ["So", "h\u00f6r", "ich", "\u00e4rms\u00b7ter", "wohl", "/", "wir", "sol\u00b7len", "al\u00b7le", "b\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADV", "$(", "PPER", "VMFIN", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Da\u00df die natur zu viel an L\u00e4lien gethan/", "tokens": ["Da\u00df", "die", "na\u00b7tur", "zu", "viel", "an", "L\u00e4\u00b7li\u00b7en", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PIS", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und ihr die nase nicht nach frantzen-art gerissen.", "tokens": ["Und", "ihr", "die", "na\u00b7se", "nicht", "nach", "frant\u00b7zen\u00b7art", "ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "PTKNEG", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ich habe l\u00e4ngsten schon der sache nachgedacht/", "tokens": ["Ich", "ha\u00b7be", "l\u00e4ngs\u00b7ten", "schon", "der", "sa\u00b7che", "nach\u00b7ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Warum die k\u00fcsse sich so sparsam eingefunden/", "tokens": ["Wa\u00b7rum", "die", "k\u00fcs\u00b7se", "sich", "so", "spar\u00b7sam", "ein\u00b7ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "VVFIN", "PRF", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "So hat das lumpen-ding/ die nase/ blo\u00df gemacht/", "tokens": ["So", "hat", "das", "lum\u00b7pen\u00b7ding", "/", "die", "na\u00b7se", "/", "blo\u00df", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$(", "ART", "NN", "$(", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Da\u00df mir bey m\u00e4nnern auch ist alle gunst verschwunden.", "tokens": ["Da\u00df", "mir", "bey", "m\u00e4n\u00b7nern", "auch", "ist", "al\u00b7le", "gunst", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "ADV", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Beschimpfftes nasenloch! wie reimt sich nacht und schein?", "tokens": ["Be\u00b7schimpff\u00b7tes", "na\u00b7sen\u00b7loch", "!", "wie", "reimt", "sich", "nacht", "und", "schein", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$.", "PWAV", "VVFIN", "PRF", "NN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Wie schickt sich mist und koth zu purpur und rubinen?", "tokens": ["Wie", "schickt", "sich", "mist", "und", "koth", "zu", "pur\u00b7pur", "und", "ru\u00b7bi\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "ADJD", "KON", "ADJD", "PTKA", "ADJD", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Und dennoch soll dein schlam der liebe zunder seyn/", "tokens": ["Und", "den\u00b7noch", "soll", "dein", "schlam", "der", "lie\u00b7be", "zun\u00b7der", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPOSAT", "VVFIN", "ART", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und L\u00e4lien ihr ruhm aus deinem rotze gr\u00fcnen.", "tokens": ["Und", "L\u00e4\u00b7li\u00b7en", "ihr", "ruhm", "aus", "dei\u00b7nem", "rot\u00b7ze", "gr\u00fc\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPOSAT", "NN", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Er h\u00e4tte noch weit mehr vor eyffer ausgespien/", "tokens": ["Er", "h\u00e4t\u00b7te", "noch", "weit", "mehr", "vor", "eyf\u00b7fer", "aus\u00b7ge\u00b7spi\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADV", "APPR", "NN", "VVIZU", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.30": {"text": "Gleich aber fiengen auch die augen an zu blitzen/", "tokens": ["Gleich", "a\u00b7ber", "fi\u00b7en\u00b7gen", "auch", "die", "au\u00b7gen", "an", "zu", "blit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ADV", "ART", "NN", "APZR", "PTKZU", "VVINF", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Und sprachen: unsre glut soll eisen an sich ziehn/", "tokens": ["Und", "spra\u00b7chen", ":", "uns\u00b7re", "glut", "soll", "ei\u00b7sen", "an", "sich", "ziehn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPOSAT", "NN", "VMFIN", "ADV", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die sonne selber mu\u00df vor unsern flammen schwitzen;", "tokens": ["Die", "son\u00b7ne", "sel\u00b7ber", "mu\u00df", "vor", "un\u00b7sern", "flam\u00b7men", "schwit\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VMFIN", "APPR", "PPOSAT", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und darum haben wir offt thr\u00e4nend angesehn/", "tokens": ["Und", "da\u00b7rum", "ha\u00b7ben", "wir", "offt", "thr\u00e4\u00b7nend", "an\u00b7ge\u00b7sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Warum doch lieb und gunst so selten auff uns blicket?", "tokens": ["Wa\u00b7rum", "doch", "lieb", "und", "gunst", "so", "sel\u00b7ten", "auff", "uns", "bli\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJD", "KON", "ADV", "ADV", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Warum die meisten offt als stumme bilder gehn/", "tokens": ["Wa\u00b7rum", "die", "meis\u00b7ten", "offt", "als", "stum\u00b7me", "bil\u00b7der", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "VVFIN", "ADV", "KOUS", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und mancher flegel kaum das schmale h\u00fctgen r\u00fccket.", "tokens": ["Und", "man\u00b7cher", "fle\u00b7gel", "kaum", "das", "schma\u00b7le", "h\u00fct\u00b7gen", "r\u00fc\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "ART", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Nun aber hat die zeit den knoten auffgel\u00f6st;", "tokens": ["Nun", "a\u00b7ber", "hat", "die", "zeit", "den", "kno\u00b7ten", "auff\u00b7ge\u00b7l\u00f6st", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Denn wie der sonnen-glantz/ wenn wind und wolcken steigen/", "tokens": ["Denn", "wie", "der", "son\u00b7nen\u00b7glantz", "/", "wenn", "wind", "und", "wol\u00b7cken", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "$(", "KOUS", "NE", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Die strahlen nur umsonst aus seinem circkel st\u00f6st/", "tokens": ["Die", "strah\u00b7len", "nur", "um\u00b7sonst", "aus", "sei\u00b7nem", "cir\u00b7ckel", "st\u00f6st", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Und auch bey voller glut kan keinen schimmer zeigen/", "tokens": ["Und", "auch", "bey", "vol\u00b7ler", "glut", "kan", "kei\u00b7nen", "schim\u00b7mer", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "VMFIN", "PIAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "So brennet unser feur auch nur vergebens an:", "tokens": ["So", "bren\u00b7net", "un\u00b7ser", "feur", "auch", "nur", "ver\u00b7ge\u00b7bens", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "So lange L\u00e4lia der nase will erlauben/", "tokens": ["So", "lan\u00b7ge", "L\u00e4\u00b7lia", "der", "na\u00b7se", "will", "er\u00b7lau\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.43": {"text": "Da\u00df sie den freyen lauff uns unterbrechen kan/", "tokens": ["Da\u00df", "sie", "den", "frey\u00b7en", "lauff", "uns", "un\u00b7ter\u00b7bre\u00b7chen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PPER", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Und unsrer sonnen-glut macht licht und flamme rauben.", "tokens": ["Und", "uns\u00b7rer", "son\u00b7nen\u00b7glut", "macht", "licht", "und", "flam\u00b7me", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "NN", "KON", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wolt ihr nun dieses nicht/ was unsre kr\u00e4ffte dr\u00fcckt/", "tokens": ["Wolt", "ihr", "nun", "die\u00b7ses", "nicht", "/", "was", "uns\u00b7re", "kr\u00e4ff\u00b7te", "dr\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PDS", "PTKNEG", "$(", "PWS", "PPOSAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Ihr glieder ingesamt mit eurem schimpffe leiden;", "tokens": ["Ihr", "glie\u00b7der", "in\u00b7ge\u00b7samt", "mit", "eu\u00b7rem", "schimpf\u00b7fe", "lei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "So schafft/ da\u00df L\u00e4lia bald nach dem artzte schickt/", "tokens": ["So", "schafft", "/", "da\u00df", "L\u00e4\u00b7lia", "bald", "nach", "dem", "artz\u00b7te", "schickt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "KOUS", "NE", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.48": {"text": "Und ihr das dritte theil l\u00e4st von der nase schneiden.", "tokens": ["Und", "ihr", "das", "drit\u00b7te", "theil", "l\u00e4st", "von", "der", "na\u00b7se", "schnei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Ha possen! fielen hier die wangen ihnen ein/", "tokens": ["Ha", "pos\u00b7sen", "!", "fie\u00b7len", "hier", "die", "wan\u00b7gen", "ih\u00b7nen", "ein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVINF", "$.", "VVFIN", "ADV", "ART", "NN", "PPER", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Da\u00df unser fr\u00fchlings-feld soll vor der zeit erbleichen/", "tokens": ["Da\u00df", "un\u00b7ser", "fr\u00fch\u00b7lings\u00b7feld", "soll", "vor", "der", "zeit", "er\u00b7blei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Da\u00df thau und zucker nicht vor unsre rosen seyn/", "tokens": ["Da\u00df", "thau", "und", "zu\u00b7cker", "nicht", "vor", "uns\u00b7re", "ro\u00b7sen", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "KON", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Und uns die liebe nicht will sanffte pflaumen streichen/", "tokens": ["Und", "uns", "die", "lie\u00b7be", "nicht", "will", "sanff\u00b7te", "pflau\u00b7men", "strei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "VVFIN", "PTKNEG", "VMFIN", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Giebt eurem schmertze wohl/ ihr augen/ wenig nach;", "tokens": ["Giebt", "eu\u00b7rem", "schmert\u00b7ze", "wohl", "/", "ihr", "au\u00b7gen", "/", "we\u00b7nig", "nach", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "VVFIN", "ADV", "$(", "PPOSAT", "NN", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Da\u00df aber L\u00e4lia soll euren rath vollstrecken/", "tokens": ["Da\u00df", "a\u00b7ber", "L\u00e4\u00b7lia", "soll", "eu\u00b7ren", "rath", "voll\u00b7stre\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.55": {"text": "Wird ihrer marmel-haut nur wieder fleck und schmach/", "tokens": ["Wird", "ih\u00b7rer", "mar\u00b7mel\u00b7haut", "nur", "wie\u00b7der", "fleck", "und", "schmach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "ADV", "PTKVZ", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Uns aber allerseits nur neuen schimpff erwecken;", "tokens": ["Uns", "a\u00b7ber", "al\u00b7ler\u00b7seits", "nur", "neu\u00b7en", "schimpff", "er\u00b7we\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Aus wunden/ schnitt und blut qvillt warlich schlechte cur;", "tokens": ["Aus", "wun\u00b7den", "/", "schnitt", "und", "blut", "qvillt", "war\u00b7lich", "schlech\u00b7te", "cur", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$(", "VVFIN", "KON", "NN", "VVFIN", "ADV", "VVFIN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Ein artzt ist nicht genug hier mittel auszutheilen;", "tokens": ["Ein", "artzt", "ist", "nicht", "ge\u00b7nug", "hier", "mit\u00b7tel", "aus\u00b7zu\u00b7thei\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "PTKNEG", "ADV", "ADV", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Denn grosse nasen sind ein fehler der natur/", "tokens": ["Denn", "gros\u00b7se", "na\u00b7sen", "sind", "ein", "feh\u00b7ler", "der", "na\u00b7tur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Und lassen sich nicht so/ wie junge k\u00e4lber/ heilen.", "tokens": ["Und", "las\u00b7sen", "sich", "nicht", "so", "/", "wie", "jun\u00b7ge", "k\u00e4l\u00b7ber", "/", "hei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKNEG", "ADV", "$(", "KOKOM", "ADJA", "NN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Wohlan! versetzte drauff die auffgeschwellte brust/", "tokens": ["Wo\u00b7hlan", "!", "ver\u00b7setz\u00b7te", "drauff", "die", "auff\u00b7ge\u00b7schwell\u00b7te", "brust", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "PAV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "So mu\u00df man gleichwohl auch ein mittel ausersinnen;", "tokens": ["So", "mu\u00df", "man", "gleich\u00b7wohl", "auch", "ein", "mit\u00b7tel", "aus\u00b7er\u00b7sin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Denn da\u00df mein zucker-ei\u00df soll ohne brand und lust/", "tokens": ["Denn", "da\u00df", "mein", "zu\u00b7cke\u00b7rei\u00df", "soll", "oh\u00b7ne", "brand", "und", "lust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "VMFIN", "APPR", "NN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Und dieser perlen-schnee ohn alle glut zerrinnen/", "tokens": ["Und", "die\u00b7ser", "per\u00b7len\u00b7schnee", "ohn", "al\u00b7le", "glut", "zer\u00b7rin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Will mir und meiner haut noch keines weges ein.", "tokens": ["Will", "mir", "und", "mei\u00b7ner", "haut", "noch", "kei\u00b7nes", "we\u00b7ges", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KON", "PPOSAT", "VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Ein berg mu\u00df seine krafft aus thau und sonne saugen/", "tokens": ["Ein", "berg", "mu\u00df", "sei\u00b7ne", "krafft", "aus", "thau", "und", "son\u00b7ne", "sau\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPOSAT", "NN", "APPR", "NE", "KON", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Ein sch\u00f6ner garten mu\u00df stets voller h\u00e4nde seyn/", "tokens": ["Ein", "sch\u00f6\u00b7ner", "gar\u00b7ten", "mu\u00df", "stets", "vol\u00b7ler", "h\u00e4n\u00b7de", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "VMFIN", "ADV", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Und \u00e4pffel/ die nur bl\u00fchn/ und nicht zu brechen taugen/", "tokens": ["Und", "\u00e4pf\u00b7fel", "/", "die", "nur", "bl\u00fchn", "/", "und", "nicht", "zu", "bre\u00b7chen", "tau\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$(", "PRELS", "ADV", "VVINF", "$(", "KON", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Sind keiner augen werth. Ist nun mein liebes-feld", "tokens": ["Sind", "kei\u00b7ner", "au\u00b7gen", "werth", ".", "Ist", "nun", "mein", "lie\u00b7bes\u00b7feld"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "ADJD", "$.", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "So/ wie ihr alle wi\u00dft/ mit bergen zu vergleichen/", "tokens": ["So", "/", "wie", "ihr", "al\u00b7le", "wi\u00dft", "/", "mit", "ber\u00b7gen", "zu", "ver\u00b7glei\u00b7chen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "PWAV", "PPER", "PIS", "VVFIN", "$(", "APPR", "VVINF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Wo schwimmt der balsam-thau/ der ihre krafft erh\u00e4lt?", "tokens": ["Wo", "schwimmt", "der", "bal\u00b7sam\u00b7\u00b7thau", "/", "der", "ih\u00b7re", "krafft", "er\u00b7h\u00e4lt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Wo l\u00e4st mein sonnenschein die s\u00fcsse strahlen streichen?", "tokens": ["Wo", "l\u00e4st", "mein", "son\u00b7nen\u00b7schein", "die", "s\u00fcs\u00b7se", "strah\u00b7len", "strei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Sind meine fr\u00fcchte reiff? wo bleibt die edle hand?", "tokens": ["Sind", "mei\u00b7ne", "fr\u00fcch\u00b7te", "reiff", "?", "wo", "bleibt", "die", "ed\u00b7le", "hand", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "VVFIN", "$.", "PWAV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Dir mir den zucker soll von meinen \u00e4pffeln lesen/", "tokens": ["Dir", "mir", "den", "zu\u00b7cker", "soll", "von", "mei\u00b7nen", "\u00e4pf\u00b7feln", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ART", "NN", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Und zeigen/ da\u00df mein grund nicht ausgedorrter sand/", "tokens": ["Und", "zei\u00b7gen", "/", "da\u00df", "mein", "grund", "nicht", "aus\u00b7ge\u00b7dorr\u00b7ter", "sand", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "KOUS", "PPOSAT", "NN", "PTKNEG", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Und meine spitzen nicht von stein und holtz gewesen?", "tokens": ["Und", "mei\u00b7ne", "spit\u00b7zen", "nicht", "von", "stein", "und", "holtz", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKNEG", "APPR", "ADJD", "KON", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Ich schwere bey der krafft/ die dieser purpur f\u00fchrt/", "tokens": ["Ich", "schwe\u00b7re", "bey", "der", "krafft", "/", "die", "die\u00b7ser", "pur\u00b7pur", "f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$(", "ART", "PDAT", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Und solt ich einen gleich aus Engelland verschreiben/", "tokens": ["Und", "solt", "ich", "ei\u00b7nen", "gleich", "aus", "En\u00b7gel\u00b7land", "ver\u00b7schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "ADV", "APPR", "NE", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Da\u00df doch ein garten eh' von h\u00e4nden unber\u00fchrt/", "tokens": ["Da\u00df", "doch", "ein", "gar\u00b7ten", "eh'", "von", "h\u00e4n\u00b7den", "un\u00b7be\u00b7r\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Als meine liebes-frucht soll ungebrochen bleiben.", "tokens": ["Als", "mei\u00b7ne", "lie\u00b7bes\u00b7frucht", "soll", "un\u00b7ge\u00b7bro\u00b7chen", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Doch weil der schaden hier mich nicht alleine trifft/", "tokens": ["Doch", "weil", "der", "scha\u00b7den", "hier", "mich", "nicht", "al\u00b7lei\u00b7ne", "trifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "ADV", "PPER", "PTKNEG", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "So hab ich dieses nur euch allen vorzutragen/", "tokens": ["So", "hab", "ich", "die\u00b7ses", "nur", "euch", "al\u00b7len", "vor\u00b7zu\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "ADV", "PPER", "PIS", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Da\u00df unser gantzer wunsch auff tr\u00fcbem sande schifft/", "tokens": ["Da\u00df", "un\u00b7ser", "gant\u00b7zer", "wunsch", "auff", "tr\u00fc\u00b7bem", "san\u00b7de", "schifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Wo wir die nase nicht beym Jupiter verklagen.", "tokens": ["Wo", "wir", "die", "na\u00b7se", "nicht", "beym", "Ju\u00b7pi\u00b7ter", "ver\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "PTKNEG", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.85": {"text": "Eh! nicht beym Jupiter/ bey leibe/ sprach der mund:", "tokens": ["Eh", "!", "nicht", "beym", "Ju\u00b7pi\u00b7ter", "/", "bey", "lei\u00b7be", "/", "sprach", "der", "mund", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PTKNEG", "APPRART", "NN", "$(", "APPR", "VVFIN", "$(", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.86": {"text": "Verliebte k\u00f6nnen nicht von liebes-fehlern richten;", "tokens": ["Ver\u00b7lieb\u00b7te", "k\u00f6n\u00b7nen", "nicht", "von", "lie\u00b7bes\u00b7feh\u00b7lern", "rich\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PTKNEG", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Die liebe Jupiters ist allenthalben kund/", "tokens": ["Die", "lie\u00b7be", "Ju\u00b7pi\u00b7ters", "ist", "al\u00b7len\u00b7thal\u00b7ben", "kund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Wie soll sein blinder geist denn unsre h\u00e4ndel schlichten?", "tokens": ["Wie", "soll", "sein", "blin\u00b7der", "geist", "denn", "uns\u00b7re", "h\u00e4n\u00b7del", "schlich\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPOSAT", "ADJA", "NN", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "So soll Apollo denn hierinnen richter seyn/", "tokens": ["So", "soll", "A\u00b7pol\u00b7lo", "denn", "hie\u00b7rin\u00b7nen", "rich\u00b7ter", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "KON", "PAV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Erwiederte die brust: denn klugheit/ recht und leben/", "tokens": ["Er\u00b7wie\u00b7der\u00b7te", "die", "brust", ":", "denn", "klug\u00b7heit", "/", "recht", "und", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "KON", "NN", "$(", "ADJD", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Di\u00df alles trifft bey ihm in gleicher wagen ein/", "tokens": ["Di\u00df", "al\u00b7les", "trifft", "bey", "ihm", "in", "glei\u00b7cher", "wa\u00b7gen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "APPR", "PPER", "APPR", "ADJA", "VVFIN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Und wird nach seiner art den besten ausschlag geben.", "tokens": ["Und", "wird", "nach", "sei\u00b7ner", "art", "den", "bes\u00b7ten", "aus\u00b7schlag", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Hier fielen sie der brust mit vollen stimmen bey:", "tokens": ["Hier", "fie\u00b7len", "sie", "der", "brust", "mit", "vol\u00b7len", "stim\u00b7men", "bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ADJA", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Wer aber/ fiengen bald die augen an zu fragen/", "tokens": ["Wer", "a\u00b7ber", "/", "fi\u00b7en\u00b7gen", "bald", "die", "au\u00b7gen", "an", "zu", "fra\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$(", "VVFIN", "ADV", "ART", "NN", "APZR", "PTKZU", "VVINF", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.95": {"text": "Tritt unter uns hervor/ der am bequemsten sey/", "tokens": ["Tritt", "un\u00b7ter", "uns", "her\u00b7vor", "/", "der", "am", "be\u00b7quems\u00b7ten", "sey", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "PTKVZ", "$(", "ART", "APPRART", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Die klage f\u00f6rmiglich dem richter vorzutragen?", "tokens": ["Die", "kla\u00b7ge", "f\u00f6r\u00b7mig\u00b7lich", "dem", "rich\u00b7ter", "vor\u00b7zu\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "ART", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Ich/ sprach der bleiche mund; denn weil mein corallin", "tokens": ["Ich", "/", "sprach", "der", "blei\u00b7che", "mund", ";", "denn", "weil", "mein", "co\u00b7ral\u00b7lin"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$(", "VVFIN", "ART", "ADJA", "NN", "$.", "KON", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Vor grosser hitze fast in st\u00fccke will zerspringen/", "tokens": ["Vor", "gros\u00b7ser", "hit\u00b7ze", "fast", "in", "st\u00fc\u00b7cke", "will", "zer\u00b7sprin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "APPR", "VVFIN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "So werd ich desto mehr mit reden mich bem\u00fchn/", "tokens": ["So", "werd", "ich", "des\u00b7to", "mehr", "mit", "re\u00b7den", "mich", "be\u00b7m\u00fchn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "APPR", "VVFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Und bey dem richter scharff auff frische k\u00fchlung dringen.", "tokens": ["Und", "bey", "dem", "rich\u00b7ter", "scharff", "auff", "fri\u00b7sche", "k\u00fch\u00b7lung", "drin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "VVFIN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Es sey drum/ huben drauff die wangen wieder an/", "tokens": ["Es", "sey", "drum", "/", "hu\u00b7ben", "drauff", "die", "wan\u00b7gen", "wie\u00b7der", "an", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "$(", "VVFIN", "PAV", "ART", "NN", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Vergi\u00df nur aber nicht den schaden einzuschliessen/", "tokens": ["Ver\u00b7gi\u00df", "nur", "a\u00b7ber", "nicht", "den", "scha\u00b7den", "ein\u00b7zu\u00b7schlies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "PTKNEG", "ART", "ADJA", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Den uns das plumpe loch der nasen angethan/", "tokens": ["Den", "uns", "das", "plum\u00b7pe", "loch", "der", "na\u00b7sen", "an\u00b7ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Und unsre liljen noch mit ihrem schimpffe b\u00fcssen.", "tokens": ["Und", "uns\u00b7re", "lil\u00b7jen", "noch", "mit", "ih\u00b7rem", "schimpf\u00b7fe", "b\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Was unsrer sonnen-glantz vor grosse wunder schafft/", "tokens": ["Was", "uns\u00b7rer", "son\u00b7nen\u00b7glantz", "vor", "gros\u00b7se", "wun\u00b7der", "schafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Das weist du selber wol/ versetzten hier die augen:", "tokens": ["Das", "weist", "du", "sel\u00b7ber", "wol", "/", "ver\u00b7setz\u00b7ten", "hier", "die", "au\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "$(", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Denn ein verliebter geist mu\u00df seine lebens-krafft/", "tokens": ["Denn", "ein", "ver\u00b7lieb\u00b7ter", "geist", "mu\u00df", "sei\u00b7ne", "le\u00b7bens\u00b7krafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VMFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Und seiner flammen oel aus diesen ampeln saugen.", "tokens": ["Und", "sei\u00b7ner", "flam\u00b7men", "o\u00b7el", "aus", "die\u00b7sen", "am\u00b7peln", "sau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+--+-+--++-", "measure": "iambic.hexa.relaxed"}, "line.109": {"text": "Drum pr\u00e4ge dir den punct vor allen dingen ein/", "tokens": ["Drum", "pr\u00e4\u00b7ge", "dir", "den", "punct", "vor", "al\u00b7len", "din\u00b7gen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "VVFIN", "APPR", "PIAT", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Da\u00df wir nur todten blitz aus unserm himmel schiessen/", "tokens": ["Da\u00df", "wir", "nur", "tod\u00b7ten", "blitz", "aus", "un\u00b7serm", "him\u00b7mel", "schies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "So lange die natur nicht L\u00e4lien befreyn/", "tokens": ["So", "lan\u00b7ge", "die", "na\u00b7tur", "nicht", "L\u00e4\u00b7li\u00b7en", "be\u00b7freyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PTKNEG", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Und ihr die nase mu\u00df in andre formen giessen.", "tokens": ["Und", "ihr", "die", "na\u00b7se", "mu\u00df", "in", "and\u00b7re", "for\u00b7men", "gies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VMFIN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Ha! sprach die sch\u00f6ne brust/ h\u00e4lt dieses auch nicht platz/", "tokens": ["Ha", "!", "sprach", "die", "sch\u00f6\u00b7ne", "brust", "/", "h\u00e4lt", "die\u00b7ses", "auch", "nicht", "platz", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "ART", "ADJA", "NN", "$(", "VVFIN", "PDS", "ADV", "PTKNEG", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "So wird mein marmel-blick doch deine zunge sch\u00e4rffen;", "tokens": ["So", "wird", "mein", "mar\u00b7mel\u00b7blick", "doch", "dei\u00b7ne", "zun\u00b7ge", "sch\u00e4rf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Denn wo di\u00df paradie\u00df/ wo dieser garten-schatz", "tokens": ["Denn", "wo", "di\u00df", "pa\u00b7ra\u00b7die\u00df", "/", "wo", "die\u00b7ser", "gar\u00b7ten\u00b7schatz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWAV", "PDS", "VVFIN", "$(", "PWAV", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Die lebens-fr\u00fcchte soll der s\u00e4ulung unterwerffen/", "tokens": ["Die", "le\u00b7bens\u00b7fr\u00fcch\u00b7te", "soll", "der", "s\u00e4u\u00b7lung", "un\u00b7ter\u00b7werf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "So m\u00f6gt ihr auch nur bald nach eurem grabe gehn.", "tokens": ["So", "m\u00f6gt", "ihr", "auch", "nur", "bald", "nach", "eu\u00b7rem", "gra\u00b7be", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Denn was der strenge blitz der muschel-runden augen/", "tokens": ["Denn", "was", "der", "stren\u00b7ge", "blitz", "der", "mu\u00b7schel\u00b7run\u00b7den", "au\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Was mund und wange hei\u00dft in tausend flammen stehn/", "tokens": ["Was", "mund", "und", "wan\u00b7ge", "hei\u00dft", "in", "tau\u00b7send", "flam\u00b7men", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "NN", "VVFIN", "APPR", "CARD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Mu\u00df wieder perlen-milch aus diesen \u00e4pffeln saugen.", "tokens": ["Mu\u00df", "wie\u00b7der", "per\u00b7len\u00b7milch", "aus", "die\u00b7sen", "\u00e4pf\u00b7feln", "sau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "APPR", "PDAT", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Ich brauche/ sprach der mund/ so vieler lehren nicht.", "tokens": ["Ich", "brau\u00b7che", "/", "sprach", "der", "mund", "/", "so", "vie\u00b7ler", "leh\u00b7ren", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "ART", "NN", "$(", "ADV", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Schickt nur zum richter hin/ und last die nase laden;", "tokens": ["Schickt", "nur", "zum", "rich\u00b7ter", "hin", "/", "und", "last", "die", "na\u00b7se", "la\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$(", "KON", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Denn red ich \u00e4rmster nicht nach meiner schuld und pflicht/", "tokens": ["Denn", "red", "ich", "\u00e4rms\u00b7ter", "nicht", "nach", "mei\u00b7ner", "schuld", "und", "pflicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKNEG", "APPR", "PPOSAT", "ADJD", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "So wird der ausgang mir am allermeisten schaden.", "tokens": ["So", "wird", "der", "aus\u00b7gang", "mir", "am", "al\u00b7ler\u00b7meis\u00b7ten", "scha\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "VVFIN", "PPER", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Drauff ward den augenblick das ruder fortger\u00fcckt/", "tokens": ["Drauff", "ward", "den", "au\u00b7gen\u00b7blick", "das", "ru\u00b7der", "fort\u00b7ge\u00b7r\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Und das erz\u00f6rnte schiff in freye see getrieben;", "tokens": ["Und", "das", "er\u00b7z\u00f6rn\u00b7te", "schiff", "in", "frey\u00b7e", "see", "ge\u00b7trie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VVFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Apollo nahm es an. Die nase ward beschickt/", "tokens": ["A\u00b7pol\u00b7lo", "nahm", "es", "an", ".", "Die", "na\u00b7se", "ward", "be\u00b7schickt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Und eine tagefarth zum klagen ausgeschrieben.", "tokens": ["Und", "ei\u00b7ne", "ta\u00b7ge\u00b7farth", "zum", "kla\u00b7gen", "aus\u00b7ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Als nun der liebe tag nach vieler angst erschien/", "tokens": ["Als", "nun", "der", "lie\u00b7be", "tag", "nach", "vie\u00b7ler", "angst", "er\u00b7schien", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Und schon Apollo war auff seinen thron gestiegen/", "tokens": ["Und", "schon", "A\u00b7pol\u00b7lo", "war", "auff", "sei\u00b7nen", "thron", "ge\u00b7stie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Von dem hier diamant/ dort jaspis und rubin", "tokens": ["Von", "dem", "hier", "di\u00b7a\u00b7mant", "/", "dort", "jas\u00b7pis", "und", "ru\u00b7bin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "ADJD", "$(", "ADV", "ADJD", "KON", "NE"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.132": {"text": "Auff das gesamte volck lie\u00df tausend blicke fliegen:", "tokens": ["Auff", "das", "ge\u00b7sam\u00b7te", "volck", "lie\u00df", "tau\u00b7send", "bli\u00b7cke", "flie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "ADJD", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Als/ sag' ich/ sich nunmehr die kl\u00e4ger eingestellt/", "tokens": ["Als", "/", "sag'", "ich", "/", "sich", "nun\u00b7mehr", "die", "kl\u00e4\u00b7ger", "ein\u00b7ge\u00b7stellt", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "VVFIN", "PPER", "$(", "PRF", "ADV", "ART", "ADJA", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Kam endlich auch zuletzt die nase vorgetreten/", "tokens": ["Kam", "end\u00b7lich", "auch", "zu\u00b7letzt", "die", "na\u00b7se", "vor\u00b7ge\u00b7tre\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Und hatt' ihr/ weil ein weib im reden leicht verf\u00e4llt/", "tokens": ["Und", "hatt'", "ihr", "/", "weil", "ein", "weib", "im", "re\u00b7den", "leicht", "ver\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "$(", "KOUS", "ART", "NN", "APPRART", "VVINF", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Der Venus kleinen sohn zum beystand auserbeten.", "tokens": ["Der", "Ve\u00b7nus", "klei\u00b7nen", "sohn", "zum", "beys\u00b7tand", "au\u00b7ser\u00b7be\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPRART", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Sein leib war diesesmahl mit sammet angelegt/", "tokens": ["Sein", "leib", "war", "die\u00b7ses\u00b7mahl", "mit", "sam\u00b7met", "an\u00b7ge\u00b7legt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "APPR", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Die hand trug buch und schrifft vor k\u00f6cher/ pfeil und bogen/", "tokens": ["Die", "hand", "trug", "buch", "und", "schrifft", "vor", "k\u00f6\u00b7cher", "/", "pfeil", "und", "bo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "VVFIN", "APPR", "ADJA", "$(", "VVIMP", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "Auff jenes war das bild der mutter abgepr\u00e4gt/", "tokens": ["Auff", "je\u00b7nes", "war", "das", "bild", "der", "mut\u00b7ter", "ab\u00b7ge\u00b7pr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.140": {"text": "Und dieses war zur pracht mit scharlach \u00fcberzogen.", "tokens": ["Und", "die\u00b7ses", "war", "zur", "pracht", "mit", "schar\u00b7lach", "\u00fc\u00b7berz\u00b7o\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "APPRART", "NN", "APPR", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Als dieses auch geschehn/ da trat der mund herf\u00fcr/", "tokens": ["Als", "die\u00b7ses", "auch", "ge\u00b7schehn", "/", "da", "trat", "der", "mund", "her\u00b7f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "VVPP", "$(", "ADV", "VVFIN", "ART", "NN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "Und brachte voller zorn sein eyfriges verlangen", "tokens": ["Und", "brach\u00b7te", "vol\u00b7ler", "zorn", "sein", "ey\u00b7fri\u00b7ges", "ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJA", "NN", "PPOSAT", "ADJA", "VVINF"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.143": {"text": "Mit diesen worten an: Gerechter f\u00fcrst/ vor dir", "tokens": ["Mit", "die\u00b7sen", "wor\u00b7ten", "an", ":", "Ge\u00b7rech\u00b7ter", "f\u00fcrst", "/", "vor", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PDAT", "NN", "PTKVZ", "$.", "NN", "ADV", "$(", "APPR", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "Erscheinen wir anitzt/ mund/ auge/ brust und wangen/", "tokens": ["Er\u00b7schei\u00b7nen", "wir", "a\u00b7nitzt", "/", "mund", "/", "au\u00b7ge", "/", "brust", "und", "wan\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$(", "NN", "$(", "NN", "$(", "VVFIN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Und klagen ingesammt: Was massen die natur/", "tokens": ["Und", "kla\u00b7gen", "in\u00b7ge\u00b7sammt", ":", "Was", "mas\u00b7sen", "die", "na\u00b7tur", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "PWS", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Als sie der L\u00e4lien die geister eingegossen/", "tokens": ["Als", "sie", "der", "L\u00e4\u00b7li\u00b7en", "die", "geis\u00b7ter", "ein\u00b7ge\u00b7gos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Und milch und honigseim in ihre lippen fuhr/", "tokens": ["Und", "milch", "und", "ho\u00b7ni\u00b7gseim", "in", "ih\u00b7re", "lip\u00b7pen", "fuhr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "Zwar endlich ihren leib mit grosser kunst geschlossen;", "tokens": ["Zwar", "end\u00b7lich", "ih\u00b7ren", "leib", "mit", "gros\u00b7ser", "kunst", "ge\u00b7schlos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Als aber nach der zeit die glieder sich gestreckt/", "tokens": ["Als", "a\u00b7ber", "nach", "der", "zeit", "die", "glie\u00b7der", "sich", "ge\u00b7streckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "ART", "NN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Hat sich die nase dort ie mehr und mehr erhoben/", "tokens": ["Hat", "sich", "die", "na\u00b7se", "dort", "ie", "mehr", "und", "mehr", "er\u00b7ho\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ART", "NN", "ADV", "ADV", "ADV", "KON", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Bi\u00df sie der augen licht/ wie nebel/ \u00fcberdeckt/", "tokens": ["Bi\u00df", "sie", "der", "au\u00b7gen", "licht", "/", "wie", "ne\u00b7bel", "/", "\u00fc\u00b7berd\u00b7eckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "$(", "KOKOM", "NE", "$(", "VVPP", "$("], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.152": {"text": "Und wie ein fichten-baum in kurtzem auffgeschoben.", "tokens": ["Und", "wie", "ein", "fich\u00b7ten\u00b7baum", "in", "kurt\u00b7zem", "auff\u00b7ge\u00b7scho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "APPR", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Wann dann nun scheinbar ist/ da\u00df diese frevel-that", "tokens": ["Wann", "dann", "nun", "schein\u00b7bar", "ist", "/", "da\u00df", "die\u00b7se", "fre\u00b7vel\u00b7that"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "ADJD", "VAFIN", "$(", "KOUS", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Uns allen bey der welt zum schimpffe mu\u00df gereichen/", "tokens": ["Uns", "al\u00b7len", "bey", "der", "welt", "zum", "schimpf\u00b7fe", "mu\u00df", "ge\u00b7rei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "APPR", "ART", "NN", "APPRART", "VVFIN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Indem mein carmasin sich fast verfinstert hat/", "tokens": ["In\u00b7dem", "mein", "car\u00b7ma\u00b7sin", "sich", "fast", "ver\u00b7fins\u00b7tert", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "Und meiner rosen blut vor kummer will erbleichen;", "tokens": ["Und", "mei\u00b7ner", "ro\u00b7sen", "blut", "vor", "kum\u00b7mer", "will", "er\u00b7blei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "APPR", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "Indem der augen blitz vergebens sich bem\u00fcht", "tokens": ["In\u00b7dem", "der", "au\u00b7gen", "blitz", "ver\u00b7ge\u00b7bens", "sich", "be\u00b7m\u00fcht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVIMP", "ADV", "PRF", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Durch strahlen reiner gunst ein treues hertz zu fangen;", "tokens": ["Durch", "strah\u00b7len", "rei\u00b7ner", "gunst", "ein", "treu\u00b7es", "hertz", "zu", "fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Der purpur nur umsonst auff beyden wangen bl\u00fcht/", "tokens": ["Der", "pur\u00b7pur", "nur", "um\u00b7sonst", "auff", "bey\u00b7den", "wan\u00b7gen", "bl\u00fcht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Und schon die br\u00fcste selbst mit leerem k\u00f6cher prangen;", "tokens": ["Und", "schon", "die", "br\u00fcs\u00b7te", "selbst", "mit", "lee\u00b7rem", "k\u00f6\u00b7cher", "pran\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Indem wir/ kurtz gesagt/ der m\u00e4nner lust-spiel seyn/", "tokens": ["In\u00b7dem", "wir", "/", "kurtz", "ge\u00b7sagt", "/", "der", "m\u00e4n\u00b7ner", "lust\u00b7spiel", "seyn", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "ADJD", "VVPP", "$(", "ART", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Und tausendfachen schimpff/ auch sonder ursach/ leiden/", "tokens": ["Und", "tau\u00b7send\u00b7fa\u00b7chen", "schimpff", "/", "auch", "son\u00b7der", "ur\u00b7sach", "/", "lei\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$(", "ADV", "ADV", "ADJD", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "Wenn sie nach ihrer art uns \u00fcberall beschreyn/", "tokens": ["Wenn", "sie", "nach", "ih\u00b7rer", "art", "uns", "\u00fc\u00b7be\u00b7rall", "be\u00b7schreyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Man k\u00f6nte speck und wurst von unsrer nase schneiden:", "tokens": ["Man", "k\u00f6n\u00b7te", "speck", "und", "wurst", "von", "uns\u00b7rer", "na\u00b7se", "schnei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "NE", "KON", "VAFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Als suchen wir bey dir/ Apollo/ schutz und rath/", "tokens": ["Als", "su\u00b7chen", "wir", "bey", "dir", "/", "A\u00b7pol\u00b7lo", "/", "schutz", "und", "rath", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPR", "PPER", "$(", "NE", "$(", "ADJD", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "Und bitten ingesammt/ in rechten auszusprechen/", "tokens": ["Und", "bit\u00b7ten", "in\u00b7ge\u00b7sammt", "/", "in", "rech\u00b7ten", "aus\u00b7zu\u00b7spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$(", "APPR", "ADJA", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Da\u00df gleich den augenblick/ von wegen dieser that/", "tokens": ["Da\u00df", "gleich", "den", "au\u00b7gen\u00b7blick", "/", "von", "we\u00b7gen", "die\u00b7ser", "that", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "$(", "APPR", "APPR", "PDAT", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "Becklagte m\u00f6ge sich der L\u00e4lien entbrechen/", "tokens": ["Beck\u00b7lag\u00b7te", "m\u00f6\u00b7ge", "sich", "der", "L\u00e4\u00b7li\u00b7en", "ent\u00b7bre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VMFIN", "PRF", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Bi\u00df da\u00df ihr die natur den fehler ausgewetzt/", "tokens": ["Bi\u00df", "da\u00df", "ihr", "die", "na\u00b7tur", "den", "feh\u00b7ler", "aus\u00b7ge\u00b7wetzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.170": {"text": "Und das verwachsne fleisch vom neuen umgegossen;", "tokens": ["Und", "das", "ver\u00b7wachs\u00b7ne", "fleisch", "vom", "neu\u00b7en", "um\u00b7ge\u00b7gos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Sie aber uns/ wie recht/ den schaden hat ersetzt/", "tokens": ["Sie", "a\u00b7ber", "uns", "/", "wie", "recht", "/", "den", "scha\u00b7den", "hat", "er\u00b7setzt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPER", "$(", "PWAV", "ADJD", "$(", "ART", "ADJA", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "Der uns so lange zeit aus ihrer haut geflossen.", "tokens": ["Der", "uns", "so", "lan\u00b7ge", "zeit", "aus", "ih\u00b7rer", "haut", "ge\u00b7flos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Cupido fieng hierauff mit diesen worten an:", "tokens": ["Cu\u00b7pi\u00b7do", "fi\u00b7eng", "hier\u00b7auff", "mit", "die\u00b7sen", "wor\u00b7ten", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PAV", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.174": {"text": "Vor dir/ Apollo/ ist die nase hier erschienen/", "tokens": ["Vor", "dir", "/", "A\u00b7pol\u00b7lo", "/", "ist", "die", "na\u00b7se", "hier", "er\u00b7schie\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$(", "NE", "$(", "VAFIN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Und dingt ihr alles aus/ was etwan k\u00fcnfftig kan", "tokens": ["Und", "dingt", "ihr", "al\u00b7les", "aus", "/", "was", "et\u00b7wan", "k\u00fcnff\u00b7tig", "kan"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PIS", "PTKVZ", "$(", "PWS", "ADV", "ADJD", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Ihr/ als beklagten/ noch zu ihrer nothdurfft dienen.", "tokens": ["Ihr", "/", "als", "be\u00b7klag\u00b7ten", "/", "noch", "zu", "ih\u00b7rer", "noth\u00b7durfft", "die\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "KOKOM", "VVFIN", "$(", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Nechst diesem hat sie itzt mit mehrerm angeh\u00f6rt/", "tokens": ["Nechst", "die\u00b7sem", "hat", "sie", "itzt", "mit", "meh\u00b7rerm", "an\u00b7ge\u00b7h\u00f6rt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "VAFIN", "PPER", "ADV", "APPR", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Was massen gegentheil zu klagen sich nicht sch\u00e4met/", "tokens": ["Was", "mas\u00b7sen", "ge\u00b7gen\u00b7theil", "zu", "kla\u00b7gen", "sich", "nicht", "sch\u00e4\u00b7met", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "PTKZU", "VVINF", "PRF", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Ob h\u00e4tte sich ihr fleisch so freventlich gemehrt/", "tokens": ["Ob", "h\u00e4t\u00b7te", "sich", "ihr", "fleisch", "so", "fre\u00b7vent\u00b7lich", "ge\u00b7mehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PRF", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "Da\u00df es den augen selbst den freyen lauff gel\u00e4hmet/", "tokens": ["Da\u00df", "es", "den", "au\u00b7gen", "selbst", "den", "frey\u00b7en", "lauff", "ge\u00b7l\u00e4h\u00b7met", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Den annoch rothen mund um seine rosen bracht/", "tokens": ["Den", "an\u00b7noch", "ro\u00b7then", "mund", "um", "sei\u00b7ne", "ro\u00b7sen", "bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Den wangen und der brust die liebes-krafft benommen/", "tokens": ["Den", "wan\u00b7gen", "und", "der", "brust", "die", "lie\u00b7bes\u00b7krafft", "be\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.183": {"text": "Und endlich gar zuletzt durch seinen schimpff gemacht/", "tokens": ["Und", "end\u00b7lich", "gar", "zu\u00b7letzt", "durch", "sei\u00b7nen", "schimpff", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "Da\u00df sie bey m\u00e4nnern auch um ihre wohlfahrt kommen.", "tokens": ["Da\u00df", "sie", "bey", "m\u00e4n\u00b7nern", "auch", "um", "ih\u00b7re", "wohl\u00b7fahrt", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "ADV", "APPR", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Nun stellt beklagte di\u00df zu freyem urtheil dar:", "tokens": ["Nun", "stellt", "be\u00b7klag\u00b7te", "di\u00df", "zu", "frey\u00b7em", "ur\u00b7theil", "dar", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVFIN", "PDS", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Ob grosse nasen stets der augen glantz verr\u00fccken/", "tokens": ["Ob", "gros\u00b7se", "na\u00b7sen", "stets", "der", "au\u00b7gen", "glantz", "ver\u00b7r\u00fc\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADV", "ART", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Indem ja wohlbekandt/ und allzu offenbar/", "tokens": ["In\u00b7dem", "ja", "wohl\u00b7be\u00b7kandt", "/", "und", "all\u00b7zu", "of\u00b7fen\u00b7bar", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "$(", "KON", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.188": {"text": "Da\u00df jungfern mehrentheils nach grossen nasen blicken?", "tokens": ["Da\u00df", "jung\u00b7fern", "meh\u00b7ren\u00b7theils", "nach", "gros\u00b7sen", "na\u00b7sen", "bli\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "Und herentgegen offt sich mancher st\u00fcmper qv\u00e4lt/", "tokens": ["Und", "he\u00b7rent\u00b7ge\u00b7gen", "offt", "sich", "man\u00b7cher", "st\u00fcm\u00b7per", "qv\u00e4lt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PRF", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "Da\u00df er in lieb und pein mu\u00df ohne k\u00fchlung brennen/", "tokens": ["Da\u00df", "er", "in", "lieb", "und", "pein", "mu\u00df", "oh\u00b7ne", "k\u00fch\u00b7lung", "bren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJD", "KON", "NN", "VMFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "Weil seinem kopffe blo\u00df ein gr\u00f6sser n\u00e4\u00dfgen fehlt/", "tokens": ["Weil", "sei\u00b7nem", "kopf\u00b7fe", "blo\u00df", "ein", "gr\u00f6s\u00b7ser", "n\u00e4\u00df\u00b7gen", "fehlt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.192": {"text": "Und ihn die jungfern noch vor keinen mann erkennen.", "tokens": ["Und", "ihn", "die", "jung\u00b7fern", "noch", "vor", "kei\u00b7nen", "mann", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "ADV", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "So will sie auch nicht erst zu forschen sich bem\u00fchn/", "tokens": ["So", "will", "sie", "auch", "nicht", "erst", "zu", "for\u00b7schen", "sich", "be\u00b7m\u00fchn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "ADV", "PTKZU", "VVFIN", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.194": {"text": "Ob nicht ein einig wort die lippen offt verg\u00e4llen/", "tokens": ["Ob", "nicht", "ein", "ei\u00b7nig", "wort", "die", "lip\u00b7pen", "offt", "ver\u00b7g\u00e4l\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJD", "NN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Ein eyfrig wange kan aus sonne regen ziehn/", "tokens": ["Ein", "ey\u00b7frig", "wan\u00b7ge", "kan", "aus", "son\u00b7ne", "re\u00b7gen", "ziehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "VMFIN", "APPR", "ADJA", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Und ein erz\u00fcrnter blick den gantzen leib verstellen.", "tokens": ["Und", "ein", "er\u00b7z\u00fcrn\u00b7ter", "blick", "den", "gant\u00b7zen", "leib", "ver\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.197": {"text": "Bringt aber dieses nur entgegen-sch\u00fctzend ein/", "tokens": ["Bringt", "a\u00b7ber", "die\u00b7ses", "nur", "ent\u00b7ge\u00b7gen\u00b7sch\u00fct\u00b7zend", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PDAT", "ADV", "ADJD", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.198": {"text": "Da\u00df kl\u00e4gere sich blo\u00df aus \u00fcbermuth beschweren/", "tokens": ["Da\u00df", "kl\u00e4\u00b7ge\u00b7re", "sich", "blo\u00df", "aus", "\u00fc\u00b7ber\u00b7muth", "be\u00b7schwe\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "PRF", "ADV", "APPR", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.199": {"text": "Da\u00df sie in keiner gunst bey junggesellen seyn/", "tokens": ["Da\u00df", "sie", "in", "kei\u00b7ner", "gunst", "bey", "jung\u00b7ge\u00b7sel\u00b7len", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "NN", "APPR", "ADJA", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Und ihre lebens-krafft durch stille glut verzehren.", "tokens": ["Und", "ih\u00b7re", "le\u00b7bens\u00b7krafft", "durch", "stil\u00b7le", "glut", "ver\u00b7zeh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "Immassen sich denn schon die zeugen eingestellt/", "tokens": ["Im\u00b7mas\u00b7sen", "sich", "denn", "schon", "die", "zeu\u00b7gen", "ein\u00b7ge\u00b7stellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "ADV", "ADV", "ART", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Die ehmahls L\u00e4lien den r\u00fccken halten m\u00fcssen;", "tokens": ["Die", "eh\u00b7mahls", "L\u00e4\u00b7li\u00b7en", "den", "r\u00fc\u00b7cken", "hal\u00b7ten", "m\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.203": {"text": "Wenn Polidorens mund zu ihrem sich gesellt/", "tokens": ["Wenn", "Po\u00b7li\u00b7do\u00b7rens", "mund", "zu", "ih\u00b7rem", "sich", "ge\u00b7sellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "APPR", "PPOSAT", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.204": {"text": "Und seine seele lie\u00df in ihren purpur fliessen.", "tokens": ["Und", "sei\u00b7ne", "see\u00b7le", "lie\u00df", "in", "ih\u00b7ren", "pur\u00b7pur", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.205": {"text": "So ist zum andern falsch und irrig angebracht:", "tokens": ["So", "ist", "zum", "an\u00b7dern", "falsch", "und", "ir\u00b7rig", "an\u00b7ge\u00b7bracht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "ADJA", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.206": {"text": "Ob m\u00fcsten gegentheil der m\u00e4nner urtheil leiden/", "tokens": ["Ob", "m\u00fcs\u00b7ten", "ge\u00b7gen\u00b7theil", "der", "m\u00e4n\u00b7ner", "ur\u00b7theil", "lei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.207": {"text": "Und w\u00fcrden \u00f6ffentlich durch diesen schimpff verlacht:", "tokens": ["Und", "w\u00fcr\u00b7den", "\u00f6f\u00b7fent\u00b7lich", "durch", "die\u00b7sen", "schimpff", "ver\u00b7lacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.208": {"text": "Man k\u00f6nte speck und wurst von ihrer nase schneiden.", "tokens": ["Man", "k\u00f6n\u00b7te", "speck", "und", "wurst", "von", "ih\u00b7rer", "na\u00b7se", "schnei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "NE", "KON", "VAFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "Denn wie das gringste wort nicht zu erweisen steht.", "tokens": ["Denn", "wie", "das", "grings\u00b7te", "wort", "nicht", "zu", "er\u00b7wei\u00b7sen", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.210": {"text": "So ist ja drittens falsch/ und freventlich ersonnen/", "tokens": ["So", "ist", "ja", "drit\u00b7tens", "falsch", "/", "und", "fre\u00b7vent\u00b7lich", "er\u00b7son\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ADJD", "$(", "KON", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.211": {"text": "Da\u00df sich die nase mehr/ als rechtens ist/ erh\u00f6ht/", "tokens": ["Da\u00df", "sich", "die", "na\u00b7se", "mehr", "/", "als", "rech\u00b7tens", "ist", "/", "er\u00b7h\u00f6ht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "ADV", "$(", "KOKOM", "ADV", "VAFIN", "$(", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.212": {"text": "Und wider die natur zu grossen platz gewonnen/", "tokens": ["Und", "wi\u00b7der", "die", "na\u00b7tur", "zu", "gros\u00b7sen", "platz", "ge\u00b7won\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.213": {"text": "Indem sie/ uneracht schon mercklich dargethan/", "tokens": ["In\u00b7dem", "sie", "/", "un\u00b7e\u00b7racht", "schon", "merck\u00b7lich", "dar\u00b7ge\u00b7than", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "ADJD", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.214": {"text": "Da\u00df alle klagen sich auff schwache steltzen gr\u00fcnden/", "tokens": ["Da\u00df", "al\u00b7le", "kla\u00b7gen", "sich", "auff", "schwa\u00b7che", "stelt\u00b7zen", "gr\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "PRF", "APPR", "ADJA", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.215": {"text": "Auch noch durch diese schrifft mit ruhme zeigen kan/", "tokens": ["Auch", "noch", "durch", "die\u00b7se", "schrifft", "mit", "ruh\u00b7me", "zei\u00b7gen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PDS", "VVFIN", "APPR", "ADJA", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.216": {"text": "Da\u00df Venus selbst an ihr kan keinen tadel finden.", "tokens": ["Da\u00df", "Ve\u00b7nus", "selbst", "an", "ihr", "kan", "kei\u00b7nen", "ta\u00b7del", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "APPR", "PPER", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Weil denn nun sonnenklar aus obigen erhellt/", "tokens": ["Weil", "denn", "nun", "son\u00b7nen\u00b7klar", "aus", "o\u00b7bi\u00b7gen", "er\u00b7hellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ADJD", "APPR", "ADJA", "VVFIN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.218": {"text": "Da\u00df mehrgedachtes theil/ mund/ auge/ brust und wangen/", "tokens": ["Da\u00df", "mehr\u00b7ge\u00b7dach\u00b7tes", "theil", "/", "mund", "/", "au\u00b7ge", "/", "brust", "und", "wan\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$(", "NN", "$(", "NN", "$(", "VVFIN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.219": {"text": "Weil etwan L\u00e4lien der spiegel nicht gef\u00e4llt/", "tokens": ["Weil", "et\u00b7wan", "L\u00e4\u00b7li\u00b7en", "der", "spie\u00b7gel", "nicht", "ge\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "ART", "NN", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.220": {"text": "Aus blossem \u00fcbermuth zu rechten angefangen;", "tokens": ["Aus", "blos\u00b7sem", "\u00fc\u00b7ber\u00b7muth", "zu", "rech\u00b7ten", "an\u00b7ge\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.221": {"text": "Und aber dieser schimpff beklagter ehre kr\u00e4nckt/", "tokens": ["Und", "a\u00b7ber", "die\u00b7ser", "schimpff", "be\u00b7klag\u00b7ter", "eh\u00b7re", "kr\u00e4nckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PDS", "VVFIN", "ADJD", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "Und ieder kerl auff sie das maul noch w\u00fcrde r\u00fcmpffen;", "tokens": ["Und", "ie\u00b7der", "kerl", "auff", "sie", "das", "maul", "noch", "w\u00fcr\u00b7de", "r\u00fcmpf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "PPER", "ART", "NN", "ADV", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.223": {"text": "Hingegen die natur und alles recht gedenckt/", "tokens": ["Hin\u00b7ge\u00b7gen", "die", "na\u00b7tur", "und", "al\u00b7les", "recht", "ge\u00b7denckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "PIS", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Da\u00df keiner andre soll an seinen ehren schimpffen.", "tokens": ["Da\u00df", "kei\u00b7ner", "and\u00b7re", "soll", "an", "sei\u00b7nen", "eh\u00b7ren", "schimpf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIS", "VMFIN", "APPR", "PPOSAT", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.225": {"text": "Als fleht/ Apollo/ sie dich gantz gehorsamst an/", "tokens": ["Als", "fleht", "/", "A\u00b7pol\u00b7lo", "/", "sie", "dich", "gantz", "ge\u00b7hor\u00b7samst", "an", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "$(", "NE", "$(", "PPER", "PRF", "ADV", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "Und bittet/ kl\u00e4gere nicht lassen abzutreten/", "tokens": ["Und", "bit\u00b7tet", "/", "kl\u00e4\u00b7ge\u00b7re", "nicht", "las\u00b7sen", "ab\u00b7zu\u00b7tre\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "VVFIN", "PTKNEG", "VVINF", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Bi\u00df da\u00df sie allerseits den schaden gut gethan/", "tokens": ["Bi\u00df", "da\u00df", "sie", "al\u00b7ler\u00b7seits", "den", "scha\u00b7den", "gut", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADV", "ART", "ADJA", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "Und ihr hier \u00f6ffentlich den frevel abgebeten.", "tokens": ["Und", "ihr", "hier", "\u00f6f\u00b7fent\u00b7lich", "den", "fre\u00b7vel", "ab\u00b7ge\u00b7be\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.229": {"text": "Was aber gegentheil de\u00dfwegen w\u00fcrdig sey/", "tokens": ["Was", "a\u00b7ber", "ge\u00b7gen\u00b7theil", "de\u00df\u00b7we\u00b7gen", "w\u00fcr\u00b7dig", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "PAV", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.230": {"text": "Di\u00df alles will sie dir/ als richtern/ \u00fcberlassen/", "tokens": ["Di\u00df", "al\u00b7les", "will", "sie", "dir", "/", "als", "rich\u00b7tern", "/", "\u00fc\u00b7ber\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "PIS", "VMFIN", "PPER", "PPER", "$(", "KOKOM", "VVINF", "$(", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.231": {"text": "Und stellet/ grosser f\u00fcrst/ es deinem willen frey/", "tokens": ["Und", "stel\u00b7let", "/", "gros\u00b7ser", "f\u00fcrst", "/", "es", "dei\u00b7nem", "wil\u00b7len", "frey", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "ADJA", "NN", "$(", "PPER", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.232": {"text": "Was du vor straffen denckst im urthel abzufassen.", "tokens": ["Was", "du", "vor", "straf\u00b7fen", "denckst", "im", "ur\u00b7thel", "ab\u00b7zu\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "VVFIN", "ADV", "APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.233": {"text": "Wir bleiben (warff der mund dagegen wieder ein)", "tokens": ["Wir", "blei\u00b7ben", "(", "warff", "der", "mund", "da\u00b7ge\u00b7gen", "wie\u00b7der", "ein", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "ART", "NN", "PAV", "ADV", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.234": {"text": "Bey dem/ was wir bereits mit mehrerm vorgetragen/", "tokens": ["Bey", "dem", "/", "was", "wir", "be\u00b7reits", "mit", "meh\u00b7rerm", "vor\u00b7ge\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$(", "PWS", "PPER", "ADV", "APPR", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Und w\u00fcrde wohl so schwer nicht zu behaupten seyn/", "tokens": ["Und", "w\u00fcr\u00b7de", "wohl", "so", "schwer", "nicht", "zu", "be\u00b7haup\u00b7ten", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ADJD", "PTKNEG", "PTKZU", "VVINF", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.236": {"text": "Da\u00df grosse nasen offt bey m\u00e4nnern fehl geschlagen;", "tokens": ["Da\u00df", "gros\u00b7se", "na\u00b7sen", "offt", "bey", "m\u00e4n\u00b7nern", "fehl", "ge\u00b7schla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Doch weil beklagte sich auff blosses nein gelegt/", "tokens": ["Doch", "weil", "be\u00b7klag\u00b7te", "sich", "auff", "blos\u00b7ses", "nein", "ge\u00b7legt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "VVFIN", "PRF", "APPR", "ADJA", "PTKANT", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.238": {"text": "Und ihre m\u00e4ngel denckt mit worten auszuschmieren/", "tokens": ["Und", "ih\u00b7re", "m\u00e4n\u00b7gel", "denckt", "mit", "wor\u00b7ten", "aus\u00b7zu\u00b7schmie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.239": {"text": "So sind wir/ was die stadt von ihr zu reden pflegt/", "tokens": ["So", "sind", "wir", "/", "was", "die", "stadt", "von", "ihr", "zu", "re\u00b7den", "pflegt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$(", "PWS", "ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.240": {"text": "Auch allerseits bereit durch zeugen auszuf\u00fchren.", "tokens": ["Auch", "al\u00b7ler\u00b7seits", "be\u00b7reit", "durch", "zeu\u00b7gen", "aus\u00b7zu\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "APPR", "VVFIN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.241": {"text": "Cupido sprach hierauff: Beklagte nimmt es an/", "tokens": ["Cu\u00b7pi\u00b7do", "sprach", "hier\u00b7auff", ":", "Be\u00b7klag\u00b7te", "nimmt", "es", "an", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PAV", "$.", "NN", "VVFIN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.242": {"text": "Und bittet selber/ nur die zeugen vorzulassen.", "tokens": ["Und", "bit\u00b7tet", "sel\u00b7ber", "/", "nur", "die", "zeu\u00b7gen", "vor\u00b7zu\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$(", "ADV", "ART", "VVFIN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.243": {"text": "Gleich ward den augenblick ein rauchfa\u00df auffgethan/", "tokens": ["Gleich", "ward", "den", "au\u00b7gen\u00b7blick", "ein", "rauch\u00b7fa\u00df", "auff\u00b7ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.244": {"text": "Vor dessen reiner glut die sterne selbst erblassen.", "tokens": ["Vor", "des\u00b7sen", "rei\u00b7ner", "glut", "die", "ster\u00b7ne", "selbst", "er\u00b7blas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "ADJA", "NN", "ART", "ADJA", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.245": {"text": "Inzwischen stellten sich zwey menschen-ohren dar/", "tokens": ["I\u00b7nzwi\u00b7schen", "stell\u00b7ten", "sich", "zwey", "men\u00b7schen\u00b7oh\u00b7ren", "dar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "CARD", "NN", "PTKVZ", "$("], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.246": {"text": "Apollo aber rieff: Ich schwere bey den flammen;", "tokens": ["A\u00b7pol\u00b7lo", "a\u00b7ber", "rieff", ":", "Ich", "schwe\u00b7re", "bey", "den", "flam\u00b7men", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.247": {"text": "Macht heut' ein zeuge nicht die warheit offenbahr/", "tokens": ["Macht", "heut'", "ein", "zeu\u00b7ge", "nicht", "die", "war\u00b7heit", "of\u00b7fen\u00b7bahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "VVFIN", "PTKNEG", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.248": {"text": "Da\u00df er sich selber soll zu feur und glut verdammen.", "tokens": ["Da\u00df", "er", "sich", "sel\u00b7ber", "soll", "zu", "feur", "und", "glut", "ver\u00b7dam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VMFIN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.249": {"text": "Und hiemit fieng er an: Wem steht ihr ohren zu?", "tokens": ["Und", "hie\u00b7mit", "fi\u00b7eng", "er", "an", ":", "Wem", "steht", "ihr", "oh\u00b7ren", "zu", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.250": {"text": "Der sch\u00f6nen L\u00e4lie/ versetzten ihm die ohren.", "tokens": ["Der", "sch\u00f6\u00b7nen", "L\u00e4\u00b7lie", "/", "ver\u00b7setz\u00b7ten", "ihm", "die", "oh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.251": {"text": "Was st\u00f6ret/ sprach er/ denn der L\u00e4lien die ruh/", "tokens": ["Was", "st\u00f6\u00b7ret", "/", "sprach", "er", "/", "denn", "der", "L\u00e4\u00b7li\u00b7en", "die", "ruh", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "VVFIN", "PPER", "$(", "KON", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.252": {"text": "Und warum hat ihr mund der sch\u00f6nheit glantz verlohren?", "tokens": ["Und", "wa\u00b7rum", "hat", "ihr", "mund", "der", "sch\u00f6n\u00b7heit", "glantz", "ver\u00b7loh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "PPOSAT", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.253": {"text": "Streut etwan ha\u00df und neid verg\u00e4llte reden aus?", "tokens": ["Streut", "et\u00b7wan", "ha\u00df", "und", "neid", "ver\u00b7g\u00e4ll\u00b7te", "re\u00b7den", "aus", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVIMP", "KON", "NN", "VVFIN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.254": {"text": "Ach nein! Begegneten ihm hier die ohren wieder:", "tokens": ["Ach", "nein", "!", "Be\u00b7ge\u00b7gne\u00b7ten", "ihm", "hier", "die", "oh\u00b7ren", "wie\u00b7der", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$.", "NN", "PPER", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.255": {"text": "Der L\u00e4lien ihr muth ist wie ein lorbeer-strau\u00df;", "tokens": ["Der", "L\u00e4\u00b7li\u00b7en", "ihr", "muth", "ist", "wie", "ein", "lor\u00b7beer\u00b7strau\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.256": {"text": "Und legt die zweige nicht vor blitz und donner nieder.", "tokens": ["Und", "legt", "die", "zwei\u00b7ge", "nicht", "vor", "blitz", "und", "don\u00b7ner", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "PTKNEG", "APPR", "NE", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.257": {"text": "So mu\u00df denn/ fuhr er fort/ ein leibes-mangel seyn/", "tokens": ["So", "mu\u00df", "denn", "/", "fuhr", "er", "fort", "/", "ein", "lei\u00b7bes\u00b7man\u00b7gel", "seyn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "$(", "VVFIN", "PPER", "PTKVZ", "$(", "ART", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.258": {"text": "Um den sich L\u00e4lie mu\u00df ingeheim betr\u00fcben?", "tokens": ["Um", "den", "sich", "L\u00e4\u00b7lie", "mu\u00df", "in\u00b7ge\u00b7heim", "be\u00b7tr\u00fc\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PRF", "NE", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.259": {"text": "Ach! fielen ihm hierauff die ohren wieder ein:", "tokens": ["Ach", "!", "fie\u00b7len", "ihm", "hier\u00b7auff", "die", "oh\u00b7ren", "wie\u00b7der", "ein", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "PAV", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.260": {"text": "Welch unmensch solte wohl nicht ihre glieder lieben?", "tokens": ["Welch", "un\u00b7mensch", "sol\u00b7te", "wohl", "nicht", "ih\u00b7re", "glie\u00b7der", "lie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "VMFIN", "ADV", "PTKNEG", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.261": {"text": "Welch Momus hat iemahls hier fehler ausgesetzt?", "tokens": ["Welch", "Mo\u00b7mus", "hat", "ie\u00b7mahls", "hier", "feh\u00b7ler", "aus\u00b7ge\u00b7setzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.262": {"text": "Und wer will der natur noch pfuscher-striche weisen/", "tokens": ["Und", "wer", "will", "der", "na\u00b7tur", "noch", "pfu\u00b7scher\u00b7stri\u00b7che", "wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "ART", "NN", "ADV", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.263": {"text": "Wo selber Polidor die farben hochgesch\u00e4tzt/", "tokens": ["Wo", "sel\u00b7ber", "Po\u00b7li\u00b7dor", "die", "far\u00b7ben", "hoch\u00b7ge\u00b7sch\u00e4tzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.264": {"text": "Und tausend andre noch das meister-st\u00fccke preisen?", "tokens": ["Und", "tau\u00b7send", "and\u00b7re", "noch", "das", "meis\u00b7ter\u00b7st\u00fc\u00b7cke", "prei\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "PIS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.265": {"text": "Und gleichwohl/ sprach er/ soll die nase nicht bestehn.", "tokens": ["Und", "gleich\u00b7wohl", "/", "sprach", "er", "/", "soll", "die", "na\u00b7se", "nicht", "be\u00b7stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "VVFIN", "PPER", "$(", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.266": {"text": "Ha! widersetzten sie/ die leute sind betrogen:", "tokens": ["Ha", "!", "wi\u00b7der\u00b7setz\u00b7ten", "sie", "/", "die", "leu\u00b7te", "sind", "be\u00b7tro\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "$(", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.267": {"text": "Weil neulich L\u00e4lia sich ohngefehr versehn/", "tokens": ["Weil", "neu\u00b7lich", "L\u00e4\u00b7lia", "sich", "ohn\u00b7ge\u00b7fehr", "ver\u00b7sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "PRF", "ADJD", "VVINF", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.268": {"text": "Und durch ein falsches gla\u00df ihr selber vorgelogen.", "tokens": ["Und", "durch", "ein", "fal\u00b7sches", "gla\u00df", "ihr", "sel\u00b7ber", "vor\u00b7ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.269": {"text": "So ist sie/ fragt' er fort/ von allem tadel frey?", "tokens": ["So", "ist", "sie", "/", "fragt'", "er", "fort", "/", "von", "al\u00b7lem", "ta\u00b7del", "frey", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$(", "VVFIN", "PPER", "PTKVZ", "$(", "APPR", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.270": {"text": "Von allem/ sprachen sie; und wer es nicht will glauben/", "tokens": ["Von", "al\u00b7lem", "/", "spra\u00b7chen", "sie", ";", "und", "wer", "es", "nicht", "will", "glau\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$(", "VVFIN", "PPER", "$.", "KON", "PWS", "PPER", "PTKNEG", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.271": {"text": "Und trifft/ da\u00df L\u00e4lia deswegen traurig sey/", "tokens": ["Und", "trifft", "/", "da\u00df", "L\u00e4\u00b7lia", "des\u00b7we\u00b7gen", "trau\u00b7rig", "sey", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "NE", "PAV", "ADJD", "VAFIN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.272": {"text": "Der mag uns/ wie er will/ auff tausend foltern schrauben.", "tokens": ["Der", "mag", "uns", "/", "wie", "er", "will", "/", "auff", "tau\u00b7send", "fol\u00b7tern", "schrau\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "$(", "PWAV", "PPER", "VMFIN", "$(", "APPR", "CARD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.273": {"text": "Drauff traten beyderseits nach seinem wincken ab/", "tokens": ["Drauff", "tra\u00b7ten", "bey\u00b7der\u00b7seits", "nach", "sei\u00b7nem", "win\u00b7cken", "ab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "APPR", "PPOSAT", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.274": {"text": "Und ward den augenblick der gegenpart befohlen/", "tokens": ["Und", "ward", "den", "au\u00b7gen\u00b7blick", "der", "ge\u00b7gen\u00b7part", "be\u00b7foh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.275": {"text": "Sie solte/ weil es noch weit mehr zu richten gab/", "tokens": ["Sie", "sol\u00b7te", "/", "weil", "es", "noch", "weit", "mehr", "zu", "rich\u00b7ten", "gab", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$(", "KOUS", "PPER", "ADV", "ADJD", "ADV", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.276": {"text": "Zu besserm unterricht auch ihre zeugen holen;", "tokens": ["Zu", "bes\u00b7serm", "un\u00b7ter\u00b7richt", "auch", "ih\u00b7re", "zeu\u00b7gen", "ho\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VVFIN", "ADV", "PPOSAT", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.277": {"text": "Gleich aber brachte sie Cupido schon gef\u00fchrt/", "tokens": ["Gleich", "a\u00b7ber", "brach\u00b7te", "sie", "Cu\u00b7pi\u00b7do", "schon", "ge\u00b7f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "NE", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.278": {"text": "Und war ein gr\u00fcner stul und zinnern hand-gef\u00e4sse.", "tokens": ["Und", "war", "ein", "gr\u00fc\u00b7ner", "stul", "und", "zin\u00b7nern", "han\u00b7dge\u00b7f\u00e4s\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.279": {"text": "Nun dachte iederman/ er h\u00e4tte sich vexirt/", "tokens": ["Nun", "dach\u00b7te", "ie\u00b7der\u00b7man", "/", "er", "h\u00e4t\u00b7te", "sich", "ve\u00b7xirt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$(", "PPER", "VAFIN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.280": {"text": "Und da\u00df sein tummer kopff auff narren-balcken s\u00e4sse:", "tokens": ["Und", "da\u00df", "sein", "tum\u00b7mer", "kopff", "auff", "nar\u00b7ren\u00b7bal\u00b7cken", "s\u00e4s\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "ADJA", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.281": {"text": "Als aber bald darauff Apollo sie besprach/", "tokens": ["Als", "a\u00b7ber", "bald", "dar\u00b7auff", "A\u00b7pol\u00b7lo", "sie", "be\u00b7sprach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PAV", "NE", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.282": {"text": "Und fragt: Ob beyderseits die L\u00e4lie wohl kennten?", "tokens": ["Und", "fragt", ":", "Ob", "bey\u00b7der\u00b7seits", "die", "L\u00e4\u00b7lie", "wohl", "kenn\u00b7ten", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "KOUS", "APPR", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.283": {"text": "Da lie\u00df ein ieder auch im lachen wieder nach/", "tokens": ["Da", "lie\u00df", "ein", "ie\u00b7der", "auch", "im", "la\u00b7chen", "wie\u00b7der", "nach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PIAT", "ADV", "APPRART", "VVFIN", "ADV", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.284": {"text": "Als ihm der gr\u00fcne stuhl mit hundert complimenten", "tokens": ["Als", "ihm", "der", "gr\u00fc\u00b7ne", "stuhl", "mit", "hun\u00b7dert", "com\u00b7pli\u00b7men\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.285": {"text": "Di\u00df zu der antwort gab: Ach! kennt ich diese nicht/", "tokens": ["Di\u00df", "zu", "der", "ant\u00b7wort", "gab", ":", "Ach", "!", "kennt", "ich", "die\u00b7se", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "VVFIN", "$.", "ITJ", "$.", "VVFIN", "PPER", "PDS", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.286": {"text": "So w\u00e4re nicht zur zeit mein polster eingedr\u00fccket;", "tokens": ["So", "w\u00e4\u00b7re", "nicht", "zur", "zeit", "mein", "pols\u00b7ter", "ein\u00b7ge\u00b7dr\u00fc\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "APPRART", "NN", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.287": {"text": "Denn eben sie hat mich so sch\u00e4ndlich zugericht/", "tokens": ["Denn", "e\u00b7ben", "sie", "hat", "mich", "so", "sch\u00e4nd\u00b7lich", "zu\u00b7ge\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.288": {"text": "Wenn sie den Polidor durch k\u00fcssen gantz entz\u00fccket/", "tokens": ["Wenn", "sie", "den", "Po\u00b7li\u00b7dor", "durch", "k\u00fcs\u00b7sen", "gantz", "ent\u00b7z\u00fc\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "VVFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.289": {"text": "Den rundgew\u00f6lbten mund in seinen mund gesteckt/", "tokens": ["Den", "rund\u00b7ge\u00b7w\u00f6lb\u00b7ten", "mund", "in", "sei\u00b7nen", "mund", "ge\u00b7steckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.290": {"text": "Der lippen s\u00fcsse milch wie kinder angesogen/", "tokens": ["Der", "lip\u00b7pen", "s\u00fcs\u00b7se", "milch", "wie", "kin\u00b7der", "an\u00b7ge\u00b7so\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KOKOM", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.291": {"text": "Der wangen liebes-schnee wie zucker abgeleckt/", "tokens": ["Der", "wan\u00b7gen", "lie\u00b7bes\u00b7schnee", "wie", "zu\u00b7cker", "ab\u00b7ge\u00b7leckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KOKOM", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.292": {"text": "Und seinen schwachen geist dem hertzen nachgezogen.", "tokens": ["Und", "sei\u00b7nen", "schwa\u00b7chen", "geist", "dem", "hert\u00b7zen", "nach\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.293": {"text": "Und kennt ich diese nicht/ fieng auch das handfa\u00df an/", "tokens": ["Und", "kennt", "ich", "die\u00b7se", "nicht", "/", "fi\u00b7eng", "auch", "das", "hand\u00b7fa\u00df", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PDS", "PTKNEG", "$(", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.294": {"text": "So w\u00e4re nicht mein zinn so voller holer ballen;", "tokens": ["So", "w\u00e4\u00b7re", "nicht", "mein", "zinn", "so", "vol\u00b7ler", "ho\u00b7ler", "bal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "PPOSAT", "NN", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.295": {"text": "Denn wenn ihr \u00f6ffters schon der r\u00fccken weh gethan/", "tokens": ["Denn", "wenn", "ihr", "\u00f6ff\u00b7ters", "schon", "der", "r\u00fc\u00b7cken", "weh", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.296": {"text": "Und sie vor k\u00fcssen fast in ohnmacht wollen fallen;", "tokens": ["Und", "sie", "vor", "k\u00fcs\u00b7sen", "fast", "in", "ohn\u00b7macht", "wol\u00b7len", "fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "VVFIN", "ADV", "APPR", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.297": {"text": "So hab ich \u00e4rmstes denn die st\u00fctze m\u00fcssen seyn.", "tokens": ["So", "hab", "ich", "\u00e4rms\u00b7tes", "denn", "die", "st\u00fct\u00b7ze", "m\u00fcs\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJA", "KON", "ART", "VVFIN", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.298": {"text": "Ach! w\u00fcrde mir so viel nur wasser eingegossen/", "tokens": ["Ach", "!", "w\u00fcr\u00b7de", "mir", "so", "viel", "nur", "was\u00b7ser", "ein\u00b7ge\u00b7gos\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.299": {"text": "Als t\u00e4glich L\u00e4lien ambrirter liebes-wein", "tokens": ["Als", "t\u00e4g\u00b7lich", "L\u00e4\u00b7li\u00b7en", "am\u00b7br\u00b7ir\u00b7ter", "lie\u00b7bes\u00b7wein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "NN", "ADJA", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.300": {"text": "Von Polydoren ist in ihren mund geflossen/", "tokens": ["Von", "Po\u00b7ly\u00b7do\u00b7ren", "ist", "in", "ih\u00b7ren", "mund", "ge\u00b7flos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.301": {"text": "Hier traten sie zur\u00fcck. Und/ sprach Cupido drauff/", "tokens": ["Hier", "tra\u00b7ten", "sie", "zu\u00b7r\u00fcck", ".", "Und", "/", "sprach", "Cu\u00b7pi\u00b7do", "drauff", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "KON", "$(", "VVFIN", "NE", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.302": {"text": "Nun sieht man wo der grund der klagen ist geblieben/", "tokens": ["Nun", "sieht", "man", "wo", "der", "grund", "der", "kla\u00b7gen", "ist", "ge\u00b7blie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PWAV", "ART", "NN", "ART", "ADJA", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.303": {"text": "Doch weist beklagte noch auch dieses zeugni\u00df auff/", "tokens": ["Doch", "weist", "be\u00b7klag\u00b7te", "noch", "auch", "die\u00b7ses", "zeug\u00b7ni\u00df", "auff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVFIN", "ADV", "ADV", "PDAT", "NN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.304": {"text": "Das ihr die Venus selbst mit eigner hand geschrieben.", "tokens": ["Das", "ihr", "die", "Ve\u00b7nus", "selbst", "mit", "eig\u00b7ner", "hand", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.305": {"text": "Aus diesem buche wird ein ieder aber sehn/", "tokens": ["Aus", "die\u00b7sem", "bu\u00b7che", "wird", "ein", "ie\u00b7der", "a\u00b7ber", "sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "ART", "PIS", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.306": {"text": "Wie L\u00e4liens gesicht und Polidor sich k\u00fcssen/", "tokens": ["Wie", "L\u00e4\u00b7li\u00b7ens", "ge\u00b7sicht", "und", "Po\u00b7li\u00b7dor", "sich", "k\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVPP", "KON", "NN", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.307": {"text": "Wie artig mund auff mund zusammen buhlen stehn;", "tokens": ["Wie", "ar\u00b7tig", "mund", "auff", "mund", "zu\u00b7sam\u00b7men", "buh\u00b7len", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "NN", "APPR", "NN", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.308": {"text": "Indem die mutter sie hierinnen abgerissen.", "tokens": ["In\u00b7dem", "die", "mut\u00b7ter", "sie", "hie\u00b7rin\u00b7nen", "ab\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.309": {"text": "Hier \u00fcbergab er nun dem richter schrifft und buch/", "tokens": ["Hier", "\u00fc\u00b7berg\u00b7ab", "er", "nun", "dem", "rich\u00b7ter", "schrifft", "und", "buch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "VVFIN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.310": {"text": "Wer aber war wohl mehr als L\u00e4lia gewesen?", "tokens": ["Wer", "a\u00b7ber", "war", "wohl", "mehr", "als", "L\u00e4\u00b7lia", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "PIAT", "KOKOM", "NE", "VAPP", "$."], "meter": "-+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.311": {"text": "Apollo l\u00f6ste selbst das rothe scharlach-tuch/", "tokens": ["A\u00b7pol\u00b7lo", "l\u00f6s\u00b7te", "selbst", "das", "ro\u00b7the", "scha\u00b7rlach\u00b7tuch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.312": {"text": "Und gab die edle schrifft/ wie folget/ abzulesen:", "tokens": ["Und", "gab", "die", "ed\u00b7le", "schrifft", "/", "wie", "fol\u00b7get", "/", "ab\u00b7zu\u00b7le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "VVFIN", "$(", "PWAV", "VVFIN", "$(", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.313": {"text": "Wir Venus zeugen hier mit unsrer eignen hand/", "tokens": ["Wir", "Ve\u00b7nus", "zeu\u00b7gen", "hier", "mit", "uns\u00b7rer", "eig\u00b7nen", "hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.314": {"text": "Da\u00df wir die L\u00e4lie vor v\u00f6llig sch\u00f6n erkennen;", "tokens": ["Da\u00df", "wir", "die", "L\u00e4\u00b7lie", "vor", "v\u00f6l\u00b7lig", "sch\u00f6n", "er\u00b7ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ADJD", "ADJD", "VVINF", "$."], "meter": "----+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.315": {"text": "Und machen durch di\u00df blat der gantzen welt bekandt/", "tokens": ["Und", "ma\u00b7chen", "durch", "di\u00df", "blat", "der", "gant\u00b7zen", "welt", "be\u00b7kandt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDS", "VVFIN", "ART", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.316": {"text": "Da\u00df keiner/ der sie schimpfft/ soll unserm zorn entrennen.", "tokens": ["Da\u00df", "kei\u00b7ner", "/", "der", "sie", "schimpfft", "/", "soll", "un\u00b7serm", "zorn", "en\u00b7tren\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$(", "PRELS", "PPER", "VVFIN", "$(", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.317": {"text": "Drauff sah er in das buch/ auff Polidorens mund/", "tokens": ["Drauff", "sah", "er", "in", "das", "buch", "/", "auff", "Po\u00b7li\u00b7do\u00b7rens", "mund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "APPR", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.318": {"text": "Und sprach: wir solten wohl nun straff und urthel h\u00e4uffen:", "tokens": ["Und", "sprach", ":", "wir", "sol\u00b7ten", "wohl", "nun", "straff", "und", "ur\u00b7thel", "h\u00e4uf\u00b7fen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VMFIN", "ADV", "ADV", "VVFIN", "KON", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.319": {"text": "Allein durch dieses thut die liebes-g\u00f6ttin kund/", "tokens": ["Al\u00b7lein", "durch", "die\u00b7ses", "thut", "die", "lie\u00b7bes\u00b7g\u00f6t\u00b7tin", "kund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.320": {"text": "Da\u00df sich kein andrer soll an L\u00e4lien vergreiffen.", "tokens": ["Da\u00df", "sich", "kein", "an\u00b7drer", "soll", "an", "L\u00e4\u00b7li\u00b7en", "ver\u00b7greif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PIAT", "PIS", "VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.321": {"text": "Nun aber kan ja nicht die straffe so ergehn/", "tokens": ["Nun", "a\u00b7ber", "kan", "ja", "nicht", "die", "straf\u00b7fe", "so", "er\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "ADV", "PTKNEG", "ART", "VVFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.322": {"text": "Da\u00df nicht auch L\u00e4lia den Schaden m\u00fcste b\u00fcssen:", "tokens": ["Da\u00df", "nicht", "auch", "L\u00e4\u00b7lia", "den", "Scha\u00b7den", "m\u00fcs\u00b7te", "b\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADV", "NE", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.323": {"text": "Denn wo die glieder schon im blut und thr\u00e4nen stehn/", "tokens": ["Denn", "wo", "die", "glie\u00b7der", "schon", "im", "blut", "und", "thr\u00e4\u00b7nen", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADV", "APPRART", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.324": {"text": "Da kan das hertze nicht in muscateller fliessen.", "tokens": ["Da", "kan", "das", "hert\u00b7ze", "nicht", "in", "mus\u00b7ca\u00b7tel\u00b7ler", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PTKNEG", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.325": {"text": "Genug da\u00df Venus selbst die nase sch\u00f6n erkannt;", "tokens": ["Ge\u00b7nug", "da\u00df", "Ve\u00b7nus", "selbst", "die", "na\u00b7se", "sch\u00f6n", "er\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NN", "ADV", "ART", "ADJA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.326": {"text": "Und darum sollen sie der straffe seyn entnommen/", "tokens": ["Und", "da\u00b7rum", "sol\u00b7len", "sie", "der", "straf\u00b7fe", "seyn", "ent\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VMFIN", "PPER", "ART", "VVFIN", "PPOSAT", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.327": {"text": "Bi\u00df da\u00df ihr Polidor aus Hol- und Engeland/", "tokens": ["Bi\u00df", "da\u00df", "ihr", "Po\u00b7li\u00b7dor", "aus", "Hol", "und", "En\u00b7ge\u00b7land", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPOSAT", "NN", "APPR", "TRUNC", "KON", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.328": {"text": "Wird wieder voller lust zu seiner sonne kommen.", "tokens": ["Wird", "wie\u00b7der", "vol\u00b7ler", "lust", "zu", "sei\u00b7ner", "son\u00b7ne", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.329": {"text": "Inzwischen soll hiemit euch fest befohlen seyn/", "tokens": ["I\u00b7nzwi\u00b7schen", "soll", "hie\u00b7mit", "euch", "fest", "be\u00b7foh\u00b7len", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PAV", "PPER", "ADJD", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.330": {"text": "Da\u00df ieder k\u00fcnfftig wird dergleichen schimpff vermeiden;", "tokens": ["Da\u00df", "ie\u00b7der", "k\u00fcnff\u00b7tig", "wird", "derg\u00b7lei\u00b7chen", "schimpff", "ver\u00b7mei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VAFIN", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.331": {"text": "Im fall er nicht von uns gerechte straff und pein/", "tokens": ["Im", "fall", "er", "nicht", "von", "uns", "ge\u00b7rech\u00b7te", "straff", "und", "pein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PTKNEG", "APPR", "PPER", "ADJA", "VVFIN", "KON", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.332": {"text": "Und tausend urthel will von Polidoren leiden.", "tokens": ["Und", "tau\u00b7send", "ur\u00b7thel", "will", "von", "Po\u00b7li\u00b7do\u00b7ren", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.333": {"text": "Zuletzt bringt L\u00e4lien noch diese lehren heim:", "tokens": ["Zu\u00b7letzt", "bringt", "L\u00e4\u00b7li\u00b7en", "noch", "die\u00b7se", "leh\u00b7ren", "heim", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ADV", "PDS", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.334": {"text": "Da\u00df auch die kl\u00fcgsten wohl in ihren augen fehlen/", "tokens": ["Da\u00df", "auch", "die", "kl\u00fcgs\u00b7ten", "wohl", "in", "ih\u00b7ren", "au\u00b7gen", "feh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.335": {"text": "Und kinder offtermahls vor butter honigseim/", "tokens": ["Und", "kin\u00b7der", "off\u00b7ter\u00b7mahls", "vor", "but\u00b7ter", "ho\u00b7ni\u00b7gseim", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.336": {"text": "Die jungfern aber offt vor rosen dornen w\u00e4hlen.", "tokens": ["Die", "jung\u00b7fern", "a\u00b7ber", "offt", "vor", "ro\u00b7sen", "dor\u00b7nen", "w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}