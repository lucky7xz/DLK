{"textgrid.poem.46276": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "An die Marina", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr wisset was f\u00fcr schwere klagen,", "tokens": ["Ihr", "wis\u00b7set", "was", "f\u00fcr", "schwe\u00b7re", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "f\u00fcr gro\u00dfe schmerzen, sorg und plagen", "tokens": ["f\u00fcr", "gro\u00b7\u00dfe", "schmer\u00b7zen", ",", "sorg", "und", "pla\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "VVINF", "$,", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mich eure sch\u00f6nheit zart und rein", "tokens": ["mich", "eu\u00b7re", "sch\u00f6n\u00b7heit", "zart", "und", "rein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und eurer braunen augen schein", "tokens": ["und", "eu\u00b7rer", "brau\u00b7nen", "au\u00b7gen", "schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "schon lange zeit hat machen tragen.", "tokens": ["schon", "lan\u00b7ge", "zeit", "hat", "ma\u00b7chen", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was solt ich euch dan weiters sagen,", "tokens": ["Was", "solt", "ich", "euch", "dan", "wei\u00b7ters", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PPER", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "weil uns die lieb zugleich geschlagen,", "tokens": ["weil", "uns", "die", "lieb", "zu\u00b7gleich", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "dan das uns jetzt kan f\u00fcglich sein,", "tokens": ["dan", "das", "uns", "jetzt", "kan", "f\u00fcg\u00b7lich", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PPER", "ADV", "VMFIN", "ADJD", "VAINF", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.9": {"text": "ihr wisset was.", "tokens": ["ihr", "wis\u00b7set", "was", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Derhalben l\u00e4nger nicht zu zagen,", "tokens": ["Der\u00b7hal\u00b7ben", "l\u00e4n\u00b7ger", "nicht", "zu", "za\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "so wollet mir nu nicht versagen", "tokens": ["so", "wol\u00b7let", "mir", "nu", "nicht", "ver\u00b7sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "vil tausend k\u00fc\u00df f\u00fcr tausend pein;", "tokens": ["vil", "tau\u00b7send", "k\u00fc\u00df", "f\u00fcr", "tau\u00b7send", "pein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "VVFIN", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "und weil wir beed jetzund allein,", "tokens": ["und", "weil", "wir", "beed", "je\u00b7tzund", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "so lasset uns auch vollends wagen", "tokens": ["so", "las\u00b7set", "uns", "auch", "vol\u00b7lends", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "ihr wisset was.", "tokens": ["ihr", "wis\u00b7set", "was", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Ihr wisset was f\u00fcr schwere klagen,", "tokens": ["Ihr", "wis\u00b7set", "was", "f\u00fcr", "schwe\u00b7re", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "f\u00fcr gro\u00dfe schmerzen, sorg und plagen", "tokens": ["f\u00fcr", "gro\u00b7\u00dfe", "schmer\u00b7zen", ",", "sorg", "und", "pla\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "VVINF", "$,", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mich eure sch\u00f6nheit zart und rein", "tokens": ["mich", "eu\u00b7re", "sch\u00f6n\u00b7heit", "zart", "und", "rein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und eurer braunen augen schein", "tokens": ["und", "eu\u00b7rer", "brau\u00b7nen", "au\u00b7gen", "schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "schon lange zeit hat machen tragen.", "tokens": ["schon", "lan\u00b7ge", "zeit", "hat", "ma\u00b7chen", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was solt ich euch dan weiters sagen,", "tokens": ["Was", "solt", "ich", "euch", "dan", "wei\u00b7ters", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PPER", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "weil uns die lieb zugleich geschlagen,", "tokens": ["weil", "uns", "die", "lieb", "zu\u00b7gleich", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "dan das uns jetzt kan f\u00fcglich sein,", "tokens": ["dan", "das", "uns", "jetzt", "kan", "f\u00fcg\u00b7lich", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PPER", "ADV", "VMFIN", "ADJD", "VAINF", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.9": {"text": "ihr wisset was.", "tokens": ["ihr", "wis\u00b7set", "was", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Derhalben l\u00e4nger nicht zu zagen,", "tokens": ["Der\u00b7hal\u00b7ben", "l\u00e4n\u00b7ger", "nicht", "zu", "za\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "so wollet mir nu nicht versagen", "tokens": ["so", "wol\u00b7let", "mir", "nu", "nicht", "ver\u00b7sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "vil tausend k\u00fc\u00df f\u00fcr tausend pein;", "tokens": ["vil", "tau\u00b7send", "k\u00fc\u00df", "f\u00fcr", "tau\u00b7send", "pein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "VVFIN", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "und weil wir beed jetzund allein,", "tokens": ["und", "weil", "wir", "beed", "je\u00b7tzund", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "so lasset uns auch vollends wagen", "tokens": ["so", "las\u00b7set", "uns", "auch", "vol\u00b7lends", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "ihr wisset was.", "tokens": ["ihr", "wis\u00b7set", "was", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}