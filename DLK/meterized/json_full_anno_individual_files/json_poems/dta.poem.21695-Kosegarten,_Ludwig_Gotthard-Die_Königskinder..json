{"dta.poem.21695": {"metadata": {"author": {"name": "Kosegarten, Ludwig Gotthard", "birth": "N.A.", "death": "N.A."}, "title": "Die K\u00f6nigskinder.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1802", "urn": "urn:nbn:de:kobv:b4-200905193310", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es waren einmal zwey K\u00f6nigskinder,", "tokens": ["Es", "wa\u00b7ren", "ein\u00b7mal", "zwey", "K\u00f6\u00b7nigs\u00b7kin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "CARD", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Frisch junges frommes Blut.", "tokens": ["Frisch", "jun\u00b7ges", "from\u00b7mes", "Blut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es war dem Knaben das M\u00e4gdlein,", "tokens": ["Es", "war", "dem", "Kna\u00b7ben", "das", "M\u00e4gd\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Dem M\u00e4gdlein der Knabe gut.", "tokens": ["Dem", "M\u00e4gd\u00b7lein", "der", "Kna\u00b7be", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "\u201esag an allersch\u00f6nste Jungfrau,", "tokens": ["\u201e", "sag", "an", "al\u00b7ler\u00b7sch\u00f6ns\u00b7te", "Jung\u00b7frau", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u201ewie mag ich kommen zu Dir?", "tokens": ["\u201e", "wie", "mag", "ich", "kom\u00b7men", "zu", "Dir", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u201eein grosses wildes Wasser", "tokens": ["\u201e", "ein", "gros\u00b7ses", "wil\u00b7des", "Was\u00b7ser"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201efliesst zwischen dir und mir.\u201c \u2014", "tokens": ["\u201e", "fliesst", "zwi\u00b7schen", "dir", "und", "mir", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "VVFIN", "APPR", "PPER", "KON", "PPER", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "\u201ezieh aus die Kleider, zieh aus die Schuh.", "tokens": ["\u201e", "zieh", "aus", "die", "Klei\u00b7der", ",", "zieh", "aus", "die", "Schuh", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "APPR", "ART", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u201erudre frisch mit Fuss und Hand.", "tokens": ["\u201e", "rud\u00b7re", "frisch", "mit", "Fuss", "und", "Hand", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADJD", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u201eich will in der Leuchten ein Licht anstecken,", "tokens": ["\u201e", "ich", "will", "in", "der", "Leuch\u00b7ten", "ein", "Licht", "an\u00b7ste\u00b7cken", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "\u201edas leuchtet dich sicher ans Land.\u201c \u2014", "tokens": ["\u201e", "das", "leuch\u00b7tet", "dich", "si\u00b7cher", "ans", "Land", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PDS", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$.", "$(", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "Ein Schalk vernahm die Rede,", "tokens": ["Ein", "Schalk", "ver\u00b7nahm", "die", "Re\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Trug arge List im Sinn.", "tokens": ["Trug", "ar\u00b7ge", "List", "im", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eder Liebschaft will ich steuren,", "tokens": ["\u201e", "der", "Lieb\u00b7schaft", "will", "ich", "steu\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201edieweil ich lebend bin.\u201c \u2014", "tokens": ["\u201e", "die\u00b7weil", "ich", "le\u00b7bend", "bin", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ADJD", "VAFIN", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Dass Gott dich strafe du arger Schalk!", "tokens": ["Dass", "Gott", "dich", "stra\u00b7fe", "du", "ar\u00b7ger", "Schalk", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dass Gott dich verderbe zur Stunde! \u2014", "tokens": ["Dass", "Gott", "dich", "ver\u00b7der\u00b7be", "zur", "Stun\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "APPRART", "NN", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Er blies das Licht in der Leuchten aus.", "tokens": ["Er", "blies", "das", "Licht", "in", "der", "Leuch\u00b7ten", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der K\u00f6nigssohn ging zu Grunde.", "tokens": ["Der", "K\u00f6\u00b7nigs\u00b7sohn", "ging", "zu", "Grun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Ein Hofbursch trat zur Th\u00fcr herein,", "tokens": ["Ein", "Hof\u00b7bursch", "trat", "zur", "Th\u00fcr", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl vor die Tafelrunde.", "tokens": ["Wohl", "vor", "die", "Ta\u00b7fel\u00b7run\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es war ein B\u00fcrschchen h\u00fcbsch und fein,", "tokens": ["Es", "war", "ein", "B\u00fcr\u00b7schchen", "h\u00fcbsch", "und", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und flink von Sinn und Munde.", "tokens": ["Und", "flink", "von", "Sinn", "und", "Mun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "\u201egott gr\u00fcss' euch, ihr Frauen und Fr\u00e4ulein,", "tokens": ["\u201e", "gott", "gr\u00fcss'", "euch", ",", "ihr", "Frau\u00b7en", "und", "Fr\u00e4u\u00b7lein", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "\u201egott gesegn' euch Essen und Trinken.", "tokens": ["\u201e", "gott", "ge\u00b7segn'", "euch", "Es\u00b7sen", "und", "Trin\u00b7ken", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "\u201eich sah einen wackern K\u00f6nigssohn,", "tokens": ["\u201e", "ich", "sah", "ei\u00b7nen", "wa\u00b7ckern", "K\u00f6\u00b7nigs\u00b7sohn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "\u201eich sah ihn schwimmen und sinken.\u201c", "tokens": ["\u201e", "ich", "sah", "ihn", "schwim\u00b7men", "und", "sin\u00b7ken", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "VVINF", "KON", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Die Frauen und Fr\u00e4ulein sie fuhren auf", "tokens": ["Die", "Frau\u00b7en", "und", "Fr\u00e4u\u00b7lein", "sie", "fuh\u00b7ren", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "PPER", "VVFIN", "APPR"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Von ihren scharlachenen Sesseln.", "tokens": ["Von", "ih\u00b7ren", "schar\u00b7la\u00b7che\u00b7nen", "Ses\u00b7seln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gar \u00fcbel sich die sch\u00f6ne K\u00f6nigstochter gehub.", "tokens": ["Gar", "\u00fc\u00b7bel", "sich", "die", "sch\u00f6\u00b7ne", "K\u00f6\u00b7nig\u00b7stoch\u00b7ter", "ge\u00b7hub", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PRF", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Sie sass wie auf Disteln und Nesseln.", "tokens": ["Sie", "sass", "wie", "auf", "Dis\u00b7teln", "und", "Nes\u00b7seln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.9": {"line.1": {"text": "\u201each Mutter, herzliebe Mutter,", "tokens": ["\u201e", "ach", "Mut\u00b7ter", ",", "herz\u00b7lie\u00b7be", "Mut\u00b7ter", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "XY", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u201espatzieren m\u00f6gt' ich gehn.", "tokens": ["\u201e", "spat\u00b7zie\u00b7ren", "m\u00f6gt'", "ich", "gehn", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVINF", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201everg\u00f6nnt mir zu gehn in den gr\u00fcnen Wald", "tokens": ["\u201e", "ver\u00b7g\u00f6nnt", "mir", "zu", "gehn", "in", "den", "gr\u00fc\u00b7nen", "Wald"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPER", "PTKZU", "VVINF", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "\u201ewo die sch\u00f6nen Bl\u00fcmlein stehn.\u201c \u2014", "tokens": ["\u201e", "wo", "die", "sch\u00f6\u00b7nen", "Bl\u00fcm\u00b7lein", "stehn", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PWAV", "ART", "ADJA", "NN", "VVINF", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "\u201edu magst wohl gehn in den gr\u00fcnen Wald", "tokens": ["\u201e", "du", "magst", "wohl", "gehn", "in", "den", "gr\u00fc\u00b7nen", "Wald"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ADV", "VVINF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201ewo die sch\u00f6nen Bl\u00fcmlein stehn.\u201c \u2014", "tokens": ["\u201e", "wo", "die", "sch\u00f6\u00b7nen", "Bl\u00fcm\u00b7lein", "stehn", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PWAV", "ART", "ADJA", "NN", "VVINF", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u201edoch wecke dein j\u00fcngstes Schwesterlein auf", "tokens": ["\u201e", "doch", "we\u00b7cke", "dein", "j\u00fcngs\u00b7tes", "Schwes\u00b7ter\u00b7lein", "auf"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201eund lass es mit dir gehn.\u201c \u2014", "tokens": ["\u201e", "und", "lass", "es", "mit", "dir", "gehn", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "APPR", "PPER", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "\u201each Mutter, herzliebe Mutter,", "tokens": ["\u201e", "ach", "Mut\u00b7ter", ",", "herz\u00b7lie\u00b7be", "Mut\u00b7ter", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "XY", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u201egar lustig ists am Strand.", "tokens": ["\u201e", "gar", "lus\u00b7tig", "ists", "am", "Strand", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "VAFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201everg\u00f6nnt mir zu gehn an das Wasser,", "tokens": ["\u201e", "ver\u00b7g\u00f6nnt", "mir", "zu", "gehn", "an", "das", "Was\u00b7ser", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "\u201eauf dem sch\u00f6nen weissen Sand.\u201c \u2014", "tokens": ["\u201e", "auf", "dem", "sch\u00f6\u00b7nen", "weis\u00b7sen", "Sand", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "APPR", "ART", "ADJA", "ADJA", "NN", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "\u201edu magst wohl gehn an das Wasser,", "tokens": ["\u201e", "du", "magst", "wohl", "gehn", "an", "das", "Was\u00b7ser", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201eauf dem sch\u00f6nen weissen Sand.", "tokens": ["\u201e", "auf", "dem", "sch\u00f6\u00b7nen", "weis\u00b7sen", "Sand", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u201edoch wecke dein j\u00fcngstes Br\u00fcderchen auf", "tokens": ["\u201e", "doch", "we\u00b7cke", "dein", "j\u00fcngs\u00b7tes", "Br\u00fc\u00b7der\u00b7chen", "auf"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201eund nimm es mit an Strand.\u201c \u2014", "tokens": ["\u201e", "und", "nimm", "es", "mit", "an", "Strand", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "KON", "VVIMP", "PPER", "APPR", "APPR", "NN", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "\u201emein Bruder und meine Schwester", "tokens": ["\u201e", "mein", "Bru\u00b7der", "und", "mei\u00b7ne", "Schwes\u00b7ter"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u201esie haben noch keinen Verstand.", "tokens": ["\u201e", "sie", "ha\u00b7ben", "noch", "kei\u00b7nen", "Ver\u00b7stand", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "\u201esie pfl\u00fccken die sch\u00f6nsten Blumen ab", "tokens": ["\u201e", "sie", "pfl\u00fc\u00b7cken", "die", "sch\u00f6ns\u00b7ten", "Blu\u00b7men", "ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201eund f\u00fcllen die Schuhe mit Sand!\u201c", "tokens": ["\u201e", "und", "f\u00fcl\u00b7len", "die", "Schu\u00b7he", "mit", "Sand", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "ART", "NN", "APPR", "NN", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.14": {"line.1": {"text": "Die Jungfrau schied von dannen", "tokens": ["Die", "Jung\u00b7frau", "schied", "von", "dan\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ging traurig an den Strand.", "tokens": ["Ging", "trau\u00b7rig", "an", "den", "Strand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da fand sie wohl einen Fischer", "tokens": ["Da", "fand", "sie", "wohl", "ei\u00b7nen", "Fi\u00b7scher"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der fischete hart am Land.", "tokens": ["Der", "fi\u00b7sche\u00b7te", "hart", "am", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "APPRART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "\u201egott gr\u00fcss euch, herzlieber Fischer,", "tokens": ["\u201e", "gott", "gr\u00fcss", "euch", ",", "herz\u00b7lie\u00b7ber", "Fi\u00b7scher", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "$,", "ADV", "NE", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "\u201ewas bracht' euch euer Fang?", "tokens": ["\u201e", "was", "bracht'", "euch", "eu\u00b7er", "Fang", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201ehabt ihr nicht gefischt einen K\u00f6nigssohn,", "tokens": ["\u201e", "habt", "ihr", "nicht", "ge\u00b7fischt", "ei\u00b7nen", "K\u00f6\u00b7nigs\u00b7sohn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "PTKNEG", "VVPP", "ART", "NN", "$,"], "meter": "+----+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "\u201eden die wilde Fluth verschlang?\u201c \u2014", "tokens": ["\u201e", "den", "die", "wil\u00b7de", "Fluth", "ver\u00b7schlang", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ART", "ART", "ADJA", "NN", "VVFIN", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "\u201eich hab' gefischt den ganzen Tag,", "tokens": ["\u201e", "ich", "hab'", "ge\u00b7fischt", "den", "gan\u00b7zen", "Tag", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "VVPP", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edie Nacht so schwarz und lang.", "tokens": ["\u201e", "die", "Nacht", "so", "schwarz", "und", "lang", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eich hab' gefischt einen K\u00f6nigssohn,", "tokens": ["\u201e", "ich", "hab'", "ge\u00b7fischt", "ei\u00b7nen", "K\u00f6\u00b7nigs\u00b7sohn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "VVPP", "ART", "NN", "$,"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "\u201eder hier zu Grunde sank.\u201c \u2014", "tokens": ["\u201e", "der", "hier", "zu", "Grun\u00b7de", "sank", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ART", "ADV", "APPR", "NN", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "\u201egar \u00fcbel gehub sich die K\u00f6nigstochter;", "tokens": ["\u201e", "gar", "\u00fc\u00b7bel", "ge\u00b7hub", "sich", "die", "K\u00f6\u00b7nig\u00b7stoch\u00b7ter", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u201esie weinte, sie klagte, sie sprach:", "tokens": ["\u201e", "sie", "wein\u00b7te", ",", "sie", "klag\u00b7te", ",", "sie", "sprach", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "\u201eist mein Herzliebster todt und hin,", "tokens": ["\u201e", "ist", "mein", "Herz\u00b7liebs\u00b7ter", "todt", "und", "hin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPOSAT", "NN", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201enicht mehr ich leben mag.\u201c", "tokens": ["\u201e", "nicht", "mehr", "ich", "le\u00b7ben", "mag.", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["$(", "PTKNEG", "ADV", "PPER", "VVFIN", "NE", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.18": {"line.1": {"text": "\u201esie nahm das goldene Kettlein vom Hals,", "tokens": ["\u201e", "sie", "nahm", "das", "gol\u00b7de\u00b7ne", "Ket\u00b7tlein", "vom", "Hals", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201evom Arm die Spange noch warm;", "tokens": ["\u201e", "vom", "Arm", "die", "Span\u00b7ge", "noch", "warm", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u201egab Spang' und Kettlein dem Fischer,", "tokens": ["\u201e", "gab", "Spang'", "und", "Ket\u00b7tlein", "dem", "Fi\u00b7scher", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NE", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u201eund nahm ihren Liebsten in Arm.\u201c", "tokens": ["\u201e", "und", "nahm", "ih\u00b7ren", "Liebs\u00b7ten", "in", "Arm", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.19": {"line.1": {"text": "\u201egute Nacht nun herzliebe Mutter,", "tokens": ["\u201e", "gu\u00b7te", "Nacht", "nun", "herz\u00b7lie\u00b7be", "Mut\u00b7ter", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "\u201egute Nacht, lieb Vater und Br\u00fcder.", "tokens": ["\u201e", "gu\u00b7te", "Nacht", ",", "lieb", "Va\u00b7ter", "und", "Br\u00fc\u00b7der", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "ADJD", "NN", "KON", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "\u201egute Nacht ihr s\u00fcssen Schwesterlein,", "tokens": ["\u201e", "gu\u00b7te", "Nacht", "ihr", "s\u00fcs\u00b7sen", "Schwes\u00b7ter\u00b7lein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "\u201eich seh' euch nimmer wieder.\u201c", "tokens": ["\u201e", "ich", "seh'", "euch", "nim\u00b7mer", "wie\u00b7der", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "\u201eich gr\u00fcss euch zu tausendmalen,", "tokens": ["\u201e", "ich", "gr\u00fcss", "euch", "zu", "tau\u00b7send\u00b7ma\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201eund bitt' euch, habt nicht Harm! !", "tokens": ["\u201e", "und", "bitt'", "euch", ",", "habt", "nicht", "Harm", "!", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "$,", "VAFIN", "PTKNEG", "NN", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eich versenke mich ins Meeres Grund", "tokens": ["\u201e", "ich", "ver\u00b7sen\u00b7ke", "mich", "ins", "Mee\u00b7res", "Grund"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PPER", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "\u201emit meinem Liebsten im Arm.", "tokens": ["\u201e", "mit", "mei\u00b7nem", "Liebs\u00b7ten", "im", "Arm", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.21": {"line.1": {"text": "\u201efahr wohl, fahr wohl, du schn\u00f6de Welt,", "tokens": ["\u201e", "fahr", "wohl", ",", "fahr", "wohl", ",", "du", "schn\u00f6\u00b7de", "Welt", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "$,", "VVFIN", "ADV", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eich muss itzt von dir scheiden.", "tokens": ["\u201e", "ich", "muss", "itzt", "von", "dir", "schei\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eich muss zu meinem Herzliebsten gehn", "tokens": ["\u201e", "ich", "muss", "zu", "mei\u00b7nem", "Herz\u00b7liebs\u00b7ten", "gehn"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201eins Reich der ewigen Freuden.\u201c \u2014", "tokens": ["\u201e", "ins", "Reich", "der", "e\u00b7wi\u00b7gen", "Freu\u00b7den", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "APPRART", "NN", "ART", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "Und als die M\u00e4hr' am Land erscholl,", "tokens": ["Und", "als", "die", "M\u00e4hr'", "am", "Land", "er\u00b7scholl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da war gross Leid und Jammer;", "tokens": ["Da", "war", "gross", "Leid", "und", "Jam\u00b7mer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es haben getraurt Kanzel und Altar,", "tokens": ["Es", "ha\u00b7ben", "ge\u00b7traurt", "Kan\u00b7zel", "und", "Al\u00b7tar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Getrauert Saal und Kammer.", "tokens": ["Ge\u00b7trau\u00b7ert", "Saal", "und", "Kam\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Die K\u00f6nigstochter und sie war todt,", "tokens": ["Die", "K\u00f6\u00b7nig\u00b7stoch\u00b7ter", "und", "sie", "war", "todt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ins Meeres Grund versunken.", "tokens": ["Ins", "Mee\u00b7res", "Grund", "ver\u00b7sun\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der K\u00f6nigssohn und er war todt,", "tokens": ["Der", "K\u00f6\u00b7nigs\u00b7sohn", "und", "er", "war", "todt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In wilder Fluth ertrunken.", "tokens": ["In", "wil\u00b7der", "Fluth", "er\u00b7trun\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Nun Gott gedenk' es dem argen Schalk,", "tokens": ["Nun", "Gott", "ge\u00b7denk'", "es", "dem", "ar\u00b7gen", "Schalk", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der schuld daran gewesen!", "tokens": ["Der", "schuld", "da\u00b7ran", "ge\u00b7we\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PAV", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gedenk' es jedem noch heut zu Tag,", "tokens": ["Ge\u00b7denk'", "es", "je\u00b7dem", "noch", "heut", "zu", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIS", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der treue Liebe will l\u00f6sen!", "tokens": ["Der", "treu\u00b7e", "Lie\u00b7be", "will", "l\u00f6\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}