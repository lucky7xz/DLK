{"textgrid.poem.54097": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Schnipsel", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Alles ist richtig, auch das Gegenteil. Nur: \u00bbZwar . . . aber\u00ab \u2013 das ist nie richtig.", "tokens": ["Al\u00b7les", "ist", "rich\u00b7tig", ",", "auch", "das", "Ge\u00b7gen\u00b7teil", ".", "Nur", ":", "\u00bb", "Zwar", ".", ".", ".", "a\u00b7ber", "\u00ab", "\u2013", "das", "ist", "nie", "rich\u00b7tig", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJD", "$,", "ADV", "ART", "NN", "$.", "ADV", "$.", "$(", "ADV", "$.", "$.", "$.", "ADV", "$(", "$(", "PDS", "VAFIN", "ADV", "ADJD", "$."], "meter": "+--+-+-+-+-++--+-+-", "measure": "iambic.octa.plus.invert"}}, "stanza.2": {"line.1": {"text": "Zwanzig Jahre lang habe ich geglaubt, es sei Spa\u00df. Es ist Ernst? K\u00f6nnt ihr haben.", "tokens": ["Zwan\u00b7zig", "Jah\u00b7re", "lang", "ha\u00b7be", "ich", "ge\u00b7glaubt", ",", "es", "sei", "Spa\u00df", ".", "Es", "ist", "Ernst", "?", "K\u00f6nnt", "ihr", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "VAFIN", "PPER", "VVPP", "$,", "PPER", "VAFIN", "NN", "$.", "PPER", "VAFIN", "NE", "$.", "VMFIN", "PPER", "VAFIN", "$."], "meter": "+-+--+-+-+--+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.3": {"line.1": {"text": "Die Frauen haben es ja von Zeit zu Zeit auch nicht leicht. Wir M\u00e4nner aber m\u00fcssen uns rasieren.", "tokens": ["Die", "Frau\u00b7en", "ha\u00b7ben", "es", "ja", "von", "Zeit", "zu", "Zeit", "auch", "nicht", "leicht", ".", "Wir", "M\u00e4n\u00b7ner", "a\u00b7ber", "m\u00fcs\u00b7sen", "uns", "ra\u00b7sie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "APPR", "NN", "APPR", "NN", "ADV", "PTKNEG", "ADJD", "$.", "PPER", "NN", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.4": {"line.1": {"text": "Ein General in Uniform\u2013: das ist wie ein Kommerzienrat in geb\u00fcgelter Heizer-Kluft.", "tokens": ["Ein", "Ge\u00b7ne\u00b7ral", "in", "U\u00b7ni\u00b7form", "\u2013", ":", "das", "ist", "wie", "ein", "Kom\u00b7mer\u00b7zi\u00b7en\u00b7rat", "in", "ge\u00b7b\u00fc\u00b7gel\u00b7ter", "Hei\u00b7zer\u00b7Kluft", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$(", "$.", "PDS", "VAFIN", "KOKOM", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+-+-+-+--+-+-+--+--+-+", "measure": "iambic.octa.plus.invert"}}, "stanza.5": {"line.1": {"text": "Wegen ung\u00fcnstiger Witterung fand die deutsche Revolution in der Musik statt.", "tokens": ["We\u00b7gen", "un\u00b7g\u00fcns\u00b7ti\u00b7ger", "Wit\u00b7te\u00b7rung", "fand", "die", "deut\u00b7sche", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", "in", "der", "Mu\u00b7sik", "statt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+--+--+--+-+-+-+-+-+-+-", "measure": "dactylic.tri.plus"}}, "stanza.6": {"line.1": {"text": "Alles ist richtig, auch das Gegenteil. Nur: \u00bbZwar . . . aber\u00ab \u2013 das ist nie richtig.", "tokens": ["Al\u00b7les", "ist", "rich\u00b7tig", ",", "auch", "das", "Ge\u00b7gen\u00b7teil", ".", "Nur", ":", "\u00bb", "Zwar", ".", ".", ".", "a\u00b7ber", "\u00ab", "\u2013", "das", "ist", "nie", "rich\u00b7tig", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJD", "$,", "ADV", "ART", "NN", "$.", "ADV", "$.", "$(", "ADV", "$.", "$.", "$.", "ADV", "$(", "$(", "PDS", "VAFIN", "ADV", "ADJD", "$."], "meter": "+--+-+-+-+-++--+-+-", "measure": "iambic.octa.plus.invert"}}, "stanza.7": {"line.1": {"text": "Zwanzig Jahre lang habe ich geglaubt, es sei Spa\u00df. Es ist Ernst? K\u00f6nnt ihr haben.", "tokens": ["Zwan\u00b7zig", "Jah\u00b7re", "lang", "ha\u00b7be", "ich", "ge\u00b7glaubt", ",", "es", "sei", "Spa\u00df", ".", "Es", "ist", "Ernst", "?", "K\u00f6nnt", "ihr", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "VAFIN", "PPER", "VVPP", "$,", "PPER", "VAFIN", "NN", "$.", "PPER", "VAFIN", "NE", "$.", "VMFIN", "PPER", "VAFIN", "$."], "meter": "+-+--+-+-+--+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.8": {"line.1": {"text": "Die Frauen haben es ja von Zeit zu Zeit auch nicht leicht. Wir M\u00e4nner aber m\u00fcssen uns rasieren.", "tokens": ["Die", "Frau\u00b7en", "ha\u00b7ben", "es", "ja", "von", "Zeit", "zu", "Zeit", "auch", "nicht", "leicht", ".", "Wir", "M\u00e4n\u00b7ner", "a\u00b7ber", "m\u00fcs\u00b7sen", "uns", "ra\u00b7sie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "APPR", "NN", "APPR", "NN", "ADV", "PTKNEG", "ADJD", "$.", "PPER", "NN", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.9": {"line.1": {"text": "Ein General in Uniform\u2013: das ist wie ein Kommerzienrat in geb\u00fcgelter Heizer-Kluft.", "tokens": ["Ein", "Ge\u00b7ne\u00b7ral", "in", "U\u00b7ni\u00b7form", "\u2013", ":", "das", "ist", "wie", "ein", "Kom\u00b7mer\u00b7zi\u00b7en\u00b7rat", "in", "ge\u00b7b\u00fc\u00b7gel\u00b7ter", "Hei\u00b7zer\u00b7Kluft", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$(", "$.", "PDS", "VAFIN", "KOKOM", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+-+-+-+--+-+-+--+--+-+", "measure": "iambic.octa.plus.invert"}}, "stanza.10": {"line.1": {"text": "Wegen ung\u00fcnstiger Witterung fand die deutsche Revolution in der Musik statt.", "tokens": ["We\u00b7gen", "un\u00b7g\u00fcns\u00b7ti\u00b7ger", "Wit\u00b7te\u00b7rung", "fand", "die", "deut\u00b7sche", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", "in", "der", "Mu\u00b7sik", "statt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+--+--+--+-+-+-+-+-+-+-", "measure": "dactylic.tri.plus"}}}}}