{"textgrid.poem.57304": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Dank dir, mein Geist, dass du seit deiner Reife Beginn,", "genre": "verse", "period": "N.A.", "pub_year": 1775, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dank dir, mein Geist, dass du seit deiner Reife Beginn,", "tokens": ["Dank", "dir", ",", "mein", "Geist", ",", "dass", "du", "seit", "dei\u00b7ner", "Rei\u00b7fe", "Be\u00b7ginn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Beschlossest, bey dem Beschluss verhartest:", "tokens": ["Be\u00b7schlos\u00b7sest", ",", "bey", "dem", "Be\u00b7schluss", "ver\u00b7har\u00b7test", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nie durch h\u00f6fisches Lob zu entweihn", "tokens": ["Nie", "durch", "h\u00f6\u00b7fi\u00b7sches", "Lob", "zu", "ent\u00b7weihn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Die heilige Dichtkunst,", "tokens": ["Die", "hei\u00b7li\u00b7ge", "Dicht\u00b7kunst", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.2": {"line.1": {"text": "Durch das Lob l\u00fcstender Schwelger, oder eingewebter", "tokens": ["Durch", "das", "Lob", "l\u00fcs\u00b7ten\u00b7der", "Schwel\u00b7ger", ",", "o\u00b7der", "ein\u00b7ge\u00b7web\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,", "KON", "NN"], "meter": "+-+---+-+-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Fliegen, Eroberer, Tyrannen ohne Schwert,", "tokens": ["Flie\u00b7gen", ",", "Er\u00b7o\u00b7be\u00b7rer", ",", "Ty\u00b7ran\u00b7nen", "oh\u00b7ne", "Schwert", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Nicht gr\u00fcbelnder, handelnder Gottesleugner,", "tokens": ["Nicht", "gr\u00fc\u00b7beln\u00b7der", ",", "han\u00b7deln\u00b7der", "Got\u00b7tes\u00b7leug\u00b7ner", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Halbmenschen, die sich, in vollem dummen Ernst, f\u00fcr h\u00f6here", "tokens": ["Halb\u00b7men\u00b7schen", ",", "die", "sich", ",", "in", "vol\u00b7lem", "dum\u00b7men", "Ernst", ",", "f\u00fcr", "h\u00f6\u00b7he\u00b7re"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELS", "PRF", "$,", "APPR", "ADJA", "ADJA", "NN", "$,", "APPR", "ADJA"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.3": {"line.1": {"text": "Wesen halten als uns. Nicht alte Dichtersitte,", "tokens": ["We\u00b7sen", "hal\u00b7ten", "als", "uns", ".", "Nicht", "al\u00b7te", "Dich\u00b7ter\u00b7sit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KOKOM", "PPER", "$.", "PTKNEG", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Nicht Schimmer, der Licht log,", "tokens": ["Nicht", "Schim\u00b7mer", ",", "der", "Licht", "log", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Freunde nicht, die geblendet bewunderten,", "tokens": ["Freun\u00b7de", "nicht", ",", "die", "ge\u00b7blen\u00b7det", "be\u00b7wun\u00b7der\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "PRELS", "VVPP", "VVFIN", "$,"], "meter": "+--+-+--+--", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Vermochten deinen Entschluss zu ersch\u00fcttern.", "tokens": ["Ver\u00b7moch\u00b7ten", "dei\u00b7nen", "Ent\u00b7schluss", "zu", "er\u00b7sch\u00fct\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Denn du, ein biegsamer Fr\u00fchlingsspross", "tokens": ["Denn", "du", ",", "ein", "bieg\u00b7sa\u00b7mer", "Fr\u00fch\u00b7lings\u00b7spross"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Bey kleineren Dingen,", "tokens": ["Bey", "klei\u00b7ne\u00b7ren", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Bist, wenn es gr\u00f6ssere gilt,", "tokens": ["Bist", ",", "wenn", "es", "gr\u00f6s\u00b7se\u00b7re", "gilt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "ADJA", "VVFIN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Eiche, die dem Orkane steht.", "tokens": ["Ei\u00b7che", ",", "die", "dem", "Or\u00b7ka\u00b7ne", "steht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.5": {"line.1": {"text": "Und deckte gebildeter Marmor euch das Grab;", "tokens": ["Und", "deck\u00b7te", "ge\u00b7bil\u00b7de\u00b7ter", "Mar\u00b7mor", "euch", "das", "Grab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "PPER", "ART", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Schands\u00e4ul' ist der Marmor: wenn euer Gesang", "tokens": ["Schand\u00b7s\u00e4ul'", "ist", "der", "Mar\u00b7mor", ":", "wenn", "eu\u00b7er", "Ge\u00b7sang"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN", "$.", "KOUS", "PPOSAT", "NN"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Kakerlakken, oder Orangutane", "tokens": ["Ka\u00b7ker\u00b7lak\u00b7ken", ",", "o\u00b7der", "O\u00b7ran\u00b7gu\u00b7ta\u00b7ne"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "KON", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Zu G\u00f6ttern verschuf.", "tokens": ["Zu", "G\u00f6t\u00b7tern", "ver\u00b7schuf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Ruhe nicht sanft, Gebein der Verg\u00f6tterer! Sie sinds,", "tokens": ["Ru\u00b7he", "nicht", "sanft", ",", "Ge\u00b7bein", "der", "Ver\u00b7g\u00f6t\u00b7te\u00b7rer", "!", "Sie", "sinds", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADJD", "$,", "NN", "ART", "NN", "$.", "PPER", "VAFIN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Sie habens gemacht, dass nun die Geschichte nur", "tokens": ["Sie", "ha\u00b7bens", "ge\u00b7macht", ",", "dass", "nun", "die", "Ge\u00b7schich\u00b7te", "nur"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "KOUS", "ADV", "ART", "NN", "ADV"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Denkmaal ist; die Dichtkunst", "tokens": ["Denk\u00b7maal", "ist", ";", "die", "Dicht\u00b7kunst"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "$.", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Nicht Denkmaal ist!", "tokens": ["Nicht", "Denk\u00b7maal", "ist", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Gemacht, dass ich mit zitternder Hand", "tokens": ["Ge\u00b7macht", ",", "dass", "ich", "mit", "zit\u00b7tern\u00b7der", "Hand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Die Saite von Daniens Friederich r\u00fchrte;", "tokens": ["Die", "Sai\u00b7te", "von", "Da\u00b7ni\u00b7ens", "Frie\u00b7de\u00b7rich", "r\u00fchr\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NE", "VVFIN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Sie werde von Badens Friederich r\u00fchren,", "tokens": ["Sie", "wer\u00b7de", "von", "Ba\u00b7dens", "Frie\u00b7de\u00b7rich", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "NE", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mit zitternder Hand.", "tokens": ["Mit", "zit\u00b7tern\u00b7der", "Hand", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.8": {"line.1": {"text": "Denn o wo ist der sorgsame Wahrheitsforscher,", "tokens": ["Denn", "o", "wo", "ist", "der", "sorg\u00b7sa\u00b7me", "Wahr\u00b7heits\u00b7for\u00b7scher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "PWAV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der geht, und die Zeugen verh\u00f6rt? Geh hin, noch leben die Zeugen,", "tokens": ["Der", "geht", ",", "und", "die", "Zeu\u00b7gen", "ver\u00b7h\u00f6rt", "?", "Geh", "hin", ",", "noch", "le\u00b7ben", "die", "Zeu\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KON", "ART", "NN", "VVPP", "$.", "NE", "PTKVZ", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+-+-+--+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und halte Verh\u00f6r, und zeih, wenn du kanst,", "tokens": ["Und", "hal\u00b7te", "Ver\u00b7h\u00f6r", ",", "und", "zeih", ",", "wenn", "du", "kanst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "KON", "VVFIN", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Auch mich der Entweihung!", "tokens": ["Auch", "mich", "der", "Ent\u00b7wei\u00b7hung", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.9": {"line.1": {"text": "Dank dir, mein Geist, dass du seit deiner Reife Beginn,", "tokens": ["Dank", "dir", ",", "mein", "Geist", ",", "dass", "du", "seit", "dei\u00b7ner", "Rei\u00b7fe", "Be\u00b7ginn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Beschlossest, bey dem Beschluss verhartest:", "tokens": ["Be\u00b7schlos\u00b7sest", ",", "bey", "dem", "Be\u00b7schluss", "ver\u00b7har\u00b7test", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nie durch h\u00f6fisches Lob zu entweihn", "tokens": ["Nie", "durch", "h\u00f6\u00b7fi\u00b7sches", "Lob", "zu", "ent\u00b7weihn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Die heilige Dichtkunst,", "tokens": ["Die", "hei\u00b7li\u00b7ge", "Dicht\u00b7kunst", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.10": {"line.1": {"text": "Durch das Lob l\u00fcstender Schwelger, oder eingewebter", "tokens": ["Durch", "das", "Lob", "l\u00fcs\u00b7ten\u00b7der", "Schwel\u00b7ger", ",", "o\u00b7der", "ein\u00b7ge\u00b7web\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,", "KON", "NN"], "meter": "+-+---+-+-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Fliegen, Eroberer, Tyrannen ohne Schwert,", "tokens": ["Flie\u00b7gen", ",", "Er\u00b7o\u00b7be\u00b7rer", ",", "Ty\u00b7ran\u00b7nen", "oh\u00b7ne", "Schwert", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Nicht gr\u00fcbelnder, handelnder Gottesleugner,", "tokens": ["Nicht", "gr\u00fc\u00b7beln\u00b7der", ",", "han\u00b7deln\u00b7der", "Got\u00b7tes\u00b7leug\u00b7ner", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Halbmenschen, die sich, in vollem dummen Ernst, f\u00fcr h\u00f6here", "tokens": ["Halb\u00b7men\u00b7schen", ",", "die", "sich", ",", "in", "vol\u00b7lem", "dum\u00b7men", "Ernst", ",", "f\u00fcr", "h\u00f6\u00b7he\u00b7re"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELS", "PRF", "$,", "APPR", "ADJA", "ADJA", "NN", "$,", "APPR", "ADJA"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.11": {"line.1": {"text": "Wesen halten als uns. Nicht alte Dichtersitte,", "tokens": ["We\u00b7sen", "hal\u00b7ten", "als", "uns", ".", "Nicht", "al\u00b7te", "Dich\u00b7ter\u00b7sit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KOKOM", "PPER", "$.", "PTKNEG", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Nicht Schimmer, der Licht log,", "tokens": ["Nicht", "Schim\u00b7mer", ",", "der", "Licht", "log", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Freunde nicht, die geblendet bewunderten,", "tokens": ["Freun\u00b7de", "nicht", ",", "die", "ge\u00b7blen\u00b7det", "be\u00b7wun\u00b7der\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "PRELS", "VVPP", "VVFIN", "$,"], "meter": "+--+-+--+--", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Vermochten deinen Entschluss zu ersch\u00fcttern.", "tokens": ["Ver\u00b7moch\u00b7ten", "dei\u00b7nen", "Ent\u00b7schluss", "zu", "er\u00b7sch\u00fct\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Denn du, ein biegsamer Fr\u00fchlingsspross", "tokens": ["Denn", "du", ",", "ein", "bieg\u00b7sa\u00b7mer", "Fr\u00fch\u00b7lings\u00b7spross"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Bey kleineren Dingen,", "tokens": ["Bey", "klei\u00b7ne\u00b7ren", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Bist, wenn es gr\u00f6ssere gilt,", "tokens": ["Bist", ",", "wenn", "es", "gr\u00f6s\u00b7se\u00b7re", "gilt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "ADJA", "VVFIN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Eiche, die dem Orkane steht.", "tokens": ["Ei\u00b7che", ",", "die", "dem", "Or\u00b7ka\u00b7ne", "steht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.13": {"line.1": {"text": "Und deckte gebildeter Marmor euch das Grab;", "tokens": ["Und", "deck\u00b7te", "ge\u00b7bil\u00b7de\u00b7ter", "Mar\u00b7mor", "euch", "das", "Grab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "PPER", "ART", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Schands\u00e4ul' ist der Marmor: wenn euer Gesang", "tokens": ["Schand\u00b7s\u00e4ul'", "ist", "der", "Mar\u00b7mor", ":", "wenn", "eu\u00b7er", "Ge\u00b7sang"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN", "$.", "KOUS", "PPOSAT", "NN"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Kakerlakken, oder Orangutane", "tokens": ["Ka\u00b7ker\u00b7lak\u00b7ken", ",", "o\u00b7der", "O\u00b7ran\u00b7gu\u00b7ta\u00b7ne"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "KON", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Zu G\u00f6ttern verschuf.", "tokens": ["Zu", "G\u00f6t\u00b7tern", "ver\u00b7schuf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.14": {"line.1": {"text": "Ruhe nicht sanft, Gebein der Verg\u00f6tterer! Sie sinds,", "tokens": ["Ru\u00b7he", "nicht", "sanft", ",", "Ge\u00b7bein", "der", "Ver\u00b7g\u00f6t\u00b7te\u00b7rer", "!", "Sie", "sinds", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADJD", "$,", "NN", "ART", "NN", "$.", "PPER", "VAFIN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Sie habens gemacht, dass nun die Geschichte nur", "tokens": ["Sie", "ha\u00b7bens", "ge\u00b7macht", ",", "dass", "nun", "die", "Ge\u00b7schich\u00b7te", "nur"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "KOUS", "ADV", "ART", "NN", "ADV"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Denkmaal ist; die Dichtkunst", "tokens": ["Denk\u00b7maal", "ist", ";", "die", "Dicht\u00b7kunst"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "$.", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Nicht Denkmaal ist!", "tokens": ["Nicht", "Denk\u00b7maal", "ist", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.15": {"line.1": {"text": "Gemacht, dass ich mit zitternder Hand", "tokens": ["Ge\u00b7macht", ",", "dass", "ich", "mit", "zit\u00b7tern\u00b7der", "Hand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Die Saite von Daniens Friederich r\u00fchrte;", "tokens": ["Die", "Sai\u00b7te", "von", "Da\u00b7ni\u00b7ens", "Frie\u00b7de\u00b7rich", "r\u00fchr\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NE", "VVFIN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Sie werde von Badens Friederich r\u00fchren,", "tokens": ["Sie", "wer\u00b7de", "von", "Ba\u00b7dens", "Frie\u00b7de\u00b7rich", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "NE", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mit zitternder Hand.", "tokens": ["Mit", "zit\u00b7tern\u00b7der", "Hand", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.16": {"line.1": {"text": "Denn o wo ist der sorgsame Wahrheitsforscher,", "tokens": ["Denn", "o", "wo", "ist", "der", "sorg\u00b7sa\u00b7me", "Wahr\u00b7heits\u00b7for\u00b7scher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "PWAV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der geht, und die Zeugen verh\u00f6rt? Geh hin, noch leben die Zeugen,", "tokens": ["Der", "geht", ",", "und", "die", "Zeu\u00b7gen", "ver\u00b7h\u00f6rt", "?", "Geh", "hin", ",", "noch", "le\u00b7ben", "die", "Zeu\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KON", "ART", "NN", "VVPP", "$.", "NE", "PTKVZ", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+-+-+--+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und halte Verh\u00f6r, und zeih, wenn du kanst,", "tokens": ["Und", "hal\u00b7te", "Ver\u00b7h\u00f6r", ",", "und", "zeih", ",", "wenn", "du", "kanst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "KON", "VVFIN", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Auch mich der Entweihung!", "tokens": ["Auch", "mich", "der", "Ent\u00b7wei\u00b7hung", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}}}}