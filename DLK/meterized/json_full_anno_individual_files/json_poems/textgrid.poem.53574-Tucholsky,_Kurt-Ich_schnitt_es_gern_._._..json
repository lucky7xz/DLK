{"textgrid.poem.53574": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Ich schnitt es gern . . .", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie sch\u00f6n ist doch des Pfolkes Neigung!", "tokens": ["Wie", "sch\u00f6n", "ist", "doch", "des", "Pfol\u00b7kes", "Nei\u00b7gung", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wen es mal liebt, den liebt es ganz", "tokens": ["Wen", "es", "mal", "liebt", ",", "den", "liebt", "es", "ganz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,", "ART", "VVFIN", "PPER", "ADV"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "und beut entflammt, in j\u00e4her Steigung,", "tokens": ["und", "beut", "ent\u00b7flammt", ",", "in", "j\u00e4\u00b7her", "Stei\u00b7gung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dem Helden seinen Ruhmeskranz.", "tokens": ["dem", "Hel\u00b7den", "sei\u00b7nen", "Ruh\u00b7mes\u00b7kranz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Die M\u00e4nner des Paradeschrittes", "tokens": ["Die", "M\u00e4n\u00b7ner", "des", "Pa\u00b7ra\u00b7de\u00b7schrit\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "umjubelt es tagaus, tagein \u2013", "tokens": ["um\u00b7ju\u00b7belt", "es", "ta\u00b7gaus", ",", "ta\u00b7gein", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "es segnet auch ihr Haupt und schnitt es", "tokens": ["es", "seg\u00b7net", "auch", "ihr", "Haupt", "und", "schnitt", "es"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "sich gern in alle Rinden ein.", "tokens": ["sich", "gern", "in", "al\u00b7le", "Rin\u00b7den", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "So auch der Knab dort.", "tokens": ["So", "auch", "der", "Knab", "dort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Auf der Stra\u00dfe", "tokens": ["Auf", "der", "Stra\u00b7\u00dfe"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "steht er in Abendsonnenglut", "tokens": ["steht", "er", "in", "A\u00b7bend\u00b7son\u00b7nen\u00b7glut"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "und tut f\u00fcr sich in kleinem Ma\u00dfe,", "tokens": ["und", "tut", "f\u00fcr", "sich", "in", "klei\u00b7nem", "Ma\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "was sonst die Stra\u00dfenreinigung tut.", "tokens": ["was", "sonst", "die", "Stra\u00b7\u00dfen\u00b7rei\u00b7ni\u00b7gung", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Zieht er auf dem Asphalt Figuren?", "tokens": ["Zieht", "er", "auf", "dem", "As\u00b7phalt", "Fi\u00b7gu\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Liebt er das alte Ornament?", "tokens": ["Liebt", "er", "das", "al\u00b7te", "Or\u00b7na\u00b7ment", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sieh da: er zeigt des Flei\u00dfes Spuren", "tokens": ["Sieh", "da", ":", "er", "zeigt", "des", "Flei\u00b7\u00dfes", "Spu\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "der Jugend, die dergleichen kennt.", "tokens": ["der", "Ju\u00b7gend", ",", "die", "derg\u00b7lei\u00b7chen", "kennt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "La\u00dft uns noch einmal wiederkehren.", "tokens": ["La\u00dft", "uns", "noch", "ein\u00b7mal", "wie\u00b7der\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie ist dies Volk doch wohlgesinnt!", "tokens": ["Wie", "ist", "dies", "Volk", "doch", "wohl\u00b7ge\u00b7sinnt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PDS", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich lese voller Wehmutsz\u00e4hren:", "tokens": ["Ich", "le\u00b7se", "vol\u00b7ler", "Weh\u00b7muts\u00b7z\u00e4h\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbn. O. S. K. . . .\u00ab", "tokens": ["\u00bb", "n.", "O.", "S.", "K.", ".", ".", ".", "\u00ab"], "token_info": ["punct", "abbreviation", "abbreviation", "abbreviation", "abbreviation", "punct", "punct", "punct", "punct"], "pos": ["$(", "APPR", "NE", "NE", "NE", "$.", "$.", "$.", "$("]}, "line.5": {"text": "Du gutes Kind \u2013!", "tokens": ["Du", "gu\u00b7tes", "Kind", "\u2013", "!"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADJA", "NN", "$(", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Wie sch\u00f6n ist doch des Pfolkes Neigung!", "tokens": ["Wie", "sch\u00f6n", "ist", "doch", "des", "Pfol\u00b7kes", "Nei\u00b7gung", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wen es mal liebt, den liebt es ganz", "tokens": ["Wen", "es", "mal", "liebt", ",", "den", "liebt", "es", "ganz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,", "ART", "VVFIN", "PPER", "ADV"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "und beut entflammt, in j\u00e4her Steigung,", "tokens": ["und", "beut", "ent\u00b7flammt", ",", "in", "j\u00e4\u00b7her", "Stei\u00b7gung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dem Helden seinen Ruhmeskranz.", "tokens": ["dem", "Hel\u00b7den", "sei\u00b7nen", "Ruh\u00b7mes\u00b7kranz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Die M\u00e4nner des Paradeschrittes", "tokens": ["Die", "M\u00e4n\u00b7ner", "des", "Pa\u00b7ra\u00b7de\u00b7schrit\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "umjubelt es tagaus, tagein \u2013", "tokens": ["um\u00b7ju\u00b7belt", "es", "ta\u00b7gaus", ",", "ta\u00b7gein", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "es segnet auch ihr Haupt und schnitt es", "tokens": ["es", "seg\u00b7net", "auch", "ihr", "Haupt", "und", "schnitt", "es"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "sich gern in alle Rinden ein.", "tokens": ["sich", "gern", "in", "al\u00b7le", "Rin\u00b7den", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "So auch der Knab dort.", "tokens": ["So", "auch", "der", "Knab", "dort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Auf der Stra\u00dfe", "tokens": ["Auf", "der", "Stra\u00b7\u00dfe"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "steht er in Abendsonnenglut", "tokens": ["steht", "er", "in", "A\u00b7bend\u00b7son\u00b7nen\u00b7glut"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "und tut f\u00fcr sich in kleinem Ma\u00dfe,", "tokens": ["und", "tut", "f\u00fcr", "sich", "in", "klei\u00b7nem", "Ma\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "was sonst die Stra\u00dfenreinigung tut.", "tokens": ["was", "sonst", "die", "Stra\u00b7\u00dfen\u00b7rei\u00b7ni\u00b7gung", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "Zieht er auf dem Asphalt Figuren?", "tokens": ["Zieht", "er", "auf", "dem", "As\u00b7phalt", "Fi\u00b7gu\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Liebt er das alte Ornament?", "tokens": ["Liebt", "er", "das", "al\u00b7te", "Or\u00b7na\u00b7ment", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sieh da: er zeigt des Flei\u00dfes Spuren", "tokens": ["Sieh", "da", ":", "er", "zeigt", "des", "Flei\u00b7\u00dfes", "Spu\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "der Jugend, die dergleichen kennt.", "tokens": ["der", "Ju\u00b7gend", ",", "die", "derg\u00b7lei\u00b7chen", "kennt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "La\u00dft uns noch einmal wiederkehren.", "tokens": ["La\u00dft", "uns", "noch", "ein\u00b7mal", "wie\u00b7der\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie ist dies Volk doch wohlgesinnt!", "tokens": ["Wie", "ist", "dies", "Volk", "doch", "wohl\u00b7ge\u00b7sinnt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PDS", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich lese voller Wehmutsz\u00e4hren:", "tokens": ["Ich", "le\u00b7se", "vol\u00b7ler", "Weh\u00b7muts\u00b7z\u00e4h\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbn. O. S. K. . . .\u00ab", "tokens": ["\u00bb", "n.", "O.", "S.", "K.", ".", ".", ".", "\u00ab"], "token_info": ["punct", "abbreviation", "abbreviation", "abbreviation", "abbreviation", "punct", "punct", "punct", "punct"], "pos": ["$(", "APPR", "NE", "NE", "NE", "$.", "$.", "$.", "$("]}, "line.5": {"text": "Du gutes Kind \u2013!", "tokens": ["Du", "gu\u00b7tes", "Kind", "\u2013", "!"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADJA", "NN", "$(", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}