{"textgrid.poem.48688": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "9. Jerusalem! Jerusalem!", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin Jerusalem, Jerusalem, die harte,", "tokens": ["Ich", "bin", "Je\u00b7ru\u00b7sa\u00b7lem", ",", "Je\u00b7ru\u00b7sa\u00b7lem", ",", "die", "har\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "$,", "NE", "$,", "ART", "ADJA", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "die keiner Dr\u00e4uung traut. Ich bin derselben Art,", "tokens": ["die", "kei\u00b7ner", "Dr\u00e4u\u00b7ung", "traut", ".", "Ich", "bin", "der\u00b7sel\u00b7ben", "Art", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$.", "PPER", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die Eisen hat f\u00fcr Fleisch und nie bewogen ward,", "tokens": ["die", "Ei\u00b7sen", "hat", "f\u00fcr", "Fleisch", "und", "nie", "be\u00b7wo\u00b7gen", "ward", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "KON", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "wie oft sich auch Gott selbst mir gab zum Widerparte.", "tokens": ["wie", "oft", "sich", "auch", "Gott", "selbst", "mir", "gab", "zum", "Wi\u00b7der\u00b7par\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PRF", "ADV", "NN", "ADV", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Von dir k\u00f6mt di\u00df noch her, o Eden, erster Garte,", "tokens": ["Von", "dir", "k\u00f6mt", "di\u00df", "noch", "her", ",", "o", "E\u00b7den", ",", "ers\u00b7ter", "Gar\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PDS", "ADV", "PTKVZ", "$,", "FM", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "da\u00df ich in Unverstand so tief bin ausgelahrt,", "tokens": ["da\u00df", "ich", "in", "Un\u00b7ver\u00b7stand", "so", "tief", "bin", "aus\u00b7ge\u00b7lahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADV", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "wei\u00df selbst mein Bestes nicht, dem B\u00f6sen vorgespart.", "tokens": ["wei\u00df", "selbst", "mein", "Bes\u00b7tes", "nicht", ",", "dem", "B\u00f6\u00b7sen", "vor\u00b7ge\u00b7spart", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was wird mein Lohn denn sein, auf den ich noch so warte?", "tokens": ["Was", "wird", "mein", "Lohn", "denn", "sein", ",", "auf", "den", "ich", "noch", "so", "war\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "NN", "KON", "VAINF", "$,", "APPR", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ist nun die Torheit klug, hat Aberwitz Verstand?", "tokens": ["Ist", "nun", "die", "Tor\u00b7heit", "klug", ",", "hat", "A\u00b7ber\u00b7witz", "Ver\u00b7stand", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJD", "$,", "VAFIN", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was bild' ich mir denn ein? Es ist ein eitler Tand,", "tokens": ["Was", "bild'", "ich", "mir", "denn", "ein", "?", "Es", "ist", "ein", "eit\u00b7ler", "Tand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "ADV", "PTKVZ", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df ich mich meine selbst aus meiner Not zu retten.", "tokens": ["da\u00df", "ich", "mich", "mei\u00b7ne", "selbst", "aus", "mei\u00b7ner", "Not", "zu", "ret\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PPOSAT", "ADV", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Barmherziger, sieh' nicht auf den verkehrten Sinn,", "tokens": ["Barm\u00b7her\u00b7zi\u00b7ger", ",", "sieh'", "nicht", "auf", "den", "ver\u00b7kehr\u00b7ten", "Sinn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "der mich und alle Welt zur H\u00f6lle f\u00fchret' hin,", "tokens": ["der", "mich", "und", "al\u00b7le", "Welt", "zur", "H\u00f6l\u00b7le", "f\u00fch\u00b7ret'", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "KON", "PIAT", "NN", "APPRART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "wenn wir nicht Zuversicht in deine Gnade h\u00e4tten.", "tokens": ["wenn", "wir", "nicht", "Zu\u00b7ver\u00b7sicht", "in", "dei\u00b7ne", "Gna\u00b7de", "h\u00e4t\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ich bin Jerusalem, Jerusalem, die harte,", "tokens": ["Ich", "bin", "Je\u00b7ru\u00b7sa\u00b7lem", ",", "Je\u00b7ru\u00b7sa\u00b7lem", ",", "die", "har\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "$,", "NE", "$,", "ART", "ADJA", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "die keiner Dr\u00e4uung traut. Ich bin derselben Art,", "tokens": ["die", "kei\u00b7ner", "Dr\u00e4u\u00b7ung", "traut", ".", "Ich", "bin", "der\u00b7sel\u00b7ben", "Art", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$.", "PPER", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die Eisen hat f\u00fcr Fleisch und nie bewogen ward,", "tokens": ["die", "Ei\u00b7sen", "hat", "f\u00fcr", "Fleisch", "und", "nie", "be\u00b7wo\u00b7gen", "ward", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "KON", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "wie oft sich auch Gott selbst mir gab zum Widerparte.", "tokens": ["wie", "oft", "sich", "auch", "Gott", "selbst", "mir", "gab", "zum", "Wi\u00b7der\u00b7par\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PRF", "ADV", "NN", "ADV", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Von dir k\u00f6mt di\u00df noch her, o Eden, erster Garte,", "tokens": ["Von", "dir", "k\u00f6mt", "di\u00df", "noch", "her", ",", "o", "E\u00b7den", ",", "ers\u00b7ter", "Gar\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PDS", "ADV", "PTKVZ", "$,", "FM", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "da\u00df ich in Unverstand so tief bin ausgelahrt,", "tokens": ["da\u00df", "ich", "in", "Un\u00b7ver\u00b7stand", "so", "tief", "bin", "aus\u00b7ge\u00b7lahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADV", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "wei\u00df selbst mein Bestes nicht, dem B\u00f6sen vorgespart.", "tokens": ["wei\u00df", "selbst", "mein", "Bes\u00b7tes", "nicht", ",", "dem", "B\u00f6\u00b7sen", "vor\u00b7ge\u00b7spart", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was wird mein Lohn denn sein, auf den ich noch so warte?", "tokens": ["Was", "wird", "mein", "Lohn", "denn", "sein", ",", "auf", "den", "ich", "noch", "so", "war\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "NN", "KON", "VAINF", "$,", "APPR", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ist nun die Torheit klug, hat Aberwitz Verstand?", "tokens": ["Ist", "nun", "die", "Tor\u00b7heit", "klug", ",", "hat", "A\u00b7ber\u00b7witz", "Ver\u00b7stand", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJD", "$,", "VAFIN", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was bild' ich mir denn ein? Es ist ein eitler Tand,", "tokens": ["Was", "bild'", "ich", "mir", "denn", "ein", "?", "Es", "ist", "ein", "eit\u00b7ler", "Tand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "ADV", "PTKVZ", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df ich mich meine selbst aus meiner Not zu retten.", "tokens": ["da\u00df", "ich", "mich", "mei\u00b7ne", "selbst", "aus", "mei\u00b7ner", "Not", "zu", "ret\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PPOSAT", "ADV", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Barmherziger, sieh' nicht auf den verkehrten Sinn,", "tokens": ["Barm\u00b7her\u00b7zi\u00b7ger", ",", "sieh'", "nicht", "auf", "den", "ver\u00b7kehr\u00b7ten", "Sinn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "der mich und alle Welt zur H\u00f6lle f\u00fchret' hin,", "tokens": ["der", "mich", "und", "al\u00b7le", "Welt", "zur", "H\u00f6l\u00b7le", "f\u00fch\u00b7ret'", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "KON", "PIAT", "NN", "APPRART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "wenn wir nicht Zuversicht in deine Gnade h\u00e4tten.", "tokens": ["wenn", "wir", "nicht", "Zu\u00b7ver\u00b7sicht", "in", "dei\u00b7ne", "Gna\u00b7de", "h\u00e4t\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}