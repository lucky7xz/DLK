{"textgrid.poem.31268": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "1L: Das Feld steht Kr\u00e4utter-leer/", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Feld steht Kr\u00e4utter-leer/", "tokens": ["Das", "Feld", "steht", "Kr\u00e4ut\u00b7ter\u00b7leer", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Frau ", "tokens": ["Frau"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "der Wald hat allbereit", "tokens": ["der", "Wald", "hat", "all\u00b7be\u00b7reit"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "sein bundtes St\u00e4rbe-Kleid/", "tokens": ["sein", "bund\u00b7tes", "St\u00e4r\u00b7be\u00b7Kleid", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "ein sch\u00f6nes Schau-Ger\u00fcst/", "tokens": ["ein", "sch\u00f6\u00b7nes", "Schau\u00b7Ge\u00b7r\u00fcst", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "das bald Verwehsung k\u00fcsst.", "tokens": ["das", "bald", "Ver\u00b7weh\u00b7sung", "k\u00fcsst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Wo blihb die Amstel hin/", "tokens": ["Wo", "blihb", "die", "A\u00b7mstel", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "das Singe-V\u00f6gelgin?", "tokens": ["das", "Sin\u00b7ge\u00b7V\u00f6\u00b7gel\u00b7gin", "?"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Der Fr\u00f6schgen ihr ", "tokens": ["Der", "Fr\u00f6schgen", "ihr"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "beschehmbt nicht mehr Hann\u00df Sachs.", "tokens": ["be\u00b7schehmbt", "nicht", "mehr", "Hann\u00df", "Sachs", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Dr\u00fcmb sey es endlich hihr geklagt/", "tokens": ["Dr\u00fcmb", "sey", "es", "end\u00b7lich", "hihr", "ge\u00b7klagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "wa\u00df mir das Hertz benagt!", "tokens": ["wa\u00df", "mir", "das", "Hertz", "be\u00b7nagt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Unsre Gaben/ s\u00fcsses Kind/", "tokens": ["Uns\u00b7re", "Ga\u00b7ben", "/", "s\u00fcs\u00b7ses", "Kind", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "fl\u00fcchtig wie Narzissen sind/", "tokens": ["fl\u00fcch\u00b7tig", "wie", "Nar\u00b7zis\u00b7sen", "sind", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "NN", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und es f\u00e4hrt mit uns die Zeit", "tokens": ["und", "es", "f\u00e4hrt", "mit", "uns", "die", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "strakks in die Verg\u00e4ssenheit.", "tokens": ["strakks", "in", "die", "Ver\u00b7g\u00e4s\u00b7sen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Einst so welckt mir dihse Haut", "tokens": ["Einst", "so", "welckt", "mir", "dih\u00b7se", "Haut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "trukkner al\u00df ein Sommer-Kraut/", "tokens": ["trukk\u00b7ner", "al\u00df", "ein", "Som\u00b7mer\u00b7Kraut", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "einst so zwikkt mir dih\u00df Gebein", "tokens": ["einst", "so", "zwikkt", "mir", "dih\u00df", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PDS", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Bodagra und Zipperlein.", "tokens": ["Bo\u00b7da\u00b7gra", "und", "Zip\u00b7per\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Hengen la\u00df ich dan mein Maul", "tokens": ["Hen\u00b7gen", "la\u00df", "ich", "dan", "mein", "Maul"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "wie ein alter Karren-Gaul/", "tokens": ["wie", "ein", "al\u00b7ter", "Kar\u00b7ren\u00b7Gaul", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "stakkrich sezz ich Fuh\u00df for Fuh\u00df", "tokens": ["stak\u00b7krich", "sezz", "ich", "Fuh\u00df", "for", "Fuh\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "NE", "NE", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "wie ein steiffer Tapp-ins-Muh\u00df.", "tokens": ["wie", "ein", "steif\u00b7fer", "Tapp\u00b7ins\u00b7\u00b7M\u00b7uh\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Nachts/ wenn mich die Fl\u00f6he j\u00fckken/", "tokens": ["Nachts", "/", "wenn", "mich", "die", "Fl\u00f6\u00b7he", "j\u00fck\u00b7ken", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PPER", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "krault mir keine mehr den R\u00fckken/", "tokens": ["krault", "mir", "kei\u00b7ne", "mehr", "den", "R\u00fck\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "PIS", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "denn for sowa\u00df/ lihbes Kind/", "tokens": ["denn", "for", "so\u00b7wa\u00df", "/", "lih\u00b7bes", "Kind", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "$(", "ADJA", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "b\u00fcn ich dan zu keusch gesinnt.", "tokens": ["b\u00fcn", "ich", "dan", "zu", "keusch", "ge\u00b7sinnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKA", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "ist mir dan durchau\u00df zerschmoltzen/", "tokens": ["ist", "mir", "dan", "durch\u00b7au\u00df", "zer\u00b7schmolt\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "und ich seufftz die gantze Zeit", "tokens": ["und", "ich", "seufftz", "die", "gant\u00b7ze", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "in betr\u00fchbter Einsamkeit!", "tokens": ["in", "be\u00b7tr\u00fchb\u00b7ter", "Ein\u00b7sam\u00b7keit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Alles bl\u00fcht und mu\u00df vergehn/", "tokens": ["Al\u00b7les", "bl\u00fcht", "und", "mu\u00df", "ver\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "dir wird Gleiches mahl geschehn!", "tokens": ["dir", "wird", "Glei\u00b7ches", "mahl", "ge\u00b7schehn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die weissen Kugeln/ so sich itz", "tokens": ["Die", "weis\u00b7sen", "Ku\u00b7geln", "/", "so", "sich", "itz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "PRF", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "so s\u00fc\u00df und anmuhtsvoll bewegen/", "tokens": ["so", "s\u00fc\u00df", "und", "an\u00b7muhts\u00b7voll", "be\u00b7we\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "wird einst ein ungeheurer Plitz", "tokens": ["wird", "einst", "ein", "un\u00b7ge\u00b7heu\u00b7rer", "Plitz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "in nichts wie Staub und Asche legen.", "tokens": ["in", "nichts", "wie", "Staub", "und", "A\u00b7sche", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "KOKOM", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dan wird dich niemand mehr betasten/", "tokens": ["Dan", "wird", "dich", "nie\u00b7mand", "mehr", "be\u00b7tas\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "dan lihgt dein Leib im schwartzen Kasten/", "tokens": ["dan", "lihgt", "dein", "Leib", "im", "schwart\u00b7zen", "Kas\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "dan triefft/ dan stinckt nach Talg", "tokens": ["dan", "triefft", "/", "dan", "stinckt", "nach", "Talg"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$(", "ADV", "VVFIN", "APPR", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "dein runtzlig fauler Balg.", "tokens": ["dein", "runtz\u00b7lig", "fau\u00b7ler", "Balg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Dein Mund so s\u00fc\u00df benelckt", "tokens": ["Dein", "Mund", "so", "s\u00fc\u00df", "be\u00b7nelckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "klafft j\u00e4mmerlich verwelckt/", "tokens": ["klafft", "j\u00e4m\u00b7mer\u00b7lich", "ver\u00b7welckt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "von Rohsen nicht die Spur/", "tokens": ["von", "Roh\u00b7sen", "nicht", "die", "Spur", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "zwo trukkne Schruntzeln nur/", "tokens": ["zwo", "trukk\u00b7ne", "Schrunt\u00b7zeln", "nur", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "zerm\u00fcrbelt und zerbrochen/", "tokens": ["zer\u00b7m\u00fcr\u00b7belt", "und", "zer\u00b7bro\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "von Kr\u00f6ten \u00fcberkrochen!", "tokens": ["von", "Kr\u00f6\u00b7ten", "\u00fc\u00b7ber\u00b7kro\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "La\u00df die mit den weissen B\u00e4ffgen/", "tokens": ["La\u00df", "die", "mit", "den", "weis\u00b7sen", "B\u00e4ff\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sie seynd Aeffgen!", "tokens": ["sie", "seynd", "A\u00b7eff\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "La\u00df sie pappeln/ la\u00df sie plarren/", "tokens": ["La\u00df", "sie", "pap\u00b7peln", "/", "la\u00df", "sie", "plar\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$(", "VVIMP", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "sie seynd Narren!", "tokens": ["sie", "seynd", "Nar\u00b7ren", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Ob J\u00fcde/ Heyde/ oder Christ/", "tokens": ["Ob", "J\u00fc\u00b7de", "/", "Hey\u00b7de", "/", "o\u00b7der", "Christ", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "$(", "NE", "$(", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "er wird zu Mist!", "tokens": ["er", "wird", "zu", "Mist", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Morgen lengst ist alles au\u00df/", "tokens": ["Mor\u00b7gen", "lengst", "ist", "al\u00b7les", "au\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "VAFIN", "PIS", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "M\u00e4ntsch/ du bist nur eine Lau\u00df/", "tokens": ["M\u00e4ntsch", "/", "du", "bist", "nur", "ei\u00b7ne", "Lau\u00df", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPER", "VAFIN", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "morgen/ oder gar schon heut/", "tokens": ["mor\u00b7gen", "/", "o\u00b7der", "gar", "schon", "heut", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KON", "ADV", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "dr\u00f6hnt vom Thurm dein Grab-Gel\u00e4ut!", "tokens": ["dr\u00f6hnt", "vom", "Thurm", "dein", "Grab\u00b7Ge\u00b7l\u00e4ut", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Eins nur ist uns dan gewi\u00df:", "tokens": ["Eins", "nur", "ist", "uns", "dan", "ge\u00b7wi\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "schwartz-polihrte F\u00fcnsterni\u00df!", "tokens": ["schwartz\u00b7po\u00b7lihr\u00b7te", "F\u00fcns\u00b7ter\u00b7ni\u00df", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "La\u00df uns alles dr\u00fcmb vergessen/", "tokens": ["La\u00df", "uns", "al\u00b7les", "dr\u00fcmb", "ver\u00b7ges\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PIS", "PAV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rohsen pflantzen \u00fcmb Zypressen/", "tokens": ["Roh\u00b7sen", "pflant\u00b7zen", "\u00fcmb", "Zyp\u00b7res\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NE", "$("], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "die dein Auge/ wenn es strahlt/", "tokens": ["die", "dein", "Au\u00b7ge", "/", "wenn", "es", "strahlt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "gleichsahm wie mit Goldt bemahlt!", "tokens": ["gleich\u00b7sahm", "wie", "mit", "Goldt", "be\u00b7mahlt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Deinen weichen Alabaster", "tokens": ["Dei\u00b7nen", "wei\u00b7chen", "A\u00b7la\u00b7bas\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "trukk ihn auff mich r\u00e4cht al\u00df Pflaster/", "tokens": ["trukk", "ihn", "auff", "mich", "r\u00e4cht", "al\u00df", "Pflas\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "VVFIN", "KOUS", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Mund an Mund und Brust an Brust/", "tokens": ["Mund", "an", "Mund", "und", "Brust", "an", "Brust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "in verschwihgner G\u00f6tter-Lust/", "tokens": ["in", "ver\u00b7schwihg\u00b7ner", "G\u00f6t\u00b7ter\u00b7Lust", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "bi\u00df ihr P\u00e4rlen-Safft dich/ Kind/", "tokens": ["bi\u00df", "ihr", "P\u00e4r\u00b7len\u00b7\u00b7S\u00b7afft", "dich", "/", "Kind", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "$(", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "gantz durchrinnt!", "tokens": ["gantz", "durch\u00b7rinnt", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Ob sie Jungffern oder Huren/", "tokens": ["Ob", "sie", "Jungf\u00b7fern", "o\u00b7der", "Hu\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "alle in die Grube fuhren/", "tokens": ["al\u00b7le", "in", "die", "Gru\u00b7be", "fuh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "nichts mehr war ihr Sch\u00f6n-Seyn n\u00fczze", "tokens": ["nichts", "mehr", "war", "ihr", "Sch\u00f6n\u00b7Seyn", "n\u00fcz\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ADV", "VAFIN", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "in der schwartzen Lethe-Pf\u00fczze!", "tokens": ["in", "der", "schwart\u00b7zen", "Lethe\u00b7P\u00b7f\u00fcz\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Selbst ", "tokens": ["Selbst"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "ist Stanck und Gifft seit dausend Jahren!", "tokens": ["ist", "Stanck", "und", "Gifft", "seit", "dau\u00b7send", "Jah\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dr\u00fcmb so k\u00fcnt es fast geschehn/", "tokens": ["Dr\u00fcmb", "so", "k\u00fcnt", "es", "fast", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "da\u00df die Augen mir voll Wasser stehn!", "tokens": ["da\u00df", "die", "Au\u00b7gen", "mir", "voll", "Was\u00b7ser", "stehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "ADJD", "NN", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Wa\u00df ist die Welt und ihr ber\u00fchmbtes Gl\u00e4ntzen?", "tokens": ["Wa\u00df", "ist", "die", "Welt", "und", "ihr", "be\u00b7r\u00fchmb\u00b7tes", "Gl\u00e4nt\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Blizz bey Nacht.", "tokens": ["Ein", "Blizz", "bey", "Nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Eh welcke Rohsen eure Scheitel kr\u00e4ntzen/", "tokens": ["Eh", "wel\u00b7cke", "Roh\u00b7sen", "eu\u00b7re", "Schei\u00b7tel", "kr\u00e4nt\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWAT", "NN", "PPOSAT", "NN", "VVINF", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "singt/ drinckt und lacht!", "tokens": ["singt", "/", "drinckt", "und", "lacht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Heut sind wir noch jung und roht/", "tokens": ["Heut", "sind", "wir", "noch", "jung", "und", "roht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "morgen hat uns schon der Dodt/", "tokens": ["mor\u00b7gen", "hat", "uns", "schon", "der", "Dodt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "morgen sind wir Asche!", "tokens": ["mor\u00b7gen", "sind", "wir", "A\u00b7sche", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Das Feld steht Kr\u00e4utter-leer/", "tokens": ["Das", "Feld", "steht", "Kr\u00e4ut\u00b7ter\u00b7leer", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Frau ", "tokens": ["Frau"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "der Wald hat allbereit", "tokens": ["der", "Wald", "hat", "all\u00b7be\u00b7reit"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "sein bundtes St\u00e4rbe-Kleid/", "tokens": ["sein", "bund\u00b7tes", "St\u00e4r\u00b7be\u00b7Kleid", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "ein sch\u00f6nes Schau-Ger\u00fcst/", "tokens": ["ein", "sch\u00f6\u00b7nes", "Schau\u00b7Ge\u00b7r\u00fcst", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "das bald Verwehsung k\u00fcsst.", "tokens": ["das", "bald", "Ver\u00b7weh\u00b7sung", "k\u00fcsst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Wo blihb die Amstel hin/", "tokens": ["Wo", "blihb", "die", "A\u00b7mstel", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "das Singe-V\u00f6gelgin?", "tokens": ["das", "Sin\u00b7ge\u00b7V\u00f6\u00b7gel\u00b7gin", "?"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Der Fr\u00f6schgen ihr ", "tokens": ["Der", "Fr\u00f6schgen", "ihr"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "beschehmbt nicht mehr Hann\u00df Sachs.", "tokens": ["be\u00b7schehmbt", "nicht", "mehr", "Hann\u00df", "Sachs", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Dr\u00fcmb sey es endlich hihr geklagt/", "tokens": ["Dr\u00fcmb", "sey", "es", "end\u00b7lich", "hihr", "ge\u00b7klagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "wa\u00df mir das Hertz benagt!", "tokens": ["wa\u00df", "mir", "das", "Hertz", "be\u00b7nagt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Unsre Gaben/ s\u00fcsses Kind/", "tokens": ["Uns\u00b7re", "Ga\u00b7ben", "/", "s\u00fcs\u00b7ses", "Kind", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "fl\u00fcchtig wie Narzissen sind/", "tokens": ["fl\u00fcch\u00b7tig", "wie", "Nar\u00b7zis\u00b7sen", "sind", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "NN", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und es f\u00e4hrt mit uns die Zeit", "tokens": ["und", "es", "f\u00e4hrt", "mit", "uns", "die", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "strakks in die Verg\u00e4ssenheit.", "tokens": ["strakks", "in", "die", "Ver\u00b7g\u00e4s\u00b7sen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Einst so welckt mir dihse Haut", "tokens": ["Einst", "so", "welckt", "mir", "dih\u00b7se", "Haut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "trukkner al\u00df ein Sommer-Kraut/", "tokens": ["trukk\u00b7ner", "al\u00df", "ein", "Som\u00b7mer\u00b7Kraut", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "einst so zwikkt mir dih\u00df Gebein", "tokens": ["einst", "so", "zwikkt", "mir", "dih\u00df", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PDS", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Bodagra und Zipperlein.", "tokens": ["Bo\u00b7da\u00b7gra", "und", "Zip\u00b7per\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Hengen la\u00df ich dan mein Maul", "tokens": ["Hen\u00b7gen", "la\u00df", "ich", "dan", "mein", "Maul"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "wie ein alter Karren-Gaul/", "tokens": ["wie", "ein", "al\u00b7ter", "Kar\u00b7ren\u00b7Gaul", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "stakkrich sezz ich Fuh\u00df for Fuh\u00df", "tokens": ["stak\u00b7krich", "sezz", "ich", "Fuh\u00df", "for", "Fuh\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "NE", "NE", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "wie ein steiffer Tapp-ins-Muh\u00df.", "tokens": ["wie", "ein", "steif\u00b7fer", "Tapp\u00b7ins\u00b7\u00b7M\u00b7uh\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Nachts/ wenn mich die Fl\u00f6he j\u00fckken/", "tokens": ["Nachts", "/", "wenn", "mich", "die", "Fl\u00f6\u00b7he", "j\u00fck\u00b7ken", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PPER", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "krault mir keine mehr den R\u00fckken/", "tokens": ["krault", "mir", "kei\u00b7ne", "mehr", "den", "R\u00fck\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "PIS", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "denn for sowa\u00df/ lihbes Kind/", "tokens": ["denn", "for", "so\u00b7wa\u00df", "/", "lih\u00b7bes", "Kind", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "$(", "ADJA", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "b\u00fcn ich dan zu keusch gesinnt.", "tokens": ["b\u00fcn", "ich", "dan", "zu", "keusch", "ge\u00b7sinnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKA", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "ist mir dan durchau\u00df zerschmoltzen/", "tokens": ["ist", "mir", "dan", "durch\u00b7au\u00df", "zer\u00b7schmolt\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "und ich seufftz die gantze Zeit", "tokens": ["und", "ich", "seufftz", "die", "gant\u00b7ze", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "in betr\u00fchbter Einsamkeit!", "tokens": ["in", "be\u00b7tr\u00fchb\u00b7ter", "Ein\u00b7sam\u00b7keit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Alles bl\u00fcht und mu\u00df vergehn/", "tokens": ["Al\u00b7les", "bl\u00fcht", "und", "mu\u00df", "ver\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "dir wird Gleiches mahl geschehn!", "tokens": ["dir", "wird", "Glei\u00b7ches", "mahl", "ge\u00b7schehn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die weissen Kugeln/ so sich itz", "tokens": ["Die", "weis\u00b7sen", "Ku\u00b7geln", "/", "so", "sich", "itz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "PRF", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "so s\u00fc\u00df und anmuhtsvoll bewegen/", "tokens": ["so", "s\u00fc\u00df", "und", "an\u00b7muhts\u00b7voll", "be\u00b7we\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "wird einst ein ungeheurer Plitz", "tokens": ["wird", "einst", "ein", "un\u00b7ge\u00b7heu\u00b7rer", "Plitz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "in nichts wie Staub und Asche legen.", "tokens": ["in", "nichts", "wie", "Staub", "und", "A\u00b7sche", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "KOKOM", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dan wird dich niemand mehr betasten/", "tokens": ["Dan", "wird", "dich", "nie\u00b7mand", "mehr", "be\u00b7tas\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "dan lihgt dein Leib im schwartzen Kasten/", "tokens": ["dan", "lihgt", "dein", "Leib", "im", "schwart\u00b7zen", "Kas\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "dan triefft/ dan stinckt nach Talg", "tokens": ["dan", "triefft", "/", "dan", "stinckt", "nach", "Talg"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$(", "ADV", "VVFIN", "APPR", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "dein runtzlig fauler Balg.", "tokens": ["dein", "runtz\u00b7lig", "fau\u00b7ler", "Balg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Dein Mund so s\u00fc\u00df benelckt", "tokens": ["Dein", "Mund", "so", "s\u00fc\u00df", "be\u00b7nelckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "klafft j\u00e4mmerlich verwelckt/", "tokens": ["klafft", "j\u00e4m\u00b7mer\u00b7lich", "ver\u00b7welckt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "von Rohsen nicht die Spur/", "tokens": ["von", "Roh\u00b7sen", "nicht", "die", "Spur", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "zwo trukkne Schruntzeln nur/", "tokens": ["zwo", "trukk\u00b7ne", "Schrunt\u00b7zeln", "nur", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "zerm\u00fcrbelt und zerbrochen/", "tokens": ["zer\u00b7m\u00fcr\u00b7belt", "und", "zer\u00b7bro\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "von Kr\u00f6ten \u00fcberkrochen!", "tokens": ["von", "Kr\u00f6\u00b7ten", "\u00fc\u00b7ber\u00b7kro\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "La\u00df die mit den weissen B\u00e4ffgen/", "tokens": ["La\u00df", "die", "mit", "den", "weis\u00b7sen", "B\u00e4ff\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sie seynd Aeffgen!", "tokens": ["sie", "seynd", "A\u00b7eff\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "La\u00df sie pappeln/ la\u00df sie plarren/", "tokens": ["La\u00df", "sie", "pap\u00b7peln", "/", "la\u00df", "sie", "plar\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$(", "VVIMP", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "sie seynd Narren!", "tokens": ["sie", "seynd", "Nar\u00b7ren", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Ob J\u00fcde/ Heyde/ oder Christ/", "tokens": ["Ob", "J\u00fc\u00b7de", "/", "Hey\u00b7de", "/", "o\u00b7der", "Christ", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "$(", "NE", "$(", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "er wird zu Mist!", "tokens": ["er", "wird", "zu", "Mist", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Morgen lengst ist alles au\u00df/", "tokens": ["Mor\u00b7gen", "lengst", "ist", "al\u00b7les", "au\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "VAFIN", "PIS", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "M\u00e4ntsch/ du bist nur eine Lau\u00df/", "tokens": ["M\u00e4ntsch", "/", "du", "bist", "nur", "ei\u00b7ne", "Lau\u00df", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPER", "VAFIN", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "morgen/ oder gar schon heut/", "tokens": ["mor\u00b7gen", "/", "o\u00b7der", "gar", "schon", "heut", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KON", "ADV", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "dr\u00f6hnt vom Thurm dein Grab-Gel\u00e4ut!", "tokens": ["dr\u00f6hnt", "vom", "Thurm", "dein", "Grab\u00b7Ge\u00b7l\u00e4ut", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Eins nur ist uns dan gewi\u00df:", "tokens": ["Eins", "nur", "ist", "uns", "dan", "ge\u00b7wi\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "schwartz-polihrte F\u00fcnsterni\u00df!", "tokens": ["schwartz\u00b7po\u00b7lihr\u00b7te", "F\u00fcns\u00b7ter\u00b7ni\u00df", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "La\u00df uns alles dr\u00fcmb vergessen/", "tokens": ["La\u00df", "uns", "al\u00b7les", "dr\u00fcmb", "ver\u00b7ges\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PIS", "PAV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rohsen pflantzen \u00fcmb Zypressen/", "tokens": ["Roh\u00b7sen", "pflant\u00b7zen", "\u00fcmb", "Zyp\u00b7res\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NE", "$("], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "die dein Auge/ wenn es strahlt/", "tokens": ["die", "dein", "Au\u00b7ge", "/", "wenn", "es", "strahlt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "gleichsahm wie mit Goldt bemahlt!", "tokens": ["gleich\u00b7sahm", "wie", "mit", "Goldt", "be\u00b7mahlt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Deinen weichen Alabaster", "tokens": ["Dei\u00b7nen", "wei\u00b7chen", "A\u00b7la\u00b7bas\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "trukk ihn auff mich r\u00e4cht al\u00df Pflaster/", "tokens": ["trukk", "ihn", "auff", "mich", "r\u00e4cht", "al\u00df", "Pflas\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "VVFIN", "KOUS", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Mund an Mund und Brust an Brust/", "tokens": ["Mund", "an", "Mund", "und", "Brust", "an", "Brust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "in verschwihgner G\u00f6tter-Lust/", "tokens": ["in", "ver\u00b7schwihg\u00b7ner", "G\u00f6t\u00b7ter\u00b7Lust", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "bi\u00df ihr P\u00e4rlen-Safft dich/ Kind/", "tokens": ["bi\u00df", "ihr", "P\u00e4r\u00b7len\u00b7\u00b7S\u00b7afft", "dich", "/", "Kind", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "$(", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "gantz durchrinnt!", "tokens": ["gantz", "durch\u00b7rinnt", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.13": {"line.1": {"text": "Ob sie Jungffern oder Huren/", "tokens": ["Ob", "sie", "Jungf\u00b7fern", "o\u00b7der", "Hu\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "alle in die Grube fuhren/", "tokens": ["al\u00b7le", "in", "die", "Gru\u00b7be", "fuh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "nichts mehr war ihr Sch\u00f6n-Seyn n\u00fczze", "tokens": ["nichts", "mehr", "war", "ihr", "Sch\u00f6n\u00b7Seyn", "n\u00fcz\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ADV", "VAFIN", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "in der schwartzen Lethe-Pf\u00fczze!", "tokens": ["in", "der", "schwart\u00b7zen", "Lethe\u00b7P\u00b7f\u00fcz\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Selbst ", "tokens": ["Selbst"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "ist Stanck und Gifft seit dausend Jahren!", "tokens": ["ist", "Stanck", "und", "Gifft", "seit", "dau\u00b7send", "Jah\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dr\u00fcmb so k\u00fcnt es fast geschehn/", "tokens": ["Dr\u00fcmb", "so", "k\u00fcnt", "es", "fast", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "da\u00df die Augen mir voll Wasser stehn!", "tokens": ["da\u00df", "die", "Au\u00b7gen", "mir", "voll", "Was\u00b7ser", "stehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "ADJD", "NN", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.14": {"line.1": {"text": "Wa\u00df ist die Welt und ihr ber\u00fchmbtes Gl\u00e4ntzen?", "tokens": ["Wa\u00df", "ist", "die", "Welt", "und", "ihr", "be\u00b7r\u00fchmb\u00b7tes", "Gl\u00e4nt\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Blizz bey Nacht.", "tokens": ["Ein", "Blizz", "bey", "Nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Eh welcke Rohsen eure Scheitel kr\u00e4ntzen/", "tokens": ["Eh", "wel\u00b7cke", "Roh\u00b7sen", "eu\u00b7re", "Schei\u00b7tel", "kr\u00e4nt\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWAT", "NN", "PPOSAT", "NN", "VVINF", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "singt/ drinckt und lacht!", "tokens": ["singt", "/", "drinckt", "und", "lacht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Heut sind wir noch jung und roht/", "tokens": ["Heut", "sind", "wir", "noch", "jung", "und", "roht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "morgen hat uns schon der Dodt/", "tokens": ["mor\u00b7gen", "hat", "uns", "schon", "der", "Dodt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "morgen sind wir Asche!", "tokens": ["mor\u00b7gen", "sind", "wir", "A\u00b7sche", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}