{"textgrid.poem.53858": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Winke-winke", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": " dem Andenken des ermordeten Hans Paasche", "tokens": ["dem", "An\u00b7den\u00b7ken", "des", "er\u00b7mor\u00b7de\u00b7ten", "Hans", "Paa\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NE", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Nun schwimm man ab.", "tokens": ["Nun", "schwimm", "man", "ab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Wir haben lang genug geh\u00f6rt:", "tokens": ["Wir", "ha\u00b7ben", "lang", "ge\u00b7nug", "ge\u00b7h\u00f6rt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbich wei\u00df von nichts. Ich bin es nicht gewesen.\u00ab", "tokens": ["\u00bb", "ich", "wei\u00df", "von", "nichts", ".", "Ich", "bin", "es", "nicht", "ge\u00b7we\u00b7sen", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "PIS", "$.", "PPER", "VAFIN", "PPER", "PTKNEG", "VAPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und immer, wenn wer deine Leutnants st\u00f6rt,", "tokens": ["Und", "im\u00b7mer", ",", "wenn", "wer", "dei\u00b7ne", "Leut\u00b7nants", "st\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PWS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "dann konnten wir ein klein Dementi lesen.", "tokens": ["dann", "konn\u00b7ten", "wir", "ein", "klein", "De\u00b7men\u00b7ti", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das wertete dann jeder nach Geb\u00fchr.", "tokens": ["Das", "wer\u00b7te\u00b7te", "dann", "je\u00b7der", "nach", "Ge\u00b7b\u00fchr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Denn du kannst nichts daf\u00fcr.", "tokens": ["Denn", "du", "kannst", "nichts", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PIS", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wie stark ist denn dein werter Schie\u00dfverein?", "tokens": ["Wie", "stark", "ist", "denn", "dein", "wer\u00b7ter", "Schie\u00df\u00b7ver\u00b7ein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbdie Finger weg! Das Heer ist stets geheiligt!\u00ab", "tokens": ["\u00bb", "die", "Fin\u00b7ger", "weg", "!", "Das", "Heer", "ist", "stets", "ge\u00b7hei\u00b7ligt", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "PTKVZ", "$.", "ART", "NN", "VAFIN", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Auf allen Fu\u00dfballpl\u00e4tzen \u00fcbt sich wer was ein,", "tokens": ["Auf", "al\u00b7len", "Fu\u00df\u00b7ball\u00b7pl\u00e4t\u00b7zen", "\u00fcbt", "sich", "wer", "was", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PRF", "PWS", "PWS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und niemals ist die Reichswehr dran beteiligt.", "tokens": ["und", "nie\u00b7mals", "ist", "die", "Reichs\u00b7wehr", "dran", "be\u00b7tei\u00b7ligt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Wehrverb\u00e4nde? Fememordgeschw\u00fcr?", "tokens": ["Die", "Wehr\u00b7ver\u00b7b\u00e4n\u00b7de", "?", "Fe\u00b7me\u00b7mord\u00b7ge\u00b7schw\u00fcr", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Nie kannst du was daf\u00fcr.", "tokens": ["Nie", "kannst", "du", "was", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Du \u00fcbernahmst das Heer der Republik.", "tokens": ["Du", "\u00fc\u00b7bern\u00b7ahmst", "das", "Heer", "der", "Re\u00b7pub\u00b7lik", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Was tatest du? Du wahrst die Traditionen.", "tokens": ["Was", "ta\u00b7test", "du", "?", "Du", "wahrst", "die", "Tra\u00b7di\u00b7ti\u00b7o\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und die die Wahrheit sagten in der Politik,", "tokens": ["Und", "die", "die", "Wahr\u00b7heit", "sag\u00b7ten", "in", "der", "Po\u00b7li\u00b7tik", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "die d\u00fcrfen heut \u2013 dank dir \u2013 im Zuchthaus wohnen.", "tokens": ["die", "d\u00fcr\u00b7fen", "heut", "\u2013", "dank", "dir", "\u2013", "im", "Zucht\u00b7haus", "woh\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "$(", "APPR", "PPER", "$(", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Scharf schnappt ins Schlo\u00df die kleine Zellent\u00fcr.", "tokens": ["Scharf", "schnappt", "ins", "Schlo\u00df", "die", "klei\u00b7ne", "Zel\u00b7len\u00b7t\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und du kannst nichts daf\u00fcr.", "tokens": ["Und", "du", "kannst", "nichts", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PIS", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Nun schwimm man ab, du s\u00fc\u00dfes Ornament.", "tokens": ["Nun", "schwimm", "man", "ab", ",", "du", "s\u00fc\u00b7\u00dfes", "Or\u00b7na\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sieh, deine kleine Schwarze ist erwachsen heute . . .", "tokens": ["Sieh", ",", "dei\u00b7ne", "klei\u00b7ne", "Schwar\u00b7ze", "ist", "er\u00b7wach\u00b7sen", "heu\u00b7te", ".", ".", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "$,", "PPOSAT", "ADJA", "NN", "VAFIN", "VVPP", "ADV", "$.", "$.", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du wirst wahrscheinlich Oberpr\u00e4sident;", "tokens": ["Du", "wirst", "wahr\u00b7schein\u00b7lich", "O\u00b7ber\u00b7pr\u00e4\u00b7si\u00b7dent", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "denn so belohnt man hierzuland die gro\u00dfen Leute.", "tokens": ["denn", "so", "be\u00b7lohnt", "man", "hier\u00b7zu\u00b7land", "die", "gro\u00b7\u00dfen", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir k\u00f6nnen uns bei dir bedanken. R\u00fchr", "tokens": ["Wir", "k\u00f6n\u00b7nen", "uns", "bei", "dir", "be\u00b7dan\u00b7ken", ".", "R\u00fchr"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$.", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "dich endlich, Otto.", "tokens": ["dich", "end\u00b7lich", ",", "Ot\u00b7to", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "$,", "NE", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Du kannst nichts daf\u00fcr.", "tokens": ["Du", "kannst", "nichts", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "PAV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": " dem Andenken des ermordeten Hans Paasche", "tokens": ["dem", "An\u00b7den\u00b7ken", "des", "er\u00b7mor\u00b7de\u00b7ten", "Hans", "Paa\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NE", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Nun schwimm man ab.", "tokens": ["Nun", "schwimm", "man", "ab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Wir haben lang genug geh\u00f6rt:", "tokens": ["Wir", "ha\u00b7ben", "lang", "ge\u00b7nug", "ge\u00b7h\u00f6rt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbich wei\u00df von nichts. Ich bin es nicht gewesen.\u00ab", "tokens": ["\u00bb", "ich", "wei\u00df", "von", "nichts", ".", "Ich", "bin", "es", "nicht", "ge\u00b7we\u00b7sen", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "PIS", "$.", "PPER", "VAFIN", "PPER", "PTKNEG", "VAPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und immer, wenn wer deine Leutnants st\u00f6rt,", "tokens": ["Und", "im\u00b7mer", ",", "wenn", "wer", "dei\u00b7ne", "Leut\u00b7nants", "st\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PWS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "dann konnten wir ein klein Dementi lesen.", "tokens": ["dann", "konn\u00b7ten", "wir", "ein", "klein", "De\u00b7men\u00b7ti", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das wertete dann jeder nach Geb\u00fchr.", "tokens": ["Das", "wer\u00b7te\u00b7te", "dann", "je\u00b7der", "nach", "Ge\u00b7b\u00fchr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Denn du kannst nichts daf\u00fcr.", "tokens": ["Denn", "du", "kannst", "nichts", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PIS", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Wie stark ist denn dein werter Schie\u00dfverein?", "tokens": ["Wie", "stark", "ist", "denn", "dein", "wer\u00b7ter", "Schie\u00df\u00b7ver\u00b7ein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbdie Finger weg! Das Heer ist stets geheiligt!\u00ab", "tokens": ["\u00bb", "die", "Fin\u00b7ger", "weg", "!", "Das", "Heer", "ist", "stets", "ge\u00b7hei\u00b7ligt", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "PTKVZ", "$.", "ART", "NN", "VAFIN", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Auf allen Fu\u00dfballpl\u00e4tzen \u00fcbt sich wer was ein,", "tokens": ["Auf", "al\u00b7len", "Fu\u00df\u00b7ball\u00b7pl\u00e4t\u00b7zen", "\u00fcbt", "sich", "wer", "was", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PRF", "PWS", "PWS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und niemals ist die Reichswehr dran beteiligt.", "tokens": ["und", "nie\u00b7mals", "ist", "die", "Reichs\u00b7wehr", "dran", "be\u00b7tei\u00b7ligt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Wehrverb\u00e4nde? Fememordgeschw\u00fcr?", "tokens": ["Die", "Wehr\u00b7ver\u00b7b\u00e4n\u00b7de", "?", "Fe\u00b7me\u00b7mord\u00b7ge\u00b7schw\u00fcr", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Nie kannst du was daf\u00fcr.", "tokens": ["Nie", "kannst", "du", "was", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Du \u00fcbernahmst das Heer der Republik.", "tokens": ["Du", "\u00fc\u00b7bern\u00b7ahmst", "das", "Heer", "der", "Re\u00b7pub\u00b7lik", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Was tatest du? Du wahrst die Traditionen.", "tokens": ["Was", "ta\u00b7test", "du", "?", "Du", "wahrst", "die", "Tra\u00b7di\u00b7ti\u00b7o\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und die die Wahrheit sagten in der Politik,", "tokens": ["Und", "die", "die", "Wahr\u00b7heit", "sag\u00b7ten", "in", "der", "Po\u00b7li\u00b7tik", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "die d\u00fcrfen heut \u2013 dank dir \u2013 im Zuchthaus wohnen.", "tokens": ["die", "d\u00fcr\u00b7fen", "heut", "\u2013", "dank", "dir", "\u2013", "im", "Zucht\u00b7haus", "woh\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "$(", "APPR", "PPER", "$(", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Scharf schnappt ins Schlo\u00df die kleine Zellent\u00fcr.", "tokens": ["Scharf", "schnappt", "ins", "Schlo\u00df", "die", "klei\u00b7ne", "Zel\u00b7len\u00b7t\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und du kannst nichts daf\u00fcr.", "tokens": ["Und", "du", "kannst", "nichts", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PIS", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Nun schwimm man ab, du s\u00fc\u00dfes Ornament.", "tokens": ["Nun", "schwimm", "man", "ab", ",", "du", "s\u00fc\u00b7\u00dfes", "Or\u00b7na\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sieh, deine kleine Schwarze ist erwachsen heute . . .", "tokens": ["Sieh", ",", "dei\u00b7ne", "klei\u00b7ne", "Schwar\u00b7ze", "ist", "er\u00b7wach\u00b7sen", "heu\u00b7te", ".", ".", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "$,", "PPOSAT", "ADJA", "NN", "VAFIN", "VVPP", "ADV", "$.", "$.", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du wirst wahrscheinlich Oberpr\u00e4sident;", "tokens": ["Du", "wirst", "wahr\u00b7schein\u00b7lich", "O\u00b7ber\u00b7pr\u00e4\u00b7si\u00b7dent", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "denn so belohnt man hierzuland die gro\u00dfen Leute.", "tokens": ["denn", "so", "be\u00b7lohnt", "man", "hier\u00b7zu\u00b7land", "die", "gro\u00b7\u00dfen", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir k\u00f6nnen uns bei dir bedanken. R\u00fchr", "tokens": ["Wir", "k\u00f6n\u00b7nen", "uns", "bei", "dir", "be\u00b7dan\u00b7ken", ".", "R\u00fchr"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$.", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "dich endlich, Otto.", "tokens": ["dich", "end\u00b7lich", ",", "Ot\u00b7to", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "$,", "NE", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Du kannst nichts daf\u00fcr.", "tokens": ["Du", "kannst", "nichts", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "PAV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}