{"dta.poem.5512": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Anderweitige  B etrachtung  \n Der Gr\u00f6sse GOTTES  \n In seiner Vorherversehung und F\u00fchrung  \n bey dem 1732sten Jahrs-Wechsel.  \n Bewei\u00df, da\u00df eine so grosse, auch auf Kleinigkei-  \n ten gerichtete Providentz und Vorsorge eben etwas  \n G\u00f6ttliches und eine aller Menschen und anderer  \n Geister Begriff \u00fcbersteigende Kraft und  \n Weisheit sey.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Auf, auf, mein Geist! auf, auf, bereite dich,", "tokens": ["Auf", ",", "auf", ",", "mein", "Geist", "!", "auf", ",", "auf", ",", "be\u00b7rei\u00b7te", "dich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "$,", "PTKVZ", "$,", "PPOSAT", "NN", "$.", "PTKVZ", "$,", "PTKVZ", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dem Sch\u00f6pfer der Natur zum Ruhm, von neuen,", "tokens": ["Dem", "Sch\u00f6p\u00b7fer", "der", "Na\u00b7tur", "zum", "Ruhm", ",", "von", "neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPRART", "NN", "$,", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zu dieser Wechsel-Zeit recht innig dich zu freuen!", "tokens": ["Zu", "die\u00b7ser", "Wech\u00b7sel\u00b7Zeit", "recht", "in\u00b7nig", "dich", "zu", "freu\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "ADJD", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dein grosses Wohn-Hau\u00df drehet sich", "tokens": ["Dein", "gros\u00b7ses", "Wohn\u00b7Hau\u00df", "dre\u00b7het", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nicht mehr, so wie vorhero, von der Sonne;", "tokens": ["Nicht", "mehr", ",", "so", "wie", "vor\u00b7he\u00b7ro", ",", "von", "der", "Son\u00b7ne", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,", "ADV", "KOKOM", "ADV", "$,", "APPR", "ART", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Wir n\u00e4hern uns dem Licht und Lebens-Strahl,", "tokens": ["Wir", "n\u00e4\u00b7hern", "uns", "dem", "Licht", "und", "Le\u00b7bens\u00b7Strahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Zu unserm Nutz, zu unsrer Lust und Wonne,", "tokens": ["Zu", "un\u00b7serm", "Nutz", ",", "zu", "uns\u00b7rer", "Lust", "und", "Won\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Nach GOttes Ordnung abermahl.", "tokens": ["Nach", "Got\u00b7tes", "Ord\u00b7nung", "a\u00b7ber\u00b7mahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Weil dieses nun, da\u00df man die Wunder-Wercke", "tokens": ["Weil", "die\u00b7ses", "nun", ",", "da\u00df", "man", "die", "Wun\u00b7der\u00b7\u00b7Wer\u00b7cke"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "ADV", "$,", "KOUS", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Des herrlichen Regirers wol bemercke,", "tokens": ["Des", "herr\u00b7li\u00b7chen", "Re\u00b7gi\u00b7rers", "wol", "be\u00b7mer\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Mehr als zu wol verdient; so soll mich diese Zeit", "tokens": ["Mehr", "als", "zu", "wol", "ver\u00b7dient", ";", "so", "soll", "mich", "die\u00b7se", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "KOKOM", "APPR", "ADV", "VVPP", "$.", "ADV", "VMFIN", "PRF", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So wol zum Danck, als Lobe, treiben;", "tokens": ["So", "wol", "zum", "Danck", ",", "als", "Lo\u00b7be", ",", "trei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "$,", "KOUS", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Ich will, nach meiner Pflicht und aller M\u00f6glichkeit,", "tokens": ["Ich", "will", ",", "nach", "mei\u00b7ner", "Pflicht", "und", "al\u00b7ler", "M\u00f6g\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "APPR", "PPOSAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Zu dessen Preis\u2019 und Ruhm, gedencken, reden, schreiben,", "tokens": ["Zu", "des\u00b7sen", "Preis'", "und", "Ruhm", ",", "ge\u00b7den\u00b7cken", ",", "re\u00b7den", ",", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "KON", "NN", "$,", "NN", "$,", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der alle Welt- und Himmel-Heere,", "tokens": ["Der", "al\u00b7le", "Welt", "und", "Him\u00b7mel\u00b7Hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Jm Grund- und Gr\u00e4ntzen-losen Meere", "tokens": ["Jm", "Grun\u00b7d", "und", "Gr\u00e4nt\u00b7zen\u00b7lo\u00b7sen", "Mee\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "TRUNC", "KON", "NN", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Des allgemeinen Raums, gemacht, erh\u00e4lt und f\u00fchrt,", "tokens": ["Des", "all\u00b7ge\u00b7mei\u00b7nen", "Raums", ",", "ge\u00b7macht", ",", "er\u00b7h\u00e4lt", "und", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVPP", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ja alles, was darin, zu seiner ew\u2019gen Ehre", "tokens": ["Ja", "al\u00b7les", ",", "was", "da\u00b7rin", ",", "zu", "sei\u00b7ner", "ew'\u00b7gen", "Eh\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "PIS", "$,", "PRELS", "PAV", "$,", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und einem weisen Zweck, regirt!", "tokens": ["Und", "ei\u00b7nem", "wei\u00b7sen", "Zweck", ",", "re\u00b7girt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Grund- und Gr\u00e4ntzen-lose Tieffe seel'ger Liebe!\nhelle Klarheit", "tokens": ["Grun\u00b7d", "und", "Gr\u00e4nt\u00b7zen\u00b7lo\u00b7se", "Tief\u00b7fe", "seel'\u00b7ger", "Lie\u00b7be", "!", "hel\u00b7le", "Klar\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["TRUNC", "KON", "NN", "ADJA", "ADJA", "NN", "$.", "ADJA", "NN"], "meter": "+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.invert"}, "line.2": {"text": "Eines nie-durchdrungnen Lichts! ewige, selbst\u00e4nd'ge\nWahrheit!", "tokens": ["Ei\u00b7nes", "nie\u00b7durch\u00b7drung\u00b7nen", "Lichts", "!", "e\u00b7wi\u00b7ge", ",", "selb\u00b7st\u00e4n\u00b7d'\u00b7ge", "Wahr\u00b7heit", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "G\u00f6nne mir auch dieses mahl", "tokens": ["G\u00f6n\u00b7ne", "mir", "auch", "die\u00b7ses", "mahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aus dem Meere deiner Weisheit einen hellen Gna-\nden-Strahl,", "tokens": ["Aus", "dem", "Mee\u00b7re", "dei\u00b7ner", "Weis\u00b7heit", "ei\u00b7nen", "hel\u00b7len", "Gna", "den\u00b7Strahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "ART", "ADJA", "TRUNC", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.5": {"text": "Da\u00df ich, deiner Herrlichkeit, Weisheit', Lieb' und\nMacht zum Preise,", "tokens": ["Da\u00df", "ich", ",", "dei\u00b7ner", "Herr\u00b7lich\u00b7keit", ",", "Weis\u00b7heit'", ",", "Lieb'", "und", "Macht", "zum", "Prei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PPOSAT", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Nach Verm\u00f6gen, deine Wege mir und vielen andern\nweise!", "tokens": ["Nach", "Ver\u00b7m\u00f6\u00b7gen", ",", "dei\u00b7ne", "We\u00b7ge", "mir", "und", "vie\u00b7len", "an\u00b7dern", "wei\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PPOSAT", "NN", "PPER", "KON", "PIAT", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.7": {"text": "Sch\u00e4rffe mir, zu diesem Endzweck, selbst die Kr\u00e4fte\nmeiner Sinnen!", "tokens": ["Sch\u00e4rf\u00b7fe", "mir", ",", "zu", "die\u00b7sem", "End\u00b7zweck", ",", "selbst", "die", "Kr\u00e4f\u00b7te", "mei\u00b7ner", "Sin\u00b7nen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "PDAT", "NN", "$,", "ADV", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.8": {"text": "La\u00df mein Dencken dir gefallen! Segne selber mein\nBeginnen!", "tokens": ["La\u00df", "mein", "Den\u00b7cken", "dir", "ge\u00b7fal\u00b7len", "!", "Seg\u00b7ne", "sel\u00b7ber", "mein", "Be\u00b7gin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "PPER", "VVPP", "$.", "NE", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.3": {"line.1": {"text": "Wir haben, im verwichnen Jahr,", "tokens": ["Wir", "ha\u00b7ben", ",", "im", "ver\u00b7wich\u00b7nen", "Jahr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Theilchen grosse Meng\u2019 und ungeheure Schaar,", "tokens": ["Der", "Theil\u00b7chen", "gros\u00b7se", "Meng'", "und", "un\u00b7ge\u00b7heu\u00b7re", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die allen Engeln, Geistern, Seelen", "tokens": ["Die", "al\u00b7len", "En\u00b7geln", ",", "Geis\u00b7tern", ",", "See\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ART", "PIAT", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Unm\u00f6glich f\u00e4llt zu kennen und zu zehlen,", "tokens": ["Un\u00b7m\u00f6g\u00b7lich", "f\u00e4llt", "zu", "ken\u00b7nen", "und", "zu", "zeh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Aus welchen alle Ding\u2019 entstehen und bestehen,", "tokens": ["Aus", "wel\u00b7chen", "al\u00b7le", "Ding'", "ent\u00b7ste\u00b7hen", "und", "be\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PIAT", "NN", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu ihres Sch\u00f6pfers Ruhm, erstaunet, angesehen.", "tokens": ["Zu", "ih\u00b7res", "Sch\u00f6p\u00b7fers", "Ruhm", ",", "er\u00b7stau\u00b7net", ",", "an\u00b7ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wir haben auf die Zahl absonderlich geachtet,", "tokens": ["Wir", "ha\u00b7ben", "auf", "die", "Zahl", "ab\u00b7son\u00b7der\u00b7lich", "ge\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wir haben einiger derselben Regeln, Kr\u00e4fte,", "tokens": ["Wir", "ha\u00b7ben", "ei\u00b7ni\u00b7ger", "der\u00b7sel\u00b7ben", "Re\u00b7geln", ",", "Kr\u00e4f\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "PDAT", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Gesetz und Ordnungen betrachtet.", "tokens": ["Ge\u00b7setz", "und", "Ord\u00b7nun\u00b7gen", "be\u00b7trach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Jetzt f\u00fchl\u2019 ich einen Trieb in mir,", "tokens": ["Jetzt", "f\u00fchl'", "ich", "ei\u00b7nen", "Trieb", "in", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Annoch zum edlern Zweck und herrlichern Gesch\u00e4fte", "tokens": ["An\u00b7noch", "zum", "ed\u00b7lern", "Zweck", "und", "herr\u00b7li\u00b7chern", "Ge\u00b7sch\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPRART", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Seelen Kraft zu lencken, zu erheben,", "tokens": ["Der", "See\u00b7len", "Kraft", "zu", "len\u00b7cken", ",", "zu", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und, in der herrlichen Regierung", "tokens": ["Und", ",", "in", "der", "herr\u00b7li\u00b7chen", "Re\u00b7gie\u00b7rung"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und aller dieser Theil\u2019 unendlich weisen F\u00fchrung,", "tokens": ["Und", "al\u00b7ler", "die\u00b7ser", "Theil'", "un\u00b7end\u00b7lich", "wei\u00b7sen", "F\u00fch\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PDAT", "NN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der GOttheit weise Macht zum Ruhm, mich zu bestreben.", "tokens": ["Der", "Got\u00b7theit", "wei\u00b7se", "Macht", "zum", "Ruhm", ",", "mich", "zu", "be\u00b7stre\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPRART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Auf diese Weise wird der GOttheit Licht und Schein", "tokens": ["Auf", "die\u00b7se", "Wei\u00b7se", "wird", "der", "Got\u00b7theit", "Licht", "und", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Am herrlichsten erkannt, ger\u00fchmet und gepriesen;", "tokens": ["Am", "herr\u00b7lichs\u00b7ten", "er\u00b7kannt", ",", "ge\u00b7r\u00fch\u00b7met", "und", "ge\u00b7prie\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVPP", "$,", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man wird zugleich, was er auch uns erwiesen,", "tokens": ["Man", "wird", "zu\u00b7gleich", ",", "was", "er", "auch", "uns", "er\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "$,", "PWS", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was er f\u00fcr eine Kraft in unsern Geist gesencket,", "tokens": ["Was", "er", "f\u00fcr", "ei\u00b7ne", "Kraft", "in", "un\u00b7sern", "Geist", "ge\u00b7sen\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und wie, wenn man von ihm was w\u00fcrdiges gedencket,", "tokens": ["Und", "wie", ",", "wenn", "man", "von", "ihm", "was", "w\u00fcr\u00b7di\u00b7ges", "ge\u00b7den\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "$,", "KOUS", "PIS", "APPR", "PPER", "PIS", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wir ihn, durch uns, uns selbst in ihm, erh\u00f6h\u2019n,", "tokens": ["Wir", "ihn", ",", "durch", "uns", ",", "uns", "selbst", "in", "ihm", ",", "er\u00b7h\u00f6h'n", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "PPER", "$,", "APPR", "PPER", "$,", "PPER", "ADV", "APPR", "PPER", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Recht \u00fcberzeuglich sehn.", "tokens": ["Recht", "\u00fc\u00b7berz\u00b7eug\u00b7lich", "sehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Selbst\u00e4ndige Weisheit! selbst\u00e4ndige G\u00fcte!", "tokens": ["Selb\u00b7st\u00e4n\u00b7di\u00b7ge", "Weis\u00b7heit", "!", "selb\u00b7st\u00e4n\u00b7di\u00b7ge", "G\u00fc\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Unendlicher Ursprung der ewigen Wahrheit!", "tokens": ["Un\u00b7end\u00b7li\u00b7cher", "Ur\u00b7sprung", "der", "e\u00b7wi\u00b7gen", "Wahr\u00b7heit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Erleuchte du selbst mein verfinstert Gem\u00fcthe", "tokens": ["Er\u00b7leuch\u00b7te", "du", "selbst", "mein", "ver\u00b7fins\u00b7tert", "Ge\u00b7m\u00fc\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "VVFIN", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Mit einer dich heller entdeckenden Klarheit!", "tokens": ["Mit", "ei\u00b7ner", "dich", "hel\u00b7ler", "ent\u00b7de\u00b7cken\u00b7den", "Klar\u00b7heit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPER", "ADJD", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.5": {"text": "Die Wunder, die Himmel und Erden erf\u00fcllen,", "tokens": ["Die", "Wun\u00b7der", ",", "die", "Him\u00b7mel", "und", "Er\u00b7den", "er\u00b7f\u00fcl\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.6": {"text": "Entstehen aus deinem allm\u00e4chtigen Willen;", "tokens": ["Ent\u00b7ste\u00b7hen", "aus", "dei\u00b7nem", "all\u00b7m\u00e4ch\u00b7ti\u00b7gen", "Wil\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.7": {"text": "Bestehen durch deine best\u00e4ndige Macht;", "tokens": ["Be\u00b7ste\u00b7hen", "durch", "dei\u00b7ne", "be\u00b7st\u00e4n\u00b7di\u00b7ge", "Macht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.8": {"text": "Geschehen, wie du es vorhero gedacht!", "tokens": ["Ge\u00b7sche\u00b7hen", ",", "wie", "du", "es", "vor\u00b7he\u00b7ro", "ge\u00b7dacht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Da\u00df unz\u00e4hliche Gesch\u00f6pfe in den Himmeln, auf der Welt,", "tokens": ["Da\u00df", "un\u00b7z\u00e4h\u00b7li\u00b7che", "Ge\u00b7sch\u00f6p\u00b7fe", "in", "den", "Him\u00b7meln", ",", "auf", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-++-+-+-+-+-+-+", "measure": "unknown.measure.octa.plus"}, "line.2": {"text": "Durch die Allmachts-volle GOttheit sind erschaffen und", "tokens": ["Durch", "die", "All\u00b7machts\u00b7vol\u00b7le", "Got\u00b7theit", "sind", "er\u00b7schaf\u00b7fen", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "VVPP", "KON"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Da\u00df zugleich sein weiser Wille solche Creatur erh\u00e4lt,", "tokens": ["Da\u00df", "zu\u00b7gleich", "sein", "wei\u00b7ser", "Wil\u00b7le", "sol\u00b7che", "Crea\u00b7tur", "er\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "ADJA", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+--+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Haben wir in vor\u2019gem Jahr, wie bereits gesagt, verstanden;", "tokens": ["Ha\u00b7ben", "wir", "in", "vor'\u00b7gem", "Jahr", ",", "wie", "be\u00b7reits", "ge\u00b7sagt", ",", "ver\u00b7stan\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ADJA", "NN", "$,", "PWAV", "ADV", "VVPP", "$,", "VVPP", "$."], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "W\u00e4ren nun die Creaturen, der Natur nach, und in sich,", "tokens": ["W\u00e4\u00b7ren", "nun", "die", "Crea\u00b7tu\u00b7ren", ",", "der", "Na\u00b7tur", "nach", ",", "und", "in", "sich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "ART", "NN", "PTKVZ", "$,", "KON", "APPR", "PRF", "$,"], "meter": "+--+-+-+-+-+-+", "measure": "iambic.septa.invert"}, "line.6": {"text": "Nicht der Aendrung unterworffen, sondern unver\u00e4nderlich;", "tokens": ["Nicht", "der", "A\u00b7en\u00b7drung", "un\u00b7ter\u00b7worf\u00b7fen", ",", "son\u00b7dern", "un\u00b7ver\u00b7\u00e4n\u00b7der\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VVPP", "$,", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.7": {"text": "W\u00fcrde, nebst derselben ", "tokens": ["W\u00fcr\u00b7de", ",", "nebst", "der\u00b7sel\u00b7ben"], "token_info": ["word", "punct", "word", "word"], "pos": ["VAFIN", "$,", "APPR", "PDAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Zu derselben Daur und Wesen, unumg\u00e4nglich n\u00f6thig seyn.", "tokens": ["Zu", "der\u00b7sel\u00b7ben", "Daur", "und", "We\u00b7sen", ",", "un\u00b7um\u00b7g\u00e4ng\u00b7lich", "n\u00f6\u00b7thig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "KON", "NN", "$,", "ADJD", "ADJD", "VAINF", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.8": {"line.1": {"text": "Aber da die Creatur bald sich \u00e4ndert, bald vergehet,", "tokens": ["A\u00b7ber", "da", "die", "Crea\u00b7tur", "bald", "sich", "\u00e4n\u00b7dert", ",", "bald", "ver\u00b7ge\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADV", "PRF", "VVFIN", "$,", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.2": {"text": "Stirbet, aufgel\u00f6set wird, k\u00f6mmt, verweset und entstehet,", "tokens": ["Stir\u00b7bet", ",", "auf\u00b7ge\u00b7l\u00f6\u00b7set", "wird", ",", "k\u00f6mmt", ",", "ver\u00b7we\u00b7set", "und", "ent\u00b7ste\u00b7het", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVPP", "VAFIN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Und doch alles, nach der Maasse, Ordnung, Regeln und", "tokens": ["Und", "doch", "al\u00b7les", ",", "nach", "der", "Maas\u00b7se", ",", "Ord\u00b7nung", ",", "Re\u00b7geln", "und"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "PIS", "$,", "APPR", "ART", "NN", "$,", "NN", "$,", "NN", "KON"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.4": {"text": "Sich ver\u00e4ndert, sich beweget, steht, vergehet und geschicht;", "tokens": ["Sich", "ver\u00b7\u00e4n\u00b7dert", ",", "sich", "be\u00b7we\u00b7get", ",", "steht", ",", "ver\u00b7ge\u00b7het", "und", "ge\u00b7schicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "VVPP", "$,", "PRF", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.9": {"line.1": {"text": "Sieht man ja wol \u00fcberzeuglich, da\u00df solch\u2019 eine weise F\u00fchrung", "tokens": ["Sieht", "man", "ja", "wol", "\u00fc\u00b7berz\u00b7eug\u00b7lich", ",", "da\u00df", "solch'", "ei\u00b7ne", "wei\u00b7se", "F\u00fch\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "ADV", "ADJD", "$,", "KOUS", "PIAT", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "So ver\u00e4nderlicher Dinge, solche richtige Regirung", "tokens": ["So", "ver\u00b7\u00e4n\u00b7der\u00b7li\u00b7cher", "Din\u00b7ge", ",", "sol\u00b7che", "rich\u00b7ti\u00b7ge", "Re\u00b7gi\u00b7rung"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "$,", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Solcher ungef\u00fcgten Theile, der unz\u00e4hlich vielerley,", "tokens": ["Sol\u00b7cher", "un\u00b7ge\u00b7f\u00fcg\u00b7ten", "Thei\u00b7le", ",", "der", "un\u00b7z\u00e4h\u00b7lich", "vie\u00b7ler\u00b7ley", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PRELS", "ADJD", "PIAT", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Sonder eine ", "tokens": ["Son\u00b7der", "ei\u00b7ne"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.10": {"line.1": {"text": "Es wird keiner l\u00e4ugnen k\u00f6nnen, da\u00df auf unserm Kreis", "tokens": ["Es", "wird", "kei\u00b7ner", "l\u00e4ug\u00b7nen", "k\u00f6n\u00b7nen", ",", "da\u00df", "auf", "un\u00b7serm", "Kreis"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIS", "VVINF", "VMINF", "$,", "KOUS", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.2": {"text": "Nicht nur viele ", "tokens": ["Nicht", "nur", "vie\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "ADV", "PIAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Sondern auch in allen C\u00f6rpern und in der Materie", "tokens": ["Son\u00b7dern", "auch", "in", "al\u00b7len", "C\u00f6r\u00b7pern", "und", "in", "der", "Ma\u00b7te\u00b7rie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PIAT", "NN", "KON", "APPR", "ART", "NN"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Erstere sind: die wir f\u00fchlen, h\u00f6ren, riechen, schmecken, sehen;", "tokens": ["Ers\u00b7te\u00b7re", "sind", ":", "die", "wir", "f\u00fch\u00b7len", ",", "h\u00f6\u00b7ren", ",", "rie\u00b7chen", ",", "schme\u00b7cken", ",", "se\u00b7hen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PIS", "VAFIN", "$.", "PRELS", "PPER", "VVFIN", "$,", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.5": {"text": "Letztere sind dennoch ", "tokens": ["Letz\u00b7te\u00b7re", "sind", "den\u00b7noch"], "token_info": ["word", "word", "word"], "pos": ["PIS", "VAFIN", "ADV"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.6": {"text": "Da die Sonne lieblich scheinet. Bey den Menschen und den", "tokens": ["Da", "die", "Son\u00b7ne", "lieb\u00b7lich", "schei\u00b7net", ".", "Bey", "den", "Men\u00b7schen", "und", "den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJD", "VVFIN", "$.", "APPR", "ART", "NN", "KON", "ART"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.7": {"text": "Wovon wir, bey letzteren, mehrentheils ", "tokens": ["Wo\u00b7von", "wir", ",", "bey", "letz\u00b7te\u00b7ren", ",", "meh\u00b7ren\u00b7theils"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PWAV", "PPER", "$,", "APPR", "PIS", "$,", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Und, bey den vern\u00fcnftigen, ", "tokens": ["Und", ",", "bey", "den", "ver\u00b7n\u00fcnf\u00b7ti\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "ADJA", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Sind die Aendrungen unz\u00e4hlich: da es dennoch m\u00f6glich w\u00e4r\u2019", "tokens": ["Sind", "die", "A\u00b7en\u00b7drun\u00b7gen", "un\u00b7z\u00e4h\u00b7lich", ":", "da", "es", "den\u00b7noch", "m\u00f6g\u00b7lich", "w\u00e4r'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "ADJD", "$.", "KOUS", "PPER", "ADV", "ADJD", "VAFIN"], "meter": "+-+-+--+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.10": {"text": "Da\u00df gantz andere gesch\u00e4hen. Ich spatziere hin und her", "tokens": ["Da\u00df", "gantz", "an\u00b7de\u00b7re", "ge\u00b7sch\u00e4\u00b7hen", ".", "Ich", "spat\u00b7zie\u00b7re", "hin", "und", "her"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIS", "VVPP", "$.", "PPER", "VVFIN", "PTKVZ", "KON", "ADV"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.11": {"text": "Ob es gleich nicht minder m\u00f6glich, da\u00df ich sitzen, reiten,", "tokens": ["Ob", "es", "gleich", "nicht", "min\u00b7der", "m\u00f6g\u00b7lich", ",", "da\u00df", "ich", "sit\u00b7zen", ",", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "ADV", "ADJD", "$,", "KOUS", "PPER", "VVINF", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.12": {"text": "Fahren, stehn und liegen k\u00f6nnte, oder etwas anders treiben.", "tokens": ["Fah\u00b7ren", ",", "stehn", "und", "lie\u00b7gen", "k\u00f6nn\u00b7te", ",", "o\u00b7der", "et\u00b7was", "an\u00b7ders", "trei\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "KON", "VVINF", "VMFIN", "$,", "KON", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.13": {"text": "Nun entsteht mit Recht die Frage: ob der Sch\u00f6pfer aller", "tokens": ["Nun", "ent\u00b7steht", "mit", "Recht", "die", "Fra\u00b7ge", ":", "ob", "der", "Sch\u00f6p\u00b7fer", "al\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN", "ART", "NN", "$.", "KOUS", "ART", "NN", "PIAT"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.14": {"text": "Keinen Theil an allem nehme? ob ihm alles zu geringe,", "tokens": ["Kei\u00b7nen", "Theil", "an", "al\u00b7lem", "neh\u00b7me", "?", "ob", "ihm", "al\u00b7les", "zu", "ge\u00b7rin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PIS", "VVFIN", "$.", "KOUS", "PPER", "PIS", "PTKZU", "ADJA", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.15": {"text": "Was er je hervorgebracht? ob er, da\u00df die\u00df so gescheh\u2019,", "tokens": ["Was", "er", "je", "her\u00b7vor\u00b7ge\u00b7bracht", "?", "ob", "er", ",", "da\u00df", "die\u00df", "so", "ge\u00b7scheh'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "$.", "KOUS", "PPER", "$,", "KOUS", "PDS", "ADV", "ADJD", "$,"], "meter": "+-+-+-+--++--+", "measure": "trochaic.septa.relaxed"}, "line.16": {"text": "Oder auf ein\u2019 andre Weise, sich gar nicht bek\u00fcmmere?", "tokens": ["O\u00b7der", "auf", "ein'", "and\u00b7re", "Wei\u00b7se", ",", "sich", "gar", "nicht", "be\u00b7k\u00fcm\u00b7me\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,", "PRF", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.11": {"line.1": {"text": "Von Ver\u00e4ndrungen der C\u00f6rper blos allein ist offenbar,", "tokens": ["Von", "Ver\u00b7\u00e4n\u00b7drun\u00b7gen", "der", "C\u00f6r\u00b7per", "blos", "al\u00b7lein", "ist", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ADV", "ADV", "VAFIN", "ADJD", "$,"], "meter": "+-+---+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Da\u00df die G\u00f6ttliche Regirung sich damit gewi\u00df befasse", "tokens": ["Da\u00df", "die", "G\u00f6tt\u00b7li\u00b7che", "Re\u00b7gi\u00b7rung", "sich", "da\u00b7mit", "ge\u00b7wi\u00df", "be\u00b7fas\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PRF", "PAV", "ADV", "VVFIN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Und von ihrer Aenderung, sich durchaus nicht scheiden lasse,", "tokens": ["Und", "von", "ih\u00b7rer", "A\u00b7en\u00b7de\u00b7rung", ",", "sich", "durc\u00b7haus", "nicht", "schei\u00b7den", "las\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$,", "PRF", "ADV", "PTKNEG", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Die\u00df erweiset die\u00df Exempel \u00fcberzeuglich, deutlich, klar:", "tokens": ["Die\u00df", "er\u00b7wei\u00b7set", "die\u00df", "Ex\u00b7em\u00b7pel", "\u00fc\u00b7berz\u00b7eug\u00b7lich", ",", "deut\u00b7lich", ",", "klar", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PDS", "VVFIN", "PDS", "NN", "ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "+-+--+--+-+-+-+", "measure": "trochaic.septa.relaxed"}}, "stanza.12": {"line.1": {"text": "Da\u00df die Sonn\u2019 jetzt lieblich scheint, da es st\u00fcrmen k\u00f6nnt\u2019 und", "tokens": ["Da\u00df", "die", "Sonn'", "jetzt", "lieb\u00b7lich", "scheint", ",", "da", "es", "st\u00fcr\u00b7men", "k\u00f6nnt'", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "ADJD", "VVFIN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "KON"], "meter": "--+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Stammt entweder gantz gewi\u00df von der ersten Ordnung ab,", "tokens": ["Stammt", "ent\u00b7we\u00b7der", "gantz", "ge\u00b7wi\u00df", "von", "der", "ers\u00b7ten", "Ord\u00b7nung", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Da der Sch\u00f6pfer allen C\u00f6rpern eine solche Regel gab,", "tokens": ["Da", "der", "Sch\u00f6p\u00b7fer", "al\u00b7len", "C\u00f6r\u00b7pern", "ei\u00b7ne", "sol\u00b7che", "Re\u00b7gel", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIAT", "NN", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Da\u00df, ", "tokens": ["Da\u00df", ","], "token_info": ["word", "punct"], "pos": ["KOUS", "$,"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Unser Himmel gl\u00e4ntzt und pranget in entw\u00f6lckter Heiterkeit;", "tokens": ["Un\u00b7ser", "Him\u00b7mel", "gl\u00e4ntzt", "und", "pran\u00b7get", "in", "ent\u00b7w\u00f6lck\u00b7ter", "Hei\u00b7ter\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.6": {"text": "Oder dieses sch\u00f6ne Wetter und der heut\u2019ge Sonnen-Schein", "tokens": ["O\u00b7der", "die\u00b7ses", "sch\u00f6\u00b7ne", "Wet\u00b7ter", "und", "der", "heut'\u00b7ge", "Son\u00b7nen\u00b7Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "ADJA", "NN", "KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.7": {"text": "M\u00fcste durch ein Wunder-Werck kommen und entstanden", "tokens": ["M\u00fcs\u00b7te", "durch", "ein", "Wun\u00b7der\u00b7\u00b7Werck", "kom\u00b7men", "und", "ent\u00b7stan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN", "VVINF", "KON", "ADJA"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Beides zeigt des Sch\u00f6pfers Macht, Lieb\u2019 und weise Vorsorg", "tokens": ["Bei\u00b7des", "zeigt", "des", "Sch\u00f6p\u00b7fers", "Macht", ",", "Lieb'", "und", "wei\u00b7se", "Vor\u00b7sorg"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "$,", "NN", "KON", "ADJA", "NN"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "In dem ersten Fall erhellt,", "tokens": ["In", "dem", "ers\u00b7ten", "Fall", "er\u00b7hellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Da\u00df, da sein allwissend Aug\u2019 alles \u00fcbersehen kann,", "tokens": ["Da\u00df", ",", "da", "sein", "all\u00b7wis\u00b7send", "Aug'", "al\u00b7les", "\u00fc\u00b7ber\u00b7se\u00b7hen", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPOSAT", "ADJD", "NN", "PIS", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.11": {"text": "Er, bey der Zusammensetzung und der Anlag\u2019 unsrer Welt,", "tokens": ["Er", ",", "bey", "der", "Zu\u00b7sam\u00b7men\u00b7set\u00b7zung", "und", "der", "An\u00b7lag'", "uns\u00b7rer", "Welt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "APPR", "ART", "NN", "KON", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "Alles, was aus dieser Mischung bis zum heut\u2019gen Tag\u2019 ent-", "tokens": ["Al\u00b7les", ",", "was", "aus", "die\u00b7ser", "Misc\u00b7hung", "bis", "zum", "heut'\u00b7gen", "Tag'", "ent"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "APPR", "PDAT", "NN", "APPR", "APPRART", "ADJA", "NN", "TRUNC"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.13": {"text": "Fliessen und geschehen w\u00fcrde, schon mit einem Blick gesehen;", "tokens": ["Flies\u00b7sen", "und", "ge\u00b7sche\u00b7hen", "w\u00fcr\u00b7de", ",", "schon", "mit", "ei\u00b7nem", "Blick", "ge\u00b7se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVPP", "VAFIN", "$,", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.14": {"text": "Also, da\u00df schon, in der That,", "tokens": ["Al\u00b7so", ",", "da\u00df", "schon", ",", "in", "der", "That", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ADV", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "GoTT, vor so viel tausend Jahren,", "tokens": ["GoTT", ",", "vor", "so", "viel", "tau\u00b7send", "Jah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ADV", "ADV", "CARD", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "Vor die Wittrungen, die wir \u00fcberkommen und erfahren,", "tokens": ["Vor", "die", "Witt\u00b7run\u00b7gen", ",", "die", "wir", "\u00fc\u00b7ber\u00b7kom\u00b7men", "und", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.17": {"text": "In der Ordnung der Natur allbereit gesorget hat.", "tokens": ["In", "der", "Ord\u00b7nung", "der", "Na\u00b7tur", "all\u00b7be\u00b7reit", "ge\u00b7sor\u00b7get", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.18": {"text": "Ist nun, nach dem letzten Fall, dieses Tages Sonnen-Strahl", "tokens": ["Ist", "nun", ",", "nach", "dem", "letz\u00b7ten", "Fall", ",", "die\u00b7ses", "Ta\u00b7ges", "Son\u00b7nen\u00b7Strahl"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "$,", "APPR", "ART", "ADJA", "NN", "$,", "PDAT", "NN", "NN"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Welches GOtt nur zuzuschreiben; so ist gleichfals abermahl", "tokens": ["Wel\u00b7ches", "Gott", "nur", "zu\u00b7zu\u00b7schrei\u00b7ben", ";", "so", "ist", "gleich\u00b7fals", "a\u00b7ber\u00b7mahl"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAT", "NN", "ADV", "VVIZU", "$.", "ADV", "VAFIN", "ADV", "ADV"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.20": {"text": "GoTTES Vorsorg \u00fcberzeuglich, sonder Wiederspruch", "tokens": ["GoT\u00b7TES", "Vor\u00b7sorg", "\u00fc\u00b7berz\u00b7eug\u00b7lich", ",", "son\u00b7der", "Wie\u00b7der\u00b7spruch"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "ADJD", "$,", "KON", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}}, "stanza.13": {"line.1": {"text": "Wenn wir nun noch fernerhin auch die Handlungen", "tokens": ["Wenn", "wir", "nun", "noch", "fer\u00b7ner\u00b7hin", "auch", "die", "Hand\u00b7lun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ADV", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Welche aus dem ", "tokens": ["Wel\u00b7che", "aus", "dem"], "token_info": ["word", "word", "word"], "pos": ["PWAT", "APPR", "ART"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.14": {"line.1": {"text": "Oder aus der ", "tokens": ["O\u00b7der", "aus", "der"], "token_info": ["word", "word", "word"], "pos": ["KON", "APPR", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Da\u00df derselben Grund und Quell in den Creaturen liege;", "tokens": ["Da\u00df", "der\u00b7sel\u00b7ben", "Grund", "und", "Quell", "in", "den", "Crea\u00b7tu\u00b7ren", "lie\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "KON", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.3": {"text": "Aber daraus folget nicht, da\u00df GOtt keinen Antheil nehm\u2019", "tokens": ["A\u00b7ber", "da\u00b7raus", "fol\u00b7get", "nicht", ",", "da\u00df", "Gott", "kei\u00b7nen", "An\u00b7theil", "nehm'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PTKNEG", "$,", "KOUS", "NN", "PIAT", "NN", "VVFIN"], "meter": "+-+-+-++-+-+-+", "measure": "unknown.measure.octa.plus"}, "line.4": {"text": "Und sich mit den Handlungen im geringsten nicht befasse;", "tokens": ["Und", "sich", "mit", "den", "Hand\u00b7lun\u00b7gen", "im", "ge\u00b7rings\u00b7ten", "nicht", "be\u00b7fas\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ART", "NN", "APPRART", "ADJA", "PTKNEG", "VVFIN", "$."], "meter": "--+-++-+-+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Sondern sie in allen Dingen schalten, thun und walten lasse.", "tokens": ["Son\u00b7dern", "sie", "in", "al\u00b7len", "Din\u00b7gen", "schal\u00b7ten", ",", "thun", "und", "wal\u00b7ten", "las\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PIAT", "NN", "VVFIN", "$,", "VVINF", "KON", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.6": {"text": "Zwar ist dieses wahr; hat GOtt Creaturen schaffen wollen,", "tokens": ["Zwar", "ist", "die\u00b7ses", "wahr", ";", "hat", "Gott", "Crea\u00b7tu\u00b7ren", "schaf\u00b7fen", "wol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PDAT", "ADJD", "$.", "VAFIN", "NN", "NN", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.7": {"text": "Welche einen freyen Willen h\u00e4tten; l\u00e4sset sich auch schliessen", "tokens": ["Wel\u00b7che", "ei\u00b7nen", "frey\u00b7en", "Wil\u00b7len", "h\u00e4t\u00b7ten", ";", "l\u00e4s\u00b7set", "sich", "auch", "schlies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "VAFIN", "$.", "VVFIN", "PRF", "ADV", "VVINF"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.8": {"text": "Da\u00df er freye ", "tokens": ["Da\u00df", "er", "frey\u00b7e"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Denn sonst w\u00e4ren sie nicht das, was sie h\u00e4tten werden sollen.", "tokens": ["Denn", "sonst", "w\u00e4\u00b7ren", "sie", "nicht", "das", ",", "was", "sie", "h\u00e4t\u00b7ten", "wer\u00b7den", "sol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PTKNEG", "PDS", "$,", "PRELS", "PPER", "VAFIN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.10": {"text": "Dieser Schlu\u00df ist wahr. Allein,", "tokens": ["Die\u00b7ser", "Schlu\u00df", "ist", "wahr", ".", "Al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "ADJD", "$.", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Es kann doch, bey dieser Freyheit, dennoch nicht gel\u00e4ugnet", "tokens": ["Es", "kann", "doch", ",", "bey", "die\u00b7ser", "Frey\u00b7heit", ",", "den\u00b7noch", "nicht", "ge\u00b7l\u00e4ug\u00b7net"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "$,", "APPR", "PDAT", "NN", "$,", "ADV", "PTKNEG", "VVPP"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Da\u00df die GOttheit alle Wercke, die von ihnen auf der Erden", "tokens": ["Da\u00df", "die", "Got\u00b7theit", "al\u00b7le", "Wer\u00b7cke", ",", "die", "von", "ih\u00b7nen", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PIAT", "NN", "$,", "PRELS", "APPR", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.13": {"text": "W\u00fcrden vorgenommen werden,", "tokens": ["W\u00fcr\u00b7den", "vor\u00b7ge\u00b7nom\u00b7men", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Nicht zuvor gesehen h\u00e4tte; folglich stehet leicht zu fassen,", "tokens": ["Nicht", "zu\u00b7vor", "ge\u00b7se\u00b7hen", "h\u00e4t\u00b7te", ";", "folg\u00b7lich", "ste\u00b7het", "leicht", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVPP", "VAFIN", "$.", "ADV", "VVFIN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.15": {"text": "Da\u00df er auch zugleich beschlossen, was geschicht, geschehn zu", "tokens": ["Da\u00df", "er", "auch", "zu\u00b7gleich", "be\u00b7schlos\u00b7sen", ",", "was", "ge\u00b7schicht", ",", "ge\u00b7schehn", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "$,", "PRELS", "VVPP", "$,", "VVPP", "PTKZU"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.16": {"text": "Da\u00df demnach auch solche Dinge, welche sonsten frey geschehn,", "tokens": ["Da\u00df", "dem\u00b7nach", "auch", "sol\u00b7che", "Din\u00b7ge", ",", "wel\u00b7che", "sons\u00b7ten", "frey", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PAV", "ADV", "PIAT", "NN", "$,", "PRELS", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.17": {"text": "Dennoch unter GOttes Willen, Providentz und Vorsehn", "tokens": ["Den\u00b7noch", "un\u00b7ter", "Got\u00b7tes", "Wil\u00b7len", ",", "Pro\u00b7vi\u00b7dentz", "und", "Vor\u00b7sehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.18": {"text": "Weil der Sch\u00f6pfer sonsten nur,", "tokens": ["Weil", "der", "Sch\u00f6p\u00b7fer", "sons\u00b7ten", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "Wenn er dieses nicht gewollt, eine solche Creatur", "tokens": ["Wenn", "er", "die\u00b7ses", "nicht", "ge\u00b7wollt", ",", "ei\u00b7ne", "sol\u00b7che", "Crea\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "PTKNEG", "VMPP", "$,", "ART", "PIAT", "NN"], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.20": {"text": "Ja nicht d\u00fcrfen werden lassen. Da so denn, unstreitig, nicht", "tokens": ["Ja", "nicht", "d\u00fcr\u00b7fen", "wer\u00b7den", "las\u00b7sen", ".", "Da", "so", "denn", ",", "un\u00b7strei\u00b7tig", ",", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PTKANT", "PTKNEG", "VVINF", "VAFIN", "VVINF", "$.", "ADV", "ADV", "ADV", "$,", "ADJD", "$,", "PTKNEG"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.21": {"text": "Das, was jetzt aus freyen Willen von denselbigen geschicht,", "tokens": ["Das", ",", "was", "jetzt", "aus", "frey\u00b7en", "Wil\u00b7len", "von", "den\u00b7sel\u00b7bi\u00b7gen", "ge\u00b7schicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ADV", "APPR", "ADJA", "NN", "APPR", "PDS", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.22": {"text": "Vorgenommen werden k\u00f6nnte. Da\u00df ich also kl\u00e4rlich sehe,", "tokens": ["Vor\u00b7ge\u00b7nom\u00b7men", "wer\u00b7den", "k\u00f6nn\u00b7te", ".", "Da\u00df", "ich", "al\u00b7so", "kl\u00e4r\u00b7lich", "se\u00b7he", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAINF", "VMFIN", "$.", "KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.23": {"text": "Wie von allen Handlungen, nichts von ungef\u00e4hr geschehe,", "tokens": ["Wie", "von", "al\u00b7len", "Hand\u00b7lun\u00b7gen", ",", "nichts", "von", "un\u00b7ge\u00b7f\u00e4hr", "ge\u00b7sche\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PIAT", "NN", "$,", "PIS", "APPR", "ADJD", "VVFIN", "$,"], "meter": "+-+-++-+-+-+-+-", "measure": "unknown.measure.octa.plus"}, "line.24": {"text": "Sondern alles unter einer G\u00f6ttlichen Regirung stehe.", "tokens": ["Son\u00b7dern", "al\u00b7les", "un\u00b7ter", "ei\u00b7ner", "G\u00f6tt\u00b7li\u00b7chen", "Re\u00b7gi\u00b7rung", "ste\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+--+--+-", "measure": "trochaic.septa.relaxed"}}, "stanza.15": {"line.1": {"text": "La\u00dft uns aber nunmehr auch von des Sch\u00f6pfers aller", "tokens": ["La\u00dft", "uns", "a\u00b7ber", "nun\u00b7mehr", "auch", "von", "des", "Sch\u00f6p\u00b7fers", "al\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "ADV", "APPR", "ART", "NN", "PIAT"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Unl\u00e4ugbarer Providentz w\u00fcrdige Begriff\u2019 uns machen!", "tokens": ["Un\u00b7l\u00e4ug\u00b7ba\u00b7rer", "Pro\u00b7vi\u00b7dentz", "w\u00fcr\u00b7di\u00b7ge", "Be\u00b7griff'", "uns", "ma\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.16": {"line.1": {"text": "Nemlich, da\u00df dieselbe nicht eine ", "tokens": ["Nem\u00b7lich", ",", "da\u00df", "die\u00b7sel\u00b7be", "nicht", "ei\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PDAT", "PTKNEG", "ART"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Sondern, da\u00df in ihr zugleich immer, mit vereinter Kraft,", "tokens": ["Son\u00b7dern", ",", "da\u00df", "in", "ihr", "zu\u00b7gleich", "im\u00b7mer", ",", "mit", "ver\u00b7ein\u00b7ter", "Kraft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "APPR", "PPER", "ADV", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-+-+", "measure": "iambic.septa.invert"}, "line.3": {"text": "Von der GOttheit wahrem Wesen eine jede Eigenschaft,", "tokens": ["Von", "der", "Got\u00b7theit", "wah\u00b7rem", "We\u00b7sen", "ei\u00b7ne", "je\u00b7de", "Ei\u00b7gen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "ART", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Nemlich ", "tokens": ["Nem\u00b7lich"], "token_info": ["word"], "pos": ["ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Wunderbar zusammen fliesset.", "tokens": ["Wun\u00b7der\u00b7bar", "zu\u00b7sam\u00b7men", "flies\u00b7set", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Seine ", "tokens": ["Sei\u00b7ne"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Nebst dem ", "tokens": ["Nebst", "dem"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "In dem allerhellsten Lichte, in der gr\u00f6sten Deutlichkeit.", "tokens": ["In", "dem", "al\u00b7ler\u00b7hells\u00b7ten", "Lich\u00b7te", ",", "in", "der", "gr\u00f6s\u00b7ten", "Deut\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Er erkennt, was die Verbindung aller ", "tokens": ["Er", "er\u00b7kennt", ",", "was", "die", "Ver\u00b7bin\u00b7dung", "al\u00b7ler"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ART", "NN", "PIAT"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Er begreift die Wirckungen, die dadurch, zu aller Zeit,", "tokens": ["Er", "be\u00b7greift", "die", "Wir\u00b7ckun\u00b7gen", ",", "die", "da\u00b7durch", ",", "zu", "al\u00b7ler", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PAV", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Aller Orten, so im grossen, als im kleinen, kommen werden;", "tokens": ["Al\u00b7ler", "Or\u00b7ten", ",", "so", "im", "gros\u00b7sen", ",", "als", "im", "klei\u00b7nen", ",", "kom\u00b7men", "wer\u00b7den", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADV", "APPRART", "ADJA", "$,", "KOUS", "APPRART", "ADJA", "$,", "VVFIN", "VAINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.7": {"text": "Er ergr\u00fcndet, was der Thiere Willk\u00fchr wirckt und nach sich", "tokens": ["Er", "er\u00b7gr\u00fcn\u00b7det", ",", "was", "der", "Thie\u00b7re", "Will\u00b7k\u00fchr", "wirckt", "und", "nach", "sich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ART", "NN", "NN", "VVFIN", "KON", "APPR", "PRF"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.8": {"text": "Er erforscht, was die Gesch\u00f6pfe, denen er ein frey Gem\u00fcht", "tokens": ["Er", "er\u00b7forscht", ",", "was", "die", "Ge\u00b7sch\u00f6p\u00b7fe", ",", "de\u00b7nen", "er", "ein", "frey", "Ge\u00b7m\u00fcht"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ART", "NN", "$,", "PRELS", "PPER", "ART", "ADJD", "NN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.9": {"text": "Und, in ihren Handlungen, einen ungezwungnen Willen", "tokens": ["Und", ",", "in", "ih\u00b7ren", "Hand\u00b7lun\u00b7gen", ",", "ei\u00b7nen", "un\u00b7ge\u00b7zwung\u00b7nen", "Wil\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "APPR", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.10": {"text": "Eingesencket, reden, handeln, thun, beginnen und erf\u00fcllen,", "tokens": ["Ein\u00b7ge\u00b7sen\u00b7cket", ",", "re\u00b7den", ",", "han\u00b7deln", ",", "thun", ",", "be\u00b7gin\u00b7nen", "und", "er\u00b7f\u00fcl\u00b7len", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVINF", "$,", "VVINF", "$,", "VVINF", "$,", "VVINF", "KON", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.11": {"text": "Wircken und begehren werden, was gerahten, nicht gerahten", "tokens": ["Wir\u00b7cken", "und", "be\u00b7geh\u00b7ren", "wer\u00b7den", ",", "was", "ge\u00b7rah\u00b7ten", ",", "nicht", "ge\u00b7rah\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "KON", "VVINF", "VAFIN", "$,", "PRELS", "VVPP", "$,", "PTKNEG", "VVPP"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.12": {"text": "Und was unterbleiben werde, auch was aus derselben Thaten", "tokens": ["Und", "was", "un\u00b7ter\u00b7blei\u00b7ben", "wer\u00b7de", ",", "auch", "was", "aus", "der\u00b7sel\u00b7ben", "Tha\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VVINF", "VAFIN", "$,", "ADV", "PRELS", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.13": {"text": "In der k\u00fcnftgen Zeit erfolgt. Ja nicht nur das, was geschicht", "tokens": ["In", "der", "k\u00fcnft\u00b7gen", "Zeit", "er\u00b7folgt", ".", "Ja", "nicht", "nur", "das", ",", "was", "ge\u00b7schicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$.", "PTKANT", "PTKNEG", "ADV", "PDS", "$,", "PRELS", "VVPP"], "meter": "--+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Und geschehen wird, weis er; sondern auch, wenn was", "tokens": ["Und", "ge\u00b7sche\u00b7hen", "wird", ",", "weis", "er", ";", "son\u00b7dern", "auch", ",", "wenn", "was"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVPP", "VAFIN", "$,", "KOUS", "PPER", "$.", "KON", "ADV", "$,", "KOUS", "PIS"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.15": {"text": "Was daraus entstehen w\u00fcrde, ist ihm ja so wol bekannt,", "tokens": ["Was", "da\u00b7raus", "ent\u00b7ste\u00b7hen", "w\u00fcr\u00b7de", ",", "ist", "ihm", "ja", "so", "wol", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PAV", "VVINF", "VAFIN", "$,", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "+---+-+-+-+-+-+", "measure": "dactylic.init"}, "line.16": {"text": "Als wenn ich, was gegenw\u00e4rtig mir vor Augen lieget, sehe.", "tokens": ["Als", "wenn", "ich", ",", "was", "ge\u00b7gen\u00b7w\u00e4r\u00b7tig", "mir", "vor", "Au\u00b7gen", "lie\u00b7get", ",", "se\u00b7he", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "$,", "PRELS", "ADJD", "PPER", "APPR", "NN", "VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.17": {"text": "Dieser Weisheit helle Sonne und sein G\u00f6ttlicher Verstand", "tokens": ["Die\u00b7ser", "Weis\u00b7heit", "hel\u00b7le", "Son\u00b7ne", "und", "sein", "G\u00f6tt\u00b7li\u00b7cher", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "ADJA", "NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.18": {"text": "Strahlt aus allen Creaturen recht, als wie ein helles Licht.", "tokens": ["Strahlt", "aus", "al\u00b7len", "Crea\u00b7tu\u00b7ren", "recht", ",", "als", "wie", "ein", "hel\u00b7les", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "ADJD", "$,", "KOUS", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.19": {"text": "Wie ist alles durch einander wunderw\u00fcrdig eingericht,", "tokens": ["Wie", "ist", "al\u00b7les", "durch", "ein\u00b7an\u00b7der", "wun\u00b7der\u00b7w\u00fcr\u00b7dig", "ein\u00b7ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PIS", "APPR", "PRF", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.20": {"text": "Und bewunderns-wehrt verkn\u00fcpffet! Man sieht \u00fcberall die", "tokens": ["Und", "be\u00b7wun\u00b7derns\u00b7wehrt", "ver\u00b7kn\u00fcpf\u00b7fet", "!", "Man", "sieht", "\u00fc\u00b7be\u00b7rall", "die"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "$.", "PIS", "VVFIN", "ADV", "ART"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.21": {"text": "Wie von allen Creaturen, in dem Reiche der Natur,", "tokens": ["Wie", "von", "al\u00b7len", "Crea\u00b7tu\u00b7ren", ",", "in", "dem", "Rei\u00b7che", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PIAT", "NN", "$,", "APPR", "ART", "NE", "ART", "NN", "$,"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.22": {"text": "Eines stets am andern hanget;", "tokens": ["Ei\u00b7nes", "stets", "am", "an\u00b7dern", "han\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "APPRART", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Jegliches hat seinen Zweck und es wird der Zweck aufs neu", "tokens": ["Jeg\u00b7li\u00b7ches", "hat", "sei\u00b7nen", "Zweck", "und", "es", "wird", "der", "Zweck", "aufs", "neu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPOSAT", "NN", "KON", "PPER", "VAFIN", "ART", "NN", "APPRART", "ADJD"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.24": {"text": "Wiederum ein Mittel, wodurch es zum neuen Zweck\u2019 ge-", "tokens": ["Wie\u00b7de\u00b7rum", "ein", "Mit\u00b7tel", ",", "wo\u00b7durch", "es", "zum", "neu\u00b7en", "Zweck'", "ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "$,", "PWAV", "PPER", "APPRART", "ADJA", "NN", "TRUNC"], "meter": "--+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.18": {"line.1": {"text": "GoTTES Liebe, seiner G\u00fcte, seiner Gnaden\nWunder-Schein", "tokens": ["GoT\u00b7TES", "Lie\u00b7be", ",", "sei\u00b7ner", "G\u00fc\u00b7te", ",", "sei\u00b7ner", "Gna\u00b7den", "Wun\u00b7der\u00b7Schein"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Fl\u00f6\u00dft sich ferner, nebst der ", "tokens": ["Fl\u00f6\u00dft", "sich", "fer\u00b7ner", ",", "nebst", "der"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "$,", "APPR", "ART"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Jhm, dem allerh\u00f6chsten Gut, wallt im G\u00f6ttlichen Gem\u00fchte", "tokens": ["Jhm", ",", "dem", "al\u00b7ler\u00b7h\u00f6chs\u00b7ten", "Gut", ",", "wallt", "im", "G\u00f6tt\u00b7li\u00b7chen", "Ge\u00b7m\u00fch\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "ART", "ADJA", "NN", "$,", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "+-+-+-++-+-+-+-", "measure": "unknown.measure.octa.plus"}, "line.4": {"text": "Eine seelige Geneigtheit, Gnad\u2019, Erbarmung, Huld und", "tokens": ["Ei\u00b7ne", "see\u00b7li\u00b7ge", "Ge\u00b7neig\u00b7theit", ",", "Gnad'", ",", "Er\u00b7bar\u00b7mung", ",", "Huld", "und"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.5": {"text": "Den Gesch\u00f6pfen mitzutheilen, stets ihr Gutes zu vergr\u00f6ssern,", "tokens": ["Den", "Ge\u00b7sch\u00f6p\u00b7fen", "mit\u00b7zu\u00b7thei\u00b7len", ",", "stets", "ihr", "Gu\u00b7tes", "zu", "ver\u00b7gr\u00f6s\u00b7sern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,", "ADV", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.6": {"text": "Und, nach seiner weisen Ordnung, ihren Zustand zu verbessern.", "tokens": ["Und", ",", "nach", "sei\u00b7ner", "wei\u00b7sen", "Ord\u00b7nung", ",", "ih\u00b7ren", "Zu\u00b7stand", "zu", "ver\u00b7bes\u00b7sern", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.19": {"line.1": {"text": "Gleichfals wirckt der GOttheit ", "tokens": ["Gleich\u00b7fals", "wirckt", "der", "Got\u00b7theit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "In der Providentz, vereint. Nimmt man diese nun zu-", "tokens": ["In", "der", "Pro\u00b7vi\u00b7dentz", ",", "ver\u00b7eint", ".", "Nimmt", "man", "die\u00b7se", "nun", "zu"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "VVPP", "$.", "VVFIN", "PIS", "PDAT", "ADV", "TRUNC"], "meter": "-+--+-++-+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und man leitet aus denselben G\u00f6ttliche Vorsehung her;", "tokens": ["Und", "man", "lei\u00b7tet", "aus", "den\u00b7sel\u00b7ben", "G\u00f6tt\u00b7li\u00b7che", "Vor\u00b7se\u00b7hung", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PDAT", "NN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+--+---", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Wird von solcher Providentz nicht allein ein richtiger,", "tokens": ["Wird", "von", "sol\u00b7cher", "Pro\u00b7vi\u00b7dentz", "nicht", "al\u00b7lein", "ein", "rich\u00b7ti\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "PTKNEG", "ADV", "ART", "ADJA", "$,"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Auch ein tr\u00f6stlicher, Begriff, sonder allen Zweifel, stammen.", "tokens": ["Auch", "ein", "tr\u00f6st\u00b7li\u00b7cher", ",", "Be\u00b7griff", ",", "son\u00b7der", "al\u00b7len", "Zwei\u00b7fel", ",", "stam\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "NN", "$,", "KON", "PIAT", "NN", "$,", "VVFIN", "$."], "meter": "+-+--+-+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Wird ein sterblicher Monarch und ein irdischer Regent,", "tokens": ["Wird", "ein", "sterb\u00b7li\u00b7cher", "Mon\u00b7arch", "und", "ein", "ir\u00b7di\u00b7scher", "Re\u00b7gent", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "--+--+---+--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Welcher seiner Unterthanen Nutz und Bestes sucht und kennt,", "tokens": ["Wel\u00b7cher", "sei\u00b7ner", "Un\u00b7ter\u00b7tha\u00b7nen", "Nutz", "und", "Bes\u00b7tes", "sucht", "und", "kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "PPOSAT", "NN", "NN", "KON", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.8": {"text": "Dem es an Gewalt nicht fehlet und der sie als Kinder liebt,", "tokens": ["Dem", "es", "an", "Ge\u00b7walt", "nicht", "feh\u00b7let", "und", "der", "sie", "als", "Kin\u00b7der", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "PTKNEG", "VVFIN", "KON", "PRELS", "PPER", "KOUS", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.9": {"text": "Selbige nicht gl\u00fccklich machen? wird desselben Regiment", "tokens": ["Sel\u00b7bi\u00b7ge", "nicht", "gl\u00fcck\u00b7lich", "ma\u00b7chen", "?", "wird", "des\u00b7sel\u00b7ben", "Re\u00b7gi\u00b7ment"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKNEG", "ADJD", "VVINF", "$.", "VAFIN", "PDAT", "NN"], "meter": "+---+-+-+-+-+-+", "measure": "dactylic.init"}, "line.10": {"text": "Nicht gedeylich f\u00fcr sie seyn? da nun GOtt, im h\u00f6chsten Grad,", "tokens": ["Nicht", "ge\u00b7dey\u00b7lich", "f\u00fcr", "sie", "seyn", "?", "da", "nun", "Gott", ",", "im", "h\u00f6chs\u00b7ten", "Grad", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "APPR", "PPER", "VAINF", "$.", "ADV", "ADV", "NN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "--+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Alle die Vollkommenheiten Macht und Eigenschaften hat;", "tokens": ["Al\u00b7le", "die", "Voll\u00b7kom\u00b7men\u00b7hei\u00b7ten", "Macht", "und", "Ei\u00b7gen\u00b7schaf\u00b7ten", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "ADJA", "NN", "KON", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.12": {"text": "K\u00f6nnen wir unm\u00f6glich anders von desselben F\u00fchrung", "tokens": ["K\u00f6n\u00b7nen", "wir", "un\u00b7m\u00f6g\u00b7lich", "an\u00b7ders", "von", "des\u00b7sel\u00b7ben", "F\u00fch\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADJD", "ADV", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.13": {"text": "Als; es werde nichts, als gutes aus derselben uns entspriessen.", "tokens": ["Als", ";", "es", "wer\u00b7de", "nichts", ",", "als", "gu\u00b7tes", "aus", "der\u00b7sel\u00b7ben", "uns", "ent\u00b7spries\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$.", "PPER", "VAFIN", "PIS", "$,", "KOUS", "ADJA", "APPR", "PDAT", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.14": {"text": "Aber la\u00dft uns diese Wahrheit deutlicher noch zu verstehn", "tokens": ["A\u00b7ber", "la\u00dft", "uns", "die\u00b7se", "Wahr\u00b7heit", "deut\u00b7li\u00b7cher", "noch", "zu", "ver\u00b7stehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "PDAT", "NN", "ADJD", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.15": {"text": "Das, wor\u00fcber die Versehung sich erstrecket, \u00fcbersehn.", "tokens": ["Das", ",", "wo\u00b7r\u00fc\u00b7ber", "die", "Ver\u00b7se\u00b7hung", "sich", "er\u00b7stre\u00b7cket", ",", "\u00fc\u00b7ber\u00b7sehn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "$,", "PWAV", "ART", "NN", "PRF", "VVFIN", "$,", "VVINF", "$."], "meter": "----+-+-+-+-+-+", "measure": "unknown.measure.hexa"}}, "stanza.20": {"line.1": {"text": "Erstlich kommen Dinge vor, welche g\u00e4ntzlich ", "tokens": ["Erst\u00b7lich", "kom\u00b7men", "Din\u00b7ge", "vor", ",", "wel\u00b7che", "g\u00e4ntz\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVFIN", "NN", "PTKVZ", "$,", "PRELS", "ADJD"], "meter": "+-+-+----+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Deren sind nun ", "tokens": ["De\u00b7ren", "sind", "nun"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Willk\u00fchr oder freyer Wille etwas \u00e4ndern, etwas geben,", "tokens": ["Will\u00b7k\u00fchr", "o\u00b7der", "frey\u00b7er", "Wil\u00b7le", "et\u00b7was", "\u00e4n\u00b7dern", ",", "et\u00b7was", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "ADV", "VVINF", "$,", "ADV", "VVINF", "$,"], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Etwas nehmen, mindern, mehren, bessern und verschlimmern", "tokens": ["Et\u00b7was", "neh\u00b7men", ",", "min\u00b7dern", ",", "meh\u00b7ren", ",", "bes\u00b7sern", "und", "ver\u00b7schlim\u00b7mern"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVINF", "$,", "ADJA", "$,", "VVFIN", "$,", "ADJA", "KON", "VVINF"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}}}}