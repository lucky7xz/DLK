{"textgrid.poem.25476": {"metadata": {"author": {"name": "Goeckingk, Leopold Friedrich G\u00fcnther von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Elephant ist gl\u00fccklich angekommen.", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Elephant ist gl\u00fccklich angekommen.", "tokens": ["Der", "E\u00b7le\u00b7phant", "ist", "gl\u00fcck\u00b7lich", "an\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich dank' Euch zwar daf\u00fcr, doch in der That!", "tokens": ["Ich", "dank'", "Euch", "zwar", "da\u00b7f\u00fcr", ",", "doch", "in", "der", "That", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PAV", "$,", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich war ein Thor, da\u00df ich um einen bat,", "tokens": ["Ich", "war", "ein", "Thor", ",", "da\u00df", "ich", "um", "ei\u00b7nen", "bat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "KOUS", "PPER", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn wozu soll der Knochenberg mir frommen?", "tokens": ["Denn", "wo\u00b7zu", "soll", "der", "Kno\u00b7chen\u00b7berg", "mir", "from\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "ART", "NN", "PPER", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Mir fra\u00df ein Reitpferd schon zu viel,", "tokens": ["Mir", "fra\u00df", "ein", "Reit\u00b7pferd", "schon", "zu", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKA", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und ich sollt' itzt der Sch\u00f6pfung Riesen f\u00fcttern?", "tokens": ["Und", "ich", "sollt'", "itzt", "der", "Sch\u00f6p\u00b7fung", "Rie\u00b7sen", "f\u00fct\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ihm w\u00e4re \u2013 was ich ohne Zittern", "tokens": ["Ihm", "w\u00e4\u00b7re", "\u2013", "was", "ich", "oh\u00b7ne", "Zit\u00b7tern"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$(", "PWS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Kaum denken kann \u2013 mein Hab' und Gut ein Spiel!", "tokens": ["Kaum", "den\u00b7ken", "kann", "\u2013", "mein", "Hab'", "und", "Gut", "ein", "Spiel", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "$(", "PPOSAT", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Allein er war nun einmal da,", "tokens": ["Al\u00b7lein", "er", "war", "nun", "ein\u00b7mal", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und stand vor meiner Th\u00fcr', und sah", "tokens": ["Und", "stand", "vor", "mei\u00b7ner", "Th\u00fcr'", ",", "und", "sah"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Das Haus ver\u00e4chtlich an, als wollt' er fragen:", "tokens": ["Das", "Haus", "ver\u00b7\u00e4cht\u00b7lich", "an", ",", "als", "wollt'", "er", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$,", "KOUS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Nun! ist denn hier kein Thor f\u00fcr mich?", "tokens": ["Nun", "!", "ist", "denn", "hier", "kein", "Thor", "f\u00fcr", "mich", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VAFIN", "ADV", "ADV", "PIAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Und machte Mien' als wollt' er sich", "tokens": ["Und", "mach\u00b7te", "Mien'", "als", "wollt'", "er", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NN", "KOUS", "VMFIN", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Mit seinen Z\u00e4hnen Eins durch W\u00e4nd' und S\u00e4ulen schlagen.", "tokens": ["Mit", "sei\u00b7nen", "Z\u00e4h\u00b7nen", "Eins", "durch", "W\u00e4nd'", "und", "S\u00e4u\u00b7len", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ganz ", "tokens": ["Ganz"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.16": {"text": "Hob vor Erstaunen bis zur Stirne", "tokens": ["Hob", "vor", "Er\u00b7stau\u00b7nen", "bis", "zur", "Stir\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "NN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Die Augenwimper auf, ja selbst der Mund der Dirne,", "tokens": ["Die", "Au\u00b7gen\u00b7wim\u00b7per", "auf", ",", "ja", "selbst", "der", "Mund", "der", "Dir\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADV", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Die von dem Markte kam, ward stumm.", "tokens": ["Die", "von", "dem", "Mark\u00b7te", "kam", ",", "ward", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Sein F\u00fchrer, der den Geist der Stadt nicht kannte,", "tokens": ["Sein", "F\u00fch\u00b7rer", ",", "der", "den", "Geist", "der", "Stadt", "nicht", "kann\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ART", "NN", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Hatt' \u00fcberall beim Einzug' gleich", "tokens": ["Hatt'", "\u00fc\u00b7be\u00b7rall", "beim", "Ein\u00b7zug'", "gleich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Es ausposaunt: der Elephante", "tokens": ["Es", "aus\u00b7po\u00b7saunt", ":", "der", "E\u00b7le\u00b7phan\u00b7te"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Sey ein Geschenk von Euch.", "tokens": ["Sey", "ein", "Ge\u00b7schenk", "von", "Euch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "Ihr glaubt nicht, ", "tokens": ["Ihr", "glaubt", "nicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.24": {"text": "F\u00fcr Eindruck machte. Jede M\u00fctze,", "tokens": ["F\u00fcr", "Ein\u00b7druck", "mach\u00b7te", ".", "Je\u00b7de", "M\u00fct\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$.", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Die sonst vor mir wohl fest gesessen hat,", "tokens": ["Die", "sonst", "vor", "mir", "wohl", "fest", "ge\u00b7ses\u00b7sen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPER", "ADV", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Fuhr, als ich kam, schnell, wie vom Blitze", "tokens": ["Fuhr", ",", "als", "ich", "kam", ",", "schnell", ",", "wie", "vom", "Blit\u00b7ze"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADJD", "$,", "PWAV", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Getroffen, bis zur Erd' herab.", "tokens": ["Ge\u00b7trof\u00b7fen", ",", "bis", "zur", "Erd'", "her\u00b7ab", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "F\u00fcr Verse \u2013 diese Lumpereien! \u2013", "tokens": ["F\u00fcr", "Ver\u00b7se", "\u2013", "die\u00b7se", "Lum\u00b7pe\u00b7rei\u00b7en", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$(", "PDAT", "NN", "$.", "$("], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.29": {"text": "Ein solch Geschenk! das schien nun jedem zwar", "tokens": ["Ein", "solch", "Ge\u00b7schenk", "!", "das", "schien", "nun", "je\u00b7dem", "zwar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "$.", "PDS", "VVFIN", "ADV", "PIS", "ADV"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.30": {"text": "Unglaublich, oder sonderbar;", "tokens": ["Un\u00b7glaub\u00b7lich", ",", "o\u00b7der", "son\u00b7der\u00b7bar", ";"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Ja, Eure Hoheit wird verzeihen!", "tokens": ["Ja", ",", "Eu\u00b7re", "Ho\u00b7heit", "wird", "ver\u00b7zei\u00b7hen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Man h\u00e4tt' Euch, traun! den Augenblick,", "tokens": ["Man", "h\u00e4tt'", "Euch", ",", "traun", "!", "den", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "$,", "VVINF", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Wer wei\u00df, wof\u00fcr? gehalten, wenn zum Gl\u00fcck'", "tokens": ["Wer", "wei\u00df", ",", "wo\u00b7f\u00fcr", "?", "ge\u00b7hal\u00b7ten", ",", "wenn", "zum", "Gl\u00fcck"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$,", "PWAV", "$.", "VVPP", "$,", "KOUS", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "F\u00fcr mich, Ihr nicht ein K\u00f6nig w\u00e4ret.", "tokens": ["F\u00fcr", "mich", ",", "Ihr", "nicht", "ein", "K\u00f6\u00b7nig", "w\u00e4\u00b7ret", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PPER", "PTKNEG", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Allein das blo\u00dfe Wort gleicht einem Zauberst\u00fcck'", "tokens": ["Al\u00b7lein", "das", "blo\u00b7\u00dfe", "Wort", "gleicht", "ei\u00b7nem", "Zau\u00b7ber\u00b7st\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Auf Herrn Amphions Leyer; wer es h\u00f6ret,", "tokens": ["Auf", "Herrn", "Am\u00b7phi\u00b7ons", "Le\u00b7yer", ";", "wer", "es", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "NE", "$.", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.37": {"text": "Dem schwinden Sinnen und Verstand,", "tokens": ["Dem", "schwin\u00b7den", "Sin\u00b7nen", "und", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Als h\u00e4tt' ihn s\u00fc\u00dfer Wein beth\u00f6ret,", "tokens": ["Als", "h\u00e4tt'", "ihn", "s\u00fc\u00b7\u00dfer", "Wein", "be\u00b7th\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Und wer itzt wie ein Stein da stand,", "tokens": ["Und", "wer", "itzt", "wie", "ein", "Stein", "da", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "KOKOM", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Der tanzt, als h\u00e4tt' es ihn ", "tokens": ["Der", "tanzt", ",", "als", "h\u00e4tt'", "es", "ihn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "KOKOM", "VAFIN", "PPER", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.41": {"text": "So war auch ich im Auge aller Leute", "tokens": ["So", "war", "auch", "ich", "im", "Au\u00b7ge", "al\u00b7ler", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PPER", "APPRART", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.42": {"text": "Von Stund an gleich ein andrer Mann;", "tokens": ["Von", "Stund", "an", "gleich", "ein", "an\u00b7drer", "Mann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "Denn ob ich, trotz dem Elephanten! heute", "tokens": ["Denn", "ob", "ich", ",", "trotz", "dem", "E\u00b7le\u00b7phan\u00b7ten", "!", "heu\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "KOUS", "PPER", "$,", "APPR", "ART", "NN", "$.", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.44": {"text": "Gleich keinem Bettler, mehr als gestern, helfen kann,", "tokens": ["Gleich", "kei\u00b7nem", "Bett\u00b7ler", ",", "mehr", "als", "ge\u00b7stern", ",", "hel\u00b7fen", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "PIAT", "KOKOM", "ADV", "$,", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "So ist es doch genug, da\u00df ich nur an", "tokens": ["So", "ist", "es", "doch", "ge\u00b7nug", ",", "da\u00df", "ich", "nur", "an"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$,", "KOUS", "PPER", "ADV", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "Dem Hof' von ", "tokens": ["Dem", "Hof'", "von"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.47": {"text": "Vielleicht ging' ich den Weg durchs Leben bis ans Grab,", "tokens": ["Viel\u00b7leicht", "ging'", "ich", "den", "Weg", "durchs", "Le\u00b7ben", "bis", "ans", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Und wenn ich auch ein zweiter ", "tokens": ["Und", "wenn", "ich", "auch", "ein", "zwei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.49": {"text": "Ganz unbemerkt mit ", "tokens": ["Ganz", "un\u00b7be\u00b7merkt", "mit"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJD", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.50": {"text": "Allein ein Elephant von einem K\u00f6nig'! \u2013 Ehre", "tokens": ["Al\u00b7lein", "ein", "E\u00b7le\u00b7phant", "von", "ei\u00b7nem", "K\u00f6\u00b7nig'", "!", "\u2013", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "NN", "$.", "$(", "NN"], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.51": {"text": "Die Menge regnet's gleich herab!", "tokens": ["Die", "Men\u00b7ge", "reg\u00b7net's", "gleich", "her\u00b7ab", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "Nun glauben zwar vielleicht die Leute,", "tokens": ["Nun", "glau\u00b7ben", "zwar", "viel\u00b7leicht", "die", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.53": {"text": "Da\u00df ich des Elephanten mich", "tokens": ["Da\u00df", "ich", "des", "E\u00b7le\u00b7phan\u00b7ten", "mich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.54": {"text": "In seiner Scheune inniglich,", "tokens": ["In", "sei\u00b7ner", "Scheu\u00b7ne", "in\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.55": {"text": "Und ihrer Kompliment' auf meinem Sopha freute;", "tokens": ["Und", "ih\u00b7rer", "Kom\u00b7pli\u00b7ment'", "auf", "mei\u00b7nem", "So\u00b7pha", "freu\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Doch, ", "tokens": ["Doch", ","], "token_info": ["word", "punct"], "pos": ["KON", "$,"], "meter": "+", "measure": "single.up"}, "line.57": {"text": "Denn der ist nicht den kleinsten Zahn", "tokens": ["Denn", "der", "ist", "nicht", "den", "kleins\u00b7ten", "Zahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "VAFIN", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Von einem Elephanten werth,", "tokens": ["Von", "ei\u00b7nem", "E\u00b7le\u00b7phan\u00b7ten", "werth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.59": {"text": "Wer keinen edlern Stolz in seinem Herzen n\u00e4hrt.", "tokens": ["Wer", "kei\u00b7nen", "ed\u00b7lern", "Stolz", "in", "sei\u00b7nem", "Her\u00b7zen", "n\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Belohntet ", "tokens": ["Be\u00b7lohn\u00b7tet"], "token_info": ["word"], "pos": ["VVPP"], "meter": "-+-", "measure": "amphibrach.single"}, "line.61": {"text": "So wi\u00dft: der Elephant gibt, Ehre nicht, nur Neid,", "tokens": ["So", "wi\u00dft", ":", "der", "E\u00b7le\u00b7phant", "gibt", ",", "Eh\u00b7re", "nicht", ",", "nur", "Neid", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "ART", "NN", "VVFIN", "$,", "NN", "PTKNEG", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.63": {"text": "Von Geist und Witz und Sprache seyd.", "tokens": ["Von", "Geist", "und", "Witz", "und", "Spra\u00b7che", "seyd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "Und seyd ", "tokens": ["Und", "seyd"], "token_info": ["word", "word"], "pos": ["KON", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.65": {"text": "Der Mann geehrt, \u2013 denn besser ist doch besser! \u2013", "tokens": ["Der", "Mann", "ge\u00b7ehrt", ",", "\u2013", "denn", "bes\u00b7ser", "ist", "doch", "bes\u00b7ser", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "$(", "KON", "ADJD", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.66": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.67": {"text": "Wird er dadurch in meinen Augen gr\u00f6\u00dfer,", "tokens": ["Wird", "er", "da\u00b7durch", "in", "mei\u00b7nen", "Au\u00b7gen", "gr\u00f6\u00b7\u00dfer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.68": {"text": "Als er den Tag vorher schon war.", "tokens": ["Als", "er", "den", "Tag", "vor\u00b7her", "schon", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "So dank' auch ich f\u00fcr ", "tokens": ["So", "dank'", "auch", "ich", "f\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PPER", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.70": {"text": "Im Fall' ", "tokens": ["Im", "Fall'"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.71": {"text": "In meiner Denkungsart gefiel,", "tokens": ["In", "mei\u00b7ner", "Den\u00b7kungs\u00b7art", "ge\u00b7fiel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.72": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.73": {"text": "Zu unterhalten, war wahrhaftig nicht mein Ziel.", "tokens": ["Zu", "un\u00b7ter\u00b7hal\u00b7ten", ",", "war", "wahr\u00b7haf\u00b7tig", "nicht", "mein", "Ziel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "VAFIN", "ADJD", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Wenn aber das Geschenk, \u2013 es sieht", "tokens": ["Wenn", "a\u00b7ber", "das", "Ge\u00b7schenk", ",", "\u2013", "es", "sieht"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "$,", "$(", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "Beinah so aus! \u2013 blo\u00dff\u00fcr die Ehre", "tokens": ["Bei\u00b7nah", "so", "aus", "!", "\u2013", "blo\u00df\u00b7f\u00fcr", "die", "Eh\u00b7re"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKVZ", "$.", "$(", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.76": {"text": "Der Dedikation, ein Trankgeld w\u00e4re:", "tokens": ["Der", "De\u00b7di\u00b7ka\u00b7ti\u00b7on", ",", "ein", "Trank\u00b7geld", "w\u00e4\u00b7re", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.77": {"text": "Nun, gn\u00e4dger Herr, so sind wir quitt!", "tokens": ["Nun", ",", "gn\u00e4d\u00b7ger", "Herr", ",", "so", "sind", "wir", "quitt", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "ADV", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "Allein auch dann bin ich ", "tokens": ["Al\u00b7lein", "auch", "dann", "bin", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "VAFIN", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.79": {"text": "Denn, ist gleich mir der Elephant nichts n\u00fctz,", "tokens": ["Denn", ",", "ist", "gleich", "mir", "der", "E\u00b7le\u00b7phant", "nichts", "n\u00fctz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "ADV", "PPER", "ART", "NN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.80": {"text": "So hab' ich doch f\u00fcr ihn den rechten Mann gefunden,", "tokens": ["So", "hab'", "ich", "doch", "f\u00fcr", "ihn", "den", "rech\u00b7ten", "Mann", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Der nun auf einmal reich durch den Besitz", "tokens": ["Der", "nun", "auf", "ein\u00b7mal", "reich", "durch", "den", "Be\u00b7sitz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ADV", "ADJD", "APPR", "ART", "NN"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.82": {"text": "Des Thieres ist. Ein alter J\u00e4ger, ", "tokens": ["Des", "Thie\u00b7res", "ist", ".", "Ein", "al\u00b7ter", "J\u00e4\u00b7ger", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.83": {"text": "Der meinem Vater treu bis an sein Ende war,", "tokens": ["Der", "mei\u00b7nem", "Va\u00b7ter", "treu", "bis", "an", "sein", "En\u00b7de", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "APPR", "APPR", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "In dem ich, wenn er stirbt, (was freilich sonderbar", "tokens": ["In", "dem", "ich", ",", "wenn", "er", "stirbt", ",", "(", "was", "frei\u00b7lich", "son\u00b7der\u00b7bar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,", "$(", "PWS", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Am Hofe klingen mag,) den ersten Freund verliere;", "tokens": ["Am", "Ho\u00b7fe", "klin\u00b7gen", "mag", ",", ")", "den", "ers\u00b7ten", "Freund", "ver\u00b7lie\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "VMFIN", "$,", "$(", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Denn ach! er macht' in meiner Kindheit mir", "tokens": ["Denn", "ach", "!", "er", "macht'", "in", "mei\u00b7ner", "Kind\u00b7heit", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "XY", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.87": {"text": "Gewi\u00df noch zehnmal gr\u00f6\u00dfre Freuden,", "tokens": ["Ge\u00b7wi\u00df", "noch", "zehn\u00b7mal", "gr\u00f6\u00df\u00b7re", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.88": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.89": {"text": "Um das mich Stadt und Land beneiden!", "tokens": ["Um", "das", "mich", "Stadt", "und", "Land", "be\u00b7nei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PPER", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.90": {"text": "Ihm war es Kleinigkeit, stockstill auf starren Zeh'n,", "tokens": ["Ihm", "war", "es", "Klei\u00b7nig\u00b7keit", ",", "stock\u00b7still", "auf", "star\u00b7ren", "Zeh'n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NN", "$,", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Wenn gleich von Eis ihm Bart und Locken klangen,", "tokens": ["Wenn", "gleich", "von", "Eis", "ihm", "Bart", "und", "Lo\u00b7cken", "klan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "NN", "PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.92": {"text": "Beim Grunzen wilder S\u00e4u'n, beim Zischen gro\u00dfer Schlangen,", "tokens": ["Beim", "Grun\u00b7zen", "wil\u00b7der", "S\u00e4u'n", ",", "beim", "Zi\u00b7schen", "gro\u00b7\u00dfer", "Schlan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$,", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Drei N\u00e4chte lang im Forst' zu stehn,", "tokens": ["Drei", "N\u00e4ch\u00b7te", "lang", "im", "For\u00b7st'", "zu", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.94": {"text": "Um mir ein kleines Reh zu fangen!", "tokens": ["Um", "mir", "ein", "klei\u00b7nes", "Reh", "zu", "fan\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.95": {"text": "Und dieser alte J\u00e4ger, itzt", "tokens": ["Und", "die\u00b7ser", "al\u00b7te", "J\u00e4\u00b7ger", ",", "itzt"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PDAT", "ADJA", "NN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.96": {"text": "Zu steif, um auf die Jagd zu gehen,", "tokens": ["Zu", "steif", ",", "um", "auf", "die", "Jagd", "zu", "ge\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$,", "KOUI", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.97": {"text": "(was anders mag er schwerlich wohl verstehen)", "tokens": ["(", "was", "an\u00b7ders", "mag", "er", "schwer\u00b7lich", "wohl", "ver\u00b7ste\u00b7hen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "VMFIN", "PPER", "ADJD", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.98": {"text": "Ist's, der den Elephanten nun besitzt.", "tokens": ["Ist's", ",", "der", "den", "E\u00b7le\u00b7phan\u00b7ten", "nun", "be\u00b7sitzt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.99": {"text": "Verzeiht der guten Absicht, ", "tokens": ["Ver\u00b7zeiht", "der", "gu\u00b7ten", "Ab\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.100": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.101": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.102": {"text": "Die Kreuz und Quer durchzieht.", "tokens": ["Die", "Kreuz", "und", "Quer", "durch\u00b7zieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.103": {"text": "Wird er auf seinem Zuge reich,", "tokens": ["Wird", "er", "auf", "sei\u00b7nem", "Zu\u00b7ge", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.104": {"text": "(er wird's gewi\u00df, wenn sonst nicht Mann und Thier erkranken,)", "tokens": ["(", "er", "wird's", "ge\u00b7wi\u00df", ",", "wenn", "sonst", "nicht", "Mann", "und", "Thier", "er\u00b7kran\u00b7ken", ",", ")"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "$,", "KOUS", "ADV", "PTKNEG", "NN", "KON", "NN", "VVINF", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "So will er hin nach ", "tokens": ["So", "will", "er", "hin", "nach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.106": {"text": "Sich selbst pers\u00f6nlich zu bedanken.", "tokens": ["Sich", "selbst", "per\u00b7s\u00f6n\u00b7lich", "zu", "be\u00b7dan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Elephant ist gl\u00fccklich angekommen.", "tokens": ["Der", "E\u00b7le\u00b7phant", "ist", "gl\u00fcck\u00b7lich", "an\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich dank' Euch zwar daf\u00fcr, doch in der That!", "tokens": ["Ich", "dank'", "Euch", "zwar", "da\u00b7f\u00fcr", ",", "doch", "in", "der", "That", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PAV", "$,", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich war ein Thor, da\u00df ich um einen bat,", "tokens": ["Ich", "war", "ein", "Thor", ",", "da\u00df", "ich", "um", "ei\u00b7nen", "bat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "KOUS", "PPER", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn wozu soll der Knochenberg mir frommen?", "tokens": ["Denn", "wo\u00b7zu", "soll", "der", "Kno\u00b7chen\u00b7berg", "mir", "from\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "ART", "NN", "PPER", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Mir fra\u00df ein Reitpferd schon zu viel,", "tokens": ["Mir", "fra\u00df", "ein", "Reit\u00b7pferd", "schon", "zu", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKA", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und ich sollt' itzt der Sch\u00f6pfung Riesen f\u00fcttern?", "tokens": ["Und", "ich", "sollt'", "itzt", "der", "Sch\u00f6p\u00b7fung", "Rie\u00b7sen", "f\u00fct\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ihm w\u00e4re \u2013 was ich ohne Zittern", "tokens": ["Ihm", "w\u00e4\u00b7re", "\u2013", "was", "ich", "oh\u00b7ne", "Zit\u00b7tern"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$(", "PWS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Kaum denken kann \u2013 mein Hab' und Gut ein Spiel!", "tokens": ["Kaum", "den\u00b7ken", "kann", "\u2013", "mein", "Hab'", "und", "Gut", "ein", "Spiel", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "$(", "PPOSAT", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Allein er war nun einmal da,", "tokens": ["Al\u00b7lein", "er", "war", "nun", "ein\u00b7mal", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und stand vor meiner Th\u00fcr', und sah", "tokens": ["Und", "stand", "vor", "mei\u00b7ner", "Th\u00fcr'", ",", "und", "sah"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Das Haus ver\u00e4chtlich an, als wollt' er fragen:", "tokens": ["Das", "Haus", "ver\u00b7\u00e4cht\u00b7lich", "an", ",", "als", "wollt'", "er", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$,", "KOUS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Nun! ist denn hier kein Thor f\u00fcr mich?", "tokens": ["Nun", "!", "ist", "denn", "hier", "kein", "Thor", "f\u00fcr", "mich", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VAFIN", "ADV", "ADV", "PIAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Und machte Mien' als wollt' er sich", "tokens": ["Und", "mach\u00b7te", "Mien'", "als", "wollt'", "er", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NN", "KOUS", "VMFIN", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Mit seinen Z\u00e4hnen Eins durch W\u00e4nd' und S\u00e4ulen schlagen.", "tokens": ["Mit", "sei\u00b7nen", "Z\u00e4h\u00b7nen", "Eins", "durch", "W\u00e4nd'", "und", "S\u00e4u\u00b7len", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ganz ", "tokens": ["Ganz"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.16": {"text": "Hob vor Erstaunen bis zur Stirne", "tokens": ["Hob", "vor", "Er\u00b7stau\u00b7nen", "bis", "zur", "Stir\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "NN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Die Augenwimper auf, ja selbst der Mund der Dirne,", "tokens": ["Die", "Au\u00b7gen\u00b7wim\u00b7per", "auf", ",", "ja", "selbst", "der", "Mund", "der", "Dir\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADV", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Die von dem Markte kam, ward stumm.", "tokens": ["Die", "von", "dem", "Mark\u00b7te", "kam", ",", "ward", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Sein F\u00fchrer, der den Geist der Stadt nicht kannte,", "tokens": ["Sein", "F\u00fch\u00b7rer", ",", "der", "den", "Geist", "der", "Stadt", "nicht", "kann\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ART", "NN", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Hatt' \u00fcberall beim Einzug' gleich", "tokens": ["Hatt'", "\u00fc\u00b7be\u00b7rall", "beim", "Ein\u00b7zug'", "gleich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Es ausposaunt: der Elephante", "tokens": ["Es", "aus\u00b7po\u00b7saunt", ":", "der", "E\u00b7le\u00b7phan\u00b7te"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Sey ein Geschenk von Euch.", "tokens": ["Sey", "ein", "Ge\u00b7schenk", "von", "Euch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "Ihr glaubt nicht, ", "tokens": ["Ihr", "glaubt", "nicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.24": {"text": "F\u00fcr Eindruck machte. Jede M\u00fctze,", "tokens": ["F\u00fcr", "Ein\u00b7druck", "mach\u00b7te", ".", "Je\u00b7de", "M\u00fct\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$.", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Die sonst vor mir wohl fest gesessen hat,", "tokens": ["Die", "sonst", "vor", "mir", "wohl", "fest", "ge\u00b7ses\u00b7sen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPER", "ADV", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Fuhr, als ich kam, schnell, wie vom Blitze", "tokens": ["Fuhr", ",", "als", "ich", "kam", ",", "schnell", ",", "wie", "vom", "Blit\u00b7ze"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADJD", "$,", "PWAV", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Getroffen, bis zur Erd' herab.", "tokens": ["Ge\u00b7trof\u00b7fen", ",", "bis", "zur", "Erd'", "her\u00b7ab", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "F\u00fcr Verse \u2013 diese Lumpereien! \u2013", "tokens": ["F\u00fcr", "Ver\u00b7se", "\u2013", "die\u00b7se", "Lum\u00b7pe\u00b7rei\u00b7en", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$(", "PDAT", "NN", "$.", "$("], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.29": {"text": "Ein solch Geschenk! das schien nun jedem zwar", "tokens": ["Ein", "solch", "Ge\u00b7schenk", "!", "das", "schien", "nun", "je\u00b7dem", "zwar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "$.", "PDS", "VVFIN", "ADV", "PIS", "ADV"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.30": {"text": "Unglaublich, oder sonderbar;", "tokens": ["Un\u00b7glaub\u00b7lich", ",", "o\u00b7der", "son\u00b7der\u00b7bar", ";"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Ja, Eure Hoheit wird verzeihen!", "tokens": ["Ja", ",", "Eu\u00b7re", "Ho\u00b7heit", "wird", "ver\u00b7zei\u00b7hen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Man h\u00e4tt' Euch, traun! den Augenblick,", "tokens": ["Man", "h\u00e4tt'", "Euch", ",", "traun", "!", "den", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "$,", "VVINF", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Wer wei\u00df, wof\u00fcr? gehalten, wenn zum Gl\u00fcck'", "tokens": ["Wer", "wei\u00df", ",", "wo\u00b7f\u00fcr", "?", "ge\u00b7hal\u00b7ten", ",", "wenn", "zum", "Gl\u00fcck"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$,", "PWAV", "$.", "VVPP", "$,", "KOUS", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "F\u00fcr mich, Ihr nicht ein K\u00f6nig w\u00e4ret.", "tokens": ["F\u00fcr", "mich", ",", "Ihr", "nicht", "ein", "K\u00f6\u00b7nig", "w\u00e4\u00b7ret", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PPER", "PTKNEG", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Allein das blo\u00dfe Wort gleicht einem Zauberst\u00fcck'", "tokens": ["Al\u00b7lein", "das", "blo\u00b7\u00dfe", "Wort", "gleicht", "ei\u00b7nem", "Zau\u00b7ber\u00b7st\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Auf Herrn Amphions Leyer; wer es h\u00f6ret,", "tokens": ["Auf", "Herrn", "Am\u00b7phi\u00b7ons", "Le\u00b7yer", ";", "wer", "es", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "NE", "$.", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.37": {"text": "Dem schwinden Sinnen und Verstand,", "tokens": ["Dem", "schwin\u00b7den", "Sin\u00b7nen", "und", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Als h\u00e4tt' ihn s\u00fc\u00dfer Wein beth\u00f6ret,", "tokens": ["Als", "h\u00e4tt'", "ihn", "s\u00fc\u00b7\u00dfer", "Wein", "be\u00b7th\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Und wer itzt wie ein Stein da stand,", "tokens": ["Und", "wer", "itzt", "wie", "ein", "Stein", "da", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "KOKOM", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Der tanzt, als h\u00e4tt' es ihn ", "tokens": ["Der", "tanzt", ",", "als", "h\u00e4tt'", "es", "ihn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "KOKOM", "VAFIN", "PPER", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.41": {"text": "So war auch ich im Auge aller Leute", "tokens": ["So", "war", "auch", "ich", "im", "Au\u00b7ge", "al\u00b7ler", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PPER", "APPRART", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.42": {"text": "Von Stund an gleich ein andrer Mann;", "tokens": ["Von", "Stund", "an", "gleich", "ein", "an\u00b7drer", "Mann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "Denn ob ich, trotz dem Elephanten! heute", "tokens": ["Denn", "ob", "ich", ",", "trotz", "dem", "E\u00b7le\u00b7phan\u00b7ten", "!", "heu\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "KOUS", "PPER", "$,", "APPR", "ART", "NN", "$.", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.44": {"text": "Gleich keinem Bettler, mehr als gestern, helfen kann,", "tokens": ["Gleich", "kei\u00b7nem", "Bett\u00b7ler", ",", "mehr", "als", "ge\u00b7stern", ",", "hel\u00b7fen", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "PIAT", "KOKOM", "ADV", "$,", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "So ist es doch genug, da\u00df ich nur an", "tokens": ["So", "ist", "es", "doch", "ge\u00b7nug", ",", "da\u00df", "ich", "nur", "an"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$,", "KOUS", "PPER", "ADV", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "Dem Hof' von ", "tokens": ["Dem", "Hof'", "von"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.47": {"text": "Vielleicht ging' ich den Weg durchs Leben bis ans Grab,", "tokens": ["Viel\u00b7leicht", "ging'", "ich", "den", "Weg", "durchs", "Le\u00b7ben", "bis", "ans", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Und wenn ich auch ein zweiter ", "tokens": ["Und", "wenn", "ich", "auch", "ein", "zwei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.49": {"text": "Ganz unbemerkt mit ", "tokens": ["Ganz", "un\u00b7be\u00b7merkt", "mit"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJD", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.50": {"text": "Allein ein Elephant von einem K\u00f6nig'! \u2013 Ehre", "tokens": ["Al\u00b7lein", "ein", "E\u00b7le\u00b7phant", "von", "ei\u00b7nem", "K\u00f6\u00b7nig'", "!", "\u2013", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "NN", "$.", "$(", "NN"], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.51": {"text": "Die Menge regnet's gleich herab!", "tokens": ["Die", "Men\u00b7ge", "reg\u00b7net's", "gleich", "her\u00b7ab", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "Nun glauben zwar vielleicht die Leute,", "tokens": ["Nun", "glau\u00b7ben", "zwar", "viel\u00b7leicht", "die", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.53": {"text": "Da\u00df ich des Elephanten mich", "tokens": ["Da\u00df", "ich", "des", "E\u00b7le\u00b7phan\u00b7ten", "mich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.54": {"text": "In seiner Scheune inniglich,", "tokens": ["In", "sei\u00b7ner", "Scheu\u00b7ne", "in\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.55": {"text": "Und ihrer Kompliment' auf meinem Sopha freute;", "tokens": ["Und", "ih\u00b7rer", "Kom\u00b7pli\u00b7ment'", "auf", "mei\u00b7nem", "So\u00b7pha", "freu\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Doch, ", "tokens": ["Doch", ","], "token_info": ["word", "punct"], "pos": ["KON", "$,"], "meter": "+", "measure": "single.up"}, "line.57": {"text": "Denn der ist nicht den kleinsten Zahn", "tokens": ["Denn", "der", "ist", "nicht", "den", "kleins\u00b7ten", "Zahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "VAFIN", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Von einem Elephanten werth,", "tokens": ["Von", "ei\u00b7nem", "E\u00b7le\u00b7phan\u00b7ten", "werth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.59": {"text": "Wer keinen edlern Stolz in seinem Herzen n\u00e4hrt.", "tokens": ["Wer", "kei\u00b7nen", "ed\u00b7lern", "Stolz", "in", "sei\u00b7nem", "Her\u00b7zen", "n\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Belohntet ", "tokens": ["Be\u00b7lohn\u00b7tet"], "token_info": ["word"], "pos": ["VVPP"], "meter": "-+-", "measure": "amphibrach.single"}, "line.61": {"text": "So wi\u00dft: der Elephant gibt, Ehre nicht, nur Neid,", "tokens": ["So", "wi\u00dft", ":", "der", "E\u00b7le\u00b7phant", "gibt", ",", "Eh\u00b7re", "nicht", ",", "nur", "Neid", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "ART", "NN", "VVFIN", "$,", "NN", "PTKNEG", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.63": {"text": "Von Geist und Witz und Sprache seyd.", "tokens": ["Von", "Geist", "und", "Witz", "und", "Spra\u00b7che", "seyd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "Und seyd ", "tokens": ["Und", "seyd"], "token_info": ["word", "word"], "pos": ["KON", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.65": {"text": "Der Mann geehrt, \u2013 denn besser ist doch besser! \u2013", "tokens": ["Der", "Mann", "ge\u00b7ehrt", ",", "\u2013", "denn", "bes\u00b7ser", "ist", "doch", "bes\u00b7ser", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "$(", "KON", "ADJD", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.66": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.67": {"text": "Wird er dadurch in meinen Augen gr\u00f6\u00dfer,", "tokens": ["Wird", "er", "da\u00b7durch", "in", "mei\u00b7nen", "Au\u00b7gen", "gr\u00f6\u00b7\u00dfer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.68": {"text": "Als er den Tag vorher schon war.", "tokens": ["Als", "er", "den", "Tag", "vor\u00b7her", "schon", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "So dank' auch ich f\u00fcr ", "tokens": ["So", "dank'", "auch", "ich", "f\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PPER", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.70": {"text": "Im Fall' ", "tokens": ["Im", "Fall'"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.71": {"text": "In meiner Denkungsart gefiel,", "tokens": ["In", "mei\u00b7ner", "Den\u00b7kungs\u00b7art", "ge\u00b7fiel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.72": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.73": {"text": "Zu unterhalten, war wahrhaftig nicht mein Ziel.", "tokens": ["Zu", "un\u00b7ter\u00b7hal\u00b7ten", ",", "war", "wahr\u00b7haf\u00b7tig", "nicht", "mein", "Ziel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "VAFIN", "ADJD", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Wenn aber das Geschenk, \u2013 es sieht", "tokens": ["Wenn", "a\u00b7ber", "das", "Ge\u00b7schenk", ",", "\u2013", "es", "sieht"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "$,", "$(", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "Beinah so aus! \u2013 blo\u00dff\u00fcr die Ehre", "tokens": ["Bei\u00b7nah", "so", "aus", "!", "\u2013", "blo\u00df\u00b7f\u00fcr", "die", "Eh\u00b7re"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKVZ", "$.", "$(", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.76": {"text": "Der Dedikation, ein Trankgeld w\u00e4re:", "tokens": ["Der", "De\u00b7di\u00b7ka\u00b7ti\u00b7on", ",", "ein", "Trank\u00b7geld", "w\u00e4\u00b7re", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.77": {"text": "Nun, gn\u00e4dger Herr, so sind wir quitt!", "tokens": ["Nun", ",", "gn\u00e4d\u00b7ger", "Herr", ",", "so", "sind", "wir", "quitt", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "ADV", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "Allein auch dann bin ich ", "tokens": ["Al\u00b7lein", "auch", "dann", "bin", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "VAFIN", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.79": {"text": "Denn, ist gleich mir der Elephant nichts n\u00fctz,", "tokens": ["Denn", ",", "ist", "gleich", "mir", "der", "E\u00b7le\u00b7phant", "nichts", "n\u00fctz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "ADV", "PPER", "ART", "NN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.80": {"text": "So hab' ich doch f\u00fcr ihn den rechten Mann gefunden,", "tokens": ["So", "hab'", "ich", "doch", "f\u00fcr", "ihn", "den", "rech\u00b7ten", "Mann", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Der nun auf einmal reich durch den Besitz", "tokens": ["Der", "nun", "auf", "ein\u00b7mal", "reich", "durch", "den", "Be\u00b7sitz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ADV", "ADJD", "APPR", "ART", "NN"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.82": {"text": "Des Thieres ist. Ein alter J\u00e4ger, ", "tokens": ["Des", "Thie\u00b7res", "ist", ".", "Ein", "al\u00b7ter", "J\u00e4\u00b7ger", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.83": {"text": "Der meinem Vater treu bis an sein Ende war,", "tokens": ["Der", "mei\u00b7nem", "Va\u00b7ter", "treu", "bis", "an", "sein", "En\u00b7de", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "APPR", "APPR", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "In dem ich, wenn er stirbt, (was freilich sonderbar", "tokens": ["In", "dem", "ich", ",", "wenn", "er", "stirbt", ",", "(", "was", "frei\u00b7lich", "son\u00b7der\u00b7bar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,", "$(", "PWS", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Am Hofe klingen mag,) den ersten Freund verliere;", "tokens": ["Am", "Ho\u00b7fe", "klin\u00b7gen", "mag", ",", ")", "den", "ers\u00b7ten", "Freund", "ver\u00b7lie\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "VMFIN", "$,", "$(", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Denn ach! er macht' in meiner Kindheit mir", "tokens": ["Denn", "ach", "!", "er", "macht'", "in", "mei\u00b7ner", "Kind\u00b7heit", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "XY", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.87": {"text": "Gewi\u00df noch zehnmal gr\u00f6\u00dfre Freuden,", "tokens": ["Ge\u00b7wi\u00df", "noch", "zehn\u00b7mal", "gr\u00f6\u00df\u00b7re", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.88": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.89": {"text": "Um das mich Stadt und Land beneiden!", "tokens": ["Um", "das", "mich", "Stadt", "und", "Land", "be\u00b7nei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PPER", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.90": {"text": "Ihm war es Kleinigkeit, stockstill auf starren Zeh'n,", "tokens": ["Ihm", "war", "es", "Klei\u00b7nig\u00b7keit", ",", "stock\u00b7still", "auf", "star\u00b7ren", "Zeh'n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NN", "$,", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Wenn gleich von Eis ihm Bart und Locken klangen,", "tokens": ["Wenn", "gleich", "von", "Eis", "ihm", "Bart", "und", "Lo\u00b7cken", "klan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "NN", "PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.92": {"text": "Beim Grunzen wilder S\u00e4u'n, beim Zischen gro\u00dfer Schlangen,", "tokens": ["Beim", "Grun\u00b7zen", "wil\u00b7der", "S\u00e4u'n", ",", "beim", "Zi\u00b7schen", "gro\u00b7\u00dfer", "Schlan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$,", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Drei N\u00e4chte lang im Forst' zu stehn,", "tokens": ["Drei", "N\u00e4ch\u00b7te", "lang", "im", "For\u00b7st'", "zu", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.94": {"text": "Um mir ein kleines Reh zu fangen!", "tokens": ["Um", "mir", "ein", "klei\u00b7nes", "Reh", "zu", "fan\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.95": {"text": "Und dieser alte J\u00e4ger, itzt", "tokens": ["Und", "die\u00b7ser", "al\u00b7te", "J\u00e4\u00b7ger", ",", "itzt"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PDAT", "ADJA", "NN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.96": {"text": "Zu steif, um auf die Jagd zu gehen,", "tokens": ["Zu", "steif", ",", "um", "auf", "die", "Jagd", "zu", "ge\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$,", "KOUI", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.97": {"text": "(was anders mag er schwerlich wohl verstehen)", "tokens": ["(", "was", "an\u00b7ders", "mag", "er", "schwer\u00b7lich", "wohl", "ver\u00b7ste\u00b7hen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "VMFIN", "PPER", "ADJD", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.98": {"text": "Ist's, der den Elephanten nun besitzt.", "tokens": ["Ist's", ",", "der", "den", "E\u00b7le\u00b7phan\u00b7ten", "nun", "be\u00b7sitzt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.99": {"text": "Verzeiht der guten Absicht, ", "tokens": ["Ver\u00b7zeiht", "der", "gu\u00b7ten", "Ab\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.100": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.101": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.102": {"text": "Die Kreuz und Quer durchzieht.", "tokens": ["Die", "Kreuz", "und", "Quer", "durch\u00b7zieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.103": {"text": "Wird er auf seinem Zuge reich,", "tokens": ["Wird", "er", "auf", "sei\u00b7nem", "Zu\u00b7ge", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.104": {"text": "(er wird's gewi\u00df, wenn sonst nicht Mann und Thier erkranken,)", "tokens": ["(", "er", "wird's", "ge\u00b7wi\u00df", ",", "wenn", "sonst", "nicht", "Mann", "und", "Thier", "er\u00b7kran\u00b7ken", ",", ")"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "$,", "KOUS", "ADV", "PTKNEG", "NN", "KON", "NN", "VVINF", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "So will er hin nach ", "tokens": ["So", "will", "er", "hin", "nach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.106": {"text": "Sich selbst pers\u00f6nlich zu bedanken.", "tokens": ["Sich", "selbst", "per\u00b7s\u00f6n\u00b7lich", "zu", "be\u00b7dan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}