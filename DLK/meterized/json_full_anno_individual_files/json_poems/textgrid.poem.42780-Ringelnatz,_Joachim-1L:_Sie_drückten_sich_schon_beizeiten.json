{"textgrid.poem.42780": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sie dr\u00fcckten sich schon beizeiten", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sie dr\u00fcckten sich schon beizeiten", "tokens": ["Sie", "dr\u00fcck\u00b7ten", "sich", "schon", "bei\u00b7zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Fort aus dem Tanzlokal", "tokens": ["Fort", "aus", "dem", "Tanz\u00b7lo\u00b7kal"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und suchten zu beiden Seiten", "tokens": ["Und", "such\u00b7ten", "zu", "bei\u00b7den", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der Stra\u00dfe das Gast- und Logierhaus Continental.", "tokens": ["Der", "Stra\u00b7\u00dfe", "das", "Gast", "und", "Lo\u00b7gier\u00b7haus", "Con\u00b7ti\u00b7nen\u00b7tal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "TRUNC", "KON", "NN", "NE", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "So dringlich: Man h\u00e4tte k\u00f6nnen glauben,", "tokens": ["So", "dring\u00b7lich", ":", "Man", "h\u00e4t\u00b7te", "k\u00f6n\u00b7nen", "glau\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PIS", "VAFIN", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er triebe sie vorw\u00e4rts wie ein Rind.", "tokens": ["Er", "trie\u00b7be", "sie", "vor\u00b7w\u00e4rts", "wie", "ein", "Rind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und doch handelten beide im besten Glauben.", "tokens": ["Und", "doch", "han\u00b7del\u00b7ten", "bei\u00b7de", "im", "bes\u00b7ten", "Glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "APPRART", "ADJA", "NN", "$."], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Er wollte ihr nur die Unschuld rauben.", "tokens": ["Er", "woll\u00b7te", "ihr", "nur", "die", "Un\u00b7schuld", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sie wollte partout von ihm ein Kind.", "tokens": ["Sie", "woll\u00b7te", "par\u00b7tout", "von", "ihm", "ein", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Da geschah es, etwa am Halleschen Tor,", "tokens": ["Da", "ge\u00b7schah", "es", ",", "et\u00b7wa", "am", "Hal\u00b7le\u00b7schen", "Tor", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da\u00df Frieda \u00fcber dem Knutschen und Schmusen", "tokens": ["Da\u00df", "Frie\u00b7da", "\u00fc\u00b7ber", "dem", "Knut\u00b7schen", "und", "Schmu\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "APPR", "ART", "NN", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Aus ihrem hitzig gekitzelten Busen", "tokens": ["Aus", "ih\u00b7rem", "hit\u00b7zig", "ge\u00b7kit\u00b7zel\u00b7ten", "Bu\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJD", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Eine zertanzte, verdr\u00fcckte Rose verlor.", "tokens": ["Ei\u00b7ne", "zer\u00b7tanz\u00b7te", ",", "ver\u00b7dr\u00fcck\u00b7te", "Ro\u00b7se", "ver\u00b7lor", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "NE", "VVFIN", "$."], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}}, "stanza.4": {"line.1": {"text": "Und ein sehr feiner Herr, dessen Eleganz", "tokens": ["Und", "ein", "sehr", "fei\u00b7ner", "Herr", ",", "des\u00b7sen", "E\u00b7le\u00b7ganz"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "ADV", "ADJA", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Nicht so rumtoben tut, folgte den beiden.", "tokens": ["Nicht", "so", "rum\u00b7to\u00b7ben", "tut", ",", "folg\u00b7te", "den", "bei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVINF", "VVFIN", "$,", "VVFIN", "ART", "PIAT", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Jedoch hielt er sich vornehm bescheiden", "tokens": ["Je\u00b7doch", "hielt", "er", "sich", "vor\u00b7nehm", "be\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Immer in einer gewissen Distanz.", "tokens": ["Im\u00b7mer", "in", "ei\u00b7ner", "ge\u00b7wis\u00b7sen", "Dis\u00b7tanz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Er wollte urspr\u00fcnglich zum Bierhaus Siechen.", "tokens": ["Er", "woll\u00b7te", "ur\u00b7spr\u00fcng\u00b7lich", "zum", "Bier\u00b7haus", "Sie\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Aber nun hemmte er seinen Lauf,", "tokens": ["A\u00b7ber", "nun", "hemm\u00b7te", "er", "sei\u00b7nen", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Zog die Handschuh aus, hob die Rose auf", "tokens": ["Zog", "die", "Hand\u00b7schuh", "aus", ",", "hob", "die", "Ro\u00b7se", "auf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,", "VVFIN", "ART", "NN", "APPR"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und begann langsam daran zu riechen.", "tokens": ["Und", "be\u00b7gann", "lang\u00b7sam", "da\u00b7ran", "zu", "rie\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PAV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Er w\u00fcnschte aber keinen Augenblicksgenu\u00df;", "tokens": ["Er", "w\u00fcnschte", "a\u00b7ber", "kei\u00b7nen", "Au\u00b7gen\u00b7blicks\u00b7ge\u00b7nu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Deshalb stieg er mit der Rose in den Omnibus.", "tokens": ["Des\u00b7halb", "stieg", "er", "mit", "der", "Ro\u00b7se", "in", "den", "Om\u00b7ni\u00b7bus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Derweilen war Frieda mit ihrem Soldaten", "tokens": ["Der\u00b7wei\u00b7len", "war", "Frie\u00b7da", "mit", "ih\u00b7rem", "Sol\u00b7da\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "NE", "APPR", "PPOSAT", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Auf einen Kinderspielplatz geraten.", "tokens": ["Auf", "ei\u00b7nen", "Kin\u00b7der\u00b7spiel\u00b7platz", "ge\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Dort merkten sie nicht, wie die Nacht verstrich", "tokens": ["Dort", "merk\u00b7ten", "sie", "nicht", ",", "wie", "die", "Nacht", "ver\u00b7strich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$,", "PWAV", "ART", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und da\u00df ein unruhiger Mann mit einem Spaten", "tokens": ["Und", "da\u00df", "ein", "un\u00b7ru\u00b7hi\u00b7ger", "Mann", "mit", "ei\u00b7nem", "Spa\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie dauernd beschlich.", "tokens": ["Sie", "dau\u00b7ernd", "be\u00b7schlich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.7": {"line.1": {"text": "Als sich nach l\u00e4ngerem Aufenthalt", "tokens": ["Als", "sich", "nach", "l\u00e4n\u00b7ge\u00b7rem", "Auf\u00b7ent\u00b7halt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "APPR", "ADJA", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Das Paar in der Richtung zur Gasanstalt", "tokens": ["Das", "Paar", "in", "der", "Rich\u00b7tung", "zur", "Ga\u00b7san\u00b7stalt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPRART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Mit kurzen, trippelnden Schritten verlor,", "tokens": ["Mit", "kur\u00b7zen", ",", "trip\u00b7peln\u00b7den", "Schrit\u00b7ten", "ver\u00b7lor", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sprang der unruhige Mann pl\u00f6tzlich hervor.", "tokens": ["Sprang", "der", "un\u00b7ru\u00b7hi\u00b7ge", "Mann", "pl\u00f6tz\u00b7lich", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Und fing an, eine Stelle, wo er im Sand", "tokens": ["Und", "fing", "an", ",", "ei\u00b7ne", "Stel\u00b7le", ",", "wo", "er", "im", "Sand"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "ART", "NN", "$,", "PWAV", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Die Spur von Friedas Stiefelchen fand,", "tokens": ["Die", "Spur", "von", "Frie\u00b7das", "Stie\u00b7fel\u00b7chen", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Mit seinem Spaten herauszuheben.", "tokens": ["Mit", "sei\u00b7nem", "Spa\u00b7ten", "her\u00b7aus\u00b7zu\u00b7he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Worauf er behutsam mit zitternder Hand", "tokens": ["Wo\u00b7rauf", "er", "be\u00b7hut\u00b7sam", "mit", "zit\u00b7tern\u00b7der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PPER", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.9": {"text": "Die feuchte Form in ein Sacktuch band,", "tokens": ["Die", "feuch\u00b7te", "Form", "in", "ein", "Sack\u00b7tuch", "band", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Um sich dann leichenbla\u00df heimzubegeben.", "tokens": ["Um", "sich", "dann", "lei\u00b7chen\u00b7bla\u00df", "heim\u00b7zu\u00b7be\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Wie um das d\u00fcmmste M\u00e4dchen", "tokens": ["Wie", "um", "das", "d\u00fcmms\u00b7te", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sich sonderbare F\u00e4dchen", "tokens": ["Sich", "son\u00b7der\u00b7ba\u00b7re", "F\u00e4d\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["PRF", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nachts durch die Stra\u00dfen ziehn \u2013", "tokens": ["Nachts", "durch", "die", "Stra\u00b7\u00dfen", "ziehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Die Dichter und die Maler", "tokens": ["Die", "Dich\u00b7ter", "und", "die", "Ma\u00b7ler"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und auch die Kriminaler,", "tokens": ["Und", "auch", "die", "Kri\u00b7mi\u00b7na\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Die kennen ihr Berlin.", "tokens": ["Die", "ken\u00b7nen", "ihr", "Ber\u00b7lin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Sie dr\u00fcckten sich schon beizeiten", "tokens": ["Sie", "dr\u00fcck\u00b7ten", "sich", "schon", "bei\u00b7zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Fort aus dem Tanzlokal", "tokens": ["Fort", "aus", "dem", "Tanz\u00b7lo\u00b7kal"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und suchten zu beiden Seiten", "tokens": ["Und", "such\u00b7ten", "zu", "bei\u00b7den", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der Stra\u00dfe das Gast- und Logierhaus Continental.", "tokens": ["Der", "Stra\u00b7\u00dfe", "das", "Gast", "und", "Lo\u00b7gier\u00b7haus", "Con\u00b7ti\u00b7nen\u00b7tal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "TRUNC", "KON", "NN", "NE", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "So dringlich: Man h\u00e4tte k\u00f6nnen glauben,", "tokens": ["So", "dring\u00b7lich", ":", "Man", "h\u00e4t\u00b7te", "k\u00f6n\u00b7nen", "glau\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PIS", "VAFIN", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er triebe sie vorw\u00e4rts wie ein Rind.", "tokens": ["Er", "trie\u00b7be", "sie", "vor\u00b7w\u00e4rts", "wie", "ein", "Rind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und doch handelten beide im besten Glauben.", "tokens": ["Und", "doch", "han\u00b7del\u00b7ten", "bei\u00b7de", "im", "bes\u00b7ten", "Glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "APPRART", "ADJA", "NN", "$."], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Er wollte ihr nur die Unschuld rauben.", "tokens": ["Er", "woll\u00b7te", "ihr", "nur", "die", "Un\u00b7schuld", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sie wollte partout von ihm ein Kind.", "tokens": ["Sie", "woll\u00b7te", "par\u00b7tout", "von", "ihm", "ein", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Da geschah es, etwa am Halleschen Tor,", "tokens": ["Da", "ge\u00b7schah", "es", ",", "et\u00b7wa", "am", "Hal\u00b7le\u00b7schen", "Tor", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da\u00df Frieda \u00fcber dem Knutschen und Schmusen", "tokens": ["Da\u00df", "Frie\u00b7da", "\u00fc\u00b7ber", "dem", "Knut\u00b7schen", "und", "Schmu\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "APPR", "ART", "NN", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Aus ihrem hitzig gekitzelten Busen", "tokens": ["Aus", "ih\u00b7rem", "hit\u00b7zig", "ge\u00b7kit\u00b7zel\u00b7ten", "Bu\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJD", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Eine zertanzte, verdr\u00fcckte Rose verlor.", "tokens": ["Ei\u00b7ne", "zer\u00b7tanz\u00b7te", ",", "ver\u00b7dr\u00fcck\u00b7te", "Ro\u00b7se", "ver\u00b7lor", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "NE", "VVFIN", "$."], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}}, "stanza.12": {"line.1": {"text": "Und ein sehr feiner Herr, dessen Eleganz", "tokens": ["Und", "ein", "sehr", "fei\u00b7ner", "Herr", ",", "des\u00b7sen", "E\u00b7le\u00b7ganz"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "ADV", "ADJA", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Nicht so rumtoben tut, folgte den beiden.", "tokens": ["Nicht", "so", "rum\u00b7to\u00b7ben", "tut", ",", "folg\u00b7te", "den", "bei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVINF", "VVFIN", "$,", "VVFIN", "ART", "PIAT", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Jedoch hielt er sich vornehm bescheiden", "tokens": ["Je\u00b7doch", "hielt", "er", "sich", "vor\u00b7nehm", "be\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Immer in einer gewissen Distanz.", "tokens": ["Im\u00b7mer", "in", "ei\u00b7ner", "ge\u00b7wis\u00b7sen", "Dis\u00b7tanz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.13": {"line.1": {"text": "Er wollte urspr\u00fcnglich zum Bierhaus Siechen.", "tokens": ["Er", "woll\u00b7te", "ur\u00b7spr\u00fcng\u00b7lich", "zum", "Bier\u00b7haus", "Sie\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Aber nun hemmte er seinen Lauf,", "tokens": ["A\u00b7ber", "nun", "hemm\u00b7te", "er", "sei\u00b7nen", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Zog die Handschuh aus, hob die Rose auf", "tokens": ["Zog", "die", "Hand\u00b7schuh", "aus", ",", "hob", "die", "Ro\u00b7se", "auf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,", "VVFIN", "ART", "NN", "APPR"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und begann langsam daran zu riechen.", "tokens": ["Und", "be\u00b7gann", "lang\u00b7sam", "da\u00b7ran", "zu", "rie\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PAV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.14": {"line.1": {"text": "Er w\u00fcnschte aber keinen Augenblicksgenu\u00df;", "tokens": ["Er", "w\u00fcnschte", "a\u00b7ber", "kei\u00b7nen", "Au\u00b7gen\u00b7blicks\u00b7ge\u00b7nu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Deshalb stieg er mit der Rose in den Omnibus.", "tokens": ["Des\u00b7halb", "stieg", "er", "mit", "der", "Ro\u00b7se", "in", "den", "Om\u00b7ni\u00b7bus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Derweilen war Frieda mit ihrem Soldaten", "tokens": ["Der\u00b7wei\u00b7len", "war", "Frie\u00b7da", "mit", "ih\u00b7rem", "Sol\u00b7da\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "NE", "APPR", "PPOSAT", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Auf einen Kinderspielplatz geraten.", "tokens": ["Auf", "ei\u00b7nen", "Kin\u00b7der\u00b7spiel\u00b7platz", "ge\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Dort merkten sie nicht, wie die Nacht verstrich", "tokens": ["Dort", "merk\u00b7ten", "sie", "nicht", ",", "wie", "die", "Nacht", "ver\u00b7strich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$,", "PWAV", "ART", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und da\u00df ein unruhiger Mann mit einem Spaten", "tokens": ["Und", "da\u00df", "ein", "un\u00b7ru\u00b7hi\u00b7ger", "Mann", "mit", "ei\u00b7nem", "Spa\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie dauernd beschlich.", "tokens": ["Sie", "dau\u00b7ernd", "be\u00b7schlich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.15": {"line.1": {"text": "Als sich nach l\u00e4ngerem Aufenthalt", "tokens": ["Als", "sich", "nach", "l\u00e4n\u00b7ge\u00b7rem", "Auf\u00b7ent\u00b7halt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "APPR", "ADJA", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Das Paar in der Richtung zur Gasanstalt", "tokens": ["Das", "Paar", "in", "der", "Rich\u00b7tung", "zur", "Ga\u00b7san\u00b7stalt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPRART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Mit kurzen, trippelnden Schritten verlor,", "tokens": ["Mit", "kur\u00b7zen", ",", "trip\u00b7peln\u00b7den", "Schrit\u00b7ten", "ver\u00b7lor", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sprang der unruhige Mann pl\u00f6tzlich hervor.", "tokens": ["Sprang", "der", "un\u00b7ru\u00b7hi\u00b7ge", "Mann", "pl\u00f6tz\u00b7lich", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Und fing an, eine Stelle, wo er im Sand", "tokens": ["Und", "fing", "an", ",", "ei\u00b7ne", "Stel\u00b7le", ",", "wo", "er", "im", "Sand"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "ART", "NN", "$,", "PWAV", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Die Spur von Friedas Stiefelchen fand,", "tokens": ["Die", "Spur", "von", "Frie\u00b7das", "Stie\u00b7fel\u00b7chen", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Mit seinem Spaten herauszuheben.", "tokens": ["Mit", "sei\u00b7nem", "Spa\u00b7ten", "her\u00b7aus\u00b7zu\u00b7he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Worauf er behutsam mit zitternder Hand", "tokens": ["Wo\u00b7rauf", "er", "be\u00b7hut\u00b7sam", "mit", "zit\u00b7tern\u00b7der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PPER", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.9": {"text": "Die feuchte Form in ein Sacktuch band,", "tokens": ["Die", "feuch\u00b7te", "Form", "in", "ein", "Sack\u00b7tuch", "band", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Um sich dann leichenbla\u00df heimzubegeben.", "tokens": ["Um", "sich", "dann", "lei\u00b7chen\u00b7bla\u00df", "heim\u00b7zu\u00b7be\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Wie um das d\u00fcmmste M\u00e4dchen", "tokens": ["Wie", "um", "das", "d\u00fcmms\u00b7te", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sich sonderbare F\u00e4dchen", "tokens": ["Sich", "son\u00b7der\u00b7ba\u00b7re", "F\u00e4d\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["PRF", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nachts durch die Stra\u00dfen ziehn \u2013", "tokens": ["Nachts", "durch", "die", "Stra\u00b7\u00dfen", "ziehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Die Dichter und die Maler", "tokens": ["Die", "Dich\u00b7ter", "und", "die", "Ma\u00b7ler"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und auch die Kriminaler,", "tokens": ["Und", "auch", "die", "Kri\u00b7mi\u00b7na\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Die kennen ihr Berlin.", "tokens": ["Die", "ken\u00b7nen", "ihr", "Ber\u00b7lin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}