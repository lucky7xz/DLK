{"textgrid.poem.44443": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "Warschau", "genre": "verse", "period": "N.A.", "pub_year": 1831, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So bist du denn gefallen, Stadt der Ehre,", "tokens": ["So", "bist", "du", "denn", "ge\u00b7fal\u00b7len", ",", "Stadt", "der", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Heldensinnes letzter Zufluchtsort?", "tokens": ["Des", "Hel\u00b7den\u00b7sin\u00b7nes", "letz\u00b7ter", "Zu\u00b7fluch\u00b7tsort", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo M\u00e4nnerfreiheit nicht mit Satz und Lehre,", "tokens": ["Wo", "M\u00e4n\u00b7ner\u00b7frei\u00b7heit", "nicht", "mit", "Satz", "und", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PTKNEG", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit Schwertern focht, statt mit dem hohlen Wort.", "tokens": ["Mit", "Schwer\u00b7tern", "focht", ",", "statt", "mit", "dem", "hoh\u00b7len", "Wort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "KOUI", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Bist du gefallen? und die Schar der Zungen,", "tokens": ["Bist", "du", "ge\u00b7fal\u00b7len", "?", "und", "die", "Schar", "der", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$.", "KON", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu Meinungsstreit allein noch reg und frisch,", "tokens": ["Zu", "Mei\u00b7nungs\u00b7streit", "al\u00b7lein", "noch", "reg", "und", "frisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bringt plappernd dir die letzten Huldigungen", "tokens": ["Bringt", "plap\u00b7pernd", "dir", "die", "letz\u00b7ten", "Hul\u00b7di\u00b7gun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und setzt sich drauf an des Ministers Tisch.", "tokens": ["Und", "setzt", "sich", "drauf", "an", "des", "Mi\u00b7nis\u00b7ters", "Tisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PAV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Was glaubtest du auch, Stadt der edlen Toren,", "tokens": ["Was", "glaub\u00b7test", "du", "auch", ",", "Stadt", "der", "ed\u00b7len", "To\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Welt, sie nehme Teil an deiner wahren Not?", "tokens": ["Die", "Welt", ",", "sie", "neh\u00b7me", "Teil", "an", "dei\u00b7ner", "wah\u00b7ren", "Not", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als neuerer Lukulle Gladiatoren,", "tokens": ["Als", "neu\u00b7e\u00b7rer", "Lu\u00b7kul\u00b7le", "Gla\u00b7di\u00b7a\u00b7to\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "NN", "$,"], "meter": "-+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Geno\u00df man euern Sieg, genie\u00dft man euern Tod.", "tokens": ["Ge\u00b7no\u00df", "man", "eu\u00b7ern", "Sieg", ",", "ge\u00b7nie\u00dft", "man", "eu\u00b7ern", "Tod", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPOSAT", "NN", "$,", "VVFIN", "PIS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Als j\u00fcngst ein Volk, die Kohle sonstger Feuer,", "tokens": ["Als", "j\u00fcngst", "ein", "Volk", ",", "die", "Koh\u00b7le", "sonst\u00b7ger", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Halb katzenhaft nach seinem Herrn gekrallt,", "tokens": ["Halb", "kat\u00b7zen\u00b7haft", "nach", "sei\u00b7nem", "Herrn", "ge\u00b7krallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da griff ein K\u00f6nig selbst in seine Leier,", "tokens": ["Da", "griff", "ein", "K\u00f6\u00b7nig", "selbst", "in", "sei\u00b7ne", "Lei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und ein Despot rief ihrem Dr\u00e4nger: Halt!", "tokens": ["Und", "ein", "Des\u00b7pot", "rief", "ih\u00b7rem", "Dr\u00e4n\u00b7ger", ":", "Halt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Da sah man eine Welt in Harnisch gehen,", "tokens": ["Da", "sah", "man", "ei\u00b7ne", "Welt", "in", "Har\u00b7nisch", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So Ost als West nahm Teil am edlen Streit;", "tokens": ["So", "Ost", "als", "West", "nahm", "Teil", "am", "ed\u00b7len", "Streit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "KOUS", "NN", "VVFIN", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch damals galts Ruinen, Propyl\u00e4en,", "tokens": ["Doch", "da\u00b7mals", "galts", "Ru\u00b7i\u00b7nen", ",", "Pro\u00b7py\u00b7l\u00e4\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Erinnrungen erinnert sch\u00f6ner Zeit,", "tokens": ["E\u00b7rinn\u00b7run\u00b7gen", "e\u00b7rin\u00b7nert", "sch\u00f6\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+----+-+", "measure": "unknown.measure.tetra"}}, "stanza.6": {"line.1": {"text": "Man hatte schulweis den Homer gelesen", "tokens": ["Man", "hat\u00b7te", "schul\u00b7weis", "den", "Ho\u00b7mer", "ge\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADJD", "ART", "NE", "VVPP"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und hie\u00df gebildet, weil man da geweint;", "tokens": ["Und", "hie\u00df", "ge\u00b7bil\u00b7det", ",", "weil", "man", "da", "ge\u00b7weint", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVPP", "$,", "KOUS", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Polen Not war leiblich wahres Wesen,", "tokens": ["Der", "Po\u00b7len", "Not", "war", "leib\u00b7lich", "wah\u00b7res", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die kein \u00c4on mit Abendrot bescheint.", "tokens": ["Die", "kein", "\u00c4\u00b7on", "mit", "A\u00b7ben\u00b7drot", "be\u00b7scheint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.7": {"line.1": {"text": "Auch mochte dort man hilfreich sich erweisen,", "tokens": ["Auch", "moch\u00b7te", "dort", "man", "hilf\u00b7reich", "sich", "er\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIS", "ADJD", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der eigne Vorteil blieb gesch\u00fctzt, bewahrt;", "tokens": ["Der", "eig\u00b7ne", "Vor\u00b7teil", "blieb", "ge\u00b7sch\u00fctzt", ",", "be\u00b7wahrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kaum kniff ins eigne Fleisch das Rettungseisen,", "tokens": ["Kaum", "kniff", "ins", "eig\u00b7ne", "Fleisch", "das", "Ret\u00b7tungs\u00b7ei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da lie\u00df mit eins der Mut von seiner Art.", "tokens": ["Da", "lie\u00df", "mit", "eins", "der", "Mut", "von", "sei\u00b7ner", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PIS", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "O Frankreich, Frankreich! konntest du verkennen", "tokens": ["O", "Fran\u00b7kreich", ",", "Fran\u00b7kreich", "!", "konn\u00b7test", "du", "ver\u00b7ken\u00b7nen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "NE", "$.", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Platz, auf den ein Gott dich hingestellt?", "tokens": ["Den", "Platz", ",", "auf", "den", "ein", "Gott", "dich", "hin\u00b7ge\u00b7stellt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ART", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bist stolz, der Freiheit Br\u00e4utgam dich zu nennen,", "tokens": ["Bist", "stolz", ",", "der", "Frei\u00b7heit", "Br\u00e4ut\u00b7gam", "dich", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "ART", "NN", "NE", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und zeugst mit ihr nicht Kinder f\u00fcr die Welt?", "tokens": ["Und", "zeugst", "mit", "ihr", "nicht", "Kin\u00b7der", "f\u00fcr", "die", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PTKNEG", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "O schau! viel kl\u00fcger sind sie, die dich hassen;", "tokens": ["O", "schau", "!", "viel", "kl\u00fc\u00b7ger", "sind", "sie", ",", "die", "dich", "has\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "ADV", "ADJD", "VAFIN", "PPER", "$,", "PRELS", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ihr Werk scheint ihnen halb nur und von heut,", "tokens": ["Ihr", "Werk", "scheint", "ih\u00b7nen", "halb", "nur", "und", "von", "heut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "ADV", "KON", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Solang ein Fleck noch auf der Welt gelassen,", "tokens": ["So\u00b7lang", "ein", "Fleck", "noch", "auf", "der", "Welt", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wo nicht ein Herr ob einem Knecht gebeut.", "tokens": ["Wo", "nicht", "ein", "Herr", "ob", "ei\u00b7nem", "Knecht", "ge\u00b7beut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ART", "NN", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Du r\u00fchmst dich deines Zwingherrn \u00dcberwinder,", "tokens": ["Du", "r\u00fchmst", "dich", "dei\u00b7nes", "Zwing\u00b7herrn", "\u00dc\u00b7berw\u00b7in\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den fremde Macht bis heute nie verlie\u00df?", "tokens": ["Den", "frem\u00b7de", "Macht", "bis", "heu\u00b7te", "nie", "ver\u00b7lie\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auf Polens Flur erschl\u00e4gt man Frankreichs Kinder,", "tokens": ["Auf", "Po\u00b7lens", "Flur", "er\u00b7schl\u00e4gt", "man", "Fran\u00b7kreichs", "Kin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVFIN", "PIS", "NE", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In Warschaus Angeln klirrt die Pforte von Paris.", "tokens": ["In", "Warsc\u00b7haus", "An\u00b7geln", "klirrt", "die", "Pfor\u00b7te", "von", "Pa\u00b7ris", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVFIN", "ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Und du, dem man den Namen ging zu holen", "tokens": ["Und", "du", ",", "dem", "man", "den", "Na\u00b7men", "ging", "zu", "ho\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "PRELS", "PIS", "ART", "NN", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ins Land des Gro\u00dfen, kleiner Kasimir!", "tokens": ["Ins", "Land", "des", "Gro\u00b7\u00dfen", ",", "klei\u00b7ner", "Ka\u00b7si\u00b7mir", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als dich der Vater nannte, dacht er: Polen!", "tokens": ["Als", "dich", "der", "Va\u00b7ter", "nann\u00b7te", ",", "dacht", "er", ":", "Po\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "$.", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dein Name bricht mit Polen \u00fcber dir.", "tokens": ["Dein", "Na\u00b7me", "bricht", "mit", "Po\u00b7len", "\u00fc\u00b7ber", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "NE", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "W\u00e4rs Unbill gleich, dich unbegabt zu schelten,", "tokens": ["W\u00e4rs", "Un\u00b7bill", "gleich", ",", "dich", "un\u00b7be\u00b7gabt", "zu", "schel\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "$,", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ist klug gleich manches, was dein Kl\u00fcgeln schuf;", "tokens": ["Ist", "klug", "gleich", "man\u00b7ches", ",", "was", "dein", "Kl\u00fc\u00b7geln", "schuf", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "PIS", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auf gro\u00dfen Bahnen kann nur Gro\u00dfes gelten,", "tokens": ["Auf", "gro\u00b7\u00dfen", "Bah\u00b7nen", "kann", "nur", "Gro\u00b7\u00dfes", "gel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Klein ist, wer kleiner ist als sein Beruf.", "tokens": ["Klein", "ist", ",", "wer", "klei\u00b7ner", "ist", "als", "sein", "Be\u00b7ruf", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "PWS", "ADJD", "VAFIN", "KOKOM", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Ihr Briten, auf! es gilt Smyrneser Trauben,", "tokens": ["Ihr", "Bri\u00b7ten", ",", "auf", "!", "es", "gilt", "Smyr\u00b7ne\u00b7ser", "Trau\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PTKVZ", "$.", "PPER", "VVFIN", "NN", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Oporto-Wein, Brabanter Linnen, auf!", "tokens": ["O\u00b7por\u00b7to\u00b7Wein", ",", "Bra\u00b7ban\u00b7ter", "Lin\u00b7nen", ",", "auf", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "NE", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Frankreich will euern Freund Miguel berauben,", "tokens": ["Fran\u00b7kreich", "will", "eu\u00b7ern", "Freund", "Mi\u00b7guel", "be\u00b7rau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPOSAT", "NN", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "La\u00dft zehn, la\u00dft zwanzig Orlogschiffen Lauf!", "tokens": ["La\u00dft", "zehn", ",", "la\u00dft", "zwan\u00b7zig", "Or\u00b7log\u00b7schif\u00b7fen", "Lauf", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "CARD", "$,", "VVIMP", "CARD", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Ihr Brutuse mit Pfefferd\u00fct und Elle,", "tokens": ["Ihr", "Bru\u00b7tu\u00b7se", "mit", "Pfef\u00b7fer\u00b7d\u00fct", "und", "El\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gerecht nur gegen euch, und das nach filzger Norm!", "tokens": ["Ge\u00b7recht", "nur", "ge\u00b7gen", "euch", ",", "und", "das", "nach", "filz\u00b7ger", "Norm", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PPER", "$,", "KON", "PDS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Schreit nicht das Volk an eurer eignen Schwelle?", "tokens": ["Schreit", "nicht", "das", "Volk", "an", "eu\u00b7rer", "eig\u00b7nen", "Schwel\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Es ruft nach Brot, und ihr gebt ihm Reform.", "tokens": ["Es", "ruft", "nach", "Brot", ",", "und", "ihr", "gebt", "ihm", "Re\u00b7form", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "War Warschau hingebaut am Meeresstrande,", "tokens": ["War", "Warsc\u00b7hau", "hin\u00b7ge\u00b7baut", "am", "Mee\u00b7res\u00b7stran\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und w\u00fcchse Zimmt, wo jetzt nur gr\u00fcne Saat,", "tokens": ["Und", "w\u00fcch\u00b7se", "Zimmt", ",", "wo", "jetzt", "nur", "gr\u00fc\u00b7ne", "Saat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "PWAV", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ihr f\u00fchltet m\u00e4chtgere Verwandtschaftsbande,", "tokens": ["Ihr", "f\u00fchl\u00b7tet", "m\u00e4cht\u00b7ge\u00b7re", "Ver\u00b7wandt\u00b7schafts\u00b7ban\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Polen st\u00fcnde frei, ein Volk, ein Staat.", "tokens": ["Und", "Po\u00b7len", "st\u00fcn\u00b7de", "frei", ",", "ein", "Volk", ",", "ein", "Staat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADJD", "$,", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Doch weil ihr, gleich dem Geizgen im Gedichte,", "tokens": ["Doch", "weil", "ihr", ",", "gleich", "dem", "Geiz\u00b7gen", "im", "Ge\u00b7dich\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "$,", "ADV", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein\u00e4ugig gern, wenn euer Feind nur blind,", "tokens": ["Ein\u00b7\u00e4u\u00b7gig", "gern", ",", "wenn", "eu\u00b7er", "Feind", "nur", "blind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "KOUS", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Lie\u00dft, da\u00df kein Frank den blutgen Hader schlichte,", "tokens": ["Lie\u00dft", ",", "da\u00df", "kein", "Frank", "den", "blut\u00b7gen", "Ha\u00b7der", "schlich\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PIAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ihr Polens Staub hinwehen in den Wind.", "tokens": ["Ihr", "Po\u00b7lens", "Staub", "hin\u00b7we\u00b7hen", "in", "den", "Wind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Und wolltet ihr das Land, vom Rhein durchflossen,", "tokens": ["Und", "woll\u00b7tet", "ihr", "das", "Land", ",", "vom", "Rhein", "durch\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "NN", "$,", "APPRART", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Heimsuchen nicht mit Krieg, der immer hart,", "tokens": ["Heim\u00b7su\u00b7chen", "nicht", "mit", "Krieg", ",", "der", "im\u00b7mer", "hart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "APPR", "NN", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.3": {"text": "Warum mit euern Grenz- und Ruhmsgenossen", "tokens": ["Wa\u00b7rum", "mit", "eu\u00b7ern", "Grenz", "und", "Ruhms\u00b7ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "PPOSAT", "TRUNC", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nach Stambul hin nicht lenken eure Fahrt?", "tokens": ["Nach", "Stam\u00b7bul", "hin", "nicht", "len\u00b7ken", "eu\u00b7re", "Fahrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "PTKNEG", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Dort konntet einem alten Freund ihr n\u00fctzen,", "tokens": ["Dort", "konn\u00b7tet", "ei\u00b7nem", "al\u00b7ten", "Freund", "ihr", "n\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und jeder Streich traf nur den grimmen Zar,", "tokens": ["Und", "je\u00b7der", "Streich", "traf", "nur", "den", "grim\u00b7men", "Zar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch wechselt ihr das Herz mit euren Sitzen,", "tokens": ["Doch", "wech\u00b7selt", "ihr", "das", "Herz", "mit", "eu\u00b7ren", "Sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Wollsack eurer Freiheit Hochaltar. \u2013", "tokens": ["Der", "Woll\u00b7sack", "eu\u00b7rer", "Frei\u00b7heit", "Hoc\u00b7hal\u00b7tar", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Die aber in des Weltteils Mitte wohnen,", "tokens": ["Die", "a\u00b7ber", "in", "des", "Welt\u00b7teils", "Mit\u00b7te", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sind mild, ein Freiheit tr\u00e4umendes Geschlecht!", "tokens": ["Sind", "mild", ",", "ein", "Frei\u00b7heit", "tr\u00e4u\u00b7men\u00b7des", "Ge\u00b7schlecht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie auch als Bettlerpfennig nehmend von den Thronen,", "tokens": ["Sie", "auch", "als", "Bett\u00b7lerp\u00b7fen\u00b7nig", "neh\u00b7mend", "von", "den", "Thro\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KOUS", "NN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch, wo ein Herr, ist auch der Deutsche Knecht.", "tokens": ["Doch", ",", "wo", "ein", "Herr", ",", "ist", "auch", "der", "Deut\u00b7sche", "Knecht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ART", "NN", "$,", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Die einen sind zu schwach, die andern \u2013 stille!", "tokens": ["Die", "ei\u00b7nen", "sind", "zu", "schwach", ",", "die", "an\u00b7dern", "\u2013", "stil\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "PTKA", "ADJD", "$,", "PRELS", "PIS", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von diesen spreche nimmermehr ein Lied!", "tokens": ["Von", "die\u00b7sen", "spre\u00b7che", "nim\u00b7mer\u00b7mehr", "ein", "Lied", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Zum Guten fehlt nicht Macht, es fehlt der Wille,", "tokens": ["Zum", "Gu\u00b7ten", "fehlt", "nicht", "Macht", ",", "es", "fehlt", "der", "Wil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PTKNEG", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Auge fehlt, das frei nach au\u00dfen sieht.", "tokens": ["Das", "Au\u00b7ge", "fehlt", ",", "das", "frei", "nach", "au\u00b7\u00dfen", "sieht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "ADJD", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Die Freiheit hassen sie, doch nicht alleine,", "tokens": ["Die", "Frei\u00b7heit", "has\u00b7sen", "sie", ",", "doch", "nicht", "al\u00b7lei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht mehr als all, was stammt vom ewgen Geist,", "tokens": ["Nicht", "mehr", "als", "all", ",", "was", "stammt", "vom", "ew\u00b7gen", "Geist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "KOKOM", "PIAT", "$,", "PWS", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und atmend lebt im hellen Sonnenscheine,", "tokens": ["Und", "at\u00b7mend", "lebt", "im", "hel\u00b7len", "Son\u00b7nen\u00b7schei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was w\u00e4rmt, erhebt, was denkt und unterweist.", "tokens": ["Was", "w\u00e4rmt", ",", "er\u00b7hebt", ",", "was", "denkt", "und", "un\u00b7ter\u00b7weist", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "VVFIN", "$,", "PWS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Dort t\u00f6nt kein Wort durch sp\u00e4herwache L\u00fcfte,", "tokens": ["Dort", "t\u00f6nt", "kein", "Wort", "durch", "sp\u00e4\u00b7her\u00b7wa\u00b7che", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Scheu kriecht das Denken in sich selbst zur\u00fcck,", "tokens": ["Scheu", "kriecht", "das", "Den\u00b7ken", "in", "sich", "selbst", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "APPR", "PRF", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Brust vernieten krummgebogne ", "tokens": ["Die", "Brust", "ver\u00b7nie\u00b7ten", "krumm\u00b7ge\u00b7bog\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.23": {"line.1": {"text": "Gleichwie in Dantes dunkeln Schauderorten", "tokens": ["Gleich\u00b7wie", "in", "Dan\u00b7tes", "dun\u00b7keln", "Schau\u00b7der\u00b7or\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Inschrift lehrt, da\u00df da kein R\u00fccktritt sei,", "tokens": ["Die", "In\u00b7schrift", "lehrt", ",", "da\u00df", "da", "kein", "R\u00fcck\u00b7tritt", "sei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "ADV", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Steh inschriftweis an dieses Landes Pforten", "tokens": ["Steh", "in\u00b7schrift\u00b7weis", "an", "die\u00b7ses", "Lan\u00b7des", "Pfor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PDAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Dem Throne nah sitzt dort ein Mann seit Jahren,", "tokens": ["Dem", "Thro\u00b7ne", "nah", "sitzt", "dort", "ein", "Mann", "seit", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die glatte Stirn im Venusdienst gebleicht,", "tokens": ["Die", "glat\u00b7te", "Stirn", "im", "Ve\u00b7nus\u00b7dienst", "ge\u00b7bleicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dem Einf\u00e4ll luftig durchs Gehirne fahren,", "tokens": ["Dem", "Ein\u00b7f\u00e4ll", "luf\u00b7tig", "durchs", "Ge\u00b7hir\u00b7ne", "fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die ihm ein andrer auf Systeme zeucht;", "tokens": ["Die", "ihm", "ein", "an\u00b7drer", "auf", "Sys\u00b7te\u00b7me", "zeucht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "APPR", "NN", "VVFIN", "$."], "meter": "---+--+--+", "measure": "iambic.tri.relaxed"}}, "stanza.25": {"line.1": {"text": "Und wenn der Zeitgeist durch die Macht der Schwere", "tokens": ["Und", "wenn", "der", "Zeit\u00b7geist", "durch", "die", "Macht", "der", "Schwe\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zur Erde sinkt, der strahlend er entflog,", "tokens": ["Zur", "Er\u00b7de", "sinkt", ",", "der", "strah\u00b7lend", "er", "ent\u00b7flog", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PRELS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So schw\u00f6rt der kleine Mann auf Wort und Ehre,", "tokens": ["So", "schw\u00f6rt", "der", "klei\u00b7ne", "Mann", "auf", "Wort", "und", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sein Gaukeln seis, das ihn hernieder zog.", "tokens": ["Sein", "Gau\u00b7keln", "seis", ",", "das", "ihn", "her\u00b7nie\u00b7der", "zog", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Wer lieber sich von Ebenb\u00fcrtgen treten,", "tokens": ["Wer", "lie\u00b7ber", "sich", "von", "E\u00b7ben\u00b7b\u00fcrt\u00b7gen", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als mahnen lassen will vom mindern Mann,", "tokens": ["Als", "mah\u00b7nen", "las\u00b7sen", "will", "vom", "min\u00b7dern", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVINF", "VVINF", "VMFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wird fruchtlos zu der Menschheit Fest gebeten,", "tokens": ["Wird", "frucht\u00b7los", "zu", "der", "Menschheit", "Fest", "ge\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Er war entschuldigt, eh es noch begann.", "tokens": ["Er", "war", "ent\u00b7schul\u00b7digt", ",", "eh", "es", "noch", "be\u00b7gann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Dir aber, Preu\u00dfen, la\u00df mich donnernd sprechen,", "tokens": ["Dir", "a\u00b7ber", ",", "Preu\u00b7\u00dfen", ",", "la\u00df", "mich", "don\u00b7nernd", "spre\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "NE", "$,", "VVIMP", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Warum tust du nicht deiner Pflicht genug?", "tokens": ["Wa\u00b7rum", "tust", "du", "nicht", "dei\u00b7ner", "Pflicht", "ge\u00b7nug", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kaum w\u00e4chst ja Brot auf deinen sandgen Fl\u00e4chen,", "tokens": ["Kaum", "w\u00e4chst", "ja", "Brot", "auf", "dei\u00b7nen", "sand\u00b7gen", "Fl\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Geist allein dein Acker und dein Pflug.", "tokens": ["Der", "Geist", "al\u00b7lein", "dein", "A\u00b7cker", "und", "dein", "Pflug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Als dich der leider Einzge deiner Fritze", "tokens": ["Als", "dich", "der", "lei\u00b7der", "Einz\u00b7ge", "dei\u00b7ner", "Frit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Zahl zum Trotz, hoch zu den Sternen trug,", "tokens": ["Der", "Zahl", "zum", "Trotz", ",", "hoch", "zu", "den", "Ster\u00b7nen", "trug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dacht er dich stets auch an der Bildung Spitze,", "tokens": ["Dacht", "er", "dich", "stets", "auch", "an", "der", "Bil\u00b7dung", "Spit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.4": {"text": "Stoff gegen Stoff, zerbricht der schw\u00e4chre Krug.", "tokens": ["Stoff", "ge\u00b7gen", "Stoff", ",", "zer\u00b7bricht", "der", "schw\u00e4ch\u00b7re", "Krug", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.29": {"line.1": {"text": "Und wars dein Volk nicht, das dich r\u00fcckerstritten,", "tokens": ["Und", "wars", "dein", "Volk", "nicht", ",", "das", "dich", "r\u00fc\u00b7cker\u00b7strit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "PTKNEG", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als du gestellt dich an des Abgrunds Bord?", "tokens": ["Als", "du", "ge\u00b7stellt", "dich", "an", "des", "Ab\u00b7grunds", "Bord", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Warum nun zittern in des Volkes Mitten,", "tokens": ["Wa\u00b7rum", "nun", "zit\u00b7tern", "in", "des", "Vol\u00b7kes", "Mit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Dasein betteln von dem eisgen Nord?", "tokens": ["Das", "Da\u00b7sein", "bet\u00b7teln", "von", "dem", "eis\u00b7gen", "Nord", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Lebst etwa du in der Erinnrung R\u00e4umen,", "tokens": ["Lebst", "et\u00b7wa", "du", "in", "der", "E\u00b7rinn\u00b7rung", "R\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.2": {"text": "Wie damals, als dein Junkerheer zerschmolz?", "tokens": ["Wie", "da\u00b7mals", ",", "als", "dein", "Jun\u00b7ker\u00b7heer", "zer\u00b7schmolz", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "KOUS", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein gleich Erwachen harret gleichen Tr\u00e4umen,", "tokens": ["Ein", "gleich", "Er\u00b7wa\u00b7chen", "har\u00b7ret", "glei\u00b7chen", "Tr\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Jena liegt, wo D\u00fcnkel steht und Stolz.", "tokens": ["Ein", "Je\u00b7na", "liegt", ",", "wo", "D\u00fcn\u00b7kel", "steht", "und", "Stolz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$,", "PWAV", "NN", "VVFIN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "Sie aber h\u00f6ren nicht, sind nicht zu retten!", "tokens": ["Sie", "a\u00b7ber", "h\u00f6\u00b7ren", "nicht", ",", "sind", "nicht", "zu", "ret\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKNEG", "$,", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Niederung verm\u00e4hlt sich gern dem Sumpf;", "tokens": ["Die", "Nie\u00b7de\u00b7rung", "ver\u00b7m\u00e4hlt", "sich", "gern", "dem", "Sumpf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Barbarsche K\u00f6nige in goldnen Ketten,", "tokens": ["Bar\u00b7bar\u00b7sche", "K\u00f6\u00b7ni\u00b7ge", "in", "gold\u00b7nen", "Ket\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "D\u00fcnkt ihnen sch\u00f6n ein russischer Triumph.", "tokens": ["D\u00fcnkt", "ih\u00b7nen", "sch\u00f6n", "ein", "rus\u00b7si\u00b7scher", "Tri\u00b7umph", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Du aber, Freiheit, die der Fr\u00fchlingsmorgen", "tokens": ["Du", "a\u00b7ber", ",", "Frei\u00b7heit", ",", "die", "der", "Fr\u00fch\u00b7lings\u00b7mor\u00b7gen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "$,", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hervorrief aus dem eisumschlo\u00dfnen Grab,", "tokens": ["Her\u00b7vor\u00b7rief", "aus", "dem", "ei\u00b7sum\u00b7schlo\u00df\u00b7nen", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Sonne hat von neuem sich verborgen,", "tokens": ["Die", "Son\u00b7ne", "hat", "von", "neu\u00b7em", "sich", "ver\u00b7bor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ADJA", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Steig wieder nur zur kalten Gruft hinab.", "tokens": ["Steig", "wie\u00b7der", "nur", "zur", "kal\u00b7ten", "Gruft", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "Doch h\u00fcte dich, zu fest, zu lang zu schlafen,", "tokens": ["Doch", "h\u00fc\u00b7te", "dich", ",", "zu", "fest", ",", "zu", "lang", "zu", "schla\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PTKA", "ADJD", "$,", "PTKA", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hat ja kein Winter ewig noch gethront,", "tokens": ["Hat", "ja", "kein", "Win\u00b7ter", "e\u00b7wig", "noch", "ge\u00b7thront", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn im Mai erst laue Strahlen trafen,", "tokens": ["Und", "wenn", "im", "Mai", "erst", "lau\u00b7e", "Strah\u00b7len", "tra\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPRART", "NN", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "K\u00f6mmt ", "tokens": ["K\u00f6mmt"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}, "stanza.34": {"line.1": {"text": "So bist du denn gefallen, Stadt der Ehre,", "tokens": ["So", "bist", "du", "denn", "ge\u00b7fal\u00b7len", ",", "Stadt", "der", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Heldensinnes letzter Zufluchtsort?", "tokens": ["Des", "Hel\u00b7den\u00b7sin\u00b7nes", "letz\u00b7ter", "Zu\u00b7fluch\u00b7tsort", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo M\u00e4nnerfreiheit nicht mit Satz und Lehre,", "tokens": ["Wo", "M\u00e4n\u00b7ner\u00b7frei\u00b7heit", "nicht", "mit", "Satz", "und", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PTKNEG", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit Schwertern focht, statt mit dem hohlen Wort.", "tokens": ["Mit", "Schwer\u00b7tern", "focht", ",", "statt", "mit", "dem", "hoh\u00b7len", "Wort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "KOUI", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Bist du gefallen? und die Schar der Zungen,", "tokens": ["Bist", "du", "ge\u00b7fal\u00b7len", "?", "und", "die", "Schar", "der", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$.", "KON", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu Meinungsstreit allein noch reg und frisch,", "tokens": ["Zu", "Mei\u00b7nungs\u00b7streit", "al\u00b7lein", "noch", "reg", "und", "frisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bringt plappernd dir die letzten Huldigungen", "tokens": ["Bringt", "plap\u00b7pernd", "dir", "die", "letz\u00b7ten", "Hul\u00b7di\u00b7gun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und setzt sich drauf an des Ministers Tisch.", "tokens": ["Und", "setzt", "sich", "drauf", "an", "des", "Mi\u00b7nis\u00b7ters", "Tisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PAV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.36": {"line.1": {"text": "Was glaubtest du auch, Stadt der edlen Toren,", "tokens": ["Was", "glaub\u00b7test", "du", "auch", ",", "Stadt", "der", "ed\u00b7len", "To\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Welt, sie nehme Teil an deiner wahren Not?", "tokens": ["Die", "Welt", ",", "sie", "neh\u00b7me", "Teil", "an", "dei\u00b7ner", "wah\u00b7ren", "Not", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als neuerer Lukulle Gladiatoren,", "tokens": ["Als", "neu\u00b7e\u00b7rer", "Lu\u00b7kul\u00b7le", "Gla\u00b7di\u00b7a\u00b7to\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "NN", "$,"], "meter": "-+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Geno\u00df man euern Sieg, genie\u00dft man euern Tod.", "tokens": ["Ge\u00b7no\u00df", "man", "eu\u00b7ern", "Sieg", ",", "ge\u00b7nie\u00dft", "man", "eu\u00b7ern", "Tod", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPOSAT", "NN", "$,", "VVFIN", "PIS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Als j\u00fcngst ein Volk, die Kohle sonstger Feuer,", "tokens": ["Als", "j\u00fcngst", "ein", "Volk", ",", "die", "Koh\u00b7le", "sonst\u00b7ger", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Halb katzenhaft nach seinem Herrn gekrallt,", "tokens": ["Halb", "kat\u00b7zen\u00b7haft", "nach", "sei\u00b7nem", "Herrn", "ge\u00b7krallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da griff ein K\u00f6nig selbst in seine Leier,", "tokens": ["Da", "griff", "ein", "K\u00f6\u00b7nig", "selbst", "in", "sei\u00b7ne", "Lei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und ein Despot rief ihrem Dr\u00e4nger: Halt!", "tokens": ["Und", "ein", "Des\u00b7pot", "rief", "ih\u00b7rem", "Dr\u00e4n\u00b7ger", ":", "Halt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.38": {"line.1": {"text": "Da sah man eine Welt in Harnisch gehen,", "tokens": ["Da", "sah", "man", "ei\u00b7ne", "Welt", "in", "Har\u00b7nisch", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So Ost als West nahm Teil am edlen Streit;", "tokens": ["So", "Ost", "als", "West", "nahm", "Teil", "am", "ed\u00b7len", "Streit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "KOUS", "NN", "VVFIN", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch damals galts Ruinen, Propyl\u00e4en,", "tokens": ["Doch", "da\u00b7mals", "galts", "Ru\u00b7i\u00b7nen", ",", "Pro\u00b7py\u00b7l\u00e4\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Erinnrungen erinnert sch\u00f6ner Zeit,", "tokens": ["E\u00b7rinn\u00b7run\u00b7gen", "e\u00b7rin\u00b7nert", "sch\u00f6\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+----+-+", "measure": "unknown.measure.tetra"}}, "stanza.39": {"line.1": {"text": "Man hatte schulweis den Homer gelesen", "tokens": ["Man", "hat\u00b7te", "schul\u00b7weis", "den", "Ho\u00b7mer", "ge\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADJD", "ART", "NE", "VVPP"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und hie\u00df gebildet, weil man da geweint;", "tokens": ["Und", "hie\u00df", "ge\u00b7bil\u00b7det", ",", "weil", "man", "da", "ge\u00b7weint", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVPP", "$,", "KOUS", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Polen Not war leiblich wahres Wesen,", "tokens": ["Der", "Po\u00b7len", "Not", "war", "leib\u00b7lich", "wah\u00b7res", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die kein \u00c4on mit Abendrot bescheint.", "tokens": ["Die", "kein", "\u00c4\u00b7on", "mit", "A\u00b7ben\u00b7drot", "be\u00b7scheint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.40": {"line.1": {"text": "Auch mochte dort man hilfreich sich erweisen,", "tokens": ["Auch", "moch\u00b7te", "dort", "man", "hilf\u00b7reich", "sich", "er\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIS", "ADJD", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der eigne Vorteil blieb gesch\u00fctzt, bewahrt;", "tokens": ["Der", "eig\u00b7ne", "Vor\u00b7teil", "blieb", "ge\u00b7sch\u00fctzt", ",", "be\u00b7wahrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kaum kniff ins eigne Fleisch das Rettungseisen,", "tokens": ["Kaum", "kniff", "ins", "eig\u00b7ne", "Fleisch", "das", "Ret\u00b7tungs\u00b7ei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da lie\u00df mit eins der Mut von seiner Art.", "tokens": ["Da", "lie\u00df", "mit", "eins", "der", "Mut", "von", "sei\u00b7ner", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PIS", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.41": {"line.1": {"text": "O Frankreich, Frankreich! konntest du verkennen", "tokens": ["O", "Fran\u00b7kreich", ",", "Fran\u00b7kreich", "!", "konn\u00b7test", "du", "ver\u00b7ken\u00b7nen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "NE", "$.", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Platz, auf den ein Gott dich hingestellt?", "tokens": ["Den", "Platz", ",", "auf", "den", "ein", "Gott", "dich", "hin\u00b7ge\u00b7stellt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ART", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bist stolz, der Freiheit Br\u00e4utgam dich zu nennen,", "tokens": ["Bist", "stolz", ",", "der", "Frei\u00b7heit", "Br\u00e4ut\u00b7gam", "dich", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "ART", "NN", "NE", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und zeugst mit ihr nicht Kinder f\u00fcr die Welt?", "tokens": ["Und", "zeugst", "mit", "ihr", "nicht", "Kin\u00b7der", "f\u00fcr", "die", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PTKNEG", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.42": {"line.1": {"text": "O schau! viel kl\u00fcger sind sie, die dich hassen;", "tokens": ["O", "schau", "!", "viel", "kl\u00fc\u00b7ger", "sind", "sie", ",", "die", "dich", "has\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "ADV", "ADJD", "VAFIN", "PPER", "$,", "PRELS", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ihr Werk scheint ihnen halb nur und von heut,", "tokens": ["Ihr", "Werk", "scheint", "ih\u00b7nen", "halb", "nur", "und", "von", "heut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "ADV", "KON", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Solang ein Fleck noch auf der Welt gelassen,", "tokens": ["So\u00b7lang", "ein", "Fleck", "noch", "auf", "der", "Welt", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wo nicht ein Herr ob einem Knecht gebeut.", "tokens": ["Wo", "nicht", "ein", "Herr", "ob", "ei\u00b7nem", "Knecht", "ge\u00b7beut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ART", "NN", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.43": {"line.1": {"text": "Du r\u00fchmst dich deines Zwingherrn \u00dcberwinder,", "tokens": ["Du", "r\u00fchmst", "dich", "dei\u00b7nes", "Zwing\u00b7herrn", "\u00dc\u00b7berw\u00b7in\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den fremde Macht bis heute nie verlie\u00df?", "tokens": ["Den", "frem\u00b7de", "Macht", "bis", "heu\u00b7te", "nie", "ver\u00b7lie\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auf Polens Flur erschl\u00e4gt man Frankreichs Kinder,", "tokens": ["Auf", "Po\u00b7lens", "Flur", "er\u00b7schl\u00e4gt", "man", "Fran\u00b7kreichs", "Kin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVFIN", "PIS", "NE", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In Warschaus Angeln klirrt die Pforte von Paris.", "tokens": ["In", "Warsc\u00b7haus", "An\u00b7geln", "klirrt", "die", "Pfor\u00b7te", "von", "Pa\u00b7ris", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVFIN", "ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "Und du, dem man den Namen ging zu holen", "tokens": ["Und", "du", ",", "dem", "man", "den", "Na\u00b7men", "ging", "zu", "ho\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "PRELS", "PIS", "ART", "NN", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ins Land des Gro\u00dfen, kleiner Kasimir!", "tokens": ["Ins", "Land", "des", "Gro\u00b7\u00dfen", ",", "klei\u00b7ner", "Ka\u00b7si\u00b7mir", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als dich der Vater nannte, dacht er: Polen!", "tokens": ["Als", "dich", "der", "Va\u00b7ter", "nann\u00b7te", ",", "dacht", "er", ":", "Po\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "$.", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dein Name bricht mit Polen \u00fcber dir.", "tokens": ["Dein", "Na\u00b7me", "bricht", "mit", "Po\u00b7len", "\u00fc\u00b7ber", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "NE", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.45": {"line.1": {"text": "W\u00e4rs Unbill gleich, dich unbegabt zu schelten,", "tokens": ["W\u00e4rs", "Un\u00b7bill", "gleich", ",", "dich", "un\u00b7be\u00b7gabt", "zu", "schel\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "$,", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ist klug gleich manches, was dein Kl\u00fcgeln schuf;", "tokens": ["Ist", "klug", "gleich", "man\u00b7ches", ",", "was", "dein", "Kl\u00fc\u00b7geln", "schuf", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "PIS", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auf gro\u00dfen Bahnen kann nur Gro\u00dfes gelten,", "tokens": ["Auf", "gro\u00b7\u00dfen", "Bah\u00b7nen", "kann", "nur", "Gro\u00b7\u00dfes", "gel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Klein ist, wer kleiner ist als sein Beruf.", "tokens": ["Klein", "ist", ",", "wer", "klei\u00b7ner", "ist", "als", "sein", "Be\u00b7ruf", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "PWS", "ADJD", "VAFIN", "KOKOM", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.46": {"line.1": {"text": "Ihr Briten, auf! es gilt Smyrneser Trauben,", "tokens": ["Ihr", "Bri\u00b7ten", ",", "auf", "!", "es", "gilt", "Smyr\u00b7ne\u00b7ser", "Trau\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PTKVZ", "$.", "PPER", "VVFIN", "NN", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Oporto-Wein, Brabanter Linnen, auf!", "tokens": ["O\u00b7por\u00b7to\u00b7Wein", ",", "Bra\u00b7ban\u00b7ter", "Lin\u00b7nen", ",", "auf", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "NE", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Frankreich will euern Freund Miguel berauben,", "tokens": ["Fran\u00b7kreich", "will", "eu\u00b7ern", "Freund", "Mi\u00b7guel", "be\u00b7rau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPOSAT", "NN", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "La\u00dft zehn, la\u00dft zwanzig Orlogschiffen Lauf!", "tokens": ["La\u00dft", "zehn", ",", "la\u00dft", "zwan\u00b7zig", "Or\u00b7log\u00b7schif\u00b7fen", "Lauf", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "CARD", "$,", "VVIMP", "CARD", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.47": {"line.1": {"text": "Ihr Brutuse mit Pfefferd\u00fct und Elle,", "tokens": ["Ihr", "Bru\u00b7tu\u00b7se", "mit", "Pfef\u00b7fer\u00b7d\u00fct", "und", "El\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gerecht nur gegen euch, und das nach filzger Norm!", "tokens": ["Ge\u00b7recht", "nur", "ge\u00b7gen", "euch", ",", "und", "das", "nach", "filz\u00b7ger", "Norm", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PPER", "$,", "KON", "PDS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Schreit nicht das Volk an eurer eignen Schwelle?", "tokens": ["Schreit", "nicht", "das", "Volk", "an", "eu\u00b7rer", "eig\u00b7nen", "Schwel\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Es ruft nach Brot, und ihr gebt ihm Reform.", "tokens": ["Es", "ruft", "nach", "Brot", ",", "und", "ihr", "gebt", "ihm", "Re\u00b7form", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.48": {"line.1": {"text": "War Warschau hingebaut am Meeresstrande,", "tokens": ["War", "Warsc\u00b7hau", "hin\u00b7ge\u00b7baut", "am", "Mee\u00b7res\u00b7stran\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und w\u00fcchse Zimmt, wo jetzt nur gr\u00fcne Saat,", "tokens": ["Und", "w\u00fcch\u00b7se", "Zimmt", ",", "wo", "jetzt", "nur", "gr\u00fc\u00b7ne", "Saat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "PWAV", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ihr f\u00fchltet m\u00e4chtgere Verwandtschaftsbande,", "tokens": ["Ihr", "f\u00fchl\u00b7tet", "m\u00e4cht\u00b7ge\u00b7re", "Ver\u00b7wandt\u00b7schafts\u00b7ban\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Polen st\u00fcnde frei, ein Volk, ein Staat.", "tokens": ["Und", "Po\u00b7len", "st\u00fcn\u00b7de", "frei", ",", "ein", "Volk", ",", "ein", "Staat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADJD", "$,", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.49": {"line.1": {"text": "Doch weil ihr, gleich dem Geizgen im Gedichte,", "tokens": ["Doch", "weil", "ihr", ",", "gleich", "dem", "Geiz\u00b7gen", "im", "Ge\u00b7dich\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "$,", "ADV", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein\u00e4ugig gern, wenn euer Feind nur blind,", "tokens": ["Ein\u00b7\u00e4u\u00b7gig", "gern", ",", "wenn", "eu\u00b7er", "Feind", "nur", "blind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "KOUS", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Lie\u00dft, da\u00df kein Frank den blutgen Hader schlichte,", "tokens": ["Lie\u00dft", ",", "da\u00df", "kein", "Frank", "den", "blut\u00b7gen", "Ha\u00b7der", "schlich\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PIAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ihr Polens Staub hinwehen in den Wind.", "tokens": ["Ihr", "Po\u00b7lens", "Staub", "hin\u00b7we\u00b7hen", "in", "den", "Wind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.50": {"line.1": {"text": "Und wolltet ihr das Land, vom Rhein durchflossen,", "tokens": ["Und", "woll\u00b7tet", "ihr", "das", "Land", ",", "vom", "Rhein", "durch\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "NN", "$,", "APPRART", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Heimsuchen nicht mit Krieg, der immer hart,", "tokens": ["Heim\u00b7su\u00b7chen", "nicht", "mit", "Krieg", ",", "der", "im\u00b7mer", "hart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "APPR", "NN", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.3": {"text": "Warum mit euern Grenz- und Ruhmsgenossen", "tokens": ["Wa\u00b7rum", "mit", "eu\u00b7ern", "Grenz", "und", "Ruhms\u00b7ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "PPOSAT", "TRUNC", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nach Stambul hin nicht lenken eure Fahrt?", "tokens": ["Nach", "Stam\u00b7bul", "hin", "nicht", "len\u00b7ken", "eu\u00b7re", "Fahrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "PTKNEG", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.51": {"line.1": {"text": "Dort konntet einem alten Freund ihr n\u00fctzen,", "tokens": ["Dort", "konn\u00b7tet", "ei\u00b7nem", "al\u00b7ten", "Freund", "ihr", "n\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und jeder Streich traf nur den grimmen Zar,", "tokens": ["Und", "je\u00b7der", "Streich", "traf", "nur", "den", "grim\u00b7men", "Zar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch wechselt ihr das Herz mit euren Sitzen,", "tokens": ["Doch", "wech\u00b7selt", "ihr", "das", "Herz", "mit", "eu\u00b7ren", "Sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Wollsack eurer Freiheit Hochaltar. \u2013", "tokens": ["Der", "Woll\u00b7sack", "eu\u00b7rer", "Frei\u00b7heit", "Hoc\u00b7hal\u00b7tar", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.52": {"line.1": {"text": "Die aber in des Weltteils Mitte wohnen,", "tokens": ["Die", "a\u00b7ber", "in", "des", "Welt\u00b7teils", "Mit\u00b7te", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sind mild, ein Freiheit tr\u00e4umendes Geschlecht!", "tokens": ["Sind", "mild", ",", "ein", "Frei\u00b7heit", "tr\u00e4u\u00b7men\u00b7des", "Ge\u00b7schlecht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie auch als Bettlerpfennig nehmend von den Thronen,", "tokens": ["Sie", "auch", "als", "Bett\u00b7lerp\u00b7fen\u00b7nig", "neh\u00b7mend", "von", "den", "Thro\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KOUS", "NN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch, wo ein Herr, ist auch der Deutsche Knecht.", "tokens": ["Doch", ",", "wo", "ein", "Herr", ",", "ist", "auch", "der", "Deut\u00b7sche", "Knecht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ART", "NN", "$,", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.53": {"line.1": {"text": "Die einen sind zu schwach, die andern \u2013 stille!", "tokens": ["Die", "ei\u00b7nen", "sind", "zu", "schwach", ",", "die", "an\u00b7dern", "\u2013", "stil\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "PTKA", "ADJD", "$,", "PRELS", "PIS", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von diesen spreche nimmermehr ein Lied!", "tokens": ["Von", "die\u00b7sen", "spre\u00b7che", "nim\u00b7mer\u00b7mehr", "ein", "Lied", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Zum Guten fehlt nicht Macht, es fehlt der Wille,", "tokens": ["Zum", "Gu\u00b7ten", "fehlt", "nicht", "Macht", ",", "es", "fehlt", "der", "Wil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PTKNEG", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Auge fehlt, das frei nach au\u00dfen sieht.", "tokens": ["Das", "Au\u00b7ge", "fehlt", ",", "das", "frei", "nach", "au\u00b7\u00dfen", "sieht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "ADJD", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.54": {"line.1": {"text": "Die Freiheit hassen sie, doch nicht alleine,", "tokens": ["Die", "Frei\u00b7heit", "has\u00b7sen", "sie", ",", "doch", "nicht", "al\u00b7lei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht mehr als all, was stammt vom ewgen Geist,", "tokens": ["Nicht", "mehr", "als", "all", ",", "was", "stammt", "vom", "ew\u00b7gen", "Geist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "KOKOM", "PIAT", "$,", "PWS", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und atmend lebt im hellen Sonnenscheine,", "tokens": ["Und", "at\u00b7mend", "lebt", "im", "hel\u00b7len", "Son\u00b7nen\u00b7schei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was w\u00e4rmt, erhebt, was denkt und unterweist.", "tokens": ["Was", "w\u00e4rmt", ",", "er\u00b7hebt", ",", "was", "denkt", "und", "un\u00b7ter\u00b7weist", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "VVFIN", "$,", "PWS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.55": {"line.1": {"text": "Dort t\u00f6nt kein Wort durch sp\u00e4herwache L\u00fcfte,", "tokens": ["Dort", "t\u00f6nt", "kein", "Wort", "durch", "sp\u00e4\u00b7her\u00b7wa\u00b7che", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Scheu kriecht das Denken in sich selbst zur\u00fcck,", "tokens": ["Scheu", "kriecht", "das", "Den\u00b7ken", "in", "sich", "selbst", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "APPR", "PRF", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Brust vernieten krummgebogne ", "tokens": ["Die", "Brust", "ver\u00b7nie\u00b7ten", "krumm\u00b7ge\u00b7bog\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.56": {"line.1": {"text": "Gleichwie in Dantes dunkeln Schauderorten", "tokens": ["Gleich\u00b7wie", "in", "Dan\u00b7tes", "dun\u00b7keln", "Schau\u00b7der\u00b7or\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Inschrift lehrt, da\u00df da kein R\u00fccktritt sei,", "tokens": ["Die", "In\u00b7schrift", "lehrt", ",", "da\u00df", "da", "kein", "R\u00fcck\u00b7tritt", "sei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "ADV", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Steh inschriftweis an dieses Landes Pforten", "tokens": ["Steh", "in\u00b7schrift\u00b7weis", "an", "die\u00b7ses", "Lan\u00b7des", "Pfor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PDAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.57": {"line.1": {"text": "Dem Throne nah sitzt dort ein Mann seit Jahren,", "tokens": ["Dem", "Thro\u00b7ne", "nah", "sitzt", "dort", "ein", "Mann", "seit", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die glatte Stirn im Venusdienst gebleicht,", "tokens": ["Die", "glat\u00b7te", "Stirn", "im", "Ve\u00b7nus\u00b7dienst", "ge\u00b7bleicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dem Einf\u00e4ll luftig durchs Gehirne fahren,", "tokens": ["Dem", "Ein\u00b7f\u00e4ll", "luf\u00b7tig", "durchs", "Ge\u00b7hir\u00b7ne", "fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die ihm ein andrer auf Systeme zeucht;", "tokens": ["Die", "ihm", "ein", "an\u00b7drer", "auf", "Sys\u00b7te\u00b7me", "zeucht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "APPR", "NN", "VVFIN", "$."], "meter": "---+--+--+", "measure": "iambic.tri.relaxed"}}, "stanza.58": {"line.1": {"text": "Und wenn der Zeitgeist durch die Macht der Schwere", "tokens": ["Und", "wenn", "der", "Zeit\u00b7geist", "durch", "die", "Macht", "der", "Schwe\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zur Erde sinkt, der strahlend er entflog,", "tokens": ["Zur", "Er\u00b7de", "sinkt", ",", "der", "strah\u00b7lend", "er", "ent\u00b7flog", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PRELS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So schw\u00f6rt der kleine Mann auf Wort und Ehre,", "tokens": ["So", "schw\u00f6rt", "der", "klei\u00b7ne", "Mann", "auf", "Wort", "und", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sein Gaukeln seis, das ihn hernieder zog.", "tokens": ["Sein", "Gau\u00b7keln", "seis", ",", "das", "ihn", "her\u00b7nie\u00b7der", "zog", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.59": {"line.1": {"text": "Wer lieber sich von Ebenb\u00fcrtgen treten,", "tokens": ["Wer", "lie\u00b7ber", "sich", "von", "E\u00b7ben\u00b7b\u00fcrt\u00b7gen", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als mahnen lassen will vom mindern Mann,", "tokens": ["Als", "mah\u00b7nen", "las\u00b7sen", "will", "vom", "min\u00b7dern", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVINF", "VVINF", "VMFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wird fruchtlos zu der Menschheit Fest gebeten,", "tokens": ["Wird", "frucht\u00b7los", "zu", "der", "Menschheit", "Fest", "ge\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Er war entschuldigt, eh es noch begann.", "tokens": ["Er", "war", "ent\u00b7schul\u00b7digt", ",", "eh", "es", "noch", "be\u00b7gann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.60": {"line.1": {"text": "Dir aber, Preu\u00dfen, la\u00df mich donnernd sprechen,", "tokens": ["Dir", "a\u00b7ber", ",", "Preu\u00b7\u00dfen", ",", "la\u00df", "mich", "don\u00b7nernd", "spre\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "NE", "$,", "VVIMP", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Warum tust du nicht deiner Pflicht genug?", "tokens": ["Wa\u00b7rum", "tust", "du", "nicht", "dei\u00b7ner", "Pflicht", "ge\u00b7nug", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kaum w\u00e4chst ja Brot auf deinen sandgen Fl\u00e4chen,", "tokens": ["Kaum", "w\u00e4chst", "ja", "Brot", "auf", "dei\u00b7nen", "sand\u00b7gen", "Fl\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Geist allein dein Acker und dein Pflug.", "tokens": ["Der", "Geist", "al\u00b7lein", "dein", "A\u00b7cker", "und", "dein", "Pflug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.61": {"line.1": {"text": "Als dich der leider Einzge deiner Fritze", "tokens": ["Als", "dich", "der", "lei\u00b7der", "Einz\u00b7ge", "dei\u00b7ner", "Frit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Zahl zum Trotz, hoch zu den Sternen trug,", "tokens": ["Der", "Zahl", "zum", "Trotz", ",", "hoch", "zu", "den", "Ster\u00b7nen", "trug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dacht er dich stets auch an der Bildung Spitze,", "tokens": ["Dacht", "er", "dich", "stets", "auch", "an", "der", "Bil\u00b7dung", "Spit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.4": {"text": "Stoff gegen Stoff, zerbricht der schw\u00e4chre Krug.", "tokens": ["Stoff", "ge\u00b7gen", "Stoff", ",", "zer\u00b7bricht", "der", "schw\u00e4ch\u00b7re", "Krug", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.62": {"line.1": {"text": "Und wars dein Volk nicht, das dich r\u00fcckerstritten,", "tokens": ["Und", "wars", "dein", "Volk", "nicht", ",", "das", "dich", "r\u00fc\u00b7cker\u00b7strit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "PTKNEG", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als du gestellt dich an des Abgrunds Bord?", "tokens": ["Als", "du", "ge\u00b7stellt", "dich", "an", "des", "Ab\u00b7grunds", "Bord", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Warum nun zittern in des Volkes Mitten,", "tokens": ["Wa\u00b7rum", "nun", "zit\u00b7tern", "in", "des", "Vol\u00b7kes", "Mit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Dasein betteln von dem eisgen Nord?", "tokens": ["Das", "Da\u00b7sein", "bet\u00b7teln", "von", "dem", "eis\u00b7gen", "Nord", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.63": {"line.1": {"text": "Lebst etwa du in der Erinnrung R\u00e4umen,", "tokens": ["Lebst", "et\u00b7wa", "du", "in", "der", "E\u00b7rinn\u00b7rung", "R\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.2": {"text": "Wie damals, als dein Junkerheer zerschmolz?", "tokens": ["Wie", "da\u00b7mals", ",", "als", "dein", "Jun\u00b7ker\u00b7heer", "zer\u00b7schmolz", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "KOUS", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein gleich Erwachen harret gleichen Tr\u00e4umen,", "tokens": ["Ein", "gleich", "Er\u00b7wa\u00b7chen", "har\u00b7ret", "glei\u00b7chen", "Tr\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Jena liegt, wo D\u00fcnkel steht und Stolz.", "tokens": ["Ein", "Je\u00b7na", "liegt", ",", "wo", "D\u00fcn\u00b7kel", "steht", "und", "Stolz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$,", "PWAV", "NN", "VVFIN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.64": {"line.1": {"text": "Sie aber h\u00f6ren nicht, sind nicht zu retten!", "tokens": ["Sie", "a\u00b7ber", "h\u00f6\u00b7ren", "nicht", ",", "sind", "nicht", "zu", "ret\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKNEG", "$,", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Niederung verm\u00e4hlt sich gern dem Sumpf;", "tokens": ["Die", "Nie\u00b7de\u00b7rung", "ver\u00b7m\u00e4hlt", "sich", "gern", "dem", "Sumpf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Barbarsche K\u00f6nige in goldnen Ketten,", "tokens": ["Bar\u00b7bar\u00b7sche", "K\u00f6\u00b7ni\u00b7ge", "in", "gold\u00b7nen", "Ket\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "D\u00fcnkt ihnen sch\u00f6n ein russischer Triumph.", "tokens": ["D\u00fcnkt", "ih\u00b7nen", "sch\u00f6n", "ein", "rus\u00b7si\u00b7scher", "Tri\u00b7umph", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.65": {"line.1": {"text": "Du aber, Freiheit, die der Fr\u00fchlingsmorgen", "tokens": ["Du", "a\u00b7ber", ",", "Frei\u00b7heit", ",", "die", "der", "Fr\u00fch\u00b7lings\u00b7mor\u00b7gen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "$,", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hervorrief aus dem eisumschlo\u00dfnen Grab,", "tokens": ["Her\u00b7vor\u00b7rief", "aus", "dem", "ei\u00b7sum\u00b7schlo\u00df\u00b7nen", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Sonne hat von neuem sich verborgen,", "tokens": ["Die", "Son\u00b7ne", "hat", "von", "neu\u00b7em", "sich", "ver\u00b7bor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ADJA", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Steig wieder nur zur kalten Gruft hinab.", "tokens": ["Steig", "wie\u00b7der", "nur", "zur", "kal\u00b7ten", "Gruft", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.66": {"line.1": {"text": "Doch h\u00fcte dich, zu fest, zu lang zu schlafen,", "tokens": ["Doch", "h\u00fc\u00b7te", "dich", ",", "zu", "fest", ",", "zu", "lang", "zu", "schla\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PTKA", "ADJD", "$,", "PTKA", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hat ja kein Winter ewig noch gethront,", "tokens": ["Hat", "ja", "kein", "Win\u00b7ter", "e\u00b7wig", "noch", "ge\u00b7thront", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn im Mai erst laue Strahlen trafen,", "tokens": ["Und", "wenn", "im", "Mai", "erst", "lau\u00b7e", "Strah\u00b7len", "tra\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPRART", "NN", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "K\u00f6mmt ", "tokens": ["K\u00f6mmt"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}}}}