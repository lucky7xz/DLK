{"textgrid.poem.57334": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wirke! Das ist das grosse Gesetz, in des Tempels", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wirke! Das ist das grosse Gesetz, in des Tempels", "tokens": ["Wir\u00b7ke", "!", "Das", "ist", "das", "gros\u00b7se", "Ge\u00b7setz", ",", "in", "des", "Tem\u00b7pels"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Tafel gehaun, dass es kund sey, und von Golde", "tokens": ["Ta\u00b7fel", "ge\u00b7haun", ",", "dass", "es", "kund", "sey", ",", "und", "von", "Gol\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVINF", "$,", "KOUS", "PPER", "PTKVZ", "VAFIN", "$,", "KON", "APPR", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "In den parischen Stein gesenket,", "tokens": ["In", "den", "pa\u00b7ri\u00b7schen", "Stein", "ge\u00b7sen\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie auf die Lilie wallt", "tokens": ["Wie", "auf", "die", "Li\u00b7lie", "wallt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Goldener Staub. Noch fassest du nicht des Gesetzes", "tokens": ["Gol\u00b7de\u00b7ner", "Staub", ".", "Noch", "fas\u00b7sest", "du", "nicht", "des", "Ge\u00b7set\u00b7zes"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "ADV", "VVFIN", "PPER", "PTKNEG", "ART", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Ganzen Verstand. Denn es steht war in der Halle", "tokens": ["Gan\u00b7zen", "Ver\u00b7stand", ".", "Denn", "es", "steht", "war", "in", "der", "Hal\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "$.", "KON", "PPER", "VVFIN", "VAFIN", "APPR", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nicht geschrieben, allein es fordert's", "tokens": ["Nicht", "ge\u00b7schrie\u00b7ben", ",", "al\u00b7lein", "es", "for\u00b7dert's"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "VVPP", "$,", "ADV", "PPER", "NE"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Also der heilige Sinn,", "tokens": ["Al\u00b7so", "der", "hei\u00b7li\u00b7ge", "Sinn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.3": {"line.1": {"text": "Also, durchdenk's arbeitend, durchdenk's, wenn du ausruhst:", "tokens": ["Al\u00b7so", ",", "durch\u00b7denk's", "ar\u00b7bei\u00b7tend", ",", "durch\u00b7denk's", ",", "wenn", "du", "aus\u00b7ruhst", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VVPP", "$,", "NE", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Gut sey, und stark, und es daure, was du wirkest!", "tokens": ["Gut", "sey", ",", "und", "stark", ",", "und", "es", "dau\u00b7re", ",", "was", "du", "wir\u00b7kest", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "KON", "ADJD", "$,", "KON", "PPER", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "\u00bbdaure?\u00ab Daure! da liegt's! weit wallst du", "tokens": ["\u00bb", "dau\u00b7re", "?", "\u00ab", "Dau\u00b7re", "!", "da", "liegt's", "!", "weit", "wallst", "du"], "token_info": ["punct", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "$.", "$(", "NE", "$.", "ADV", "VVFIN", "$.", "ADJD", "VVFIN", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Irre; verliest du dich da,", "tokens": ["Ir\u00b7re", ";", "ver\u00b7liest", "du", "dich", "da", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "PPER", "PRF", "ADV", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.4": {"line.1": {"text": "Wende! Da schied's durch Gr\u00e4nze sich ab; und der Gr\u00e4nzstein", "tokens": ["Wen\u00b7de", "!", "Da", "schie\u00b7d's", "durch", "Gr\u00e4n\u00b7ze", "sich", "ab", ";", "und", "der", "Gr\u00e4nz\u00b7stein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "ADV", "VVFIN", "APPR", "NN", "PRF", "PTKVZ", "$.", "KON", "ART", "NN"], "meter": "+--+--+--+--++", "measure": "dactylic.tetra.plus"}, "line.2": {"text": "Hub sich empor in die Wolken, unersteiglich", "tokens": ["Hub", "sich", "em\u00b7por", "in", "die", "Wol\u00b7ken", ",", "un\u00b7er\u00b7steig\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PRF", "PTKVZ", "APPR", "ART", "NN", "$,", "ADJD"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dem, der \u00e4msig allein f\u00fcr's Leben,", "tokens": ["Dem", ",", "der", "\u00e4m\u00b7sig", "al\u00b7lein", "f\u00fcr's", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ADJD", "ADV", "APPRART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Heissen Gesch\u00e4ften sich weiht.", "tokens": ["Heis\u00b7sen", "Ge\u00b7sch\u00e4f\u00b7ten", "sich", "weiht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PRF", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.5": {"line.1": {"text": "Einfluss der That, wenn jetzt sie geschieht! und nur wenig", "tokens": ["Ein\u00b7fluss", "der", "That", ",", "wenn", "jetzt", "sie", "ge\u00b7schieht", "!", "und", "nur", "we\u00b7nig"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "KOUS", "ADV", "PPER", "VVFIN", "$.", "KON", "ADV", "PIS"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wirkung bleibt nach, nur ein Schatten, so verschwindet.", "tokens": ["Wir\u00b7kung", "bleibt", "nach", ",", "nur", "ein", "Schat\u00b7ten", ",", "so", "ver\u00b7schwin\u00b7det", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "$,", "ADV", "ART", "NN", "$,", "ADV", "VVPP", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "\u00bbwenig?\u00ab z\u00fcrnst du. So w\u00e4hrt's was l\u00e4nger,", "tokens": ["\u00bb", "we\u00b7nig", "?", "\u00ab", "z\u00fcrnst", "du", ".", "So", "w\u00e4hrt's", "was", "l\u00e4n\u00b7ger", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "$.", "$(", "VVFIN", "PPER", "$.", "ADV", "APPR", "PRELS", "ADJD", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Bis sie gesunken verglimt.", "tokens": ["Bis", "sie", "ge\u00b7sun\u00b7ken", "ver\u00b7glimt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "Die du bewogst, thun Eignes hinzu, und zuletzt wird", "tokens": ["Die", "du", "be\u00b7wogst", ",", "thun", "Eig\u00b7nes", "hin\u00b7zu", ",", "und", "zu\u00b7letzt", "wird"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "$,", "VVFIN", "NN", "PTKVZ", "$,", "KON", "ADV", "VAFIN"], "meter": "-+-+-+--+-+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Dessen so viel, dass der Tropfen in dem Meere", "tokens": ["Des\u00b7sen", "so", "viel", ",", "dass", "der", "Trop\u00b7fen", "in", "dem", "Mee\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ADV", "$,", "KOUS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nun zerfliesset, vergeht. \u00bbVerginge?\u00ab", "tokens": ["Nun", "zer\u00b7flies\u00b7set", ",", "ver\u00b7geht", ".", "\u00bb", "Ver\u00b7gin\u00b7ge", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVFIN", "$.", "$(", "NN", "$.", "$("], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "In die Atome sich l\u00f6st.", "tokens": ["In", "die", "A\u00b7to\u00b7me", "sich", "l\u00f6st", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.7": {"line.1": {"text": "Nicht, dass dein Thun, verkenne mich nicht, mir nicht heilig", "tokens": ["Nicht", ",", "dass", "dein", "Thun", ",", "ver\u00b7ken\u00b7ne", "mich", "nicht", ",", "mir", "nicht", "hei\u00b7lig"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "$,", "KOUS", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "PTKNEG", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "W\u00e4re, vollf\u00fchrt's, wess auch andre sich erfreuen:", "tokens": ["W\u00e4\u00b7re", ",", "voll\u00b7f\u00fchrt's", ",", "wess", "auch", "and\u00b7re", "sich", "er\u00b7freu\u00b7en", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "NE", "$,", "VVFIN", "ADV", "PIS", "PRF", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Nicht ver\u00e4chtlich, wofern es dir nur", "tokens": ["Nicht", "ver\u00b7\u00e4cht\u00b7lich", ",", "wo\u00b7fern", "es", "dir", "nur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "$,", "KOUS", "PPER", "PPER", "ADV"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Frommet, verkenne mich nicht!", "tokens": ["From\u00b7met", ",", "ver\u00b7ken\u00b7ne", "mich", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.8": {"line.1": {"text": "K\u00f6nige sind weitwirkend, auch bleibt's, wie ein Abend", "tokens": ["K\u00f6\u00b7ni\u00b7ge", "sind", "weit\u00b7wir\u00b7kend", ",", "auch", "bleibt's", ",", "wie", "ein", "A\u00b7bend"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAFIN", "VVPP", "$,", "ADV", "VVFIN", "$,", "PWAV", "ART", "NN"], "meter": "+---++--+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Schatten; und doch muss auch dieser sich verlieren!", "tokens": ["Schat\u00b7ten", ";", "und", "doch", "muss", "auch", "die\u00b7ser", "sich", "ver\u00b7lie\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "ADV", "VMFIN", "ADV", "PDAT", "PRF", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Ach die Handlung sinkt hin, und klimt nicht", "tokens": ["Ach", "die", "Hand\u00b7lung", "sinkt", "hin", ",", "und", "klimt", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "PTKNEG"], "meter": "+-+-+-++-", "measure": "unknown.measure.penta"}, "line.4": {"text": "\u00dcber der Sonderung Stein.", "tokens": ["\u00dc\u00b7ber", "der", "Son\u00b7de\u00b7rung", "Stein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.9": {"line.1": {"text": "Geist des Gesangs, was rufest du mir, und gebietest", "tokens": ["Geist", "des", "Ge\u00b7sangs", ",", "was", "ru\u00b7fest", "du", "mir", ",", "und", "ge\u00b7bie\u00b7test"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "PWS", "VVFIN", "PPER", "PPER", "$,", "KON", "VVFIN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Anderen Ton? O du kennest noch nicht ganz dich!", "tokens": ["An\u00b7de\u00b7ren", "Ton", "?", "O", "du", "ken\u00b7nest", "noch", "nicht", "ganz", "dich", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "NE", "NE", "VVFIN", "ADV", "PTKNEG", "ADV", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bey Amphion! auch diese Saite", "tokens": ["Bey", "Am\u00b7phi\u00b7on", "!", "auch", "die\u00b7se", "Sai\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "$.", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Stimte der Grieche f\u00fcr's Herz.", "tokens": ["Stim\u00b7te", "der", "Grie\u00b7che", "f\u00fcr's", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.10": {"line.1": {"text": "K\u00f6nige sind weitwirkend, auch bleibt's, wie ein Abend", "tokens": ["K\u00f6\u00b7ni\u00b7ge", "sind", "weit\u00b7wir\u00b7kend", ",", "auch", "bleibt's", ",", "wie", "ein", "A\u00b7bend"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAFIN", "VVPP", "$,", "ADV", "VVFIN", "$,", "PWAV", "ART", "NN"], "meter": "+---++--+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Schatten; und doch muss auch dieser sich verlieren!", "tokens": ["Schat\u00b7ten", ";", "und", "doch", "muss", "auch", "die\u00b7ser", "sich", "ver\u00b7lie\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "ADV", "VMFIN", "ADV", "PDAT", "PRF", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Ach die Handlung sinkt hin, und klimt nicht", "tokens": ["Ach", "die", "Hand\u00b7lung", "sinkt", "hin", ",", "und", "klimt", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "PTKNEG"], "meter": "+-+-+-++-", "measure": "unknown.measure.penta"}, "line.4": {"text": "\u00dcber der Sonderung Stein.", "tokens": ["\u00dc\u00b7ber", "der", "Son\u00b7de\u00b7rung", "Stein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.11": {"line.1": {"text": "Aber wenn, wem die Sterblichkeit ruft, noch, was wirket,", "tokens": ["A\u00b7ber", "wenn", ",", "wem", "die", "Sterb\u00b7lich\u00b7keit", "ruft", ",", "noch", ",", "was", "wir\u00b7ket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "PWS", "ART", "NN", "VVFIN", "$,", "ADV", "$,", "PWS", "VVFIN", "$,"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Hinter sich l\u00e4sst, noch ein Denken in des Geistes", "tokens": ["Hin\u00b7ter", "sich", "l\u00e4sst", ",", "noch", "ein", "Den\u00b7ken", "in", "des", "Geis\u00b7tes"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRF", "VVFIN", "$,", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Werken, welches von Kraft, von Gutem", "tokens": ["Wer\u00b7ken", ",", "wel\u00b7ches", "von", "Kraft", ",", "von", "Gu\u00b7tem"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "NN", "$,", "APPR", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Voll, wo es waltet, uns h\u00e4lt:", "tokens": ["Voll", ",", "wo", "es", "wal\u00b7tet", ",", "uns", "h\u00e4lt", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.12": {"line.1": {"text": "Jenseit ist das der H\u00f6he, die gr\u00e4nzt. Was es wirkte,", "tokens": ["Jen\u00b7seit", "ist", "das", "der", "H\u00f6\u00b7he", ",", "die", "gr\u00e4nzt", ".", "Was", "es", "wirk\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ART", "NN", "$,", "PRELS", "ADJD", "$.", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+++-+-", "measure": "unknown.measure.septa"}, "line.2": {"text": "Wirket es stets, wie im Anfang, so von neuem:", "tokens": ["Wir\u00b7ket", "es", "stets", ",", "wie", "im", "An\u00b7fang", ",", "so", "von", "neu\u00b7em", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWAV", "APPRART", "NN", "$,", "ADV", "APPR", "ADJA", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Jahre fliehn; und es str\u00f6mt sein Einfluss,", "tokens": ["Jah\u00b7re", "fliehn", ";", "und", "es", "str\u00f6mt", "sein", "Ein\u00b7fluss", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$.", "KON", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wie der Beginn sich ergoss.", "tokens": ["Wie", "der", "Be\u00b7ginn", "sich", "er\u00b7goss", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.13": {"line.1": {"text": "Da ist das Werk! und t\u00f6net nicht bloss, wie vollbrachte", "tokens": ["Da", "ist", "das", "Werk", "!", "und", "t\u00f6\u00b7net", "nicht", "bloss", ",", "wie", "voll\u00b7brach\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$.", "KON", "VVFIN", "PTKNEG", "ADV", "$,", "PWAV", "ADJA"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Handlungen, nach. Wenn von diesen bis zum fernsten", "tokens": ["Hand\u00b7lun\u00b7gen", ",", "nach", ".", "Wenn", "von", "die\u00b7sen", "bis", "zum", "ferns\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "$.", "KOUS", "APPR", "PDAT", "APPR", "APPRART", "ADJA"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Hall sich jede verlor, zum letzten", "tokens": ["Hall", "sich", "je\u00b7de", "ver\u00b7lor", ",", "zum", "letz\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "PRF", "PIAT", "VVFIN", "$,", "APPRART", "ADJA"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Lispel sich; redet es laut!", "tokens": ["Lis\u00b7pel", "sich", ";", "re\u00b7det", "es", "laut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "$.", "VVFIN", "PPER", "ADJD", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.14": {"line.1": {"text": "Nutzet, doch nicht, wie einst das Gesch\u00e4ft, nur an Einer", "tokens": ["Nut\u00b7zet", ",", "doch", "nicht", ",", "wie", "einst", "das", "Ge\u00b7sch\u00e4ft", ",", "nur", "an", "Ei\u00b7ner"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "PTKNEG", "$,", "PWAV", "ADV", "ART", "NN", "$,", "ADV", "APPR", "PIS"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "St\u00e4te, zugleich an so vielen, als getrente", "tokens": ["St\u00e4\u00b7te", ",", "zu\u00b7gleich", "an", "so", "vie\u00b7len", ",", "als", "ge\u00b7tren\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "ADV", "APPR", "ADV", "PIAT", "$,", "KOUS", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Sich's, nach M\u00fche, nach Lust, zu ihrer.", "tokens": ["Sich's", ",", "nach", "M\u00fc\u00b7he", ",", "nach", "Lust", ",", "zu", "ih\u00b7rer", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "NN", "$,", "APPR", "NN", "$,", "APPR", "PPOSAT", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Musse Gef\u00e4hrten ersehn.", "tokens": ["Mus\u00b7se", "Ge\u00b7f\u00e4hr\u00b7ten", "er\u00b7sehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVINF", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.15": {"line.1": {"text": "R\u00fchrt es, und wird die R\u00fchrung zu That; so durchwallt die", "tokens": ["R\u00fchrt", "es", ",", "und", "wird", "die", "R\u00fch\u00b7rung", "zu", "That", ";", "so", "durch\u00b7wallt", "die"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KON", "VAFIN", "ART", "NN", "APPR", "NN", "$.", "ADV", "VVFIN", "ART"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "\u00c4hnlichen Pfad mit der andern, die dem eignen", "tokens": ["\u00c4hn\u00b7li\u00b7chen", "Pfad", "mit", "der", "an\u00b7dern", ",", "die", "dem", "eig\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "ART", "ADJA", "$,", "PRELS", "ART", "ADJA"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Quell entfloss. Und gelingt nicht diese", "tokens": ["Quell", "ent\u00b7floss", ".", "Und", "ge\u00b7lingt", "nicht", "die\u00b7se"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "$.", "KON", "VVFIN", "PTKNEG", "PDAT"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "R\u00fchrung dem bleibenden oft?", "tokens": ["R\u00fch\u00b7rung", "dem", "blei\u00b7ben\u00b7den", "oft", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "ADV", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.16": {"line.1": {"text": "Wirke! Das ist das grosse Gesetz, in der Halle", "tokens": ["Wir\u00b7ke", "!", "Das", "ist", "das", "gros\u00b7se", "Ge\u00b7setz", ",", "in", "der", "Hal\u00b7le"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Marmor gehaun, dass es kund sey; und die Dauer", "tokens": ["Mar\u00b7mor", "ge\u00b7haun", ",", "dass", "es", "kund", "sey", ";", "und", "die", "Dau\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVINF", "$,", "KOUS", "PPER", "PTKVZ", "VAFIN", "$.", "KON", "ART", "NN"], "meter": "+--+--++--+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Liest der weisere mit, als st\u00fcnd' es", "tokens": ["Liest", "der", "wei\u00b7se\u00b7re", "mit", ",", "als", "st\u00fcnd'", "es"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "PTKVZ", "$,", "KOUS", "VVFIN", "PPER"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Goldenes Gusses mit da.", "tokens": ["Gol\u00b7de\u00b7nes", "Gus\u00b7ses", "mit", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADV", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.17": {"line.1": {"text": "Frey ist der Flug der Ode, sie kieset, wonach sie", "tokens": ["Frey", "ist", "der", "Flug", "der", "O\u00b7de", ",", "sie", "kie\u00b7set", ",", "wo\u00b7nach", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN", "ART", "NN", "$,", "PPER", "VVFIN", "$,", "PWAV", "PPER"], "meter": "-+-+-+--++-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "L\u00fcstet, und singt's. Was verbeut ihr, dass sie leise", "tokens": ["L\u00fcs\u00b7tet", ",", "und", "singt'", "s.", "Was", "ver\u00b7beut", "ihr", ",", "dass", "sie", "lei\u00b7se"], "token_info": ["word", "punct", "word", "word", "abbreviation", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "KON", "VVFIN", "NE", "PWS", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADJD"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Schwebe, wenn sie der Schwung, der hoch jetzt", "tokens": ["Schwe\u00b7be", ",", "wenn", "sie", "der", "Schwung", ",", "der", "hoch", "jetzt"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "ART", "NN", "$,", "PRELS", "ADJD", "ADV"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Steiget, itzt h\u00f6her, nicht freut.", "tokens": ["Stei\u00b7get", ",", "itzt", "h\u00f6\u00b7her", ",", "nicht", "freut", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ADJD", "$,", "PTKNEG", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.18": {"line.1": {"text": "Wirke! Das ist das grosse Gesetz, in des Tempels", "tokens": ["Wir\u00b7ke", "!", "Das", "ist", "das", "gros\u00b7se", "Ge\u00b7setz", ",", "in", "des", "Tem\u00b7pels"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Tafel gehaun, dass es kund sey, und von Golde", "tokens": ["Ta\u00b7fel", "ge\u00b7haun", ",", "dass", "es", "kund", "sey", ",", "und", "von", "Gol\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVINF", "$,", "KOUS", "PPER", "PTKVZ", "VAFIN", "$,", "KON", "APPR", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "In den parischen Stein gesenket,", "tokens": ["In", "den", "pa\u00b7ri\u00b7schen", "Stein", "ge\u00b7sen\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie auf die Lilie wallt", "tokens": ["Wie", "auf", "die", "Li\u00b7lie", "wallt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Goldener Staub. Noch fassest du nicht des Gesetzes", "tokens": ["Gol\u00b7de\u00b7ner", "Staub", ".", "Noch", "fas\u00b7sest", "du", "nicht", "des", "Ge\u00b7set\u00b7zes"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "ADV", "VVFIN", "PPER", "PTKNEG", "ART", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Ganzen Verstand. Denn es steht war in der Halle", "tokens": ["Gan\u00b7zen", "Ver\u00b7stand", ".", "Denn", "es", "steht", "war", "in", "der", "Hal\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "$.", "KON", "PPER", "VVFIN", "VAFIN", "APPR", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nicht geschrieben, allein es fordert's", "tokens": ["Nicht", "ge\u00b7schrie\u00b7ben", ",", "al\u00b7lein", "es", "for\u00b7dert's"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "VVPP", "$,", "ADV", "PPER", "NE"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Also der heilige Sinn,", "tokens": ["Al\u00b7so", "der", "hei\u00b7li\u00b7ge", "Sinn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.20": {"line.1": {"text": "Also, durchdenk's arbeitend, durchdenk's, wenn du ausruhst:", "tokens": ["Al\u00b7so", ",", "durch\u00b7denk's", "ar\u00b7bei\u00b7tend", ",", "durch\u00b7denk's", ",", "wenn", "du", "aus\u00b7ruhst", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VVPP", "$,", "NE", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Gut sey, und stark, und es daure, was du wirkest!", "tokens": ["Gut", "sey", ",", "und", "stark", ",", "und", "es", "dau\u00b7re", ",", "was", "du", "wir\u00b7kest", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "KON", "ADJD", "$,", "KON", "PPER", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "\u00bbdaure?\u00ab Daure! da liegt's! weit wallst du", "tokens": ["\u00bb", "dau\u00b7re", "?", "\u00ab", "Dau\u00b7re", "!", "da", "liegt's", "!", "weit", "wallst", "du"], "token_info": ["punct", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "$.", "$(", "NE", "$.", "ADV", "VVFIN", "$.", "ADJD", "VVFIN", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Irre; verliest du dich da,", "tokens": ["Ir\u00b7re", ";", "ver\u00b7liest", "du", "dich", "da", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "PPER", "PRF", "ADV", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.21": {"line.1": {"text": "Wende! Da schied's durch Gr\u00e4nze sich ab; und der Gr\u00e4nzstein", "tokens": ["Wen\u00b7de", "!", "Da", "schie\u00b7d's", "durch", "Gr\u00e4n\u00b7ze", "sich", "ab", ";", "und", "der", "Gr\u00e4nz\u00b7stein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "ADV", "VVFIN", "APPR", "NN", "PRF", "PTKVZ", "$.", "KON", "ART", "NN"], "meter": "+--+--+--+--++", "measure": "dactylic.tetra.plus"}, "line.2": {"text": "Hub sich empor in die Wolken, unersteiglich", "tokens": ["Hub", "sich", "em\u00b7por", "in", "die", "Wol\u00b7ken", ",", "un\u00b7er\u00b7steig\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PRF", "PTKVZ", "APPR", "ART", "NN", "$,", "ADJD"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dem, der \u00e4msig allein f\u00fcr's Leben,", "tokens": ["Dem", ",", "der", "\u00e4m\u00b7sig", "al\u00b7lein", "f\u00fcr's", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ADJD", "ADV", "APPRART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Heissen Gesch\u00e4ften sich weiht.", "tokens": ["Heis\u00b7sen", "Ge\u00b7sch\u00e4f\u00b7ten", "sich", "weiht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PRF", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.22": {"line.1": {"text": "Einfluss der That, wenn jetzt sie geschieht! und nur wenig", "tokens": ["Ein\u00b7fluss", "der", "That", ",", "wenn", "jetzt", "sie", "ge\u00b7schieht", "!", "und", "nur", "we\u00b7nig"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "KOUS", "ADV", "PPER", "VVFIN", "$.", "KON", "ADV", "PIS"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wirkung bleibt nach, nur ein Schatten, so verschwindet.", "tokens": ["Wir\u00b7kung", "bleibt", "nach", ",", "nur", "ein", "Schat\u00b7ten", ",", "so", "ver\u00b7schwin\u00b7det", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "$,", "ADV", "ART", "NN", "$,", "ADV", "VVPP", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "\u00bbwenig?\u00ab z\u00fcrnst du. So w\u00e4hrt's was l\u00e4nger,", "tokens": ["\u00bb", "we\u00b7nig", "?", "\u00ab", "z\u00fcrnst", "du", ".", "So", "w\u00e4hrt's", "was", "l\u00e4n\u00b7ger", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "$.", "$(", "VVFIN", "PPER", "$.", "ADV", "APPR", "PRELS", "ADJD", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Bis sie gesunken verglimt.", "tokens": ["Bis", "sie", "ge\u00b7sun\u00b7ken", "ver\u00b7glimt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.23": {"line.1": {"text": "Die du bewogst, thun Eignes hinzu, und zuletzt wird", "tokens": ["Die", "du", "be\u00b7wogst", ",", "thun", "Eig\u00b7nes", "hin\u00b7zu", ",", "und", "zu\u00b7letzt", "wird"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "$,", "VVFIN", "NN", "PTKVZ", "$,", "KON", "ADV", "VAFIN"], "meter": "-+-+-+--+-+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Dessen so viel, dass der Tropfen in dem Meere", "tokens": ["Des\u00b7sen", "so", "viel", ",", "dass", "der", "Trop\u00b7fen", "in", "dem", "Mee\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ADV", "$,", "KOUS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nun zerfliesset, vergeht. \u00bbVerginge?\u00ab", "tokens": ["Nun", "zer\u00b7flies\u00b7set", ",", "ver\u00b7geht", ".", "\u00bb", "Ver\u00b7gin\u00b7ge", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVFIN", "$.", "$(", "NN", "$.", "$("], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "In die Atome sich l\u00f6st.", "tokens": ["In", "die", "A\u00b7to\u00b7me", "sich", "l\u00f6st", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.24": {"line.1": {"text": "Nicht, dass dein Thun, verkenne mich nicht, mir nicht heilig", "tokens": ["Nicht", ",", "dass", "dein", "Thun", ",", "ver\u00b7ken\u00b7ne", "mich", "nicht", ",", "mir", "nicht", "hei\u00b7lig"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "$,", "KOUS", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "PTKNEG", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "W\u00e4re, vollf\u00fchrt's, wess auch andre sich erfreuen:", "tokens": ["W\u00e4\u00b7re", ",", "voll\u00b7f\u00fchrt's", ",", "wess", "auch", "and\u00b7re", "sich", "er\u00b7freu\u00b7en", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "NE", "$,", "VVFIN", "ADV", "PIS", "PRF", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Nicht ver\u00e4chtlich, wofern es dir nur", "tokens": ["Nicht", "ver\u00b7\u00e4cht\u00b7lich", ",", "wo\u00b7fern", "es", "dir", "nur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "$,", "KOUS", "PPER", "PPER", "ADV"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Frommet, verkenne mich nicht!", "tokens": ["From\u00b7met", ",", "ver\u00b7ken\u00b7ne", "mich", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.25": {"line.1": {"text": "K\u00f6nige sind weitwirkend, auch bleibt's, wie ein Abend", "tokens": ["K\u00f6\u00b7ni\u00b7ge", "sind", "weit\u00b7wir\u00b7kend", ",", "auch", "bleibt's", ",", "wie", "ein", "A\u00b7bend"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAFIN", "VVPP", "$,", "ADV", "VVFIN", "$,", "PWAV", "ART", "NN"], "meter": "+---++--+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Schatten; und doch muss auch dieser sich verlieren!", "tokens": ["Schat\u00b7ten", ";", "und", "doch", "muss", "auch", "die\u00b7ser", "sich", "ver\u00b7lie\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "ADV", "VMFIN", "ADV", "PDAT", "PRF", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Ach die Handlung sinkt hin, und klimt nicht", "tokens": ["Ach", "die", "Hand\u00b7lung", "sinkt", "hin", ",", "und", "klimt", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "PTKNEG"], "meter": "+-+-+-++-", "measure": "unknown.measure.penta"}, "line.4": {"text": "\u00dcber der Sonderung Stein.", "tokens": ["\u00dc\u00b7ber", "der", "Son\u00b7de\u00b7rung", "Stein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.26": {"line.1": {"text": "Geist des Gesangs, was rufest du mir, und gebietest", "tokens": ["Geist", "des", "Ge\u00b7sangs", ",", "was", "ru\u00b7fest", "du", "mir", ",", "und", "ge\u00b7bie\u00b7test"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "PWS", "VVFIN", "PPER", "PPER", "$,", "KON", "VVFIN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Anderen Ton? O du kennest noch nicht ganz dich!", "tokens": ["An\u00b7de\u00b7ren", "Ton", "?", "O", "du", "ken\u00b7nest", "noch", "nicht", "ganz", "dich", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "NE", "NE", "VVFIN", "ADV", "PTKNEG", "ADV", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bey Amphion! auch diese Saite", "tokens": ["Bey", "Am\u00b7phi\u00b7on", "!", "auch", "die\u00b7se", "Sai\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "$.", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Stimte der Grieche f\u00fcr's Herz.", "tokens": ["Stim\u00b7te", "der", "Grie\u00b7che", "f\u00fcr's", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.27": {"line.1": {"text": "K\u00f6nige sind weitwirkend, auch bleibt's, wie ein Abend", "tokens": ["K\u00f6\u00b7ni\u00b7ge", "sind", "weit\u00b7wir\u00b7kend", ",", "auch", "bleibt's", ",", "wie", "ein", "A\u00b7bend"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAFIN", "VVPP", "$,", "ADV", "VVFIN", "$,", "PWAV", "ART", "NN"], "meter": "+---++--+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Schatten; und doch muss auch dieser sich verlieren!", "tokens": ["Schat\u00b7ten", ";", "und", "doch", "muss", "auch", "die\u00b7ser", "sich", "ver\u00b7lie\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "ADV", "VMFIN", "ADV", "PDAT", "PRF", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Ach die Handlung sinkt hin, und klimt nicht", "tokens": ["Ach", "die", "Hand\u00b7lung", "sinkt", "hin", ",", "und", "klimt", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "PTKNEG"], "meter": "+-+-+-++-", "measure": "unknown.measure.penta"}, "line.4": {"text": "\u00dcber der Sonderung Stein.", "tokens": ["\u00dc\u00b7ber", "der", "Son\u00b7de\u00b7rung", "Stein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.28": {"line.1": {"text": "Aber wenn, wem die Sterblichkeit ruft, noch, was wirket,", "tokens": ["A\u00b7ber", "wenn", ",", "wem", "die", "Sterb\u00b7lich\u00b7keit", "ruft", ",", "noch", ",", "was", "wir\u00b7ket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "PWS", "ART", "NN", "VVFIN", "$,", "ADV", "$,", "PWS", "VVFIN", "$,"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Hinter sich l\u00e4sst, noch ein Denken in des Geistes", "tokens": ["Hin\u00b7ter", "sich", "l\u00e4sst", ",", "noch", "ein", "Den\u00b7ken", "in", "des", "Geis\u00b7tes"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRF", "VVFIN", "$,", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Werken, welches von Kraft, von Gutem", "tokens": ["Wer\u00b7ken", ",", "wel\u00b7ches", "von", "Kraft", ",", "von", "Gu\u00b7tem"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "NN", "$,", "APPR", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Voll, wo es waltet, uns h\u00e4lt:", "tokens": ["Voll", ",", "wo", "es", "wal\u00b7tet", ",", "uns", "h\u00e4lt", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.29": {"line.1": {"text": "Jenseit ist das der H\u00f6he, die gr\u00e4nzt. Was es wirkte,", "tokens": ["Jen\u00b7seit", "ist", "das", "der", "H\u00f6\u00b7he", ",", "die", "gr\u00e4nzt", ".", "Was", "es", "wirk\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ART", "NN", "$,", "PRELS", "ADJD", "$.", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+++-+-", "measure": "unknown.measure.septa"}, "line.2": {"text": "Wirket es stets, wie im Anfang, so von neuem:", "tokens": ["Wir\u00b7ket", "es", "stets", ",", "wie", "im", "An\u00b7fang", ",", "so", "von", "neu\u00b7em", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWAV", "APPRART", "NN", "$,", "ADV", "APPR", "ADJA", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Jahre fliehn; und es str\u00f6mt sein Einfluss,", "tokens": ["Jah\u00b7re", "fliehn", ";", "und", "es", "str\u00f6mt", "sein", "Ein\u00b7fluss", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$.", "KON", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wie der Beginn sich ergoss.", "tokens": ["Wie", "der", "Be\u00b7ginn", "sich", "er\u00b7goss", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.30": {"line.1": {"text": "Da ist das Werk! und t\u00f6net nicht bloss, wie vollbrachte", "tokens": ["Da", "ist", "das", "Werk", "!", "und", "t\u00f6\u00b7net", "nicht", "bloss", ",", "wie", "voll\u00b7brach\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$.", "KON", "VVFIN", "PTKNEG", "ADV", "$,", "PWAV", "ADJA"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Handlungen, nach. Wenn von diesen bis zum fernsten", "tokens": ["Hand\u00b7lun\u00b7gen", ",", "nach", ".", "Wenn", "von", "die\u00b7sen", "bis", "zum", "ferns\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "$.", "KOUS", "APPR", "PDAT", "APPR", "APPRART", "ADJA"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Hall sich jede verlor, zum letzten", "tokens": ["Hall", "sich", "je\u00b7de", "ver\u00b7lor", ",", "zum", "letz\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "PRF", "PIAT", "VVFIN", "$,", "APPRART", "ADJA"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Lispel sich; redet es laut!", "tokens": ["Lis\u00b7pel", "sich", ";", "re\u00b7det", "es", "laut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "$.", "VVFIN", "PPER", "ADJD", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.31": {"line.1": {"text": "Nutzet, doch nicht, wie einst das Gesch\u00e4ft, nur an Einer", "tokens": ["Nut\u00b7zet", ",", "doch", "nicht", ",", "wie", "einst", "das", "Ge\u00b7sch\u00e4ft", ",", "nur", "an", "Ei\u00b7ner"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "PTKNEG", "$,", "PWAV", "ADV", "ART", "NN", "$,", "ADV", "APPR", "PIS"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "St\u00e4te, zugleich an so vielen, als getrente", "tokens": ["St\u00e4\u00b7te", ",", "zu\u00b7gleich", "an", "so", "vie\u00b7len", ",", "als", "ge\u00b7tren\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "ADV", "APPR", "ADV", "PIAT", "$,", "KOUS", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Sich's, nach M\u00fche, nach Lust, zu ihrer.", "tokens": ["Sich's", ",", "nach", "M\u00fc\u00b7he", ",", "nach", "Lust", ",", "zu", "ih\u00b7rer", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "NN", "$,", "APPR", "NN", "$,", "APPR", "PPOSAT", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Musse Gef\u00e4hrten ersehn.", "tokens": ["Mus\u00b7se", "Ge\u00b7f\u00e4hr\u00b7ten", "er\u00b7sehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVINF", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.32": {"line.1": {"text": "R\u00fchrt es, und wird die R\u00fchrung zu That; so durchwallt die", "tokens": ["R\u00fchrt", "es", ",", "und", "wird", "die", "R\u00fch\u00b7rung", "zu", "That", ";", "so", "durch\u00b7wallt", "die"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KON", "VAFIN", "ART", "NN", "APPR", "NN", "$.", "ADV", "VVFIN", "ART"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "\u00c4hnlichen Pfad mit der andern, die dem eignen", "tokens": ["\u00c4hn\u00b7li\u00b7chen", "Pfad", "mit", "der", "an\u00b7dern", ",", "die", "dem", "eig\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "ART", "ADJA", "$,", "PRELS", "ART", "ADJA"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Quell entfloss. Und gelingt nicht diese", "tokens": ["Quell", "ent\u00b7floss", ".", "Und", "ge\u00b7lingt", "nicht", "die\u00b7se"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "$.", "KON", "VVFIN", "PTKNEG", "PDAT"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "R\u00fchrung dem bleibenden oft?", "tokens": ["R\u00fch\u00b7rung", "dem", "blei\u00b7ben\u00b7den", "oft", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "ADV", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.33": {"line.1": {"text": "Wirke! Das ist das grosse Gesetz, in der Halle", "tokens": ["Wir\u00b7ke", "!", "Das", "ist", "das", "gros\u00b7se", "Ge\u00b7setz", ",", "in", "der", "Hal\u00b7le"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Marmor gehaun, dass es kund sey; und die Dauer", "tokens": ["Mar\u00b7mor", "ge\u00b7haun", ",", "dass", "es", "kund", "sey", ";", "und", "die", "Dau\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVINF", "$,", "KOUS", "PPER", "PTKVZ", "VAFIN", "$.", "KON", "ART", "NN"], "meter": "+--+--++--+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Liest der weisere mit, als st\u00fcnd' es", "tokens": ["Liest", "der", "wei\u00b7se\u00b7re", "mit", ",", "als", "st\u00fcnd'", "es"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "PTKVZ", "$,", "KOUS", "VVFIN", "PPER"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Goldenes Gusses mit da.", "tokens": ["Gol\u00b7de\u00b7nes", "Gus\u00b7ses", "mit", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADV", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.34": {"line.1": {"text": "Frey ist der Flug der Ode, sie kieset, wonach sie", "tokens": ["Frey", "ist", "der", "Flug", "der", "O\u00b7de", ",", "sie", "kie\u00b7set", ",", "wo\u00b7nach", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN", "ART", "NN", "$,", "PPER", "VVFIN", "$,", "PWAV", "PPER"], "meter": "-+-+-+--++-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "L\u00fcstet, und singt's. Was verbeut ihr, dass sie leise", "tokens": ["L\u00fcs\u00b7tet", ",", "und", "singt'", "s.", "Was", "ver\u00b7beut", "ihr", ",", "dass", "sie", "lei\u00b7se"], "token_info": ["word", "punct", "word", "word", "abbreviation", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "KON", "VVFIN", "NE", "PWS", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADJD"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Schwebe, wenn sie der Schwung, der hoch jetzt", "tokens": ["Schwe\u00b7be", ",", "wenn", "sie", "der", "Schwung", ",", "der", "hoch", "jetzt"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "ART", "NN", "$,", "PRELS", "ADJD", "ADV"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Steiget, itzt h\u00f6her, nicht freut.", "tokens": ["Stei\u00b7get", ",", "itzt", "h\u00f6\u00b7her", ",", "nicht", "freut", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ADJD", "$,", "PTKNEG", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}}}}