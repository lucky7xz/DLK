{"textgrid.poem.39178": {"metadata": {"author": {"name": "Strachwitz, Moritz von", "birth": "N.A.", "death": "N.A."}, "title": "[ihr, die Ihr schwatzt von Winkeln, Polygonen]", "genre": "verse", "period": "N.A.", "pub_year": 1834, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr, die Ihr schwatzt von Winkeln, Polygonen", "tokens": ["Ihr", ",", "die", "Ihr", "schwatzt", "von", "Win\u00b7keln", ",", "Po\u00b7ly\u00b7go\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "$,", "PRELS", "PPER", "VVFIN", "APPR", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und regelrechten Parallelogrammen,", "tokens": ["Und", "re\u00b7gel\u00b7rech\u00b7ten", "Par\u00b7al\u00b7le\u00b7lo\u00b7gram\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Ihr berechnet des Gedankens Flammen", "tokens": ["Die", "Ihr", "be\u00b7rech\u00b7net", "des", "Ge\u00b7dan\u00b7kens", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nach mathematischen Dimensionen;", "tokens": ["Nach", "ma\u00b7the\u00b7ma\u00b7ti\u00b7schen", "Di\u00b7men\u00b7si\u00b7o\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "---+--+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Die Ihr festnagelt alle Himmelszonen", "tokens": ["Die", "Ihr", "fest\u00b7na\u00b7gelt", "al\u00b7le", "Him\u00b7mels\u00b7zo\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und abdrescht in Brosch\u00fcren und Programmen:", "tokens": ["Und", "ab\u00b7drescht", "in", "Bro\u00b7sch\u00fc\u00b7ren", "und", "Pro\u00b7gram\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So zirkelt fort und baut und brecht zusammen,", "tokens": ["So", "zir\u00b7kelt", "fort", "und", "baut", "und", "brecht", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "KON", "VVFIN", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nur m\u00f6gt Ihr mich mit Eurem Quark verschonen.", "tokens": ["Nur", "m\u00f6gt", "Ihr", "mich", "mit", "Eu\u00b7rem", "Quark", "ver\u00b7scho\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ich kann mich einmal nicht daran gew\u00f6hnen,", "tokens": ["Ich", "kann", "mich", "ein\u00b7mal", "nicht", "da\u00b7ran", "ge\u00b7w\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich will mich einmal nicht damit befassen:", "tokens": ["Ich", "will", "mich", "ein\u00b7mal", "nicht", "da\u00b7mit", "be\u00b7fas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was will die Zahl in meinen wilden T\u00f6nen?", "tokens": ["Was", "will", "die", "Zahl", "in", "mei\u00b7nen", "wil\u00b7den", "T\u00f6\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Stets werd' ich Eure eck'gen Formen hassen", "tokens": ["Stets", "werd'", "ich", "Eu\u00b7re", "eck'\u00b7gen", "For\u00b7men", "has\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und regellos im Labyrinth des Sch\u00f6nen", "tokens": ["Und", "re\u00b7gel\u00b7los", "im", "La\u00b7by\u00b7rinth", "des", "Sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mich ohne Faden freudig gehen lassen.", "tokens": ["Mich", "oh\u00b7ne", "Fa\u00b7den", "freu\u00b7dig", "ge\u00b7hen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ihr, die Ihr schwatzt von Winkeln, Polygonen", "tokens": ["Ihr", ",", "die", "Ihr", "schwatzt", "von", "Win\u00b7keln", ",", "Po\u00b7ly\u00b7go\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "$,", "PRELS", "PPER", "VVFIN", "APPR", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und regelrechten Parallelogrammen,", "tokens": ["Und", "re\u00b7gel\u00b7rech\u00b7ten", "Par\u00b7al\u00b7le\u00b7lo\u00b7gram\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Ihr berechnet des Gedankens Flammen", "tokens": ["Die", "Ihr", "be\u00b7rech\u00b7net", "des", "Ge\u00b7dan\u00b7kens", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nach mathematischen Dimensionen;", "tokens": ["Nach", "ma\u00b7the\u00b7ma\u00b7ti\u00b7schen", "Di\u00b7men\u00b7si\u00b7o\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "---+--+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Die Ihr festnagelt alle Himmelszonen", "tokens": ["Die", "Ihr", "fest\u00b7na\u00b7gelt", "al\u00b7le", "Him\u00b7mels\u00b7zo\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und abdrescht in Brosch\u00fcren und Programmen:", "tokens": ["Und", "ab\u00b7drescht", "in", "Bro\u00b7sch\u00fc\u00b7ren", "und", "Pro\u00b7gram\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So zirkelt fort und baut und brecht zusammen,", "tokens": ["So", "zir\u00b7kelt", "fort", "und", "baut", "und", "brecht", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "KON", "VVFIN", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nur m\u00f6gt Ihr mich mit Eurem Quark verschonen.", "tokens": ["Nur", "m\u00f6gt", "Ihr", "mich", "mit", "Eu\u00b7rem", "Quark", "ver\u00b7scho\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Ich kann mich einmal nicht daran gew\u00f6hnen,", "tokens": ["Ich", "kann", "mich", "ein\u00b7mal", "nicht", "da\u00b7ran", "ge\u00b7w\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich will mich einmal nicht damit befassen:", "tokens": ["Ich", "will", "mich", "ein\u00b7mal", "nicht", "da\u00b7mit", "be\u00b7fas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was will die Zahl in meinen wilden T\u00f6nen?", "tokens": ["Was", "will", "die", "Zahl", "in", "mei\u00b7nen", "wil\u00b7den", "T\u00f6\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Stets werd' ich Eure eck'gen Formen hassen", "tokens": ["Stets", "werd'", "ich", "Eu\u00b7re", "eck'\u00b7gen", "For\u00b7men", "has\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und regellos im Labyrinth des Sch\u00f6nen", "tokens": ["Und", "re\u00b7gel\u00b7los", "im", "La\u00b7by\u00b7rinth", "des", "Sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mich ohne Faden freudig gehen lassen.", "tokens": ["Mich", "oh\u00b7ne", "Fa\u00b7den", "freu\u00b7dig", "ge\u00b7hen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}