{"textgrid.poem.65363": {"metadata": {"author": {"name": "M\u00fcller, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Der Peripatetiker", "genre": "verse", "period": "N.A.", "pub_year": 1810, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Alles will ich nun verlernen,", "tokens": ["Al\u00b7les", "will", "ich", "nun", "ver\u00b7ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was mich lehrte das Papier.", "tokens": ["Was", "mich", "lehr\u00b7te", "das", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarze, steife, stumme Lettern,", "tokens": ["Schwar\u00b7ze", ",", "stei\u00b7fe", ",", "stum\u00b7me", "Let\u00b7tern", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sagt, was wollt ihr noch von mir?", "tokens": ["Sagt", ",", "was", "wollt", "ihr", "noch", "von", "mir", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "VMFIN", "PPER", "ADV", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "In die gr\u00fcne Wanderschule", "tokens": ["In", "die", "gr\u00fc\u00b7ne", "Wan\u00b7der\u00b7schu\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ruft mich ein Philosophus,", "tokens": ["Ruft", "mich", "ein", "Phi\u00b7lo\u00b7so\u00b7phus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Einer, der sich nennt mit Rechten", "tokens": ["Ei\u00b7ner", ",", "der", "sich", "nennt", "mit", "Rech\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "PRF", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein Peripatetikus.", "tokens": ["Ein", "Pe\u00b7ri\u00b7pa\u00b7te\u00b7ti\u00b7kus", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+---", "measure": "unknown.measure.di"}}, "stanza.3": {"line.1": {"text": "Denn er zieht mit seiner Lehre", "tokens": ["Denn", "er", "zieht", "mit", "sei\u00b7ner", "Leh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch die L\u00e4nder ein und aus,", "tokens": ["Durch", "die", "L\u00e4n\u00b7der", "ein", "und", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schl\u00e4gt in Wald und Feld und Garten", "tokens": ["Schl\u00e4gt", "in", "Wald", "und", "Feld", "und", "Gar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf sein wunderbares Haus.", "tokens": ["Auf", "sein", "wun\u00b7der\u00b7ba\u00b7res", "Haus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Eine gro\u00dfe Schaar von Sch\u00fclern", "tokens": ["Ei\u00b7ne", "gro\u00b7\u00dfe", "Schaar", "von", "Sch\u00fc\u00b7lern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Folgt ihm durch die weite Welt,", "tokens": ["Folgt", "ihm", "durch", "die", "wei\u00b7te", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "V\u00f6glein in den blauen L\u00fcften,", "tokens": ["V\u00f6\u00b7glein", "in", "den", "blau\u00b7en", "L\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "V\u00f6glein in dem gr\u00fcnen Zelt.", "tokens": ["V\u00f6\u00b7glein", "in", "dem", "gr\u00fc\u00b7nen", "Zelt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Und sie zwitschern unverdrossen", "tokens": ["Und", "sie", "zwit\u00b7schern", "un\u00b7ver\u00b7dros\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihres Meisters Weisheit nach;", "tokens": ["Ih\u00b7res", "Meis\u00b7ters", "Weis\u00b7heit", "nach", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was sie gestern erst erfahren,", "tokens": ["Was", "sie", "ge\u00b7stern", "erst", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Lehren sie an diesem Tag.", "tokens": ["Leh\u00b7ren", "sie", "an", "die\u00b7sem", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und der Weise aller Weisen", "tokens": ["Und", "der", "Wei\u00b7se", "al\u00b7ler", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kollert sich im weichen Gras,", "tokens": ["Kol\u00b7lert", "sich", "im", "wei\u00b7chen", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wiegt sich auf den schwanken Zweigen,", "tokens": ["Wiegt", "sich", "auf", "den", "schwan\u00b7ken", "Zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als ob Alles w\u00e4r' ein Spa\u00df.", "tokens": ["Als", "ob", "Al\u00b7les", "w\u00e4r'", "ein", "Spa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Also streut er seine Lettern,", "tokens": ["Al\u00b7so", "streut", "er", "sei\u00b7ne", "Let\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wei\u00df und roth und gelb und blau,", "tokens": ["Wei\u00df", "und", "roth", "und", "gelb", "und", "blau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ohne Wahl, mit vollen H\u00e4nden,", "tokens": ["Oh\u00b7ne", "Wahl", ",", "mit", "vol\u00b7len", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00dcber Berg und Thal und Au'.", "tokens": ["\u00dc\u00b7ber", "Berg", "und", "Thal", "und", "Au'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Lest, o lest die lieben Schriften", "tokens": ["Lest", ",", "o", "lest", "die", "lie\u00b7ben", "Schrif\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "FM", "FM", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Voller Wahrheit, voller Lust,", "tokens": ["Vol\u00b7ler", "Wahr\u00b7heit", ",", "vol\u00b7ler", "Lust", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Br\u00fcder, lest und st\u00fcrzt euch selig", "tokens": ["Br\u00fc\u00b7der", ",", "lest", "und", "st\u00fcrzt", "euch", "se\u00b7lig"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "KON", "VVFIN", "PPER", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An des Lehrers warme Brust!", "tokens": ["An", "des", "Leh\u00b7rers", "war\u00b7me", "Brust", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Alles will ich nun verlernen,", "tokens": ["Al\u00b7les", "will", "ich", "nun", "ver\u00b7ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was mich lehrte das Papier.", "tokens": ["Was", "mich", "lehr\u00b7te", "das", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarze, steife, stumme Lettern,", "tokens": ["Schwar\u00b7ze", ",", "stei\u00b7fe", ",", "stum\u00b7me", "Let\u00b7tern", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sagt, was wollt ihr noch von mir?", "tokens": ["Sagt", ",", "was", "wollt", "ihr", "noch", "von", "mir", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "VMFIN", "PPER", "ADV", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "In die gr\u00fcne Wanderschule", "tokens": ["In", "die", "gr\u00fc\u00b7ne", "Wan\u00b7der\u00b7schu\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ruft mich ein Philosophus,", "tokens": ["Ruft", "mich", "ein", "Phi\u00b7lo\u00b7so\u00b7phus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Einer, der sich nennt mit Rechten", "tokens": ["Ei\u00b7ner", ",", "der", "sich", "nennt", "mit", "Rech\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "PRF", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein Peripatetikus.", "tokens": ["Ein", "Pe\u00b7ri\u00b7pa\u00b7te\u00b7ti\u00b7kus", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+---", "measure": "unknown.measure.di"}}, "stanza.11": {"line.1": {"text": "Denn er zieht mit seiner Lehre", "tokens": ["Denn", "er", "zieht", "mit", "sei\u00b7ner", "Leh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch die L\u00e4nder ein und aus,", "tokens": ["Durch", "die", "L\u00e4n\u00b7der", "ein", "und", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schl\u00e4gt in Wald und Feld und Garten", "tokens": ["Schl\u00e4gt", "in", "Wald", "und", "Feld", "und", "Gar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf sein wunderbares Haus.", "tokens": ["Auf", "sein", "wun\u00b7der\u00b7ba\u00b7res", "Haus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Eine gro\u00dfe Schaar von Sch\u00fclern", "tokens": ["Ei\u00b7ne", "gro\u00b7\u00dfe", "Schaar", "von", "Sch\u00fc\u00b7lern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Folgt ihm durch die weite Welt,", "tokens": ["Folgt", "ihm", "durch", "die", "wei\u00b7te", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "V\u00f6glein in den blauen L\u00fcften,", "tokens": ["V\u00f6\u00b7glein", "in", "den", "blau\u00b7en", "L\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "V\u00f6glein in dem gr\u00fcnen Zelt.", "tokens": ["V\u00f6\u00b7glein", "in", "dem", "gr\u00fc\u00b7nen", "Zelt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Und sie zwitschern unverdrossen", "tokens": ["Und", "sie", "zwit\u00b7schern", "un\u00b7ver\u00b7dros\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihres Meisters Weisheit nach;", "tokens": ["Ih\u00b7res", "Meis\u00b7ters", "Weis\u00b7heit", "nach", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was sie gestern erst erfahren,", "tokens": ["Was", "sie", "ge\u00b7stern", "erst", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Lehren sie an diesem Tag.", "tokens": ["Leh\u00b7ren", "sie", "an", "die\u00b7sem", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Und der Weise aller Weisen", "tokens": ["Und", "der", "Wei\u00b7se", "al\u00b7ler", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kollert sich im weichen Gras,", "tokens": ["Kol\u00b7lert", "sich", "im", "wei\u00b7chen", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wiegt sich auf den schwanken Zweigen,", "tokens": ["Wiegt", "sich", "auf", "den", "schwan\u00b7ken", "Zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als ob Alles w\u00e4r' ein Spa\u00df.", "tokens": ["Als", "ob", "Al\u00b7les", "w\u00e4r'", "ein", "Spa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Also streut er seine Lettern,", "tokens": ["Al\u00b7so", "streut", "er", "sei\u00b7ne", "Let\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wei\u00df und roth und gelb und blau,", "tokens": ["Wei\u00df", "und", "roth", "und", "gelb", "und", "blau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ohne Wahl, mit vollen H\u00e4nden,", "tokens": ["Oh\u00b7ne", "Wahl", ",", "mit", "vol\u00b7len", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00dcber Berg und Thal und Au'.", "tokens": ["\u00dc\u00b7ber", "Berg", "und", "Thal", "und", "Au'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Lest, o lest die lieben Schriften", "tokens": ["Lest", ",", "o", "lest", "die", "lie\u00b7ben", "Schrif\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "FM", "FM", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Voller Wahrheit, voller Lust,", "tokens": ["Vol\u00b7ler", "Wahr\u00b7heit", ",", "vol\u00b7ler", "Lust", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Br\u00fcder, lest und st\u00fcrzt euch selig", "tokens": ["Br\u00fc\u00b7der", ",", "lest", "und", "st\u00fcrzt", "euch", "se\u00b7lig"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "KON", "VVFIN", "PPER", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An des Lehrers warme Brust!", "tokens": ["An", "des", "Leh\u00b7rers", "war\u00b7me", "Brust", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}