{"textgrid.poem.53251": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Held, zu welches Herrschafft F\u00fcssen", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Held, zu welches Herrschafft F\u00fcssen", "tokens": ["Held", ",", "zu", "wel\u00b7ches", "Herr\u00b7schafft", "F\u00fcs\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "PWAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4nder liegen, Str\u00f6me fliessen,", "tokens": ["L\u00e4n\u00b7der", "lie\u00b7gen", ",", "Str\u00f6\u00b7me", "flies\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die ich auch nicht zehle schier,", "tokens": ["Die", "ich", "auch", "nicht", "zeh\u00b7le", "schier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PTKNEG", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Welchen ehren und anbehten", "tokens": ["Wel\u00b7chen", "eh\u00b7ren", "und", "an\u00b7beh\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVINF", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sampt den D\u00f6rffern und den St\u00e4dten", "tokens": ["Sampt", "den", "D\u00f6rf\u00b7fern", "und", "den", "St\u00e4d\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch die wild- und zahmen Thier:", "tokens": ["Auch", "die", "wild", "und", "zah\u00b7men", "Thier", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Von dem grossen Theil der Erden", "tokens": ["Von", "dem", "gros\u00b7sen", "Theil", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df ein kleines Feld mir werden,", "tokens": ["La\u00df", "ein", "klei\u00b7nes", "Feld", "mir", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "PPER", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welches mir ertheile Brod,", "tokens": ["Wel\u00b7ches", "mir", "er\u00b7thei\u00b7le", "Brod", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun die Krafft mir wird genommen", "tokens": ["Nun", "die", "Krafft", "mir", "wird", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PPER", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und auff mich gedrungen kommen", "tokens": ["Und", "auff", "mich", "ge\u00b7drun\u00b7gen", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "VVPP", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Beydes Alter und der Tod.", "tokens": ["Bey\u00b7des", "Al\u00b7ter", "und", "der", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Hat ein Pferd sich wol gehalten", "tokens": ["Hat", "ein", "Pferd", "sich", "wol", "ge\u00b7hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "PRF", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und zuletzt beginnt zu alten,", "tokens": ["Und", "zu\u00b7letzt", "be\u00b7ginnt", "zu", "al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nicht mehr taug in die Schlacht,", "tokens": ["Und", "nicht", "mehr", "taug", "in", "die", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Es mu\u00df fressen, bi\u00df es stirbet,", "tokens": ["Es", "mu\u00df", "fres\u00b7sen", ",", "bi\u00df", "es", "stir\u00b7bet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ja kein alter Hund verdirbet,", "tokens": ["Ja", "kein", "al\u00b7ter", "Hund", "ver\u00b7dir\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der uns trewlich hat bewacht.", "tokens": ["Der", "uns", "trew\u00b7lich", "hat", "be\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "La\u00df auch mich nur Futter kriegen,", "tokens": ["La\u00df", "auch", "mich", "nur", "Fut\u00b7ter", "krie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PPER", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bi\u00df der Tod mich heisst erliegen,", "tokens": ["Bi\u00df", "der", "Tod", "mich", "heisst", "er\u00b7lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bin ich dessen anders wehrt,", "tokens": ["Bin", "ich", "des\u00b7sen", "an\u00b7ders", "wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hab' ich mit ber\u00fchmter Zungen", "tokens": ["Hab'", "ich", "mit", "be\u00b7r\u00fchm\u00b7ter", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Deinem Haus' und Dir gesungen,", "tokens": ["Dei\u00b7nem", "Haus'", "und", "Dir", "ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Was kein Rost der Zeit verzehrt.", "tokens": ["Was", "kein", "Rost", "der", "Zeit", "ver\u00b7zehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ph\u00f6bus ist bey mir daheime,", "tokens": ["Ph\u00f6\u00b7bus", "ist", "bey", "mir", "da\u00b7hei\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Diese Kunst der Deutschen Reime", "tokens": ["Die\u00b7se", "Kunst", "der", "Deut\u00b7schen", "Rei\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lernet Preussen erst von mir,", "tokens": ["Ler\u00b7net", "Preus\u00b7sen", "erst", "von", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Meine sind die ersten Seiten,", "tokens": ["Mei\u00b7ne", "sind", "die", "ers\u00b7ten", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zwar man sang vor meinen Zeiten,", "tokens": ["Zwar", "man", "sang", "vor", "mei\u00b7nen", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Aber ohn Geschick und Zier.", "tokens": ["A\u00b7ber", "ohn", "Ge\u00b7schick", "und", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch was ist hievon zu sagen?", "tokens": ["Doch", "was", "ist", "hie\u00b7von", "zu", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PAV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fcrsten schencken nach Behagen,", "tokens": ["F\u00fcrs\u00b7ten", "schen\u00b7cken", "nach", "Be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gnade treibet sie allein,", "tokens": ["Gna\u00b7de", "trei\u00b7bet", "sie", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht Verdienst, das Sie thun sollen,", "tokens": ["Nicht", "Ver\u00b7dienst", ",", "das", "Sie", "thun", "sol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein, Sie herrschen frey und wollen", "tokens": ["Nein", ",", "Sie", "herr\u00b7schen", "frey", "und", "wol\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "ADJD", "KON", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hie auch ungebunden seyn.", "tokens": ["Hie", "auch", "un\u00b7ge\u00b7bun\u00b7den", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Thu, O Churf\u00fcrst, nach Belieben.", "tokens": ["Thu", ",", "O", "Chur\u00b7f\u00fcrst", ",", "nach", "Be\u00b7lie\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NE", "NE", "$,", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Such' ich Huben zehnmal sieben?", "tokens": ["Such'", "ich", "Hu\u00b7ben", "zehn\u00b7mal", "sie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein, auch zwantzig nicht einmal,", "tokens": ["Nein", ",", "auch", "zwant\u00b7zig", "nicht", "ein\u00b7mal", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "CARD", "PTKNEG", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Andre m\u00f6gen nach Begn\u00fcgen", "tokens": ["And\u00b7re", "m\u00f6\u00b7gen", "nach", "Be\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch mit tausend Ochsen pfl\u00fcgen,", "tokens": ["Auch", "mit", "tau\u00b7send", "Och\u00b7sen", "pfl\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mir ist gnug ein gr\u00fcnes Thal,", "tokens": ["Mir", "ist", "gnug", "ein", "gr\u00fc\u00b7nes", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.8": {"line.1": {"text": "Da ich Gott und Dich kan geigen,", "tokens": ["Da", "ich", "Gott", "und", "Dich", "kan", "gei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "PPER", "VMFIN", "VVPP", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Und von fern sehn auffwarts steigen", "tokens": ["Und", "von", "fern", "sehn", "auff\u00b7warts", "stei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJD", "VVFIN", "ADV", "VVINF"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Meines armen Daches Rauch,", "tokens": ["Mei\u00b7nes", "ar\u00b7men", "Da\u00b7ches", "Rauch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn der Abend k\u00f6mpt gegangen.", "tokens": ["Wenn", "der", "A\u00b7bend", "k\u00f6mpt", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sollt' ich aber nichts empfangen,", "tokens": ["Sollt'", "ich", "a\u00b7ber", "nichts", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PIS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wol, Herr, dieses gn\u00fcgt mir auch.", "tokens": ["Wol", ",", "Herr", ",", "die\u00b7ses", "gn\u00fcgt", "mir", "auch", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Held, zu welches Herrschafft F\u00fcssen", "tokens": ["Held", ",", "zu", "wel\u00b7ches", "Herr\u00b7schafft", "F\u00fcs\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "PWAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4nder liegen, Str\u00f6me fliessen,", "tokens": ["L\u00e4n\u00b7der", "lie\u00b7gen", ",", "Str\u00f6\u00b7me", "flies\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die ich auch nicht zehle schier,", "tokens": ["Die", "ich", "auch", "nicht", "zeh\u00b7le", "schier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PTKNEG", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Welchen ehren und anbehten", "tokens": ["Wel\u00b7chen", "eh\u00b7ren", "und", "an\u00b7beh\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVINF", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sampt den D\u00f6rffern und den St\u00e4dten", "tokens": ["Sampt", "den", "D\u00f6rf\u00b7fern", "und", "den", "St\u00e4d\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch die wild- und zahmen Thier:", "tokens": ["Auch", "die", "wild", "und", "zah\u00b7men", "Thier", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Von dem grossen Theil der Erden", "tokens": ["Von", "dem", "gros\u00b7sen", "Theil", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df ein kleines Feld mir werden,", "tokens": ["La\u00df", "ein", "klei\u00b7nes", "Feld", "mir", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "PPER", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welches mir ertheile Brod,", "tokens": ["Wel\u00b7ches", "mir", "er\u00b7thei\u00b7le", "Brod", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun die Krafft mir wird genommen", "tokens": ["Nun", "die", "Krafft", "mir", "wird", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PPER", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und auff mich gedrungen kommen", "tokens": ["Und", "auff", "mich", "ge\u00b7drun\u00b7gen", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "VVPP", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Beydes Alter und der Tod.", "tokens": ["Bey\u00b7des", "Al\u00b7ter", "und", "der", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Hat ein Pferd sich wol gehalten", "tokens": ["Hat", "ein", "Pferd", "sich", "wol", "ge\u00b7hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "PRF", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und zuletzt beginnt zu alten,", "tokens": ["Und", "zu\u00b7letzt", "be\u00b7ginnt", "zu", "al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nicht mehr taug in die Schlacht,", "tokens": ["Und", "nicht", "mehr", "taug", "in", "die", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Es mu\u00df fressen, bi\u00df es stirbet,", "tokens": ["Es", "mu\u00df", "fres\u00b7sen", ",", "bi\u00df", "es", "stir\u00b7bet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ja kein alter Hund verdirbet,", "tokens": ["Ja", "kein", "al\u00b7ter", "Hund", "ver\u00b7dir\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der uns trewlich hat bewacht.", "tokens": ["Der", "uns", "trew\u00b7lich", "hat", "be\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "La\u00df auch mich nur Futter kriegen,", "tokens": ["La\u00df", "auch", "mich", "nur", "Fut\u00b7ter", "krie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PPER", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bi\u00df der Tod mich heisst erliegen,", "tokens": ["Bi\u00df", "der", "Tod", "mich", "heisst", "er\u00b7lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bin ich dessen anders wehrt,", "tokens": ["Bin", "ich", "des\u00b7sen", "an\u00b7ders", "wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hab' ich mit ber\u00fchmter Zungen", "tokens": ["Hab'", "ich", "mit", "be\u00b7r\u00fchm\u00b7ter", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Deinem Haus' und Dir gesungen,", "tokens": ["Dei\u00b7nem", "Haus'", "und", "Dir", "ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Was kein Rost der Zeit verzehrt.", "tokens": ["Was", "kein", "Rost", "der", "Zeit", "ver\u00b7zehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Ph\u00f6bus ist bey mir daheime,", "tokens": ["Ph\u00f6\u00b7bus", "ist", "bey", "mir", "da\u00b7hei\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Diese Kunst der Deutschen Reime", "tokens": ["Die\u00b7se", "Kunst", "der", "Deut\u00b7schen", "Rei\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lernet Preussen erst von mir,", "tokens": ["Ler\u00b7net", "Preus\u00b7sen", "erst", "von", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Meine sind die ersten Seiten,", "tokens": ["Mei\u00b7ne", "sind", "die", "ers\u00b7ten", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zwar man sang vor meinen Zeiten,", "tokens": ["Zwar", "man", "sang", "vor", "mei\u00b7nen", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Aber ohn Geschick und Zier.", "tokens": ["A\u00b7ber", "ohn", "Ge\u00b7schick", "und", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Doch was ist hievon zu sagen?", "tokens": ["Doch", "was", "ist", "hie\u00b7von", "zu", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PAV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fcrsten schencken nach Behagen,", "tokens": ["F\u00fcrs\u00b7ten", "schen\u00b7cken", "nach", "Be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gnade treibet sie allein,", "tokens": ["Gna\u00b7de", "trei\u00b7bet", "sie", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht Verdienst, das Sie thun sollen,", "tokens": ["Nicht", "Ver\u00b7dienst", ",", "das", "Sie", "thun", "sol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein, Sie herrschen frey und wollen", "tokens": ["Nein", ",", "Sie", "herr\u00b7schen", "frey", "und", "wol\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "ADJD", "KON", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hie auch ungebunden seyn.", "tokens": ["Hie", "auch", "un\u00b7ge\u00b7bun\u00b7den", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Thu, O Churf\u00fcrst, nach Belieben.", "tokens": ["Thu", ",", "O", "Chur\u00b7f\u00fcrst", ",", "nach", "Be\u00b7lie\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NE", "NE", "$,", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Such' ich Huben zehnmal sieben?", "tokens": ["Such'", "ich", "Hu\u00b7ben", "zehn\u00b7mal", "sie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein, auch zwantzig nicht einmal,", "tokens": ["Nein", ",", "auch", "zwant\u00b7zig", "nicht", "ein\u00b7mal", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "CARD", "PTKNEG", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Andre m\u00f6gen nach Begn\u00fcgen", "tokens": ["And\u00b7re", "m\u00f6\u00b7gen", "nach", "Be\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch mit tausend Ochsen pfl\u00fcgen,", "tokens": ["Auch", "mit", "tau\u00b7send", "Och\u00b7sen", "pfl\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mir ist gnug ein gr\u00fcnes Thal,", "tokens": ["Mir", "ist", "gnug", "ein", "gr\u00fc\u00b7nes", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.16": {"line.1": {"text": "Da ich Gott und Dich kan geigen,", "tokens": ["Da", "ich", "Gott", "und", "Dich", "kan", "gei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "PPER", "VMFIN", "VVPP", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Und von fern sehn auffwarts steigen", "tokens": ["Und", "von", "fern", "sehn", "auff\u00b7warts", "stei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJD", "VVFIN", "ADV", "VVINF"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Meines armen Daches Rauch,", "tokens": ["Mei\u00b7nes", "ar\u00b7men", "Da\u00b7ches", "Rauch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn der Abend k\u00f6mpt gegangen.", "tokens": ["Wenn", "der", "A\u00b7bend", "k\u00f6mpt", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sollt' ich aber nichts empfangen,", "tokens": ["Sollt'", "ich", "a\u00b7ber", "nichts", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PIS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wol, Herr, dieses gn\u00fcgt mir auch.", "tokens": ["Wol", ",", "Herr", ",", "die\u00b7ses", "gn\u00fcgt", "mir", "auch", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}