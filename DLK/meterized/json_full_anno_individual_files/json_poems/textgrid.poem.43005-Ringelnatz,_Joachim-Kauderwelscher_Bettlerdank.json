{"textgrid.poem.43005": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Kauderwelscher Bettlerdank", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich danke dir f\u00fcr Wasser, Wein und Speise,", "tokens": ["Ich", "dan\u00b7ke", "dir", "f\u00fcr", "Was\u00b7ser", ",", "Wein", "und", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ich bin froh, da\u00df meine Sprache fremd", "tokens": ["Und", "ich", "bin", "froh", ",", "da\u00df", "mei\u00b7ne", "Spra\u00b7che", "fremd"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "$,", "KOUS", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Hier ist. \u2013 Ein Bettler mit verlaustem Hemd", "tokens": ["Hier", "ist", ".", "\u2013", "Ein", "Bett\u00b7ler", "mit", "ver\u00b7laus\u00b7tem", "Hemd"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$.", "$(", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Will ich nur sein. Auf meiner Weiterreise", "tokens": ["Will", "ich", "nur", "sein", ".", "Auf", "mei\u00b7ner", "Wei\u00b7ter\u00b7rei\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "VAINF", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Tr\u00e4um ich davon, wie gut und leise", "tokens": ["Tr\u00e4um", "ich", "da\u00b7von", ",", "wie", "gut", "und", "lei\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PAV", "$,", "PWAV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Du von der Schwelle nach der K\u00fcche gingst", "tokens": ["Du", "von", "der", "Schwel\u00b7le", "nach", "der", "K\u00fc\u00b7che", "gingst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und \u2013 was ich wei\u00df \u2013 wie r\u00fchrend sch\u00f6n du singst.", "tokens": ["Und", "\u2013", "was", "ich", "wei\u00df", "\u2013", "wie", "r\u00fch\u00b7rend", "sch\u00f6n", "du", "singst", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PWS", "PPER", "VVFIN", "$(", "PWAV", "ADJD", "ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Denn ich hab lange dich belauscht, bevor", "tokens": ["Denn", "ich", "hab", "lan\u00b7ge", "dich", "be\u00b7lauscht", ",", "be\u00b7vor"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PPER", "VVFIN", "$,", "KOUS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ich klingelte an deinem starren Tor.", "tokens": ["Ich", "klin\u00b7gel\u00b7te", "an", "dei\u00b7nem", "star\u00b7ren", "Tor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Du hast mich offnen Herzens angeblickt.", "tokens": ["Du", "hast", "mich", "off\u00b7nen", "Her\u00b7zens", "an\u00b7ge\u00b7blickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch ich bem\u00fche mich, mich zu verstellen.", "tokens": ["Doch", "ich", "be\u00b7m\u00fc\u00b7he", "mich", ",", "mich", "zu", "ver\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Du sollst nicht ahnen, wen und wie \u2013 \u2013", "tokens": ["Du", "sollst", "nicht", "ah\u00b7nen", ",", "wen", "und", "wie", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$,", "PWS", "KON", "PWAV", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Himmlisch hast du mein Bettelherz erquickt!", "tokens": ["Himm\u00b7lisch", "hast", "du", "mein", "Bet\u00b7tel\u00b7herz", "er\u00b7quickt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.3": {"line.1": {"text": "So ziehen eilig sanfte Wellen", "tokens": ["So", "zie\u00b7hen", "ei\u00b7lig", "sanf\u00b7te", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vorbei; doch sie vergehen nie.", "tokens": ["Vor\u00b7bei", ";", "doch", "sie", "ver\u00b7ge\u00b7hen", "nie", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "KON", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und eine Welle, die du selbst entsandtest", "tokens": ["Und", "ei\u00b7ne", "Wel\u00b7le", ",", "die", "du", "selbst", "ent\u00b7sand\u00b7test"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und die ich selber nie erkennen lerne,", "tokens": ["Und", "die", "ich", "sel\u00b7ber", "nie", "er\u00b7ken\u00b7nen", "ler\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "PPER", "ADV", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bringt dir vielleicht aus einer fremden Ferne", "tokens": ["Bringt", "dir", "viel\u00b7leicht", "aus", "ei\u00b7ner", "frem\u00b7den", "Fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den Dank zur\u00fcck, den du an mir nicht fandest.", "tokens": ["Den", "Dank", "zu\u00b7r\u00fcck", ",", "den", "du", "an", "mir", "nicht", "fan\u00b7dest", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PRELS", "PPER", "APPR", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Ich danke dir f\u00fcr Wasser, Wein und Speise,", "tokens": ["Ich", "dan\u00b7ke", "dir", "f\u00fcr", "Was\u00b7ser", ",", "Wein", "und", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ich bin froh, da\u00df meine Sprache fremd", "tokens": ["Und", "ich", "bin", "froh", ",", "da\u00df", "mei\u00b7ne", "Spra\u00b7che", "fremd"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "$,", "KOUS", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Hier ist. \u2013 Ein Bettler mit verlaustem Hemd", "tokens": ["Hier", "ist", ".", "\u2013", "Ein", "Bett\u00b7ler", "mit", "ver\u00b7laus\u00b7tem", "Hemd"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$.", "$(", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Will ich nur sein. Auf meiner Weiterreise", "tokens": ["Will", "ich", "nur", "sein", ".", "Auf", "mei\u00b7ner", "Wei\u00b7ter\u00b7rei\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "VAINF", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Tr\u00e4um ich davon, wie gut und leise", "tokens": ["Tr\u00e4um", "ich", "da\u00b7von", ",", "wie", "gut", "und", "lei\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PAV", "$,", "PWAV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Du von der Schwelle nach der K\u00fcche gingst", "tokens": ["Du", "von", "der", "Schwel\u00b7le", "nach", "der", "K\u00fc\u00b7che", "gingst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und \u2013 was ich wei\u00df \u2013 wie r\u00fchrend sch\u00f6n du singst.", "tokens": ["Und", "\u2013", "was", "ich", "wei\u00df", "\u2013", "wie", "r\u00fch\u00b7rend", "sch\u00f6n", "du", "singst", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PWS", "PPER", "VVFIN", "$(", "PWAV", "ADJD", "ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Denn ich hab lange dich belauscht, bevor", "tokens": ["Denn", "ich", "hab", "lan\u00b7ge", "dich", "be\u00b7lauscht", ",", "be\u00b7vor"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PPER", "VVFIN", "$,", "KOUS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ich klingelte an deinem starren Tor.", "tokens": ["Ich", "klin\u00b7gel\u00b7te", "an", "dei\u00b7nem", "star\u00b7ren", "Tor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Du hast mich offnen Herzens angeblickt.", "tokens": ["Du", "hast", "mich", "off\u00b7nen", "Her\u00b7zens", "an\u00b7ge\u00b7blickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch ich bem\u00fche mich, mich zu verstellen.", "tokens": ["Doch", "ich", "be\u00b7m\u00fc\u00b7he", "mich", ",", "mich", "zu", "ver\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Du sollst nicht ahnen, wen und wie \u2013 \u2013", "tokens": ["Du", "sollst", "nicht", "ah\u00b7nen", ",", "wen", "und", "wie", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$,", "PWS", "KON", "PWAV", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Himmlisch hast du mein Bettelherz erquickt!", "tokens": ["Himm\u00b7lisch", "hast", "du", "mein", "Bet\u00b7tel\u00b7herz", "er\u00b7quickt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.7": {"line.1": {"text": "So ziehen eilig sanfte Wellen", "tokens": ["So", "zie\u00b7hen", "ei\u00b7lig", "sanf\u00b7te", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vorbei; doch sie vergehen nie.", "tokens": ["Vor\u00b7bei", ";", "doch", "sie", "ver\u00b7ge\u00b7hen", "nie", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "KON", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Und eine Welle, die du selbst entsandtest", "tokens": ["Und", "ei\u00b7ne", "Wel\u00b7le", ",", "die", "du", "selbst", "ent\u00b7sand\u00b7test"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und die ich selber nie erkennen lerne,", "tokens": ["Und", "die", "ich", "sel\u00b7ber", "nie", "er\u00b7ken\u00b7nen", "ler\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "PPER", "ADV", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bringt dir vielleicht aus einer fremden Ferne", "tokens": ["Bringt", "dir", "viel\u00b7leicht", "aus", "ei\u00b7ner", "frem\u00b7den", "Fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den Dank zur\u00fcck, den du an mir nicht fandest.", "tokens": ["Den", "Dank", "zu\u00b7r\u00fcck", ",", "den", "du", "an", "mir", "nicht", "fan\u00b7dest", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PRELS", "PPER", "APPR", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}}}}