{"textgrid.poem.56300": {"metadata": {"author": {"name": "Chamisso, Adelbert von", "birth": "N.A.", "death": "N.A."}, "title": "1", "genre": "verse", "period": "N.A.", "pub_year": 1832, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Noch war zu Toledo in hohem Flor", "tokens": ["Noch", "war", "zu", "To\u00b7le\u00b7do", "in", "ho\u00b7hem", "Flor"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "NE", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die heimliche Kunst, die sonst sich verlor;", "tokens": ["Die", "heim\u00b7li\u00b7che", "Kunst", ",", "die", "sonst", "sich", "ver\u00b7lor", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "PRF", "VVFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein weiser Meister war dort bekannt,", "tokens": ["Ein", "wei\u00b7ser", "Meis\u00b7ter", "war", "dort", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Yglano, der Magier und Nekromant.", "tokens": ["Yg\u00b7la\u00b7no", ",", "der", "Ma\u00b7gier", "und", "Ne\u00b7kro\u00b7mant", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Wie abends er einst vor dem Stundenglas", "tokens": ["Wie", "a\u00b7bends", "er", "einst", "vor", "dem", "Stun\u00b7den\u00b7glas"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "In seinem Museum sinnend sa\u00df,", "tokens": ["In", "sei\u00b7nem", "Mu\u00b7se\u00b7um", "sin\u00b7nend", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Trat ein zu ihm dem\u00fctig fast", "tokens": ["Trat", "ein", "zu", "ihm", "de\u00b7m\u00fc\u00b7tig", "fast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "APPR", "PPER", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Vetter Anselmo, ein seltener Gast. \u2013", "tokens": ["Sein", "Vet\u00b7ter", "An\u00b7sel\u00b7mo", ",", "ein", "sel\u00b7te\u00b7ner", "Gast", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "NE", "$,", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.3": {"line.1": {"text": "\u00bbherr Vetter Anselmo, wie hat man das Gl\u00fcck?", "tokens": ["\u00bb", "herr", "Vet\u00b7ter", "An\u00b7sel\u00b7mo", ",", "wie", "hat", "man", "das", "Gl\u00fcck", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "NE", "NE", "$,", "PWAV", "VAFIN", "PIS", "ART", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Was f\u00fchrt Euch endlich zu uns zur\u00fcck?", "tokens": ["Was", "f\u00fchrt", "Euch", "end\u00b7lich", "zu", "uns", "zu\u00b7r\u00fcck", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ihr wart ja sonst auf der rechten Bahn,", "tokens": ["Ihr", "wart", "ja", "sonst", "auf", "der", "rech\u00b7ten", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was gingen Euch da die Verwandten an?\u00ab \u2013", "tokens": ["Was", "gin\u00b7gen", "Euch", "da", "die", "Ver\u00b7wand\u00b7ten", "an", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "\u00bbseid grausam nicht und ungerecht,", "tokens": ["\u00bb", "seid", "grau\u00b7sam", "nicht", "und", "un\u00b7ge\u00b7recht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADJD", "PTKNEG", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Herr Vetter; versteht mich endlich recht.", "tokens": ["Herr", "Vet\u00b7ter", ";", "ver\u00b7steht", "mich", "end\u00b7lich", "recht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$.", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mich hielt von Toledos leuchtendem Stern,", "tokens": ["Mich", "hielt", "von", "To\u00b7le\u00b7dos", "leuch\u00b7ten\u00b7dem", "Stern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von Don Yglano nur Ehrfurcht fern.", "tokens": ["Von", "Don", "Yg\u00b7la\u00b7no", "nur", "Ehr\u00b7furcht", "fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "ADV", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "O w\u00fc\u00dftet Ihr, wie der Busen mir schwoll,", "tokens": ["O", "w\u00fc\u00df\u00b7tet", "Ihr", ",", "wie", "der", "Bu\u00b7sen", "mir", "schwoll", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "PPER", "ADJD", "$,"], "meter": "-+----+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Wann Euer Lob mir entgegen erscholl!", "tokens": ["Wann", "Eu\u00b7er", "Lob", "mir", "ent\u00b7ge\u00b7gen", "er\u00b7scholl", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PPER", "PTKVZ", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie stolz und jubelnd ich eingestimmt:", "tokens": ["Wie", "stolz", "und", "ju\u00b7belnd", "ich", "ein\u00b7ge\u00b7stimmt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "VVPP", "PPER", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der ist uns allen zum Muster bestimmt!", "tokens": ["Der", "ist", "uns", "al\u00b7len", "zum", "Mus\u00b7ter", "be\u00b7stimmt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PIAT", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Der eine rief, der andere schrie:", "tokens": ["Der", "ei\u00b7ne", "rief", ",", "der", "an\u00b7de\u00b7re", "schrie", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "So einen sah die Welt noch nie,", "tokens": ["So", "ei\u00b7nen", "sah", "die", "Welt", "noch", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "VVFIN", "ART", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der zauberm\u00e4chtig und weise zugleich", "tokens": ["Der", "zau\u00b7ber\u00b7m\u00e4ch\u00b7tig", "und", "wei\u00b7se", "zu\u00b7gleich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "VVFIN", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Beherrscht der Geister n\u00e4chtliches Reich!", "tokens": ["Be\u00b7herrscht", "der", "Geis\u00b7ter", "n\u00e4cht\u00b7li\u00b7ches", "Reich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.7": {"line.1": {"text": "Er ist das Gold der Wissenschaft,", "tokens": ["Er", "ist", "das", "Gold", "der", "Wis\u00b7sen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ist das Erz und ist die Kraft;", "tokens": ["Und", "ist", "das", "Erz", "und", "ist", "die", "Kraft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "KON", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So mannlich fest, so kindlich mild,", "tokens": ["So", "mann\u00b7lich", "fest", ",", "so", "kind\u00b7lich", "mild", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKVZ", "$,", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So aller Tugend vollendetes Bild!", "tokens": ["So", "al\u00b7ler", "Tu\u00b7gend", "voll\u00b7en\u00b7de\u00b7tes", "Bild", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Doch hat Euch einer zu tadeln gewu\u00dft,", "tokens": ["Doch", "hat", "Euch", "ei\u00b7ner", "zu", "ta\u00b7deln", "ge\u00b7wu\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIS", "PTKZU", "VVINF", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den alle so preisen zu meiner Lust,", "tokens": ["Den", "al\u00b7le", "so", "prei\u00b7sen", "zu", "mei\u00b7ner", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und dieser Tadel, da\u00df Ihr es wi\u00dft,", "tokens": ["Und", "die\u00b7ser", "Ta\u00b7del", ",", "da\u00df", "Ihr", "es", "wi\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ist eben der Wurm, der das Herz mir fri\u00dft.", "tokens": ["Ist", "e\u00b7ben", "der", "Wurm", ",", "der", "das", "Herz", "mir", "fri\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PRELS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.9": {"line.1": {"text": "Er sprach: wie kommt es, wer macht mir das klar,", "tokens": ["Er", "sprach", ":", "wie", "kommt", "es", ",", "wer", "macht", "mir", "das", "klar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWAV", "VVFIN", "PPER", "$,", "PWS", "VVFIN", "PPER", "ART", "ADJD", "$,"], "meter": "-+-+-++--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Da\u00df euer L\u00f6w und Lamm und Aar", "tokens": ["Da\u00df", "eu\u00b7er", "L\u00f6w", "und", "Lamm", "und", "Aar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Biedermann, der sein Vetter doch ist,", "tokens": ["Den", "Bie\u00b7der\u00b7mann", ",", "der", "sein", "Vet\u00b7ter", "doch", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Den guten Anselmo so schm\u00e4hlich vergi\u00dft?\u00ab \u2013", "tokens": ["Den", "gu\u00b7ten", "An\u00b7sel\u00b7mo", "so", "schm\u00e4h\u00b7lich", "ver\u00b7gi\u00dft", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.10": {"line.1": {"text": "\u00bbwas sagtet denn Ihr, wenn ich bitten darf,", "tokens": ["\u00bb", "was", "sag\u00b7tet", "denn", "Ihr", ",", "wenn", "ich", "bit\u00b7ten", "darf", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "KON", "PPER", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zu solchem Tadel, so spitz und scharf?", "tokens": ["Zu", "sol\u00b7chem", "Ta\u00b7del", ",", "so", "spitz", "und", "scharf", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "ADV", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich machte die Lehre mir gerne zu Nutz;", "tokens": ["Ich", "mach\u00b7te", "die", "Leh\u00b7re", "mir", "ger\u00b7ne", "zu", "Nutz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ihr nahmt mich, Vetter, doch wacker in Schutz?\u00ab \u2013", "tokens": ["Ihr", "nahmt", "mich", ",", "Vet\u00b7ter", ",", "doch", "wa\u00b7cker", "in", "Schutz", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "NN", "$,", "ADV", "ADJD", "APPR", "NN", "$.", "$(", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "\u00bbvermocht ich es denn, der ich da stand", "tokens": ["\u00bb", "ver\u00b7mocht", "ich", "es", "denn", ",", "der", "ich", "da", "stand"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPER", "PPER", "ADV", "$,", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dem h\u00e4mischen Kl\u00e4ger bequem zur Hand,", "tokens": ["Dem", "h\u00e4\u00b7mi\u00b7schen", "Kl\u00e4\u00b7ger", "be\u00b7quem", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Um so mich zu legen ad acta gleich,", "tokens": ["Um", "so", "mich", "zu", "le\u00b7gen", "ad", "ac\u00b7ta", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "PPER", "PTKZU", "VVINF", "FM", "FM", "ADV", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Zerlumpt, verhungert, hager und bleich?", "tokens": ["Zer\u00b7lumpt", ",", "ver\u00b7hun\u00b7gert", ",", "ha\u00b7ger", "und", "bleich", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.12": {"line.1": {"text": "Ich frag Euch, o blickt doch auf mich herab,", "tokens": ["Ich", "frag", "Euch", ",", "o", "blickt", "doch", "auf", "mich", "her\u00b7ab", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "FM", "VVFIN", "ADV", "APPR", "PPER", "ADV", "$,"], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sah je ein Bettler als Leiche im Grab", "tokens": ["Sah", "je", "ein", "Bett\u00b7ler", "als", "Lei\u00b7che", "im", "Grab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "KOUS", "NN", "APPRART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Erb\u00e4rmlicher aus? o tilgt doch die Schmach!", "tokens": ["Er\u00b7b\u00e4rm\u00b7li\u00b7cher", "aus", "?", "o", "tilgt", "doch", "die", "Schmach", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "FM", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie trifft Euch zumeist, wie der Neider sprach.", "tokens": ["Sie", "trifft", "Euch", "zu\u00b7meist", ",", "wie", "der", "Nei\u00b7der", "sprach", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.13": {"line.1": {"text": "Mir eine Pfr\u00fcnde, ein Bischofsstab!", "tokens": ["Mir", "ei\u00b7ne", "Pfr\u00fcn\u00b7de", ",", "ein", "Bi\u00b7schofs\u00b7stab", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Das macht nur bald mit dem Teufel ab,", "tokens": ["Das", "macht", "nur", "bald", "mit", "dem", "Teu\u00b7fel", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und ihm und Euch mit Haut und Haar", "tokens": ["Und", "ihm", "und", "Euch", "mit", "Haut", "und", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "KON", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verschreib ich mich auf immerdar.\u00ab \u2013", "tokens": ["Ver\u00b7schreib", "ich", "mich", "auf", "im\u00b7mer\u00b7dar", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "PPER", "PRF", "APPR", "ADV", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "\u00bbherr Vetter, Herr Vetter! ei, ei! mit Vergunst!", "tokens": ["\u00bb", "herr", "Vet\u00b7ter", ",", "Herr", "Vet\u00b7ter", "!", "ei", ",", "ei", "!", "mit", "Ver\u00b7gunst", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "$,", "NN", "NE", "$.", "NE", "$,", "ITJ", "$.", "APPR", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Von Gott allein ist meine Kunst,", "tokens": ["Von", "Gott", "al\u00b7lein", "ist", "mei\u00b7ne", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Versteht mich recht, von Gott allein;", "tokens": ["Ver\u00b7steht", "mich", "recht", ",", "von", "Gott", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab mit dem Teufel nichts gemein.\u00ab \u2013", "tokens": ["Hab", "mit", "dem", "Teu\u00b7fel", "nichts", "ge\u00b7mein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PIS", "ADJD", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "\u00bbvon Gott, versteht sich! sagt ich es nicht?", "tokens": ["\u00bb", "von", "Gott", ",", "ver\u00b7steht", "sich", "!", "sagt", "ich", "es", "nicht", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$,", "VVFIN", "PRF", "$.", "VVFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Es ist der Hunger, der aus mir spricht.", "tokens": ["Es", "ist", "der", "Hun\u00b7ger", ",", "der", "aus", "mir", "spricht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mit Gott, Herr Vetter, verhelft mir zu Brod", "tokens": ["Mit", "Gott", ",", "Herr", "Vet\u00b7ter", ",", "ver\u00b7helft", "mir", "zu", "Brod"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "NE", "$,", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und rechnet auf mich auf Leben und Tod!\u00ab \u2013", "tokens": ["Und", "rech\u00b7net", "auf", "mich", "auf", "Le\u00b7ben", "und", "Tod", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "APPR", "PRF", "APPR", "NN", "KON", "NN", "$.", "$(", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "\u00bbihr wolltet dankbar, erkenntlich sodann", "tokens": ["\u00bb", "ihr", "woll\u00b7tet", "dank\u00b7bar", ",", "er\u00b7kennt\u00b7lich", "so\u00b7dann"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ADJD", "$,", "ADJD", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vergelten, was Gutes ich Euch getan,", "tokens": ["Ver\u00b7gel\u00b7ten", ",", "was", "Gu\u00b7tes", "ich", "Euch", "ge\u00b7tan", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "NN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Wann einen G\u00f6nner und Schutzpatron", "tokens": ["Wann", "ei\u00b7nen", "G\u00f6n\u00b7ner", "und", "Schutz\u00b7pat\u00b7ron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich einmal suchte f\u00fcr meinen Sohn?\u00ab \u2013", "tokens": ["Ich", "ein\u00b7mal", "such\u00b7te", "f\u00fcr", "mei\u00b7nen", "Sohn", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "\u00bbja, dankbar, ja! mit unendlicher Lust!", "tokens": ["\u00bb", "ja", ",", "dank\u00b7bar", ",", "ja", "!", "mit", "un\u00b7end\u00b7li\u00b7cher", "Lust", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "ADJD", "$,", "ADV", "$.", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Die Dankbarkeit ist die Tugend just,", "tokens": ["Die", "Dank\u00b7bar\u00b7keit", "ist", "die", "Tu\u00b7gend", "just", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Die einz'ge vielleicht, deren, unverbl\u00fcmt,", "tokens": ["Die", "einz'\u00b7ge", "viel\u00b7leicht", ",", "de\u00b7ren", ",", "un\u00b7ver\u00b7bl\u00fcmt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$,", "PDS", "$,", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Mit Fug und Recht mein Herz sich r\u00fchmt.", "tokens": ["Mit", "Fug", "und", "Recht", "mein", "Herz", "sich", "r\u00fchmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PPOSAT", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Man hat von mir Euch B\u00f6ses gesagt,", "tokens": ["Man", "hat", "von", "mir", "Euch", "B\u00f6\u00b7ses", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPER", "PPER", "NE", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Mich manches Lasters angeklagt,", "tokens": ["Mich", "man\u00b7ches", "Las\u00b7ters", "an\u00b7ge\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mich angeschw\u00e4rzt zu aller Stund,", "tokens": ["Mich", "an\u00b7ge\u00b7schw\u00e4rzt", "zu", "al\u00b7ler", "Stund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Oft, leider! vielleicht nicht ohne Grund.", "tokens": ["Oft", ",", "lei\u00b7der", "!", "viel\u00b7leicht", "nicht", "oh\u00b7ne", "Grund", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$.", "ADV", "PTKNEG", "APPR", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "Ich wei\u00df, Herr Vetter, ich habe gefehlt,", "tokens": ["Ich", "wei\u00df", ",", "Herr", "Vet\u00b7ter", ",", "ich", "ha\u00b7be", "ge\u00b7fehlt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NN", "NE", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das Gute vers\u00e4umt, das B\u00f6se gew\u00e4hlt,", "tokens": ["Das", "Gu\u00b7te", "ver\u00b7s\u00e4umt", ",", "das", "B\u00f6\u00b7se", "ge\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gewatet in S\u00fcnden bis an die Knie;", "tokens": ["Ge\u00b7wa\u00b7tet", "in", "S\u00fcn\u00b7den", "bis", "an", "die", "Knie", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "APPR", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Undankbar aber, das war ich nie.", "tokens": ["Un\u00b7dank\u00b7bar", "a\u00b7ber", ",", "das", "war", "ich", "nie", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "PDS", "VAFIN", "PPER", "ADV", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.20": {"line.1": {"text": "O Dankbarkeit, du s\u00fc\u00dfe Pflicht,", "tokens": ["O", "Dank\u00b7bar\u00b7keit", ",", "du", "s\u00fc\u00b7\u00dfe", "Pflicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du Himmelslust, du Himmelslicht!", "tokens": ["Du", "Him\u00b7mels\u00b7lust", ",", "du", "Him\u00b7mels\u00b7licht", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie hab ich dich mir eingepr\u00e4gt,", "tokens": ["Wie", "hab", "ich", "dich", "mir", "ein\u00b7ge\u00b7pr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PRF", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie hab ich stets dich heilig gehegt!", "tokens": ["Wie", "hab", "ich", "stets", "dich", "hei\u00b7lig", "ge\u00b7hegt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "VVFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.21": {"line.1": {"text": "Und Euer vortrefflicher, teurer Sohn \u2013", "tokens": ["Und", "Eu\u00b7er", "vor\u00b7treff\u00b7li\u00b7cher", ",", "teu\u00b7rer", "Sohn", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "$,", "ADJA", "NN", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wie lieb ich den lieben Vetter doch schon!", "tokens": ["Wie", "lieb", "ich", "den", "lie\u00b7ben", "Vet\u00b7ter", "doch", "schon", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ART", "ADJA", "NN", "ADV", "ADV", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "O welch ein Gl\u00fcck ist Dankbarkeit!", "tokens": ["O", "welch", "ein", "Gl\u00fcck", "ist", "Dank\u00b7bar\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "O w\u00e4r ich doch erst, Herr Vetter, so weit!\u00ab \u2013", "tokens": ["O", "w\u00e4r", "ich", "doch", "erst", ",", "Herr", "Vet\u00b7ter", ",", "so", "weit", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "ADV", "$,", "NN", "NE", "$,", "ADV", "ADJD", "$.", "$(", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.22": {"line.1": {"text": "\u00bbgemach, gemach! das liegt noch fern,", "tokens": ["\u00bb", "ge\u00b7mach", ",", "ge\u00b7mach", "!", "das", "liegt", "noch", "fern", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "ADV", "$.", "PDS", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und nicht das N\u00e4chste vers\u00e4um ich gern.", "tokens": ["Und", "nicht", "das", "N\u00e4chs\u00b7te", "ver\u00b7s\u00e4um", "ich", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ART", "ADJA", "NN", "PPER", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da kommt Frau Martha, die eben fragt,", "tokens": ["Da", "kommt", "Frau", "Mar\u00b7tha", ",", "die", "e\u00b7ben", "fragt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was mir zum Abendessen behagt.", "tokens": ["Was", "mir", "zum", "A\u00b7ben\u00b7des\u00b7sen", "be\u00b7hagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.23": {"line.1": {"text": "So h\u00f6rt, Frau Martha; seid eben gefa\u00dft \u2013", "tokens": ["So", "h\u00f6rt", ",", "Frau", "Mar\u00b7tha", ";", "seid", "e\u00b7ben", "ge\u00b7fa\u00dft", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "NN", "NE", "$.", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nicht wahr, Herr Vetter? \u2013 auf einen Gast;", "tokens": ["Nicht", "wahr", ",", "Herr", "Vet\u00b7ter", "?", "\u2013", "auf", "ei\u00b7nen", "Gast", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "NN", "NE", "$.", "$(", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ihr habt zwei H\u00fchner; das zweite Huhn", "tokens": ["Ihr", "habt", "zwei", "H\u00fch\u00b7ner", ";", "das", "zwei\u00b7te", "Huhn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "CARD", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Steckt erst an den Spie\u00df, wenn ich's hei\u00dfe tun.", "tokens": ["Steckt", "erst", "an", "den", "Spie\u00df", ",", "wenn", "ich's", "hei\u00b7\u00dfe", "tun", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,", "KOUS", "PIS", "VVFIN", "VVINF", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.24": {"line.1": {"text": "Jetzt aber nehmt die Flasche dort,", "tokens": ["Jetzt", "a\u00b7ber", "nehmt", "die", "Fla\u00b7sche", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und dort den Humpen von seinem Ort,", "tokens": ["Und", "dort", "den", "Hum\u00b7pen", "von", "sei\u00b7nem", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und schenkt mir langsam den edlen Wein", "tokens": ["Und", "schenkt", "mir", "lang\u00b7sam", "den", "ed\u00b7len", "Wein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von hoch, recht perlend und sch\u00e4umend ein.", "tokens": ["Von", "hoch", ",", "recht", "per\u00b7lend", "und", "sch\u00e4u\u00b7mend", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "$,", "ADV", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.25": {"line.1": {"text": "Ihr, Vetter, indes kommt n\u00e4her zu mir,", "tokens": ["Ihr", ",", "Vet\u00b7ter", ",", "in\u00b7des", "kommt", "n\u00e4\u00b7her", "zu", "mir", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "ADV", "VVFIN", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In diesen Kreis auf dem Estrich hier;", "tokens": ["In", "die\u00b7sen", "Kreis", "auf", "dem", "Est\u00b7rich", "hier", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da, nehmt das Stundenglas in die Hand,", "tokens": ["Da", ",", "nehmt", "das", "Stun\u00b7den\u00b7glas", "in", "die", "Hand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und schaut nur scharf auf den rinnenden Sand.", "tokens": ["Und", "schaut", "nur", "scharf", "auf", "den", "rin\u00b7nen\u00b7den", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.26": {"line.1": {"text": "Es ist nur so ein Experiment.", "tokens": ["Es", "ist", "nur", "so", "ein", "Ex\u00b7pe\u00b7ri\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ihr wi\u00dft den Anfang, ich wei\u00df das End.", "tokens": ["Ihr", "wi\u00dft", "den", "An\u00b7fang", ",", "ich", "wei\u00df", "das", "End", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie hocus pocus, bracadabra!", "tokens": ["Sie", "ho\u00b7cus", "po\u00b7cus", ",", "bra\u00b7ca\u00b7dab\u00b7ra", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir sind noch hier und w\u00e4hnen uns da!\u00ab \u2013", "tokens": ["Wir", "sind", "noch", "hier", "und", "w\u00e4h\u00b7nen", "uns", "da", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "KON", "VVFIN", "PPER", "ADV", "$.", "$(", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.27": {"line.1": {"text": "Er hatte die Worte murmelnd gebraucht,", "tokens": ["Er", "hat\u00b7te", "die", "Wor\u00b7te", "mur\u00b7melnd", "ge\u00b7braucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und heimlich zugleich ihn angehaucht;", "tokens": ["Und", "heim\u00b7lich", "zu\u00b7gleich", "ihn", "an\u00b7ge\u00b7haucht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "PPER", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Anselmo stand die Augen verdreht", "tokens": ["An\u00b7sel\u00b7mo", "stand", "die", "Au\u00b7gen", "ver\u00b7dreht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN", "VVFIN"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und starr, wie ein h\u00f6lzerner Heiliger steht.", "tokens": ["Und", "starr", ",", "wie", "ein", "h\u00f6l\u00b7zer\u00b7ner", "Hei\u00b7li\u00b7ger", "steht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PWAV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.28": {"line.1": {"text": "Noch war zu Toledo in hohem Flor", "tokens": ["Noch", "war", "zu", "To\u00b7le\u00b7do", "in", "ho\u00b7hem", "Flor"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "NE", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die heimliche Kunst, die sonst sich verlor;", "tokens": ["Die", "heim\u00b7li\u00b7che", "Kunst", ",", "die", "sonst", "sich", "ver\u00b7lor", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "PRF", "VVFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein weiser Meister war dort bekannt,", "tokens": ["Ein", "wei\u00b7ser", "Meis\u00b7ter", "war", "dort", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Yglano, der Magier und Nekromant.", "tokens": ["Yg\u00b7la\u00b7no", ",", "der", "Ma\u00b7gier", "und", "Ne\u00b7kro\u00b7mant", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.29": {"line.1": {"text": "Wie abends er einst vor dem Stundenglas", "tokens": ["Wie", "a\u00b7bends", "er", "einst", "vor", "dem", "Stun\u00b7den\u00b7glas"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "In seinem Museum sinnend sa\u00df,", "tokens": ["In", "sei\u00b7nem", "Mu\u00b7se\u00b7um", "sin\u00b7nend", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Trat ein zu ihm dem\u00fctig fast", "tokens": ["Trat", "ein", "zu", "ihm", "de\u00b7m\u00fc\u00b7tig", "fast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "APPR", "PPER", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Vetter Anselmo, ein seltener Gast. \u2013", "tokens": ["Sein", "Vet\u00b7ter", "An\u00b7sel\u00b7mo", ",", "ein", "sel\u00b7te\u00b7ner", "Gast", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "NE", "$,", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.30": {"line.1": {"text": "\u00bbherr Vetter Anselmo, wie hat man das Gl\u00fcck?", "tokens": ["\u00bb", "herr", "Vet\u00b7ter", "An\u00b7sel\u00b7mo", ",", "wie", "hat", "man", "das", "Gl\u00fcck", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "NE", "NE", "$,", "PWAV", "VAFIN", "PIS", "ART", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Was f\u00fchrt Euch endlich zu uns zur\u00fcck?", "tokens": ["Was", "f\u00fchrt", "Euch", "end\u00b7lich", "zu", "uns", "zu\u00b7r\u00fcck", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ihr wart ja sonst auf der rechten Bahn,", "tokens": ["Ihr", "wart", "ja", "sonst", "auf", "der", "rech\u00b7ten", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was gingen Euch da die Verwandten an?\u00ab \u2013", "tokens": ["Was", "gin\u00b7gen", "Euch", "da", "die", "Ver\u00b7wand\u00b7ten", "an", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "\u00bbseid grausam nicht und ungerecht,", "tokens": ["\u00bb", "seid", "grau\u00b7sam", "nicht", "und", "un\u00b7ge\u00b7recht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADJD", "PTKNEG", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Herr Vetter; versteht mich endlich recht.", "tokens": ["Herr", "Vet\u00b7ter", ";", "ver\u00b7steht", "mich", "end\u00b7lich", "recht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$.", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mich hielt von Toledos leuchtendem Stern,", "tokens": ["Mich", "hielt", "von", "To\u00b7le\u00b7dos", "leuch\u00b7ten\u00b7dem", "Stern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von Don Yglano nur Ehrfurcht fern.", "tokens": ["Von", "Don", "Yg\u00b7la\u00b7no", "nur", "Ehr\u00b7furcht", "fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "ADV", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.32": {"line.1": {"text": "O w\u00fc\u00dftet Ihr, wie der Busen mir schwoll,", "tokens": ["O", "w\u00fc\u00df\u00b7tet", "Ihr", ",", "wie", "der", "Bu\u00b7sen", "mir", "schwoll", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "PPER", "ADJD", "$,"], "meter": "-+----+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Wann Euer Lob mir entgegen erscholl!", "tokens": ["Wann", "Eu\u00b7er", "Lob", "mir", "ent\u00b7ge\u00b7gen", "er\u00b7scholl", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PPER", "PTKVZ", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie stolz und jubelnd ich eingestimmt:", "tokens": ["Wie", "stolz", "und", "ju\u00b7belnd", "ich", "ein\u00b7ge\u00b7stimmt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "VVPP", "PPER", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der ist uns allen zum Muster bestimmt!", "tokens": ["Der", "ist", "uns", "al\u00b7len", "zum", "Mus\u00b7ter", "be\u00b7stimmt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PIAT", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.33": {"line.1": {"text": "Der eine rief, der andere schrie:", "tokens": ["Der", "ei\u00b7ne", "rief", ",", "der", "an\u00b7de\u00b7re", "schrie", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "So einen sah die Welt noch nie,", "tokens": ["So", "ei\u00b7nen", "sah", "die", "Welt", "noch", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "VVFIN", "ART", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der zauberm\u00e4chtig und weise zugleich", "tokens": ["Der", "zau\u00b7ber\u00b7m\u00e4ch\u00b7tig", "und", "wei\u00b7se", "zu\u00b7gleich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "VVFIN", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Beherrscht der Geister n\u00e4chtliches Reich!", "tokens": ["Be\u00b7herrscht", "der", "Geis\u00b7ter", "n\u00e4cht\u00b7li\u00b7ches", "Reich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.34": {"line.1": {"text": "Er ist das Gold der Wissenschaft,", "tokens": ["Er", "ist", "das", "Gold", "der", "Wis\u00b7sen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ist das Erz und ist die Kraft;", "tokens": ["Und", "ist", "das", "Erz", "und", "ist", "die", "Kraft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "KON", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So mannlich fest, so kindlich mild,", "tokens": ["So", "mann\u00b7lich", "fest", ",", "so", "kind\u00b7lich", "mild", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKVZ", "$,", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So aller Tugend vollendetes Bild!", "tokens": ["So", "al\u00b7ler", "Tu\u00b7gend", "voll\u00b7en\u00b7de\u00b7tes", "Bild", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.35": {"line.1": {"text": "Doch hat Euch einer zu tadeln gewu\u00dft,", "tokens": ["Doch", "hat", "Euch", "ei\u00b7ner", "zu", "ta\u00b7deln", "ge\u00b7wu\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIS", "PTKZU", "VVINF", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den alle so preisen zu meiner Lust,", "tokens": ["Den", "al\u00b7le", "so", "prei\u00b7sen", "zu", "mei\u00b7ner", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und dieser Tadel, da\u00df Ihr es wi\u00dft,", "tokens": ["Und", "die\u00b7ser", "Ta\u00b7del", ",", "da\u00df", "Ihr", "es", "wi\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ist eben der Wurm, der das Herz mir fri\u00dft.", "tokens": ["Ist", "e\u00b7ben", "der", "Wurm", ",", "der", "das", "Herz", "mir", "fri\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PRELS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.36": {"line.1": {"text": "Er sprach: wie kommt es, wer macht mir das klar,", "tokens": ["Er", "sprach", ":", "wie", "kommt", "es", ",", "wer", "macht", "mir", "das", "klar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWAV", "VVFIN", "PPER", "$,", "PWS", "VVFIN", "PPER", "ART", "ADJD", "$,"], "meter": "-+-+-++--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Da\u00df euer L\u00f6w und Lamm und Aar", "tokens": ["Da\u00df", "eu\u00b7er", "L\u00f6w", "und", "Lamm", "und", "Aar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Biedermann, der sein Vetter doch ist,", "tokens": ["Den", "Bie\u00b7der\u00b7mann", ",", "der", "sein", "Vet\u00b7ter", "doch", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Den guten Anselmo so schm\u00e4hlich vergi\u00dft?\u00ab \u2013", "tokens": ["Den", "gu\u00b7ten", "An\u00b7sel\u00b7mo", "so", "schm\u00e4h\u00b7lich", "ver\u00b7gi\u00dft", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.37": {"line.1": {"text": "\u00bbwas sagtet denn Ihr, wenn ich bitten darf,", "tokens": ["\u00bb", "was", "sag\u00b7tet", "denn", "Ihr", ",", "wenn", "ich", "bit\u00b7ten", "darf", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "KON", "PPER", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zu solchem Tadel, so spitz und scharf?", "tokens": ["Zu", "sol\u00b7chem", "Ta\u00b7del", ",", "so", "spitz", "und", "scharf", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "ADV", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich machte die Lehre mir gerne zu Nutz;", "tokens": ["Ich", "mach\u00b7te", "die", "Leh\u00b7re", "mir", "ger\u00b7ne", "zu", "Nutz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ihr nahmt mich, Vetter, doch wacker in Schutz?\u00ab \u2013", "tokens": ["Ihr", "nahmt", "mich", ",", "Vet\u00b7ter", ",", "doch", "wa\u00b7cker", "in", "Schutz", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "NN", "$,", "ADV", "ADJD", "APPR", "NN", "$.", "$(", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.38": {"line.1": {"text": "\u00bbvermocht ich es denn, der ich da stand", "tokens": ["\u00bb", "ver\u00b7mocht", "ich", "es", "denn", ",", "der", "ich", "da", "stand"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPER", "PPER", "ADV", "$,", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dem h\u00e4mischen Kl\u00e4ger bequem zur Hand,", "tokens": ["Dem", "h\u00e4\u00b7mi\u00b7schen", "Kl\u00e4\u00b7ger", "be\u00b7quem", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Um so mich zu legen ad acta gleich,", "tokens": ["Um", "so", "mich", "zu", "le\u00b7gen", "ad", "ac\u00b7ta", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "PPER", "PTKZU", "VVINF", "FM", "FM", "ADV", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Zerlumpt, verhungert, hager und bleich?", "tokens": ["Zer\u00b7lumpt", ",", "ver\u00b7hun\u00b7gert", ",", "ha\u00b7ger", "und", "bleich", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.39": {"line.1": {"text": "Ich frag Euch, o blickt doch auf mich herab,", "tokens": ["Ich", "frag", "Euch", ",", "o", "blickt", "doch", "auf", "mich", "her\u00b7ab", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "FM", "VVFIN", "ADV", "APPR", "PPER", "ADV", "$,"], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sah je ein Bettler als Leiche im Grab", "tokens": ["Sah", "je", "ein", "Bett\u00b7ler", "als", "Lei\u00b7che", "im", "Grab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "KOUS", "NN", "APPRART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Erb\u00e4rmlicher aus? o tilgt doch die Schmach!", "tokens": ["Er\u00b7b\u00e4rm\u00b7li\u00b7cher", "aus", "?", "o", "tilgt", "doch", "die", "Schmach", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "FM", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie trifft Euch zumeist, wie der Neider sprach.", "tokens": ["Sie", "trifft", "Euch", "zu\u00b7meist", ",", "wie", "der", "Nei\u00b7der", "sprach", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.40": {"line.1": {"text": "Mir eine Pfr\u00fcnde, ein Bischofsstab!", "tokens": ["Mir", "ei\u00b7ne", "Pfr\u00fcn\u00b7de", ",", "ein", "Bi\u00b7schofs\u00b7stab", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Das macht nur bald mit dem Teufel ab,", "tokens": ["Das", "macht", "nur", "bald", "mit", "dem", "Teu\u00b7fel", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und ihm und Euch mit Haut und Haar", "tokens": ["Und", "ihm", "und", "Euch", "mit", "Haut", "und", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "KON", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verschreib ich mich auf immerdar.\u00ab \u2013", "tokens": ["Ver\u00b7schreib", "ich", "mich", "auf", "im\u00b7mer\u00b7dar", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "PPER", "PRF", "APPR", "ADV", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "\u00bbherr Vetter, Herr Vetter! ei, ei! mit Vergunst!", "tokens": ["\u00bb", "herr", "Vet\u00b7ter", ",", "Herr", "Vet\u00b7ter", "!", "ei", ",", "ei", "!", "mit", "Ver\u00b7gunst", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "$,", "NN", "NE", "$.", "NE", "$,", "ITJ", "$.", "APPR", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Von Gott allein ist meine Kunst,", "tokens": ["Von", "Gott", "al\u00b7lein", "ist", "mei\u00b7ne", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Versteht mich recht, von Gott allein;", "tokens": ["Ver\u00b7steht", "mich", "recht", ",", "von", "Gott", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab mit dem Teufel nichts gemein.\u00ab \u2013", "tokens": ["Hab", "mit", "dem", "Teu\u00b7fel", "nichts", "ge\u00b7mein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PIS", "ADJD", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "\u00bbvon Gott, versteht sich! sagt ich es nicht?", "tokens": ["\u00bb", "von", "Gott", ",", "ver\u00b7steht", "sich", "!", "sagt", "ich", "es", "nicht", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$,", "VVFIN", "PRF", "$.", "VVFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Es ist der Hunger, der aus mir spricht.", "tokens": ["Es", "ist", "der", "Hun\u00b7ger", ",", "der", "aus", "mir", "spricht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mit Gott, Herr Vetter, verhelft mir zu Brod", "tokens": ["Mit", "Gott", ",", "Herr", "Vet\u00b7ter", ",", "ver\u00b7helft", "mir", "zu", "Brod"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "NE", "$,", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und rechnet auf mich auf Leben und Tod!\u00ab \u2013", "tokens": ["Und", "rech\u00b7net", "auf", "mich", "auf", "Le\u00b7ben", "und", "Tod", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "APPR", "PRF", "APPR", "NN", "KON", "NN", "$.", "$(", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.43": {"line.1": {"text": "\u00bbihr wolltet dankbar, erkenntlich sodann", "tokens": ["\u00bb", "ihr", "woll\u00b7tet", "dank\u00b7bar", ",", "er\u00b7kennt\u00b7lich", "so\u00b7dann"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ADJD", "$,", "ADJD", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vergelten, was Gutes ich Euch getan,", "tokens": ["Ver\u00b7gel\u00b7ten", ",", "was", "Gu\u00b7tes", "ich", "Euch", "ge\u00b7tan", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "NN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Wann einen G\u00f6nner und Schutzpatron", "tokens": ["Wann", "ei\u00b7nen", "G\u00f6n\u00b7ner", "und", "Schutz\u00b7pat\u00b7ron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich einmal suchte f\u00fcr meinen Sohn?\u00ab \u2013", "tokens": ["Ich", "ein\u00b7mal", "such\u00b7te", "f\u00fcr", "mei\u00b7nen", "Sohn", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.44": {"line.1": {"text": "\u00bbja, dankbar, ja! mit unendlicher Lust!", "tokens": ["\u00bb", "ja", ",", "dank\u00b7bar", ",", "ja", "!", "mit", "un\u00b7end\u00b7li\u00b7cher", "Lust", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "ADJD", "$,", "ADV", "$.", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Die Dankbarkeit ist die Tugend just,", "tokens": ["Die", "Dank\u00b7bar\u00b7keit", "ist", "die", "Tu\u00b7gend", "just", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Die einz'ge vielleicht, deren, unverbl\u00fcmt,", "tokens": ["Die", "einz'\u00b7ge", "viel\u00b7leicht", ",", "de\u00b7ren", ",", "un\u00b7ver\u00b7bl\u00fcmt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$,", "PDS", "$,", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Mit Fug und Recht mein Herz sich r\u00fchmt.", "tokens": ["Mit", "Fug", "und", "Recht", "mein", "Herz", "sich", "r\u00fchmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PPOSAT", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Man hat von mir Euch B\u00f6ses gesagt,", "tokens": ["Man", "hat", "von", "mir", "Euch", "B\u00f6\u00b7ses", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPER", "PPER", "NE", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Mich manches Lasters angeklagt,", "tokens": ["Mich", "man\u00b7ches", "Las\u00b7ters", "an\u00b7ge\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mich angeschw\u00e4rzt zu aller Stund,", "tokens": ["Mich", "an\u00b7ge\u00b7schw\u00e4rzt", "zu", "al\u00b7ler", "Stund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Oft, leider! vielleicht nicht ohne Grund.", "tokens": ["Oft", ",", "lei\u00b7der", "!", "viel\u00b7leicht", "nicht", "oh\u00b7ne", "Grund", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$.", "ADV", "PTKNEG", "APPR", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.46": {"line.1": {"text": "Ich wei\u00df, Herr Vetter, ich habe gefehlt,", "tokens": ["Ich", "wei\u00df", ",", "Herr", "Vet\u00b7ter", ",", "ich", "ha\u00b7be", "ge\u00b7fehlt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NN", "NE", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das Gute vers\u00e4umt, das B\u00f6se gew\u00e4hlt,", "tokens": ["Das", "Gu\u00b7te", "ver\u00b7s\u00e4umt", ",", "das", "B\u00f6\u00b7se", "ge\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gewatet in S\u00fcnden bis an die Knie;", "tokens": ["Ge\u00b7wa\u00b7tet", "in", "S\u00fcn\u00b7den", "bis", "an", "die", "Knie", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "APPR", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Undankbar aber, das war ich nie.", "tokens": ["Un\u00b7dank\u00b7bar", "a\u00b7ber", ",", "das", "war", "ich", "nie", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "PDS", "VAFIN", "PPER", "ADV", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.47": {"line.1": {"text": "O Dankbarkeit, du s\u00fc\u00dfe Pflicht,", "tokens": ["O", "Dank\u00b7bar\u00b7keit", ",", "du", "s\u00fc\u00b7\u00dfe", "Pflicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du Himmelslust, du Himmelslicht!", "tokens": ["Du", "Him\u00b7mels\u00b7lust", ",", "du", "Him\u00b7mels\u00b7licht", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie hab ich dich mir eingepr\u00e4gt,", "tokens": ["Wie", "hab", "ich", "dich", "mir", "ein\u00b7ge\u00b7pr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PRF", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie hab ich stets dich heilig gehegt!", "tokens": ["Wie", "hab", "ich", "stets", "dich", "hei\u00b7lig", "ge\u00b7hegt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "VVFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.48": {"line.1": {"text": "Und Euer vortrefflicher, teurer Sohn \u2013", "tokens": ["Und", "Eu\u00b7er", "vor\u00b7treff\u00b7li\u00b7cher", ",", "teu\u00b7rer", "Sohn", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "$,", "ADJA", "NN", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wie lieb ich den lieben Vetter doch schon!", "tokens": ["Wie", "lieb", "ich", "den", "lie\u00b7ben", "Vet\u00b7ter", "doch", "schon", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ART", "ADJA", "NN", "ADV", "ADV", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "O welch ein Gl\u00fcck ist Dankbarkeit!", "tokens": ["O", "welch", "ein", "Gl\u00fcck", "ist", "Dank\u00b7bar\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "O w\u00e4r ich doch erst, Herr Vetter, so weit!\u00ab \u2013", "tokens": ["O", "w\u00e4r", "ich", "doch", "erst", ",", "Herr", "Vet\u00b7ter", ",", "so", "weit", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "ADV", "$,", "NN", "NE", "$,", "ADV", "ADJD", "$.", "$(", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.49": {"line.1": {"text": "\u00bbgemach, gemach! das liegt noch fern,", "tokens": ["\u00bb", "ge\u00b7mach", ",", "ge\u00b7mach", "!", "das", "liegt", "noch", "fern", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "ADV", "$.", "PDS", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und nicht das N\u00e4chste vers\u00e4um ich gern.", "tokens": ["Und", "nicht", "das", "N\u00e4chs\u00b7te", "ver\u00b7s\u00e4um", "ich", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ART", "ADJA", "NN", "PPER", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da kommt Frau Martha, die eben fragt,", "tokens": ["Da", "kommt", "Frau", "Mar\u00b7tha", ",", "die", "e\u00b7ben", "fragt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was mir zum Abendessen behagt.", "tokens": ["Was", "mir", "zum", "A\u00b7ben\u00b7des\u00b7sen", "be\u00b7hagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.50": {"line.1": {"text": "So h\u00f6rt, Frau Martha; seid eben gefa\u00dft \u2013", "tokens": ["So", "h\u00f6rt", ",", "Frau", "Mar\u00b7tha", ";", "seid", "e\u00b7ben", "ge\u00b7fa\u00dft", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "NN", "NE", "$.", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nicht wahr, Herr Vetter? \u2013 auf einen Gast;", "tokens": ["Nicht", "wahr", ",", "Herr", "Vet\u00b7ter", "?", "\u2013", "auf", "ei\u00b7nen", "Gast", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "NN", "NE", "$.", "$(", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ihr habt zwei H\u00fchner; das zweite Huhn", "tokens": ["Ihr", "habt", "zwei", "H\u00fch\u00b7ner", ";", "das", "zwei\u00b7te", "Huhn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "CARD", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Steckt erst an den Spie\u00df, wenn ich's hei\u00dfe tun.", "tokens": ["Steckt", "erst", "an", "den", "Spie\u00df", ",", "wenn", "ich's", "hei\u00b7\u00dfe", "tun", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,", "KOUS", "PIS", "VVFIN", "VVINF", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.51": {"line.1": {"text": "Jetzt aber nehmt die Flasche dort,", "tokens": ["Jetzt", "a\u00b7ber", "nehmt", "die", "Fla\u00b7sche", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und dort den Humpen von seinem Ort,", "tokens": ["Und", "dort", "den", "Hum\u00b7pen", "von", "sei\u00b7nem", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und schenkt mir langsam den edlen Wein", "tokens": ["Und", "schenkt", "mir", "lang\u00b7sam", "den", "ed\u00b7len", "Wein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von hoch, recht perlend und sch\u00e4umend ein.", "tokens": ["Von", "hoch", ",", "recht", "per\u00b7lend", "und", "sch\u00e4u\u00b7mend", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "$,", "ADV", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.52": {"line.1": {"text": "Ihr, Vetter, indes kommt n\u00e4her zu mir,", "tokens": ["Ihr", ",", "Vet\u00b7ter", ",", "in\u00b7des", "kommt", "n\u00e4\u00b7her", "zu", "mir", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "ADV", "VVFIN", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In diesen Kreis auf dem Estrich hier;", "tokens": ["In", "die\u00b7sen", "Kreis", "auf", "dem", "Est\u00b7rich", "hier", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da, nehmt das Stundenglas in die Hand,", "tokens": ["Da", ",", "nehmt", "das", "Stun\u00b7den\u00b7glas", "in", "die", "Hand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und schaut nur scharf auf den rinnenden Sand.", "tokens": ["Und", "schaut", "nur", "scharf", "auf", "den", "rin\u00b7nen\u00b7den", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.53": {"line.1": {"text": "Es ist nur so ein Experiment.", "tokens": ["Es", "ist", "nur", "so", "ein", "Ex\u00b7pe\u00b7ri\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ihr wi\u00dft den Anfang, ich wei\u00df das End.", "tokens": ["Ihr", "wi\u00dft", "den", "An\u00b7fang", ",", "ich", "wei\u00df", "das", "End", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie hocus pocus, bracadabra!", "tokens": ["Sie", "ho\u00b7cus", "po\u00b7cus", ",", "bra\u00b7ca\u00b7dab\u00b7ra", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir sind noch hier und w\u00e4hnen uns da!\u00ab \u2013", "tokens": ["Wir", "sind", "noch", "hier", "und", "w\u00e4h\u00b7nen", "uns", "da", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "KON", "VVFIN", "PPER", "ADV", "$.", "$(", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.54": {"line.1": {"text": "Er hatte die Worte murmelnd gebraucht,", "tokens": ["Er", "hat\u00b7te", "die", "Wor\u00b7te", "mur\u00b7melnd", "ge\u00b7braucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und heimlich zugleich ihn angehaucht;", "tokens": ["Und", "heim\u00b7lich", "zu\u00b7gleich", "ihn", "an\u00b7ge\u00b7haucht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "PPER", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Anselmo stand die Augen verdreht", "tokens": ["An\u00b7sel\u00b7mo", "stand", "die", "Au\u00b7gen", "ver\u00b7dreht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN", "VVFIN"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und starr, wie ein h\u00f6lzerner Heiliger steht.", "tokens": ["Und", "starr", ",", "wie", "ein", "h\u00f6l\u00b7zer\u00b7ner", "Hei\u00b7li\u00b7ger", "steht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PWAV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}}}}