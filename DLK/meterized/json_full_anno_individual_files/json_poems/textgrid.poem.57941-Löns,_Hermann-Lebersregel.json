{"textgrid.poem.57941": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Lebersregel", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00dcb' immer Untert\u00e4nigkeit", "tokens": ["\u00dcb'", "im\u00b7mer", "Un\u00b7ter\u00b7t\u00e4\u00b7nig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis an dein fr\u00fches Grab,", "tokens": ["Bis", "an", "dein", "fr\u00fc\u00b7hes", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und weiche keinen Finger breit", "tokens": ["Und", "wei\u00b7che", "kei\u00b7nen", "Fin\u00b7ger", "breit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Magistrate ab.", "tokens": ["Vom", "Ma\u00b7gist\u00b7ra\u00b7te", "ab", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.2": {"line.1": {"text": "Sag' immer: \u00bbJa\u00ab und dann nur \u00bbNee\u00ab,", "tokens": ["Sag'", "im\u00b7mer", ":", "\u00bb", "Ja", "\u00ab", "und", "dann", "nur", "\u00bb", "Nee", "\u00ab", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "ADV", "$.", "$(", "PTKANT", "$(", "KON", "ADV", "ADV", "$(", "NN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bist du in Minderzahl,", "tokens": ["Bist", "du", "in", "Min\u00b7der\u00b7zahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das schadet nichts und macht sogar", "tokens": ["Das", "scha\u00b7det", "nichts", "und", "macht", "so\u00b7gar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PIS", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz gut sich auch einmal.", "tokens": ["Ganz", "gut", "sich", "auch", "ein\u00b7mal", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Opposition ist p\u00f6belhaft,", "tokens": ["Op\u00b7po\u00b7si\u00b7ti\u00b7on", "ist", "p\u00f6\u00b7bel\u00b7haft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Nach eigner Meinung geht", "tokens": ["Nach", "eig\u00b7ner", "Mei\u00b7nung", "geht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kein feiner Mann, im Gegenteil,", "tokens": ["Kein", "fei\u00b7ner", "Mann", ",", "im", "Ge\u00b7gen\u00b7teil", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das tut blo\u00df ein Prolet.", "tokens": ["Das", "tut", "blo\u00df", "ein", "Pro\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Drum tue ruhig deine Pflicht,", "tokens": ["Drum", "tue", "ru\u00b7hig", "dei\u00b7ne", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie sich's f\u00fcr dich geh\u00f6rt,", "tokens": ["Wie", "sich's", "f\u00fcr", "dich", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vielleicht wirst du Senator dann", "tokens": ["Viel\u00b7leicht", "wirst", "du", "Se\u00b7na\u00b7tor", "dann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und stirbst einst hochgeehrt.", "tokens": ["Und", "stirbst", "einst", "hoch\u00b7geehrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Und jeder, der dein Grabmal sieht,", "tokens": ["Und", "je\u00b7der", ",", "der", "dein", "Grab\u00b7mal", "sieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der zieht den Hut und spricht:", "tokens": ["Der", "zieht", "den", "Hut", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er tat stets, was man ihm gesagt,", "tokens": ["Er", "tat", "stets", ",", "was", "man", "ihm", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PRELS", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und str\u00e4ubte nie sich nicht.", "tokens": ["Und", "str\u00e4ub\u00b7te", "nie", "sich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PRF", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Er ward dem Magistrate nicht", "tokens": ["Er", "ward", "dem", "Ma\u00b7gist\u00b7ra\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum \u00c4rger und zur Last,", "tokens": ["Zum", "\u00c4r\u00b7ger", "und", "zur", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit einem Wort: er war ein Mann,", "tokens": ["Mit", "ei\u00b7nem", "Wort", ":", "er", "war", "ein", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie er aufs Rathaus pa\u00dft.", "tokens": ["Wie", "er", "aufs", "Rat\u00b7haus", "pa\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "\u00dcb' immer Untert\u00e4nigkeit", "tokens": ["\u00dcb'", "im\u00b7mer", "Un\u00b7ter\u00b7t\u00e4\u00b7nig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis an dein fr\u00fches Grab,", "tokens": ["Bis", "an", "dein", "fr\u00fc\u00b7hes", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und weiche keinen Finger breit", "tokens": ["Und", "wei\u00b7che", "kei\u00b7nen", "Fin\u00b7ger", "breit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Magistrate ab.", "tokens": ["Vom", "Ma\u00b7gist\u00b7ra\u00b7te", "ab", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Sag' immer: \u00bbJa\u00ab und dann nur \u00bbNee\u00ab,", "tokens": ["Sag'", "im\u00b7mer", ":", "\u00bb", "Ja", "\u00ab", "und", "dann", "nur", "\u00bb", "Nee", "\u00ab", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "ADV", "$.", "$(", "PTKANT", "$(", "KON", "ADV", "ADV", "$(", "NN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bist du in Minderzahl,", "tokens": ["Bist", "du", "in", "Min\u00b7der\u00b7zahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das schadet nichts und macht sogar", "tokens": ["Das", "scha\u00b7det", "nichts", "und", "macht", "so\u00b7gar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PIS", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz gut sich auch einmal.", "tokens": ["Ganz", "gut", "sich", "auch", "ein\u00b7mal", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Opposition ist p\u00f6belhaft,", "tokens": ["Op\u00b7po\u00b7si\u00b7ti\u00b7on", "ist", "p\u00f6\u00b7bel\u00b7haft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Nach eigner Meinung geht", "tokens": ["Nach", "eig\u00b7ner", "Mei\u00b7nung", "geht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kein feiner Mann, im Gegenteil,", "tokens": ["Kein", "fei\u00b7ner", "Mann", ",", "im", "Ge\u00b7gen\u00b7teil", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das tut blo\u00df ein Prolet.", "tokens": ["Das", "tut", "blo\u00df", "ein", "Pro\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Drum tue ruhig deine Pflicht,", "tokens": ["Drum", "tue", "ru\u00b7hig", "dei\u00b7ne", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie sich's f\u00fcr dich geh\u00f6rt,", "tokens": ["Wie", "sich's", "f\u00fcr", "dich", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vielleicht wirst du Senator dann", "tokens": ["Viel\u00b7leicht", "wirst", "du", "Se\u00b7na\u00b7tor", "dann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und stirbst einst hochgeehrt.", "tokens": ["Und", "stirbst", "einst", "hoch\u00b7geehrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Und jeder, der dein Grabmal sieht,", "tokens": ["Und", "je\u00b7der", ",", "der", "dein", "Grab\u00b7mal", "sieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der zieht den Hut und spricht:", "tokens": ["Der", "zieht", "den", "Hut", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er tat stets, was man ihm gesagt,", "tokens": ["Er", "tat", "stets", ",", "was", "man", "ihm", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PRELS", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und str\u00e4ubte nie sich nicht.", "tokens": ["Und", "str\u00e4ub\u00b7te", "nie", "sich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PRF", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Er ward dem Magistrate nicht", "tokens": ["Er", "ward", "dem", "Ma\u00b7gist\u00b7ra\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum \u00c4rger und zur Last,", "tokens": ["Zum", "\u00c4r\u00b7ger", "und", "zur", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit einem Wort: er war ein Mann,", "tokens": ["Mit", "ei\u00b7nem", "Wort", ":", "er", "war", "ein", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie er aufs Rathaus pa\u00dft.", "tokens": ["Wie", "er", "aufs", "Rat\u00b7haus", "pa\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}