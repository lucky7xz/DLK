{"dta.poem.3796": {"metadata": {"author": {"name": "Spindler, Christian Gotthold", "birth": "N.A.", "death": "N.A."}, "title": "Die abgedanckte Liebe,  \n oder  \n das K\u00f6rbgen.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1745", "urn": "urn:nbn:de:kobv:b4-20581-9", "language": ["de:0.99"], "booktitle": "Spindler, Christian Gotthold: Unschuldige Jugend-Fr\u00fcchte. Leipzig, 1745."}, "poem": {"stanza.1": {"line.1": {"text": "Mein Herr! letzt kam ein Brieff von ihrer", "tokens": ["Mein", "Herr", "!", "letzt", "kam", "ein", "Brieff", "von", "ih\u00b7rer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "eignen Hand,", "tokens": ["eig\u00b7nen", "Hand", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Darinnen nennt man mich der Reitzung Gegen-", "tokens": ["Da\u00b7rin\u00b7nen", "nennt", "man", "mich", "der", "Reit\u00b7zung", "Ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PIS", "PRF", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "stand,", "tokens": ["stand", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Sein treu und frommes Lamm; o! was vor", "tokens": ["Sein", "treu", "und", "from\u00b7mes", "Lamm", ";", "o", "!", "was", "vor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPOSAT", "ADJD", "KON", "ADJA", "NN", "$.", "FM", "$.", "PWS", "APPR"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "albre Possen!", "tokens": ["alb\u00b7re", "Pos\u00b7sen", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Ich glaube gantz gewi\u00df, mein Herr! sie sind ge-", "tokens": ["Ich", "glau\u00b7be", "gantz", "ge\u00b7wi\u00df", ",", "mein", "Herr", "!", "sie", "sind", "ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "TRUNC"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "schossen.", "tokens": ["schos\u00b7sen", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "Sie brennen voller Lust, voll grosser Liebes-", "tokens": ["Sie", "bren\u00b7nen", "vol\u00b7ler", "Lust", ",", "voll", "gros\u00b7ser", "Lie\u00b7bes"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVINF", "ADJA", "NN", "$,", "ADJD", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Brunst,", "tokens": ["Brunst", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.11": {"text": "Die\u00df schreibt ihr eigner Kiel; alleine, Herr! mit", "tokens": ["Die\u00df", "schreibt", "ihr", "eig\u00b7ner", "Kiel", ";", "al\u00b7lei\u00b7ne", ",", "Herr", "!", "mit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["PDS", "VVFIN", "PPOSAT", "ADJA", "NN", "$.", "ADV", "$,", "NN", "$.", "APPR"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "Gunst,", "tokens": ["Gunst", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.13": {"text": "Die\u00df klingt sehr abgeschmackt, sehr schlecht und", "tokens": ["Die\u00df", "klingt", "sehr", "ab\u00b7ge\u00b7schmackt", ",", "sehr", "schlecht", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "VVPP", "$,", "ADV", "ADJD", "KON"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "niedertr\u00e4chtig,", "tokens": ["nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.15": {"text": "Sie geben sich zu blo\u00df, sie sind ihr selbst nicht", "tokens": ["Sie", "ge\u00b7ben", "sich", "zu", "blo\u00df", ",", "sie", "sind", "ihr", "selbst", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ADV", "$,", "PPER", "VAFIN", "PPER", "ADV", "PTKNEG"], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "m\u00e4chtig.", "tokens": ["m\u00e4ch\u00b7tig", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.17": {"text": "Die Liebe l\u00e4st sich nicht mit einem jeden ein.", "tokens": ["Die", "Lie\u00b7be", "l\u00e4st", "sich", "nicht", "mit", "ei\u00b7nem", "je\u00b7den", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PTKNEG", "APPR", "ART", "PIAT", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wer liebt, mu\u00df tugendhafft und auch verschwie-", "tokens": ["Wer", "liebt", ",", "mu\u00df", "tu\u00b7gend\u00b7hafft", "und", "auch", "ver\u00b7schwie"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$,", "VMFIN", "NN", "KON", "ADV", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "gen seyn.", "tokens": ["gen", "seyn", "."], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAINF", "$."], "meter": "-+", "measure": "iambic.single"}, "line.20": {"text": "Und beydes sind sie nicht; nach ihrem geilen", "tokens": ["Und", "bey\u00b7des", "sind", "sie", "nicht", ";", "nach", "ih\u00b7rem", "gei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIS", "VAFIN", "PPER", "PTKNEG", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Rennen,", "tokens": ["Ren\u00b7nen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.22": {"text": "Wird sie fast jedes Kind in unserm Orte kennen.", "tokens": ["Wird", "sie", "fast", "je\u00b7des", "Kind", "in", "un\u00b7serm", "Or\u00b7te", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Es ist ja gantz bekannt, es wei\u00df ja jedermann,", "tokens": ["Es", "ist", "ja", "gantz", "be\u00b7kannt", ",", "es", "wei\u00df", "ja", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "$,", "PPER", "VVFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Da\u00df keine K\u00f6chin mehr, der sie nicht zugethan.", "tokens": ["Da\u00df", "kei\u00b7ne", "K\u00f6\u00b7chin", "mehr", ",", "der", "sie", "nicht", "zu\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADV", "$,", "PRELS", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die wilde Liebes-Glut erhitzet ihre Glieder,", "tokens": ["Die", "wil\u00b7de", "Lie\u00b7bes\u00b7Glut", "er\u00b7hit\u00b7zet", "ih\u00b7re", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Die schl\u00e4get Ehre, Gl\u00fcck, und alle Wohlfahrt", "tokens": ["Die", "schl\u00e4\u00b7get", "Eh\u00b7re", ",", "Gl\u00fcck", ",", "und", "al\u00b7le", "Wohl\u00b7fahrt"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "NN", "$,", "NN", "$,", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "nieder.", "tokens": ["nie\u00b7der", "."], "token_info": ["word", "punct"], "pos": ["PTKVZ", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.28": {"text": "Wer jeden Tag, wie sie, zwey Dutzend Gl\u00e4ser", "tokens": ["Wer", "je\u00b7den", "Tag", ",", "wie", "sie", ",", "zwey", "Dut\u00b7zend", "Gl\u00e4\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PIAT", "NN", "$,", "PWAV", "PPER", "$,", "CARD", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "leert,", "tokens": ["leert", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.30": {"text": "Wer ohne K\u00fcmmerni\u00df von seiner Schnure zehrt,", "tokens": ["Wer", "oh\u00b7ne", "K\u00fcm\u00b7mer\u00b7ni\u00df", "von", "sei\u00b7ner", "Schnu\u00b7re", "zehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Und sonsten nichts verdient; mit dem nimmt es", "tokens": ["Und", "sons\u00b7ten", "nichts", "ver\u00b7dient", ";", "mit", "dem", "nimmt", "es"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "VVPP", "$.", "APPR", "ART", "VVFIN", "PPER"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.32": {"text": "behende,", "tokens": ["be\u00b7hen\u00b7de", ","], "token_info": ["word", "punct"], "pos": ["ADJA", "$,"], "meter": "+--", "measure": "dactylic.init"}, "line.33": {"text": "(wie man es treibt, so gehts) ein schlecht und", "tokens": ["(", "wie", "man", "es", "treibt", ",", "so", "gehts", ")", "ein", "schlecht", "und"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PWAV", "PIS", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "$(", "ART", "ADJD", "KON"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "sch\u00e4ndlich Ende.", "tokens": ["sch\u00e4nd\u00b7lich", "En\u00b7de", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.35": {"text": "Zwar, ich verzeihe sie ihr frey geschrieben Blatt.", "tokens": ["Zwar", ",", "ich", "ver\u00b7zei\u00b7he", "sie", "ihr", "frey", "ge\u00b7schrie\u00b7ben", "Blatt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PPER", "PPER", "ADJD", "VVPP", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Doch, da sie nun mein Kiel genug gewarnet hat,", "tokens": ["Doch", ",", "da", "sie", "nun", "mein", "Kiel", "ge\u00b7nug", "ge\u00b7war\u00b7net", "hat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "PPOSAT", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "So m\u00fcssen sie auch selbst ihr eigen Wohl be-", "tokens": ["So", "m\u00fcs\u00b7sen", "sie", "auch", "selbst", "ihr", "ei\u00b7gen", "Wohl", "be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "PPER", "ADJD", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.38": {"text": "dencken,", "tokens": ["den\u00b7cken", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.39": {"text": "Sonst m\u00f6chte manche noch sie auch ein K\u00f6rb-", "tokens": ["Sonst", "m\u00f6ch\u00b7te", "man\u00b7che", "noch", "sie", "auch", "ein", "K\u00f6r\u00b7b"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "PPER", "ADV", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.40": {"text": "gen schencken.", "tokens": ["gen", "schen\u00b7cken", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.41": {"text": "Klingt ihnen dieser Satz vieleicht etwas zu frey,", "tokens": ["Klingt", "ih\u00b7nen", "die\u00b7ser", "Satz", "vie\u00b7leicht", "et\u00b7was", "zu", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDAT", "NN", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "So glauben sie, da\u00df es die Frucht der Wahr-", "tokens": ["So", "glau\u00b7ben", "sie", ",", "da\u00df", "es", "die", "Frucht", "der", "Wahr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "ART", "TRUNC"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.43": {"text": "heit sey.", "tokens": ["heit", "sey", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$."], "meter": "--", "measure": "unknown.measure.zero"}, "line.44": {"text": "Sie sind vor diesesmahl nach W\u00fcrden abgeloh-", "tokens": ["Sie", "sind", "vor", "die\u00b7ses\u00b7mahl", "nach", "W\u00fcr\u00b7den", "ab\u00b7ge\u00b7loh"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADV", "APPR", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "net.", "tokens": ["net", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-", "measure": "single.down"}, "line.46": {"text": "Vielleicht, damit ihr Kiel des Schreibens bald", "tokens": ["Viel\u00b7leicht", ",", "da\u00b7mit", "ihr", "Kiel", "des", "Schrei\u00b7bens", "bald"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPOSAT", "NN", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.47": {"text": "entwohnet.", "tokens": ["ent\u00b7woh\u00b7net", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.48": {"text": "Wenn also ihr Verstand, mein Herr! sein bestes", "tokens": ["Wenn", "al\u00b7so", "ihr", "Ver\u00b7stand", ",", "mein", "Herr", "!", "sein", "bes\u00b7tes"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$.", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.49": {"text": "thut,", "tokens": ["thut", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-", "measure": "single.down"}, "line.50": {"text": "Vieleicht wird mit der Zeit Sie ", "tokens": ["Vie\u00b7leicht", "wird", "mit", "der", "Zeit", "Sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.51": {"text": "noch gut.", "tokens": ["noch", "gut", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADJD", "$."], "meter": "-+", "measure": "iambic.single"}}}}}