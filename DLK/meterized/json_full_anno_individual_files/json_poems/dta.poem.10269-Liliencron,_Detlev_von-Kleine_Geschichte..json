{"dta.poem.10269": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "Kleine Geschichte.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1883", "urn": "urn:nbn:de:kobv:b4-200905197184", "language": ["de:0.99"], "booktitle": "Liliencron, Detlev von: Adjutantenritte und andere Gedichte. Leipzig, [1883]."}, "poem": {"stanza.1": {"line.1": {"text": "Fr&#252;hsommer wars, am Nachmittag.             ", "tokens": ["Fr", "&#252;", "hsom\u00b7mer", "wars", ",", "am", "Nach\u00b7mit\u00b7tag", "."], "token_info": ["word", "XML_entity", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$(", "ADJD", "VAFIN", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Wei\u00dfdorn stand in Bl\u00fcte.", "tokens": ["Der", "Wei\u00df\u00b7dorn", "stand", "in", "Bl\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich ging allein durch Feld und Hag", "tokens": ["Ich", "ging", "al\u00b7lein", "durch", "Feld", "und", "Hag"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit sehnendem Gem\u00fcte.", "tokens": ["Mit", "seh\u00b7nen\u00b7dem", "Ge\u00b7m\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Es trieb mich in den Tag hinein", "tokens": ["Es", "trieb", "mich", "in", "den", "Tag", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein z\u00e4rtliches Verlangen", "tokens": ["Ein", "z\u00e4rt\u00b7li\u00b7ches", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nach dunkler Laube D\u00e4mmerschein", "tokens": ["Nach", "dunk\u00b7ler", "Lau\u00b7be", "D\u00e4m\u00b7mer\u00b7schein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und weichen M\u00e4dchenwangen.", "tokens": ["Und", "wei\u00b7chen", "M\u00e4d\u00b7chen\u00b7wan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich fand ein Wirtshaus, alt, bestroht,", "tokens": ["Ich", "fand", "ein", "Wirts\u00b7haus", ",", "alt", ",", "be\u00b7stroht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADJD", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Umringt von Baumgardinen.", "tokens": ["Um\u00b7ringt", "von", "Baum\u00b7gar\u00b7di\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die alte Frau am Eingang bot", "tokens": ["Die", "al\u00b7te", "Frau", "am", "Ein\u00b7gang", "bot"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geb\u00e4ck und Apfelsinen.", "tokens": ["Ge\u00b7b\u00e4ck", "und", "Ap\u00b7fel\u00b7si\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Im Garten: Schaukeln, Karoussel,", "tokens": ["Im", "Gar\u00b7ten", ":", "Schau\u00b7keln", ",", "Ka\u00b7rous\u00b7sel", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$.", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Zelte, \u00fcbersonnte.", "tokens": ["Und", "Zel\u00b7te", ",", "\u00fc\u00b7ber\u00b7sonn\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Scheibenstand, wo man als Tell", "tokens": ["Ein", "Schei\u00b7ben\u00b7stand", ",", "wo", "man", "als", "Tell"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "PIS", "KOKOM", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Apfel schie\u00dfen konnte.", "tokens": ["Den", "Ap\u00b7fel", "schie\u00b7\u00dfen", "konn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Den Affen zeigt Neapels Sohn,", "tokens": ["Den", "Af\u00b7fen", "zeigt", "Nea\u00b7pels", "Sohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die Kegelkugeln rollen.", "tokens": ["Die", "Ke\u00b7gel\u00b7ku\u00b7geln", "rol\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dort steigt ein roter Luftballon,", "tokens": ["Dort", "steigt", "ein", "ro\u00b7ter", "Luft\u00b7bal\u00b7lon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um den die Kinder tollen.", "tokens": ["Um", "den", "die", "Kin\u00b7der", "tol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Musik, Gel\u00e4chter, Hopsasa,", "tokens": ["Mu\u00b7sik", ",", "Ge\u00b7l\u00e4ch\u00b7ter", ",", "Hop\u00b7sa\u00b7sa", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NE", "$,"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.2": {"text": "Wo bleibt das h\u00fcbsche M\u00e4dchen.", "tokens": ["Wo", "bleibt", "das", "h\u00fcb\u00b7sche", "M\u00e4d\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da pl\u00f6tzlich in dem Tralala", "tokens": ["Da", "pl\u00f6tz\u00b7lich", "in", "dem", "Tra\u00b7la\u00b7la"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein allerliebstes K\u00e4thchen.", "tokens": ["Ein", "al\u00b7ler\u00b7liebs\u00b7tes", "K\u00e4th\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Das war ein gar zu liebes Ding,", "tokens": ["Das", "war", "ein", "gar", "zu", "lie\u00b7bes", "Ding", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Goldregen\u00fcberbogen.", "tokens": ["Gold\u00b7re\u00b7gen\u00b7\u00fc\u00b7berb\u00b7o\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Just kam ein kleiner Schmetterling", "tokens": ["Just", "kam", "ein", "klei\u00b7ner", "Schmet\u00b7ter\u00b7ling"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dicht ihr vorbeigeflogen.", "tokens": ["Dicht", "ihr", "vor\u00b7bei\u00b7ge\u00b7flo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ich stutzte \u00fcberraschungsfroh,", "tokens": ["Ich", "stutz\u00b7te", "\u00fc\u00b7berr\u00b7as\u00b7chungs\u00b7froh", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schaut\u2019 ihr in Auges Tiefe.", "tokens": ["Schaut'", "ihr", "in", "Au\u00b7ges", "Tie\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn auch ihr Blick mich immer floh,", "tokens": ["Wenn", "auch", "ihr", "Blick", "mich", "im\u00b7mer", "floh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Augen waren Briefe:", "tokens": ["Die", "Au\u00b7gen", "wa\u00b7ren", "Brie\u00b7fe", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "\u201egeh\u2019 langsam durch den Garten hier,", "tokens": ["\u201e", "geh'", "lang\u00b7sam", "durch", "den", "Gar\u00b7ten", "hier", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADJD", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf buntbelebten Wegen.", "tokens": ["Auf", "bunt\u00b7be\u00b7leb\u00b7ten", "We\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir treffen uns, ich komme dir", "tokens": ["Wir", "tref\u00b7fen", "uns", ",", "ich", "kom\u00b7me", "dir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von ungef\u00e4hr entgegen.\u201c", "tokens": ["Von", "un\u00b7ge\u00b7f\u00e4hr", "ent\u00b7ge\u00b7gen", ".", "\u201c"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJD", "PTKVZ", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "So wandr\u2019 ich denn, und wie der Dieb", "tokens": ["So", "wandr'", "ich", "denn", ",", "und", "wie", "der", "Dieb"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KON", "PWAV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schiel\u2019 ich in N\u00e4h\u2019 und Weite,", "tokens": ["Schiel'", "ich", "in", "N\u00e4h'", "und", "Wei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ob bei der Mutter sie verblieb,", "tokens": ["Ob", "bei", "der", "Mut\u00b7ter", "sie", "ver\u00b7blieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ob sie mir an der Seite.", "tokens": ["Ob", "sie", "mir", "an", "der", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Indessen steht sie neben mir \u2014", "tokens": ["In\u00b7des\u00b7sen", "steht", "sie", "ne\u00b7ben", "mir"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich kann nicht Worte finden.", "tokens": ["Ich", "kann", "nicht", "Wor\u00b7te", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein zwei, drei Zoll lang F\u00e4dchen schier", "tokens": ["Ein", "zwei", ",", "drei", "Zoll", "lang", "F\u00e4d\u00b7chen", "schier"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "CARD", "$,", "CARD", "NN", "ADJD", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "K\u00f6nnt\u2019 uns zusammenbinden.", "tokens": ["K\u00f6nnt'", "uns", "zu\u00b7sam\u00b7men\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Im Saale trommelts, quikt und quackt", "tokens": ["Im", "Saa\u00b7le", "trom\u00b7melts", ",", "quikt", "und", "quackt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "$,", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Geiger und der Pfeifer.", "tokens": ["Der", "Gei\u00b7ger", "und", "der", "Pfei\u00b7fer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir tanzen bald in regem Takt", "tokens": ["Wir", "tan\u00b7zen", "bald", "in", "re\u00b7gem", "Takt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den alten deutschen Schleifer.", "tokens": ["Den", "al\u00b7ten", "deut\u00b7schen", "Schlei\u00b7fer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Ich dr\u00fccke sanft die kleine Hand,", "tokens": ["Ich", "dr\u00fc\u00b7cke", "sanft", "die", "klei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie dr\u00fcckt die Hand mir wieder.", "tokens": ["Sie", "dr\u00fcckt", "die", "Hand", "mir", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo dann den Weg mit ihr ich fand,", "tokens": ["Wo", "dann", "den", "Weg", "mit", "ihr", "ich", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "APPR", "PPOSAT", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da leuchtete der Flieder.", "tokens": ["Da", "leuch\u00b7te\u00b7te", "der", "Flie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Bleib hier, bleib hier, bis Tageslicht", "tokens": ["Bleib", "hier", ",", "bleib", "hier", ",", "bis", "Ta\u00b7ges\u00b7licht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADV", "$,", "VVFIN", "ADV", "$,", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und letztes Rot verblassen.", "tokens": ["Und", "letz\u00b7tes", "Rot", "ver\u00b7blas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201each, Liebster, l\u00e4nger darf ich nicht", "tokens": ["\u201e", "ach", ",", "Liebs\u00b7ter", ",", "l\u00e4n\u00b7ger", "darf", "ich", "nicht"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ITJ", "$,", "NN", "$,", "ADJD", "VMFIN", "PPER", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Mutter warten lassen.\u201c", "tokens": ["Die", "Mut\u00b7ter", "war\u00b7ten", "las\u00b7sen", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Bleib hier, ich zeige dir den Stern,", "tokens": ["Bleib", "hier", ",", "ich", "zei\u00b7ge", "dir", "den", "Stern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo einst wir uns gesehen.", "tokens": ["Wo", "einst", "wir", "uns", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sieht er uns hier vom Himmel fern,", "tokens": ["Sieht", "er", "uns", "hier", "vom", "Him\u00b7mel", "fern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dann bleibt er gr\u00fc\u00dfend stehen.", "tokens": ["Dann", "bleibt", "er", "gr\u00fc\u00b7\u00dfend", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "\u201ela\u00df mich, Herzallerliebster mein,", "tokens": ["\u201e", "la\u00df", "mich", ",", "Her\u00b7zal\u00b7ler\u00b7liebs\u00b7ter", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "$,", "NN", "PPOSAT", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die Mutter sucht im Garten\u201c.", "tokens": ["Die", "Mut\u00b7ter", "sucht", "im", "Gar\u00b7ten", "\u201c", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$(", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So schleiche dir ich hinterdrein,", "tokens": ["So", "schlei\u00b7che", "dir", "ich", "hin\u00b7ter\u00b7drein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und will im Dunkel warten.", "tokens": ["Und", "will", "im", "Dun\u00b7kel", "war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Wenn alles schwarz und still im Haus,", "tokens": ["Wenn", "al\u00b7les", "schwarz", "und", "still", "im", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "KON", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann wart\u2019 ich in der Laube.", "tokens": ["Dann", "wart'", "ich", "in", "der", "Lau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn alles still, dann komm heraus,", "tokens": ["Wenn", "al\u00b7les", "still", ",", "dann", "komm", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKVZ", "$,", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du meine wei\u00dfe Taube.", "tokens": ["Du", "mei\u00b7ne", "wei\u00b7\u00dfe", "Tau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Es klinkt die Th\u00fcr, und gleich darauf", "tokens": ["Es", "klinkt", "die", "Th\u00fcr", ",", "und", "gleich", "da\u00b7rauf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KON", "ADV", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Huscht sie zu mir hernieder,", "tokens": ["Huscht", "sie", "zu", "mir", "her\u00b7nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201epst, nicht so st\u00fcrmisch, h\u00f6r\u2019 doch auf,", "tokens": ["\u201e", "pst", ",", "nicht", "so", "st\u00fcr\u00b7misch", ",", "h\u00f6r'", "doch", "auf", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "PTKNEG", "ADV", "ADJD", "$,", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du weckst die Mutter wieder.\u201c", "tokens": ["Du", "weckst", "die", "Mut\u00b7ter", "wie\u00b7der", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Von tausend Welten \u00fcberdacht,", "tokens": ["Von", "tau\u00b7send", "Wel\u00b7ten", "\u00fc\u00b7berd\u00b7acht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ruhig weiter gehen.", "tokens": ["Die", "ru\u00b7hig", "wei\u00b7ter", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es zog ein Stern um Mitternacht,", "tokens": ["Es", "zog", "ein", "Stern", "um", "Mit\u00b7ter\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gr\u00fc\u00dfend blieb er stehen.", "tokens": ["Und", "gr\u00fc\u00b7\u00dfend", "blieb", "er", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}