{"textgrid.poem.39060": {"metadata": {"author": {"name": "Neuber, Friederike Caroline", "birth": "N.A.", "death": "N.A."}, "title": "Abschied der Neuberschen Gesellschaft aus Hamburg", "genre": "verse", "period": "N.A.", "pub_year": 1740, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "HeRR FABRICIUS.", "tokens": ["HeRR", "FaB\u00b7RI\u00b7CI\u00b7US", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Was sollen wir denn hier? Das St\u00fcck ist ja vorbei?", "tokens": ["Was", "sol\u00b7len", "wir", "denn", "hier", "?", "Das", "St\u00fcck", "ist", "ja", "vor\u00b7bei", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "ADV", "$.", "ART", "NN", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "HeRR MEYER.", "tokens": ["HeRR", "Me\u00b7Y\u00b7ER", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Ich wei\u00df wahrhaftig nicht, was dieser Anhang sei,", "tokens": ["Ich", "wei\u00df", "wahr\u00b7haf\u00b7tig", "nicht", ",", "was", "die\u00b7ser", "An\u00b7hang", "sei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKNEG", "$,", "PWS", "PDAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der unvermuthet kommt.", "tokens": ["Der", "un\u00b7ver\u00b7mu\u00b7thet", "kommt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "MaDAME NEUBER.", "tokens": ["Ma\u00b7DA\u00b7ME", "NeU\u00b7BER", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Geduld, gebt euch zufrieden!", "tokens": ["Ge\u00b7duld", ",", "gebt", "euch", "zu\u00b7frie\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "HeRR SUPPIG.", "tokens": ["HeRR", "SuP\u00b7PIG", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.8": {"line.1": {"text": "Damit ists nicht genug.", "tokens": ["Da\u00b7mit", "ists", "nicht", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Hr. MEYER.", "tokens": ["Hr.", "Me\u00b7Y\u00b7ER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Wir sind hieher beschieden,", "tokens": ["Wir", "sind", "hie\u00b7her", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "und wissen nicht warum.", "tokens": ["und", "wis\u00b7sen", "nicht", "wa\u00b7rum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PWAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Hr. SUPPIG.", "tokens": ["Hr.", "SuP\u00b7PIG", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.12": {"line.1": {"text": "Was ists? Was wird denn draus?", "tokens": ["Was", "ists", "?", "Was", "wird", "denn", "draus", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$.", "PWS", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Md. NEUBER.", "tokens": ["Md.", "NeU\u00b7BER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.14": {"line.1": {"text": "Ich f\u00fchr euch allesammt mit Ehren aus dem Haus.", "tokens": ["Ich", "f\u00fchr", "euch", "al\u00b7le\u00b7sammt", "mit", "Eh\u00b7ren", "aus", "dem", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht durch Betrug und List: nein, recht wie sichs geb\u00fchret.", "tokens": ["Nicht", "durch", "Be\u00b7trug", "und", "List", ":", "nein", ",", "recht", "wie", "sichs", "ge\u00b7b\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "KON", "NN", "$.", "PTKANT", "$,", "ADJD", "KOKOM", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich hab euch zwar hieher in diese Noth gef\u00fchret;", "tokens": ["Ich", "hab", "euch", "zwar", "hie\u00b7her", "in", "die\u00b7se", "Noth", "ge\u00b7f\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PAV", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "alleine recht mit Zwang. Ich hab mich recht gewehrt.", "tokens": ["al\u00b7lei\u00b7ne", "recht", "mit", "Zwang", ".", "Ich", "hab", "mich", "recht", "ge\u00b7wehrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "$.", "PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich wu\u00dfte, da\u00df dies Haus den Segen selbst verzehrt;", "tokens": ["Ich", "wu\u00df\u00b7te", ",", "da\u00df", "dies", "Haus", "den", "Se\u00b7gen", "selbst", "ver\u00b7zehrt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PDS", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "und dennoch trat ich ein. Die Schwachheit einer Frauen,", "tokens": ["und", "den\u00b7noch", "trat", "ich", "ein", ".", "Die", "Schwach\u00b7heit", "ei\u00b7ner", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "vermag doch wohl einmal auch einen Mann zu trauen?", "tokens": ["ver\u00b7mag", "doch", "wohl", "ein\u00b7mal", "auch", "ei\u00b7nen", "Mann", "zu", "trau\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADV", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Genug: ich rett uns nun aus Elend und Gefahr,", "tokens": ["Ge\u00b7nug", ":", "ich", "rett", "uns", "nun", "aus", "E\u00b7lend", "und", "Ge\u00b7fahr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "die uns durch Eigennutz und List gedrohet war.", "tokens": ["die", "uns", "durch", "Ei\u00b7gen\u00b7nutz", "und", "List", "ge\u00b7dro\u00b7het", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "KON", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Hr. SUPPIG.", "tokens": ["Hr.", "SuP\u00b7PIG", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.16": {"line.1": {"text": "Der Spa\u00df kost nur viel Geld.", "tokens": ["Der", "Spa\u00df", "kost", "nur", "viel", "Geld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Hr. FABRICIUS.", "tokens": ["Hr.", "FaB\u00b7RI\u00b7CI\u00b7US", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.18": {"line.1": {"text": "Mein Freund was ist zu machen?", "tokens": ["Mein", "Freund", "was", "ist", "zu", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PWS", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Md. NEUBER.", "tokens": ["Md.", "NeU\u00b7BER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.20": {"line.1": {"text": "Geduld! Die Redlichkeit kann doch am Ende lachen,", "tokens": ["Ge\u00b7duld", "!", "Die", "Red\u00b7lich\u00b7keit", "kann", "doch", "am", "En\u00b7de", "la\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VMFIN", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "wenn List und Eigennutz sich selber nagt und fri\u00dft;", "tokens": ["wenn", "List", "und", "Ei\u00b7gen\u00b7nutz", "sich", "sel\u00b7ber", "nagt", "und", "fri\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PRF", "ADV", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die Unschuld hintergeht.", "tokens": ["die", "Un\u00b7schuld", "hin\u00b7ter\u00b7geht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Hr. FABRICIUS.", "tokens": ["Hr.", "FaB\u00b7RI\u00b7CI\u00b7US", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Wenn das Dein Trost noch ist", "tokens": ["Wenn", "das", "Dein", "Trost", "noch", "ist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "PPOSAT", "NN", "ADV", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "so mag es immer sein.", "tokens": ["so", "mag", "es", "im\u00b7mer", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Hr. SUPPIG.", "tokens": ["Hr.", "SuP\u00b7PIG", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.24": {"line.1": {"text": "Das kann mich auch erg\u00f6tzen.", "tokens": ["Das", "kann", "mich", "auch", "er\u00b7g\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Hr. MEYER.", "tokens": ["Hr.", "Me\u00b7Y\u00b7ER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.26": {"line.1": {"text": "Der Himmel kann es auch ja wieder reich ersetzen.", "tokens": ["Der", "Him\u00b7mel", "kann", "es", "auch", "ja", "wie\u00b7der", "reich", "er\u00b7set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Md. NEUBER.", "tokens": ["Md.", "NeU\u00b7BER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.28": {"line.1": {"text": "Ach ja, das wird er thun. Er f\u00e4ngt jetzund schon an.", "tokens": ["Ach", "ja", ",", "das", "wird", "er", "thun", ".", "Er", "f\u00e4ngt", "je\u00b7tzund", "schon", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$,", "PDS", "VAFIN", "PPER", "VVINF", "$.", "PPER", "VVFIN", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Hr. FABRICIUS.", "tokens": ["Hr.", "FaB\u00b7RI\u00b7CI\u00b7US", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.30": {"line.1": {"text": "So mag das immer sein, was man uns angethan.", "tokens": ["So", "mag", "das", "im\u00b7mer", "sein", ",", "was", "man", "uns", "an\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PDS", "ADV", "VAINF", "$,", "PRELS", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vergeben, redlich sein, sind lauter gro\u00dfe Dinge.", "tokens": ["Ver\u00b7ge\u00b7ben", ",", "red\u00b7lich", "sein", ",", "sind", "lau\u00b7ter", "gro\u00b7\u00dfe", "Din\u00b7ge", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "VAINF", "$,", "VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Md. NEUBER.", "tokens": ["Md.", "NeU\u00b7BER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.32": {"line.1": {"text": "Wenn ich euch allerseits nun jetzt die Nachricht bringe:", "tokens": ["Wenn", "ich", "euch", "al\u00b7ler\u00b7seits", "nun", "jetzt", "die", "Nach\u00b7richt", "brin\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df selbst der Geiz, die List, und was man B\u00f6ses nennt,", "tokens": ["Da\u00df", "selbst", "der", "Geiz", ",", "die", "List", ",", "und", "was", "man", "B\u00f6\u00b7ses", "nennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "$,", "ART", "NN", "$,", "KON", "PWS", "PIS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "uns nicht mehr schaden kann; da\u00df uns Gott Gutes g\u00f6nnt;", "tokens": ["uns", "nicht", "mehr", "scha\u00b7den", "kann", ";", "da\u00df", "uns", "Gott", "Gu\u00b7tes", "g\u00f6nnt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "VVINF", "VMFIN", "$.", "KOUS", "PPER", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "da\u00df er uns gl\u00fccklich macht, und ruhig will erhalten:", "tokens": ["da\u00df", "er", "uns", "gl\u00fcck\u00b7lich", "macht", ",", "und", "ru\u00b7hig", "will", "er\u00b7hal\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVFIN", "$,", "KON", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "daf\u00fcr mu\u00df unser Dank zu keiner Zeit erkalten.", "tokens": ["da\u00b7f\u00fcr", "mu\u00df", "un\u00b7ser", "Dank", "zu", "kei\u00b7ner", "Zeit", "er\u00b7kal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ihr Freunde! werfet nun den Kummer und Verdru\u00df", "tokens": ["Ihr", "Freun\u00b7de", "!", "wer\u00b7fet", "nun", "den", "Kum\u00b7mer", "und", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "ADV", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "in diesen alten Staub, werft ihn vor eurem Fu\u00df:", "tokens": ["in", "die\u00b7sen", "al\u00b7ten", "Staub", ",", "werft", "ihn", "vor", "eu\u00b7rem", "Fu\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "und denkt an nichts als Dank und billiges verehren,", "tokens": ["und", "denkt", "an", "nichts", "als", "Dank", "und", "bil\u00b7li\u00b7ges", "ver\u00b7eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIS", "KOKOM", "NN", "KON", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "h\u00f6rt auf mit Klag und Angst, mit \u00c4rgern und Beschweren,", "tokens": ["h\u00f6rt", "auf", "mit", "Klag", "und", "Angst", ",", "mit", "\u00c4r\u00b7gern", "und", "Be\u00b7schwe\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "und la\u00dft mir nun den Ruhm, da\u00df keine wahre Pflicht", "tokens": ["und", "la\u00dft", "mir", "nun", "den", "Ruhm", ",", "da\u00df", "kei\u00b7ne", "wah\u00b7re", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "ADV", "ART", "NN", "$,", "KOUS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "von mir vergessen wird. Verst\u00f6rt mich jetzund nicht,", "tokens": ["von", "mir", "ver\u00b7ges\u00b7sen", "wird", ".", "Ver\u00b7st\u00f6rt", "mich", "je\u00b7tzund", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAFIN", "$.", "VVFIN", "PPER", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "ich mu\u00df die Schuldigkeit f\u00fcrs Gute nicht vergessen,", "tokens": ["ich", "mu\u00df", "die", "Schul\u00b7dig\u00b7keit", "f\u00fcrs", "Gu\u00b7te", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPRART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Das B\u00f6se mit Vernunft und mit Geduld ermessen.", "tokens": ["Das", "B\u00f6\u00b7se", "mit", "Ver\u00b7nunft", "und", "mit", "Ge\u00b7duld", "er\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Darinnen kommt der Ruhm, auch wiederum zur\u00fcck", "tokens": ["Da\u00b7rin\u00b7nen", "kommt", "der", "Ruhm", ",", "auch", "wie\u00b7de\u00b7rum", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "ADV", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "an euch, und euren Ruhm, an eure Ruh und Gl\u00fcck.", "tokens": ["an", "euch", ",", "und", "eu\u00b7ren", "Ruhm", ",", "an", "eu\u00b7re", "Ruh", "und", "Gl\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KON", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Hr. FABRICIUS.", "tokens": ["Hr.", "FaB\u00b7RI\u00b7CI\u00b7US", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.34": {"line.1": {"text": "Sprich nur, soviel Du kannst, wir wollen Dich nicht st\u00f6ren.", "tokens": ["Sprich", "nur", ",", "so\u00b7viel", "Du", "kannst", ",", "wir", "wol\u00b7len", "Dich", "nicht", "st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$,", "VVFIN", "PPER", "VMFIN", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Hr. SUPPIG.", "tokens": ["Hr.", "SuP\u00b7PIG", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.36": {"line.1": {"text": "Ach ja, das will ich gern und auch geduldig h\u00f6ren.", "tokens": ["Ach", "ja", ",", "das", "will", "ich", "gern", "und", "auch", "ge\u00b7dul\u00b7dig", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$,", "PDS", "VMFIN", "PPER", "ADV", "KON", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Hr. MEYER.", "tokens": ["Hr.", "Me\u00b7Y\u00b7ER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.38": {"line.1": {"text": "Wir andern stimmen bei und wollen stille sein.", "tokens": ["Wir", "an\u00b7dern", "stim\u00b7men", "bei", "und", "wol\u00b7len", "stil\u00b7le", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VVFIN", "APPR", "KON", "VMFIN", "PIS", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.39": {"line.1": {"text": "Md. NEUBER.", "tokens": ["Md.", "NeU\u00b7BER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.40": {"line.1": {"text": "Durch dies wird Gl\u00fcck und Ruh f\u00fcr euch auch allgemein.", "tokens": ["Durch", "dies", "wird", "Gl\u00fcck", "und", "Ruh", "f\u00fcr", "euch", "auch", "all\u00b7ge\u00b7mein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "NN", "KON", "NN", "APPR", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ihr Freunde schickt den Wunsch zugleich aus euren Herzen,", "tokens": ["Ihr", "Freun\u00b7de", "schickt", "den", "Wunsch", "zu\u00b7gleich", "aus", "eu\u00b7ren", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und la\u00dft uns alle Noth bei Gl\u00fcck und Ruh verschmerzen.", "tokens": ["Und", "la\u00dft", "uns", "al\u00b7le", "Noth", "bei", "Gl\u00fcck", "und", "Ruh", "ver\u00b7schmer\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "PIAT", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Heut sag ich auch im Gl\u00fcck an Dich ein wahres Wort,", "tokens": ["Heut", "sag", "ich", "auch", "im", "Gl\u00fcck", "an", "Dich", "ein", "wah\u00b7res", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gesegnet, benedeit, wahrhaftig sch\u00f6ner Ort,", "tokens": ["Ge\u00b7seg\u00b7net", ",", "be\u00b7ne\u00b7deit", ",", "wahr\u00b7haf\u00b7tig", "sch\u00f6\u00b7ner", "Ort", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "mein Hamburg! La\u00df mich doch zwei St\u00fcck in Dir betrachten", "tokens": ["mein", "Ham\u00b7burg", "!", "La\u00df", "mich", "doch", "zwei", "St\u00fcck", "in", "Dir", "be\u00b7trach\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NE", "$.", "VVIMP", "PPER", "ADV", "CARD", "NN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "und jedes nach den Werth und seine Gr\u00f6\u00dfe achten.", "tokens": ["und", "je\u00b7des", "nach", "den", "Werth", "und", "sei\u00b7ne", "Gr\u00f6\u00b7\u00dfe", "ach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "APPR", "ART", "NN", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ihr Freunde habt Geduld! Heut gehts die Feinde an,", "tokens": ["Ihr", "Freun\u00b7de", "habt", "Ge\u00b7duld", "!", "Heut", "gehts", "die", "Fein\u00b7de", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "weil sie der Rang betrifft, und sie sehr viel gethan", "tokens": ["weil", "sie", "der", "Rang", "be\u00b7tr\u00b7ifft", ",", "und", "sie", "sehr", "viel", "ge\u00b7than"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "KON", "PPER", "ADV", "ADV", "VVPP"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "zu meinem Untergang. Ich will mich nicht beschweren", "tokens": ["zu", "mei\u00b7nem", "Un\u00b7ter\u00b7gang", ".", "Ich", "will", "mich", "nicht", "be\u00b7schwe\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "und sie aus Dankbarkeit vielmehr noch daf\u00fcr ehren.", "tokens": ["und", "sie", "aus", "Dank\u00b7bar\u00b7keit", "viel\u00b7mehr", "noch", "da\u00b7f\u00fcr", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "ADV", "ADV", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Hier h\u00e4lt mich wenig Gunst und kein Verdienst zur\u00fcck,", "tokens": ["Hier", "h\u00e4lt", "mich", "we\u00b7nig", "Gunst", "und", "kein", "Ver\u00b7dienst", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "KON", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "drum g\u00f6nnet wenigstens Euch und mir dieses Gl\u00fcck,", "tokens": ["drum", "g\u00f6n\u00b7net", "we\u00b7nigs\u00b7tens", "Euch", "und", "mir", "die\u00b7ses", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "PPER", "KON", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "da\u00df Ihr uns nicht mehr seht. Vielleicht da\u00df Zeiten kommen,", "tokens": ["da\u00df", "Ihr", "uns", "nicht", "mehr", "seht", ".", "Viel\u00b7leicht", "da\u00df", "Zei\u00b7ten", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "ADV", "VVFIN", "$.", "ADV", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "in welchen Ihr und wir in allen zugenommen,", "tokens": ["in", "wel\u00b7chen", "Ihr", "und", "wir", "in", "al\u00b7len", "zu\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PPOSAT", "KON", "PPER", "APPR", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "was unser Schauspiel gro\u00df und Euch erkenntlich macht:", "tokens": ["was", "un\u00b7ser", "Schau\u00b7spiel", "gro\u00df", "und", "Euch", "er\u00b7kennt\u00b7lich", "macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ADJD", "KON", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "nur gebt auf den Hanswurst in Zukunft besser Acht,", "tokens": ["nur", "gebt", "auf", "den", "Hans\u00b7wurst", "in", "Zu\u00b7kunft", "bes\u00b7ser", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "ADJD", "CARD", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.18": {"text": "da\u00df er nicht Hungers stirbt und Euch mehr Schulden spielet,", "tokens": ["da\u00df", "er", "nicht", "Hun\u00b7gers", "stirbt", "und", "Euch", "mehr", "Schul\u00b7den", "spie\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "NN", "VVFIN", "KON", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "in seinem Zotenkram, die Ihr im Herzen f\u00fchlet.", "tokens": ["in", "sei\u00b7nem", "Zo\u00b7ten\u00b7kram", ",", "die", "Ihr", "im", "Her\u00b7zen", "f\u00fch\u00b7let", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "aus unbekannter Luft. La\u00dft ihn bei Euch erziehn,", "tokens": ["aus", "un\u00b7be\u00b7kann\u00b7ter", "Luft", ".", "La\u00dft", "ihn", "bei", "Euch", "er\u00b7ziehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "VVIMP", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "belehrt ihn, macht ihn gro\u00df, und gebt ihm eure Werke", "tokens": ["be\u00b7lehrt", "ihn", ",", "macht", "ihn", "gro\u00df", ",", "und", "gebt", "ihm", "eu\u00b7re", "Wer\u00b7ke"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADJD", "$,", "KON", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "recht mit Gelehrsamkeit mit gr\u00f6\u00dfter Weisheit St\u00e4rke:", "tokens": ["recht", "mit", "Ge\u00b7lehr\u00b7sam\u00b7keit", "mit", "gr\u00f6\u00df\u00b7ter", "Weis\u00b7heit", "St\u00e4r\u00b7ke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "ADJA", "NN", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.23": {"text": "zum Segen sch\u00fctzet ihn, nehmt ihn zum Vorbild an,", "tokens": ["zum", "Se\u00b7gen", "sch\u00fct\u00b7zet", "ihn", ",", "nehmt", "ihn", "zum", "Vor\u00b7bild", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "vielleicht da\u00df dieser Euch geschickter bessern kann,", "tokens": ["viel\u00b7leicht", "da\u00df", "die\u00b7ser", "Euch", "ge\u00b7schick\u00b7ter", "bes\u00b7sern", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PDAT", "PPER", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "wenn Ihr den Unterschied von wahr und falschen Sachen", "tokens": ["wenn", "Ihr", "den", "Un\u00b7ter\u00b7schied", "von", "wahr", "und", "fal\u00b7schen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "an ihm erkennen lernt, und Euch k\u00f6nnt besser machen.", "tokens": ["an", "ihm", "er\u00b7ken\u00b7nen", "lernt", ",", "und", "Euch", "k\u00f6nnt", "bes\u00b7ser", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVINF", "VVFIN", "$,", "KON", "PPER", "VVFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Den Worten f\u00fcg ich hier die Kraft der Wahrheit bei.", "tokens": ["Den", "Wor\u00b7ten", "f\u00fcg", "ich", "hier", "die", "Kraft", "der", "Wahr\u00b7heit", "bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ihr seid selbst \u00fcberzeugt, da\u00df es so gr\u00fcndlich sei", "tokens": ["Ihr", "seid", "selbst", "\u00fc\u00b7berz\u00b7eugt", ",", "da\u00df", "es", "so", "gr\u00fcnd\u00b7lich", "sei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "als euer Vorsatz ist, nichts Gutes zu ern\u00e4hren:", "tokens": ["als", "eu\u00b7er", "Vor\u00b7satz", "ist", ",", "nichts", "Gu\u00b7tes", "zu", "er\u00b7n\u00e4h\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VAFIN", "$,", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "als eure Klugheit steigt, die Unschuld zu verheeren,", "tokens": ["als", "eu\u00b7re", "Klug\u00b7heit", "steigt", ",", "die", "Un\u00b7schuld", "zu", "ver\u00b7hee\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "die Ihr doch nicht erbaut, nicht kennt, nicht haben wollt,", "tokens": ["die", "Ihr", "doch", "nicht", "er\u00b7baut", ",", "nicht", "kennt", ",", "nicht", "ha\u00b7ben", "wollt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PTKNEG", "VVPP", "$,", "PTKNEG", "VVFIN", "$,", "PTKNEG", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "und wenn sie Euch nur Salz und Wasser kosten sollt,", "tokens": ["und", "wenn", "sie", "Euch", "nur", "Salz", "und", "Was\u00b7ser", "kos\u00b7ten", "sollt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "ADV", "NN", "KON", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "dabei das Brot doch fehlt, das man den Bettlern reichet,", "tokens": ["da\u00b7bei", "das", "Brot", "doch", "fehlt", ",", "das", "man", "den", "Bett\u00b7lern", "rei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADV", "VVFIN", "$,", "PRELS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "ihm nicht die Bissen z\u00e4hlt und schlechter nicht vergleichet,", "tokens": ["ihm", "nicht", "die", "Bis\u00b7sen", "z\u00e4hlt", "und", "schlech\u00b7ter", "nicht", "ver\u00b7glei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ART", "NN", "VVFIN", "KON", "ADJD", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "als er es w\u00fcrdig ist. Seht! nun erkl\u00e4r ich mich,", "tokens": ["als", "er", "es", "w\u00fcr\u00b7dig", "ist", ".", "Seht", "!", "nun", "er\u00b7kl\u00e4r", "ich", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VAFIN", "$.", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "bedenkt: mein Vorsatz war, da\u00df sag ich \u00f6ffentlich,", "tokens": ["be\u00b7denkt", ":", "mein", "Vor\u00b7satz", "war", ",", "da\u00df", "sag", "ich", "\u00f6f\u00b7fent\u00b7lich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPOSAT", "NN", "VAFIN", "$,", "KOUS", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.37": {"text": "da\u00df unserm deutschen Reich kein Vorzug sollt gebrechen", "tokens": ["da\u00df", "un\u00b7serm", "deut\u00b7schen", "Reich", "kein", "Vor\u00b7zug", "sollt", "ge\u00b7bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PIAT", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "in einer Kleinigkeit, so werdet ihr selbst sprechen,", "tokens": ["in", "ei\u00b7ner", "Klei\u00b7nig\u00b7keit", ",", "so", "wer\u00b7det", "ihr", "selbst", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "denn von der Schauspielkunst habt ihr sehr wenig Licht,", "tokens": ["denn", "von", "der", "Schau\u00b7spiel\u00b7kunst", "habt", "ihr", "sehr", "we\u00b7nig", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "weils Euch an Z\u00e4rtlichkeit, Natur und Kunst gebricht", "tokens": ["weils", "Euch", "an", "Z\u00e4rt\u00b7lich\u00b7keit", ",", "Na\u00b7tur", "und", "Kunst", "ge\u00b7bricht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Das Lesen langt nicht zu, auch nicht nach Frankreich reisen,", "tokens": ["Das", "Le\u00b7sen", "langt", "nicht", "zu", ",", "auch", "nicht", "nach", "Fran\u00b7kreich", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "PTKVZ", "$,", "ADV", "PTKNEG", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "ein Schauspiel recht verstehn, erfordert einen weisen", "tokens": ["ein", "Schau\u00b7spiel", "recht", "ver\u00b7stehn", ",", "er\u00b7for\u00b7dert", "ei\u00b7nen", "wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVINF", "$,", "VVFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "wahrhaftig klugen Mann, der jede Wahrheit kennt,", "tokens": ["wahr\u00b7haf\u00b7tig", "klu\u00b7gen", "Mann", ",", "der", "je\u00b7de", "Wahr\u00b7heit", "kennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "die Tugend redlich liebt, und dem das Leben g\u00f6nnt,", "tokens": ["die", "Tu\u00b7gend", "red\u00b7lich", "liebt", ",", "und", "dem", "das", "Le\u00b7ben", "g\u00f6nnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,", "KON", "ART", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "der Flei\u00df und Wissenschaft pflichtm\u00e4\u00dfig treibt und \u00fcbet,", "tokens": ["der", "Flei\u00df", "und", "Wis\u00b7sen\u00b7schaft", "pflicht\u00b7m\u00e4\u00b7\u00dfig", "treibt", "und", "\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADJD", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "der nicht blos um Gewinnst das wahre Gute liebet,", "tokens": ["der", "nicht", "blos", "um", "Ge\u00b7winnst", "das", "wah\u00b7re", "Gu\u00b7te", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.47": {"text": "nein! der dem Guten folgt, und h\u00e4tt' er nichts als Hohn,", "tokens": ["nein", "!", "der", "dem", "Gu\u00b7ten", "folgt", ",", "und", "h\u00e4tt'", "er", "nichts", "als", "Hohn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ART", "ART", "NN", "VVFIN", "$,", "KON", "VAFIN", "PPER", "PIS", "KOKOM", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.48": {"text": "der kleinen Geister Ha\u00df und Sp\u00f6tterei zum Lohn;", "tokens": ["der", "klei\u00b7nen", "Geis\u00b7ter", "Ha\u00df", "und", "Sp\u00f6t\u00b7te\u00b7rei", "zum", "Lohn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "dem auch der Mangel lieb: wenn er sich nur mit Ehren", "tokens": ["dem", "auch", "der", "Man\u00b7gel", "lieb", ":", "wenn", "er", "sich", "nur", "mit", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "ADJD", "$.", "KOUS", "PPER", "PRF", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "aus der Beschimpfung rei\u00dft, womit ihn die beschweren", "tokens": ["aus", "der", "Be\u00b7schimp\u00b7fung", "rei\u00dft", ",", "wo\u00b7mit", "ihn", "die", "be\u00b7schwe\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "ART", "ADJA"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.51": {"text": "die seine Feinde sind. Ist dieses recht gethan", "tokens": ["die", "sei\u00b7ne", "Fein\u00b7de", "sind", ".", "Ist", "die\u00b7ses", "recht", "ge\u00b7than"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "$.", "VAFIN", "PDAT", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "so nehmt auch, was ich sag, von mir vern\u00fcnftig an.", "tokens": ["so", "nehmt", "auch", ",", "was", "ich", "sag", ",", "von", "mir", "ver\u00b7n\u00fcnf\u00b7tig", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "PWS", "PPER", "VVFIN", "$,", "APPR", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Geht selbst in Euer Herz, das wird Euch deutlich sagen,", "tokens": ["Geht", "selbst", "in", "Eu\u00b7er", "Herz", ",", "das", "wird", "Euch", "deut\u00b7lich", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,", "PDS", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "warum ich Euch so frei die Wahrheit vorgetragen.", "tokens": ["wa\u00b7rum", "ich", "Euch", "so", "frei", "die", "Wahr\u00b7heit", "vor\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Glaubt, da\u00df hier weder Stolz noch Frechheit aus mir spricht,", "tokens": ["Glaubt", ",", "da\u00df", "hier", "we\u00b7der", "Stolz", "noch", "Frech\u00b7heit", "aus", "mir", "spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "KON", "NN", "ADV", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "und auch kein \u00dcbermuth. Darum verwerft dies nicht.", "tokens": ["und", "auch", "kein", "\u00dc\u00b7ber\u00b7muth", ".", "Da\u00b7rum", "ver\u00b7werft", "dies", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "$.", "PAV", "VVFIN", "PDS", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Es liegt ein wahrer Dank in diesem Salz verborgen.", "tokens": ["Es", "liegt", "ein", "wah\u00b7rer", "Dank", "in", "die\u00b7sem", "Salz", "ver\u00b7bor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Ich lieb und ehr in Euch wahrhaftig alle Sorgen,", "tokens": ["Ich", "lieb", "und", "ehr", "in", "Euch", "wahr\u00b7haf\u00b7tig", "al\u00b7le", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "KON", "NN", "APPR", "PPER", "ADJD", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Verlust und alle M\u00fch, die Ihr mir schwer gemacht;", "tokens": ["Ver\u00b7lust", "und", "al\u00b7le", "M\u00fch", ",", "die", "Ihr", "mir", "schwer", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PIAT", "NN", "$,", "PRELS", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "weil Ihr mich doch dadurch zu keiner That gebracht,", "tokens": ["weil", "Ihr", "mich", "doch", "da\u00b7durch", "zu", "kei\u00b7ner", "That", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PAV", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "die mich besch\u00e4men k\u00f6nnt. Die Schulden sind verschwunden,", "tokens": ["die", "mich", "be\u00b7sch\u00e4\u00b7men", "k\u00f6nnt", ".", "Die", "Schul\u00b7den", "sind", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VVFIN", "$.", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "die ich aus Noth gemacht. Der Nutzen ist gefunden", "tokens": ["die", "ich", "aus", "Noth", "ge\u00b7macht", ".", "Der", "Nut\u00b7zen", "ist", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRELS", "PPER", "APPR", "NN", "VVPP", "$.", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "der Euch daraus erw\u00e4chst. Ich bin gesch\u00e4tzt, vergn\u00fcgt,", "tokens": ["der", "Euch", "da\u00b7raus", "er\u00b7w\u00e4chst", ".", "Ich", "bin", "ge\u00b7sch\u00e4tzt", ",", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "PAV", "VVFIN", "$.", "PPER", "VAFIN", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "versorgt, belohnt, gesucht. Das Gl\u00fcck nun \u00fcberwiegt", "tokens": ["ver\u00b7sorgt", ",", "be\u00b7lohnt", ",", "ge\u00b7sucht", ".", "Das", "Gl\u00fcck", "nun", "\u00fc\u00b7berw\u00b7iegt"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "VVPP", "$,", "VVPP", "$.", "ART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Es war mein Untergang bei Euch schon abgez\u00e4hlet,", "tokens": ["Es", "war", "mein", "Un\u00b7ter\u00b7gang", "bei", "Euch", "schon", "ab\u00b7ge\u00b7z\u00e4h\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "APPR", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Das Ende wu\u00dftet Ihr durch die Verhindrung schon,", "tokens": ["Das", "En\u00b7de", "wu\u00df\u00b7tet", "Ihr", "durch", "die", "Ver\u00b7hin\u00b7drung", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "und doch geschieht es nicht. Was habt Ihr nun davon?", "tokens": ["und", "doch", "ge\u00b7schieht", "es", "nicht", ".", "Was", "habt", "Ihr", "nun", "da\u00b7von", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKNEG", "$.", "PWS", "VAFIN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Ja nichts. Ein bischen Wind, ein halbes St\u00fcndchen Lachen.", "tokens": ["Ja", "nichts", ".", "Ein", "bi\u00b7schen", "Wind", ",", "ein", "hal\u00b7bes", "St\u00fcnd\u00b7chen", "La\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PIS", "$.", "ART", "ADV", "NN", "$,", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Ich wills Euch doch zum Ruhm gewi\u00df viel besser machen.", "tokens": ["Ich", "wills", "Euch", "doch", "zum", "Ruhm", "ge\u00b7wi\u00df", "viel", "bes\u00b7ser", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "APPRART", "NN", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "So wenig ihr mit Zwang uns habt zu gut gethan,", "tokens": ["So", "we\u00b7nig", "ihr", "mit", "Zwang", "uns", "habt", "zu", "gut", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPOSAT", "APPR", "NN", "PPER", "VAFIN", "PTKA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "so wahrhaft nehm ich es mit Dank und Einsicht an.", "tokens": ["so", "wahr\u00b7haft", "nehm", "ich", "es", "mit", "Dank", "und", "Ein\u00b7sicht", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "und brauch das wenige was gro\u00dfes zu verrichten.", "tokens": ["und", "brauch", "das", "we\u00b7ni\u00b7ge", "was", "gro\u00b7\u00dfes", "zu", "ver\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "PIS", "PWS", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Sprecht: handle ich nicht recht nach allen solchen Pflichten,", "tokens": ["Sprecht", ":", "hand\u00b7le", "ich", "nicht", "recht", "nach", "al\u00b7len", "sol\u00b7chen", "Pflich\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "VVFIN", "PPER", "PTKNEG", "ADJD", "APPR", "PIAT", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "die Zucht und Tugenden nicht meiden, ha\u00dfen, fliehn,", "tokens": ["die", "Zucht", "und", "Tu\u00b7gen\u00b7den", "nicht", "mei\u00b7den", ",", "ha\u00b7\u00dfen", ",", "fliehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "PTKNEG", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "und kann ich nicht getrost, mit Ehren von Euch ziehn?", "tokens": ["und", "kann", "ich", "nicht", "ge\u00b7trost", ",", "mit", "Eh\u00b7ren", "von", "Euch", "ziehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "VVPP", "$,", "APPR", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Wahrhaftig! recht getrost! Gelassen und mit Freuden", "tokens": ["Wahr\u00b7haf\u00b7tig", "!", "recht", "ge\u00b7trost", "!", "Ge\u00b7las\u00b7sen", "und", "mit", "Freu\u00b7den"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "ADJD", "VVPP", "$.", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "und dankbar will ich hier von meinen Feinden scheiden.", "tokens": ["und", "dank\u00b7bar", "will", "ich", "hier", "von", "mei\u00b7nen", "Fein\u00b7den", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Nun Freunde kommts an Euch! Ruhm, Dank und Z\u00e4rtlichkeit", "tokens": ["Nun", "Freun\u00b7de", "kommts", "an", "Euch", "!", "Ruhm", ",", "Dank", "und", "Z\u00e4rt\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NN", "VVFIN", "APPR", "PPER", "$.", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "erfordert mehr von mir, als die Beredsamkeit", "tokens": ["er\u00b7for\u00b7dert", "mehr", "von", "mir", ",", "als", "die", "Be\u00b7red\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "die im Zusammenhang viel sch\u00f6ne Worte bindet,", "tokens": ["die", "im", "Zu\u00b7sam\u00b7men\u00b7hang", "viel", "sch\u00f6\u00b7ne", "Wor\u00b7te", "bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "und doch ein altes Lied mit neuer Art erfindet.", "tokens": ["und", "doch", "ein", "al\u00b7tes", "Lied", "mit", "neu\u00b7er", "Art", "er\u00b7fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "In meinem Gl\u00fcck, belohnt Gott eure G\u00fctigkeit", "tokens": ["In", "mei\u00b7nem", "Gl\u00fcck", ",", "be\u00b7lohnt", "Gott", "eu\u00b7re", "G\u00fc\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VVFIN", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "weit mehr, als mein Verdienst und meine Leidenszeit,", "tokens": ["weit", "mehr", ",", "als", "mein", "Ver\u00b7dienst", "und", "mei\u00b7ne", "Lei\u00b7dens\u00b7zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "KOUS", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "damit Ihr nicht besch\u00e4mt und heimlich Freunde hei\u00dfet,", "tokens": ["da\u00b7mit", "Ihr", "nicht", "be\u00b7sch\u00e4mt", "und", "heim\u00b7lich", "Freun\u00b7de", "hei\u00b7\u00dfet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "KON", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "das Euch die Allmachtshand durch unsre Gl\u00fcck beweiset.", "tokens": ["das", "Euch", "die", "All\u00b7machts\u00b7hand", "durch", "uns\u00b7re", "Gl\u00fcck", "be\u00b7wei\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Gott hat an mich gedacht in Elend und Gefahr", "tokens": ["Gott", "hat", "an", "mich", "ge\u00b7dacht", "in", "E\u00b7lend", "und", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "APPR", "PPER", "VVPP", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "zur Zeit, da Euch selbst bang um meine Wohlfahrt war.", "tokens": ["zur", "Zeit", ",", "da", "Euch", "selbst", "bang", "um", "mei\u00b7ne", "Wohl\u00b7fahrt", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Allein er wu\u00dfte schon wie er mich retten wollte,", "tokens": ["Al\u00b7lein", "er", "wu\u00df\u00b7te", "schon", "wie", "er", "mich", "ret\u00b7ten", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "KOKOM", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "---+--+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.89": {"text": "und r\u00fchrte euer Herz, das mich erhalten sollte,", "tokens": ["und", "r\u00fchr\u00b7te", "eu\u00b7er", "Herz", ",", "das", "mich", "er\u00b7hal\u00b7ten", "soll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "bis seine Zeit erschien. Sie kam und ist jetzt da.", "tokens": ["bis", "sei\u00b7ne", "Zeit", "er\u00b7schien", ".", "Sie", "kam", "und", "ist", "jetzt", "da", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$.", "PPER", "VVFIN", "KON", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Ihr wahren Freunde, sagt zu meiner Wohlfahrt, ja!", "tokens": ["Ihr", "wah\u00b7ren", "Freun\u00b7de", ",", "sagt", "zu", "mei\u00b7ner", "Wohl\u00b7fahrt", ",", "ja", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Ihr g\u00f6nnt uns unsre Ruh, den Ruhm zu Eurer Ehre", "tokens": ["Ihr", "g\u00f6nnt", "uns", "uns\u00b7re", "Ruh", ",", "den", "Ruhm", "zu", "Eu\u00b7rer", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "so gern, als wenn ich noch bei Euch geblieben w\u00e4re,", "tokens": ["so", "gern", ",", "als", "wenn", "ich", "noch", "bei", "Euch", "ge\u00b7blie\u00b7ben", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOKOM", "KOUS", "PPER", "ADV", "APPR", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "und h\u00e4tt Euch stets von Noth und Mangel vorgesagt,", "tokens": ["und", "h\u00e4tt", "Euch", "stets", "von", "Noth", "und", "Man\u00b7gel", "vor\u00b7ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "und Euch sowohl als mich aufs heftigste geplagt.", "tokens": ["und", "Euch", "so\u00b7wohl", "als", "mich", "aufs", "hef\u00b7tigs\u00b7te", "ge\u00b7plagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "KOUS", "PPER", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Gott, dessen Allmachtshand die Wunden kann verneuen", "tokens": ["Gott", ",", "des\u00b7sen", "All\u00b7machts\u00b7hand", "die", "Wun\u00b7den", "kann", "ver\u00b7neu\u00b7en"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELAT", "NN", "ART", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "der wollte Euch daf\u00fcr auch segnen, benedeyen,", "tokens": ["der", "woll\u00b7te", "Euch", "da\u00b7f\u00fcr", "auch", "seg\u00b7nen", ",", "be\u00b7ne\u00b7de\u00b7yen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "VMFIN", "PPER", "PAV", "ADV", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.98": {"text": "besch\u00fctzen da\u00df der Theil, den ihr uns zugewand", "tokens": ["be\u00b7sch\u00fct\u00b7zen", "da\u00df", "der", "Theil", ",", "den", "ihr", "uns", "zu\u00b7ge\u00b7wand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "KOUS", "ART", "NN", "$,", "PRELS", "PPER", "PRF", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "viel tausend Segen bringt, in eure milde Hand.", "tokens": ["viel", "tau\u00b7send", "Se\u00b7gen", "bringt", ",", "in", "eu\u00b7re", "mil\u00b7de", "Hand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VVFIN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "Ihr Freunde nun verehrt den Schutz der Obrigkeit,", "tokens": ["Ihr", "Freun\u00b7de", "nun", "ver\u00b7ehrt", "den", "Schutz", "der", "Ob\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "in deren Vaterhand ihr hier getragen seid.", "tokens": ["in", "de\u00b7ren", "Va\u00b7ter\u00b7hand", "ihr", "hier", "ge\u00b7tra\u00b7gen", "seid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sonst war uns Haab und Gut schon alles abgenommen,", "tokens": ["Sonst", "war", "uns", "Ha\u00b7ab", "und", "Gut", "schon", "al\u00b7les", "ab\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "KON", "NN", "ADV", "PIS", "VVPP", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "eh wir an dieses Gl\u00fcck, zu dieser Ruh gekommen.", "tokens": ["eh", "wir", "an", "die\u00b7ses", "Gl\u00fcck", ",", "zu", "die\u00b7ser", "Ruh", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "$,", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Schutz allein hat uns gest\u00e4rkt, und Ruh gemacht", "tokens": ["Der", "Schutz", "al\u00b7lein", "hat", "uns", "ge\u00b7st\u00e4rkt", ",", "und", "Ruh", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "PPER", "VVPP", "$,", "KON", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "w\u00fcnscht nun, da\u00df Gott f\u00fcr Sie und ihre Mauern wacht,", "tokens": ["w\u00fcnscht", "nun", ",", "da\u00df", "Gott", "f\u00fcr", "Sie", "und", "ih\u00b7re", "Mau\u00b7ern", "wacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "NN", "APPR", "PPER", "KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "f\u00fcr ihrer B\u00fcrger Heil, Er hat ihr Herz ger\u00fchret", "tokens": ["f\u00fcr", "ih\u00b7rer", "B\u00fcr\u00b7ger", "Heil", ",", "Er", "hat", "ihr", "Herz", "ge\u00b7r\u00fch\u00b7ret"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "da\u00df uns kein Unfall hat in gr\u00f6\u00df're Noth gef\u00fchret.", "tokens": ["da\u00df", "uns", "kein", "Un\u00b7fall", "hat", "in", "gr\u00f6\u00df'\u00b7re", "Noth", "ge\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn Er das Machtwort spricht, wenn Er dem \u00dcbel wehrt", "tokens": ["Wenn", "Er", "das", "Macht\u00b7wort", "spricht", ",", "wenn", "Er", "dem", "\u00dc\u00b7bel", "wehrt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "weislich, da\u00df ihnen Heil und Freude wiederf\u00e4hrt.", "tokens": ["weis\u00b7lich", ",", "da\u00df", "ih\u00b7nen", "Heil", "und", "Freu\u00b7de", "wie\u00b7der\u00b7f\u00e4hrt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "und segnet euch gewi\u00df an jedem Tag von neuen,", "tokens": ["und", "seg\u00b7net", "euch", "ge\u00b7wi\u00df", "an", "je\u00b7dem", "Tag", "von", "neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Handlung nehme zu, und werde gl\u00fccklich reich,", "tokens": ["Die", "Hand\u00b7lung", "neh\u00b7me", "zu", ",", "und", "wer\u00b7de", "gl\u00fcck\u00b7lich", "reich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VAFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "was sie verlangen kann, komm mit dem Wunsch zugleich,", "tokens": ["was", "sie", "ver\u00b7lan\u00b7gen", "kann", ",", "komm", "mit", "dem", "Wunsch", "zu\u00b7gleich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVINF", "VMFIN", "$,", "VVFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "damit sie kein Verlust und kein Betrug betr\u00fcbet.", "tokens": ["da\u00b7mit", "sie", "kein", "Ver\u00b7lust", "und", "kein", "Be\u00b7trug", "be\u00b7tr\u00fc\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "KON", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Lebt wohl! Gott sei bei Euch! Der segnet, sch\u00fctzt und liebet.", "tokens": ["Lebt", "wohl", "!", "Gott", "sei", "bei", "Euch", "!", "Der", "seg\u00b7net", ",", "sch\u00fctzt", "und", "lie\u00b7bet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$.", "NN", "VAFIN", "APPR", "PPER", "$.", "ART", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.42": {"line.1": {"text": "HeRR FABRICIUS.", "tokens": ["HeRR", "FaB\u00b7RI\u00b7CI\u00b7US", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.43": {"line.1": {"text": "Was sollen wir denn hier? Das St\u00fcck ist ja vorbei?", "tokens": ["Was", "sol\u00b7len", "wir", "denn", "hier", "?", "Das", "St\u00fcck", "ist", "ja", "vor\u00b7bei", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "ADV", "$.", "ART", "NN", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "HeRR MEYER.", "tokens": ["HeRR", "Me\u00b7Y\u00b7ER", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.45": {"line.1": {"text": "Ich wei\u00df wahrhaftig nicht, was dieser Anhang sei,", "tokens": ["Ich", "wei\u00df", "wahr\u00b7haf\u00b7tig", "nicht", ",", "was", "die\u00b7ser", "An\u00b7hang", "sei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKNEG", "$,", "PWS", "PDAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der unvermuthet kommt.", "tokens": ["Der", "un\u00b7ver\u00b7mu\u00b7thet", "kommt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.46": {"line.1": {"text": "MaDAME NEUBER.", "tokens": ["Ma\u00b7DA\u00b7ME", "NeU\u00b7BER", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.47": {"line.1": {"text": "Geduld, gebt euch zufrieden!", "tokens": ["Ge\u00b7duld", ",", "gebt", "euch", "zu\u00b7frie\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.48": {"line.1": {"text": "HeRR SUPPIG.", "tokens": ["HeRR", "SuP\u00b7PIG", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.49": {"line.1": {"text": "Damit ists nicht genug.", "tokens": ["Da\u00b7mit", "ists", "nicht", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.50": {"line.1": {"text": "Hr. MEYER.", "tokens": ["Hr.", "Me\u00b7Y\u00b7ER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Wir sind hieher beschieden,", "tokens": ["Wir", "sind", "hie\u00b7her", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.51": {"line.1": {"text": "und wissen nicht warum.", "tokens": ["und", "wis\u00b7sen", "nicht", "wa\u00b7rum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PWAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.52": {"line.1": {"text": "Hr. SUPPIG.", "tokens": ["Hr.", "SuP\u00b7PIG", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.53": {"line.1": {"text": "Was ists? Was wird denn draus?", "tokens": ["Was", "ists", "?", "Was", "wird", "denn", "draus", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$.", "PWS", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.54": {"line.1": {"text": "Md. NEUBER.", "tokens": ["Md.", "NeU\u00b7BER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.55": {"line.1": {"text": "Ich f\u00fchr euch allesammt mit Ehren aus dem Haus.", "tokens": ["Ich", "f\u00fchr", "euch", "al\u00b7le\u00b7sammt", "mit", "Eh\u00b7ren", "aus", "dem", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht durch Betrug und List: nein, recht wie sichs geb\u00fchret.", "tokens": ["Nicht", "durch", "Be\u00b7trug", "und", "List", ":", "nein", ",", "recht", "wie", "sichs", "ge\u00b7b\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "KON", "NN", "$.", "PTKANT", "$,", "ADJD", "KOKOM", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich hab euch zwar hieher in diese Noth gef\u00fchret;", "tokens": ["Ich", "hab", "euch", "zwar", "hie\u00b7her", "in", "die\u00b7se", "Noth", "ge\u00b7f\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PAV", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "alleine recht mit Zwang. Ich hab mich recht gewehrt.", "tokens": ["al\u00b7lei\u00b7ne", "recht", "mit", "Zwang", ".", "Ich", "hab", "mich", "recht", "ge\u00b7wehrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "$.", "PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich wu\u00dfte, da\u00df dies Haus den Segen selbst verzehrt;", "tokens": ["Ich", "wu\u00df\u00b7te", ",", "da\u00df", "dies", "Haus", "den", "Se\u00b7gen", "selbst", "ver\u00b7zehrt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PDS", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "und dennoch trat ich ein. Die Schwachheit einer Frauen,", "tokens": ["und", "den\u00b7noch", "trat", "ich", "ein", ".", "Die", "Schwach\u00b7heit", "ei\u00b7ner", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "vermag doch wohl einmal auch einen Mann zu trauen?", "tokens": ["ver\u00b7mag", "doch", "wohl", "ein\u00b7mal", "auch", "ei\u00b7nen", "Mann", "zu", "trau\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADV", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Genug: ich rett uns nun aus Elend und Gefahr,", "tokens": ["Ge\u00b7nug", ":", "ich", "rett", "uns", "nun", "aus", "E\u00b7lend", "und", "Ge\u00b7fahr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "die uns durch Eigennutz und List gedrohet war.", "tokens": ["die", "uns", "durch", "Ei\u00b7gen\u00b7nutz", "und", "List", "ge\u00b7dro\u00b7het", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "KON", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.56": {"line.1": {"text": "Hr. SUPPIG.", "tokens": ["Hr.", "SuP\u00b7PIG", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.57": {"line.1": {"text": "Der Spa\u00df kost nur viel Geld.", "tokens": ["Der", "Spa\u00df", "kost", "nur", "viel", "Geld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.58": {"line.1": {"text": "Hr. FABRICIUS.", "tokens": ["Hr.", "FaB\u00b7RI\u00b7CI\u00b7US", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.59": {"line.1": {"text": "Mein Freund was ist zu machen?", "tokens": ["Mein", "Freund", "was", "ist", "zu", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PWS", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.60": {"line.1": {"text": "Md. NEUBER.", "tokens": ["Md.", "NeU\u00b7BER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.61": {"line.1": {"text": "Geduld! Die Redlichkeit kann doch am Ende lachen,", "tokens": ["Ge\u00b7duld", "!", "Die", "Red\u00b7lich\u00b7keit", "kann", "doch", "am", "En\u00b7de", "la\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VMFIN", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "wenn List und Eigennutz sich selber nagt und fri\u00dft;", "tokens": ["wenn", "List", "und", "Ei\u00b7gen\u00b7nutz", "sich", "sel\u00b7ber", "nagt", "und", "fri\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PRF", "ADV", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die Unschuld hintergeht.", "tokens": ["die", "Un\u00b7schuld", "hin\u00b7ter\u00b7geht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.62": {"line.1": {"text": "Hr. FABRICIUS.", "tokens": ["Hr.", "FaB\u00b7RI\u00b7CI\u00b7US", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Wenn das Dein Trost noch ist", "tokens": ["Wenn", "das", "Dein", "Trost", "noch", "ist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "PPOSAT", "NN", "ADV", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.63": {"line.1": {"text": "so mag es immer sein.", "tokens": ["so", "mag", "es", "im\u00b7mer", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.64": {"line.1": {"text": "Hr. SUPPIG.", "tokens": ["Hr.", "SuP\u00b7PIG", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.65": {"line.1": {"text": "Das kann mich auch erg\u00f6tzen.", "tokens": ["Das", "kann", "mich", "auch", "er\u00b7g\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.66": {"line.1": {"text": "Hr. MEYER.", "tokens": ["Hr.", "Me\u00b7Y\u00b7ER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.67": {"line.1": {"text": "Der Himmel kann es auch ja wieder reich ersetzen.", "tokens": ["Der", "Him\u00b7mel", "kann", "es", "auch", "ja", "wie\u00b7der", "reich", "er\u00b7set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.68": {"line.1": {"text": "Md. NEUBER.", "tokens": ["Md.", "NeU\u00b7BER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.69": {"line.1": {"text": "Ach ja, das wird er thun. Er f\u00e4ngt jetzund schon an.", "tokens": ["Ach", "ja", ",", "das", "wird", "er", "thun", ".", "Er", "f\u00e4ngt", "je\u00b7tzund", "schon", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$,", "PDS", "VAFIN", "PPER", "VVINF", "$.", "PPER", "VVFIN", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.70": {"line.1": {"text": "Hr. FABRICIUS.", "tokens": ["Hr.", "FaB\u00b7RI\u00b7CI\u00b7US", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.71": {"line.1": {"text": "So mag das immer sein, was man uns angethan.", "tokens": ["So", "mag", "das", "im\u00b7mer", "sein", ",", "was", "man", "uns", "an\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PDS", "ADV", "VAINF", "$,", "PRELS", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vergeben, redlich sein, sind lauter gro\u00dfe Dinge.", "tokens": ["Ver\u00b7ge\u00b7ben", ",", "red\u00b7lich", "sein", ",", "sind", "lau\u00b7ter", "gro\u00b7\u00dfe", "Din\u00b7ge", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "VAINF", "$,", "VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.72": {"line.1": {"text": "Md. NEUBER.", "tokens": ["Md.", "NeU\u00b7BER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.73": {"line.1": {"text": "Wenn ich euch allerseits nun jetzt die Nachricht bringe:", "tokens": ["Wenn", "ich", "euch", "al\u00b7ler\u00b7seits", "nun", "jetzt", "die", "Nach\u00b7richt", "brin\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df selbst der Geiz, die List, und was man B\u00f6ses nennt,", "tokens": ["Da\u00df", "selbst", "der", "Geiz", ",", "die", "List", ",", "und", "was", "man", "B\u00f6\u00b7ses", "nennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "$,", "ART", "NN", "$,", "KON", "PWS", "PIS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "uns nicht mehr schaden kann; da\u00df uns Gott Gutes g\u00f6nnt;", "tokens": ["uns", "nicht", "mehr", "scha\u00b7den", "kann", ";", "da\u00df", "uns", "Gott", "Gu\u00b7tes", "g\u00f6nnt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "VVINF", "VMFIN", "$.", "KOUS", "PPER", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "da\u00df er uns gl\u00fccklich macht, und ruhig will erhalten:", "tokens": ["da\u00df", "er", "uns", "gl\u00fcck\u00b7lich", "macht", ",", "und", "ru\u00b7hig", "will", "er\u00b7hal\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVFIN", "$,", "KON", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "daf\u00fcr mu\u00df unser Dank zu keiner Zeit erkalten.", "tokens": ["da\u00b7f\u00fcr", "mu\u00df", "un\u00b7ser", "Dank", "zu", "kei\u00b7ner", "Zeit", "er\u00b7kal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ihr Freunde! werfet nun den Kummer und Verdru\u00df", "tokens": ["Ihr", "Freun\u00b7de", "!", "wer\u00b7fet", "nun", "den", "Kum\u00b7mer", "und", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "ADV", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "in diesen alten Staub, werft ihn vor eurem Fu\u00df:", "tokens": ["in", "die\u00b7sen", "al\u00b7ten", "Staub", ",", "werft", "ihn", "vor", "eu\u00b7rem", "Fu\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "und denkt an nichts als Dank und billiges verehren,", "tokens": ["und", "denkt", "an", "nichts", "als", "Dank", "und", "bil\u00b7li\u00b7ges", "ver\u00b7eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIS", "KOKOM", "NN", "KON", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "h\u00f6rt auf mit Klag und Angst, mit \u00c4rgern und Beschweren,", "tokens": ["h\u00f6rt", "auf", "mit", "Klag", "und", "Angst", ",", "mit", "\u00c4r\u00b7gern", "und", "Be\u00b7schwe\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "und la\u00dft mir nun den Ruhm, da\u00df keine wahre Pflicht", "tokens": ["und", "la\u00dft", "mir", "nun", "den", "Ruhm", ",", "da\u00df", "kei\u00b7ne", "wah\u00b7re", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "ADV", "ART", "NN", "$,", "KOUS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "von mir vergessen wird. Verst\u00f6rt mich jetzund nicht,", "tokens": ["von", "mir", "ver\u00b7ges\u00b7sen", "wird", ".", "Ver\u00b7st\u00f6rt", "mich", "je\u00b7tzund", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAFIN", "$.", "VVFIN", "PPER", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "ich mu\u00df die Schuldigkeit f\u00fcrs Gute nicht vergessen,", "tokens": ["ich", "mu\u00df", "die", "Schul\u00b7dig\u00b7keit", "f\u00fcrs", "Gu\u00b7te", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPRART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Das B\u00f6se mit Vernunft und mit Geduld ermessen.", "tokens": ["Das", "B\u00f6\u00b7se", "mit", "Ver\u00b7nunft", "und", "mit", "Ge\u00b7duld", "er\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Darinnen kommt der Ruhm, auch wiederum zur\u00fcck", "tokens": ["Da\u00b7rin\u00b7nen", "kommt", "der", "Ruhm", ",", "auch", "wie\u00b7de\u00b7rum", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "ADV", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "an euch, und euren Ruhm, an eure Ruh und Gl\u00fcck.", "tokens": ["an", "euch", ",", "und", "eu\u00b7ren", "Ruhm", ",", "an", "eu\u00b7re", "Ruh", "und", "Gl\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KON", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.74": {"line.1": {"text": "Hr. FABRICIUS.", "tokens": ["Hr.", "FaB\u00b7RI\u00b7CI\u00b7US", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.75": {"line.1": {"text": "Sprich nur, soviel Du kannst, wir wollen Dich nicht st\u00f6ren.", "tokens": ["Sprich", "nur", ",", "so\u00b7viel", "Du", "kannst", ",", "wir", "wol\u00b7len", "Dich", "nicht", "st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$,", "VVFIN", "PPER", "VMFIN", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.76": {"line.1": {"text": "Hr. SUPPIG.", "tokens": ["Hr.", "SuP\u00b7PIG", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.77": {"line.1": {"text": "Ach ja, das will ich gern und auch geduldig h\u00f6ren.", "tokens": ["Ach", "ja", ",", "das", "will", "ich", "gern", "und", "auch", "ge\u00b7dul\u00b7dig", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$,", "PDS", "VMFIN", "PPER", "ADV", "KON", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.78": {"line.1": {"text": "Hr. MEYER.", "tokens": ["Hr.", "Me\u00b7Y\u00b7ER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.79": {"line.1": {"text": "Wir andern stimmen bei und wollen stille sein.", "tokens": ["Wir", "an\u00b7dern", "stim\u00b7men", "bei", "und", "wol\u00b7len", "stil\u00b7le", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VVFIN", "APPR", "KON", "VMFIN", "PIS", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.80": {"line.1": {"text": "Md. NEUBER.", "tokens": ["Md.", "NeU\u00b7BER", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.81": {"line.1": {"text": "Durch dies wird Gl\u00fcck und Ruh f\u00fcr euch auch allgemein.", "tokens": ["Durch", "dies", "wird", "Gl\u00fcck", "und", "Ruh", "f\u00fcr", "euch", "auch", "all\u00b7ge\u00b7mein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "NN", "KON", "NN", "APPR", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ihr Freunde schickt den Wunsch zugleich aus euren Herzen,", "tokens": ["Ihr", "Freun\u00b7de", "schickt", "den", "Wunsch", "zu\u00b7gleich", "aus", "eu\u00b7ren", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und la\u00dft uns alle Noth bei Gl\u00fcck und Ruh verschmerzen.", "tokens": ["Und", "la\u00dft", "uns", "al\u00b7le", "Noth", "bei", "Gl\u00fcck", "und", "Ruh", "ver\u00b7schmer\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "PIAT", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Heut sag ich auch im Gl\u00fcck an Dich ein wahres Wort,", "tokens": ["Heut", "sag", "ich", "auch", "im", "Gl\u00fcck", "an", "Dich", "ein", "wah\u00b7res", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gesegnet, benedeit, wahrhaftig sch\u00f6ner Ort,", "tokens": ["Ge\u00b7seg\u00b7net", ",", "be\u00b7ne\u00b7deit", ",", "wahr\u00b7haf\u00b7tig", "sch\u00f6\u00b7ner", "Ort", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "mein Hamburg! La\u00df mich doch zwei St\u00fcck in Dir betrachten", "tokens": ["mein", "Ham\u00b7burg", "!", "La\u00df", "mich", "doch", "zwei", "St\u00fcck", "in", "Dir", "be\u00b7trach\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NE", "$.", "VVIMP", "PPER", "ADV", "CARD", "NN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "und jedes nach den Werth und seine Gr\u00f6\u00dfe achten.", "tokens": ["und", "je\u00b7des", "nach", "den", "Werth", "und", "sei\u00b7ne", "Gr\u00f6\u00b7\u00dfe", "ach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "APPR", "ART", "NN", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ihr Freunde habt Geduld! Heut gehts die Feinde an,", "tokens": ["Ihr", "Freun\u00b7de", "habt", "Ge\u00b7duld", "!", "Heut", "gehts", "die", "Fein\u00b7de", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "weil sie der Rang betrifft, und sie sehr viel gethan", "tokens": ["weil", "sie", "der", "Rang", "be\u00b7tr\u00b7ifft", ",", "und", "sie", "sehr", "viel", "ge\u00b7than"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "KON", "PPER", "ADV", "ADV", "VVPP"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "zu meinem Untergang. Ich will mich nicht beschweren", "tokens": ["zu", "mei\u00b7nem", "Un\u00b7ter\u00b7gang", ".", "Ich", "will", "mich", "nicht", "be\u00b7schwe\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "und sie aus Dankbarkeit vielmehr noch daf\u00fcr ehren.", "tokens": ["und", "sie", "aus", "Dank\u00b7bar\u00b7keit", "viel\u00b7mehr", "noch", "da\u00b7f\u00fcr", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "ADV", "ADV", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Hier h\u00e4lt mich wenig Gunst und kein Verdienst zur\u00fcck,", "tokens": ["Hier", "h\u00e4lt", "mich", "we\u00b7nig", "Gunst", "und", "kein", "Ver\u00b7dienst", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "KON", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "drum g\u00f6nnet wenigstens Euch und mir dieses Gl\u00fcck,", "tokens": ["drum", "g\u00f6n\u00b7net", "we\u00b7nigs\u00b7tens", "Euch", "und", "mir", "die\u00b7ses", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "PPER", "KON", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "da\u00df Ihr uns nicht mehr seht. Vielleicht da\u00df Zeiten kommen,", "tokens": ["da\u00df", "Ihr", "uns", "nicht", "mehr", "seht", ".", "Viel\u00b7leicht", "da\u00df", "Zei\u00b7ten", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "ADV", "VVFIN", "$.", "ADV", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "in welchen Ihr und wir in allen zugenommen,", "tokens": ["in", "wel\u00b7chen", "Ihr", "und", "wir", "in", "al\u00b7len", "zu\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PPOSAT", "KON", "PPER", "APPR", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "was unser Schauspiel gro\u00df und Euch erkenntlich macht:", "tokens": ["was", "un\u00b7ser", "Schau\u00b7spiel", "gro\u00df", "und", "Euch", "er\u00b7kennt\u00b7lich", "macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ADJD", "KON", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "nur gebt auf den Hanswurst in Zukunft besser Acht,", "tokens": ["nur", "gebt", "auf", "den", "Hans\u00b7wurst", "in", "Zu\u00b7kunft", "bes\u00b7ser", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "ADJD", "CARD", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.18": {"text": "da\u00df er nicht Hungers stirbt und Euch mehr Schulden spielet,", "tokens": ["da\u00df", "er", "nicht", "Hun\u00b7gers", "stirbt", "und", "Euch", "mehr", "Schul\u00b7den", "spie\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "NN", "VVFIN", "KON", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "in seinem Zotenkram, die Ihr im Herzen f\u00fchlet.", "tokens": ["in", "sei\u00b7nem", "Zo\u00b7ten\u00b7kram", ",", "die", "Ihr", "im", "Her\u00b7zen", "f\u00fch\u00b7let", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "aus unbekannter Luft. La\u00dft ihn bei Euch erziehn,", "tokens": ["aus", "un\u00b7be\u00b7kann\u00b7ter", "Luft", ".", "La\u00dft", "ihn", "bei", "Euch", "er\u00b7ziehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "VVIMP", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "belehrt ihn, macht ihn gro\u00df, und gebt ihm eure Werke", "tokens": ["be\u00b7lehrt", "ihn", ",", "macht", "ihn", "gro\u00df", ",", "und", "gebt", "ihm", "eu\u00b7re", "Wer\u00b7ke"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADJD", "$,", "KON", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "recht mit Gelehrsamkeit mit gr\u00f6\u00dfter Weisheit St\u00e4rke:", "tokens": ["recht", "mit", "Ge\u00b7lehr\u00b7sam\u00b7keit", "mit", "gr\u00f6\u00df\u00b7ter", "Weis\u00b7heit", "St\u00e4r\u00b7ke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "ADJA", "NN", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.23": {"text": "zum Segen sch\u00fctzet ihn, nehmt ihn zum Vorbild an,", "tokens": ["zum", "Se\u00b7gen", "sch\u00fct\u00b7zet", "ihn", ",", "nehmt", "ihn", "zum", "Vor\u00b7bild", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "vielleicht da\u00df dieser Euch geschickter bessern kann,", "tokens": ["viel\u00b7leicht", "da\u00df", "die\u00b7ser", "Euch", "ge\u00b7schick\u00b7ter", "bes\u00b7sern", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PDAT", "PPER", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "wenn Ihr den Unterschied von wahr und falschen Sachen", "tokens": ["wenn", "Ihr", "den", "Un\u00b7ter\u00b7schied", "von", "wahr", "und", "fal\u00b7schen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "an ihm erkennen lernt, und Euch k\u00f6nnt besser machen.", "tokens": ["an", "ihm", "er\u00b7ken\u00b7nen", "lernt", ",", "und", "Euch", "k\u00f6nnt", "bes\u00b7ser", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVINF", "VVFIN", "$,", "KON", "PPER", "VVFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Den Worten f\u00fcg ich hier die Kraft der Wahrheit bei.", "tokens": ["Den", "Wor\u00b7ten", "f\u00fcg", "ich", "hier", "die", "Kraft", "der", "Wahr\u00b7heit", "bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ihr seid selbst \u00fcberzeugt, da\u00df es so gr\u00fcndlich sei", "tokens": ["Ihr", "seid", "selbst", "\u00fc\u00b7berz\u00b7eugt", ",", "da\u00df", "es", "so", "gr\u00fcnd\u00b7lich", "sei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "als euer Vorsatz ist, nichts Gutes zu ern\u00e4hren:", "tokens": ["als", "eu\u00b7er", "Vor\u00b7satz", "ist", ",", "nichts", "Gu\u00b7tes", "zu", "er\u00b7n\u00e4h\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VAFIN", "$,", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "als eure Klugheit steigt, die Unschuld zu verheeren,", "tokens": ["als", "eu\u00b7re", "Klug\u00b7heit", "steigt", ",", "die", "Un\u00b7schuld", "zu", "ver\u00b7hee\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "die Ihr doch nicht erbaut, nicht kennt, nicht haben wollt,", "tokens": ["die", "Ihr", "doch", "nicht", "er\u00b7baut", ",", "nicht", "kennt", ",", "nicht", "ha\u00b7ben", "wollt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PTKNEG", "VVPP", "$,", "PTKNEG", "VVFIN", "$,", "PTKNEG", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "und wenn sie Euch nur Salz und Wasser kosten sollt,", "tokens": ["und", "wenn", "sie", "Euch", "nur", "Salz", "und", "Was\u00b7ser", "kos\u00b7ten", "sollt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "ADV", "NN", "KON", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "dabei das Brot doch fehlt, das man den Bettlern reichet,", "tokens": ["da\u00b7bei", "das", "Brot", "doch", "fehlt", ",", "das", "man", "den", "Bett\u00b7lern", "rei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADV", "VVFIN", "$,", "PRELS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "ihm nicht die Bissen z\u00e4hlt und schlechter nicht vergleichet,", "tokens": ["ihm", "nicht", "die", "Bis\u00b7sen", "z\u00e4hlt", "und", "schlech\u00b7ter", "nicht", "ver\u00b7glei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ART", "NN", "VVFIN", "KON", "ADJD", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "als er es w\u00fcrdig ist. Seht! nun erkl\u00e4r ich mich,", "tokens": ["als", "er", "es", "w\u00fcr\u00b7dig", "ist", ".", "Seht", "!", "nun", "er\u00b7kl\u00e4r", "ich", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VAFIN", "$.", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "bedenkt: mein Vorsatz war, da\u00df sag ich \u00f6ffentlich,", "tokens": ["be\u00b7denkt", ":", "mein", "Vor\u00b7satz", "war", ",", "da\u00df", "sag", "ich", "\u00f6f\u00b7fent\u00b7lich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPOSAT", "NN", "VAFIN", "$,", "KOUS", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.37": {"text": "da\u00df unserm deutschen Reich kein Vorzug sollt gebrechen", "tokens": ["da\u00df", "un\u00b7serm", "deut\u00b7schen", "Reich", "kein", "Vor\u00b7zug", "sollt", "ge\u00b7bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PIAT", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "in einer Kleinigkeit, so werdet ihr selbst sprechen,", "tokens": ["in", "ei\u00b7ner", "Klei\u00b7nig\u00b7keit", ",", "so", "wer\u00b7det", "ihr", "selbst", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "denn von der Schauspielkunst habt ihr sehr wenig Licht,", "tokens": ["denn", "von", "der", "Schau\u00b7spiel\u00b7kunst", "habt", "ihr", "sehr", "we\u00b7nig", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "weils Euch an Z\u00e4rtlichkeit, Natur und Kunst gebricht", "tokens": ["weils", "Euch", "an", "Z\u00e4rt\u00b7lich\u00b7keit", ",", "Na\u00b7tur", "und", "Kunst", "ge\u00b7bricht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Das Lesen langt nicht zu, auch nicht nach Frankreich reisen,", "tokens": ["Das", "Le\u00b7sen", "langt", "nicht", "zu", ",", "auch", "nicht", "nach", "Fran\u00b7kreich", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "PTKVZ", "$,", "ADV", "PTKNEG", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "ein Schauspiel recht verstehn, erfordert einen weisen", "tokens": ["ein", "Schau\u00b7spiel", "recht", "ver\u00b7stehn", ",", "er\u00b7for\u00b7dert", "ei\u00b7nen", "wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVINF", "$,", "VVFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "wahrhaftig klugen Mann, der jede Wahrheit kennt,", "tokens": ["wahr\u00b7haf\u00b7tig", "klu\u00b7gen", "Mann", ",", "der", "je\u00b7de", "Wahr\u00b7heit", "kennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "die Tugend redlich liebt, und dem das Leben g\u00f6nnt,", "tokens": ["die", "Tu\u00b7gend", "red\u00b7lich", "liebt", ",", "und", "dem", "das", "Le\u00b7ben", "g\u00f6nnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,", "KON", "ART", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "der Flei\u00df und Wissenschaft pflichtm\u00e4\u00dfig treibt und \u00fcbet,", "tokens": ["der", "Flei\u00df", "und", "Wis\u00b7sen\u00b7schaft", "pflicht\u00b7m\u00e4\u00b7\u00dfig", "treibt", "und", "\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADJD", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "der nicht blos um Gewinnst das wahre Gute liebet,", "tokens": ["der", "nicht", "blos", "um", "Ge\u00b7winnst", "das", "wah\u00b7re", "Gu\u00b7te", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.47": {"text": "nein! der dem Guten folgt, und h\u00e4tt' er nichts als Hohn,", "tokens": ["nein", "!", "der", "dem", "Gu\u00b7ten", "folgt", ",", "und", "h\u00e4tt'", "er", "nichts", "als", "Hohn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ART", "ART", "NN", "VVFIN", "$,", "KON", "VAFIN", "PPER", "PIS", "KOKOM", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.48": {"text": "der kleinen Geister Ha\u00df und Sp\u00f6tterei zum Lohn;", "tokens": ["der", "klei\u00b7nen", "Geis\u00b7ter", "Ha\u00df", "und", "Sp\u00f6t\u00b7te\u00b7rei", "zum", "Lohn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "dem auch der Mangel lieb: wenn er sich nur mit Ehren", "tokens": ["dem", "auch", "der", "Man\u00b7gel", "lieb", ":", "wenn", "er", "sich", "nur", "mit", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "ADJD", "$.", "KOUS", "PPER", "PRF", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "aus der Beschimpfung rei\u00dft, womit ihn die beschweren", "tokens": ["aus", "der", "Be\u00b7schimp\u00b7fung", "rei\u00dft", ",", "wo\u00b7mit", "ihn", "die", "be\u00b7schwe\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "ART", "ADJA"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.51": {"text": "die seine Feinde sind. Ist dieses recht gethan", "tokens": ["die", "sei\u00b7ne", "Fein\u00b7de", "sind", ".", "Ist", "die\u00b7ses", "recht", "ge\u00b7than"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "$.", "VAFIN", "PDAT", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "so nehmt auch, was ich sag, von mir vern\u00fcnftig an.", "tokens": ["so", "nehmt", "auch", ",", "was", "ich", "sag", ",", "von", "mir", "ver\u00b7n\u00fcnf\u00b7tig", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "PWS", "PPER", "VVFIN", "$,", "APPR", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Geht selbst in Euer Herz, das wird Euch deutlich sagen,", "tokens": ["Geht", "selbst", "in", "Eu\u00b7er", "Herz", ",", "das", "wird", "Euch", "deut\u00b7lich", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,", "PDS", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "warum ich Euch so frei die Wahrheit vorgetragen.", "tokens": ["wa\u00b7rum", "ich", "Euch", "so", "frei", "die", "Wahr\u00b7heit", "vor\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Glaubt, da\u00df hier weder Stolz noch Frechheit aus mir spricht,", "tokens": ["Glaubt", ",", "da\u00df", "hier", "we\u00b7der", "Stolz", "noch", "Frech\u00b7heit", "aus", "mir", "spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "KON", "NN", "ADV", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "und auch kein \u00dcbermuth. Darum verwerft dies nicht.", "tokens": ["und", "auch", "kein", "\u00dc\u00b7ber\u00b7muth", ".", "Da\u00b7rum", "ver\u00b7werft", "dies", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "$.", "PAV", "VVFIN", "PDS", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Es liegt ein wahrer Dank in diesem Salz verborgen.", "tokens": ["Es", "liegt", "ein", "wah\u00b7rer", "Dank", "in", "die\u00b7sem", "Salz", "ver\u00b7bor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Ich lieb und ehr in Euch wahrhaftig alle Sorgen,", "tokens": ["Ich", "lieb", "und", "ehr", "in", "Euch", "wahr\u00b7haf\u00b7tig", "al\u00b7le", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "KON", "NN", "APPR", "PPER", "ADJD", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Verlust und alle M\u00fch, die Ihr mir schwer gemacht;", "tokens": ["Ver\u00b7lust", "und", "al\u00b7le", "M\u00fch", ",", "die", "Ihr", "mir", "schwer", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PIAT", "NN", "$,", "PRELS", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "weil Ihr mich doch dadurch zu keiner That gebracht,", "tokens": ["weil", "Ihr", "mich", "doch", "da\u00b7durch", "zu", "kei\u00b7ner", "That", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PAV", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "die mich besch\u00e4men k\u00f6nnt. Die Schulden sind verschwunden,", "tokens": ["die", "mich", "be\u00b7sch\u00e4\u00b7men", "k\u00f6nnt", ".", "Die", "Schul\u00b7den", "sind", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VVFIN", "$.", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "die ich aus Noth gemacht. Der Nutzen ist gefunden", "tokens": ["die", "ich", "aus", "Noth", "ge\u00b7macht", ".", "Der", "Nut\u00b7zen", "ist", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRELS", "PPER", "APPR", "NN", "VVPP", "$.", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "der Euch daraus erw\u00e4chst. Ich bin gesch\u00e4tzt, vergn\u00fcgt,", "tokens": ["der", "Euch", "da\u00b7raus", "er\u00b7w\u00e4chst", ".", "Ich", "bin", "ge\u00b7sch\u00e4tzt", ",", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "PAV", "VVFIN", "$.", "PPER", "VAFIN", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "versorgt, belohnt, gesucht. Das Gl\u00fcck nun \u00fcberwiegt", "tokens": ["ver\u00b7sorgt", ",", "be\u00b7lohnt", ",", "ge\u00b7sucht", ".", "Das", "Gl\u00fcck", "nun", "\u00fc\u00b7berw\u00b7iegt"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "VVPP", "$,", "VVPP", "$.", "ART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Es war mein Untergang bei Euch schon abgez\u00e4hlet,", "tokens": ["Es", "war", "mein", "Un\u00b7ter\u00b7gang", "bei", "Euch", "schon", "ab\u00b7ge\u00b7z\u00e4h\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "APPR", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Das Ende wu\u00dftet Ihr durch die Verhindrung schon,", "tokens": ["Das", "En\u00b7de", "wu\u00df\u00b7tet", "Ihr", "durch", "die", "Ver\u00b7hin\u00b7drung", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "und doch geschieht es nicht. Was habt Ihr nun davon?", "tokens": ["und", "doch", "ge\u00b7schieht", "es", "nicht", ".", "Was", "habt", "Ihr", "nun", "da\u00b7von", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKNEG", "$.", "PWS", "VAFIN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Ja nichts. Ein bischen Wind, ein halbes St\u00fcndchen Lachen.", "tokens": ["Ja", "nichts", ".", "Ein", "bi\u00b7schen", "Wind", ",", "ein", "hal\u00b7bes", "St\u00fcnd\u00b7chen", "La\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PIS", "$.", "ART", "ADV", "NN", "$,", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Ich wills Euch doch zum Ruhm gewi\u00df viel besser machen.", "tokens": ["Ich", "wills", "Euch", "doch", "zum", "Ruhm", "ge\u00b7wi\u00df", "viel", "bes\u00b7ser", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "APPRART", "NN", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "So wenig ihr mit Zwang uns habt zu gut gethan,", "tokens": ["So", "we\u00b7nig", "ihr", "mit", "Zwang", "uns", "habt", "zu", "gut", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPOSAT", "APPR", "NN", "PPER", "VAFIN", "PTKA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "so wahrhaft nehm ich es mit Dank und Einsicht an.", "tokens": ["so", "wahr\u00b7haft", "nehm", "ich", "es", "mit", "Dank", "und", "Ein\u00b7sicht", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "und brauch das wenige was gro\u00dfes zu verrichten.", "tokens": ["und", "brauch", "das", "we\u00b7ni\u00b7ge", "was", "gro\u00b7\u00dfes", "zu", "ver\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "PIS", "PWS", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Sprecht: handle ich nicht recht nach allen solchen Pflichten,", "tokens": ["Sprecht", ":", "hand\u00b7le", "ich", "nicht", "recht", "nach", "al\u00b7len", "sol\u00b7chen", "Pflich\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "VVFIN", "PPER", "PTKNEG", "ADJD", "APPR", "PIAT", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "die Zucht und Tugenden nicht meiden, ha\u00dfen, fliehn,", "tokens": ["die", "Zucht", "und", "Tu\u00b7gen\u00b7den", "nicht", "mei\u00b7den", ",", "ha\u00b7\u00dfen", ",", "fliehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "PTKNEG", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "und kann ich nicht getrost, mit Ehren von Euch ziehn?", "tokens": ["und", "kann", "ich", "nicht", "ge\u00b7trost", ",", "mit", "Eh\u00b7ren", "von", "Euch", "ziehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "VVPP", "$,", "APPR", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Wahrhaftig! recht getrost! Gelassen und mit Freuden", "tokens": ["Wahr\u00b7haf\u00b7tig", "!", "recht", "ge\u00b7trost", "!", "Ge\u00b7las\u00b7sen", "und", "mit", "Freu\u00b7den"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "ADJD", "VVPP", "$.", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "und dankbar will ich hier von meinen Feinden scheiden.", "tokens": ["und", "dank\u00b7bar", "will", "ich", "hier", "von", "mei\u00b7nen", "Fein\u00b7den", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Nun Freunde kommts an Euch! Ruhm, Dank und Z\u00e4rtlichkeit", "tokens": ["Nun", "Freun\u00b7de", "kommts", "an", "Euch", "!", "Ruhm", ",", "Dank", "und", "Z\u00e4rt\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NN", "VVFIN", "APPR", "PPER", "$.", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "erfordert mehr von mir, als die Beredsamkeit", "tokens": ["er\u00b7for\u00b7dert", "mehr", "von", "mir", ",", "als", "die", "Be\u00b7red\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "die im Zusammenhang viel sch\u00f6ne Worte bindet,", "tokens": ["die", "im", "Zu\u00b7sam\u00b7men\u00b7hang", "viel", "sch\u00f6\u00b7ne", "Wor\u00b7te", "bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "und doch ein altes Lied mit neuer Art erfindet.", "tokens": ["und", "doch", "ein", "al\u00b7tes", "Lied", "mit", "neu\u00b7er", "Art", "er\u00b7fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "In meinem Gl\u00fcck, belohnt Gott eure G\u00fctigkeit", "tokens": ["In", "mei\u00b7nem", "Gl\u00fcck", ",", "be\u00b7lohnt", "Gott", "eu\u00b7re", "G\u00fc\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VVFIN", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "weit mehr, als mein Verdienst und meine Leidenszeit,", "tokens": ["weit", "mehr", ",", "als", "mein", "Ver\u00b7dienst", "und", "mei\u00b7ne", "Lei\u00b7dens\u00b7zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "KOUS", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "damit Ihr nicht besch\u00e4mt und heimlich Freunde hei\u00dfet,", "tokens": ["da\u00b7mit", "Ihr", "nicht", "be\u00b7sch\u00e4mt", "und", "heim\u00b7lich", "Freun\u00b7de", "hei\u00b7\u00dfet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "KON", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "das Euch die Allmachtshand durch unsre Gl\u00fcck beweiset.", "tokens": ["das", "Euch", "die", "All\u00b7machts\u00b7hand", "durch", "uns\u00b7re", "Gl\u00fcck", "be\u00b7wei\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Gott hat an mich gedacht in Elend und Gefahr", "tokens": ["Gott", "hat", "an", "mich", "ge\u00b7dacht", "in", "E\u00b7lend", "und", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "APPR", "PPER", "VVPP", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "zur Zeit, da Euch selbst bang um meine Wohlfahrt war.", "tokens": ["zur", "Zeit", ",", "da", "Euch", "selbst", "bang", "um", "mei\u00b7ne", "Wohl\u00b7fahrt", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Allein er wu\u00dfte schon wie er mich retten wollte,", "tokens": ["Al\u00b7lein", "er", "wu\u00df\u00b7te", "schon", "wie", "er", "mich", "ret\u00b7ten", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "KOKOM", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "---+--+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.89": {"text": "und r\u00fchrte euer Herz, das mich erhalten sollte,", "tokens": ["und", "r\u00fchr\u00b7te", "eu\u00b7er", "Herz", ",", "das", "mich", "er\u00b7hal\u00b7ten", "soll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "bis seine Zeit erschien. Sie kam und ist jetzt da.", "tokens": ["bis", "sei\u00b7ne", "Zeit", "er\u00b7schien", ".", "Sie", "kam", "und", "ist", "jetzt", "da", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$.", "PPER", "VVFIN", "KON", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Ihr wahren Freunde, sagt zu meiner Wohlfahrt, ja!", "tokens": ["Ihr", "wah\u00b7ren", "Freun\u00b7de", ",", "sagt", "zu", "mei\u00b7ner", "Wohl\u00b7fahrt", ",", "ja", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Ihr g\u00f6nnt uns unsre Ruh, den Ruhm zu Eurer Ehre", "tokens": ["Ihr", "g\u00f6nnt", "uns", "uns\u00b7re", "Ruh", ",", "den", "Ruhm", "zu", "Eu\u00b7rer", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "so gern, als wenn ich noch bei Euch geblieben w\u00e4re,", "tokens": ["so", "gern", ",", "als", "wenn", "ich", "noch", "bei", "Euch", "ge\u00b7blie\u00b7ben", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOKOM", "KOUS", "PPER", "ADV", "APPR", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "und h\u00e4tt Euch stets von Noth und Mangel vorgesagt,", "tokens": ["und", "h\u00e4tt", "Euch", "stets", "von", "Noth", "und", "Man\u00b7gel", "vor\u00b7ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "und Euch sowohl als mich aufs heftigste geplagt.", "tokens": ["und", "Euch", "so\u00b7wohl", "als", "mich", "aufs", "hef\u00b7tigs\u00b7te", "ge\u00b7plagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "KOUS", "PPER", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Gott, dessen Allmachtshand die Wunden kann verneuen", "tokens": ["Gott", ",", "des\u00b7sen", "All\u00b7machts\u00b7hand", "die", "Wun\u00b7den", "kann", "ver\u00b7neu\u00b7en"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELAT", "NN", "ART", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "der wollte Euch daf\u00fcr auch segnen, benedeyen,", "tokens": ["der", "woll\u00b7te", "Euch", "da\u00b7f\u00fcr", "auch", "seg\u00b7nen", ",", "be\u00b7ne\u00b7de\u00b7yen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "VMFIN", "PPER", "PAV", "ADV", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.98": {"text": "besch\u00fctzen da\u00df der Theil, den ihr uns zugewand", "tokens": ["be\u00b7sch\u00fct\u00b7zen", "da\u00df", "der", "Theil", ",", "den", "ihr", "uns", "zu\u00b7ge\u00b7wand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "KOUS", "ART", "NN", "$,", "PRELS", "PPER", "PRF", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "viel tausend Segen bringt, in eure milde Hand.", "tokens": ["viel", "tau\u00b7send", "Se\u00b7gen", "bringt", ",", "in", "eu\u00b7re", "mil\u00b7de", "Hand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VVFIN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.82": {"line.1": {"text": "Ihr Freunde nun verehrt den Schutz der Obrigkeit,", "tokens": ["Ihr", "Freun\u00b7de", "nun", "ver\u00b7ehrt", "den", "Schutz", "der", "Ob\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "in deren Vaterhand ihr hier getragen seid.", "tokens": ["in", "de\u00b7ren", "Va\u00b7ter\u00b7hand", "ihr", "hier", "ge\u00b7tra\u00b7gen", "seid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sonst war uns Haab und Gut schon alles abgenommen,", "tokens": ["Sonst", "war", "uns", "Ha\u00b7ab", "und", "Gut", "schon", "al\u00b7les", "ab\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "KON", "NN", "ADV", "PIS", "VVPP", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "eh wir an dieses Gl\u00fcck, zu dieser Ruh gekommen.", "tokens": ["eh", "wir", "an", "die\u00b7ses", "Gl\u00fcck", ",", "zu", "die\u00b7ser", "Ruh", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "$,", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Schutz allein hat uns gest\u00e4rkt, und Ruh gemacht", "tokens": ["Der", "Schutz", "al\u00b7lein", "hat", "uns", "ge\u00b7st\u00e4rkt", ",", "und", "Ruh", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "PPER", "VVPP", "$,", "KON", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "w\u00fcnscht nun, da\u00df Gott f\u00fcr Sie und ihre Mauern wacht,", "tokens": ["w\u00fcnscht", "nun", ",", "da\u00df", "Gott", "f\u00fcr", "Sie", "und", "ih\u00b7re", "Mau\u00b7ern", "wacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "NN", "APPR", "PPER", "KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "f\u00fcr ihrer B\u00fcrger Heil, Er hat ihr Herz ger\u00fchret", "tokens": ["f\u00fcr", "ih\u00b7rer", "B\u00fcr\u00b7ger", "Heil", ",", "Er", "hat", "ihr", "Herz", "ge\u00b7r\u00fch\u00b7ret"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "da\u00df uns kein Unfall hat in gr\u00f6\u00df're Noth gef\u00fchret.", "tokens": ["da\u00df", "uns", "kein", "Un\u00b7fall", "hat", "in", "gr\u00f6\u00df'\u00b7re", "Noth", "ge\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn Er das Machtwort spricht, wenn Er dem \u00dcbel wehrt", "tokens": ["Wenn", "Er", "das", "Macht\u00b7wort", "spricht", ",", "wenn", "Er", "dem", "\u00dc\u00b7bel", "wehrt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "weislich, da\u00df ihnen Heil und Freude wiederf\u00e4hrt.", "tokens": ["weis\u00b7lich", ",", "da\u00df", "ih\u00b7nen", "Heil", "und", "Freu\u00b7de", "wie\u00b7der\u00b7f\u00e4hrt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "und segnet euch gewi\u00df an jedem Tag von neuen,", "tokens": ["und", "seg\u00b7net", "euch", "ge\u00b7wi\u00df", "an", "je\u00b7dem", "Tag", "von", "neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Handlung nehme zu, und werde gl\u00fccklich reich,", "tokens": ["Die", "Hand\u00b7lung", "neh\u00b7me", "zu", ",", "und", "wer\u00b7de", "gl\u00fcck\u00b7lich", "reich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VAFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "was sie verlangen kann, komm mit dem Wunsch zugleich,", "tokens": ["was", "sie", "ver\u00b7lan\u00b7gen", "kann", ",", "komm", "mit", "dem", "Wunsch", "zu\u00b7gleich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVINF", "VMFIN", "$,", "VVFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "damit sie kein Verlust und kein Betrug betr\u00fcbet.", "tokens": ["da\u00b7mit", "sie", "kein", "Ver\u00b7lust", "und", "kein", "Be\u00b7trug", "be\u00b7tr\u00fc\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "KON", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Lebt wohl! Gott sei bei Euch! Der segnet, sch\u00fctzt und liebet.", "tokens": ["Lebt", "wohl", "!", "Gott", "sei", "bei", "Euch", "!", "Der", "seg\u00b7net", ",", "sch\u00fctzt", "und", "lie\u00b7bet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$.", "NN", "VAFIN", "APPR", "PPER", "$.", "ART", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}