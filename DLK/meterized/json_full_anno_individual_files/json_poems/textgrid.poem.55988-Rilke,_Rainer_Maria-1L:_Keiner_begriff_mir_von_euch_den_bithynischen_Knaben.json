{"textgrid.poem.55988": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "1L: Keiner begriff mir von euch den bithynischen Knaben", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Keiner begriff mir von euch den bithynischen Knaben", "tokens": ["Kei\u00b7ner", "be\u00b7griff", "mir", "von", "euch", "den", "bi\u00b7thy\u00b7nisc\u00b7hen", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "PPER", "ART", "ADJA", "NN"], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}, "line.2": {"text": "(da\u00df ihr den Strom anfa\u00dftet und von ihm h\u00fcbt...).", "tokens": ["(", "da\u00df", "ihr", "den", "Strom", "an\u00b7fa\u00df\u00b7tet", "und", "von", "ihm", "h\u00fcbt", "...", ")", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "VVFIN", "KON", "APPR", "PPER", "ADJD", "$(", "$(", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Ich verw\u00f6hnte ihn zwar. Und dennoch: wir haben", "tokens": ["Ich", "ver\u00b7w\u00f6hn\u00b7te", "ihn", "zwar", ".", "Und", "den\u00b7noch", ":", "wir", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$.", "KON", "ADV", "$.", "PPER", "VAFIN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "ihn nur mit Schwere erf\u00fcllt und f\u00fcr immer getr\u00fcbt.", "tokens": ["ihn", "nur", "mit", "Schwe\u00b7re", "er\u00b7f\u00fcllt", "und", "f\u00fcr", "im\u00b7mer", "ge\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "VVPP", "KON", "APPR", "ADV", "VVPP", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Wer vermag denn zu lieben ? Wer kann es ? \u2013 Noch keiner.", "tokens": ["Wer", "ver\u00b7mag", "denn", "zu", "lie\u00b7ben", "?", "Wer", "kann", "es", "?", "\u2013", "Noch", "kei\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PTKZU", "VVINF", "$.", "PWS", "VMFIN", "PPER", "$.", "$(", "ADV", "PIS", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Und so hab ich unendliches Weh getan \u2013.", "tokens": ["Und", "so", "hab", "ich", "un\u00b7end\u00b7li\u00b7ches", "Weh", "ge\u00b7tan", "\u2013", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJA", "NN", "VVPP", "$(", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Nun ist er am Nil der stillenden G\u00f6tter einer,", "tokens": ["Nun", "ist", "er", "am", "Nil", "der", "stil\u00b7len\u00b7den", "G\u00f6t\u00b7ter", "ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "ART", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und ich wei\u00df kaum welcher und kann ihm nicht nahn.", "tokens": ["und", "ich", "wei\u00df", "kaum", "wel\u00b7cher", "und", "kann", "ihm", "nicht", "nahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADJD", "KON", "VMFIN", "PPER", "PTKNEG", "ADJA", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Und ihr warfet ihn noch, Wahnsinnige, bis in die Sterne,", "tokens": ["Und", "ihr", "war\u00b7fet", "ihn", "noch", ",", "Wahn\u00b7sin\u00b7ni\u00b7ge", ",", "bis", "in", "die", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$,", "ADJA", "$,", "KOUS", "APPR", "ART", "NN", "$,"], "meter": "--+-+-+---+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "damit ich euch rufe und dr\u00e4nge: meint ihr den?", "tokens": ["da\u00b7mit", "ich", "euch", "ru\u00b7fe", "und", "dr\u00e4n\u00b7ge", ":", "meint", "ihr", "den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "KON", "VVFIN", "$.", "VVFIN", "PPER", "ART", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Was ist er nicht einfach ein Toter. Er w\u00e4re es gerne.", "tokens": ["Was", "ist", "er", "nicht", "ein\u00b7fach", "ein", "To\u00b7ter", ".", "Er", "w\u00e4\u00b7re", "es", "ger\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "ADV", "ART", "NN", "$.", "PPER", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und vielleicht w\u00e4re ihm nichts geschehn.", "tokens": ["Und", "viel\u00b7leicht", "w\u00e4\u00b7re", "ihm", "nichts", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Keiner begriff mir von euch den bithynischen Knaben", "tokens": ["Kei\u00b7ner", "be\u00b7griff", "mir", "von", "euch", "den", "bi\u00b7thy\u00b7nisc\u00b7hen", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "PPER", "ART", "ADJA", "NN"], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}, "line.2": {"text": "(da\u00df ihr den Strom anfa\u00dftet und von ihm h\u00fcbt...).", "tokens": ["(", "da\u00df", "ihr", "den", "Strom", "an\u00b7fa\u00df\u00b7tet", "und", "von", "ihm", "h\u00fcbt", "...", ")", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "VVFIN", "KON", "APPR", "PPER", "ADJD", "$(", "$(", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Ich verw\u00f6hnte ihn zwar. Und dennoch: wir haben", "tokens": ["Ich", "ver\u00b7w\u00f6hn\u00b7te", "ihn", "zwar", ".", "Und", "den\u00b7noch", ":", "wir", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$.", "KON", "ADV", "$.", "PPER", "VAFIN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "ihn nur mit Schwere erf\u00fcllt und f\u00fcr immer getr\u00fcbt.", "tokens": ["ihn", "nur", "mit", "Schwe\u00b7re", "er\u00b7f\u00fcllt", "und", "f\u00fcr", "im\u00b7mer", "ge\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "VVPP", "KON", "APPR", "ADV", "VVPP", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Wer vermag denn zu lieben ? Wer kann es ? \u2013 Noch keiner.", "tokens": ["Wer", "ver\u00b7mag", "denn", "zu", "lie\u00b7ben", "?", "Wer", "kann", "es", "?", "\u2013", "Noch", "kei\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PTKZU", "VVINF", "$.", "PWS", "VMFIN", "PPER", "$.", "$(", "ADV", "PIS", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Und so hab ich unendliches Weh getan \u2013.", "tokens": ["Und", "so", "hab", "ich", "un\u00b7end\u00b7li\u00b7ches", "Weh", "ge\u00b7tan", "\u2013", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJA", "NN", "VVPP", "$(", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Nun ist er am Nil der stillenden G\u00f6tter einer,", "tokens": ["Nun", "ist", "er", "am", "Nil", "der", "stil\u00b7len\u00b7den", "G\u00f6t\u00b7ter", "ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "ART", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und ich wei\u00df kaum welcher und kann ihm nicht nahn.", "tokens": ["und", "ich", "wei\u00df", "kaum", "wel\u00b7cher", "und", "kann", "ihm", "nicht", "nahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADJD", "KON", "VMFIN", "PPER", "PTKNEG", "ADJA", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Und ihr warfet ihn noch, Wahnsinnige, bis in die Sterne,", "tokens": ["Und", "ihr", "war\u00b7fet", "ihn", "noch", ",", "Wahn\u00b7sin\u00b7ni\u00b7ge", ",", "bis", "in", "die", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$,", "ADJA", "$,", "KOUS", "APPR", "ART", "NN", "$,"], "meter": "--+-+-+---+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "damit ich euch rufe und dr\u00e4nge: meint ihr den?", "tokens": ["da\u00b7mit", "ich", "euch", "ru\u00b7fe", "und", "dr\u00e4n\u00b7ge", ":", "meint", "ihr", "den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "KON", "VVFIN", "$.", "VVFIN", "PPER", "ART", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Was ist er nicht einfach ein Toter. Er w\u00e4re es gerne.", "tokens": ["Was", "ist", "er", "nicht", "ein\u00b7fach", "ein", "To\u00b7ter", ".", "Er", "w\u00e4\u00b7re", "es", "ger\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "ADV", "ART", "NN", "$.", "PPER", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und vielleicht w\u00e4re ihm nichts geschehn.", "tokens": ["Und", "viel\u00b7leicht", "w\u00e4\u00b7re", "ihm", "nichts", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}