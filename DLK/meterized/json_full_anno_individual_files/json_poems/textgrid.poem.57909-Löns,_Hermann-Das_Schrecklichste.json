{"textgrid.poem.57909": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Das Schrecklichste", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Schwanzstern stand am Horizont;", "tokens": ["Ein", "Schwanz\u00b7stern", "stand", "am", "Ho\u00b7ri\u00b7zont", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das hat was zu bedeuten,", "tokens": ["Das", "hat", "was", "zu", "be\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von Mi\u00dfwachs, Pest und Kohlennot,", "tokens": ["Von", "Mi\u00df\u00b7wachs", ",", "Pest", "und", "Koh\u00b7len\u00b7not", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und anderen Schr\u00f6cklichkeiten.", "tokens": ["Und", "an\u00b7de\u00b7ren", "Schr\u00f6ck\u00b7lich\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Von steifem Geldstand, Arbeitsnot,", "tokens": ["Von", "stei\u00b7fem", "Geld\u00b7stand", ",", "Ar\u00b7beits\u00b7not", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von b\u00f6sen Moritaten \u2013", "tokens": ["Von", "b\u00f6\u00b7sen", "Mo\u00b7ri\u00b7ta\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir wollen zu einer weisen Frau,", "tokens": ["Wir", "wol\u00b7len", "zu", "ei\u00b7ner", "wei\u00b7sen", "Frau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die soll uns die Deutung verraten.", "tokens": ["Die", "soll", "uns", "die", "Deu\u00b7tung", "ver\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "Die aber sprach: \u00bbO Schlimm'res als Pest,", "tokens": ["Die", "a\u00b7ber", "sprach", ":", "\u00bb", "O", "Schlim\u00b7m'\u00b7res", "als", "Pest", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "$.", "$(", "NE", "NE", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Als Mi\u00dfwachs und Kohlenn\u00f6te,", "tokens": ["Als", "Mi\u00df\u00b7wachs", "und", "Koh\u00b7len\u00b7n\u00f6\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Und Klauenseuche und Rotlauf sagt", "tokens": ["Und", "Klau\u00b7en\u00b7seu\u00b7che", "und", "Rot\u00b7lauf", "sagt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "F\u00fcr Hannover dieser Komete.", "tokens": ["F\u00fcr", "Han\u00b7no\u00b7ver", "die\u00b7ser", "Ko\u00b7me\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PDAT", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "O h\u00f6ret, was er bedeuten soll\u00ab \u2013", "tokens": ["O", "h\u00f6\u00b7ret", ",", "was", "er", "be\u00b7deu\u00b7ten", "soll", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$(", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Unser Haar sich str\u00e4ubte vor Grauen \u2013", "tokens": ["Un\u00b7ser", "Haar", "sich", "str\u00e4ub\u00b7te", "vor", "Grau\u00b7en", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRF", "VVFIN", "APPR", "NN", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "\u00bbin der Herschelstra\u00dfe der Fiskus wird", "tokens": ["\u00bb", "in", "der", "Her\u00b7schel\u00b7stra\u00b7\u00dfe", "der", "Fis\u00b7kus", "wird"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "ART", "NN", "ART", "NN", "VAFIN"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Eine neue Mauer bauen!\u00ab", "tokens": ["Ei\u00b7ne", "neu\u00b7e", "Mau\u00b7er", "bau\u00b7en", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ein Schwanzstern stand am Horizont;", "tokens": ["Ein", "Schwanz\u00b7stern", "stand", "am", "Ho\u00b7ri\u00b7zont", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das hat was zu bedeuten,", "tokens": ["Das", "hat", "was", "zu", "be\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von Mi\u00dfwachs, Pest und Kohlennot,", "tokens": ["Von", "Mi\u00df\u00b7wachs", ",", "Pest", "und", "Koh\u00b7len\u00b7not", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und anderen Schr\u00f6cklichkeiten.", "tokens": ["Und", "an\u00b7de\u00b7ren", "Schr\u00f6ck\u00b7lich\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Von steifem Geldstand, Arbeitsnot,", "tokens": ["Von", "stei\u00b7fem", "Geld\u00b7stand", ",", "Ar\u00b7beits\u00b7not", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von b\u00f6sen Moritaten \u2013", "tokens": ["Von", "b\u00f6\u00b7sen", "Mo\u00b7ri\u00b7ta\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir wollen zu einer weisen Frau,", "tokens": ["Wir", "wol\u00b7len", "zu", "ei\u00b7ner", "wei\u00b7sen", "Frau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die soll uns die Deutung verraten.", "tokens": ["Die", "soll", "uns", "die", "Deu\u00b7tung", "ver\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.7": {"line.1": {"text": "Die aber sprach: \u00bbO Schlimm'res als Pest,", "tokens": ["Die", "a\u00b7ber", "sprach", ":", "\u00bb", "O", "Schlim\u00b7m'\u00b7res", "als", "Pest", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "$.", "$(", "NE", "NE", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Als Mi\u00dfwachs und Kohlenn\u00f6te,", "tokens": ["Als", "Mi\u00df\u00b7wachs", "und", "Koh\u00b7len\u00b7n\u00f6\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Und Klauenseuche und Rotlauf sagt", "tokens": ["Und", "Klau\u00b7en\u00b7seu\u00b7che", "und", "Rot\u00b7lauf", "sagt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "F\u00fcr Hannover dieser Komete.", "tokens": ["F\u00fcr", "Han\u00b7no\u00b7ver", "die\u00b7ser", "Ko\u00b7me\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PDAT", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "O h\u00f6ret, was er bedeuten soll\u00ab \u2013", "tokens": ["O", "h\u00f6\u00b7ret", ",", "was", "er", "be\u00b7deu\u00b7ten", "soll", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$(", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Unser Haar sich str\u00e4ubte vor Grauen \u2013", "tokens": ["Un\u00b7ser", "Haar", "sich", "str\u00e4ub\u00b7te", "vor", "Grau\u00b7en", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRF", "VVFIN", "APPR", "NN", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "\u00bbin der Herschelstra\u00dfe der Fiskus wird", "tokens": ["\u00bb", "in", "der", "Her\u00b7schel\u00b7stra\u00b7\u00dfe", "der", "Fis\u00b7kus", "wird"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "ART", "NN", "ART", "NN", "VAFIN"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Eine neue Mauer bauen!\u00ab", "tokens": ["Ei\u00b7ne", "neu\u00b7e", "Mau\u00b7er", "bau\u00b7en", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}