{"textgrid.poem.53847": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Wenn jener wiederk\u00e4me . . .", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In Holland ruht des Holzhauers Hacke.", "tokens": ["In", "Hol\u00b7land", "ruht", "des", "Holz\u00b7hau\u00b7ers", "Ha\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da ist eitel Freude und Koffergepacke \u2013", "tokens": ["Da", "ist", "ei\u00b7tel", "Freu\u00b7de", "und", "Kof\u00b7fer\u00b7ge\u00b7pa\u00b7cke", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "NN", "KON", "NN", "$("], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "au Backe!", "tokens": ["au", "Ba\u00b7cke", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Da legen Lakaien in die ganz enormen", "tokens": ["Da", "le\u00b7gen", "La\u00b7kai\u00b7en", "in", "die", "ganz", "en\u00b7or\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "APPR", "ART", "ADV", "VVINF"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Kisten die feldgrauen Uniformen . . .", "tokens": ["Kis\u00b7ten", "die", "feld\u00b7grau\u00b7en", "U\u00b7nif\u00b7or\u00b7men", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "\u00bber kehrt uns zur\u00fcck\u00ab, sagt der Zeitungsbericht.", "tokens": ["\u00bb", "er", "kehrt", "uns", "zu\u00b7r\u00fcck", "\u00ab", ",", "sagt", "der", "Zei\u00b7tungs\u00b7be\u00b7richt", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PTKVZ", "$(", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Warum eigentlich nicht \u2013?", "tokens": ["Wa\u00b7rum", "ei\u00b7gent\u00b7lich", "nicht", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADV", "PTKNEG", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Warum eigentlich nicht \u2013?", "tokens": ["Wa\u00b7rum", "ei\u00b7gent\u00b7lich", "nicht", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADV", "PTKNEG", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Im Fall eines Falles", "tokens": ["Im", "Fall", "ei\u00b7nes", "Fal\u00b7les"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "f\u00e4nde er ja doch schlie\u00dflich alles", "tokens": ["f\u00e4n\u00b7de", "er", "ja", "doch", "schlie\u00df\u00b7lich", "al\u00b7les"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV", "PIS"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "unver\u00e4ndert . . .", "tokens": ["un\u00b7ver\u00b7\u00e4n\u00b7dert", ".", ".", "."], "token_info": ["word", "punct", "punct", "punct"], "pos": ["ADJD", "$.", "$.", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Seine Richter. Sein Milit\u00e4r.", "tokens": ["Sei\u00b7ne", "Rich\u00b7ter", ".", "Sein", "Mi\u00b7li\u00b7t\u00e4r", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Seine Untertanen. Und noch viel mehr:", "tokens": ["Sei\u00b7ne", "Un\u00b7ter\u00b7ta\u00b7nen", ".", "Und", "noch", "viel", "mehr", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "KON", "ADV", "ADV", "ADV", "$."], "meter": "+-+-+----+", "measure": "unknown.measure.tetra"}, "line.7": {"text": "Seinen Feldmarschall. Seinen Schulunterricht.", "tokens": ["Sei\u00b7nen", "Feld\u00b7mar\u00b7schall", ".", "Sei\u00b7nen", "Schul\u00b7un\u00b7ter\u00b7richt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Also warum eigentlich nicht \u2013?", "tokens": ["Al\u00b7so", "wa\u00b7rum", "ei\u00b7gent\u00b7lich", "nicht", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PWAV", "ADV", "PTKNEG", "$(", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.3": {"line.1": {"text": "Er f\u00e4nde auch seinen Reichstag wieder.", "tokens": ["Er", "f\u00e4n\u00b7de", "auch", "sei\u00b7nen", "Reichs\u00b7tag", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "ADV", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "H\u00f6rte die alten, lieben Lieder", "tokens": ["H\u00f6r\u00b7te", "die", "al\u00b7ten", ",", "lie\u00b7ben", "Lie\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "der Sozialdemokraten . . .", "tokens": ["der", "So\u00b7zi\u00b7al\u00b7de\u00b7mo\u00b7kra\u00b7ten", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "$.", "$.", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da sitzen noch dieselben Leute,", "tokens": ["Da", "sit\u00b7zen", "noch", "die\u00b7sel\u00b7ben", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die mit ihm gebr\u00fcllt \u2013 damals wie heute.", "tokens": ["die", "mit", "ihm", "ge\u00b7br\u00fcllt", "\u2013", "da\u00b7mals", "wie", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VVPP", "$(", "ADV", "KOKOM", "ADV", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Die seine Kriegsverbrechen gebilligt.", "tokens": ["Die", "sei\u00b7ne", "Kriegs\u00b7ver\u00b7bre\u00b7chen", "ge\u00b7bil\u00b7ligt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Keine Sorgen \u2013 alles bewilligt!", "tokens": ["Kei\u00b7ne", "Sor\u00b7gen", "\u2013", "al\u00b7les", "be\u00b7wil\u00b7ligt", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$(", "PIS", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Und was auch die Republik verspricht:", "tokens": ["Und", "was", "auch", "die", "Re\u00b7pub\u00b7lik", "ver\u00b7spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Warum eigentlich nicht \u2013?", "tokens": ["Wa\u00b7rum", "ei\u00b7gent\u00b7lich", "nicht", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADV", "PTKNEG", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Dem Reisenden ist Ruhe zu g\u00f6nnen.", "tokens": ["Dem", "Rei\u00b7sen\u00b7den", "ist", "Ru\u00b7he", "zu", "g\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Flucht h\u00e4tte er sich sparen k\u00f6nnen.", "tokens": ["Die", "Flucht", "h\u00e4t\u00b7te", "er", "sich", "spa\u00b7ren", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PRF", "VVINF", "VMINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie sind ja so artig . . .", "tokens": ["Sie", "sind", "ja", "so", "ar\u00b7tig", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "$.", "$.", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Denn eine deutsche Revolution, die eint,", "tokens": ["Denn", "ei\u00b7ne", "deut\u00b7sche", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", ",", "die", "eint", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "ist niemals nicht pers\u00f6nlich gemeint.", "tokens": ["ist", "nie\u00b7mals", "nicht", "per\u00b7s\u00f6n\u00b7lich", "ge\u00b7meint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Fahr nicht nach Homburg. Komm nach Berlin!", "tokens": ["Fahr", "nicht", "nach", "Hom\u00b7burg", ".", "Komm", "nach", "Ber\u00b7lin", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "APPR", "NE", "$.", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Kehr zur\u00fcck! Hier wird dich alles verziehn.", "tokens": ["Kehr", "zu\u00b7r\u00fcck", "!", "Hier", "wird", "dich", "al\u00b7les", "ver\u00b7ziehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "PIS", "VVINF", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.5": {"line.1": {"text": "In Holland ruht des Holzhauers Hacke.", "tokens": ["In", "Hol\u00b7land", "ruht", "des", "Holz\u00b7hau\u00b7ers", "Ha\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da ist eitel Freude und Koffergepacke \u2013", "tokens": ["Da", "ist", "ei\u00b7tel", "Freu\u00b7de", "und", "Kof\u00b7fer\u00b7ge\u00b7pa\u00b7cke", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "NN", "KON", "NN", "$("], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "au Backe!", "tokens": ["au", "Ba\u00b7cke", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Da legen Lakaien in die ganz enormen", "tokens": ["Da", "le\u00b7gen", "La\u00b7kai\u00b7en", "in", "die", "ganz", "en\u00b7or\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "APPR", "ART", "ADV", "VVINF"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Kisten die feldgrauen Uniformen . . .", "tokens": ["Kis\u00b7ten", "die", "feld\u00b7grau\u00b7en", "U\u00b7nif\u00b7or\u00b7men", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "\u00bber kehrt uns zur\u00fcck\u00ab, sagt der Zeitungsbericht.", "tokens": ["\u00bb", "er", "kehrt", "uns", "zu\u00b7r\u00fcck", "\u00ab", ",", "sagt", "der", "Zei\u00b7tungs\u00b7be\u00b7richt", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PTKVZ", "$(", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Warum eigentlich nicht \u2013?", "tokens": ["Wa\u00b7rum", "ei\u00b7gent\u00b7lich", "nicht", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADV", "PTKNEG", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Warum eigentlich nicht \u2013?", "tokens": ["Wa\u00b7rum", "ei\u00b7gent\u00b7lich", "nicht", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADV", "PTKNEG", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Im Fall eines Falles", "tokens": ["Im", "Fall", "ei\u00b7nes", "Fal\u00b7les"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "f\u00e4nde er ja doch schlie\u00dflich alles", "tokens": ["f\u00e4n\u00b7de", "er", "ja", "doch", "schlie\u00df\u00b7lich", "al\u00b7les"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV", "PIS"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "unver\u00e4ndert . . .", "tokens": ["un\u00b7ver\u00b7\u00e4n\u00b7dert", ".", ".", "."], "token_info": ["word", "punct", "punct", "punct"], "pos": ["ADJD", "$.", "$.", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Seine Richter. Sein Milit\u00e4r.", "tokens": ["Sei\u00b7ne", "Rich\u00b7ter", ".", "Sein", "Mi\u00b7li\u00b7t\u00e4r", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Seine Untertanen. Und noch viel mehr:", "tokens": ["Sei\u00b7ne", "Un\u00b7ter\u00b7ta\u00b7nen", ".", "Und", "noch", "viel", "mehr", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "KON", "ADV", "ADV", "ADV", "$."], "meter": "+-+-+----+", "measure": "unknown.measure.tetra"}, "line.7": {"text": "Seinen Feldmarschall. Seinen Schulunterricht.", "tokens": ["Sei\u00b7nen", "Feld\u00b7mar\u00b7schall", ".", "Sei\u00b7nen", "Schul\u00b7un\u00b7ter\u00b7richt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Also warum eigentlich nicht \u2013?", "tokens": ["Al\u00b7so", "wa\u00b7rum", "ei\u00b7gent\u00b7lich", "nicht", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PWAV", "ADV", "PTKNEG", "$(", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.7": {"line.1": {"text": "Er f\u00e4nde auch seinen Reichstag wieder.", "tokens": ["Er", "f\u00e4n\u00b7de", "auch", "sei\u00b7nen", "Reichs\u00b7tag", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "ADV", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "H\u00f6rte die alten, lieben Lieder", "tokens": ["H\u00f6r\u00b7te", "die", "al\u00b7ten", ",", "lie\u00b7ben", "Lie\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "der Sozialdemokraten . . .", "tokens": ["der", "So\u00b7zi\u00b7al\u00b7de\u00b7mo\u00b7kra\u00b7ten", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "$.", "$.", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da sitzen noch dieselben Leute,", "tokens": ["Da", "sit\u00b7zen", "noch", "die\u00b7sel\u00b7ben", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die mit ihm gebr\u00fcllt \u2013 damals wie heute.", "tokens": ["die", "mit", "ihm", "ge\u00b7br\u00fcllt", "\u2013", "da\u00b7mals", "wie", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VVPP", "$(", "ADV", "KOKOM", "ADV", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Die seine Kriegsverbrechen gebilligt.", "tokens": ["Die", "sei\u00b7ne", "Kriegs\u00b7ver\u00b7bre\u00b7chen", "ge\u00b7bil\u00b7ligt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Keine Sorgen \u2013 alles bewilligt!", "tokens": ["Kei\u00b7ne", "Sor\u00b7gen", "\u2013", "al\u00b7les", "be\u00b7wil\u00b7ligt", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$(", "PIS", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Und was auch die Republik verspricht:", "tokens": ["Und", "was", "auch", "die", "Re\u00b7pub\u00b7lik", "ver\u00b7spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Warum eigentlich nicht \u2013?", "tokens": ["Wa\u00b7rum", "ei\u00b7gent\u00b7lich", "nicht", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADV", "PTKNEG", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Dem Reisenden ist Ruhe zu g\u00f6nnen.", "tokens": ["Dem", "Rei\u00b7sen\u00b7den", "ist", "Ru\u00b7he", "zu", "g\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Flucht h\u00e4tte er sich sparen k\u00f6nnen.", "tokens": ["Die", "Flucht", "h\u00e4t\u00b7te", "er", "sich", "spa\u00b7ren", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PRF", "VVINF", "VMINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie sind ja so artig . . .", "tokens": ["Sie", "sind", "ja", "so", "ar\u00b7tig", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "$.", "$.", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Denn eine deutsche Revolution, die eint,", "tokens": ["Denn", "ei\u00b7ne", "deut\u00b7sche", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", ",", "die", "eint", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "ist niemals nicht pers\u00f6nlich gemeint.", "tokens": ["ist", "nie\u00b7mals", "nicht", "per\u00b7s\u00f6n\u00b7lich", "ge\u00b7meint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Fahr nicht nach Homburg. Komm nach Berlin!", "tokens": ["Fahr", "nicht", "nach", "Hom\u00b7burg", ".", "Komm", "nach", "Ber\u00b7lin", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "APPR", "NE", "$.", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Kehr zur\u00fcck! Hier wird dich alles verziehn.", "tokens": ["Kehr", "zu\u00b7r\u00fcck", "!", "Hier", "wird", "dich", "al\u00b7les", "ver\u00b7ziehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "PIS", "VVINF", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}}}}