{"textgrid.poem.46743": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "[das erste Fr\u00fchlingsblatt]", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das erste Fr\u00fchlingsblatt", "tokens": ["Das", "ers\u00b7te", "Fr\u00fch\u00b7lings\u00b7blatt"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Fand ich voll seltner Chiffern,", "tokens": ["Fand", "ich", "voll", "selt\u00b7ner", "Chif\u00b7fern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es wurde gar nicht satt", "tokens": ["Es", "wur\u00b7de", "gar", "nicht", "satt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Mein Herz sie zu entziffern.", "tokens": ["Mein", "Herz", "sie", "zu", "ent\u00b7zif\u00b7fern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Es war eine Liebesschrift", "tokens": ["Es", "war", "ei\u00b7ne", "Lie\u00b7bes\u00b7schrift"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Von einer Hand geschrieben,", "tokens": ["Von", "ei\u00b7ner", "Hand", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die mit dem k\u00fcnstlichen Stift", "tokens": ["Die", "mit", "dem", "k\u00fcnst\u00b7li\u00b7chen", "Stift"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "---+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Es noch nicht lang getrieben.", "tokens": ["Es", "noch", "nicht", "lang", "ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Und als ich den Schl\u00fcssel fand,", "tokens": ["Und", "als", "ich", "den", "Schl\u00fcs\u00b7sel", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie froh war ich ger\u00fchret!", "tokens": ["Wie", "froh", "war", "ich", "ge\u00b7r\u00fch\u00b7ret", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Engel hat die Hand", "tokens": ["Ein", "En\u00b7gel", "hat", "die", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Meines Kindes gef\u00fchret.", "tokens": ["Mei\u00b7nes", "Kin\u00b7des", "ge\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.4": {"line.1": {"text": "Das hier der Schul' entlief,", "tokens": ["Das", "hier", "der", "Schul'", "ent\u00b7lief", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ist dort darein genommen,", "tokens": ["Ist", "dort", "da\u00b7rein", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PAV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und dieser erste Brief", "tokens": ["Und", "die\u00b7ser", "ers\u00b7te", "Brief"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PDAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ist mir von ihm gekommen.", "tokens": ["Ist", "mir", "von", "ihm", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Es hat in kurzer Frist", "tokens": ["Es", "hat", "in", "kur\u00b7zer", "Frist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Schon artig lernen schreiben,", "tokens": ["Schon", "ar\u00b7tig", "ler\u00b7nen", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und viel zu hoffen ist,", "tokens": ["Und", "viel", "zu", "hof\u00b7fen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wenn es wird flei\u00dfig bleiben.", "tokens": ["Wenn", "es", "wird", "flei\u00b7\u00dfig", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Das erste Fr\u00fchlingsblatt", "tokens": ["Das", "ers\u00b7te", "Fr\u00fch\u00b7lings\u00b7blatt"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Fand ich voll seltner Chiffern,", "tokens": ["Fand", "ich", "voll", "selt\u00b7ner", "Chif\u00b7fern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es wurde gar nicht satt", "tokens": ["Es", "wur\u00b7de", "gar", "nicht", "satt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Mein Herz sie zu entziffern.", "tokens": ["Mein", "Herz", "sie", "zu", "ent\u00b7zif\u00b7fern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Es war eine Liebesschrift", "tokens": ["Es", "war", "ei\u00b7ne", "Lie\u00b7bes\u00b7schrift"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Von einer Hand geschrieben,", "tokens": ["Von", "ei\u00b7ner", "Hand", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die mit dem k\u00fcnstlichen Stift", "tokens": ["Die", "mit", "dem", "k\u00fcnst\u00b7li\u00b7chen", "Stift"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "---+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Es noch nicht lang getrieben.", "tokens": ["Es", "noch", "nicht", "lang", "ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und als ich den Schl\u00fcssel fand,", "tokens": ["Und", "als", "ich", "den", "Schl\u00fcs\u00b7sel", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie froh war ich ger\u00fchret!", "tokens": ["Wie", "froh", "war", "ich", "ge\u00b7r\u00fch\u00b7ret", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Engel hat die Hand", "tokens": ["Ein", "En\u00b7gel", "hat", "die", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Meines Kindes gef\u00fchret.", "tokens": ["Mei\u00b7nes", "Kin\u00b7des", "ge\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.9": {"line.1": {"text": "Das hier der Schul' entlief,", "tokens": ["Das", "hier", "der", "Schul'", "ent\u00b7lief", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ist dort darein genommen,", "tokens": ["Ist", "dort", "da\u00b7rein", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PAV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und dieser erste Brief", "tokens": ["Und", "die\u00b7ser", "ers\u00b7te", "Brief"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PDAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ist mir von ihm gekommen.", "tokens": ["Ist", "mir", "von", "ihm", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Es hat in kurzer Frist", "tokens": ["Es", "hat", "in", "kur\u00b7zer", "Frist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Schon artig lernen schreiben,", "tokens": ["Schon", "ar\u00b7tig", "ler\u00b7nen", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und viel zu hoffen ist,", "tokens": ["Und", "viel", "zu", "hof\u00b7fen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wenn es wird flei\u00dfig bleiben.", "tokens": ["Wenn", "es", "wird", "flei\u00b7\u00dfig", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}