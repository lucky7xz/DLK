{"dta.poem.2746": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Letzter Zuruff/  \n  An Hn. P. F. den 7. April  1680.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mein Freund/ so haut der Tod dein Fleisch in tausend\nSt\u00fccke/", "tokens": ["Mein", "Freund", "/", "so", "haut", "der", "Tod", "dein", "Fleisch", "in", "tau\u00b7send", "St\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "ADV", "VVFIN", "ART", "NN", "PPOSAT", "NN", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und \u00fcberliefert es den W\u00fcrmen zu der Kost/", "tokens": ["Und", "\u00fc\u00b7berl\u00b7ie\u00b7fert", "es", "den", "W\u00fcr\u00b7men", "zu", "der", "Kost", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du bist nunmehr befreyt/ ich steh noch auf der Br\u00fccke/", "tokens": ["Du", "bist", "nun\u00b7mehr", "be\u00b7freyt", "/", "ich", "steh", "noch", "auf", "der", "Br\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$(", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und hoffe weiter nichts als Schimmel/ F\u00e4ul\u2019 und Rost.", "tokens": ["Und", "hof\u00b7fe", "wei\u00b7ter", "nichts", "als", "Schim\u00b7mel", "/", "F\u00e4ul'", "und", "Rost", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIS", "KOKOM", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mu\u00df uns die Fr\u00fchlings Lust zu einem Kirchhof werden/", "tokens": ["Mu\u00df", "uns", "die", "Fr\u00fch\u00b7lings", "Lust", "zu", "ei\u00b7nem", "Kirch\u00b7hof", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "NN", "APPR", "ART", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist denn dein Sommer-Hau\u00df ein schwartzes Leichen-Bret?", "tokens": ["Ist", "denn", "dein", "Som\u00b7mer\u00b7Hau\u00df", "ein", "schwart\u00b7zes", "Lei\u00b7chen\u00b7Bret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Sonn erfreu\u2019t die Welt mit ihren g\u00fcldnen Pferden/", "tokens": ["Die", "Sonn", "er\u00b7freu't", "die", "Welt", "mit", "ih\u00b7ren", "g\u00fcld\u00b7nen", "Pfer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da ein breit Eisen dir macht auff die Grabe St\u00e4tt.", "tokens": ["Da", "ein", "breit", "Ei\u00b7sen", "dir", "macht", "auff", "die", "Gra\u00b7be", "St\u00e4tt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "NN", "PPER", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wo bleibt nun unser Wunsch/ wo bleibet das Versprechen:", "tokens": ["Wo", "bleibt", "nun", "un\u00b7ser", "Wunsch", "/", "wo", "blei\u00b7bet", "das", "Ver\u00b7spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "PPOSAT", "NN", "$(", "PWAV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ach der ergrimmte Tod reist allen Vorsatz ein!", "tokens": ["Ach", "der", "er\u00b7grimm\u00b7te", "Tod", "reist", "al\u00b7len", "Vor\u00b7satz", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ART", "ADJA", "NN", "VVFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und wird uns unverhofft die m\u00fcden Augen brechen", "tokens": ["Und", "wird", "uns", "un\u00b7ver\u00b7hofft", "die", "m\u00fc\u00b7den", "Au\u00b7gen", "bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df auch der Sternen Licht mu\u00df Asch und Schatten seyn.", "tokens": ["Da\u00df", "auch", "der", "Ster\u00b7nen", "Licht", "mu\u00df", "Asch", "und", "Schat\u00b7ten", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "NN", "VMFIN", "NN", "KON", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wie aber gehstu hin? Ein Held f\u00e4llt unter Wunden", "tokens": ["Wie", "a\u00b7ber", "gehs\u00b7tu", "hin", "?", "Ein", "Held", "f\u00e4llt", "un\u00b7ter", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN", "PTKVZ", "$.", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Sein Purpur f\u00e4rbet offt des Feindes Angesicht.", "tokens": ["Sein", "Pur\u00b7pur", "f\u00e4r\u00b7bet", "offt", "des", "Fein\u00b7des", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Schiffer hat den Tod in w\u00fcster See gefunden/", "tokens": ["Der", "Schif\u00b7fer", "hat", "den", "Tod", "in", "w\u00fcs\u00b7ter", "See", "ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ein Bergmann der verf\u00e4llt wenn Fahrt und Gang einbricht.", "tokens": ["Ein", "Berg\u00b7mann", "der", "ver\u00b7f\u00e4llt", "wenn", "Fahrt", "und", "Gang", "ein\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "KOUS", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Du als ein Handels Mann ge\u00fcbet durch viel Reisen", "tokens": ["Du", "als", "ein", "Han\u00b7dels", "Mann", "ge\u00b7\u00fc\u00b7bet", "durch", "viel", "Rei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "KOUS", "ART", "NN", "NN", "VVPP", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und der viel Wechsel scho\u00df/ verschleust dich in den Sarck/", "tokens": ["Und", "der", "viel", "Wech\u00b7sel", "scho\u00df", "/", "ver\u00b7schleust", "dich", "in", "den", "Sarck", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIAT", "NN", "VVFIN", "$(", "VVFIN", "PRF", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Willst unsrer lieben Stadt und Leipzig noch erweisen/", "tokens": ["Willst", "uns\u00b7rer", "lie\u00b7ben", "Stadt", "und", "Leip\u00b7zig", "noch", "er\u00b7wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "KON", "NE", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wie r\u00fchmlich du vollf\u00fchrt hast deines Lebens-Marck.", "tokens": ["Wie", "r\u00fchm\u00b7lich", "du", "voll\u00b7f\u00fchrt", "hast", "dei\u00b7nes", "Le\u00b7bens\u00b7Ma\u00b7rck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVPP", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.21": {"text": "Jtzt da der Jahrmarckt kommt/ bald in den ersten Tagen", "tokens": ["Jtzt", "da", "der", "Jahr\u00b7marckt", "kommt", "/", "bald", "in", "den", "ers\u00b7ten", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "$(", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-++-++-+-+-", "measure": "unknown.measure.septa"}, "line.22": {"text": "Hastu dein Gut verkehrt. Was? nichts als Staub und Koth.", "tokens": ["Has\u00b7tu", "dein", "Gut", "ver\u00b7kehrt", ".", "Was", "?", "nichts", "als", "Staub", "und", "Koth", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "VVPP", "$.", "PWS", "$.", "PIS", "KOKOM", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Wird eine kunde wonach Herr ", "tokens": ["Wird", "ei\u00b7ne", "kun\u00b7de", "wo\u00b7nach", "Herr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "So spricht der Diener Mund er ist schon kalt und todt.", "tokens": ["So", "spricht", "der", "Die\u00b7ner", "Mund", "er", "ist", "schon", "kalt", "und", "todt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ach Wechsel voller Gl\u00fcck? ach Handlung voller Seegen!", "tokens": ["Ach", "Wech\u00b7sel", "vol\u00b7ler", "Gl\u00fcck", "?", "ach", "Hand\u00b7lung", "vol\u00b7ler", "See\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "ADJA", "NN", "$.", "XY", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Der ewige Gewinn hat dir bi\u00dfher gefehlt/", "tokens": ["Der", "e\u00b7wi\u00b7ge", "Ge\u00b7winn", "hat", "dir", "bi\u00df\u00b7her", "ge\u00b7fehlt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Da\u00df man dich Lebens satt m\u00f6cht in die Erde legen", "tokens": ["Da\u00df", "man", "dich", "Le\u00b7bens", "satt", "m\u00f6cht", "in", "die", "Er\u00b7de", "le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PRF", "NN", "ADJD", "VMFIN", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Erm\u00fcdet von viel Angst und strenger Noth gequ\u00e4lt.", "tokens": ["Er\u00b7m\u00fc\u00b7det", "von", "viel", "Angst", "und", "stren\u00b7ger", "Noth", "ge\u00b7qu\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PIAT", "NN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Der in Siberien auff ewig ist verbannet/", "tokens": ["Der", "in", "Si\u00b7be\u00b7ri\u00b7en", "auff", "e\u00b7wig", "ist", "ver\u00b7ban\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "APPR", "ADJD", "VAFIN", "VVPP", "$("], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.30": {"text": "Und den der Mittag kocht auff einer Ruder Banck/", "tokens": ["Und", "den", "der", "Mit\u00b7tag", "kocht", "auff", "ei\u00b7ner", "Ru\u00b7der", "Banck", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Der an den Hacken ligt/ an Foltern ist gespannet", "tokens": ["Der", "an", "den", "Ha\u00b7cken", "ligt", "/", "an", "Fol\u00b7tern", "ist", "ge\u00b7span\u00b7net"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$(", "APPR", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Der Gifft zur Speise hat und Schirling zu dem Tranck/", "tokens": ["Der", "Gifft", "zur", "Spei\u00b7se", "hat", "und", "Schir\u00b7ling", "zu", "dem", "Tranck", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "KON", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Empfindt nicht solche Pein als wie du hast erlitten;", "tokens": ["Emp\u00b7findt", "nicht", "sol\u00b7che", "Pein", "als", "wie", "du", "hast", "er\u00b7lit\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PIAT", "NN", "KON", "PWAV", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Des Nero Tyranney ist noch Barmhertzigkeit:", "tokens": ["Des", "Ne\u00b7ro", "Ty\u00b7ran\u00b7ney", "ist", "noch", "Barm\u00b7hert\u00b7zig\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "So hat kein Hencker je gebrennet und geschnidten", "tokens": ["So", "hat", "kein", "Hen\u00b7cker", "je", "ge\u00b7bren\u00b7net", "und", "ge\u00b7schnid\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "VVPP", "KON", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Als dich die grause Gicht gekr\u00fcmmet wie ein Scheit.", "tokens": ["Als", "dich", "die", "grau\u00b7se", "Gicht", "ge\u00b7kr\u00fcm\u00b7met", "wie", "ein", "Scheit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVPP", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Doch sey mir noch vergunt/ O Seeliger zu fragen?", "tokens": ["Doch", "sey", "mir", "noch", "ver\u00b7gunt", "/", "O", "See\u00b7li\u00b7ger", "zu", "fra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADJD", "$(", "NE", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Hat dein Gew\u00f6lbe nicht den k\u00fchnen Tod verblendt?", "tokens": ["Hat", "dein", "Ge\u00b7w\u00f6l\u00b7be", "nicht", "den", "k\u00fch\u00b7nen", "Tod", "ver\u00b7blendt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PTKNEG", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Und unterstand er sich in Marck dich zu betagen", "tokens": ["Und", "un\u00b7ter\u00b7stand", "er", "sich", "in", "Marck", "dich", "zu", "be\u00b7ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PRF", "APPR", "NN", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Da sonst ein jederman der M\u00e4rckte Freyheit kennt?", "tokens": ["Da", "sonst", "ein", "je\u00b7der\u00b7man", "der", "M\u00e4rck\u00b7te", "Frey\u00b7heit", "kennt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "PIS", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "War denn kein Zeug nicht da/ da\u00df man die d\u00fcrren Beine", "tokens": ["War", "denn", "kein", "Zeug", "nicht", "da", "/", "da\u00df", "man", "die", "d\u00fcr\u00b7ren", "Bei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "PTKNEG", "ADV", "$(", "KOUS", "PIS", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.42": {"text": "So viel nur m\u00f6glich schien aufs zierlichste bedeckt?", "tokens": ["So", "viel", "nur", "m\u00f6g\u00b7lich", "schien", "aufs", "zier\u00b7lichs\u00b7te", "be\u00b7deckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "VVFIN", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Hatt\u2019 er nicht seine Lust an Sammt und Atlas Scheine", "tokens": ["Hatt'", "er", "nicht", "sei\u00b7ne", "Lust", "an", "Sammt", "und", "At\u00b7las", "Schei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "APPR", "NN", "KON", "NE", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.44": {"text": "Da\u00df ihm der K\u00fcnstler Stich Mitleiden h\u00e4tt erweckt?", "tokens": ["Da\u00df", "ihm", "der", "K\u00fcnst\u00b7ler", "Stich", "Mit\u00b7lei\u00b7den", "h\u00e4tt", "er\u00b7weckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Hie\u00df St\u00fcckwerck und Gespienst ihm eine Spinne-Webe?", "tokens": ["Hie\u00df", "St\u00fcck\u00b7werck", "und", "Ge\u00b7spi\u00b7enst", "ihm", "ei\u00b7ne", "Spin\u00b7ne\u00b7We\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "PPER", "ART", "NN", "$."], "meter": "-++-+++-+-+-+-", "measure": "unknown.measure.octa.plus"}, "line.46": {"text": "Wie kleidet sich der Tod in keine Moden nicht?", "tokens": ["Wie", "klei\u00b7det", "sich", "der", "Tod", "in", "kei\u00b7ne", "Mo\u00b7den", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "ART", "NN", "APPR", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Und bleibt er immer so wie eine schwancke Rebe?", "tokens": ["Und", "bleibt", "er", "im\u00b7mer", "so", "wie", "ei\u00b7ne", "schwan\u00b7cke", "Re\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Ergetzet kein Damast sein holes Angesicht?", "tokens": ["Er\u00b7get\u00b7zet", "kein", "Da\u00b7mast", "sein", "ho\u00b7les", "An\u00b7ge\u00b7sicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "So forsch ich weiter nach: Was hast du denn verhandelt?", "tokens": ["So", "forsch", "ich", "wei\u00b7ter", "nach", ":", "Was", "hast", "du", "denn", "ver\u00b7han\u00b7delt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "PTKVZ", "$.", "PWS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Dein zugeschlossner Mund spricht! Ach mein Fleisch/ das", "tokens": ["Dein", "zu\u00b7ge\u00b7schloss\u00b7ner", "Mund", "spricht", "!", "Ach", "mein", "Fleisch", "/", "das"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$.", "ITJ", "PPOSAT", "NN", "$(", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.51": {"text": "Weil der/ der endlich auch die Himmel selbst verwandelt", "tokens": ["Weil", "der", "/", "der", "end\u00b7lich", "auch", "die", "Him\u00b7mel", "selbst", "ver\u00b7wan\u00b7delt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "$(", "ART", "ADV", "ADV", "ART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "(heu/", "tokens": ["(", "heu", "/"], "token_info": ["punct", "word", "punct"], "pos": ["$(", "ADV", "$("], "meter": "+", "measure": "single.up"}, "line.53": {"text": "Mir l\u00e4ngst ins Ohr gerufft/ da\u00df ich verg\u00e4nglich sey.", "tokens": ["Mir", "l\u00e4ngst", "ins", "Ohr", "ge\u00b7rufft", "/", "da\u00df", "ich", "ver\u00b7g\u00e4ng\u00b7lich", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "VVPP", "$(", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Nun wunder\u2019 ich mich mehr: welch Weltling kan es leiden", "tokens": ["Nun", "wun\u00b7der'", "ich", "mich", "mehr", ":", "welch", "Welt\u00b7ling", "kan", "es", "lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "$.", "PWAT", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Wenn \u00fcber die Geb\u00fchr sich einer kleiden l\u00e4st?", "tokens": ["Wenn", "\u00fc\u00b7ber", "die", "Ge\u00b7b\u00fchr", "sich", "ei\u00b7ner", "klei\u00b7den", "l\u00e4st", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PRF", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Und du/ dem nichts gebrach an feinsten Sammt und Seiden", "tokens": ["Und", "du", "/", "dem", "nichts", "ge\u00b7brach", "an", "feins\u00b7ten", "Sammt", "und", "Sei\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$(", "ART", "PIS", "VVFIN", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Erf\u00e4hrest da\u00df der Tod auch dieses stehen l\u00e4st/", "tokens": ["Er\u00b7f\u00e4h\u00b7rest", "da\u00df", "der", "Tod", "auch", "die\u00b7ses", "ste\u00b7hen", "l\u00e4st", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOUS", "ART", "NN", "ADV", "PDAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Und kleidet sich in Fleisch. Er hat es zwar vonn\u00f6then", "tokens": ["Und", "klei\u00b7det", "sich", "in", "Fleisch", ".", "Er", "hat", "es", "zwar", "von\u00b7n\u00f6\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "$.", "PPER", "VAFIN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Da\u00df er die leere Schos und magern H\u00fcfften ziert.", "tokens": ["Da\u00df", "er", "die", "lee\u00b7re", "Schos", "und", "ma\u00b7gern", "H\u00fcff\u00b7ten", "ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Hingegen solte nicht der freche Mensch err\u00f6then", "tokens": ["Hin\u00b7ge\u00b7gen", "sol\u00b7te", "nicht", "der", "fre\u00b7che", "Mensch", "er\u00b7r\u00f6\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PTKNEG", "ART", "ADJA", "NN", "VVINF"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.61": {"text": "Da\u00df offt ein gantzer Krahm f\u00fcr ihn nicht Zeuge f\u00fchrt?", "tokens": ["Da\u00df", "offt", "ein", "gant\u00b7zer", "Krahm", "f\u00fcr", "ihn", "nicht", "Zeu\u00b7ge", "f\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPR", "PPER", "PTKNEG", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "So gibst du nun dein Fleisch das schlechste von den Waaren", "tokens": ["So", "gibst", "du", "nun", "dein", "Fleisch", "das", "schlechs\u00b7te", "von", "den", "Waa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "ART", "ADJA", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "O kluger Handels-Mann f\u00fcr jenen Himmels-Schatz.", "tokens": ["O", "klu\u00b7ger", "Han\u00b7dels\u00b7Mann", "f\u00fcr", "je\u00b7nen", "Him\u00b7mels\u00b7Schatz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "La\u00df Scharrer unsrer Zeit in alle Winckel fahren/", "tokens": ["La\u00df", "Schar\u00b7rer", "uns\u00b7rer", "Zeit", "in", "al\u00b7le", "Win\u00b7ckel", "fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Dein Hauptgut das beh\u00e4lt f\u00fcr allen G\u00fctern Platz.", "tokens": ["Dein", "Haupt\u00b7gut", "das", "be\u00b7h\u00e4lt", "f\u00fcr", "al\u00b7len", "G\u00fc\u00b7tern", "Platz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PDS", "VVFIN", "APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Und sinn\u2019 ich endlich aus die Gleichheit in den Dingen", "tokens": ["Und", "sinn'", "ich", "end\u00b7lich", "aus", "die", "Gleich\u00b7heit", "in", "den", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Gewichte/ Ma\u00df und Zahl ist auff den Punct erf\u00fcllt.", "tokens": ["Ge\u00b7wich\u00b7te", "/", "Ma\u00df", "und", "Zahl", "ist", "auff", "den", "Punct", "er\u00b7f\u00fcllt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Als in dem Paradie\u00df wir unbekleidet giengen", "tokens": ["Als", "in", "dem", "Pa\u00b7ra\u00b7die\u00df", "wir", "un\u00b7be\u00b7klei\u00b7det", "gien\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "PPER", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Hat Evens Vorwitz sich zum ersten eingeh\u00fcllt.", "tokens": ["Hat", "E\u00b7vens", "Vor\u00b7witz", "sich", "zum", "ers\u00b7ten", "ein\u00b7ge\u00b7h\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "PRF", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Und dieses S\u00fcnden-Kleid das ist uns erblich blieben.", "tokens": ["Und", "die\u00b7ses", "S\u00fcn\u00b7den\u00b7Kleid", "das", "ist", "uns", "er\u00b7blich", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "PDS", "VAFIN", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Ob unsre Leiber sonst auch alle Sch\u00f6nheit mahlt;", "tokens": ["Ob", "uns\u00b7re", "Lei\u00b7ber", "sonst", "auch", "al\u00b7le", "Sch\u00f6n\u00b7heit", "mahlt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "So sind doch sie dem Tod zum Eigenthum verschrieben", "tokens": ["So", "sind", "doch", "sie", "dem", "Tod", "zum", "Ei\u00b7gen\u00b7thum", "ver\u00b7schrie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PPER", "ART", "NN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Erfordert es mit Recht da\u00df man durch Sterben zahlt.", "tokens": ["Er\u00b7for\u00b7dert", "es", "mit", "Recht", "da\u00df", "man", "durch", "Ster\u00b7ben", "zahlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KOUS", "PIS", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Und was ist \u00e4hnlicher den allerbesten Zeugen", "tokens": ["Und", "was", "ist", "\u00e4hn\u00b7li\u00b7cher", "den", "al\u00b7ler\u00b7bes\u00b7ten", "Zeu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VAFIN", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Als unser Haut und Fleisch? sie sind aus nichts gemacht.", "tokens": ["Als", "un\u00b7ser", "Haut", "und", "Fleisch", "?", "sie", "sind", "aus", "nichts", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "NN", "$.", "PPER", "VAFIN", "APPR", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Gott hie\u00df aus einem Klo\u00df den ersten Menschen steigen/", "tokens": ["Gott", "hie\u00df", "aus", "ei\u00b7nem", "Klo\u00df", "den", "ers\u00b7ten", "Men\u00b7schen", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Hier hat ein Wurm und Kunst die Formen aus gedacht.", "tokens": ["Hier", "hat", "ein", "Wurm", "und", "Kunst", "die", "For\u00b7men", "aus", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "KON", "NN", "ART", "NN", "APPR", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Was ist verwe\u00dflicher als sch\u00f6ne Selden Waaren", "tokens": ["Was", "ist", "ver\u00b7we\u00df\u00b7li\u00b7cher", "als", "sch\u00f6\u00b7ne", "Sel\u00b7den", "Waa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADJD", "KOKOM", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Und eine sch\u00f6ne Haut die Perlen oft besch\u00e4mt?", "tokens": ["Und", "ei\u00b7ne", "sch\u00f6\u00b7ne", "Haut", "die", "Per\u00b7len", "oft", "be\u00b7sch\u00e4mt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Denn jene darf Gebrauch und Zeit nur \u00fcberfahren/", "tokens": ["Denn", "je\u00b7ne", "darf", "Ge\u00b7brauch", "und", "Zeit", "nur", "\u00fc\u00b7berf\u00b7ah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "NN", "KON", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Und den geraden Leib hat Kranckheit offt gel\u00e4hmt.", "tokens": ["Und", "den", "ge\u00b7ra\u00b7den", "Leib", "hat", "Kran\u00b7ck\u00b7heit", "offt", "ge\u00b7l\u00e4hmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.82": {"text": "Wie br\u00fcstet sich der Mensch wenn er so herrlich gl\u00e4ntzet?", "tokens": ["Wie", "br\u00fcs\u00b7tet", "sich", "der", "Mensch", "wenn", "er", "so", "herr\u00b7lich", "gl\u00e4nt\u00b7zet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "ART", "NN", "KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Und denckt nicht da\u00df ein Koth den andern \u00fcberdeckt.", "tokens": ["Und", "denckt", "nicht", "da\u00df", "ein", "Koth", "den", "an\u00b7dern", "\u00fc\u00b7berd\u00b7eckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "KOUS", "ART", "NN", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Wird nicht mit Perl und Gold ein stoltzes Haupt bekr\u00e4ntzet?", "tokens": ["Wird", "nicht", "mit", "Perl", "und", "Gold", "ein", "stolt\u00b7zes", "Haupt", "be\u00b7kr\u00b7\u00e4nt\u00b7zet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.85": {"text": "Darunter weiter nichts als Wust und Eyter steckt.", "tokens": ["Da\u00b7run\u00b7ter", "wei\u00b7ter", "nichts", "als", "Wust", "und", "Ey\u00b7ter", "steckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PIS", "KOKOM", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Ist unser Fleisch nun Heu/ gewidmet zum Verderben", "tokens": ["Ist", "un\u00b7ser", "Fleisch", "nun", "Heu", "/", "ge\u00b7wid\u00b7met", "zum", "Ver\u00b7der\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "NN", "$(", "VVPP", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Reitzt es und wird gereitzt/ f\u00fchrt es und wird verf\u00fchrt/", "tokens": ["Reitzt", "es", "und", "wird", "ge\u00b7reitzt", "/", "f\u00fchrt", "es", "und", "wird", "ver\u00b7f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VAFIN", "VVPP", "$(", "VVFIN", "PPER", "KON", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "So glaubt ein rechter Christ/ da\u00df wenn auch in dem Sterben", "tokens": ["So", "glaubt", "ein", "rech\u00b7ter", "Christ", "/", "da\u00df", "wenn", "auch", "in", "dem", "Ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$(", "KOUS", "KOUS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Der Tod sein Recht vollzieht er dennoch nichts verliehrt.", "tokens": ["Der", "Tod", "sein", "Recht", "voll\u00b7zieht", "er", "den\u00b7noch", "nichts", "ver\u00b7liehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Drumb werther Seeliger hastu sehr wol geschlossen.", "tokens": ["Drumb", "wert\u00b7her", "See\u00b7li\u00b7ger", "has\u00b7tu", "sehr", "wol", "ge\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Wie aber stell ich recht den grossen Nutzen f\u00fcr?", "tokens": ["Wie", "a\u00b7ber", "stell", "ich", "recht", "den", "gros\u00b7sen", "Nut\u00b7zen", "f\u00fcr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJD", "PPER", "ADV", "ART", "ADJA", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Bilantz und R\u00e4itung sind nur lauter Kinder-Possen/", "tokens": ["Bi\u00b7lantz", "und", "R\u00e4i\u00b7tung", "sind", "nur", "lau\u00b7ter", "Kin\u00b7der\u00b7Pos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "ADV", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Was Welt und zeiclich ist hat kein Gehore hier.", "tokens": ["Was", "Welt", "und", "zei\u00b7clich", "ist", "hat", "kein", "Ge\u00b7ho\u00b7re", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "ADJD", "VAFIN", "VAFIN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Da unser Heyland sich in unser Fleisch verkleidet/", "tokens": ["Da", "un\u00b7ser", "Hey\u00b7land", "sich", "in", "un\u00b7ser", "Fleisch", "ver\u00b7klei\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Da wuchs das Capital der Ewigkeit uns zu;", "tokens": ["Da", "wuchs", "das", "Ca\u00b7pi\u00b7tal", "der", "E\u00b7wig\u00b7keit", "uns", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Und als er an dem Creutz vor unsre Sunden leidet", "tokens": ["Und", "als", "er", "an", "dem", "Creutz", "vor", "uns\u00b7re", "Sun\u00b7den", "lei\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Da setzt er aus Gefahr uns in die sichre Ruh.", "tokens": ["Da", "setzt", "er", "aus", "Ge\u00b7fahr", "uns", "in", "die", "sich\u00b7re", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Es sey das Fleisch nun Heu: was ist daran gelegen?", "tokens": ["Es", "sey", "das", "Fleisch", "nun", "Heu", ":", "was", "ist", "da\u00b7ran", "ge\u00b7le\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "NN", "$.", "PWS", "VAFIN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Ob uns der W\u00fcrge-Mann die Knochen gleich zerhaut/", "tokens": ["Ob", "uns", "der", "W\u00fcr\u00b7ge\u00b7Mann", "die", "Kno\u00b7chen", "gleich", "zer\u00b7haut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Und wird uns durch das Grab wie durch ein Sieb ausfegen.", "tokens": ["Und", "wird", "uns", "durch", "das", "Grab", "wie", "durch", "ein", "Sieb", "aus\u00b7fe\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "APPR", "ART", "NN", "KOKOM", "APPR", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Versichert da\u00df sie sind zu gr\u00f6sserm Glantz vertraut.", "tokens": ["Ver\u00b7si\u00b7chert", "da\u00df", "sie", "sind", "zu", "gr\u00f6s\u00b7serm", "Glantz", "ver\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KOUS", "PPER", "VAFIN", "APPR", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Ach la\u00df erblaster Freund das Heu/ dein Fleisch/ verwelcken/", "tokens": ["Ach", "la\u00df", "er\u00b7blas\u00b7ter", "Freund", "das", "Heu", "/", "dein", "Fleisch", "/", "ver\u00b7wel\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ITJ", "ADV", "ADJA", "NN", "ART", "NN", "$(", "PPOSAT", "NN", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Du hast hier wol gelebt und schl\u00e4fft mit Ehren ein/", "tokens": ["Du", "hast", "hier", "wol", "ge\u00b7lebt", "und", "schl\u00e4fft", "mit", "Eh\u00b7ren", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "KON", "VVFIN", "APPR", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "So prangt dein Garten nicht mit Wunder bunten Nelcken/", "tokens": ["So", "prangt", "dein", "Gar\u00b7ten", "nicht", "mit", "Wun\u00b7der", "bun\u00b7ten", "Nel\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PTKNEG", "APPR", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Als dermahleinst dein Fleisch wird auffgekl\u00e4ret seyn.", "tokens": ["Als", "der\u00b7mah\u00b7le\u00b7inst", "dein", "Fleisch", "wird", "auff\u00b7ge\u00b7kl\u00e4\u00b7ret", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "VAFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.106": {"text": "&q;Des HErren Athem wird in dein Gebeine blasen", "tokens": ["&", "q", ";", "Des", "Her\u00b7ren", "A\u00b7them", "wird", "in", "dein", "Ge\u00b7bei\u00b7ne", "bla\u00b7sen"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "FM.la", "$.", "ART", "NN", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.107": {"text": "&q;Du wirst voll Safft und Krafft und Geistes aufferstehn.", "tokens": ["&", "q", ";", "Du", "wirst", "voll", "Safft", "und", "Krafft", "und", "Geis\u00b7tes", "auf\u00b7fer\u00b7stehn", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM.la", "$.", "PPER", "VAFIN", "ADJD", "NN", "KON", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.108": {"text": "&q;Es mag die tolle Welt in ihren S\u00fcnden rasen", "tokens": ["&", "q", ";", "Es", "mag", "die", "tol\u00b7le", "Welt", "in", "ih\u00b7ren", "S\u00fcn\u00b7den", "ra\u00b7sen"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "FM.la", "$.", "PPER", "VMFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.109": {"text": "&q;Sie mu\u00df wie Fleisch und Heu doch endlich untergehn.", "tokens": ["&", "q", ";", "Sie", "mu\u00df", "wie", "Fleisch", "und", "Heu", "doch", "end\u00b7lich", "un\u00b7ter\u00b7gehn", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM.la", "$.", "PPER", "VMFIN", "KOKOM", "NN", "KON", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}}}}}