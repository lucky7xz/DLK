{"textgrid.poem.55071": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Epiphaniasfest", "genre": "verse", "period": "N.A.", "pub_year": 1781, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Heil'gen Drei K\u00f6nig' mit ihrem Stern,", "tokens": ["Die", "Heil'\u00b7gen", "Drei", "K\u00f6\u00b7nig'", "mit", "ih\u00b7rem", "Stern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "CARD", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sie essen, sie trinken, und bezahlen nicht gern;", "tokens": ["Sie", "es\u00b7sen", ",", "sie", "trin\u00b7ken", ",", "und", "be\u00b7zah\u00b7len", "nicht", "gern", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVINF", "$,", "KON", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sie essen gern, sie trinken gern,", "tokens": ["Sie", "es\u00b7sen", "gern", ",", "sie", "trin\u00b7ken", "gern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie essen, trinken, und bezahlen nicht gern.", "tokens": ["Sie", "es\u00b7sen", ",", "trin\u00b7ken", ",", "und", "be\u00b7zah\u00b7len", "nicht", "gern", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "$,", "KON", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.2": {"line.1": {"text": "Die Heil'gen Drei K\u00f6nig' sind kommen allhier,", "tokens": ["Die", "Heil'\u00b7gen", "Drei", "K\u00f6\u00b7nig'", "sind", "kom\u00b7men", "all\u00b7hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "CARD", "NN", "VAFIN", "VVFIN", "ADV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Es sind ihrer drei und sind nicht ihrer vier;", "tokens": ["Es", "sind", "ih\u00b7rer", "drei", "und", "sind", "nicht", "ih\u00b7rer", "vier", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "KON", "VAFIN", "PTKNEG", "PPOSAT", "CARD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und wenn zu dreien der vierte w\u00e4r,", "tokens": ["Und", "wenn", "zu", "drei\u00b7en", "der", "vier\u00b7te", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPR", "CARD", "ART", "ADJA", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So w\u00e4r ein Heil'ger-Drei-K\u00f6nig mehr.", "tokens": ["So", "w\u00e4r", "ein", "Heil'\u00b7ger\u00b7Drei\u00b7K\u00f6\u00b7nig", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Ich erster bin der wei\u00df' und auch der sch\u00f6n',", "tokens": ["Ich", "ers\u00b7ter", "bin", "der", "wei\u00df'", "und", "auch", "der", "sch\u00f6n'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VAFIN", "ART", "ADJA", "KON", "ADV", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Bei Tage solltet ihr erst mich sehn!", "tokens": ["Bei", "Ta\u00b7ge", "soll\u00b7tet", "ihr", "erst", "mich", "sehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch ach, mit allen Spezerein", "tokens": ["Doch", "ach", ",", "mit", "al\u00b7len", "Spe\u00b7zer\u00b7ein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "XY", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Werd ich sein Tag kein M\u00e4dchen mir erfrein.", "tokens": ["Werd", "ich", "sein", "Tag", "kein", "M\u00e4d\u00b7chen", "mir", "er\u00b7frein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "PIAT", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ich aber bin der braun' und bin der lang',", "tokens": ["Ich", "a\u00b7ber", "bin", "der", "braun'", "und", "bin", "der", "lang'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ART", "VVFIN", "KON", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Bekannt bei Weibern wohl und bei Gesang.", "tokens": ["Be\u00b7kannt", "bei", "Wei\u00b7bern", "wohl", "und", "bei", "Ge\u00b7sang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADV", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich bringe Gold statt Spezerein,", "tokens": ["Ich", "brin\u00b7ge", "Gold", "statt", "Spe\u00b7zer\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da werd ich \u00fcberall willkommen sein.", "tokens": ["Da", "werd", "ich", "\u00fc\u00b7be\u00b7rall", "will\u00b7kom\u00b7men", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ich endlich bin der schwarz' und bin der klein'", "tokens": ["Ich", "end\u00b7lich", "bin", "der", "schwa\u00b7rz'", "und", "bin", "der", "klein'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ART", "VVFIN", "KON", "VAFIN", "ART", "ADJA"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und mag auch wohl einmal recht lustig sein.", "tokens": ["Und", "mag", "auch", "wohl", "ein\u00b7mal", "recht", "lus\u00b7tig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADV", "ADV", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich esse gern, ich trinke gern,", "tokens": ["Ich", "es\u00b7se", "gern", ",", "ich", "trin\u00b7ke", "gern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich esse, trinke und bedanke mich gern.", "tokens": ["Ich", "es\u00b7se", ",", "trin\u00b7ke", "und", "be\u00b7dan\u00b7ke", "mich", "gern", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.6": {"line.1": {"text": "Die Heil'gen Drei K\u00f6nig' sind wohlgesinnt,", "tokens": ["Die", "Heil'\u00b7gen", "Drei", "K\u00f6\u00b7nig'", "sind", "wohl\u00b7ge\u00b7sinnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "CARD", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie suchen die Mutter und das Kind;", "tokens": ["Sie", "su\u00b7chen", "die", "Mut\u00b7ter", "und", "das", "Kind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Joseph fromm sitzt auch dabei,", "tokens": ["Der", "Jo\u00b7se\u00b7ph", "fromm", "sitzt", "auch", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJD", "VVFIN", "ADV", "PAV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Der Ochs und Esel liegen auf der Streu.", "tokens": ["Der", "Ochs", "und", "E\u00b7sel", "lie\u00b7gen", "auf", "der", "Streu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Wir bringen Myrrhen, wir bringen Gold,", "tokens": ["Wir", "brin\u00b7gen", "Myr\u00b7rhen", ",", "wir", "brin\u00b7gen", "Gold", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dem Weihrauch sind die Damen hold;", "tokens": ["Dem", "Weih\u00b7rauch", "sind", "die", "Da\u00b7men", "hold", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und haben wir Wein von gutem Gew\u00e4chs,", "tokens": ["Und", "ha\u00b7ben", "wir", "Wein", "von", "gu\u00b7tem", "Ge\u00b7w\u00e4chs", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So trinken wir drei so gut als ihrer sechs.", "tokens": ["So", "trin\u00b7ken", "wir", "drei", "so", "gut", "als", "ih\u00b7rer", "sechs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "CARD", "ADV", "ADJD", "KOKOM", "PPOSAT", "CARD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Da wir nun hier sch\u00f6ne Herrn und Fraun.", "tokens": ["Da", "wir", "nun", "hier", "sch\u00f6\u00b7ne", "Herrn", "und", "Fraun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJA", "NN", "KON", "NE", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Aber keine Ochsen und Esel schaun,", "tokens": ["A\u00b7ber", "kei\u00b7ne", "Och\u00b7sen", "und", "E\u00b7sel", "schaun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "So sind wir nicht am rechten Ort", "tokens": ["So", "sind", "wir", "nicht", "am", "rech\u00b7ten", "Ort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ziehen unseres Weges weiter fort.", "tokens": ["Und", "zie\u00b7hen", "un\u00b7se\u00b7res", "We\u00b7ges", "wei\u00b7ter", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "Die Heil'gen Drei K\u00f6nig' mit ihrem Stern,", "tokens": ["Die", "Heil'\u00b7gen", "Drei", "K\u00f6\u00b7nig'", "mit", "ih\u00b7rem", "Stern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "CARD", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sie essen, sie trinken, und bezahlen nicht gern;", "tokens": ["Sie", "es\u00b7sen", ",", "sie", "trin\u00b7ken", ",", "und", "be\u00b7zah\u00b7len", "nicht", "gern", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVINF", "$,", "KON", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sie essen gern, sie trinken gern,", "tokens": ["Sie", "es\u00b7sen", "gern", ",", "sie", "trin\u00b7ken", "gern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie essen, trinken, und bezahlen nicht gern.", "tokens": ["Sie", "es\u00b7sen", ",", "trin\u00b7ken", ",", "und", "be\u00b7zah\u00b7len", "nicht", "gern", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "$,", "KON", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.10": {"line.1": {"text": "Die Heil'gen Drei K\u00f6nig' sind kommen allhier,", "tokens": ["Die", "Heil'\u00b7gen", "Drei", "K\u00f6\u00b7nig'", "sind", "kom\u00b7men", "all\u00b7hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "CARD", "NN", "VAFIN", "VVFIN", "ADV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Es sind ihrer drei und sind nicht ihrer vier;", "tokens": ["Es", "sind", "ih\u00b7rer", "drei", "und", "sind", "nicht", "ih\u00b7rer", "vier", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "CARD", "KON", "VAFIN", "PTKNEG", "PPOSAT", "CARD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und wenn zu dreien der vierte w\u00e4r,", "tokens": ["Und", "wenn", "zu", "drei\u00b7en", "der", "vier\u00b7te", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPR", "CARD", "ART", "ADJA", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So w\u00e4r ein Heil'ger-Drei-K\u00f6nig mehr.", "tokens": ["So", "w\u00e4r", "ein", "Heil'\u00b7ger\u00b7Drei\u00b7K\u00f6\u00b7nig", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Ich erster bin der wei\u00df' und auch der sch\u00f6n',", "tokens": ["Ich", "ers\u00b7ter", "bin", "der", "wei\u00df'", "und", "auch", "der", "sch\u00f6n'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VAFIN", "ART", "ADJA", "KON", "ADV", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Bei Tage solltet ihr erst mich sehn!", "tokens": ["Bei", "Ta\u00b7ge", "soll\u00b7tet", "ihr", "erst", "mich", "sehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch ach, mit allen Spezerein", "tokens": ["Doch", "ach", ",", "mit", "al\u00b7len", "Spe\u00b7zer\u00b7ein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "XY", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Werd ich sein Tag kein M\u00e4dchen mir erfrein.", "tokens": ["Werd", "ich", "sein", "Tag", "kein", "M\u00e4d\u00b7chen", "mir", "er\u00b7frein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "PIAT", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Ich aber bin der braun' und bin der lang',", "tokens": ["Ich", "a\u00b7ber", "bin", "der", "braun'", "und", "bin", "der", "lang'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ART", "VVFIN", "KON", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Bekannt bei Weibern wohl und bei Gesang.", "tokens": ["Be\u00b7kannt", "bei", "Wei\u00b7bern", "wohl", "und", "bei", "Ge\u00b7sang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADV", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich bringe Gold statt Spezerein,", "tokens": ["Ich", "brin\u00b7ge", "Gold", "statt", "Spe\u00b7zer\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da werd ich \u00fcberall willkommen sein.", "tokens": ["Da", "werd", "ich", "\u00fc\u00b7be\u00b7rall", "will\u00b7kom\u00b7men", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Ich endlich bin der schwarz' und bin der klein'", "tokens": ["Ich", "end\u00b7lich", "bin", "der", "schwa\u00b7rz'", "und", "bin", "der", "klein'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ART", "VVFIN", "KON", "VAFIN", "ART", "ADJA"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und mag auch wohl einmal recht lustig sein.", "tokens": ["Und", "mag", "auch", "wohl", "ein\u00b7mal", "recht", "lus\u00b7tig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADV", "ADV", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich esse gern, ich trinke gern,", "tokens": ["Ich", "es\u00b7se", "gern", ",", "ich", "trin\u00b7ke", "gern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich esse, trinke und bedanke mich gern.", "tokens": ["Ich", "es\u00b7se", ",", "trin\u00b7ke", "und", "be\u00b7dan\u00b7ke", "mich", "gern", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.14": {"line.1": {"text": "Die Heil'gen Drei K\u00f6nig' sind wohlgesinnt,", "tokens": ["Die", "Heil'\u00b7gen", "Drei", "K\u00f6\u00b7nig'", "sind", "wohl\u00b7ge\u00b7sinnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "CARD", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie suchen die Mutter und das Kind;", "tokens": ["Sie", "su\u00b7chen", "die", "Mut\u00b7ter", "und", "das", "Kind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Joseph fromm sitzt auch dabei,", "tokens": ["Der", "Jo\u00b7se\u00b7ph", "fromm", "sitzt", "auch", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJD", "VVFIN", "ADV", "PAV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Der Ochs und Esel liegen auf der Streu.", "tokens": ["Der", "Ochs", "und", "E\u00b7sel", "lie\u00b7gen", "auf", "der", "Streu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Wir bringen Myrrhen, wir bringen Gold,", "tokens": ["Wir", "brin\u00b7gen", "Myr\u00b7rhen", ",", "wir", "brin\u00b7gen", "Gold", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dem Weihrauch sind die Damen hold;", "tokens": ["Dem", "Weih\u00b7rauch", "sind", "die", "Da\u00b7men", "hold", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und haben wir Wein von gutem Gew\u00e4chs,", "tokens": ["Und", "ha\u00b7ben", "wir", "Wein", "von", "gu\u00b7tem", "Ge\u00b7w\u00e4chs", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So trinken wir drei so gut als ihrer sechs.", "tokens": ["So", "trin\u00b7ken", "wir", "drei", "so", "gut", "als", "ih\u00b7rer", "sechs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "CARD", "ADV", "ADJD", "KOKOM", "PPOSAT", "CARD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.16": {"line.1": {"text": "Da wir nun hier sch\u00f6ne Herrn und Fraun.", "tokens": ["Da", "wir", "nun", "hier", "sch\u00f6\u00b7ne", "Herrn", "und", "Fraun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJA", "NN", "KON", "NE", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Aber keine Ochsen und Esel schaun,", "tokens": ["A\u00b7ber", "kei\u00b7ne", "Och\u00b7sen", "und", "E\u00b7sel", "schaun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "So sind wir nicht am rechten Ort", "tokens": ["So", "sind", "wir", "nicht", "am", "rech\u00b7ten", "Ort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ziehen unseres Weges weiter fort.", "tokens": ["Und", "zie\u00b7hen", "un\u00b7se\u00b7res", "We\u00b7ges", "wei\u00b7ter", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}}}}