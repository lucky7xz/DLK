{"dta.poem.10927": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "N\u00f6thige Lese-Schule.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1740", "urn": "urn:nbn:de:kobv:b4-200905198572", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Der Jdee vom Natur-Buch dacht ich neulich bey mir nach,", "tokens": ["Der", "Jdee", "vom", "Na\u00b7tur\u00b7Buch", "dacht", "ich", "neu\u00b7lich", "bey", "mir", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "PPER", "ADV", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Bis mich deucht, da\u00df die Natur selber folgends mit mir", "tokens": ["Bis", "mich", "deucht", ",", "da\u00df", "die", "Na\u00b7tur", "sel\u00b7ber", "fol\u00b7gends", "mit", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "$,", "KOUS", "ART", "NN", "ADV", "PIS", "APPR", "PPER"], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Jhr verstehet eure W\u00f6rter, und ihr k\u00f6nnet Schriften lesen,", "tokens": ["Ihr", "ver\u00b7ste\u00b7het", "eu\u00b7re", "W\u00f6r\u00b7ter", ",", "und", "ihr", "k\u00f6n\u00b7net", "Schrif\u00b7ten", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "PPER", "VMFIN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Meynt ihr denn, da\u00df ihr allein W\u00f6rter habt, und Schriften kennet,", "tokens": ["Meynt", "ihr", "denn", ",", "da\u00df", "ihr", "al\u00b7lein", "W\u00f6r\u00b7ter", "habt", ",", "und", "Schrif\u00b7ten", "ken\u00b7net", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "ADV", "NN", "VAFIN", "$,", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.5": {"text": "Da ihr doch derselben Zeichen blo\u00df allein durch mich benennet?", "tokens": ["Da", "ihr", "doch", "der\u00b7sel\u00b7ben", "Zei\u00b7chen", "blo\u00df", "al\u00b7lein", "durch", "mich", "be\u00b7nen\u00b7net", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PDAT", "NN", "ADV", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.6": {"text": "Es sind meine Red-und Schriften immer in der Welt gewesen.", "tokens": ["Es", "sind", "mei\u00b7ne", "Re\u00b7d\u00b7und", "Schrif\u00b7ten", "im\u00b7mer", "in", "der", "Welt", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "NN", "ADV", "APPR", "ART", "NN", "VAPP", "$."], "meter": "-+--+--+-+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Nehmt mein A B C zur Hand, das sind K\u00f6rper und Figuren,", "tokens": ["Nehmt", "mein", "A", "B", "C", "zur", "Hand", ",", "das", "sind", "K\u00f6r\u00b7per", "und", "Fi\u00b7gu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "XY", "XY", "XY", "APPRART", "NN", "$,", "PDS", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Von so mancherley verhandnen ungez\u00e4hlten Creaturen.", "tokens": ["Von", "so", "man\u00b7cher\u00b7ley", "ver\u00b7hand\u00b7nen", "un\u00b7ge\u00b7z\u00e4hl\u00b7ten", "Crea\u00b7tu\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.9": {"text": "Berge, B\u00e4ume, Thier u. Kr\u00e4uter, samt dem Meer u. denen Sternen,", "tokens": ["Ber\u00b7ge", ",", "B\u00e4u\u00b7me", ",", "Thier", "u.", "Kr\u00e4u\u00b7ter", ",", "samt", "dem", "Meer", "u.", "de\u00b7nen", "Ster\u00b7nen", ","], "token_info": ["word", "punct", "word", "punct", "word", "abbreviation", "word", "punct", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "APPR", "NN", "$,", "APPR", "ART", "NN", "APPR", "PRELS", "NN", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.10": {"text": "Sind so laut, als stumme Lettern. Aber ihr m\u00fc\u00dft lesen lernen.", "tokens": ["Sind", "so", "laut", ",", "als", "stum\u00b7me", "Let\u00b7tern", ".", "A\u00b7ber", "ihr", "m\u00fc\u00dft", "le\u00b7sen", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "KOUS", "ADJA", "NN", "$.", "KON", "PPER", "VMFIN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-+--+--+-", "measure": "trochaic.septa.relaxed"}, "line.11": {"text": "Euer Lesen lernet ihr, und gewi\u00df nicht sonder M\u00fch;", "tokens": ["Eu\u00b7er", "Le\u00b7sen", "ler\u00b7net", "ihr", ",", "und", "ge\u00b7wi\u00df", "nicht", "son\u00b7der", "M\u00fch", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "$,", "KON", "ADV", "PTKNEG", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.12": {"text": "Ist denn meine Schrift nicht werth, euch mit etwas Ernst, um sie", "tokens": ["Ist", "denn", "mei\u00b7ne", "Schrift", "nicht", "werth", ",", "euch", "mit", "et\u00b7was", "Ernst", ",", "um", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "ADJD", "$,", "PPER", "APPR", "PIAT", "NN", "$,", "KOUI", "PPER"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.13": {"text": "Zu begreifen, zu bequemen,", "tokens": ["Zu", "be\u00b7grei\u00b7fen", ",", "zu", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Und, des gro\u00dfen Inhalts halber, etwas M\u00fch zu \u00fcbernehmen?", "tokens": ["Und", ",", "des", "gro\u00b7\u00dfen", "In\u00b7halts", "hal\u00b7ber", ",", "et\u00b7was", "M\u00fch", "zu", "\u00fc\u00b7ber\u00b7neh\u00b7men", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ART", "ADJA", "NN", "APPO", "$,", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.15": {"text": "Meine Lettern k\u00f6nnen euch unvernehmlicher nicht scheinen,", "tokens": ["Mei\u00b7ne", "Let\u00b7tern", "k\u00f6n\u00b7nen", "euch", "un\u00b7ver\u00b7nehm\u00b7li\u00b7cher", "nicht", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "ADJD", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.16": {"text": "Als wenn ihr Arabiens krummgezogne Schriften seht,", "tokens": ["Als", "wenn", "ihr", "A\u00b7ra\u00b7biens", "krumm\u00b7ge\u00b7zog\u00b7ne", "Schrif\u00b7ten", "seht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPOSAT", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Da ihr doch, durch etwas M\u00fch, ihren Inhalt bald versteht,", "tokens": ["Da", "ihr", "doch", ",", "durch", "et\u00b7was", "M\u00fch", ",", "ih\u00b7ren", "In\u00b7halt", "bald", "ver\u00b7steht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$,", "APPR", "PIAT", "NN", "$,", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Und ihr d\u00fcrfet, da\u00df die meinen ganz unlesbar sind, nicht meynen.", "tokens": ["Und", "ihr", "d\u00fcr\u00b7fet", ",", "da\u00df", "die", "mei\u00b7nen", "ganz", "un\u00b7les\u00b7bar", "sind", ",", "nicht", "mey\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "KOUS", "ART", "VVFIN", "ADV", "ADJD", "VAFIN", "$,", "PTKNEG", "VVINF", "$."], "meter": "--+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Ja, gesetzt, ihr k\u00f6nnet nicht ihren Inhalt bald ergr\u00fcnden:", "tokens": ["Ja", ",", "ge\u00b7setzt", ",", "ihr", "k\u00f6n\u00b7net", "nicht", "ih\u00b7ren", "In\u00b7halt", "bald", "er\u00b7gr\u00fcn\u00b7den", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVPP", "$,", "PPER", "VMFIN", "PTKNEG", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "--+--+-+-+-+-+-", "measure": "anapaest.di.plus"}, "line.20": {"text": "Werdet ihr schon Weisheit gnug fast in jeder Letter finden.", "tokens": ["Wer\u00b7det", "ihr", "schon", "Weis\u00b7heit", "gnug", "fast", "in", "je\u00b7der", "Let\u00b7ter", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "ADV", "ADV", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.21": {"text": "Jeder Buchstab ist ein Buch, welches voller weisen Lehren,", "tokens": ["Je\u00b7der", "Buch\u00b7stab", "ist", "ein", "Buch", ",", "wel\u00b7ches", "vol\u00b7ler", "wei\u00b7sen", "Leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ART", "NN", "$,", "PWAT", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.22": {"text": "Jeder K\u00f6rper eine Schrift, welche, zu des Sch\u00f6pfers Ehren,", "tokens": ["Je\u00b7der", "K\u00f6r\u00b7per", "ei\u00b7ne", "Schrift", ",", "wel\u00b7che", ",", "zu", "des", "Sch\u00f6p\u00b7fers", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "$,", "PRELS", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-++-+-+-+-", "measure": "unknown.measure.octa.plus"}, "line.23": {"text": "Macht und Lieb und Weisheit weist. Fange doch nun jedermann,", "tokens": ["Macht", "und", "Lieb", "und", "Weis\u00b7heit", "weist", ".", "Fan\u00b7ge", "doch", "nun", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "VVFIN", "$.", "NN", "ADV", "ADV", "PIS", "$,"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.24": {"text": "In dem gro\u00dfen Buch der Welt, erst zu zu buchstabiren an.", "tokens": ["In", "dem", "gro\u00b7\u00dfen", "Buch", "der", "Welt", ",", "erst", "zu", "zu", "buch\u00b7sta\u00b7bi\u00b7ren", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$,", "ADV", "PTKZU", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.25": {"text": "Machet ihr euch hier geschickt, fertig nur zu buchstabiren,", "tokens": ["Ma\u00b7chet", "ihr", "euch", "hier", "ge\u00b7schickt", ",", "fer\u00b7tig", "nur", "zu", "buch\u00b7sta\u00b7bi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "VVPP", "$,", "ADJD", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+---+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.26": {"text": "Als wozu ihr, hier auf Erden, glaublich nur bestimmet seyd:", "tokens": ["Als", "wo\u00b7zu", "ihr", ",", "hier", "auf", "Er\u00b7den", ",", "glaub\u00b7lich", "nur", "be\u00b7stim\u00b7met", "seyd", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "PPER", "$,", "ADV", "APPR", "NN", "$,", "ADJD", "ADV", "VVPP", "VAFIN", "$."], "meter": "----+-+-+-+-+-+", "measure": "unknown.measure.hexa"}, "line.27": {"text": "Werdet ihr vermuthlich f\u00e4hig, und geschickt, nach dieser Zeit,", "tokens": ["Wer\u00b7det", "ihr", "ver\u00b7muth\u00b7lich", "f\u00e4\u00b7hig", ",", "und", "ge\u00b7schickt", ",", "nach", "die\u00b7ser", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "$,", "KON", "VVPP", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.28": {"text": "Auf der rechten hohen Schulen, zu des Sch\u00f6pfers Preis und Ehr,", "tokens": ["Auf", "der", "rech\u00b7ten", "ho\u00b7hen", "Schu\u00b7len", ",", "zu", "des", "Sch\u00f6p\u00b7fers", "Preis", "und", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$,", "APPR", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.29": {"text": "Als des Buchs der Creatur wahren Inhalt, mehr und mehr,", "tokens": ["Als", "des", "Buchs", "der", "Crea\u00b7tur", "wah\u00b7ren", "In\u00b7halt", ",", "mehr", "und", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "ADJA", "NN", "$,", "ADV", "KON", "ADV", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.30": {"text": "Jm best\u00e4ndigen Entz\u00fccken ewig selig, zu studiren.", "tokens": ["Jm", "be\u00b7st\u00e4n\u00b7di\u00b7gen", "Ent\u00b7z\u00fc\u00b7cken", "e\u00b7wig", "se\u00b7lig", ",", "zu", "stu\u00b7di\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "ADJD", "$,", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}}}}