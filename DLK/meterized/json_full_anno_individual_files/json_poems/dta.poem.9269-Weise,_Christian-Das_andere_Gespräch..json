{"dta.poem.9269": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Das andere Gespr\u00e4ch.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "So mu\u00df ich deiner noch vergessen/", "tokens": ["So", "mu\u00df", "ich", "dei\u00b7ner", "noch", "ver\u00b7ges\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du vormahls hochgeliebtes kind/", "tokens": ["Du", "vor\u00b7mahls", "hoch\u00b7ge\u00b7lieb\u00b7tes", "kind", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nachdem ich offt bey dir gesessen/", "tokens": ["Nach\u00b7dem", "ich", "offt", "bey", "dir", "ge\u00b7ses\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und an begier und liebe blind/", "tokens": ["Und", "an", "be\u00b7gier", "und", "lie\u00b7be", "blind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "KON", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gemeynt/ da\u00df deine gunst und treu/", "tokens": ["Ge\u00b7meynt", "/", "da\u00df", "dei\u00b7ne", "gunst", "und", "treu", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "KOUS", "PPOSAT", "NN", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von lauter stahl und eisen sey.", "tokens": ["Von", "lau\u00b7ter", "stahl", "und", "ei\u00b7sen", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Ich lie\u00df mir nichts gef\u00e4hrlichs tr\u00e4umen/", "tokens": ["Ich", "lie\u00df", "mir", "nichts", "ge\u00b7f\u00e4hr\u00b7lichs", "tr\u00e4u\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und dacht/ es k\u00f6nte lust und list", "tokens": ["Und", "dacht", "/", "es", "k\u00f6n\u00b7te", "lust", "und", "list"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$(", "PPER", "VMFIN", "VVFIN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich nimmermehr zusammen reimen/", "tokens": ["Sich", "nim\u00b7mer\u00b7mehr", "zu\u00b7sam\u00b7men", "rei\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch nun befind ich was du bist/", "tokens": ["Doch", "nun", "be\u00b7find", "ich", "was", "du", "bist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PWS", "PPER", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Indem ich mein verlangtes ziel", "tokens": ["In\u00b7dem", "ich", "mein", "ver\u00b7lang\u00b7tes", "ziel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In deiner liebe treffen will.", "tokens": ["In", "dei\u00b7ner", "lie\u00b7be", "tref\u00b7fen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Die worte die verrathen dich/", "tokens": ["Die", "wor\u00b7te", "die", "ver\u00b7ra\u00b7then", "dich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die stehn zu sehr auf falschen schrauben/", "tokens": ["Die", "stehn", "zu", "sehr", "auf", "fal\u00b7schen", "schrau\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADV", "APPR", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dadurch erweistu sicherlich/", "tokens": ["Da\u00b7durch", "er\u00b7weis\u00b7tu", "si\u00b7cher\u00b7lich", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df du mich nur als einen gast", "tokens": ["Da\u00df", "du", "mich", "nur", "als", "ei\u00b7nen", "gast"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zum zeit-vertreib gebrauchet hast.", "tokens": ["Zum", "zeit\u00b7ver\u00b7treib", "ge\u00b7brau\u00b7chet", "hast", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Wiewohl es l\u00e4st sich endlich h\u00f6ren/", "tokens": ["Wie\u00b7wohl", "es", "l\u00e4st", "sich", "end\u00b7lich", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PRF", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie scheinbar alle worte sind:", "tokens": ["Wie", "schein\u00b7bar", "al\u00b7le", "wor\u00b7te", "sind", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die tochter will die eltern ehren/", "tokens": ["Die", "toch\u00b7ter", "will", "die", "el\u00b7tern", "eh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sie beziehn sich auff ihr kind.", "tokens": ["Und", "sie", "be\u00b7ziehn", "sich", "auff", "ihr", "kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch d\u00fcrffte man sich nicht bem\u00fchn/", "tokens": ["Doch", "d\u00fcrff\u00b7te", "man", "sich", "nicht", "be\u00b7m\u00fchn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "PRF", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mich bey der nase rumm zu ziehn.", "tokens": ["Mich", "bey", "der", "na\u00b7se", "rumm", "zu", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Ich bin an eine nicht gebunden/", "tokens": ["Ich", "bin", "an", "ei\u00b7ne", "nicht", "ge\u00b7bun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich h\u00e4tte l\u00e4ngst in dieser stadt", "tokens": ["Ich", "h\u00e4t\u00b7te", "l\u00e4ngst", "in", "die\u00b7ser", "stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein angenehmes kind gefunden/", "tokens": ["Ein", "an\u00b7ge\u00b7neh\u00b7mes", "kind", "ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das eben ihre sch\u00f6nheit hat/", "tokens": ["Das", "e\u00b7ben", "ih\u00b7re", "sch\u00f6n\u00b7heit", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man h\u00e4tte sich nur bald erkl\u00e4rt/", "tokens": ["Man", "h\u00e4t\u00b7te", "sich", "nur", "bald", "er\u00b7kl\u00e4rt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PRF", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So h\u00e4tt ich warlich nichts begehrt.", "tokens": ["So", "h\u00e4tt", "ich", "war\u00b7lich", "nichts", "be\u00b7gehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "6. Nun die courage zu bezeugen/", "tokens": ["Nun", "die", "cou\u00b7ra\u00b7ge", "zu", "be\u00b7zeu\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKZU", "VVFIN", "$("], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "So sag ich fr\u00f6lich gute nacht/", "tokens": ["So", "sag", "ich", "fr\u00f6\u00b7lich", "gu\u00b7te", "nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will von aller liebe schweigen/", "tokens": ["Ich", "will", "von", "al\u00b7ler", "lie\u00b7be", "schwei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PIAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als h\u00e4tt ich nie daran gedacht.", "tokens": ["Als", "h\u00e4tt", "ich", "nie", "da\u00b7ran", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich will nunmehr zum blossen schein/", "tokens": ["Ich", "will", "nun\u00b7mehr", "zum", "blos\u00b7sen", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein guter freund gewesen seyn.", "tokens": ["Dein", "gu\u00b7ter", "freund", "ge\u00b7we\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "7. Nur lache nicht in deinem hertzen/", "tokens": ["Nur", "la\u00b7che", "nicht", "in", "dei\u00b7nem", "hert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich so treu gewesen bin:", "tokens": ["Da\u00df", "ich", "so", "treu", "ge\u00b7we\u00b7sen", "bin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich f\u00fchlte zwar ein wenig schmertzen/", "tokens": ["Ich", "f\u00fchl\u00b7te", "zwar", "ein", "we\u00b7nig", "schmert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch nun ist alles \u00fcberhin/", "tokens": ["Doch", "nun", "ist", "al\u00b7les", "\u00fc\u00b7berh\u00b7in", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIS", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer wei\u00df/ wer endlich mit der zeit/", "tokens": ["Wer", "wei\u00df", "/", "wer", "end\u00b7lich", "mit", "der", "zeit", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "PWS", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Am ersten diesen schlu\u00df bereut.", "tokens": ["Am", "ers\u00b7ten", "die\u00b7sen", "schlu\u00df", "be\u00b7reut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}