{"textgrid.poem.26597": {"metadata": {"author": {"name": "Saar, Ferdinand von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wonach auch der Mensch", "genre": "verse", "period": "N.A.", "pub_year": 1869, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wonach auch der Mensch", "tokens": ["Wo\u00b7nach", "auch", "der", "Mensch"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADV", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Ringe und strebe:", "tokens": ["Rin\u00b7ge", "und", "stre\u00b7be", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Als h\u00f6chstes Ziel sei stets ihm gewiesen", "tokens": ["Als", "h\u00f6chs\u00b7tes", "Ziel", "sei", "stets", "ihm", "ge\u00b7wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "VAFIN", "ADV", "PPER", "VVPP"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Erkenntni\u00df des eigenen Selbst.", "tokens": ["Er\u00b7kennt\u00b7ni\u00df", "des", "ei\u00b7ge\u00b7nen", "Selbst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Denn so er nicht ermessen kann", "tokens": ["Denn", "so", "er", "nicht", "er\u00b7mes\u00b7sen", "kann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PPER", "PTKNEG", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Seines Wesens Inhalt,", "tokens": ["Sei\u00b7nes", "We\u00b7sens", "In\u00b7halt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Und wie weit er selber", "tokens": ["Und", "wie", "weit", "er", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADJD", "PPER", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Im Guten gehen wird und im B\u00f6sen:", "tokens": ["Im", "Gu\u00b7ten", "ge\u00b7hen", "wird", "und", "im", "B\u00f6\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "VAFIN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Was soll die stets ge\u00fcbte Beurtheilung", "tokens": ["Was", "soll", "die", "stets", "ge\u00b7\u00fcb\u00b7te", "Beurt\u00b7hei\u00b7lung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und Verurtheilung des N\u00e4chsten?", "tokens": ["Und", "Ver\u00b7urt\u00b7hei\u00b7lung", "des", "N\u00e4chs\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.11": {"text": "Und eh' er nicht ganz und voll erkennt,", "tokens": ["Und", "eh'", "er", "nicht", "ganz", "und", "voll", "er\u00b7kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "ADV", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Was nichtig an ihm und verwerflich,", "tokens": ["Was", "nich\u00b7tig", "an", "ihm", "und", "ver\u00b7werf\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "APPR", "PPER", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "So lang er nicht gewahrt die eigenen Schw\u00e4chen:", "tokens": ["So", "lang", "er", "nicht", "ge\u00b7wahrt", "die", "ei\u00b7ge\u00b7nen", "Schw\u00e4\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PTKNEG", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "So lang auch", "tokens": ["So", "lang", "auch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJD", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "Ist er ein Spielball", "tokens": ["Ist", "er", "ein", "Spiel\u00b7ball"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.16": {"text": "Th\u00f6richter Einbildung und ver\u00e4chtlicher Eitelkeit.", "tokens": ["Th\u00f6\u00b7rich\u00b7ter", "Ein\u00b7bil\u00b7dung", "und", "ver\u00b7\u00e4cht\u00b7li\u00b7cher", "Ei\u00b7tel\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Mehr als je", "tokens": ["Mehr", "als", "je"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "KOKOM", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Gilt heute noch des Evangeliums Wort", "tokens": ["Gilt", "heu\u00b7te", "noch", "des", "E\u00b7van\u00b7ge\u00b7li\u00b7ums", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Vom Splitter und Balken,", "tokens": ["Vom", "Split\u00b7ter", "und", "Bal\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Und ringsum zeigt sich,", "tokens": ["Und", "ring\u00b7sum", "zeigt", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Wie tief in der Menschheit wurzelt", "tokens": ["Wie", "tief", "in", "der", "Menschheit", "wur\u00b7zelt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "APPR", "ART", "NN", "VVFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Gemeine Selbstverblendung.", "tokens": ["Ge\u00b7mei\u00b7ne", "Selbst\u00b7ver\u00b7blen\u00b7dung", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Aus allen Umh\u00fcllungen tritt sie zu Tage:", "tokens": ["Aus", "al\u00b7len", "Um\u00b7h\u00fcl\u00b7lun\u00b7gen", "tritt", "sie", "zu", "Ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Aus dem Hermelin,", "tokens": ["Aus", "dem", "Her\u00b7me\u00b7lin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Dem Philosophenmantel,", "tokens": ["Dem", "Phi\u00b7lo\u00b7so\u00b7phen\u00b7man\u00b7tel", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Dem Dichtertalar \u2013", "tokens": ["Dem", "Dich\u00b7ter\u00b7ta\u00b7lar", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "Aus des Senators Toga", "tokens": ["Aus", "des", "Se\u00b7na\u00b7tors", "To\u00b7ga"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Und dem sch\u00e4bigen Wamms des Volkstribuns.", "tokens": ["Und", "dem", "sch\u00e4\u00b7bi\u00b7gen", "Wamms", "des", "Volk\u00b7stri\u00b7buns", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.13": {"text": "Daher auch noch immer", "tokens": ["Da\u00b7her", "auch", "noch", "im\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ADV", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Der M\u00e4chtigen D\u00fcnkel,", "tokens": ["Der", "M\u00e4ch\u00b7ti\u00b7gen", "D\u00fcn\u00b7kel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.15": {"text": "Der neidvolle Verl\u00e4umdungsruf der Schwachen,", "tokens": ["Der", "neid\u00b7vol\u00b7le", "Ver\u00b7l\u00e4um\u00b7dungs\u00b7ruf", "der", "Schwa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Das Ha\u00dfgez\u00e4nk der Parteien,", "tokens": ["Das", "Ha\u00df\u00b7ge\u00b7z\u00e4nk", "der", "Par\u00b7tei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.17": {"text": "Die hohlen Phrasen der Weltverbesserer \u2013", "tokens": ["Die", "hoh\u00b7len", "Phra\u00b7sen", "der", "Welt\u00b7ver\u00b7bes\u00b7se\u00b7rer", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Und in der Kunst", "tokens": ["Und", "in", "der", "Kunst"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.19": {"text": "Das eitle Pack der Dilettanten und Kritikaster ...", "tokens": ["Das", "eit\u00b7le", "Pack", "der", "Di\u00b7let\u00b7tan\u00b7ten", "und", "Kri\u00b7ti\u00b7kas\u00b7ter", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Wonach auch der Mensch", "tokens": ["Wo\u00b7nach", "auch", "der", "Mensch"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADV", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Ringe und strebe:", "tokens": ["Rin\u00b7ge", "und", "stre\u00b7be", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Als h\u00f6chstes Ziel sei stets ihm gewiesen", "tokens": ["Als", "h\u00f6chs\u00b7tes", "Ziel", "sei", "stets", "ihm", "ge\u00b7wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "VAFIN", "ADV", "PPER", "VVPP"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Erkenntni\u00df des eigenen Selbst.", "tokens": ["Er\u00b7kennt\u00b7ni\u00df", "des", "ei\u00b7ge\u00b7nen", "Selbst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Denn so er nicht ermessen kann", "tokens": ["Denn", "so", "er", "nicht", "er\u00b7mes\u00b7sen", "kann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PPER", "PTKNEG", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Seines Wesens Inhalt,", "tokens": ["Sei\u00b7nes", "We\u00b7sens", "In\u00b7halt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Und wie weit er selber", "tokens": ["Und", "wie", "weit", "er", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADJD", "PPER", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Im Guten gehen wird und im B\u00f6sen:", "tokens": ["Im", "Gu\u00b7ten", "ge\u00b7hen", "wird", "und", "im", "B\u00f6\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "VAFIN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Was soll die stets ge\u00fcbte Beurtheilung", "tokens": ["Was", "soll", "die", "stets", "ge\u00b7\u00fcb\u00b7te", "Beurt\u00b7hei\u00b7lung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und Verurtheilung des N\u00e4chsten?", "tokens": ["Und", "Ver\u00b7urt\u00b7hei\u00b7lung", "des", "N\u00e4chs\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.11": {"text": "Und eh' er nicht ganz und voll erkennt,", "tokens": ["Und", "eh'", "er", "nicht", "ganz", "und", "voll", "er\u00b7kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "ADV", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Was nichtig an ihm und verwerflich,", "tokens": ["Was", "nich\u00b7tig", "an", "ihm", "und", "ver\u00b7werf\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "APPR", "PPER", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "So lang er nicht gewahrt die eigenen Schw\u00e4chen:", "tokens": ["So", "lang", "er", "nicht", "ge\u00b7wahrt", "die", "ei\u00b7ge\u00b7nen", "Schw\u00e4\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PTKNEG", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "So lang auch", "tokens": ["So", "lang", "auch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJD", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "Ist er ein Spielball", "tokens": ["Ist", "er", "ein", "Spiel\u00b7ball"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.16": {"text": "Th\u00f6richter Einbildung und ver\u00e4chtlicher Eitelkeit.", "tokens": ["Th\u00f6\u00b7rich\u00b7ter", "Ein\u00b7bil\u00b7dung", "und", "ver\u00b7\u00e4cht\u00b7li\u00b7cher", "Ei\u00b7tel\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Mehr als je", "tokens": ["Mehr", "als", "je"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "KOKOM", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Gilt heute noch des Evangeliums Wort", "tokens": ["Gilt", "heu\u00b7te", "noch", "des", "E\u00b7van\u00b7ge\u00b7li\u00b7ums", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Vom Splitter und Balken,", "tokens": ["Vom", "Split\u00b7ter", "und", "Bal\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Und ringsum zeigt sich,", "tokens": ["Und", "ring\u00b7sum", "zeigt", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Wie tief in der Menschheit wurzelt", "tokens": ["Wie", "tief", "in", "der", "Menschheit", "wur\u00b7zelt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "APPR", "ART", "NN", "VVFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Gemeine Selbstverblendung.", "tokens": ["Ge\u00b7mei\u00b7ne", "Selbst\u00b7ver\u00b7blen\u00b7dung", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Aus allen Umh\u00fcllungen tritt sie zu Tage:", "tokens": ["Aus", "al\u00b7len", "Um\u00b7h\u00fcl\u00b7lun\u00b7gen", "tritt", "sie", "zu", "Ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Aus dem Hermelin,", "tokens": ["Aus", "dem", "Her\u00b7me\u00b7lin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Dem Philosophenmantel,", "tokens": ["Dem", "Phi\u00b7lo\u00b7so\u00b7phen\u00b7man\u00b7tel", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Dem Dichtertalar \u2013", "tokens": ["Dem", "Dich\u00b7ter\u00b7ta\u00b7lar", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "Aus des Senators Toga", "tokens": ["Aus", "des", "Se\u00b7na\u00b7tors", "To\u00b7ga"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Und dem sch\u00e4bigen Wamms des Volkstribuns.", "tokens": ["Und", "dem", "sch\u00e4\u00b7bi\u00b7gen", "Wamms", "des", "Volk\u00b7stri\u00b7buns", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.13": {"text": "Daher auch noch immer", "tokens": ["Da\u00b7her", "auch", "noch", "im\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ADV", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Der M\u00e4chtigen D\u00fcnkel,", "tokens": ["Der", "M\u00e4ch\u00b7ti\u00b7gen", "D\u00fcn\u00b7kel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.15": {"text": "Der neidvolle Verl\u00e4umdungsruf der Schwachen,", "tokens": ["Der", "neid\u00b7vol\u00b7le", "Ver\u00b7l\u00e4um\u00b7dungs\u00b7ruf", "der", "Schwa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Das Ha\u00dfgez\u00e4nk der Parteien,", "tokens": ["Das", "Ha\u00df\u00b7ge\u00b7z\u00e4nk", "der", "Par\u00b7tei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.17": {"text": "Die hohlen Phrasen der Weltverbesserer \u2013", "tokens": ["Die", "hoh\u00b7len", "Phra\u00b7sen", "der", "Welt\u00b7ver\u00b7bes\u00b7se\u00b7rer", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Und in der Kunst", "tokens": ["Und", "in", "der", "Kunst"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.19": {"text": "Das eitle Pack der Dilettanten und Kritikaster ...", "tokens": ["Das", "eit\u00b7le", "Pack", "der", "Di\u00b7let\u00b7tan\u00b7ten", "und", "Kri\u00b7ti\u00b7kas\u00b7ter", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}}}}