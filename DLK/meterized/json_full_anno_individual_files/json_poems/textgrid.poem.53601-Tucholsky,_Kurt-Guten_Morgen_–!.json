{"textgrid.poem.53601": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Guten Morgen \u2013!", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich blick zur\u00fcck. Das tu ich alle Jahre.", "tokens": ["Ich", "blick", "zu\u00b7r\u00fcck", ".", "Das", "tu", "ich", "al\u00b7le", "Jah\u00b7re", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "PDS", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und immer mit demselbigen S\u00fckzeh.", "tokens": ["Und", "im\u00b7mer", "mit", "dem\u00b7sel\u00b7bi\u00b7gen", "S\u00fck\u00b7zeh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+--++", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Es \u00fcberhingen deine blonden Haare", "tokens": ["Es", "\u00fc\u00b7ber\u00b7hin\u00b7gen", "dei\u00b7ne", "blon\u00b7den", "Haa\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "mir Bl\u00fcten, Sommerstaub und Herbst und Schnee.", "tokens": ["mir", "Bl\u00fc\u00b7ten", ",", "Som\u00b7mer\u00b7staub", "und", "Herbst", "und", "Schnee", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Oh, Publikum! So wars bei mir pers\u00f6nlich.", "tokens": ["Oh", ",", "Pub\u00b7li\u00b7kum", "!", "So", "wars", "bei", "mir", "per\u00b7s\u00f6n\u00b7lich", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$.", "ADV", "VAFIN", "APPR", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und euch? Was hat denn euch das Jahr gebracht?", "tokens": ["Und", "euch", "?", "Was", "hat", "denn", "euch", "das", "Jahr", "ge\u00b7bracht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$.", "PWS", "VAFIN", "ADV", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir waren guter Hoffnung \u2013 wie gew\u00f6hnlich \u2013", "tokens": ["Wir", "wa\u00b7ren", "gu\u00b7ter", "Hoff\u00b7nung", "\u2013", "wie", "ge\u00b7w\u00f6hn\u00b7lich", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "$(", "PWAV", "ADJD", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wir warteten auf D\u00e4mmerung in der Nacht.", "tokens": ["wir", "war\u00b7te\u00b7ten", "auf", "D\u00e4m\u00b7me\u00b7rung", "in", "der", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Wir warteten an Depositenkassen,", "tokens": ["Wir", "war\u00b7te\u00b7ten", "an", "De\u00b7po\u00b7si\u00b7ten\u00b7kas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wir warteten beim Kohlenkommissar,", "tokens": ["wir", "war\u00b7te\u00b7ten", "beim", "Koh\u00b7len\u00b7kom\u00b7mis\u00b7sar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wir warteten in Volksversammlungsmassen \u2013", "tokens": ["wir", "war\u00b7te\u00b7ten", "in", "Volks\u00b7ver\u00b7samm\u00b7lungs\u00b7mas\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wir warten, warten, warten \u2013 \u2013", "tokens": ["wir", "war\u00b7ten", ",", "war\u00b7ten", ",", "war\u00b7ten", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "welches Jahr!", "tokens": ["wel\u00b7ches", "Jahr", "!"], "token_info": ["word", "word", "punct"], "pos": ["PWAT", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Wir warteten auf unsre Kriegsgefangenen,", "tokens": ["Wir", "war\u00b7te\u00b7ten", "auf", "uns\u00b7re", "Kriegs\u00b7ge\u00b7fan\u00b7ge\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+---+-+-+--", "measure": "dactylic.init"}, "line.2": {"text": "wir warteten auf neue Menschlichkeit,", "tokens": ["wir", "war\u00b7te\u00b7ten", "auf", "neu\u00b7e", "Menschlich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "wir warteten aufs Sterben des Vergangenen \u2013", "tokens": ["wir", "war\u00b7te\u00b7ten", "aufs", "Ster\u00b7ben", "des", "Ver\u00b7gan\u00b7ge\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.4": {"text": "wir warteten auf Frieden \u2013", "tokens": ["wir", "war\u00b7te\u00b7ten", "auf", "Frie\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "welche Zeit!", "tokens": ["wel\u00b7che", "Zeit", "!"], "token_info": ["word", "word", "punct"], "pos": ["PWAT", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.5": {"line.1": {"text": "Bilanz: das Ding ist diesmal nichts geworden.", "tokens": ["Bi\u00b7lanz", ":", "das", "Ding", "ist", "dies\u00b7mal", "nichts", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VAFIN", "ADV", "PIS", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Prozente: Null. Der Stand des Ladens: flau.", "tokens": ["Pro\u00b7zen\u00b7te", ":", "Null", ".", "Der", "Stand", "des", "La\u00b7dens", ":", "flau", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NE", "$.", "ART", "NN", "ART", "NN", "$.", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Rechts: Reaktion \u2013 links: Bolschewistenhorden.", "tokens": ["Rechts", ":", "Re\u00b7ak\u00b7ti\u00b7on", "\u2013", "links", ":", "Bol\u00b7sche\u00b7wis\u00b7ten\u00b7hor\u00b7den", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$.", "NN", "$(", "ADV", "$.", "NE", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Bleibt, in der Mitte schlie\u00dflich \u2013: nur die Frau.", "tokens": ["Bleibt", ",", "in", "der", "Mit\u00b7te", "schlie\u00df\u00b7lich", "\u2013", ":", "nur", "die", "Frau", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "ART", "NN", "ADJD", "$(", "$.", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Ihr, die ihr guckt aus sanft verklebten Lidern", "tokens": ["Ihr", ",", "die", "ihr", "guckt", "aus", "sanft", "ver\u00b7kleb\u00b7ten", "Li\u00b7dern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "PPER", "VVFIN", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "in diesen Neujahrstag \u2013 gr\u00fc\u00dft sie von mir! \u2013", "tokens": ["in", "die\u00b7sen", "Neu\u00b7jahr\u00b7stag", "\u2013", "gr\u00fc\u00dft", "sie", "von", "mir", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PDAT", "NN", "$(", "VVFIN", "PPER", "APPR", "PPER", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wir warten weiter unter einem niedern", "tokens": ["Wir", "war\u00b7ten", "wei\u00b7ter", "un\u00b7ter", "ei\u00b7nem", "nie\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und grauen Weltenhimmel \u2013 wir sind wir!", "tokens": ["und", "grau\u00b7en", "Wel\u00b7ten\u00b7him\u00b7mel", "\u2013", "wir", "sind", "wir", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$(", "PPER", "VAFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wir warten weiter. Mag der Kosmos krachen:", "tokens": ["Wir", "war\u00b7ten", "wei\u00b7ter", ".", "Mag", "der", "Kos\u00b7mos", "kra\u00b7chen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Prost Neujahr!", "tokens": ["Prost", "Neu\u00b7jahr", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Nur die Ruhe kann es machen.", "tokens": ["Nur", "die", "Ru\u00b7he", "kann", "es", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ich blick zur\u00fcck. Das tu ich alle Jahre.", "tokens": ["Ich", "blick", "zu\u00b7r\u00fcck", ".", "Das", "tu", "ich", "al\u00b7le", "Jah\u00b7re", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "PDS", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und immer mit demselbigen S\u00fckzeh.", "tokens": ["Und", "im\u00b7mer", "mit", "dem\u00b7sel\u00b7bi\u00b7gen", "S\u00fck\u00b7zeh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+--++", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Es \u00fcberhingen deine blonden Haare", "tokens": ["Es", "\u00fc\u00b7ber\u00b7hin\u00b7gen", "dei\u00b7ne", "blon\u00b7den", "Haa\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "mir Bl\u00fcten, Sommerstaub und Herbst und Schnee.", "tokens": ["mir", "Bl\u00fc\u00b7ten", ",", "Som\u00b7mer\u00b7staub", "und", "Herbst", "und", "Schnee", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Oh, Publikum! So wars bei mir pers\u00f6nlich.", "tokens": ["Oh", ",", "Pub\u00b7li\u00b7kum", "!", "So", "wars", "bei", "mir", "per\u00b7s\u00f6n\u00b7lich", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$.", "ADV", "VAFIN", "APPR", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und euch? Was hat denn euch das Jahr gebracht?", "tokens": ["Und", "euch", "?", "Was", "hat", "denn", "euch", "das", "Jahr", "ge\u00b7bracht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$.", "PWS", "VAFIN", "ADV", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir waren guter Hoffnung \u2013 wie gew\u00f6hnlich \u2013", "tokens": ["Wir", "wa\u00b7ren", "gu\u00b7ter", "Hoff\u00b7nung", "\u2013", "wie", "ge\u00b7w\u00f6hn\u00b7lich", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "$(", "PWAV", "ADJD", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wir warteten auf D\u00e4mmerung in der Nacht.", "tokens": ["wir", "war\u00b7te\u00b7ten", "auf", "D\u00e4m\u00b7me\u00b7rung", "in", "der", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Wir warteten an Depositenkassen,", "tokens": ["Wir", "war\u00b7te\u00b7ten", "an", "De\u00b7po\u00b7si\u00b7ten\u00b7kas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wir warteten beim Kohlenkommissar,", "tokens": ["wir", "war\u00b7te\u00b7ten", "beim", "Koh\u00b7len\u00b7kom\u00b7mis\u00b7sar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wir warteten in Volksversammlungsmassen \u2013", "tokens": ["wir", "war\u00b7te\u00b7ten", "in", "Volks\u00b7ver\u00b7samm\u00b7lungs\u00b7mas\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wir warten, warten, warten \u2013 \u2013", "tokens": ["wir", "war\u00b7ten", ",", "war\u00b7ten", ",", "war\u00b7ten", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "welches Jahr!", "tokens": ["wel\u00b7ches", "Jahr", "!"], "token_info": ["word", "word", "punct"], "pos": ["PWAT", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.10": {"line.1": {"text": "Wir warteten auf unsre Kriegsgefangenen,", "tokens": ["Wir", "war\u00b7te\u00b7ten", "auf", "uns\u00b7re", "Kriegs\u00b7ge\u00b7fan\u00b7ge\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+---+-+-+--", "measure": "dactylic.init"}, "line.2": {"text": "wir warteten auf neue Menschlichkeit,", "tokens": ["wir", "war\u00b7te\u00b7ten", "auf", "neu\u00b7e", "Menschlich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "wir warteten aufs Sterben des Vergangenen \u2013", "tokens": ["wir", "war\u00b7te\u00b7ten", "aufs", "Ster\u00b7ben", "des", "Ver\u00b7gan\u00b7ge\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.4": {"text": "wir warteten auf Frieden \u2013", "tokens": ["wir", "war\u00b7te\u00b7ten", "auf", "Frie\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "welche Zeit!", "tokens": ["wel\u00b7che", "Zeit", "!"], "token_info": ["word", "word", "punct"], "pos": ["PWAT", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.11": {"line.1": {"text": "Bilanz: das Ding ist diesmal nichts geworden.", "tokens": ["Bi\u00b7lanz", ":", "das", "Ding", "ist", "dies\u00b7mal", "nichts", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VAFIN", "ADV", "PIS", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Prozente: Null. Der Stand des Ladens: flau.", "tokens": ["Pro\u00b7zen\u00b7te", ":", "Null", ".", "Der", "Stand", "des", "La\u00b7dens", ":", "flau", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NE", "$.", "ART", "NN", "ART", "NN", "$.", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Rechts: Reaktion \u2013 links: Bolschewistenhorden.", "tokens": ["Rechts", ":", "Re\u00b7ak\u00b7ti\u00b7on", "\u2013", "links", ":", "Bol\u00b7sche\u00b7wis\u00b7ten\u00b7hor\u00b7den", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$.", "NN", "$(", "ADV", "$.", "NE", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Bleibt, in der Mitte schlie\u00dflich \u2013: nur die Frau.", "tokens": ["Bleibt", ",", "in", "der", "Mit\u00b7te", "schlie\u00df\u00b7lich", "\u2013", ":", "nur", "die", "Frau", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "ART", "NN", "ADJD", "$(", "$.", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Ihr, die ihr guckt aus sanft verklebten Lidern", "tokens": ["Ihr", ",", "die", "ihr", "guckt", "aus", "sanft", "ver\u00b7kleb\u00b7ten", "Li\u00b7dern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "PPER", "VVFIN", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "in diesen Neujahrstag \u2013 gr\u00fc\u00dft sie von mir! \u2013", "tokens": ["in", "die\u00b7sen", "Neu\u00b7jahr\u00b7stag", "\u2013", "gr\u00fc\u00dft", "sie", "von", "mir", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PDAT", "NN", "$(", "VVFIN", "PPER", "APPR", "PPER", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wir warten weiter unter einem niedern", "tokens": ["Wir", "war\u00b7ten", "wei\u00b7ter", "un\u00b7ter", "ei\u00b7nem", "nie\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und grauen Weltenhimmel \u2013 wir sind wir!", "tokens": ["und", "grau\u00b7en", "Wel\u00b7ten\u00b7him\u00b7mel", "\u2013", "wir", "sind", "wir", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$(", "PPER", "VAFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wir warten weiter. Mag der Kosmos krachen:", "tokens": ["Wir", "war\u00b7ten", "wei\u00b7ter", ".", "Mag", "der", "Kos\u00b7mos", "kra\u00b7chen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Prost Neujahr!", "tokens": ["Prost", "Neu\u00b7jahr", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Nur die Ruhe kann es machen.", "tokens": ["Nur", "die", "Ru\u00b7he", "kann", "es", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}