{"dta.poem.5366": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "J rdisches  \n  V ergn\u00fcgen  \n in  \n  GOTT .  \n  F \u00fcnfter  T heil.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Durch Verstopfung nicht versehrt, jene nicht zerhaut,", "tokens": ["Durch", "Ver\u00b7stop\u00b7fung", "nicht", "ver\u00b7sehrt", ",", "je\u00b7ne", "nicht", "zer\u00b7haut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "VVPP", "$,", "PDS", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-++-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "durchstochen,", "tokens": ["durch\u00b7sto\u00b7chen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Und durch Feuer, Last, und Fallen, nicht verbrannt, zer-", "tokens": ["Und", "durch", "Feu\u00b7er", ",", "Last", ",", "und", "Fal\u00b7len", ",", "nicht", "ver\u00b7brannt", ",", "zer"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "APPR", "NN", "$,", "NE", "$,", "KON", "NN", "$,", "PTKNEG", "VVPP", "$,", "TRUNC"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "qvetscht, zerbrochen,", "tokens": ["qvetscht", ",", "zer\u00b7bro\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "VVPP", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Da\u00df des Fiebers Gift und Brand nicht in meinem Blute", "tokens": ["Da\u00df", "des", "Fie\u00b7bers", "Gift", "und", "Brand", "nicht", "in", "mei\u00b7nem", "Blu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN", "KON", "NN", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.6": {"text": "w\u00fcthet,", "tokens": ["w\u00fct\u00b7het", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Daf\u00fcr bin ich, liebster Vater! blos durch deine Huld", "tokens": ["Da\u00b7f\u00fcr", "bin", "ich", ",", "liebs\u00b7ter", "Va\u00b7ter", "!", "blos", "durch", "dei\u00b7ne", "Huld"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "$,", "ADJA", "NN", "$.", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.8": {"text": "beh\u00fctet.", "tokens": ["be\u00b7h\u00fc\u00b7tet", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Hab\u2019 ich aber heut\u2019 auch das, wozu Sinnen mir gegeben,", "tokens": ["Hab'", "ich", "a\u00b7ber", "heut'", "auch", "das", ",", "wo\u00b7zu", "Sin\u00b7nen", "mir", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "ADV", "PDS", "$,", "PWAV", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.10": {"text": "Nemlich: GOtt in den Gesch\u00f6pfen zu bewundern zu erheben,", "tokens": ["Nem\u00b7lich", ":", "Gott", "in", "den", "Ge\u00b7sch\u00f6p\u00b7fen", "zu", "be\u00b7wun\u00b7dern", "zu", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.11": {"text": "Wie ich schuldig war, gethan? hab\u2019 ich auch, durch mein", "tokens": ["Wie", "ich", "schul\u00b7dig", "war", ",", "ge\u00b7than", "?", "hab'", "ich", "auch", ",", "durch", "mein"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PPER", "ADJD", "VAFIN", "$,", "VVPP", "$.", "VAFIN", "PPER", "ADV", "$,", "APPR", "PPOSAT"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.12": {"text": "Gesicht,", "tokens": ["Ge\u00b7sicht", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.13": {"text": "Das vortrefliche Gesch\u00f6pf, unsrer Sonnen Wunder-Licht,", "tokens": ["Das", "vor\u00b7tre\u00b7fli\u00b7che", "Ge\u00b7sch\u00f6pf", ",", "uns\u00b7rer", "Son\u00b7nen", "Wun\u00b7der\u00b7Licht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Mit Bedacht, Bewunderung, und, da es so wundersch\u00f6n,", "tokens": ["Mit", "Be\u00b7dacht", ",", "Be\u00b7wun\u00b7de\u00b7rung", ",", "und", ",", "da", "es", "so", "wun\u00b7der\u00b7sch\u00f6n", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "KON", "$,", "KOUS", "PPER", "ADV", "ADJD", "$,"], "meter": "--+-+--+---+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Auch da es mir alles zeiget, oft mit Dancken angesehn?", "tokens": ["Auch", "da", "es", "mir", "al\u00b7les", "zei\u00b7get", ",", "oft", "mit", "Dan\u00b7cken", "an\u00b7ge\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PPER", "PIS", "VVFIN", "$,", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.16": {"text": "Wenn, durch Lesung guter B\u00fccher, ich mich heut erbauen", "tokens": ["Wenn", ",", "durch", "Le\u00b7sung", "gu\u00b7ter", "B\u00fc\u00b7cher", ",", "ich", "mich", "heut", "er\u00b7bau\u00b7en"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "APPR", "NN", "ADJA", "NN", "$,", "PPER", "PRF", "ADV", "VVINF"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.17": {"text": "k\u00f6nnen,", "tokens": ["k\u00f6n\u00b7nen", ","], "token_info": ["word", "punct"], "pos": ["VMFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.18": {"text": "Hab\u2019 ich wol gedacht: nur GOtt hat mir dieses wollen", "tokens": ["Hab'", "ich", "wol", "ge\u00b7dacht", ":", "nur", "Gott", "hat", "mir", "die\u00b7ses", "wol\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "VVPP", "$.", "ADV", "NN", "VAFIN", "PPER", "PDS", "VMFIN"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.19": {"text": "g\u00f6nnen?", "tokens": ["g\u00f6n\u00b7nen", "?"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.20": {"text": "Gott gab mir, nebst meinem ", "tokens": ["Gott", "gab", "mir", ",", "nebst", "mei\u00b7nem"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "$,", "APPR", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.21": {"text": "Hat die Schreib\u2019- und Lesungs-Kunst wunderbar erfinden", "tokens": ["Hat", "die", "Schreib'", "und", "Le\u00b7sungs\u00b7Kunst", "wun\u00b7der\u00b7bar", "er\u00b7fin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "TRUNC", "KON", "NN", "ADJD", "VVINF"], "meter": "--+-++-+-+-+-", "measure": "anapaest.init"}, "line.22": {"text": "lassen,", "tokens": ["las\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.23": {"text": "Da\u00df wir nicht im Welt-Buch nur und in C\u00f6rpern ihre", "tokens": ["Da\u00df", "wir", "nicht", "im", "Welt\u00b7Buch", "nur", "und", "in", "C\u00f6r\u00b7pern", "ih\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "APPRART", "NN", "ADV", "KON", "APPR", "NE", "PPOSAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Pracht,", "tokens": ["Pracht", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.25": {"text": "Sondern auch der Geister Sch\u00f6nheit, Anmuth, Eindruck,", "tokens": ["Son\u00b7dern", "auch", "der", "Geis\u00b7ter", "Sch\u00f6n\u00b7heit", ",", "An\u00b7muth", ",", "Ein\u00b7druck", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.26": {"text": "Feur und Macht", "tokens": ["Feur", "und", "Macht"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.27": {"text": "Und in ihnen, seine Wunder, Lieb\u2019 und Weisheit m\u00f6g-", "tokens": ["Und", "in", "ih\u00b7nen", ",", "sei\u00b7ne", "Wun\u00b7der", ",", "Lieb'", "und", "Weis\u00b7heit", "m\u00f6g"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "$,", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "TRUNC"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.28": {"text": "ten fassen;", "tokens": ["ten", "fas\u00b7sen", ";"], "token_info": ["word", "word", "punct"], "pos": ["FM", "FM", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.29": {"text": "Hab\u2019 ich auch, wenn ich sein Wort, oder sonst was Guts,", "tokens": ["Hab'", "ich", "auch", ",", "wenn", "ich", "sein", "Wort", ",", "o\u00b7der", "sonst", "was", "Guts", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$,", "KOUS", "PPER", "PPOSAT", "NN", "$,", "KON", "ADV", "PWS", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "gelesen,", "tokens": ["ge\u00b7le\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.31": {"text": "Gottes weise Lieb\u2019 ermessen? bin ich auch ger\u00fchrt gewesen?", "tokens": ["Got\u00b7tes", "wei\u00b7se", "Lieb'", "er\u00b7mes\u00b7sen", "?", "bin", "ich", "auch", "ge\u00b7r\u00fchrt", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVINF", "$.", "VAFIN", "PPER", "ADV", "VVPP", "VAPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}}}}