{"textgrid.poem.33240": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Hier ist der Peltz und das Felleisen,", "genre": "verse", "period": "N.A.", "pub_year": 1676, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hier ist der Peltz und das Felleisen,", "tokens": ["Hier", "ist", "der", "Peltz", "und", "das", "Fell\u00b7ei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die euch, auf euren weiten Reisen,", "tokens": ["Die", "euch", ",", "auf", "eu\u00b7ren", "wei\u00b7ten", "Rei\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So grossen Nutzen han gethan,", "tokens": ["So", "gros\u00b7sen", "Nut\u00b7zen", "han", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ach! seht sie doch gen\u00e4dig an,", "tokens": ["Ach", "!", "seht", "sie", "doch", "ge\u00b7n\u00e4\u00b7dig", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Licentiat der beyden Rechten.", "tokens": ["Li\u00b7cen\u00b7ti\u00b7at", "der", "bey\u00b7den", "Rech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Von unserm und des Feindes Fechten", "tokens": ["Von", "un\u00b7serm", "und", "des", "Fein\u00b7des", "Fech\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hat man noch keine Zeitung nicht,", "tokens": ["Hat", "man", "noch", "kei\u00b7ne", "Zei\u00b7tung", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "PIAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Weil der Postillion gebricht,", "tokens": ["Weil", "der", "Pos\u00b7til\u00b7li\u00b7on", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und, mit Best\u00fcrtzung vieler Frommen,", "tokens": ["Und", ",", "mit", "Be\u00b7st\u00fcrt\u00b7zung", "vie\u00b7ler", "From\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Im Post-Hau\u00df noch nicht angekommen.", "tokens": ["Im", "Post\u00b7Hau\u00df", "noch", "nicht", "an\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Fr\u00fch, eh es Morgen achte schl\u00e4gt,", "tokens": ["Fr\u00fch", ",", "eh", "es", "Mor\u00b7gen", "ach\u00b7te", "schl\u00e4gt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PPER", "NN", "ADJA", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Macht, da\u00df euch euer Gang hertr\u00e4gt.", "tokens": ["Macht", ",", "da\u00df", "euch", "eu\u00b7er", "Gang", "her\u00b7tr\u00e4gt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ich wollt euch gern was mehrers schreiben;", "tokens": ["Ich", "wollt", "euch", "gern", "was", "meh\u00b7rers", "schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PWS", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Doch seh ich durch die Fenster-Scheiben", "tokens": ["Doch", "seh", "ich", "durch", "die", "Fens\u00b7ter\u00b7Schei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Da\u00df sich was angenehmes r\u00fchrt,", "tokens": ["Da\u00df", "sich", "was", "an\u00b7ge\u00b7neh\u00b7mes", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PWS", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Darob mein Hertze Freude sp\u00fchrt.", "tokens": ["Da\u00b7rob", "mein", "Hert\u00b7ze", "Freu\u00b7de", "sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "VVFIN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Darum so lasst euchs nicht verdriessen,", "tokens": ["Da\u00b7rum", "so", "lasst", "euchs", "nicht", "ver\u00b7dries\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Da\u00df ich die Ode schon mu\u00df schliessen.", "tokens": ["Da\u00df", "ich", "die", "O\u00b7de", "schon", "mu\u00df", "schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Licentiate Lobesan,", "tokens": ["Li\u00b7cen\u00b7ti\u00b7a\u00b7te", "Lo\u00b7be\u00b7san", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Nehmt einen guten Abend an!", "tokens": ["Nehmt", "ei\u00b7nen", "gu\u00b7ten", "A\u00b7bend", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Hier ist der Peltz und das Felleisen,", "tokens": ["Hier", "ist", "der", "Peltz", "und", "das", "Fell\u00b7ei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die euch, auf euren weiten Reisen,", "tokens": ["Die", "euch", ",", "auf", "eu\u00b7ren", "wei\u00b7ten", "Rei\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So grossen Nutzen han gethan,", "tokens": ["So", "gros\u00b7sen", "Nut\u00b7zen", "han", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ach! seht sie doch gen\u00e4dig an,", "tokens": ["Ach", "!", "seht", "sie", "doch", "ge\u00b7n\u00e4\u00b7dig", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Licentiat der beyden Rechten.", "tokens": ["Li\u00b7cen\u00b7ti\u00b7at", "der", "bey\u00b7den", "Rech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Von unserm und des Feindes Fechten", "tokens": ["Von", "un\u00b7serm", "und", "des", "Fein\u00b7des", "Fech\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hat man noch keine Zeitung nicht,", "tokens": ["Hat", "man", "noch", "kei\u00b7ne", "Zei\u00b7tung", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "PIAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Weil der Postillion gebricht,", "tokens": ["Weil", "der", "Pos\u00b7til\u00b7li\u00b7on", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und, mit Best\u00fcrtzung vieler Frommen,", "tokens": ["Und", ",", "mit", "Be\u00b7st\u00fcrt\u00b7zung", "vie\u00b7ler", "From\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Im Post-Hau\u00df noch nicht angekommen.", "tokens": ["Im", "Post\u00b7Hau\u00df", "noch", "nicht", "an\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Fr\u00fch, eh es Morgen achte schl\u00e4gt,", "tokens": ["Fr\u00fch", ",", "eh", "es", "Mor\u00b7gen", "ach\u00b7te", "schl\u00e4gt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PPER", "NN", "ADJA", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Macht, da\u00df euch euer Gang hertr\u00e4gt.", "tokens": ["Macht", ",", "da\u00df", "euch", "eu\u00b7er", "Gang", "her\u00b7tr\u00e4gt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ich wollt euch gern was mehrers schreiben;", "tokens": ["Ich", "wollt", "euch", "gern", "was", "meh\u00b7rers", "schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PWS", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Doch seh ich durch die Fenster-Scheiben", "tokens": ["Doch", "seh", "ich", "durch", "die", "Fens\u00b7ter\u00b7Schei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Da\u00df sich was angenehmes r\u00fchrt,", "tokens": ["Da\u00df", "sich", "was", "an\u00b7ge\u00b7neh\u00b7mes", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PWS", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Darob mein Hertze Freude sp\u00fchrt.", "tokens": ["Da\u00b7rob", "mein", "Hert\u00b7ze", "Freu\u00b7de", "sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "VVFIN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Darum so lasst euchs nicht verdriessen,", "tokens": ["Da\u00b7rum", "so", "lasst", "euchs", "nicht", "ver\u00b7dries\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Da\u00df ich die Ode schon mu\u00df schliessen.", "tokens": ["Da\u00df", "ich", "die", "O\u00b7de", "schon", "mu\u00df", "schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Licentiate Lobesan,", "tokens": ["Li\u00b7cen\u00b7ti\u00b7a\u00b7te", "Lo\u00b7be\u00b7san", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Nehmt einen guten Abend an!", "tokens": ["Nehmt", "ei\u00b7nen", "gu\u00b7ten", "A\u00b7bend", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}