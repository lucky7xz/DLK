{"textgrid.poem.55675": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Erster Gesang", "genre": "verse", "period": "N.A.", "pub_year": 1790, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Pfingsten, das liebliche Fest, war gekommen; es gr\u00fcnten und bl\u00fchten", "tokens": ["Pfings\u00b7ten", ",", "das", "lieb\u00b7li\u00b7che", "Fest", ",", "war", "ge\u00b7kom\u00b7men", ";", "es", "gr\u00fcn\u00b7ten", "und", "bl\u00fch\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$,", "VAFIN", "VVPP", "$.", "PPER", "VVFIN", "KON", "VVFIN"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Feld und Wald; auf H\u00fcgeln und H\u00f6hn, in B\u00fcschen und Hecken", "tokens": ["Feld", "und", "Wald", ";", "auf", "H\u00fc\u00b7geln", "und", "H\u00f6hn", ",", "in", "B\u00fc\u00b7schen", "und", "He\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$.", "APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.3": {"text": "\u00dcbten ein fr\u00f6hliches Lied die neuermunterten V\u00f6gel;", "tokens": ["\u00dcb\u00b7ten", "ein", "fr\u00f6h\u00b7li\u00b7ches", "Lied", "die", "neu\u00b7er\u00b7mun\u00b7ter\u00b7ten", "V\u00f6\u00b7gel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.4": {"text": "Jede Wiese spro\u00dfte von Blumen in duftenden Gr\u00fcnden,", "tokens": ["Je\u00b7de", "Wie\u00b7se", "spro\u00df\u00b7te", "von", "Blu\u00b7men", "in", "duf\u00b7ten\u00b7den", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.5": {"text": "Festlich heiter gl\u00e4nzte der Himmel und farbig die Erde.", "tokens": ["Fest\u00b7lich", "hei\u00b7ter", "gl\u00e4nz\u00b7te", "der", "Him\u00b7mel", "und", "far\u00b7big", "die", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VVFIN", "ART", "NN", "KON", "ADJD", "ART", "NN", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}}, "stanza.2": {"line.1": {"text": "Nobel, der K\u00f6nig, versammelt den Hof; und seine Vasallen", "tokens": ["No\u00b7bel", ",", "der", "K\u00f6\u00b7nig", ",", "ver\u00b7sam\u00b7melt", "den", "Hof", ";", "und", "sei\u00b7ne", "Va\u00b7sal\u00b7len"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$.", "KON", "PPOSAT", "NN"], "meter": "+--+--+--+-+-+--", "measure": "elegiambus"}, "line.2": {"text": "Eilen gerufen herbei mit gro\u00dfem Gepr\u00e4nge; da kommen", "tokens": ["Ei\u00b7len", "ge\u00b7ru\u00b7fen", "her\u00b7bei", "mit", "gro\u00b7\u00dfem", "Ge\u00b7pr\u00e4n\u00b7ge", ";", "da", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVPP", "ADV", "APPR", "ADJA", "NN", "$.", "ADV", "VVINF"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Viele stolze Gesellen von allen Seiten und Enden,", "tokens": ["Vie\u00b7le", "stol\u00b7ze", "Ge\u00b7sel\u00b7len", "von", "al\u00b7len", "Sei\u00b7ten", "und", "En\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "L\u00fctke, der Kranich, und Markart, der H\u00e4her, und alle die Besten.", "tokens": ["L\u00fct\u00b7ke", ",", "der", "Kra\u00b7nich", ",", "und", "Mar\u00b7kart", ",", "der", "H\u00e4\u00b7her", ",", "und", "al\u00b7le", "die", "Bes\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "KON", "NE", "$,", "ART", "NN", "$,", "KON", "PIS", "ART", "NN", "$."], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.5": {"text": "Denn der K\u00f6nig gedenkt mit allen seinen Baronen", "tokens": ["Denn", "der", "K\u00f6\u00b7nig", "ge\u00b7denkt", "mit", "al\u00b7len", "sei\u00b7nen", "Ba\u00b7ro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Hof zu halten in Feier und Pracht; er l\u00e4\u00dft sie berufen", "tokens": ["Hof", "zu", "hal\u00b7ten", "in", "Fei\u00b7er", "und", "Pracht", ";", "er", "l\u00e4\u00dft", "sie", "be\u00b7ru\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKZU", "VVINF", "APPR", "NN", "KON", "NN", "$.", "PPER", "VVFIN", "PPER", "VVPP"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.7": {"text": "Alle miteinander, so gut die Gro\u00dfen als Kleinen.", "tokens": ["Al\u00b7le", "mi\u00b7tein\u00b7an\u00b7der", ",", "so", "gut", "die", "Gro\u00b7\u00dfen", "als", "Klei\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "$,", "ADV", "ADJD", "ART", "NN", "KOUS", "NN", "$."], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Niemand sollte fehlen! und dennoch fehlte der ", "tokens": ["Nie\u00b7mand", "soll\u00b7te", "feh\u00b7len", "!", "und", "den\u00b7noch", "fehl\u00b7te", "der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "VVINF", "$.", "KON", "ADV", "VVFIN", "ART"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Reineke Fuchs, der Schelm! der viel begangenen Frevels", "tokens": ["Rei\u00b7ne\u00b7ke", "Fuchs", ",", "der", "Schelm", "!", "der", "viel", "be\u00b7gan\u00b7ge\u00b7nen", "Fre\u00b7vels"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "ART", "NN", "$.", "ART", "PIAT", "ADJA", "NN"], "meter": "+--+-+-+-+-+-+", "measure": "iambic.septa.invert"}, "line.10": {"text": "Halben des Hofs sich enthielt. So scheuet das b\u00f6se Gewissen", "tokens": ["Hal\u00b7ben", "des", "Hofs", "sich", "ent\u00b7hielt", ".", "So", "scheu\u00b7et", "das", "b\u00f6\u00b7se", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "PRF", "VVFIN", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.11": {"text": "Licht und Tag, es scheute der Fuchs die versammelten Herren.", "tokens": ["Licht", "und", "Tag", ",", "es", "scheu\u00b7te", "der", "Fuchs", "die", "ver\u00b7sam\u00b7mel\u00b7ten", "Her\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "PPER", "VVFIN", "ART", "NE", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.12": {"text": "Alle hatten zu klagen, er hatte sie alle beleidigt,", "tokens": ["Al\u00b7le", "hat\u00b7ten", "zu", "kla\u00b7gen", ",", "er", "hat\u00b7te", "sie", "al\u00b7le", "be\u00b7lei\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PTKZU", "VVINF", "$,", "PPER", "VAFIN", "PPER", "PIS", "VVPP", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.13": {"text": "Und nur Grimbart, den Dachs, den Sohn des Bruders, verschont' er.", "tokens": ["Und", "nur", "Grim\u00b7bart", ",", "den", "Dachs", ",", "den", "Sohn", "des", "Bru\u00b7ders", ",", "ver\u00b7schont'", "er", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Isegrim aber, der Wolf, begann die Klage; von allen", "tokens": ["I\u00b7seg\u00b7rim", "a\u00b7ber", ",", "der", "Wolf", ",", "be\u00b7gann", "die", "Kla\u00b7ge", ";", "von", "al\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADV", "$,", "ART", "NE", "$,", "VVFIN", "ART", "NN", "$.", "APPR", "PIAT"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Seinen Vettern und G\u00f6nnern, von allen Freunden begleitet,", "tokens": ["Sei\u00b7nen", "Vet\u00b7tern", "und", "G\u00f6n\u00b7nern", ",", "von", "al\u00b7len", "Freun\u00b7den", "be\u00b7glei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$,", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Trat er vor den K\u00f6nig und sprach die gerichtlichen Worte:", "tokens": ["Trat", "er", "vor", "den", "K\u00f6\u00b7nig", "und", "sprach", "die", "ge\u00b7richt\u00b7li\u00b7chen", "Wor\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.4": {"text": "\u00bbgn\u00e4digster K\u00f6nig und Herr! vernehmet meine Beschwerden.", "tokens": ["\u00bb", "gn\u00e4\u00b7digs\u00b7ter", "K\u00f6\u00b7nig", "und", "Herr", "!", "ver\u00b7neh\u00b7met", "mei\u00b7ne", "Be\u00b7schwer\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "KON", "NN", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Edel seid Ihr und gro\u00df und ehrenvoll, jedem erzeigt Ihr", "tokens": ["E\u00b7del", "seid", "Ihr", "und", "gro\u00df", "und", "eh\u00b7ren\u00b7voll", ",", "je\u00b7dem", "er\u00b7zeigt", "Ihr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "KON", "ADJD", "KON", "ADJD", "$,", "PIS", "VVFIN", "PPER"], "meter": "+-+--+-+--+-+++", "measure": "trochaic.octa.plus.relaxed"}, "line.6": {"text": "Recht und Gnade: so la\u00dft Euch denn auch des Schadens erbarmen,", "tokens": ["Recht", "und", "Gna\u00b7de", ":", "so", "la\u00dft", "Euch", "denn", "auch", "des", "Scha\u00b7dens", "er\u00b7bar\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.7": {"text": "Den ich von Reineke Fuchs mit gro\u00dfer Schande gelitten.", "tokens": ["Den", "ich", "von", "Rei\u00b7ne\u00b7ke", "Fuchs", "mit", "gro\u00b7\u00dfer", "Schan\u00b7de", "ge\u00b7lit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NE", "NE", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Aber vor allen Dingen erbarmt Euch, da\u00df er mein Weib so", "tokens": ["A\u00b7ber", "vor", "al\u00b7len", "Din\u00b7gen", "er\u00b7barmt", "Euch", ",", "da\u00df", "er", "mein", "Weib", "so"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PPOSAT", "NN", "ADV"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.9": {"text": "Ach! er hat sie mit Unrat besudelt, mit \u00e4tzendem Unflat,", "tokens": ["Ach", "!", "er", "hat", "sie", "mit", "Un\u00b7rat", "be\u00b7su\u00b7delt", ",", "mit", "\u00e4t\u00b7zen\u00b7dem", "Un\u00b7flat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PPER", "VAFIN", "PPER", "APPR", "NN", "VVPP", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.10": {"text": "Da\u00df mir zu Hause noch drei in bittrer Blindheit sich qu\u00e4len.", "tokens": ["Da\u00df", "mir", "zu", "Hau\u00b7se", "noch", "drei", "in", "bit\u00b7trer", "Blind\u00b7heit", "sich", "qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADV", "CARD", "APPR", "ADJA", "NN", "PRF", "VVINF", "$."], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Zwar ist alle der Frevel schon lange zur Sprache gekommen,", "tokens": ["Zwar", "ist", "al\u00b7le", "der", "Fre\u00b7vel", "schon", "lan\u00b7ge", "zur", "Spra\u00b7che", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ART", "NN", "ADV", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.12": {"text": "Ja, ein Tag war gesetzt, zu schlichten solche Beschwerden;", "tokens": ["Ja", ",", "ein", "Tag", "war", "ge\u00b7setzt", ",", "zu", "schlich\u00b7ten", "sol\u00b7che", "Be\u00b7schwer\u00b7den", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "VVPP", "$,", "PTKZU", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Er erbot sich zum Eide, doch bald besann er sich anders", "tokens": ["Er", "er\u00b7bot", "sich", "zum", "Ei\u00b7de", ",", "doch", "bald", "be\u00b7sann", "er", "sich", "an\u00b7ders"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPRART", "NN", "$,", "ADV", "ADV", "VVFIN", "PPER", "PRF", "ADV"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.14": {"text": "Und entwischte behend nach seiner Feste. Das wissen", "tokens": ["Und", "ent\u00b7wischte", "be\u00b7hend", "nach", "sei\u00b7ner", "Fes\u00b7te", ".", "Das", "wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "$.", "PDS", "VVINF"], "meter": "--+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Alle M\u00e4nner zu wohl, die hier und neben mir stehen.", "tokens": ["Al\u00b7le", "M\u00e4n\u00b7ner", "zu", "wohl", ",", "die", "hier", "und", "ne\u00b7ben", "mir", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ADV", "$,", "PRELS", "ADV", "KON", "APPR", "PPER", "VVFIN", "$."], "meter": "--+--+---+--+-", "measure": "anapaest.di.plus"}, "line.16": {"text": "Herr! ich k\u00f6nnte die Drangsal, die mir der Bube bereitet,", "tokens": ["Herr", "!", "ich", "k\u00f6nn\u00b7te", "die", "Dran\u00b7gsal", ",", "die", "mir", "der", "Bu\u00b7be", "be\u00b7rei\u00b7tet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VMFIN", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.17": {"text": "Nicht mit eilenden Worten in vielen Wochen erz\u00e4hlen.", "tokens": ["Nicht", "mit", "ei\u00b7len\u00b7den", "Wor\u00b7ten", "in", "vie\u00b7len", "Wo\u00b7chen", "er\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.18": {"text": "W\u00fcrde die Leinwand von Gent, so viel auch ihrer gemacht wird,", "tokens": ["W\u00fcr\u00b7de", "die", "Lein\u00b7wand", "von", "Gent", ",", "so", "viel", "auch", "ih\u00b7rer", "ge\u00b7macht", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "NN", "$,", "ADV", "ADV", "ADV", "PPOSAT", "VVPP", "VAFIN", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.19": {"text": "Alle zu Pergament, sie fa\u00dfte die Streiche nicht alle,", "tokens": ["Al\u00b7le", "zu", "Per\u00b7ga\u00b7ment", ",", "sie", "fa\u00df\u00b7te", "die", "Strei\u00b7che", "nicht", "al\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "PTKNEG", "PIS", "$,"], "meter": "+--+-+-+--+--+-", "measure": "hexameter"}, "line.20": {"text": "Und ich schweige davon. Doch meines Weibes Entehrung", "tokens": ["Und", "ich", "schwei\u00b7ge", "da\u00b7von", ".", "Doch", "mei\u00b7nes", "Wei\u00b7bes", "E\u00b7nteh\u00b7rung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PAV", "$.", "KON", "PPOSAT", "NN", "NN"], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Fri\u00dft mir das Herz; ich r\u00e4che sie auch, es werde, was wolle.\u00ab", "tokens": ["Fri\u00dft", "mir", "das", "Herz", ";", "ich", "r\u00e4\u00b7che", "sie", "auch", ",", "es", "wer\u00b7de", ",", "was", "wol\u00b7le", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "VAFIN", "$,", "PWS", "VMFIN", "$.", "$("], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}}, "stanza.4": {"line.1": {"text": "Als nun Isegrim so mit traurigem Mute gesprochen,", "tokens": ["Als", "nun", "I\u00b7seg\u00b7rim", "so", "mit", "trau\u00b7ri\u00b7gem", "Mu\u00b7te", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.2": {"text": "Trat ein H\u00fcndchen hervor, hie\u00df Wackerlos, redte franz\u00f6sisch", "tokens": ["Trat", "ein", "H\u00fcnd\u00b7chen", "her\u00b7vor", ",", "hie\u00df", "Wa\u00b7cker\u00b7los", ",", "red\u00b7te", "fran\u00b7z\u00f6\u00b7sisch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,", "VVFIN", "NN", "$,", "VVFIN", "ADJD"], "meter": "+-+--+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Vor dem K\u00f6nig: wie arm es gewesen und nichts ihm geblieben", "tokens": ["Vor", "dem", "K\u00f6\u00b7nig", ":", "wie", "arm", "es", "ge\u00b7we\u00b7sen", "und", "nichts", "ihm", "ge\u00b7blie\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "PWAV", "ADJD", "PPER", "VAPP", "KON", "PIS", "PPER", "VVPP"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Als ein St\u00fcckchen Wurst in einem Wintergeb\u00fcsche;", "tokens": ["Als", "ein", "St\u00fcck\u00b7chen", "Wurst", "in", "ei\u00b7nem", "Win\u00b7ter\u00b7ge\u00b7b\u00fc\u00b7sche", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Reineke hab auch das ihm genommen! Jetzt sprang auch der Kater", "tokens": ["Rei\u00b7ne\u00b7ke", "hab", "auch", "das", "ihm", "ge\u00b7nom\u00b7men", "!", "Jetzt", "sprang", "auch", "der", "Ka\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ADV", "ART", "PPER", "VVPP", "$.", "ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-+--+--+-", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Hinze zornig hervor und sprach: \u00bbErhabner Gebieter,", "tokens": ["Hin\u00b7ze", "zor\u00b7nig", "her\u00b7vor", "und", "sprach", ":", "\u00bb", "Er\u00b7hab\u00b7ner", "Ge\u00b7bie\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKVZ", "KON", "VVFIN", "$.", "$(", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.7": {"text": "Niemand beschwere sich mehr, da\u00df ihm der B\u00f6sewicht schade,", "tokens": ["Nie\u00b7mand", "be\u00b7schwe\u00b7re", "sich", "mehr", ",", "da\u00df", "ihm", "der", "B\u00f6\u00b7se\u00b7wicht", "scha\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.8": {"text": "Denn der K\u00f6nig allein! Ich sag Euch, in dieser Gesellschaft", "tokens": ["Denn", "der", "K\u00f6\u00b7nig", "al\u00b7lein", "!", "Ich", "sag", "Euch", ",", "in", "die\u00b7ser", "Ge\u00b7sell\u00b7schaft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "$.", "PPER", "VVFIN", "PPER", "$,", "APPR", "PDAT", "NN"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.9": {"text": "Ist hier niemand, jung oder alt, er f\u00fcrchtet den Frevler", "tokens": ["Ist", "hier", "nie\u00b7mand", ",", "jung", "o\u00b7der", "alt", ",", "er", "f\u00fcrch\u00b7tet", "den", "Frev\u00b7ler"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIS", "$,", "ADJD", "KON", "ADJD", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.10": {"text": "Mehr als Euch! Doch Wackerlos' Klage will wenig bedeuten,", "tokens": ["Mehr", "als", "Euch", "!", "Doch", "Wa\u00b7cke\u00b7rlos'", "Kla\u00b7ge", "will", "we\u00b7nig", "be\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "PPER", "$.", "KON", "NN", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.11": {"text": "Schon sind Jahre vorbei, seit diese H\u00e4ndel geschehen;", "tokens": ["Schon", "sind", "Jah\u00b7re", "vor\u00b7bei", ",", "seit", "die\u00b7se", "H\u00e4n\u00b7del", "ge\u00b7sche\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "PTKVZ", "$,", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "Mir geh\u00f6rte die Wurst! ich sollte mich damals beschweren.", "tokens": ["Mir", "ge\u00b7h\u00f6r\u00b7te", "die", "Wurst", "!", "ich", "soll\u00b7te", "mich", "da\u00b7mals", "be\u00b7schwe\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+--+-+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.13": {"text": "Jagen war ich gegangen: auf meinem Wege durchsucht ich", "tokens": ["Ja\u00b7gen", "war", "ich", "ge\u00b7gan\u00b7gen", ":", "auf", "mei\u00b7nem", "We\u00b7ge", "durch\u00b7sucht", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "VVPP", "$.", "APPR", "PPOSAT", "NN", "VVFIN", "PPER"], "meter": "+-+--+--+-+-+++", "measure": "trochaic.octa.plus.relaxed"}, "line.14": {"text": "Eine M\u00fchle zu Nacht; es schlief die M\u00fcllerin; sachte", "tokens": ["Ei\u00b7ne", "M\u00fch\u00b7le", "zu", "Nacht", ";", "es", "schlief", "die", "M\u00fcl\u00b7le\u00b7rin", ";", "sach\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "APPR", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "$.", "VVFIN"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.15": {"text": "Nahm ich ein W\u00fcrstchen, ich will es gestehn; doch hatte zu dieser", "tokens": ["Nahm", "ich", "ein", "W\u00fcr\u00b7stchen", ",", "ich", "will", "es", "ge\u00b7stehn", ";", "doch", "hat\u00b7te", "zu", "die\u00b7ser"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PPER", "VMFIN", "PPER", "VVPP", "$.", "ADV", "VAFIN", "APPR", "PDAT"], "meter": "+---+-+--+-+--+-", "measure": "trochaic.hexa.relaxed"}, "line.16": {"text": "Wackerlos irgend ein Recht, so dankt' er's meiner Bem\u00fchung.\u00ab", "tokens": ["Wa\u00b7cker\u00b7los", "ir\u00b7gend", "ein", "Recht", ",", "so", "dankt'", "er's", "mei\u00b7ner", "Be\u00b7m\u00fc\u00b7hung", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "ADV", "ART", "NN", "$,", "ADV", "VVFIN", "PIS", "PPOSAT", "NN", "$.", "$("], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}}, "stanza.5": {"line.1": {"text": "Und der Panther begann: \u00bbWas helfen Klagen und Worte!", "tokens": ["Und", "der", "Pan\u00b7ther", "be\u00b7gann", ":", "\u00bb", "Was", "hel\u00b7fen", "Kla\u00b7gen", "und", "Wor\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$.", "$(", "PWS", "ADJA", "NN", "KON", "NN", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Wenig richten sie aus, genug, das \u00dcbel ist ruchtbar.", "tokens": ["We\u00b7nig", "rich\u00b7ten", "sie", "aus", ",", "ge\u00b7nug", ",", "das", "\u00dc\u00b7bel", "ist", "rucht\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "$,", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Er ist ein Dieb, ein M\u00f6rder! Ich darf es k\u00fchnlich behaupten,", "tokens": ["Er", "ist", "ein", "Dieb", ",", "ein", "M\u00f6r\u00b7der", "!", "Ich", "darf", "es", "k\u00fchn\u00b7lich", "be\u00b7haup\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$.", "PPER", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ja, es wissen's die Herren, er \u00fcbet jeglichen Frevel.", "tokens": ["Ja", ",", "es", "wis\u00b7sen's", "die", "Her\u00b7ren", ",", "er", "\u00fc\u00b7bet", "jeg\u00b7li\u00b7chen", "Fre\u00b7vel", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Gut und Ehre verlieren; er lachte, gew\u00e4nn er nur etwa", "tokens": ["Gut", "und", "Eh\u00b7re", "ver\u00b7lie\u00b7ren", ";", "er", "lach\u00b7te", ",", "ge\u00b7w\u00e4nn", "er", "nur", "et\u00b7wa"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "KON", "NN", "VVINF", "$.", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "ADV"], "meter": "+-+--+--+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Einen Bissen dabei von einem fetten Kapaune.", "tokens": ["Ei\u00b7nen", "Bis\u00b7sen", "da\u00b7bei", "von", "ei\u00b7nem", "fet\u00b7ten", "Ka\u00b7pau\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.7": {"text": "La\u00dft Euch erz\u00e4hlen, wie er so \u00fcbel an Lampen, dem Hasen,", "tokens": ["La\u00dft", "Euch", "er\u00b7z\u00e4h\u00b7len", ",", "wie", "er", "so", "\u00fc\u00b7bel", "an", "Lam\u00b7pen", ",", "dem", "Ha\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$,", "PWAV", "PPER", "ADV", "ADJD", "APPR", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Gestern tat; hier steht er! der Mann, der keinen verletzte.", "tokens": ["Ge\u00b7stern", "tat", ";", "hier", "steht", "er", "!", "der", "Mann", ",", "der", "kei\u00b7nen", "ver\u00b7letz\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "$.", "ART", "NN", "$,", "PRELS", "PIAT", "ADJA", "$."], "meter": "-+--+--+-+--+-", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Reineke stellte sich fromm und wollt ihn allerlei Weisen", "tokens": ["Rei\u00b7ne\u00b7ke", "stell\u00b7te", "sich", "fromm", "und", "wollt", "ihn", "al\u00b7ler\u00b7lei", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PRF", "ADJD", "KON", "VMFIN", "PPER", "PIAT", "NN"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.10": {"text": "K\u00fcrzlich lehren und was zum Kaplan noch weiter geh\u00f6ret,", "tokens": ["K\u00fcrz\u00b7lich", "leh\u00b7ren", "und", "was", "zum", "Ka\u00b7plan", "noch", "wei\u00b7ter", "ge\u00b7h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KON", "PWS", "APPRART", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.11": {"text": "Und sie setzten sich gegeneinander, begannen das Credo.", "tokens": ["Und", "sie", "setz\u00b7ten", "sich", "ge\u00b7gen\u00b7ein\u00b7an\u00b7der", ",", "be\u00b7gan\u00b7nen", "das", "Cre\u00b7do", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "ADV", "$,", "VVFIN", "ART", "NN", "$."], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.12": {"text": "Aber Reineke konnte die alten T\u00fccken nicht lassen;", "tokens": ["A\u00b7ber", "Rei\u00b7ne\u00b7ke", "konn\u00b7te", "die", "al\u00b7ten", "T\u00fc\u00b7cken", "nicht", "las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VMFIN", "ART", "ADJA", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.13": {"text": "Innerhalb unsers K\u00f6niges Fried' und freiem Geleite", "tokens": ["In\u00b7ner\u00b7halb", "un\u00b7sers", "K\u00f6\u00b7ni\u00b7ges", "Fried'", "und", "frei\u00b7em", "Ge\u00b7lei\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NE", "KON", "ADJA", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.14": {"text": "Hielt er Lampen gefa\u00dft mit seinen Klauen und zerrte", "tokens": ["Hielt", "er", "Lam\u00b7pen", "ge\u00b7fa\u00dft", "mit", "sei\u00b7nen", "Klau\u00b7en", "und", "zerr\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "NN", "VVPP", "APPR", "PPOSAT", "NN", "KON", "VVFIN"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.15": {"text": "T\u00fcckisch den redlichen Mann. Ich kam die Stra\u00dfe gegangen,", "tokens": ["T\u00fc\u00b7ckisch", "den", "red\u00b7li\u00b7chen", "Mann", ".", "Ich", "kam", "die", "Stra\u00b7\u00dfe", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.16": {"text": "H\u00f6rte beider Gesang, der, kaum begonnen, schon wieder", "tokens": ["H\u00f6r\u00b7te", "bei\u00b7der", "Ge\u00b7sang", ",", "der", ",", "kaum", "be\u00b7gon\u00b7nen", ",", "schon", "wie\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "$,", "PRELS", "$,", "ADV", "VVPP", "$,", "ADV", "ADV"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.17": {"text": "Endete. Horchend wundert ich mich, doch als ich hinzukam,", "tokens": ["En\u00b7de\u00b7te", ".", "Hor\u00b7chend", "wun\u00b7dert", "ich", "mich", ",", "doch", "als", "ich", "hin\u00b7zu\u00b7kam", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NE", "VVFIN", "PPER", "PRF", "$,", "ADV", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+--+--+-+-+-+-+", "measure": "dactylic.di.plus"}, "line.18": {"text": "Kannt ich Reineken stracks, er hatte Lampen beim Kragen;", "tokens": ["Kannt", "ich", "Rei\u00b7ne\u00b7ken", "stracks", ",", "er", "hat\u00b7te", "Lam\u00b7pen", "beim", "Kra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "VVFIN", "$,", "PPER", "VAFIN", "NN", "APPRART", "NN", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.19": {"text": "Ja, er h\u00e4tt ihm gewi\u00df das Leben genommen, wofern ich", "tokens": ["Ja", ",", "er", "h\u00e4tt", "ihm", "ge\u00b7wi\u00df", "das", "Le\u00b7ben", "ge\u00b7nom\u00b7men", ",", "wo\u00b7fern", "ich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$,", "KOUS", "PPER"], "meter": "--+--+-+--+-+-+", "measure": "anapaest.di.plus"}, "line.20": {"text": "Nicht zum Gl\u00fccke des Wegs gekommen w\u00e4re. Da steht er!", "tokens": ["Nicht", "zum", "Gl\u00fc\u00b7cke", "des", "Wegs", "ge\u00b7kom\u00b7men", "w\u00e4\u00b7re", ".", "Da", "steht", "er", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "ART", "NN", "VVPP", "VAFIN", "$.", "ADV", "VVFIN", "PPER", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.21": {"text": "Seht die Wunden an ihm, dem frommen Manne, den keiner", "tokens": ["Seht", "die", "Wun\u00b7den", "an", "ihm", ",", "dem", "from\u00b7men", "Man\u00b7ne", ",", "den", "kei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPER", "$,", "ART", "ADJA", "NN", "$,", "PRELS", "PIS"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.22": {"text": "Zu beleidigen denkt. Und will es unser Gebieter,", "tokens": ["Zu", "be\u00b7lei\u00b7di\u00b7gen", "denkt", ".", "Und", "will", "es", "un\u00b7ser", "Ge\u00b7bie\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "$.", "KON", "VMFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.23": {"text": "Wollt ihr Herren es leiden, da\u00df so des K\u00f6niges Friede,", "tokens": ["Wollt", "ihr", "Her\u00b7ren", "es", "lei\u00b7den", ",", "da\u00df", "so", "des", "K\u00f6\u00b7ni\u00b7ges", "Frie\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PPER", "VVINF", "$,", "KOUS", "ADV", "ART", "NN", "NN", "$,"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.24": {"text": "Sein Geleit und Brief von einem Diebe verh\u00f6hnt wird,", "tokens": ["Sein", "Ge\u00b7leit", "und", "Brief", "von", "ei\u00b7nem", "Die\u00b7be", "ver\u00b7h\u00f6hnt", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "APPR", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.25": {"text": "Oh, so wird der K\u00f6nig und seine Kinder noch sp\u00e4ten", "tokens": ["Oh", ",", "so", "wird", "der", "K\u00f6\u00b7nig", "und", "sei\u00b7ne", "Kin\u00b7der", "noch", "sp\u00e4\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "ART", "NN", "KON", "PPOSAT", "NN", "ADV", "VVINF"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.26": {"text": "Vorwurf h\u00f6ren von Leuten, die Recht und Gerechtigkeit lieben.\u00ab", "tokens": ["Vor\u00b7wurf", "h\u00f6\u00b7ren", "von", "Leu\u00b7ten", ",", "die", "Recht", "und", "Ge\u00b7rech\u00b7tig\u00b7keit", "lie\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVINF", "APPR", "NN", "$,", "ART", "NN", "KON", "NN", "VVINF", "$.", "$("], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}}, "stanza.6": {"line.1": {"text": "Isegrim sagte darauf: \u00bbSo wird es bleiben, und leider", "tokens": ["I\u00b7seg\u00b7rim", "sag\u00b7te", "da\u00b7rauf", ":", "\u00bb", "So", "wird", "es", "blei\u00b7ben", ",", "und", "lei\u00b7der"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "VVFIN", "PAV", "$.", "$(", "ADV", "VAFIN", "PPER", "VVINF", "$,", "KON", "ADV"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Wird uns Reineke nie was Gutes erzeigen. Oh! l\u00e4g er", "tokens": ["Wird", "uns", "Rei\u00b7ne\u00b7ke", "nie", "was", "Gu\u00b7tes", "er\u00b7zei\u00b7gen", ".", "Oh", "!", "l\u00e4g", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "NN", "ADV", "PWS", "NN", "VVINF", "$.", "ITJ", "$.", "VVFIN", "PPER"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Lange tot; das w\u00e4re das beste f\u00fcr friedliche Leute;", "tokens": ["Lan\u00b7ge", "tot", ";", "das", "w\u00e4\u00b7re", "das", "bes\u00b7te", "f\u00fcr", "fried\u00b7li\u00b7che", "Leu\u00b7te", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PDS", "VAFIN", "ART", "ADJA", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Aber wird ihm diesmal verziehn, so wird er in kurzem", "tokens": ["A\u00b7ber", "wird", "ihm", "dies\u00b7mal", "ver\u00b7ziehn", ",", "so", "wird", "er", "in", "kur\u00b7zem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVINF", "$,", "ADV", "VAFIN", "PPER", "APPR", "ADJA"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Etliche k\u00fchnlich ber\u00fccken, die nun es am wenigsten glauben.\u00ab", "tokens": ["Et\u00b7li\u00b7che", "k\u00fchn\u00b7lich", "be\u00b7r\u00fc\u00b7cken", ",", "die", "nun", "es", "am", "we\u00b7nigs\u00b7ten", "glau\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "ADJD", "VVINF", "$,", "PRELS", "ADV", "PPER", "APPRART", "PIS", "VVINF", "$.", "$("], "meter": "+--+--+--+--++-+-", "measure": "dactylic.tetra.plus"}}, "stanza.7": {"line.1": {"text": "Reinekens Neffe, der Dachs, nahm jetzt die Rede, und mutig", "tokens": ["Rei\u00b7ne\u00b7kens", "Nef\u00b7fe", ",", "der", "Dachs", ",", "nahm", "jetzt", "die", "Re\u00b7de", ",", "und", "mu\u00b7tig"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "$,", "ART", "NN", "$,", "VVFIN", "ADV", "ART", "NN", "$,", "KON", "ADJD"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Sprach er zu Reinekens Bestem, so falsch auch dieser bekannt war.", "tokens": ["Sprach", "er", "zu", "Rei\u00b7ne\u00b7kens", "Bes\u00b7tem", ",", "so", "falsch", "auch", "die\u00b7ser", "be\u00b7kannt", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "NE", "NN", "$,", "ADV", "ADJD", "ADV", "PDAT", "ADJD", "VAFIN", "$."], "meter": "-+-+--+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbalt und wahr, Herr Isegrim!\u00ab sagt' er, \u00bbbeweist sich das Sprichwort:", "tokens": ["\u00bb", "alt", "und", "wahr", ",", "Herr", "I\u00b7seg\u00b7rim", "!", "\u00ab", "sagt'", "er", ",", "\u00bb", "be\u00b7weist", "sich", "das", "Sprich\u00b7wort", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "KON", "ADJD", "$,", "NN", "NE", "$.", "$(", "VVFIN", "PPER", "$,", "$(", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Feindes Mund frommt selten. So hat auch wahrlich mein Oheim", "tokens": ["Fein\u00b7des", "Mund", "frommt", "sel\u00b7ten", ".", "So", "hat", "auch", "wahr\u00b7lich", "mein", "O\u00b7heim"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "VVFIN", "ADJD", "$.", "ADV", "VAFIN", "ADV", "ADV", "PPOSAT", "NN"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Eurer Worte sich nicht zu getr\u00f6sten. Doch ist es ein leichtes.", "tokens": ["Eu\u00b7rer", "Wor\u00b7te", "sich", "nicht", "zu", "ge\u00b7tr\u00f6s\u00b7ten", ".", "Doch", "ist", "es", "ein", "leich\u00b7tes", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRF", "PTKNEG", "PTKZU", "VVINF", "$.", "KON", "VAFIN", "PPER", "ART", "ADJA", "$."], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.6": {"text": "W\u00e4r er hier am Hofe so gut als Ihr und erfreut' er", "tokens": ["W\u00e4r", "er", "hier", "am", "Ho\u00b7fe", "so", "gut", "als", "Ihr", "und", "er\u00b7freut'", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "APPRART", "NN", "ADV", "ADJD", "KOKOM", "PPER", "KON", "VVFIN", "PPER"], "meter": "+-+-+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.7": {"text": "Da\u00df Ihr so h\u00e4misch gesprochen und alte Geschichten erneuert.", "tokens": ["Da\u00df", "Ihr", "so", "h\u00e4\u00b7misch", "ge\u00b7spro\u00b7chen", "und", "al\u00b7te", "Ge\u00b7schich\u00b7ten", "er\u00b7neu\u00b7ert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVPP", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Aber was Ihr \u00dcbels an Reineken selber ver\u00fcbet,", "tokens": ["A\u00b7ber", "was", "Ihr", "\u00dc\u00b7bels", "an", "Rei\u00b7ne\u00b7ken", "sel\u00b7ber", "ver\u00b7\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "APPR", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.9": {"text": "\u00dcbergeht Ihr; und doch, es wissen es manche der Herren,", "tokens": ["\u00dc\u00b7ber\u00b7geht", "Ihr", ";", "und", "doch", ",", "es", "wis\u00b7sen", "es", "man\u00b7che", "der", "Her\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "KON", "ADV", "$,", "PPER", "VVFIN", "PPER", "PIS", "ART", "NN", "$,"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Wie ihr zusammen ein B\u00fcndnis geschlossen und beide versprochen,", "tokens": ["Wie", "ihr", "zu\u00b7sam\u00b7men", "ein", "B\u00fcnd\u00b7nis", "ge\u00b7schlos\u00b7sen", "und", "bei\u00b7de", "ver\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "VVPP", "KON", "PIS", "VVINF", "$,"], "meter": "-+-+--+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Als zwei gleiche Gesellen zu leben. Das mu\u00df ich erz\u00e4hlen;", "tokens": ["Als", "zwei", "glei\u00b7che", "Ge\u00b7sel\u00b7len", "zu", "le\u00b7ben", ".", "Das", "mu\u00df", "ich", "er\u00b7z\u00e4h\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "ADJA", "NN", "PTKZU", "VVINF", "$.", "PDS", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.12": {"text": "Denn im Winter einmal erduldet' er gro\u00dfe Gefahren", "tokens": ["Denn", "im", "Win\u00b7ter", "ein\u00b7mal", "er\u00b7dul\u00b7det'", "er", "gro\u00b7\u00dfe", "Ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ADV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Euretwegen. Ein Fuhrmann, er hatte Fische geladen,", "tokens": ["Eu\u00b7ret\u00b7we\u00b7gen", ".", "Ein", "Fuhr\u00b7mann", ",", "er", "hat\u00b7te", "Fi\u00b7sche", "ge\u00b7la\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ART", "NN", "$,", "PPER", "VAFIN", "NN", "VVPP", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.14": {"text": "Fuhr die Stra\u00dfe; Ihr sp\u00fcrtet ihn aus und h\u00e4ttet um alles", "tokens": ["Fuhr", "die", "Stra\u00b7\u00dfe", ";", "Ihr", "sp\u00fcr\u00b7tet", "ihn", "aus", "und", "h\u00e4t\u00b7tet", "um", "al\u00b7les"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "KON", "VAFIN", "APPR", "PIS"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.15": {"text": "Gern von der Ware gegessen; doch fehlt' es Euch leider am Gelde.", "tokens": ["Gern", "von", "der", "Wa\u00b7re", "ge\u00b7ges\u00b7sen", ";", "doch", "fehlt'", "es", "Euch", "lei\u00b7der", "am", "Gel\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$.", "ADV", "VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.16": {"text": "Da beredetet Ihr den Oheim, er legte sich listig", "tokens": ["Da", "be\u00b7re\u00b7de\u00b7tet", "Ihr", "den", "O\u00b7heim", ",", "er", "leg\u00b7te", "sich", "lis\u00b7tig"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "PPER", "VVFIN", "PRF", "ADJD"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.17": {"text": "Grade f\u00fcr tot in den Weg. Es war, beim Himmel, ein k\u00fchnes", "tokens": ["Gra\u00b7de", "f\u00fcr", "tot", "in", "den", "Weg", ".", "Es", "war", ",", "beim", "Him\u00b7mel", ",", "ein", "k\u00fch\u00b7nes"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "ADJD", "APPR", "ART", "NN", "$.", "PPER", "VAFIN", "$,", "APPRART", "NN", "$,", "ART", "ADJA"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.18": {"text": "Abenteuer! Doch merket, was ihm f\u00fcr Fische geworden.", "tokens": ["A\u00b7bent\u00b7eu\u00b7er", "!", "Doch", "mer\u00b7ket", ",", "was", "ihm", "f\u00fcr", "Fi\u00b7sche", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "VVFIN", "$,", "PWS", "PPER", "APPR", "NN", "VAPP", "$."], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.19": {"text": "Und der Fuhrmann kam und sah im Gleise den Oheim,", "tokens": ["Und", "der", "Fuhr\u00b7mann", "kam", "und", "sah", "im", "Glei\u00b7se", "den", "O\u00b7heim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "KON", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.20": {"text": "Hastig zog er sein Schwert, ihm eins zu versetzen; der Kluge", "tokens": ["Has\u00b7tig", "zog", "er", "sein", "Schwert", ",", "ihm", "eins", "zu", "ver\u00b7set\u00b7zen", ";", "der", "Klu\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "PPER", "PIS", "PTKZU", "VVINF", "$.", "ART", "NN"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.21": {"text": "R\u00fchrt' und regte sich nicht, als w\u00e4r er gestorben; der Fuhrmann", "tokens": ["R\u00fchrt'", "und", "reg\u00b7te", "sich", "nicht", ",", "als", "w\u00e4r", "er", "ge\u00b7stor\u00b7ben", ";", "der", "Fuhr\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "KON", "VVFIN", "PRF", "PTKNEG", "$,", "KOKOM", "VAFIN", "PPER", "VVPP", "$.", "ART", "NN"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.22": {"text": "Wirft ihn auf seinen Karrn und freut sich des Balges im voraus.", "tokens": ["Wirft", "ihn", "auf", "sei\u00b7nen", "Karrn", "und", "freut", "sich", "des", "Bal\u00b7ges", "im", "vo\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "PRF", "ART", "NN", "APPRART", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.23": {"text": "Ja, das wagte mein Oheim f\u00fcr Isegrim; aber der Fuhrmann", "tokens": ["Ja", ",", "das", "wag\u00b7te", "mein", "O\u00b7heim", "f\u00fcr", "I\u00b7seg\u00b7rim", ";", "a\u00b7ber", "der", "Fuhr\u00b7mann"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PDS", "VVFIN", "PPOSAT", "NN", "APPR", "NE", "$.", "ADV", "ART", "NN"], "meter": "+-+-+-+-+--+--+-", "measure": "trochaic.septa.relaxed"}, "line.24": {"text": "Fuhr dahin, und Reineke warf von den Fischen herunter.", "tokens": ["Fuhr", "da\u00b7hin", ",", "und", "Rei\u00b7ne\u00b7ke", "warf", "von", "den", "Fi\u00b7schen", "her\u00b7un\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "$,", "KON", "NN", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.25": {"text": "Isegrim kam von ferne geschlichen, verzehrte die Fische.", "tokens": ["I\u00b7seg\u00b7rim", "kam", "von", "fer\u00b7ne", "ge\u00b7schli\u00b7chen", ",", "ver\u00b7zehr\u00b7te", "die", "Fi\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADV", "VVPP", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.26": {"text": "Reineken mochte nicht l\u00e4nger zu fahren belieben; er hub sich,", "tokens": ["Rei\u00b7ne\u00b7ken", "moch\u00b7te", "nicht", "l\u00e4n\u00b7ger", "zu", "fah\u00b7ren", "be\u00b7lie\u00b7ben", ";", "er", "hub", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "VVINF", "$.", "PPER", "VVFIN", "PRF", "$,"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.27": {"text": "Sprang vom Karren und w\u00fcnschte nun auch von der Beute zu speisen.", "tokens": ["Sprang", "vom", "Kar\u00b7ren", "und", "w\u00fcnschte", "nun", "auch", "von", "der", "Beu\u00b7te", "zu", "spei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "KON", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.28": {"text": "Aber Isegrim hatte sie alle verschlungen; er hatte", "tokens": ["A\u00b7ber", "I\u00b7seg\u00b7rim", "hat\u00b7te", "sie", "al\u00b7le", "ver\u00b7schlun\u00b7gen", ";", "er", "hat\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NE", "VAFIN", "PPER", "PIS", "VVPP", "$.", "PPER", "VAFIN"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.29": {"text": "\u00dcber Not sich beladen, er wollte bersten. Die Gr\u00e4ten", "tokens": ["\u00dc\u00b7ber", "Not", "sich", "be\u00b7la\u00b7den", ",", "er", "woll\u00b7te", "bers\u00b7ten", ".", "Die", "Gr\u00e4\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "PRF", "VVPP", "$,", "PPER", "VMFIN", "VVINF", "$.", "ART", "NN"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.30": {"text": "Lie\u00df er allein zur\u00fcck und bot dem Freunde den Rest an.", "tokens": ["Lie\u00df", "er", "al\u00b7lein", "zu\u00b7r\u00fcck", "und", "bot", "dem", "Freun\u00b7de", "den", "Rest", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKVZ", "KON", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+++", "measure": "unknown.measure.octa.plus"}, "line.31": {"text": "Noch ein anderes St\u00fcckchen! auch dies erz\u00e4hl ich Euch wahrhaft.", "tokens": ["Noch", "ein", "an\u00b7de\u00b7res", "St\u00fcck\u00b7chen", "!", "auch", "dies", "er\u00b7z\u00e4hl", "ich", "Euch", "wahr\u00b7haft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$.", "ADV", "PDS", "VVFIN", "PPER", "PPER", "ADV", "$."], "meter": "--+--+--+-+-+-+", "measure": "anapaest.tri.plus"}, "line.32": {"text": "Reineken war es bewu\u00dft, bei einem Bauer am Nagel", "tokens": ["Rei\u00b7ne\u00b7ken", "war", "es", "be\u00b7wu\u00dft", ",", "bei", "ei\u00b7nem", "Bau\u00b7er", "am", "Na\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "ADJD", "$,", "APPR", "ART", "NN", "APPRART", "NE"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.33": {"text": "Hing ein gem\u00e4stetes Schwein, erst heute geschlachtet; das sagt'er", "tokens": ["Hing", "ein", "ge\u00b7m\u00e4s\u00b7te\u00b7tes", "Schwein", ",", "erst", "heu\u00b7te", "ge\u00b7schlach\u00b7tet", ";", "das", "sagt'\u00b7er"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,", "ADV", "ADV", "VVPP", "$.", "ART", "NN"], "meter": "-+-+--+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Treu dem Wolfe: sie gingen dahin, Gewinn und Gefahren", "tokens": ["Treu", "dem", "Wol\u00b7fe", ":", "sie", "gin\u00b7gen", "da\u00b7hin", ",", "Ge\u00b7winn", "und", "Ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$.", "PPER", "VVFIN", "PAV", "$,", "NN", "KON", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.35": {"text": "Redlich zu teilen. Doch M\u00fch und Gefahr trug jener alleine.", "tokens": ["Red\u00b7lich", "zu", "tei\u00b7len", ".", "Doch", "M\u00fch", "und", "Ge\u00b7fahr", "trug", "je\u00b7ner", "al\u00b7lei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$.", "KON", "NN", "KON", "NN", "VVFIN", "PDS", "ADV", "$."], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.36": {"text": "Denn er kroch zum Fenster hinein und warf mit Bem\u00fchen", "tokens": ["Denn", "er", "kroch", "zum", "Fens\u00b7ter", "hin\u00b7ein", "und", "warf", "mit", "Be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "KON", "VVFIN", "APPR", "NN"], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.37": {"text": "Die gemeinsame Beute dem Wolf herunter; zum Ungl\u00fcck", "tokens": ["Die", "ge\u00b7mein\u00b7sa\u00b7me", "Beu\u00b7te", "dem", "Wolf", "her\u00b7un\u00b7ter", ";", "zum", "Un\u00b7gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NE", "PTKVZ", "$.", "APPRART", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.38": {"text": "Waren Hunde nicht fern, die ihn im Hause versp\u00fcrten", "tokens": ["Wa\u00b7ren", "Hun\u00b7de", "nicht", "fern", ",", "die", "ihn", "im", "Hau\u00b7se", "ver\u00b7sp\u00fcr\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "PTKNEG", "ADJD", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.39": {"text": "Und ihm wacker das Fell zerzausten. Verwundet entkam er;", "tokens": ["Und", "ihm", "wa\u00b7cker", "das", "Fell", "zer\u00b7zaus\u00b7ten", ".", "Ver\u00b7wun\u00b7det", "ent\u00b7kam", "er", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "ART", "NN", "VVFIN", "$.", "VVPP", "VVFIN", "PPER", "$."], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.40": {"text": "Eilig sucht' er Isegrim auf und klagt' ihm sein Leiden", "tokens": ["Ei\u00b7lig", "sucht'", "er", "I\u00b7seg\u00b7rim", "auf", "und", "klagt'", "ihm", "sein", "Lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "NE", "PTKVZ", "KON", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.41": {"text": "Und verlangte sein Teil. Da sagte jener: \u203aIch habe", "tokens": ["Und", "ver\u00b7lang\u00b7te", "sein", "Teil", ".", "Da", "sag\u00b7te", "je\u00b7ner", ":", "\u203a", "Ich", "ha\u00b7be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PDAT", "$.", "$(", "PPER", "VAFIN"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.42": {"text": "Und benage mir's wohl; wie wird das Fette dir schmecken!\u2039", "tokens": ["Und", "be\u00b7na\u00b7ge", "mir's", "wohl", ";", "wie", "wird", "das", "Fet\u00b7te", "dir", "schme\u00b7cken", "!", "\u2039"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "NE", "ADV", "$.", "PWAV", "VAFIN", "ART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.43": {"text": "Und er brachte das St\u00fcck; das Krummholz war es, der Schl\u00e4chter", "tokens": ["Und", "er", "brach\u00b7te", "das", "St\u00fcck", ";", "das", "Krumm\u00b7holz", "war", "es", ",", "der", "Schl\u00e4ch\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$.", "ART", "NN", "VAFIN", "PPER", "$,", "ART", "NN"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.44": {"text": "Hatte daran das Schwein geh\u00e4ngt; der k\u00f6stliche Braten", "tokens": ["Hat\u00b7te", "da\u00b7ran", "das", "Schwein", "ge\u00b7h\u00e4ngt", ";", "der", "k\u00f6st\u00b7li\u00b7che", "Bra\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PAV", "ART", "NN", "VVPP", "$.", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.45": {"text": "War vom gierigen Wolfe, dem Ungerechten, verschlungen.", "tokens": ["War", "vom", "gie\u00b7ri\u00b7gen", "Wol\u00b7fe", ",", "dem", "Un\u00b7ge\u00b7rech\u00b7ten", ",", "ver\u00b7schlun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "APPRART", "ADJA", "NN", "$,", "ART", "NN", "$,", "VVPP", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.46": {"text": "Reineke konnte vor Zorn nicht reden, doch was er sich dachte,", "tokens": ["Rei\u00b7ne\u00b7ke", "konn\u00b7te", "vor", "Zorn", "nicht", "re\u00b7den", ",", "doch", "was", "er", "sich", "dach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "APPR", "NN", "PTKNEG", "VVINF", "$,", "KON", "PWS", "PPER", "PRF", "VVFIN", "$,"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.47": {"text": "Denket Euch selbst. Herr K\u00f6nig, gewi\u00df, da\u00df hundert und dr\u00fcber", "tokens": ["Den\u00b7ket", "Euch", "selbst", ".", "Herr", "K\u00f6\u00b7nig", ",", "ge\u00b7wi\u00df", ",", "da\u00df", "hun\u00b7dert", "und", "dr\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$.", "NN", "NN", "$,", "ADV", "$,", "KOUS", "CARD", "KON", "PAV"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.48": {"text": "Solcher St\u00fcckchen der Wolf an meinem Oheim verschuldet!", "tokens": ["Sol\u00b7cher", "St\u00fcck\u00b7chen", "der", "Wolf", "an", "mei\u00b7nem", "O\u00b7heim", "ver\u00b7schul\u00b7det", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NE", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+--+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.49": {"text": "Aber ich schweige davon. Wird Reineke selber gefordert,", "tokens": ["A\u00b7ber", "ich", "schwei\u00b7ge", "da\u00b7von", ".", "Wird", "Rei\u00b7ne\u00b7ke", "sel\u00b7ber", "ge\u00b7for\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PAV", "$.", "VAFIN", "NN", "ADV", "VVPP", "$,"], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.50": {"text": "Wird er sich besser verteid'gen. Indessen, gn\u00e4digster K\u00f6nig,", "tokens": ["Wird", "er", "sich", "bes\u00b7ser", "ver\u00b7tei\u00b7d'\u00b7gen", ".", "In\u00b7des\u00b7sen", ",", "gn\u00e4\u00b7digs\u00b7ter", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADJD", "VVINF", "$.", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+--+--+---+-+--+-", "measure": "dactylic.tri.plus"}, "line.51": {"text": "Edler Gebieter, ich darf es bemerken: Ihr habet, es haben", "tokens": ["Ed\u00b7ler", "Ge\u00b7bie\u00b7ter", ",", "ich", "darf", "es", "be\u00b7mer\u00b7ken", ":", "Ihr", "ha\u00b7bet", ",", "es", "ha\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$.", "PPER", "VAFIN", "$,", "PPER", "VAFIN"], "meter": "+--+--+--+-+-+-+-", "measure": "dactylic.tri.plus"}, "line.52": {"text": "Diese Herren geh\u00f6rt, wie t\u00f6richt Isegrims Rede", "tokens": ["Die\u00b7se", "Her\u00b7ren", "ge\u00b7h\u00f6rt", ",", "wie", "t\u00f6\u00b7richt", "I\u00b7se\u00b7grims", "Re\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VVFIN", "$,", "PWAV", "VVFIN", "NE", "NN"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.53": {"text": "Seinem eignen Weibe und ihrer Ehre zu nah tritt,", "tokens": ["Sei\u00b7nem", "eig\u00b7nen", "Wei\u00b7be", "und", "ih\u00b7rer", "Eh\u00b7re", "zu", "nah", "tritt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "KON", "PPOSAT", "NN", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.54": {"text": "Die er mit Leib und Leben besch\u00fctzen sollte. Denn freilich", "tokens": ["Die", "er", "mit", "Leib", "und", "Le\u00b7ben", "be\u00b7sch\u00fct\u00b7zen", "soll\u00b7te", ".", "Denn", "frei\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "VMFIN", "$.", "KON", "ADV"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.55": {"text": "Sieben Jahre sind's her und dr\u00fcber, da schenkte mein Oheim", "tokens": ["Sie\u00b7ben", "Jah\u00b7re", "sin\u00b7d's", "her", "und", "dr\u00fc\u00b7ber", ",", "da", "schenk\u00b7te", "mein", "O\u00b7heim"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["CARD", "NN", "NE", "PTKVZ", "KON", "PAV", "$,", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-+--+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.56": {"text": "Seine Lieb und Treue zum guten Teile der sch\u00f6nen", "tokens": ["Sei\u00b7ne", "Lieb", "und", "Treu\u00b7e", "zum", "gu\u00b7ten", "Tei\u00b7le", "der", "sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN", "APPRART", "ADJA", "NN", "ART", "ADJA"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.57": {"text": "Frauen Gieremund; solches geschah beim n\u00e4chtlichen Tanze;", "tokens": ["Frau\u00b7en", "Gie\u00b7re\u00b7mund", ";", "sol\u00b7ches", "ge\u00b7schah", "beim", "n\u00e4cht\u00b7li\u00b7chen", "Tan\u00b7ze", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "PIS", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+---+-+--+-", "measure": "trochaic.hexa.relaxed"}, "line.58": {"text": "Isegrim war verreist, ich sag es, wie mir's bekannt ist.", "tokens": ["I\u00b7seg\u00b7rim", "war", "ver\u00b7reist", ",", "ich", "sag", "es", ",", "wie", "mir's", "be\u00b7kannt", "ist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "VVPP", "$,", "PPER", "VVFIN", "PPER", "$,", "PWAV", "NE", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.59": {"text": "Freundlich und h\u00f6flich ist sie ihm oft zu Willen geworden,", "tokens": ["Freund\u00b7lich", "und", "h\u00f6f\u00b7lich", "ist", "sie", "ihm", "oft", "zu", "Wil\u00b7len", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VAFIN", "PPER", "PPER", "ADV", "APPR", "NN", "VAPP", "$,"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.60": {"text": "Und was ist es denn mehr? Sie bracht es niemals zur Klage,", "tokens": ["Und", "was", "ist", "es", "denn", "mehr", "?", "Sie", "bracht", "es", "nie\u00b7mals", "zur", "Kla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PPER", "ADV", "ADV", "$.", "PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-++--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.61": {"text": "Ja, sie lebt und befindet sich wohl, was macht er f\u00fcr Wesen?", "tokens": ["Ja", ",", "sie", "lebt", "und", "be\u00b7fin\u00b7det", "sich", "wohl", ",", "was", "macht", "er", "f\u00fcr", "We\u00b7sen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "KON", "VVFIN", "PRF", "ADV", "$,", "PWS", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.62": {"text": "W\u00e4r er klug, so schwieg' er davon; es bringt ihm nur Schande.\u00ab", "tokens": ["W\u00e4r", "er", "klug", ",", "so", "schwieg'", "er", "da\u00b7von", ";", "es", "bringt", "ihm", "nur", "Schan\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$,", "ADV", "VVFIN", "PPER", "PAV", "$.", "PPER", "VVFIN", "PPER", "ADV", "NN", "$.", "$("], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.63": {"text": "Weiter sagte der Dachs: \u00bbNun kommt das M\u00e4rchen vom Hasen!", "tokens": ["Wei\u00b7ter", "sag\u00b7te", "der", "Dachs", ":", "\u00bb", "Nun", "kommt", "das", "M\u00e4r\u00b7chen", "vom", "Ha\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.64": {"text": "Eitel leeres Gew\u00e4sche! Den Sch\u00fcler sollte der Meister", "tokens": ["Ei\u00b7tel", "lee\u00b7res", "Ge\u00b7w\u00e4\u00b7sche", "!", "Den", "Sch\u00fc\u00b7ler", "soll\u00b7te", "der", "Meis\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "$.", "ART", "NN", "VMFIN", "ART", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.65": {"text": "Etwa nicht z\u00fcchtigen, wenn er nicht merkt und \u00fcbel bestehet?", "tokens": ["Et\u00b7wa", "nicht", "z\u00fcch\u00b7ti\u00b7gen", ",", "wenn", "er", "nicht", "merkt", "und", "\u00fc\u00b7bel", "be\u00b7ste\u00b7het", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VVINF", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "KON", "ADJD", "VVFIN", "$."], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.66": {"text": "Sollte man nicht die Knaben bestrafen, und ginge der Leichtsinn,", "tokens": ["Soll\u00b7te", "man", "nicht", "die", "Kna\u00b7ben", "be\u00b7stra\u00b7fen", ",", "und", "gin\u00b7ge", "der", "Leicht\u00b7sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PTKNEG", "ART", "NN", "VVPP", "$,", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.67": {"text": "Ginge die Unart so hin, wie sollte die Jugend erwachsen?", "tokens": ["Gin\u00b7ge", "die", "Un\u00b7art", "so", "hin", ",", "wie", "soll\u00b7te", "die", "Ju\u00b7gend", "er\u00b7wach\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,", "PWAV", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.68": {"text": "Nun klagt Wackerlos, wie er ein W\u00fcrstchen im Winter verloren", "tokens": ["Nun", "klagt", "Wa\u00b7cker\u00b7los", ",", "wie", "er", "ein", "W\u00fcr\u00b7stchen", "im", "Win\u00b7ter", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "$,", "PWAV", "PPER", "ART", "NN", "APPRART", "NN", "VVPP"], "meter": "-+--+---+--+--+-", "measure": "iambic.penta.relaxed"}, "line.69": {"text": "Hinter der Hecke; das sollt er nun lieber im stillen verschmerzen;", "tokens": ["Hin\u00b7ter", "der", "He\u00b7cke", ";", "das", "sollt", "er", "nun", "lie\u00b7ber", "im", "stil\u00b7len", "ver\u00b7schmer\u00b7zen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "PDS", "VMFIN", "PPER", "ADV", "ADV", "APPRART", "ADJA", "VVINF", "$."], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.70": {"text": "Denn wir h\u00f6ren es ja, sie war gestohlen; zerronnen", "tokens": ["Denn", "wir", "h\u00f6\u00b7ren", "es", "ja", ",", "sie", "war", "ge\u00b7stoh\u00b7len", ";", "zer\u00b7ron\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "VAFIN", "VVPP", "$.", "VVPP"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.71": {"text": "Wie gewonnen; und wer kann meinem Oheim verargen,", "tokens": ["Wie", "ge\u00b7won\u00b7nen", ";", "und", "wer", "kann", "mei\u00b7nem", "O\u00b7heim", "ver\u00b7ar\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "$.", "KON", "PWS", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "--+--+-+--+-+-", "measure": "anapaest.di.plus"}, "line.72": {"text": "Da\u00df er gestohlenes Gut dem Diebe genommen? Es sollen", "tokens": ["Da\u00df", "er", "ge\u00b7stoh\u00b7le\u00b7nes", "Gut", "dem", "Die\u00b7be", "ge\u00b7nom\u00b7men", "?", "Es", "sol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADJA", "NN", "ART", "NN", "VVPP", "$.", "PPER", "VMFIN"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.73": {"text": "Edle M\u00e4nner von hoher Geburt sich geh\u00e4ssig den Dieben", "tokens": ["Ed\u00b7le", "M\u00e4n\u00b7ner", "von", "ho\u00b7her", "Ge\u00b7burt", "sich", "ge\u00b7h\u00e4s\u00b7sig", "den", "Die\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "PRF", "ADJD", "ART", "NN"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.74": {"text": "Und gef\u00e4hrlich erzeigen. Ja, h\u00e4tt er ihn damals gehangen,", "tokens": ["Und", "ge\u00b7f\u00e4hr\u00b7lich", "er\u00b7zei\u00b7gen", ".", "Ja", ",", "h\u00e4tt", "er", "ihn", "da\u00b7mals", "ge\u00b7han\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "$.", "PTKANT", "$,", "VAFIN", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.75": {"text": "War es verzeihlich. Doch lie\u00df er ihn los, den K\u00f6nig zu ehren;", "tokens": ["War", "es", "ver\u00b7zeih\u00b7lich", ".", "Doch", "lie\u00df", "er", "ihn", "los", ",", "den", "K\u00f6\u00b7nig", "zu", "eh\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$.", "KON", "VVFIN", "PPER", "PPER", "PTKVZ", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.76": {"text": "Denn am Leben zu strafen geh\u00f6rt dem K\u00f6nig alleine.", "tokens": ["Denn", "am", "Le\u00b7ben", "zu", "stra\u00b7fen", "ge\u00b7h\u00f6rt", "dem", "K\u00f6\u00b7nig", "al\u00b7lei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "PTKZU", "VVINF", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.77": {"text": "So gerecht er auch sei und \u00dcbeltaten verwehret.", "tokens": ["So", "ge\u00b7recht", "er", "auch", "sei", "und", "\u00dc\u00b7bel\u00b7ta\u00b7ten", "ver\u00b7weh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "VAFIN", "KON", "NN", "VVFIN", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.78": {"text": "Denn seitdem des K\u00f6nigs Friede verk\u00fcndiget worden,", "tokens": ["Denn", "seit\u00b7dem", "des", "K\u00f6\u00b7nigs", "Frie\u00b7de", "ver\u00b7k\u00fcn\u00b7di\u00b7get", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ART", "NN", "NN", "VVPP", "VAPP", "$,"], "meter": "----+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.79": {"text": "H\u00e4lt sich niemand wie er. Er hat sein Leben ver\u00e4ndert,", "tokens": ["H\u00e4lt", "sich", "nie\u00b7mand", "wie", "er", ".", "Er", "hat", "sein", "Le\u00b7ben", "ver\u00b7\u00e4n\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIS", "KOKOM", "PPER", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}, "line.80": {"text": "Speiset nur einmal des Tags, lebt wie ein Klausner, kasteit sich,", "tokens": ["Spei\u00b7set", "nur", "ein\u00b7mal", "des", "Tags", ",", "lebt", "wie", "ein", "Klaus\u00b7ner", ",", "kas\u00b7teit", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "$,", "VVFIN", "KOKOM", "ART", "NN", "$,", "VVFIN", "PRF", "$,"], "meter": "+--+--+-+-+-+--", "measure": "elegiambus"}, "line.81": {"text": "Tr\u00e4gt ein h\u00e4renes Kleid auf blo\u00dfem Leibe und hat schon", "tokens": ["Tr\u00e4gt", "ein", "h\u00e4\u00b7re\u00b7nes", "Kleid", "auf", "blo\u00b7\u00dfem", "Lei\u00b7be", "und", "hat", "schon"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "KON", "VAFIN", "ADV"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.82": {"text": "Lange von Wildbret und zahmem Fleische sich g\u00e4nzlich enthalten,", "tokens": ["Lan\u00b7ge", "von", "Wild\u00b7bret", "und", "zah\u00b7mem", "Flei\u00b7sche", "sich", "g\u00e4nz\u00b7lich", "ent\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "KON", "ADJA", "NN", "PRF", "ADJD", "VVPP", "$,"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.83": {"text": "Wie mir noch gestern einer erz\u00e4hlte, der bei ihm gewesen.", "tokens": ["Wie", "mir", "noch", "ge\u00b7stern", "ei\u00b7ner", "er\u00b7z\u00e4hl\u00b7te", ",", "der", "bei", "ihm", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "PIS", "VVFIN", "$,", "PRELS", "APPR", "PPER", "VAPP", "$."], "meter": "--+--+--+-+-+-+-", "measure": "anapaest.tri.plus"}, "line.84": {"text": "Malepartus, sein Schlo\u00df, hat er verlassen und baut sich", "tokens": ["Ma\u00b7le\u00b7par\u00b7tus", ",", "sein", "Schlo\u00df", ",", "hat", "er", "ver\u00b7las\u00b7sen", "und", "baut", "sich"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "VAFIN", "PPER", "VVINF", "KON", "VVFIN", "PRF"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.85": {"text": "Eine Klause zur Wohnung. Wie er so mager geworden,", "tokens": ["Ei\u00b7ne", "Klau\u00b7se", "zur", "Woh\u00b7nung", ".", "Wie", "er", "so", "ma\u00b7ger", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "PWAV", "PPER", "ADV", "ADJD", "VAPP", "$,"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.86": {"text": "Bleich von Hunger und Durst und andern strengeren Bu\u00dfen,", "tokens": ["Bleich", "von", "Hun\u00b7ger", "und", "Durst", "und", "an\u00b7dern", "stren\u00b7ge\u00b7ren", "Bu\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "KON", "NN", "KON", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.87": {"text": "Die er reuig ertr\u00e4gt, das werdet Ihr selber erfahren.", "tokens": ["Die", "er", "reu\u00b7ig", "er\u00b7tr\u00e4gt", ",", "das", "wer\u00b7det", "Ihr", "sel\u00b7ber", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "$,", "PDS", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.88": {"text": "Denn was kann es ihm schaden, da\u00df hier ihn jeder verklaget?", "tokens": ["Denn", "was", "kann", "es", "ihm", "scha\u00b7den", ",", "da\u00df", "hier", "ihn", "je\u00b7der", "ver\u00b7kla\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "PPER", "PPER", "VVINF", "$,", "KOUS", "ADV", "PPER", "PIS", "VVFIN", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.89": {"text": "Kommt er hieher, so f\u00fchrt er sein Recht aus und macht sie zuschanden.\u00ab", "tokens": ["Kommt", "er", "hie\u00b7her", ",", "so", "f\u00fchrt", "er", "sein", "Recht", "aus", "und", "macht", "sie", "zu\u00b7schan\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PAV", "$,", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "KON", "VVFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}}, "stanza.8": {"line.1": {"text": "Als nun Grimbart geendigt, erschien zu gro\u00dfem Erstaunen", "tokens": ["Als", "nun", "Grim\u00b7bart", "ge\u00b7en\u00b7digt", ",", "er\u00b7schien", "zu", "gro\u00b7\u00dfem", "Er\u00b7stau\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NE", "VVPP", "$,", "VVFIN", "APPR", "ADJA", "NN"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Henning, der Hahn, mit seinem Geschlecht. Auf trauriger Bahre,", "tokens": ["Hen\u00b7ning", ",", "der", "Hahn", ",", "mit", "sei\u00b7nem", "Ge\u00b7schlecht", ".", "Auf", "trau\u00b7ri\u00b7ger", "Bah\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$.", "APPR", "ADJA", "NN", "$,"], "meter": "---+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ohne Hals und Kopf, ward eine Henne getragen,", "tokens": ["Oh\u00b7ne", "Hals", "und", "Kopf", ",", "ward", "ei\u00b7ne", "Hen\u00b7ne", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.4": {"text": "Kratzfu\u00df war es, die beste der eierlegenden Hennen.", "tokens": ["Kratz\u00b7fu\u00df", "war", "es", ",", "die", "bes\u00b7te", "der", "ei\u00b7er\u00b7le\u00b7gen\u00b7den", "Hen\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "ART", "ADJA", "ART", "ADJA", "NN", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Ach, es flo\u00df ihr Blut, und Reineke hatt es vergossen!", "tokens": ["Ach", ",", "es", "flo\u00df", "ihr", "Blut", ",", "und", "Rei\u00b7ne\u00b7ke", "hatt", "es", "ver\u00b7gos\u00b7sen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "NN", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.6": {"text": "Jetzo sollt es der K\u00f6nig erfahren. Als Henning, der wackre,", "tokens": ["Jet\u00b7zo", "sollt", "es", "der", "K\u00f6\u00b7nig", "er\u00b7fah\u00b7ren", ".", "Als", "Hen\u00b7ning", ",", "der", "wack\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$.", "KOUS", "NE", "$,", "PRELS", "VVFIN", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.7": {"text": "Vor dem K\u00f6nig erschien, mit h\u00f6chstbetr\u00fcbter Geb\u00e4rde,", "tokens": ["Vor", "dem", "K\u00f6\u00b7nig", "er\u00b7schien", ",", "mit", "h\u00f6chst\u00b7be\u00b7tr\u00fcb\u00b7ter", "Ge\u00b7b\u00e4r\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.8": {"text": "Kamen mit ihm zwei H\u00e4hne, die gleichfalls trauerten. Kreyant", "tokens": ["Ka\u00b7men", "mit", "ihm", "zwei", "H\u00e4h\u00b7ne", ",", "die", "gleich\u00b7falls", "trau\u00b7er\u00b7ten", ".", "Krey\u00b7ant"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["NN", "APPR", "PPER", "CARD", "NN", "$,", "PRELS", "ADV", "VVFIN", "$.", "NN"], "meter": "+-+--+--+-+---+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Hie\u00df der eine, kein besserer Hahn war irgend zu finden", "tokens": ["Hie\u00df", "der", "ei\u00b7ne", ",", "kein", "bes\u00b7se\u00b7rer", "Hahn", "war", "ir\u00b7gend", "zu", "fin\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ART", "$,", "PIAT", "ADJA", "NN", "VAFIN", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+---+-+--+-", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Zwischen Holland und Frankreich; der andere durft ihm zur Seite", "tokens": ["Zwi\u00b7schen", "Hol\u00b7land", "und", "Fran\u00b7kreich", ";", "der", "an\u00b7de\u00b7re", "durft", "ihm", "zur", "Sei\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "NE", "$.", "ART", "ADJA", "VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.11": {"text": "Stehen, Kantart genannt, ein stracker, k\u00fchner Geselle;", "tokens": ["Ste\u00b7hen", ",", "Kan\u00b7tart", "ge\u00b7nannt", ",", "ein", "stra\u00b7cker", ",", "k\u00fch\u00b7ner", "Ge\u00b7sel\u00b7le", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VVPP", "$,", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.12": {"text": "Beide trugen ein brennendes Licht: sie waren die Br\u00fcder", "tokens": ["Bei\u00b7de", "tru\u00b7gen", "ein", "bren\u00b7nen\u00b7des", "Licht", ":", "sie", "wa\u00b7ren", "die", "Br\u00fc\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "$.", "PPER", "VAFIN", "ART", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.13": {"text": "Der ermordeten Frau. Sie riefen \u00fcber den M\u00f6rder", "tokens": ["Der", "er\u00b7mor\u00b7de\u00b7ten", "Frau", ".", "Sie", "rie\u00b7fen", "\u00fc\u00b7ber", "den", "M\u00f6r\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.14": {"text": "Ach und Weh! Es trugen die Bahr zwei j\u00fcngere H\u00e4hne,", "tokens": ["Ach", "und", "Weh", "!", "Es", "tru\u00b7gen", "die", "Bahr", "zwei", "j\u00fcn\u00b7ge\u00b7re", "H\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KON", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "CARD", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.15": {"text": "Und man konnte von fern die Jammerklage vernehmen.", "tokens": ["Und", "man", "konn\u00b7te", "von", "fern", "die", "Jam\u00b7mer\u00b7kla\u00b7ge", "ver\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "APPR", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.16": {"text": "Henning sprach: \u00bbWir klagen den unersetzlichen Schaden,", "tokens": ["Hen\u00b7ning", "sprach", ":", "\u00bb", "Wir", "kla\u00b7gen", "den", "un\u00b7er\u00b7setz\u00b7li\u00b7chen", "Scha\u00b7den", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.17": {"text": "Gn\u00e4digster Herr und K\u00f6nig! Erbarmt Euch, wie ich verletzt bin,", "tokens": ["Gn\u00e4\u00b7digs\u00b7ter", "Herr", "und", "K\u00f6\u00b7nig", "!", "Er\u00b7barmt", "Euch", ",", "wie", "ich", "ver\u00b7letzt", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$.", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+--+-++-+-", "measure": "iambic.septa.relaxed"}, "line.18": {"text": "Meine Kinder und ich. Hier seht Ihr Reinekens Werke!", "tokens": ["Mei\u00b7ne", "Kin\u00b7der", "und", "ich", ".", "Hier", "seht", "Ihr", "Rei\u00b7ne\u00b7kens", "Wer\u00b7ke", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPER", "$.", "ADV", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.19": {"text": "Als der Winter vorbei und Laub und Blumen und Bl\u00fcten", "tokens": ["Als", "der", "Win\u00b7ter", "vor\u00b7bei", "und", "Laub", "und", "Blu\u00b7men", "und", "Bl\u00fc\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PTKVZ", "KON", "NN", "KON", "NN", "KON", "NN"], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Uns zur Fr\u00f6hlichkeit riefen, erfreut ich mich meines Geschlechtes,", "tokens": ["Uns", "zur", "Fr\u00f6h\u00b7lich\u00b7keit", "rie\u00b7fen", ",", "er\u00b7freut", "ich", "mich", "mei\u00b7nes", "Ge\u00b7schlech\u00b7tes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "PRF", "PPOSAT", "NN", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.21": {"text": "Zehen junge S\u00f6hne, mit vierzehn T\u00f6chtern, sie waren", "tokens": ["Ze\u00b7hen", "jun\u00b7ge", "S\u00f6h\u00b7ne", ",", "mit", "vier\u00b7zehn", "T\u00f6ch\u00b7tern", ",", "sie", "wa\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["CARD", "ADJA", "NN", "$,", "APPR", "CARD", "NN", "$,", "PPER", "VAFIN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.22": {"text": "Voller Lust zu leben; mein Weib, die treffliche Henne,", "tokens": ["Vol\u00b7ler", "Lust", "zu", "le\u00b7ben", ";", "mein", "Weib", ",", "die", "treff\u00b7li\u00b7che", "Hen\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKZU", "VVINF", "$.", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.23": {"text": "Hatte sie alle zusammen in ", "tokens": ["Hat\u00b7te", "sie", "al\u00b7le", "zu\u00b7sam\u00b7men", "in"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PIS", "ADV", "APPR"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.24": {"text": "Alle waren so stark und wohl zufrieden, sie fanden", "tokens": ["Al\u00b7le", "wa\u00b7ren", "so", "stark", "und", "wohl", "zu\u00b7frie\u00b7den", ",", "sie", "fan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "KON", "ADV", "ADJD", "$,", "PPER", "VVFIN"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.25": {"text": "Ihre t\u00e4gliche Nahrung an wohlgesicherter St\u00e4tte.", "tokens": ["Ih\u00b7re", "t\u00e4g\u00b7li\u00b7che", "Nah\u00b7rung", "an", "wohl\u00b7ge\u00b7si\u00b7cher\u00b7ter", "St\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.26": {"text": "Reichen M\u00f6nchen geh\u00f6rte der Hof, uns schirmte die Mauer,", "tokens": ["Rei\u00b7chen", "M\u00f6n\u00b7chen", "ge\u00b7h\u00f6r\u00b7te", "der", "Hof", ",", "uns", "schirm\u00b7te", "die", "Mau\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.27": {"text": "Und sechs gro\u00dfe Hunde, die wackern Genossen des Hauses,", "tokens": ["Und", "sechs", "gro\u00b7\u00dfe", "Hun\u00b7de", ",", "die", "wa\u00b7ckern", "Ge\u00b7nos\u00b7sen", "des", "Hau\u00b7ses", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "Liebten meine Kinder und wachten \u00fcber ihr Leben;", "tokens": ["Lieb\u00b7ten", "mei\u00b7ne", "Kin\u00b7der", "und", "wach\u00b7ten", "\u00fc\u00b7ber", "ihr", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.29": {"text": "Reineken aber, den Dieb, verdro\u00df es, da\u00df wir in Frieden", "tokens": ["Rei\u00b7ne\u00b7ken", "a\u00b7ber", ",", "den", "Dieb", ",", "ver\u00b7dro\u00df", "es", ",", "da\u00df", "wir", "in", "Frie\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADV", "$,", "ART", "NN", "$,", "VVFIN", "PPER", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "+--+--+-+--+-+-", "measure": "dactylic.di.plus"}, "line.30": {"text": "Gl\u00fcckliche Tage verlebten und seine R\u00e4nke vermieden.", "tokens": ["Gl\u00fcck\u00b7li\u00b7che", "Ta\u00b7ge", "ver\u00b7leb\u00b7ten", "und", "sei\u00b7ne", "R\u00e4n\u00b7ke", "ver\u00b7mie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.31": {"text": "Immer schlich er bei Nacht um die Mauer und lauschte beim Tore;", "tokens": ["Im\u00b7mer", "schlich", "er", "bei", "Nacht", "um", "die", "Mau\u00b7er", "und", "lauschte", "beim", "To\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPR", "NN", "APPR", "ART", "NN", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "--+--+--+--+-+-", "measure": "anapaest.tetra.plus"}, "line.32": {"text": "Aber die Hunde bemerkten's; da mocht er laufen! Sie fa\u00dften", "tokens": ["A\u00b7ber", "die", "Hun\u00b7de", "be\u00b7merk\u00b7ten's", ";", "da", "mocht", "er", "lau\u00b7fen", "!", "Sie", "fa\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "VVINF", "$.", "PPER", "VVFIN"], "meter": "+--+---+-+-+--+-", "measure": "dactylic.di.plus"}, "line.33": {"text": "Wacker ihn endlich einmal und ruckten das Fell ihm zusammen;", "tokens": ["Wa\u00b7cker", "ihn", "end\u00b7lich", "ein\u00b7mal", "und", "ruck\u00b7ten", "das", "Fell", "ihm", "zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "KON", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.34": {"text": "Doch er rettete sich und lie\u00df uns ein Weilchen in Ruhe.", "tokens": ["Doch", "er", "ret\u00b7te\u00b7te", "sich", "und", "lie\u00df", "uns", "ein", "Weil\u00b7chen", "in", "Ru\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "KON", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "Aber nun h\u00f6ret mich an! Es w\u00e4hrte nicht lange, so kam er", "tokens": ["A\u00b7ber", "nun", "h\u00f6\u00b7ret", "mich", "an", "!", "Es", "w\u00e4hr\u00b7te", "nicht", "lan\u00b7ge", ",", "so", "kam", "er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "PTKNEG", "ADV", "$,", "ADV", "VVFIN", "PPER"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.36": {"text": "Als ein Klausner und brachte mir Brief und Siegel. Ich kannt es:", "tokens": ["Als", "ein", "Klaus\u00b7ner", "und", "brach\u00b7te", "mir", "Brief", "und", "Sie\u00b7gel", ".", "Ich", "kannt", "es", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "VVFIN", "PPER", "NN", "KON", "NN", "$.", "PPER", "VVFIN", "PPER", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.37": {"text": "Euer Siegel sah ich am Briefe; da fand ich geschrieben,", "tokens": ["Eu\u00b7er", "Sie\u00b7gel", "sah", "ich", "am", "Brie\u00b7fe", ";", "da", "fand", "ich", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPRART", "NN", "$.", "ADV", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+---+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.38": {"text": "Da\u00df Ihr festen Frieden so Tieren als V\u00f6geln verk\u00fcndigt.", "tokens": ["Da\u00df", "Ihr", "fes\u00b7ten", "Frie\u00b7den", "so", "Tie\u00b7ren", "als", "V\u00f6\u00b7geln", "ver\u00b7k\u00fcn\u00b7digt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADV", "NN", "KOUS", "NN", "VVPP", "$."], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.39": {"text": "Und er zeigte mir an: er sei ein Klausner geworden,", "tokens": ["Und", "er", "zeig\u00b7te", "mir", "an", ":", "er", "sei", "ein", "Klaus\u00b7ner", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VAFIN", "ART", "NN", "VAPP", "$,"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.40": {"text": "Habe strenge Gel\u00fcbde getan, die S\u00fcnden zu b\u00fc\u00dfen,", "tokens": ["Ha\u00b7be", "stren\u00b7ge", "Ge\u00b7l\u00fcb\u00b7de", "ge\u00b7tan", ",", "die", "S\u00fcn\u00b7den", "zu", "b\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVPP", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.41": {"text": "Deren Schuld er leider bekenne. Da habe nun keiner", "tokens": ["De\u00b7ren", "Schuld", "er", "lei\u00b7der", "be\u00b7ken\u00b7ne", ".", "Da", "ha\u00b7be", "nun", "kei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "NN", "PPER", "ADV", "VVFIN", "$.", "ADV", "VAFIN", "ADV", "PIS"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.42": {"text": "Mehr vor ihm sich zu f\u00fcrchten. Er habe heilig gelobet,", "tokens": ["Mehr", "vor", "ihm", "sich", "zu", "f\u00fcrch\u00b7ten", ".", "Er", "ha\u00b7be", "hei\u00b7lig", "ge\u00b7lo\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PRF", "PTKZU", "VVINF", "$.", "PPER", "VAFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.43": {"text": "Nimmermehr Fleisch zu genie\u00dfen. Er lie\u00df mich die Kutte beschauen,", "tokens": ["Nim\u00b7mer\u00b7mehr", "Fleisch", "zu", "ge\u00b7nie\u00b7\u00dfen", ".", "Er", "lie\u00df", "mich", "die", "Kut\u00b7te", "be\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PTKZU", "VVINF", "$.", "PPER", "VVFIN", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.44": {"text": "Zeigte sein Skapulier. Daneben wies er ein Zeugnis,", "tokens": ["Zeig\u00b7te", "sein", "Ska\u00b7pu\u00b7lier", ".", "Da\u00b7ne\u00b7ben", "wies", "er", "ein", "Zeug\u00b7nis", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$.", "PAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.45": {"text": "Das ihm der Prior gestellt, und, um mich sicher zu machen,", "tokens": ["Das", "ihm", "der", "Pri\u00b7or", "ge\u00b7stellt", ",", "und", ",", "um", "mich", "si\u00b7cher", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVPP", "$,", "KON", "$,", "KOUI", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.46": {"text": "Unter der Kutte ein h\u00e4renes Kleid. Dann ging er und sagte:", "tokens": ["Un\u00b7ter", "der", "Kut\u00b7te", "ein", "h\u00e4\u00b7re\u00b7nes", "Kleid", ".", "Dann", "ging", "er", "und", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$.", "ADV", "VVFIN", "PPER", "KON", "VVFIN", "$."], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.47": {"text": "\u203agott dem Herren seid mir befohlen! ich habe noch vieles", "tokens": ["\u203a", "gott", "dem", "Her\u00b7ren", "seid", "mir", "be\u00b7foh\u00b7len", "!", "ich", "ha\u00b7be", "noch", "vie\u00b7les"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "NN", "ART", "NN", "VAFIN", "PPER", "VVPP", "$.", "PPER", "VAFIN", "ADV", "PIS"], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.48": {"text": "Heute zu tun! ich habe die Sext und die None zu lesen", "tokens": ["Heu\u00b7te", "zu", "tun", "!", "ich", "ha\u00b7be", "die", "Sext", "und", "die", "No\u00b7ne", "zu", "le\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PTKZU", "VVINF", "$.", "PPER", "VAFIN", "ART", "NN", "KON", "ART", "NN", "PTKZU", "VVINF"], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.49": {"text": "Und die Vesper dazu.\u2039 Er las im Gehen und dachte", "tokens": ["Und", "die", "Ves\u00b7per", "da\u00b7zu", ".", "\u2039", "Er", "las", "im", "Ge\u00b7hen", "und", "dach\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PTKVZ", "$.", "$(", "PPER", "VVFIN", "APPRART", "NN", "KON", "VVFIN"], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.50": {"text": "Vieles B\u00f6se sich aus, er sann auf unser Verderben.", "tokens": ["Vie\u00b7les", "B\u00f6\u00b7se", "sich", "aus", ",", "er", "sann", "auf", "un\u00b7ser", "Ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PRF", "PTKVZ", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.51": {"text": "Ich mit erheitertem Herzen erz\u00e4hlte geschwinde den Kindern", "tokens": ["Ich", "mit", "er\u00b7hei\u00b7ter\u00b7tem", "Her\u00b7zen", "er\u00b7z\u00e4hl\u00b7te", "ge\u00b7schwin\u00b7de", "den", "Kin\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ADJA", "NN", "VVFIN", "ADJA", "ART", "NN"], "meter": "-+-+--+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.52": {"text": "Eures Briefes fr\u00f6hliche Botschaft, es freuten sich alle.", "tokens": ["Eu\u00b7res", "Brie\u00b7fes", "fr\u00f6h\u00b7li\u00b7che", "Bot\u00b7schaft", ",", "es", "freu\u00b7ten", "sich", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,", "PPER", "VVFIN", "PRF", "PIS", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.53": {"text": "Da nun Reineke Klausner geworden, so hatten wir weiter", "tokens": ["Da", "nun", "Rei\u00b7ne\u00b7ke", "Klaus\u00b7ner", "ge\u00b7wor\u00b7den", ",", "so", "hat\u00b7ten", "wir", "wei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "NE", "NN", "VAPP", "$,", "ADV", "VAFIN", "PPER", "ADV"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.54": {"text": "Keine Sorge noch Furcht. Ich ging mit ihnen zusammen", "tokens": ["Kei\u00b7ne", "Sor\u00b7ge", "noch", "Furcht", ".", "Ich", "ging", "mit", "ih\u00b7nen", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "ADV", "NN", "$.", "PPER", "VVFIN", "APPR", "PPER", "PTKVZ"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.55": {"text": "Vor die Mauer hinaus, wir freuten uns alle der Freiheit.", "tokens": ["Vor", "die", "Mau\u00b7er", "hin\u00b7aus", ",", "wir", "freu\u00b7ten", "uns", "al\u00b7le", "der", "Frei\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APZR", "$,", "PPER", "VVFIN", "PPER", "PIS", "ART", "NN", "$."], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.56": {"text": "Hinterlistig; da sprang er hervor und verrannt uns die Pforte;", "tokens": ["Hin\u00b7ter\u00b7lis\u00b7tig", ";", "da", "sprang", "er", "her\u00b7vor", "und", "ver\u00b7rannt", "uns", "die", "Pfor\u00b7te", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.57": {"text": "Meiner S\u00f6hne sch\u00f6nsten ergriff er und schleppt' ihn von dannen,", "tokens": ["Mei\u00b7ner", "S\u00f6h\u00b7ne", "sch\u00f6ns\u00b7ten", "er\u00b7griff", "er", "und", "schleppt'", "ihn", "von", "dan\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "APPR", "ADV", "$,"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.58": {"text": "Und nun war kein Rat, nachdem er sie einmal gekostet;", "tokens": ["Und", "nun", "war", "kein", "Rat", ",", "nach\u00b7dem", "er", "sie", "ein\u00b7mal", "ge\u00b7kos\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIAT", "NN", "$,", "KOUS", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "--+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.59": {"text": "Immer versucht' er es wieder; und weder J\u00e4ger noch Hunde", "tokens": ["Im\u00b7mer", "ver\u00b7sucht'", "er", "es", "wie\u00b7der", ";", "und", "we\u00b7der", "J\u00e4\u00b7ger", "noch", "Hun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "$.", "KON", "KON", "NN", "ADV", "NN"], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.60": {"text": "Konnten vor seinen R\u00e4nken bei Tag und Nacht uns bewahren.", "tokens": ["Konn\u00b7ten", "vor", "sei\u00b7nen", "R\u00e4n\u00b7ken", "bei", "Tag", "und", "Nacht", "uns", "be\u00b7wah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "PPER", "VVINF", "$."], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.61": {"text": "So entri\u00df er mir nun fast alle Kinder; von zwanzig", "tokens": ["So", "ent\u00b7ri\u00df", "er", "mir", "nun", "fast", "al\u00b7le", "Kin\u00b7der", ";", "von", "zwan\u00b7zig"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ADV", "PIAT", "NN", "$.", "APPR", "CARD"], "meter": "--+---+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.62": {"text": "Bin ich auf f\u00fcnfe gebracht, die andern raubt' er mir alle.", "tokens": ["Bin", "ich", "auf", "f\u00fcn\u00b7fe", "ge\u00b7bracht", ",", "die", "an\u00b7dern", "raubt'", "er", "mir", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "CARD", "VVPP", "$,", "PRELS", "PIS", "VVFIN", "PPER", "PPER", "PIS", "$."], "meter": "+-++--+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.63": {"text": "Oh, erbarmt Euch des bittern Schmerzes! Er t\u00f6tete gestern", "tokens": ["Oh", ",", "er\u00b7barmt", "Euch", "des", "bit\u00b7tern", "Schmer\u00b7zes", "!", "Er", "t\u00f6\u00b7te\u00b7te", "ge\u00b7stern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "ADV"], "meter": "+-+--+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.64": {"text": "Meine Tochter, es haben die Hunde den Leichnam gerettet.", "tokens": ["Mei\u00b7ne", "Toch\u00b7ter", ",", "es", "ha\u00b7ben", "die", "Hun\u00b7de", "den", "Leich\u00b7nam", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.65": {"text": "Seht, hier liegt sie! Er hat es getan, oh! nehmt es zu Herzen!\u00ab", "tokens": ["Seht", ",", "hier", "liegt", "sie", "!", "Er", "hat", "es", "ge\u00b7tan", ",", "oh", "!", "nehmt", "es", "zu", "Her\u00b7zen", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$,", "ADV", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "PPER", "VVPP", "$,", "FM", "$.", "VVFIN", "PPER", "APPR", "NN", "$.", "$("], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}}, "stanza.9": {"line.1": {"text": "Und der K\u00f6nig begann: \u00bbKommt n\u00e4her, Grimbart, und sehet,", "tokens": ["Und", "der", "K\u00f6\u00b7nig", "be\u00b7gann", ":", "\u00bb", "Kommt", "n\u00e4\u00b7her", ",", "Grim\u00b7bart", ",", "und", "se\u00b7het", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$.", "$(", "VVIMP", "ADJD", "$,", "NE", "$,", "KON", "VVFIN", "$,"], "meter": "--+--+-+-++-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Also fastet der Klausner, und so beweist er die Bu\u00dfe!", "tokens": ["Al\u00b7so", "fas\u00b7tet", "der", "Klaus\u00b7ner", ",", "und", "so", "be\u00b7weist", "er", "die", "Bu\u00b7\u00dfe", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KON", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Leb ich noch aber ein Jahr, so soll es ihn wahrlich gereuen!", "tokens": ["Leb", "ich", "noch", "a\u00b7ber", "ein", "Jahr", ",", "so", "soll", "es", "ihn", "wahr\u00b7lich", "ge\u00b7reu\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "ART", "NN", "$,", "ADV", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Doch was helfen die Worte! Vernehmet, trauriger Henning:", "tokens": ["Doch", "was", "hel\u00b7fen", "die", "Wor\u00b7te", "!", "Ver\u00b7neh\u00b7met", ",", "trau\u00b7ri\u00b7ger", "Hen\u00b7ning", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ART", "NN", "$.", "VVFIN", "$,", "ADJA", "NN", "$."], "meter": "+-+--+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Eurer Tochter ermangl' es an nichts, was irgend den Toten", "tokens": ["Eu\u00b7rer", "Toch\u00b7ter", "er\u00b7mangl'", "es", "an", "nichts", ",", "was", "ir\u00b7gend", "den", "To\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "PIS", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.6": {"text": "Nur zu Rechte geschieht. Ich la\u00df ihr Vigilie singen,", "tokens": ["Nur", "zu", "Rech\u00b7te", "ge\u00b7schieht", ".", "Ich", "la\u00df", "ihr", "Vi\u00b7gi\u00b7lie", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Sie mit gro\u00dfer Ehre zur Erde bestatten; dann wollen", "tokens": ["Sie", "mit", "gro\u00b7\u00dfer", "Eh\u00b7re", "zur", "Er\u00b7de", "be\u00b7stat\u00b7ten", ";", "dann", "wol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "APPR", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$.", "ADV", "VMFIN"], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Wir mit diesen Herren des Mordes Strafe bedenken.\u00ab", "tokens": ["Wir", "mit", "die\u00b7sen", "Her\u00b7ren", "des", "Mor\u00b7des", "Stra\u00b7fe", "be\u00b7den\u00b7ken", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "APPR", "PDAT", "NN", "ART", "NN", "NN", "VVINF", "$.", "$("], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Da gebot der K\u00f6nig, man solle Vigilie singen.", "tokens": ["Da", "ge\u00b7bot", "der", "K\u00f6\u00b7nig", ",", "man", "sol\u00b7le", "Vi\u00b7gi\u00b7lie", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "PIS", "PIAT", "NN", "VVINF", "$."], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Domino placebo begann die Gemeine, sie sangen", "tokens": ["Do\u00b7mi\u00b7no", "pla\u00b7ce\u00b7bo", "be\u00b7gann", "die", "Ge\u00b7mei\u00b7ne", ",", "sie", "san\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "NE", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN"], "meter": "+--+-+-+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Alle Verse davon. Ich k\u00f6nnte ferner erz\u00e4hlen,", "tokens": ["Al\u00b7le", "Ver\u00b7se", "da\u00b7von", ".", "Ich", "k\u00f6nn\u00b7te", "fer\u00b7ner", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKVZ", "$.", "PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.4": {"text": "Wer die Lektion gesungen und wer die Responsen;", "tokens": ["Wer", "die", "Lek\u00b7ti\u00b7on", "ge\u00b7sun\u00b7gen", "und", "wer", "die", "Res\u00b7pon\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVPP", "KON", "PWS", "ART", "NN", "$."], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}, "line.5": {"text": "Aber es w\u00e4hrte zu lang, ich la\u00df es lieber bewenden.", "tokens": ["A\u00b7ber", "es", "w\u00e4hr\u00b7te", "zu", "lang", ",", "ich", "la\u00df", "es", "lie\u00b7ber", "be\u00b7wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKA", "ADJD", "$,", "PPER", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.6": {"text": "In ein Grab ward die Leiche gelegt und dr\u00fcber ein sch\u00f6ner", "tokens": ["In", "ein", "Grab", "ward", "die", "Lei\u00b7che", "ge\u00b7legt", "und", "dr\u00fc\u00b7ber", "ein", "sch\u00f6\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "NN", "VVPP", "KON", "PAV", "ART", "ADJA"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.7": {"text": "Marmorstein, poliert wie ein Glas, gehauen im Viereck,", "tokens": ["Mar\u00b7mor\u00b7stein", ",", "po\u00b7liert", "wie", "ein", "Glas", ",", "ge\u00b7hau\u00b7en", "im", "Vier\u00b7eck", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "KOKOM", "ART", "NN", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.8": {"text": "Gro\u00df und dick, und oben darauf war deutlich zu lesen:", "tokens": ["Gro\u00df", "und", "dick", ",", "und", "o\u00b7ben", "da\u00b7rauf", "war", "deut\u00b7lich", "zu", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$,", "KON", "ADV", "PAV", "VAFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.9": {"text": "\u00bbkratzefu\u00df, Tochter Hennings des Hahns, die beste der Hennen,", "tokens": ["\u00bb", "krat\u00b7ze\u00b7fu\u00df", ",", "Toch\u00b7ter", "Hen\u00b7nings", "des", "Hahns", ",", "die", "bes\u00b7te", "der", "Hen\u00b7nen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "NN", "NE", "ART", "NN", "$,", "ART", "ADJA", "ART", "NN", "$,"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.10": {"text": "Legte viel Eier ins Nest und wu\u00dfte kl\u00fcglich zu scharren.", "tokens": ["Leg\u00b7te", "viel", "Ei\u00b7er", "ins", "Nest", "und", "wu\u00df\u00b7te", "kl\u00fcg\u00b7lich", "zu", "schar\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPRART", "NN", "KON", "VVFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.11": {"text": "Ach, hier liegt sie! durch Reinekens Mord den Ihren genommen.", "tokens": ["Ach", ",", "hier", "liegt", "sie", "!", "durch", "Rei\u00b7ne\u00b7kens", "Mord", "den", "Ih\u00b7ren", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PPER", "$.", "APPR", "NN", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.12": {"text": "Alle Welt soll erfahren, wie b\u00f6s und falsch er gehandelt,", "tokens": ["Al\u00b7le", "Welt", "soll", "er\u00b7fah\u00b7ren", ",", "wie", "b\u00f6s", "und", "falsch", "er", "ge\u00b7han\u00b7delt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "VVINF", "$,", "PWAV", "ADJD", "KON", "ADJD", "PPER", "VVPP", "$,"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.13": {"text": "Und die Tote beklagen.\u00ab So lautete, was man geschrieben.", "tokens": ["Und", "die", "To\u00b7te", "be\u00b7kla\u00b7gen", ".", "\u00ab", "So", "lau\u00b7te\u00b7te", ",", "was", "man", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$.", "$(", "ADV", "VVFIN", "$,", "PRELS", "PIS", "VVPP", "$."], "meter": "--+--+--+-+-+-+-", "measure": "anapaest.tri.plus"}, "line.14": {"text": "Rat mit ihnen zu halten, wie er den Frevel bestrafte,", "tokens": ["Rat", "mit", "ih\u00b7nen", "zu", "hal\u00b7ten", ",", "wie", "er", "den", "Fre\u00b7vel", "be\u00b7straf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PTKZU", "VVINF", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.15": {"text": "Der so kl\u00e4rlich vor ihn und seine Herren gebracht war.", "tokens": ["Der", "so", "kl\u00e4r\u00b7lich", "vor", "ihn", "und", "sei\u00b7ne", "Her\u00b7ren", "ge\u00b7bracht", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "APPR", "PPER", "KON", "PPOSAT", "NN", "VVPP", "VAFIN", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.16": {"text": "Und sie rieten zuletzt: man habe dem listigen Frevler", "tokens": ["Und", "sie", "rie\u00b7ten", "zu\u00b7letzt", ":", "man", "ha\u00b7be", "dem", "lis\u00b7ti\u00b7gen", "Frev\u00b7ler"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$.", "PIS", "VAFIN", "ART", "ADJA", "NN"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.17": {"text": "Einen Boten zu senden, da\u00df er um Liebes und Leides", "tokens": ["Ei\u00b7nen", "Bo\u00b7ten", "zu", "sen\u00b7den", ",", "da\u00df", "er", "um", "Lie\u00b7bes", "und", "Lei\u00b7des"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "KOUS", "PPER", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.18": {"text": "Nicht sich entz\u00f6ge, er solle sich stellen am Hofe des K\u00f6nigs", "tokens": ["Nicht", "sich", "ent\u00b7z\u00f6\u00b7ge", ",", "er", "sol\u00b7le", "sich", "stel\u00b7len", "am", "Ho\u00b7fe", "des", "K\u00f6\u00b7nigs"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "PRF", "VVFIN", "$,", "PPER", "VMFIN", "PRF", "VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.19": {"text": "An dem Tage der Herrn, wenn sie zun\u00e4chst sich versammeln;", "tokens": ["An", "dem", "Ta\u00b7ge", "der", "Herrn", ",", "wenn", "sie", "zu\u00b7n\u00e4chst", "sich", "ver\u00b7sam\u00b7meln", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "KOUS", "PPER", "ADV", "PRF", "VVINF", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.20": {"text": "Braun, den B\u00e4ren, ernannte man aber zum Boten. Der K\u00f6nig", "tokens": ["Braun", ",", "den", "B\u00e4\u00b7ren", ",", "er\u00b7nann\u00b7te", "man", "a\u00b7ber", "zum", "Bo\u00b7ten", ".", "Der", "K\u00f6\u00b7nig"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "$,", "ART", "NN", "$,", "VVFIN", "PIS", "ADV", "APPRART", "NN", "$.", "ART", "NN"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.21": {"text": "Sprach zu Braun, dem B\u00e4ren: \u00bbIch sag es, Euer Gebieter,", "tokens": ["Sprach", "zu", "Braun", ",", "dem", "B\u00e4\u00b7ren", ":", "\u00bb", "Ich", "sag", "es", ",", "Eu\u00b7er", "Ge\u00b7bie\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$,", "ART", "NN", "$.", "$(", "PPER", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.22": {"text": "Da\u00df Ihr mit Flei\u00df die Botschaft verrichtet! Doch rat ich zur Vorsicht:", "tokens": ["Da\u00df", "Ihr", "mit", "Flei\u00df", "die", "Bot\u00b7schaft", "ver\u00b7rich\u00b7tet", "!", "Doch", "rat", "ich", "zur", "Vor\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ART", "NN", "VVPP", "$.", "KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "---+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Denn es ist Reineke falsch und boshaft, allerlei Listen", "tokens": ["Denn", "es", "ist", "Rei\u00b7ne\u00b7ke", "falsch", "und", "bos\u00b7haft", ",", "al\u00b7ler\u00b7lei", "Lis\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "NN", "ADJD", "KON", "ADJD", "$,", "PIAT", "NN"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.24": {"text": "Wird er gebrauchen, er wird Euch schmeicheln, er wird Euch bel\u00fcgen,", "tokens": ["Wird", "er", "ge\u00b7brau\u00b7chen", ",", "er", "wird", "Euch", "schmei\u00b7cheln", ",", "er", "wird", "Euch", "be\u00b7l\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVINF", "$,", "PPER", "VAFIN", "PPER", "VVINF", "$,", "PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.25": {"text": "Hintergehen, wie er nur kann.\u00ab \u2013 \u00bbMitnichten\u00ab, versetzte", "tokens": ["Hin\u00b7ter\u00b7ge\u00b7hen", ",", "wie", "er", "nur", "kann", ".", "\u00ab", "\u2013", "\u00bb", "Mit\u00b7nich\u00b7ten", "\u00ab", ",", "ver\u00b7setz\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "word"], "pos": ["VVIZU", "$,", "PWAV", "PPER", "ADV", "VMFIN", "$.", "$(", "$(", "$(", "NN", "$(", "$,", "VVFIN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.26": {"text": "Zuversichtlich der B\u00e4r, \u00bbbleibt ruhig! Sollt er sich irgend", "tokens": ["Zu\u00b7ver\u00b7sicht\u00b7lich", "der", "B\u00e4r", ",", "\u00bb", "bleibt", "ru\u00b7hig", "!", "Sollt", "er", "sich", "ir\u00b7gend"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "$(", "VVFIN", "ADJD", "$.", "VMFIN", "PPER", "PRF", "ADV"], "meter": "+-+--++--+--+-", "measure": "trochaic.hexa.relaxed"}, "line.27": {"text": "Nur vermessen und mir zum Hohne das mindeste wagen,", "tokens": ["Nur", "ver\u00b7mes\u00b7sen", "und", "mir", "zum", "Hoh\u00b7ne", "das", "min\u00b7des\u00b7te", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "KON", "PPER", "APPRART", "NN", "ART", "ADJA", "VVINF", "$,"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.28": {"text": "Seht, ich schw\u00f6r es bei Gott! der m\u00f6ge mich strafen, wofern ich", "tokens": ["Seht", ",", "ich", "schw\u00f6r", "es", "bei", "Gott", "!", "der", "m\u00f6\u00b7ge", "mich", "stra\u00b7fen", ",", "wo\u00b7fern", "ich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "VVFIN", "PPER", "APPR", "NN", "$.", "ART", "VMFIN", "PPER", "VVFIN", "$,", "KOUS", "PPER"], "meter": "--+--+-+--+-+-+", "measure": "anapaest.di.plus"}, "line.29": {"text": "Ihm nicht grimmig verg\u00f6lte, da\u00df er zu bleiben nicht w\u00fc\u00dfte.\u00ab", "tokens": ["Ihm", "nicht", "grim\u00b7mig", "ver\u00b7g\u00f6l\u00b7te", ",", "da\u00df", "er", "zu", "blei\u00b7ben", "nicht", "w\u00fc\u00df\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PTKNEG", "ADJD", "VVFIN", "$,", "KOUS", "PPER", "PTKZU", "VVINF", "PTKNEG", "VVFIN", "$.", "$("], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}}, "stanza.11": {"line.1": {"text": "Pfingsten, das liebliche Fest, war gekommen; es gr\u00fcnten und bl\u00fchten", "tokens": ["Pfings\u00b7ten", ",", "das", "lieb\u00b7li\u00b7che", "Fest", ",", "war", "ge\u00b7kom\u00b7men", ";", "es", "gr\u00fcn\u00b7ten", "und", "bl\u00fch\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$,", "VAFIN", "VVPP", "$.", "PPER", "VVFIN", "KON", "VVFIN"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Feld und Wald; auf H\u00fcgeln und H\u00f6hn, in B\u00fcschen und Hecken", "tokens": ["Feld", "und", "Wald", ";", "auf", "H\u00fc\u00b7geln", "und", "H\u00f6hn", ",", "in", "B\u00fc\u00b7schen", "und", "He\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$.", "APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.3": {"text": "\u00dcbten ein fr\u00f6hliches Lied die neuermunterten V\u00f6gel;", "tokens": ["\u00dcb\u00b7ten", "ein", "fr\u00f6h\u00b7li\u00b7ches", "Lied", "die", "neu\u00b7er\u00b7mun\u00b7ter\u00b7ten", "V\u00f6\u00b7gel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.4": {"text": "Jede Wiese spro\u00dfte von Blumen in duftenden Gr\u00fcnden,", "tokens": ["Je\u00b7de", "Wie\u00b7se", "spro\u00df\u00b7te", "von", "Blu\u00b7men", "in", "duf\u00b7ten\u00b7den", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.5": {"text": "Festlich heiter gl\u00e4nzte der Himmel und farbig die Erde.", "tokens": ["Fest\u00b7lich", "hei\u00b7ter", "gl\u00e4nz\u00b7te", "der", "Him\u00b7mel", "und", "far\u00b7big", "die", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VVFIN", "ART", "NN", "KON", "ADJD", "ART", "NN", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}}, "stanza.12": {"line.1": {"text": "Nobel, der K\u00f6nig, versammelt den Hof; und seine Vasallen", "tokens": ["No\u00b7bel", ",", "der", "K\u00f6\u00b7nig", ",", "ver\u00b7sam\u00b7melt", "den", "Hof", ";", "und", "sei\u00b7ne", "Va\u00b7sal\u00b7len"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$.", "KON", "PPOSAT", "NN"], "meter": "+--+--+--+-+-+--", "measure": "elegiambus"}, "line.2": {"text": "Eilen gerufen herbei mit gro\u00dfem Gepr\u00e4nge; da kommen", "tokens": ["Ei\u00b7len", "ge\u00b7ru\u00b7fen", "her\u00b7bei", "mit", "gro\u00b7\u00dfem", "Ge\u00b7pr\u00e4n\u00b7ge", ";", "da", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVPP", "ADV", "APPR", "ADJA", "NN", "$.", "ADV", "VVINF"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Viele stolze Gesellen von allen Seiten und Enden,", "tokens": ["Vie\u00b7le", "stol\u00b7ze", "Ge\u00b7sel\u00b7len", "von", "al\u00b7len", "Sei\u00b7ten", "und", "En\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "L\u00fctke, der Kranich, und Markart, der H\u00e4her, und alle die Besten.", "tokens": ["L\u00fct\u00b7ke", ",", "der", "Kra\u00b7nich", ",", "und", "Mar\u00b7kart", ",", "der", "H\u00e4\u00b7her", ",", "und", "al\u00b7le", "die", "Bes\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "KON", "NE", "$,", "ART", "NN", "$,", "KON", "PIS", "ART", "NN", "$."], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.5": {"text": "Denn der K\u00f6nig gedenkt mit allen seinen Baronen", "tokens": ["Denn", "der", "K\u00f6\u00b7nig", "ge\u00b7denkt", "mit", "al\u00b7len", "sei\u00b7nen", "Ba\u00b7ro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Hof zu halten in Feier und Pracht; er l\u00e4\u00dft sie berufen", "tokens": ["Hof", "zu", "hal\u00b7ten", "in", "Fei\u00b7er", "und", "Pracht", ";", "er", "l\u00e4\u00dft", "sie", "be\u00b7ru\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKZU", "VVINF", "APPR", "NN", "KON", "NN", "$.", "PPER", "VVFIN", "PPER", "VVPP"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.7": {"text": "Alle miteinander, so gut die Gro\u00dfen als Kleinen.", "tokens": ["Al\u00b7le", "mi\u00b7tein\u00b7an\u00b7der", ",", "so", "gut", "die", "Gro\u00b7\u00dfen", "als", "Klei\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "$,", "ADV", "ADJD", "ART", "NN", "KOUS", "NN", "$."], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Niemand sollte fehlen! und dennoch fehlte der ", "tokens": ["Nie\u00b7mand", "soll\u00b7te", "feh\u00b7len", "!", "und", "den\u00b7noch", "fehl\u00b7te", "der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "VVINF", "$.", "KON", "ADV", "VVFIN", "ART"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Reineke Fuchs, der Schelm! der viel begangenen Frevels", "tokens": ["Rei\u00b7ne\u00b7ke", "Fuchs", ",", "der", "Schelm", "!", "der", "viel", "be\u00b7gan\u00b7ge\u00b7nen", "Fre\u00b7vels"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "ART", "NN", "$.", "ART", "PIAT", "ADJA", "NN"], "meter": "+--+-+-+-+-+-+", "measure": "iambic.septa.invert"}, "line.10": {"text": "Halben des Hofs sich enthielt. So scheuet das b\u00f6se Gewissen", "tokens": ["Hal\u00b7ben", "des", "Hofs", "sich", "ent\u00b7hielt", ".", "So", "scheu\u00b7et", "das", "b\u00f6\u00b7se", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "PRF", "VVFIN", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.11": {"text": "Licht und Tag, es scheute der Fuchs die versammelten Herren.", "tokens": ["Licht", "und", "Tag", ",", "es", "scheu\u00b7te", "der", "Fuchs", "die", "ver\u00b7sam\u00b7mel\u00b7ten", "Her\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "PPER", "VVFIN", "ART", "NE", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.12": {"text": "Alle hatten zu klagen, er hatte sie alle beleidigt,", "tokens": ["Al\u00b7le", "hat\u00b7ten", "zu", "kla\u00b7gen", ",", "er", "hat\u00b7te", "sie", "al\u00b7le", "be\u00b7lei\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PTKZU", "VVINF", "$,", "PPER", "VAFIN", "PPER", "PIS", "VVPP", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.13": {"text": "Und nur Grimbart, den Dachs, den Sohn des Bruders, verschont' er.", "tokens": ["Und", "nur", "Grim\u00b7bart", ",", "den", "Dachs", ",", "den", "Sohn", "des", "Bru\u00b7ders", ",", "ver\u00b7schont'", "er", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "Isegrim aber, der Wolf, begann die Klage; von allen", "tokens": ["I\u00b7seg\u00b7rim", "a\u00b7ber", ",", "der", "Wolf", ",", "be\u00b7gann", "die", "Kla\u00b7ge", ";", "von", "al\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADV", "$,", "ART", "NE", "$,", "VVFIN", "ART", "NN", "$.", "APPR", "PIAT"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Seinen Vettern und G\u00f6nnern, von allen Freunden begleitet,", "tokens": ["Sei\u00b7nen", "Vet\u00b7tern", "und", "G\u00f6n\u00b7nern", ",", "von", "al\u00b7len", "Freun\u00b7den", "be\u00b7glei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$,", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Trat er vor den K\u00f6nig und sprach die gerichtlichen Worte:", "tokens": ["Trat", "er", "vor", "den", "K\u00f6\u00b7nig", "und", "sprach", "die", "ge\u00b7richt\u00b7li\u00b7chen", "Wor\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.4": {"text": "\u00bbgn\u00e4digster K\u00f6nig und Herr! vernehmet meine Beschwerden.", "tokens": ["\u00bb", "gn\u00e4\u00b7digs\u00b7ter", "K\u00f6\u00b7nig", "und", "Herr", "!", "ver\u00b7neh\u00b7met", "mei\u00b7ne", "Be\u00b7schwer\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "KON", "NN", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Edel seid Ihr und gro\u00df und ehrenvoll, jedem erzeigt Ihr", "tokens": ["E\u00b7del", "seid", "Ihr", "und", "gro\u00df", "und", "eh\u00b7ren\u00b7voll", ",", "je\u00b7dem", "er\u00b7zeigt", "Ihr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "KON", "ADJD", "KON", "ADJD", "$,", "PIS", "VVFIN", "PPER"], "meter": "+-+--+-+--+-+++", "measure": "trochaic.octa.plus.relaxed"}, "line.6": {"text": "Recht und Gnade: so la\u00dft Euch denn auch des Schadens erbarmen,", "tokens": ["Recht", "und", "Gna\u00b7de", ":", "so", "la\u00dft", "Euch", "denn", "auch", "des", "Scha\u00b7dens", "er\u00b7bar\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.7": {"text": "Den ich von Reineke Fuchs mit gro\u00dfer Schande gelitten.", "tokens": ["Den", "ich", "von", "Rei\u00b7ne\u00b7ke", "Fuchs", "mit", "gro\u00b7\u00dfer", "Schan\u00b7de", "ge\u00b7lit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NE", "NE", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Aber vor allen Dingen erbarmt Euch, da\u00df er mein Weib so", "tokens": ["A\u00b7ber", "vor", "al\u00b7len", "Din\u00b7gen", "er\u00b7barmt", "Euch", ",", "da\u00df", "er", "mein", "Weib", "so"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PPOSAT", "NN", "ADV"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.9": {"text": "Ach! er hat sie mit Unrat besudelt, mit \u00e4tzendem Unflat,", "tokens": ["Ach", "!", "er", "hat", "sie", "mit", "Un\u00b7rat", "be\u00b7su\u00b7delt", ",", "mit", "\u00e4t\u00b7zen\u00b7dem", "Un\u00b7flat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PPER", "VAFIN", "PPER", "APPR", "NN", "VVPP", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.10": {"text": "Da\u00df mir zu Hause noch drei in bittrer Blindheit sich qu\u00e4len.", "tokens": ["Da\u00df", "mir", "zu", "Hau\u00b7se", "noch", "drei", "in", "bit\u00b7trer", "Blind\u00b7heit", "sich", "qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADV", "CARD", "APPR", "ADJA", "NN", "PRF", "VVINF", "$."], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Zwar ist alle der Frevel schon lange zur Sprache gekommen,", "tokens": ["Zwar", "ist", "al\u00b7le", "der", "Fre\u00b7vel", "schon", "lan\u00b7ge", "zur", "Spra\u00b7che", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ART", "NN", "ADV", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.12": {"text": "Ja, ein Tag war gesetzt, zu schlichten solche Beschwerden;", "tokens": ["Ja", ",", "ein", "Tag", "war", "ge\u00b7setzt", ",", "zu", "schlich\u00b7ten", "sol\u00b7che", "Be\u00b7schwer\u00b7den", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "VVPP", "$,", "PTKZU", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Er erbot sich zum Eide, doch bald besann er sich anders", "tokens": ["Er", "er\u00b7bot", "sich", "zum", "Ei\u00b7de", ",", "doch", "bald", "be\u00b7sann", "er", "sich", "an\u00b7ders"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPRART", "NN", "$,", "ADV", "ADV", "VVFIN", "PPER", "PRF", "ADV"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.14": {"text": "Und entwischte behend nach seiner Feste. Das wissen", "tokens": ["Und", "ent\u00b7wischte", "be\u00b7hend", "nach", "sei\u00b7ner", "Fes\u00b7te", ".", "Das", "wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "$.", "PDS", "VVINF"], "meter": "--+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Alle M\u00e4nner zu wohl, die hier und neben mir stehen.", "tokens": ["Al\u00b7le", "M\u00e4n\u00b7ner", "zu", "wohl", ",", "die", "hier", "und", "ne\u00b7ben", "mir", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ADV", "$,", "PRELS", "ADV", "KON", "APPR", "PPER", "VVFIN", "$."], "meter": "--+--+---+--+-", "measure": "anapaest.di.plus"}, "line.16": {"text": "Herr! ich k\u00f6nnte die Drangsal, die mir der Bube bereitet,", "tokens": ["Herr", "!", "ich", "k\u00f6nn\u00b7te", "die", "Dran\u00b7gsal", ",", "die", "mir", "der", "Bu\u00b7be", "be\u00b7rei\u00b7tet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VMFIN", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.17": {"text": "Nicht mit eilenden Worten in vielen Wochen erz\u00e4hlen.", "tokens": ["Nicht", "mit", "ei\u00b7len\u00b7den", "Wor\u00b7ten", "in", "vie\u00b7len", "Wo\u00b7chen", "er\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.18": {"text": "W\u00fcrde die Leinwand von Gent, so viel auch ihrer gemacht wird,", "tokens": ["W\u00fcr\u00b7de", "die", "Lein\u00b7wand", "von", "Gent", ",", "so", "viel", "auch", "ih\u00b7rer", "ge\u00b7macht", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "NN", "$,", "ADV", "ADV", "ADV", "PPOSAT", "VVPP", "VAFIN", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.19": {"text": "Alle zu Pergament, sie fa\u00dfte die Streiche nicht alle,", "tokens": ["Al\u00b7le", "zu", "Per\u00b7ga\u00b7ment", ",", "sie", "fa\u00df\u00b7te", "die", "Strei\u00b7che", "nicht", "al\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "PTKNEG", "PIS", "$,"], "meter": "+--+-+-+--+--+-", "measure": "hexameter"}, "line.20": {"text": "Und ich schweige davon. Doch meines Weibes Entehrung", "tokens": ["Und", "ich", "schwei\u00b7ge", "da\u00b7von", ".", "Doch", "mei\u00b7nes", "Wei\u00b7bes", "E\u00b7nteh\u00b7rung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PAV", "$.", "KON", "PPOSAT", "NN", "NN"], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Fri\u00dft mir das Herz; ich r\u00e4che sie auch, es werde, was wolle.\u00ab", "tokens": ["Fri\u00dft", "mir", "das", "Herz", ";", "ich", "r\u00e4\u00b7che", "sie", "auch", ",", "es", "wer\u00b7de", ",", "was", "wol\u00b7le", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "VAFIN", "$,", "PWS", "VMFIN", "$.", "$("], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}}, "stanza.14": {"line.1": {"text": "Als nun Isegrim so mit traurigem Mute gesprochen,", "tokens": ["Als", "nun", "I\u00b7seg\u00b7rim", "so", "mit", "trau\u00b7ri\u00b7gem", "Mu\u00b7te", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.2": {"text": "Trat ein H\u00fcndchen hervor, hie\u00df Wackerlos, redte franz\u00f6sisch", "tokens": ["Trat", "ein", "H\u00fcnd\u00b7chen", "her\u00b7vor", ",", "hie\u00df", "Wa\u00b7cker\u00b7los", ",", "red\u00b7te", "fran\u00b7z\u00f6\u00b7sisch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,", "VVFIN", "NN", "$,", "VVFIN", "ADJD"], "meter": "+-+--+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Vor dem K\u00f6nig: wie arm es gewesen und nichts ihm geblieben", "tokens": ["Vor", "dem", "K\u00f6\u00b7nig", ":", "wie", "arm", "es", "ge\u00b7we\u00b7sen", "und", "nichts", "ihm", "ge\u00b7blie\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "PWAV", "ADJD", "PPER", "VAPP", "KON", "PIS", "PPER", "VVPP"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Als ein St\u00fcckchen Wurst in einem Wintergeb\u00fcsche;", "tokens": ["Als", "ein", "St\u00fcck\u00b7chen", "Wurst", "in", "ei\u00b7nem", "Win\u00b7ter\u00b7ge\u00b7b\u00fc\u00b7sche", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Reineke hab auch das ihm genommen! Jetzt sprang auch der Kater", "tokens": ["Rei\u00b7ne\u00b7ke", "hab", "auch", "das", "ihm", "ge\u00b7nom\u00b7men", "!", "Jetzt", "sprang", "auch", "der", "Ka\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ADV", "ART", "PPER", "VVPP", "$.", "ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-+--+--+-", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Hinze zornig hervor und sprach: \u00bbErhabner Gebieter,", "tokens": ["Hin\u00b7ze", "zor\u00b7nig", "her\u00b7vor", "und", "sprach", ":", "\u00bb", "Er\u00b7hab\u00b7ner", "Ge\u00b7bie\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKVZ", "KON", "VVFIN", "$.", "$(", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.7": {"text": "Niemand beschwere sich mehr, da\u00df ihm der B\u00f6sewicht schade,", "tokens": ["Nie\u00b7mand", "be\u00b7schwe\u00b7re", "sich", "mehr", ",", "da\u00df", "ihm", "der", "B\u00f6\u00b7se\u00b7wicht", "scha\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.8": {"text": "Denn der K\u00f6nig allein! Ich sag Euch, in dieser Gesellschaft", "tokens": ["Denn", "der", "K\u00f6\u00b7nig", "al\u00b7lein", "!", "Ich", "sag", "Euch", ",", "in", "die\u00b7ser", "Ge\u00b7sell\u00b7schaft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "$.", "PPER", "VVFIN", "PPER", "$,", "APPR", "PDAT", "NN"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.9": {"text": "Ist hier niemand, jung oder alt, er f\u00fcrchtet den Frevler", "tokens": ["Ist", "hier", "nie\u00b7mand", ",", "jung", "o\u00b7der", "alt", ",", "er", "f\u00fcrch\u00b7tet", "den", "Frev\u00b7ler"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIS", "$,", "ADJD", "KON", "ADJD", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.10": {"text": "Mehr als Euch! Doch Wackerlos' Klage will wenig bedeuten,", "tokens": ["Mehr", "als", "Euch", "!", "Doch", "Wa\u00b7cke\u00b7rlos'", "Kla\u00b7ge", "will", "we\u00b7nig", "be\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "PPER", "$.", "KON", "NN", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.11": {"text": "Schon sind Jahre vorbei, seit diese H\u00e4ndel geschehen;", "tokens": ["Schon", "sind", "Jah\u00b7re", "vor\u00b7bei", ",", "seit", "die\u00b7se", "H\u00e4n\u00b7del", "ge\u00b7sche\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "PTKVZ", "$,", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "Mir geh\u00f6rte die Wurst! ich sollte mich damals beschweren.", "tokens": ["Mir", "ge\u00b7h\u00f6r\u00b7te", "die", "Wurst", "!", "ich", "soll\u00b7te", "mich", "da\u00b7mals", "be\u00b7schwe\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+--+-+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.13": {"text": "Jagen war ich gegangen: auf meinem Wege durchsucht ich", "tokens": ["Ja\u00b7gen", "war", "ich", "ge\u00b7gan\u00b7gen", ":", "auf", "mei\u00b7nem", "We\u00b7ge", "durch\u00b7sucht", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "VVPP", "$.", "APPR", "PPOSAT", "NN", "VVFIN", "PPER"], "meter": "+-+--+--+-+-+++", "measure": "trochaic.octa.plus.relaxed"}, "line.14": {"text": "Eine M\u00fchle zu Nacht; es schlief die M\u00fcllerin; sachte", "tokens": ["Ei\u00b7ne", "M\u00fch\u00b7le", "zu", "Nacht", ";", "es", "schlief", "die", "M\u00fcl\u00b7le\u00b7rin", ";", "sach\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "APPR", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "$.", "VVFIN"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.15": {"text": "Nahm ich ein W\u00fcrstchen, ich will es gestehn; doch hatte zu dieser", "tokens": ["Nahm", "ich", "ein", "W\u00fcr\u00b7stchen", ",", "ich", "will", "es", "ge\u00b7stehn", ";", "doch", "hat\u00b7te", "zu", "die\u00b7ser"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PPER", "VMFIN", "PPER", "VVPP", "$.", "ADV", "VAFIN", "APPR", "PDAT"], "meter": "+---+-+--+-+--+-", "measure": "trochaic.hexa.relaxed"}, "line.16": {"text": "Wackerlos irgend ein Recht, so dankt' er's meiner Bem\u00fchung.\u00ab", "tokens": ["Wa\u00b7cker\u00b7los", "ir\u00b7gend", "ein", "Recht", ",", "so", "dankt'", "er's", "mei\u00b7ner", "Be\u00b7m\u00fc\u00b7hung", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "ADV", "ART", "NN", "$,", "ADV", "VVFIN", "PIS", "PPOSAT", "NN", "$.", "$("], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}}, "stanza.15": {"line.1": {"text": "Und der Panther begann: \u00bbWas helfen Klagen und Worte!", "tokens": ["Und", "der", "Pan\u00b7ther", "be\u00b7gann", ":", "\u00bb", "Was", "hel\u00b7fen", "Kla\u00b7gen", "und", "Wor\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$.", "$(", "PWS", "ADJA", "NN", "KON", "NN", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Wenig richten sie aus, genug, das \u00dcbel ist ruchtbar.", "tokens": ["We\u00b7nig", "rich\u00b7ten", "sie", "aus", ",", "ge\u00b7nug", ",", "das", "\u00dc\u00b7bel", "ist", "rucht\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "$,", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Er ist ein Dieb, ein M\u00f6rder! Ich darf es k\u00fchnlich behaupten,", "tokens": ["Er", "ist", "ein", "Dieb", ",", "ein", "M\u00f6r\u00b7der", "!", "Ich", "darf", "es", "k\u00fchn\u00b7lich", "be\u00b7haup\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$.", "PPER", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ja, es wissen's die Herren, er \u00fcbet jeglichen Frevel.", "tokens": ["Ja", ",", "es", "wis\u00b7sen's", "die", "Her\u00b7ren", ",", "er", "\u00fc\u00b7bet", "jeg\u00b7li\u00b7chen", "Fre\u00b7vel", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Gut und Ehre verlieren; er lachte, gew\u00e4nn er nur etwa", "tokens": ["Gut", "und", "Eh\u00b7re", "ver\u00b7lie\u00b7ren", ";", "er", "lach\u00b7te", ",", "ge\u00b7w\u00e4nn", "er", "nur", "et\u00b7wa"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "KON", "NN", "VVINF", "$.", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "ADV"], "meter": "+-+--+--+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Einen Bissen dabei von einem fetten Kapaune.", "tokens": ["Ei\u00b7nen", "Bis\u00b7sen", "da\u00b7bei", "von", "ei\u00b7nem", "fet\u00b7ten", "Ka\u00b7pau\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.7": {"text": "La\u00dft Euch erz\u00e4hlen, wie er so \u00fcbel an Lampen, dem Hasen,", "tokens": ["La\u00dft", "Euch", "er\u00b7z\u00e4h\u00b7len", ",", "wie", "er", "so", "\u00fc\u00b7bel", "an", "Lam\u00b7pen", ",", "dem", "Ha\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$,", "PWAV", "PPER", "ADV", "ADJD", "APPR", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Gestern tat; hier steht er! der Mann, der keinen verletzte.", "tokens": ["Ge\u00b7stern", "tat", ";", "hier", "steht", "er", "!", "der", "Mann", ",", "der", "kei\u00b7nen", "ver\u00b7letz\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "$.", "ART", "NN", "$,", "PRELS", "PIAT", "ADJA", "$."], "meter": "-+--+--+-+--+-", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Reineke stellte sich fromm und wollt ihn allerlei Weisen", "tokens": ["Rei\u00b7ne\u00b7ke", "stell\u00b7te", "sich", "fromm", "und", "wollt", "ihn", "al\u00b7ler\u00b7lei", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PRF", "ADJD", "KON", "VMFIN", "PPER", "PIAT", "NN"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.10": {"text": "K\u00fcrzlich lehren und was zum Kaplan noch weiter geh\u00f6ret,", "tokens": ["K\u00fcrz\u00b7lich", "leh\u00b7ren", "und", "was", "zum", "Ka\u00b7plan", "noch", "wei\u00b7ter", "ge\u00b7h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KON", "PWS", "APPRART", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.11": {"text": "Und sie setzten sich gegeneinander, begannen das Credo.", "tokens": ["Und", "sie", "setz\u00b7ten", "sich", "ge\u00b7gen\u00b7ein\u00b7an\u00b7der", ",", "be\u00b7gan\u00b7nen", "das", "Cre\u00b7do", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "ADV", "$,", "VVFIN", "ART", "NN", "$."], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.12": {"text": "Aber Reineke konnte die alten T\u00fccken nicht lassen;", "tokens": ["A\u00b7ber", "Rei\u00b7ne\u00b7ke", "konn\u00b7te", "die", "al\u00b7ten", "T\u00fc\u00b7cken", "nicht", "las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VMFIN", "ART", "ADJA", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.13": {"text": "Innerhalb unsers K\u00f6niges Fried' und freiem Geleite", "tokens": ["In\u00b7ner\u00b7halb", "un\u00b7sers", "K\u00f6\u00b7ni\u00b7ges", "Fried'", "und", "frei\u00b7em", "Ge\u00b7lei\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NE", "KON", "ADJA", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.14": {"text": "Hielt er Lampen gefa\u00dft mit seinen Klauen und zerrte", "tokens": ["Hielt", "er", "Lam\u00b7pen", "ge\u00b7fa\u00dft", "mit", "sei\u00b7nen", "Klau\u00b7en", "und", "zerr\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "NN", "VVPP", "APPR", "PPOSAT", "NN", "KON", "VVFIN"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.15": {"text": "T\u00fcckisch den redlichen Mann. Ich kam die Stra\u00dfe gegangen,", "tokens": ["T\u00fc\u00b7ckisch", "den", "red\u00b7li\u00b7chen", "Mann", ".", "Ich", "kam", "die", "Stra\u00b7\u00dfe", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.16": {"text": "H\u00f6rte beider Gesang, der, kaum begonnen, schon wieder", "tokens": ["H\u00f6r\u00b7te", "bei\u00b7der", "Ge\u00b7sang", ",", "der", ",", "kaum", "be\u00b7gon\u00b7nen", ",", "schon", "wie\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "$,", "PRELS", "$,", "ADV", "VVPP", "$,", "ADV", "ADV"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.17": {"text": "Endete. Horchend wundert ich mich, doch als ich hinzukam,", "tokens": ["En\u00b7de\u00b7te", ".", "Hor\u00b7chend", "wun\u00b7dert", "ich", "mich", ",", "doch", "als", "ich", "hin\u00b7zu\u00b7kam", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NE", "VVFIN", "PPER", "PRF", "$,", "ADV", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+--+--+-+-+-+-+", "measure": "dactylic.di.plus"}, "line.18": {"text": "Kannt ich Reineken stracks, er hatte Lampen beim Kragen;", "tokens": ["Kannt", "ich", "Rei\u00b7ne\u00b7ken", "stracks", ",", "er", "hat\u00b7te", "Lam\u00b7pen", "beim", "Kra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "VVFIN", "$,", "PPER", "VAFIN", "NN", "APPRART", "NN", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.19": {"text": "Ja, er h\u00e4tt ihm gewi\u00df das Leben genommen, wofern ich", "tokens": ["Ja", ",", "er", "h\u00e4tt", "ihm", "ge\u00b7wi\u00df", "das", "Le\u00b7ben", "ge\u00b7nom\u00b7men", ",", "wo\u00b7fern", "ich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$,", "KOUS", "PPER"], "meter": "--+--+-+--+-+-+", "measure": "anapaest.di.plus"}, "line.20": {"text": "Nicht zum Gl\u00fccke des Wegs gekommen w\u00e4re. Da steht er!", "tokens": ["Nicht", "zum", "Gl\u00fc\u00b7cke", "des", "Wegs", "ge\u00b7kom\u00b7men", "w\u00e4\u00b7re", ".", "Da", "steht", "er", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "ART", "NN", "VVPP", "VAFIN", "$.", "ADV", "VVFIN", "PPER", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.21": {"text": "Seht die Wunden an ihm, dem frommen Manne, den keiner", "tokens": ["Seht", "die", "Wun\u00b7den", "an", "ihm", ",", "dem", "from\u00b7men", "Man\u00b7ne", ",", "den", "kei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPER", "$,", "ART", "ADJA", "NN", "$,", "PRELS", "PIS"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.22": {"text": "Zu beleidigen denkt. Und will es unser Gebieter,", "tokens": ["Zu", "be\u00b7lei\u00b7di\u00b7gen", "denkt", ".", "Und", "will", "es", "un\u00b7ser", "Ge\u00b7bie\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "$.", "KON", "VMFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.23": {"text": "Wollt ihr Herren es leiden, da\u00df so des K\u00f6niges Friede,", "tokens": ["Wollt", "ihr", "Her\u00b7ren", "es", "lei\u00b7den", ",", "da\u00df", "so", "des", "K\u00f6\u00b7ni\u00b7ges", "Frie\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PPER", "VVINF", "$,", "KOUS", "ADV", "ART", "NN", "NN", "$,"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.24": {"text": "Sein Geleit und Brief von einem Diebe verh\u00f6hnt wird,", "tokens": ["Sein", "Ge\u00b7leit", "und", "Brief", "von", "ei\u00b7nem", "Die\u00b7be", "ver\u00b7h\u00f6hnt", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "APPR", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.25": {"text": "Oh, so wird der K\u00f6nig und seine Kinder noch sp\u00e4ten", "tokens": ["Oh", ",", "so", "wird", "der", "K\u00f6\u00b7nig", "und", "sei\u00b7ne", "Kin\u00b7der", "noch", "sp\u00e4\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "ART", "NN", "KON", "PPOSAT", "NN", "ADV", "VVINF"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.26": {"text": "Vorwurf h\u00f6ren von Leuten, die Recht und Gerechtigkeit lieben.\u00ab", "tokens": ["Vor\u00b7wurf", "h\u00f6\u00b7ren", "von", "Leu\u00b7ten", ",", "die", "Recht", "und", "Ge\u00b7rech\u00b7tig\u00b7keit", "lie\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVINF", "APPR", "NN", "$,", "ART", "NN", "KON", "NN", "VVINF", "$.", "$("], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}}, "stanza.16": {"line.1": {"text": "Isegrim sagte darauf: \u00bbSo wird es bleiben, und leider", "tokens": ["I\u00b7seg\u00b7rim", "sag\u00b7te", "da\u00b7rauf", ":", "\u00bb", "So", "wird", "es", "blei\u00b7ben", ",", "und", "lei\u00b7der"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "VVFIN", "PAV", "$.", "$(", "ADV", "VAFIN", "PPER", "VVINF", "$,", "KON", "ADV"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Wird uns Reineke nie was Gutes erzeigen. Oh! l\u00e4g er", "tokens": ["Wird", "uns", "Rei\u00b7ne\u00b7ke", "nie", "was", "Gu\u00b7tes", "er\u00b7zei\u00b7gen", ".", "Oh", "!", "l\u00e4g", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "NN", "ADV", "PWS", "NN", "VVINF", "$.", "ITJ", "$.", "VVFIN", "PPER"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Lange tot; das w\u00e4re das beste f\u00fcr friedliche Leute;", "tokens": ["Lan\u00b7ge", "tot", ";", "das", "w\u00e4\u00b7re", "das", "bes\u00b7te", "f\u00fcr", "fried\u00b7li\u00b7che", "Leu\u00b7te", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PDS", "VAFIN", "ART", "ADJA", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Aber wird ihm diesmal verziehn, so wird er in kurzem", "tokens": ["A\u00b7ber", "wird", "ihm", "dies\u00b7mal", "ver\u00b7ziehn", ",", "so", "wird", "er", "in", "kur\u00b7zem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVINF", "$,", "ADV", "VAFIN", "PPER", "APPR", "ADJA"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Etliche k\u00fchnlich ber\u00fccken, die nun es am wenigsten glauben.\u00ab", "tokens": ["Et\u00b7li\u00b7che", "k\u00fchn\u00b7lich", "be\u00b7r\u00fc\u00b7cken", ",", "die", "nun", "es", "am", "we\u00b7nigs\u00b7ten", "glau\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "ADJD", "VVINF", "$,", "PRELS", "ADV", "PPER", "APPRART", "PIS", "VVINF", "$.", "$("], "meter": "+--+--+--+--++-+-", "measure": "dactylic.tetra.plus"}}, "stanza.17": {"line.1": {"text": "Reinekens Neffe, der Dachs, nahm jetzt die Rede, und mutig", "tokens": ["Rei\u00b7ne\u00b7kens", "Nef\u00b7fe", ",", "der", "Dachs", ",", "nahm", "jetzt", "die", "Re\u00b7de", ",", "und", "mu\u00b7tig"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "$,", "ART", "NN", "$,", "VVFIN", "ADV", "ART", "NN", "$,", "KON", "ADJD"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Sprach er zu Reinekens Bestem, so falsch auch dieser bekannt war.", "tokens": ["Sprach", "er", "zu", "Rei\u00b7ne\u00b7kens", "Bes\u00b7tem", ",", "so", "falsch", "auch", "die\u00b7ser", "be\u00b7kannt", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "NE", "NN", "$,", "ADV", "ADJD", "ADV", "PDAT", "ADJD", "VAFIN", "$."], "meter": "-+-+--+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbalt und wahr, Herr Isegrim!\u00ab sagt' er, \u00bbbeweist sich das Sprichwort:", "tokens": ["\u00bb", "alt", "und", "wahr", ",", "Herr", "I\u00b7seg\u00b7rim", "!", "\u00ab", "sagt'", "er", ",", "\u00bb", "be\u00b7weist", "sich", "das", "Sprich\u00b7wort", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "KON", "ADJD", "$,", "NN", "NE", "$.", "$(", "VVFIN", "PPER", "$,", "$(", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Feindes Mund frommt selten. So hat auch wahrlich mein Oheim", "tokens": ["Fein\u00b7des", "Mund", "frommt", "sel\u00b7ten", ".", "So", "hat", "auch", "wahr\u00b7lich", "mein", "O\u00b7heim"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "VVFIN", "ADJD", "$.", "ADV", "VAFIN", "ADV", "ADV", "PPOSAT", "NN"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Eurer Worte sich nicht zu getr\u00f6sten. Doch ist es ein leichtes.", "tokens": ["Eu\u00b7rer", "Wor\u00b7te", "sich", "nicht", "zu", "ge\u00b7tr\u00f6s\u00b7ten", ".", "Doch", "ist", "es", "ein", "leich\u00b7tes", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRF", "PTKNEG", "PTKZU", "VVINF", "$.", "KON", "VAFIN", "PPER", "ART", "ADJA", "$."], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.6": {"text": "W\u00e4r er hier am Hofe so gut als Ihr und erfreut' er", "tokens": ["W\u00e4r", "er", "hier", "am", "Ho\u00b7fe", "so", "gut", "als", "Ihr", "und", "er\u00b7freut'", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "APPRART", "NN", "ADV", "ADJD", "KOKOM", "PPER", "KON", "VVFIN", "PPER"], "meter": "+-+-+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.7": {"text": "Da\u00df Ihr so h\u00e4misch gesprochen und alte Geschichten erneuert.", "tokens": ["Da\u00df", "Ihr", "so", "h\u00e4\u00b7misch", "ge\u00b7spro\u00b7chen", "und", "al\u00b7te", "Ge\u00b7schich\u00b7ten", "er\u00b7neu\u00b7ert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVPP", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Aber was Ihr \u00dcbels an Reineken selber ver\u00fcbet,", "tokens": ["A\u00b7ber", "was", "Ihr", "\u00dc\u00b7bels", "an", "Rei\u00b7ne\u00b7ken", "sel\u00b7ber", "ver\u00b7\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "APPR", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.9": {"text": "\u00dcbergeht Ihr; und doch, es wissen es manche der Herren,", "tokens": ["\u00dc\u00b7ber\u00b7geht", "Ihr", ";", "und", "doch", ",", "es", "wis\u00b7sen", "es", "man\u00b7che", "der", "Her\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "KON", "ADV", "$,", "PPER", "VVFIN", "PPER", "PIS", "ART", "NN", "$,"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Wie ihr zusammen ein B\u00fcndnis geschlossen und beide versprochen,", "tokens": ["Wie", "ihr", "zu\u00b7sam\u00b7men", "ein", "B\u00fcnd\u00b7nis", "ge\u00b7schlos\u00b7sen", "und", "bei\u00b7de", "ver\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "VVPP", "KON", "PIS", "VVINF", "$,"], "meter": "-+-+--+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Als zwei gleiche Gesellen zu leben. Das mu\u00df ich erz\u00e4hlen;", "tokens": ["Als", "zwei", "glei\u00b7che", "Ge\u00b7sel\u00b7len", "zu", "le\u00b7ben", ".", "Das", "mu\u00df", "ich", "er\u00b7z\u00e4h\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "ADJA", "NN", "PTKZU", "VVINF", "$.", "PDS", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.12": {"text": "Denn im Winter einmal erduldet' er gro\u00dfe Gefahren", "tokens": ["Denn", "im", "Win\u00b7ter", "ein\u00b7mal", "er\u00b7dul\u00b7det'", "er", "gro\u00b7\u00dfe", "Ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ADV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Euretwegen. Ein Fuhrmann, er hatte Fische geladen,", "tokens": ["Eu\u00b7ret\u00b7we\u00b7gen", ".", "Ein", "Fuhr\u00b7mann", ",", "er", "hat\u00b7te", "Fi\u00b7sche", "ge\u00b7la\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ART", "NN", "$,", "PPER", "VAFIN", "NN", "VVPP", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.14": {"text": "Fuhr die Stra\u00dfe; Ihr sp\u00fcrtet ihn aus und h\u00e4ttet um alles", "tokens": ["Fuhr", "die", "Stra\u00b7\u00dfe", ";", "Ihr", "sp\u00fcr\u00b7tet", "ihn", "aus", "und", "h\u00e4t\u00b7tet", "um", "al\u00b7les"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "KON", "VAFIN", "APPR", "PIS"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.15": {"text": "Gern von der Ware gegessen; doch fehlt' es Euch leider am Gelde.", "tokens": ["Gern", "von", "der", "Wa\u00b7re", "ge\u00b7ges\u00b7sen", ";", "doch", "fehlt'", "es", "Euch", "lei\u00b7der", "am", "Gel\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$.", "ADV", "VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.16": {"text": "Da beredetet Ihr den Oheim, er legte sich listig", "tokens": ["Da", "be\u00b7re\u00b7de\u00b7tet", "Ihr", "den", "O\u00b7heim", ",", "er", "leg\u00b7te", "sich", "lis\u00b7tig"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "PPER", "VVFIN", "PRF", "ADJD"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.17": {"text": "Grade f\u00fcr tot in den Weg. Es war, beim Himmel, ein k\u00fchnes", "tokens": ["Gra\u00b7de", "f\u00fcr", "tot", "in", "den", "Weg", ".", "Es", "war", ",", "beim", "Him\u00b7mel", ",", "ein", "k\u00fch\u00b7nes"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "ADJD", "APPR", "ART", "NN", "$.", "PPER", "VAFIN", "$,", "APPRART", "NN", "$,", "ART", "ADJA"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.18": {"text": "Abenteuer! Doch merket, was ihm f\u00fcr Fische geworden.", "tokens": ["A\u00b7bent\u00b7eu\u00b7er", "!", "Doch", "mer\u00b7ket", ",", "was", "ihm", "f\u00fcr", "Fi\u00b7sche", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "VVFIN", "$,", "PWS", "PPER", "APPR", "NN", "VAPP", "$."], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.19": {"text": "Und der Fuhrmann kam und sah im Gleise den Oheim,", "tokens": ["Und", "der", "Fuhr\u00b7mann", "kam", "und", "sah", "im", "Glei\u00b7se", "den", "O\u00b7heim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "KON", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.20": {"text": "Hastig zog er sein Schwert, ihm eins zu versetzen; der Kluge", "tokens": ["Has\u00b7tig", "zog", "er", "sein", "Schwert", ",", "ihm", "eins", "zu", "ver\u00b7set\u00b7zen", ";", "der", "Klu\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "PPER", "PIS", "PTKZU", "VVINF", "$.", "ART", "NN"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.21": {"text": "R\u00fchrt' und regte sich nicht, als w\u00e4r er gestorben; der Fuhrmann", "tokens": ["R\u00fchrt'", "und", "reg\u00b7te", "sich", "nicht", ",", "als", "w\u00e4r", "er", "ge\u00b7stor\u00b7ben", ";", "der", "Fuhr\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "KON", "VVFIN", "PRF", "PTKNEG", "$,", "KOKOM", "VAFIN", "PPER", "VVPP", "$.", "ART", "NN"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.22": {"text": "Wirft ihn auf seinen Karrn und freut sich des Balges im voraus.", "tokens": ["Wirft", "ihn", "auf", "sei\u00b7nen", "Karrn", "und", "freut", "sich", "des", "Bal\u00b7ges", "im", "vo\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "PRF", "ART", "NN", "APPRART", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.23": {"text": "Ja, das wagte mein Oheim f\u00fcr Isegrim; aber der Fuhrmann", "tokens": ["Ja", ",", "das", "wag\u00b7te", "mein", "O\u00b7heim", "f\u00fcr", "I\u00b7seg\u00b7rim", ";", "a\u00b7ber", "der", "Fuhr\u00b7mann"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PDS", "VVFIN", "PPOSAT", "NN", "APPR", "NE", "$.", "ADV", "ART", "NN"], "meter": "+-+-+-+-+--+--+-", "measure": "trochaic.septa.relaxed"}, "line.24": {"text": "Fuhr dahin, und Reineke warf von den Fischen herunter.", "tokens": ["Fuhr", "da\u00b7hin", ",", "und", "Rei\u00b7ne\u00b7ke", "warf", "von", "den", "Fi\u00b7schen", "her\u00b7un\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "$,", "KON", "NN", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.25": {"text": "Isegrim kam von ferne geschlichen, verzehrte die Fische.", "tokens": ["I\u00b7seg\u00b7rim", "kam", "von", "fer\u00b7ne", "ge\u00b7schli\u00b7chen", ",", "ver\u00b7zehr\u00b7te", "die", "Fi\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADV", "VVPP", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.26": {"text": "Reineken mochte nicht l\u00e4nger zu fahren belieben; er hub sich,", "tokens": ["Rei\u00b7ne\u00b7ken", "moch\u00b7te", "nicht", "l\u00e4n\u00b7ger", "zu", "fah\u00b7ren", "be\u00b7lie\u00b7ben", ";", "er", "hub", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "VVINF", "$.", "PPER", "VVFIN", "PRF", "$,"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.27": {"text": "Sprang vom Karren und w\u00fcnschte nun auch von der Beute zu speisen.", "tokens": ["Sprang", "vom", "Kar\u00b7ren", "und", "w\u00fcnschte", "nun", "auch", "von", "der", "Beu\u00b7te", "zu", "spei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "KON", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.28": {"text": "Aber Isegrim hatte sie alle verschlungen; er hatte", "tokens": ["A\u00b7ber", "I\u00b7seg\u00b7rim", "hat\u00b7te", "sie", "al\u00b7le", "ver\u00b7schlun\u00b7gen", ";", "er", "hat\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NE", "VAFIN", "PPER", "PIS", "VVPP", "$.", "PPER", "VAFIN"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.29": {"text": "\u00dcber Not sich beladen, er wollte bersten. Die Gr\u00e4ten", "tokens": ["\u00dc\u00b7ber", "Not", "sich", "be\u00b7la\u00b7den", ",", "er", "woll\u00b7te", "bers\u00b7ten", ".", "Die", "Gr\u00e4\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "PRF", "VVPP", "$,", "PPER", "VMFIN", "VVINF", "$.", "ART", "NN"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.30": {"text": "Lie\u00df er allein zur\u00fcck und bot dem Freunde den Rest an.", "tokens": ["Lie\u00df", "er", "al\u00b7lein", "zu\u00b7r\u00fcck", "und", "bot", "dem", "Freun\u00b7de", "den", "Rest", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKVZ", "KON", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+++", "measure": "unknown.measure.octa.plus"}, "line.31": {"text": "Noch ein anderes St\u00fcckchen! auch dies erz\u00e4hl ich Euch wahrhaft.", "tokens": ["Noch", "ein", "an\u00b7de\u00b7res", "St\u00fcck\u00b7chen", "!", "auch", "dies", "er\u00b7z\u00e4hl", "ich", "Euch", "wahr\u00b7haft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$.", "ADV", "PDS", "VVFIN", "PPER", "PPER", "ADV", "$."], "meter": "--+--+--+-+-+-+", "measure": "anapaest.tri.plus"}, "line.32": {"text": "Reineken war es bewu\u00dft, bei einem Bauer am Nagel", "tokens": ["Rei\u00b7ne\u00b7ken", "war", "es", "be\u00b7wu\u00dft", ",", "bei", "ei\u00b7nem", "Bau\u00b7er", "am", "Na\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "ADJD", "$,", "APPR", "ART", "NN", "APPRART", "NE"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.33": {"text": "Hing ein gem\u00e4stetes Schwein, erst heute geschlachtet; das sagt'er", "tokens": ["Hing", "ein", "ge\u00b7m\u00e4s\u00b7te\u00b7tes", "Schwein", ",", "erst", "heu\u00b7te", "ge\u00b7schlach\u00b7tet", ";", "das", "sagt'\u00b7er"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,", "ADV", "ADV", "VVPP", "$.", "ART", "NN"], "meter": "-+-+--+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Treu dem Wolfe: sie gingen dahin, Gewinn und Gefahren", "tokens": ["Treu", "dem", "Wol\u00b7fe", ":", "sie", "gin\u00b7gen", "da\u00b7hin", ",", "Ge\u00b7winn", "und", "Ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$.", "PPER", "VVFIN", "PAV", "$,", "NN", "KON", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.35": {"text": "Redlich zu teilen. Doch M\u00fch und Gefahr trug jener alleine.", "tokens": ["Red\u00b7lich", "zu", "tei\u00b7len", ".", "Doch", "M\u00fch", "und", "Ge\u00b7fahr", "trug", "je\u00b7ner", "al\u00b7lei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$.", "KON", "NN", "KON", "NN", "VVFIN", "PDS", "ADV", "$."], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.36": {"text": "Denn er kroch zum Fenster hinein und warf mit Bem\u00fchen", "tokens": ["Denn", "er", "kroch", "zum", "Fens\u00b7ter", "hin\u00b7ein", "und", "warf", "mit", "Be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "KON", "VVFIN", "APPR", "NN"], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.37": {"text": "Die gemeinsame Beute dem Wolf herunter; zum Ungl\u00fcck", "tokens": ["Die", "ge\u00b7mein\u00b7sa\u00b7me", "Beu\u00b7te", "dem", "Wolf", "her\u00b7un\u00b7ter", ";", "zum", "Un\u00b7gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NE", "PTKVZ", "$.", "APPRART", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.38": {"text": "Waren Hunde nicht fern, die ihn im Hause versp\u00fcrten", "tokens": ["Wa\u00b7ren", "Hun\u00b7de", "nicht", "fern", ",", "die", "ihn", "im", "Hau\u00b7se", "ver\u00b7sp\u00fcr\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "PTKNEG", "ADJD", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.39": {"text": "Und ihm wacker das Fell zerzausten. Verwundet entkam er;", "tokens": ["Und", "ihm", "wa\u00b7cker", "das", "Fell", "zer\u00b7zaus\u00b7ten", ".", "Ver\u00b7wun\u00b7det", "ent\u00b7kam", "er", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "ART", "NN", "VVFIN", "$.", "VVPP", "VVFIN", "PPER", "$."], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.40": {"text": "Eilig sucht' er Isegrim auf und klagt' ihm sein Leiden", "tokens": ["Ei\u00b7lig", "sucht'", "er", "I\u00b7seg\u00b7rim", "auf", "und", "klagt'", "ihm", "sein", "Lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "NE", "PTKVZ", "KON", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.41": {"text": "Und verlangte sein Teil. Da sagte jener: \u203aIch habe", "tokens": ["Und", "ver\u00b7lang\u00b7te", "sein", "Teil", ".", "Da", "sag\u00b7te", "je\u00b7ner", ":", "\u203a", "Ich", "ha\u00b7be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PDAT", "$.", "$(", "PPER", "VAFIN"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.42": {"text": "Und benage mir's wohl; wie wird das Fette dir schmecken!\u2039", "tokens": ["Und", "be\u00b7na\u00b7ge", "mir's", "wohl", ";", "wie", "wird", "das", "Fet\u00b7te", "dir", "schme\u00b7cken", "!", "\u2039"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "NE", "ADV", "$.", "PWAV", "VAFIN", "ART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.43": {"text": "Und er brachte das St\u00fcck; das Krummholz war es, der Schl\u00e4chter", "tokens": ["Und", "er", "brach\u00b7te", "das", "St\u00fcck", ";", "das", "Krumm\u00b7holz", "war", "es", ",", "der", "Schl\u00e4ch\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$.", "ART", "NN", "VAFIN", "PPER", "$,", "ART", "NN"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.44": {"text": "Hatte daran das Schwein geh\u00e4ngt; der k\u00f6stliche Braten", "tokens": ["Hat\u00b7te", "da\u00b7ran", "das", "Schwein", "ge\u00b7h\u00e4ngt", ";", "der", "k\u00f6st\u00b7li\u00b7che", "Bra\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PAV", "ART", "NN", "VVPP", "$.", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.45": {"text": "War vom gierigen Wolfe, dem Ungerechten, verschlungen.", "tokens": ["War", "vom", "gie\u00b7ri\u00b7gen", "Wol\u00b7fe", ",", "dem", "Un\u00b7ge\u00b7rech\u00b7ten", ",", "ver\u00b7schlun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "APPRART", "ADJA", "NN", "$,", "ART", "NN", "$,", "VVPP", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.46": {"text": "Reineke konnte vor Zorn nicht reden, doch was er sich dachte,", "tokens": ["Rei\u00b7ne\u00b7ke", "konn\u00b7te", "vor", "Zorn", "nicht", "re\u00b7den", ",", "doch", "was", "er", "sich", "dach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "APPR", "NN", "PTKNEG", "VVINF", "$,", "KON", "PWS", "PPER", "PRF", "VVFIN", "$,"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.47": {"text": "Denket Euch selbst. Herr K\u00f6nig, gewi\u00df, da\u00df hundert und dr\u00fcber", "tokens": ["Den\u00b7ket", "Euch", "selbst", ".", "Herr", "K\u00f6\u00b7nig", ",", "ge\u00b7wi\u00df", ",", "da\u00df", "hun\u00b7dert", "und", "dr\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$.", "NN", "NN", "$,", "ADV", "$,", "KOUS", "CARD", "KON", "PAV"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.48": {"text": "Solcher St\u00fcckchen der Wolf an meinem Oheim verschuldet!", "tokens": ["Sol\u00b7cher", "St\u00fcck\u00b7chen", "der", "Wolf", "an", "mei\u00b7nem", "O\u00b7heim", "ver\u00b7schul\u00b7det", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NE", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+--+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.49": {"text": "Aber ich schweige davon. Wird Reineke selber gefordert,", "tokens": ["A\u00b7ber", "ich", "schwei\u00b7ge", "da\u00b7von", ".", "Wird", "Rei\u00b7ne\u00b7ke", "sel\u00b7ber", "ge\u00b7for\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PAV", "$.", "VAFIN", "NN", "ADV", "VVPP", "$,"], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.50": {"text": "Wird er sich besser verteid'gen. Indessen, gn\u00e4digster K\u00f6nig,", "tokens": ["Wird", "er", "sich", "bes\u00b7ser", "ver\u00b7tei\u00b7d'\u00b7gen", ".", "In\u00b7des\u00b7sen", ",", "gn\u00e4\u00b7digs\u00b7ter", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADJD", "VVINF", "$.", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+--+--+---+-+--+-", "measure": "dactylic.tri.plus"}, "line.51": {"text": "Edler Gebieter, ich darf es bemerken: Ihr habet, es haben", "tokens": ["Ed\u00b7ler", "Ge\u00b7bie\u00b7ter", ",", "ich", "darf", "es", "be\u00b7mer\u00b7ken", ":", "Ihr", "ha\u00b7bet", ",", "es", "ha\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$.", "PPER", "VAFIN", "$,", "PPER", "VAFIN"], "meter": "+--+--+--+-+-+-+-", "measure": "dactylic.tri.plus"}, "line.52": {"text": "Diese Herren geh\u00f6rt, wie t\u00f6richt Isegrims Rede", "tokens": ["Die\u00b7se", "Her\u00b7ren", "ge\u00b7h\u00f6rt", ",", "wie", "t\u00f6\u00b7richt", "I\u00b7se\u00b7grims", "Re\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VVFIN", "$,", "PWAV", "VVFIN", "NE", "NN"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.53": {"text": "Seinem eignen Weibe und ihrer Ehre zu nah tritt,", "tokens": ["Sei\u00b7nem", "eig\u00b7nen", "Wei\u00b7be", "und", "ih\u00b7rer", "Eh\u00b7re", "zu", "nah", "tritt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "KON", "PPOSAT", "NN", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.54": {"text": "Die er mit Leib und Leben besch\u00fctzen sollte. Denn freilich", "tokens": ["Die", "er", "mit", "Leib", "und", "Le\u00b7ben", "be\u00b7sch\u00fct\u00b7zen", "soll\u00b7te", ".", "Denn", "frei\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "VMFIN", "$.", "KON", "ADV"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.55": {"text": "Sieben Jahre sind's her und dr\u00fcber, da schenkte mein Oheim", "tokens": ["Sie\u00b7ben", "Jah\u00b7re", "sin\u00b7d's", "her", "und", "dr\u00fc\u00b7ber", ",", "da", "schenk\u00b7te", "mein", "O\u00b7heim"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["CARD", "NN", "NE", "PTKVZ", "KON", "PAV", "$,", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-+--+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.56": {"text": "Seine Lieb und Treue zum guten Teile der sch\u00f6nen", "tokens": ["Sei\u00b7ne", "Lieb", "und", "Treu\u00b7e", "zum", "gu\u00b7ten", "Tei\u00b7le", "der", "sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN", "APPRART", "ADJA", "NN", "ART", "ADJA"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.57": {"text": "Frauen Gieremund; solches geschah beim n\u00e4chtlichen Tanze;", "tokens": ["Frau\u00b7en", "Gie\u00b7re\u00b7mund", ";", "sol\u00b7ches", "ge\u00b7schah", "beim", "n\u00e4cht\u00b7li\u00b7chen", "Tan\u00b7ze", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "PIS", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+---+-+--+-", "measure": "trochaic.hexa.relaxed"}, "line.58": {"text": "Isegrim war verreist, ich sag es, wie mir's bekannt ist.", "tokens": ["I\u00b7seg\u00b7rim", "war", "ver\u00b7reist", ",", "ich", "sag", "es", ",", "wie", "mir's", "be\u00b7kannt", "ist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "VVPP", "$,", "PPER", "VVFIN", "PPER", "$,", "PWAV", "NE", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.59": {"text": "Freundlich und h\u00f6flich ist sie ihm oft zu Willen geworden,", "tokens": ["Freund\u00b7lich", "und", "h\u00f6f\u00b7lich", "ist", "sie", "ihm", "oft", "zu", "Wil\u00b7len", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VAFIN", "PPER", "PPER", "ADV", "APPR", "NN", "VAPP", "$,"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.60": {"text": "Und was ist es denn mehr? Sie bracht es niemals zur Klage,", "tokens": ["Und", "was", "ist", "es", "denn", "mehr", "?", "Sie", "bracht", "es", "nie\u00b7mals", "zur", "Kla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PPER", "ADV", "ADV", "$.", "PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-++--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.61": {"text": "Ja, sie lebt und befindet sich wohl, was macht er f\u00fcr Wesen?", "tokens": ["Ja", ",", "sie", "lebt", "und", "be\u00b7fin\u00b7det", "sich", "wohl", ",", "was", "macht", "er", "f\u00fcr", "We\u00b7sen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "KON", "VVFIN", "PRF", "ADV", "$,", "PWS", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.62": {"text": "W\u00e4r er klug, so schwieg' er davon; es bringt ihm nur Schande.\u00ab", "tokens": ["W\u00e4r", "er", "klug", ",", "so", "schwieg'", "er", "da\u00b7von", ";", "es", "bringt", "ihm", "nur", "Schan\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$,", "ADV", "VVFIN", "PPER", "PAV", "$.", "PPER", "VVFIN", "PPER", "ADV", "NN", "$.", "$("], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.63": {"text": "Weiter sagte der Dachs: \u00bbNun kommt das M\u00e4rchen vom Hasen!", "tokens": ["Wei\u00b7ter", "sag\u00b7te", "der", "Dachs", ":", "\u00bb", "Nun", "kommt", "das", "M\u00e4r\u00b7chen", "vom", "Ha\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.64": {"text": "Eitel leeres Gew\u00e4sche! Den Sch\u00fcler sollte der Meister", "tokens": ["Ei\u00b7tel", "lee\u00b7res", "Ge\u00b7w\u00e4\u00b7sche", "!", "Den", "Sch\u00fc\u00b7ler", "soll\u00b7te", "der", "Meis\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "$.", "ART", "NN", "VMFIN", "ART", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.65": {"text": "Etwa nicht z\u00fcchtigen, wenn er nicht merkt und \u00fcbel bestehet?", "tokens": ["Et\u00b7wa", "nicht", "z\u00fcch\u00b7ti\u00b7gen", ",", "wenn", "er", "nicht", "merkt", "und", "\u00fc\u00b7bel", "be\u00b7ste\u00b7het", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VVINF", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "KON", "ADJD", "VVFIN", "$."], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.66": {"text": "Sollte man nicht die Knaben bestrafen, und ginge der Leichtsinn,", "tokens": ["Soll\u00b7te", "man", "nicht", "die", "Kna\u00b7ben", "be\u00b7stra\u00b7fen", ",", "und", "gin\u00b7ge", "der", "Leicht\u00b7sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PTKNEG", "ART", "NN", "VVPP", "$,", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.67": {"text": "Ginge die Unart so hin, wie sollte die Jugend erwachsen?", "tokens": ["Gin\u00b7ge", "die", "Un\u00b7art", "so", "hin", ",", "wie", "soll\u00b7te", "die", "Ju\u00b7gend", "er\u00b7wach\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,", "PWAV", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.68": {"text": "Nun klagt Wackerlos, wie er ein W\u00fcrstchen im Winter verloren", "tokens": ["Nun", "klagt", "Wa\u00b7cker\u00b7los", ",", "wie", "er", "ein", "W\u00fcr\u00b7stchen", "im", "Win\u00b7ter", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "$,", "PWAV", "PPER", "ART", "NN", "APPRART", "NN", "VVPP"], "meter": "-+--+---+--+--+-", "measure": "iambic.penta.relaxed"}, "line.69": {"text": "Hinter der Hecke; das sollt er nun lieber im stillen verschmerzen;", "tokens": ["Hin\u00b7ter", "der", "He\u00b7cke", ";", "das", "sollt", "er", "nun", "lie\u00b7ber", "im", "stil\u00b7len", "ver\u00b7schmer\u00b7zen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "PDS", "VMFIN", "PPER", "ADV", "ADV", "APPRART", "ADJA", "VVINF", "$."], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.70": {"text": "Denn wir h\u00f6ren es ja, sie war gestohlen; zerronnen", "tokens": ["Denn", "wir", "h\u00f6\u00b7ren", "es", "ja", ",", "sie", "war", "ge\u00b7stoh\u00b7len", ";", "zer\u00b7ron\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "VAFIN", "VVPP", "$.", "VVPP"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.71": {"text": "Wie gewonnen; und wer kann meinem Oheim verargen,", "tokens": ["Wie", "ge\u00b7won\u00b7nen", ";", "und", "wer", "kann", "mei\u00b7nem", "O\u00b7heim", "ver\u00b7ar\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "$.", "KON", "PWS", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "--+--+-+--+-+-", "measure": "anapaest.di.plus"}, "line.72": {"text": "Da\u00df er gestohlenes Gut dem Diebe genommen? Es sollen", "tokens": ["Da\u00df", "er", "ge\u00b7stoh\u00b7le\u00b7nes", "Gut", "dem", "Die\u00b7be", "ge\u00b7nom\u00b7men", "?", "Es", "sol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADJA", "NN", "ART", "NN", "VVPP", "$.", "PPER", "VMFIN"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.73": {"text": "Edle M\u00e4nner von hoher Geburt sich geh\u00e4ssig den Dieben", "tokens": ["Ed\u00b7le", "M\u00e4n\u00b7ner", "von", "ho\u00b7her", "Ge\u00b7burt", "sich", "ge\u00b7h\u00e4s\u00b7sig", "den", "Die\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "PRF", "ADJD", "ART", "NN"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.74": {"text": "Und gef\u00e4hrlich erzeigen. Ja, h\u00e4tt er ihn damals gehangen,", "tokens": ["Und", "ge\u00b7f\u00e4hr\u00b7lich", "er\u00b7zei\u00b7gen", ".", "Ja", ",", "h\u00e4tt", "er", "ihn", "da\u00b7mals", "ge\u00b7han\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "$.", "PTKANT", "$,", "VAFIN", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.75": {"text": "War es verzeihlich. Doch lie\u00df er ihn los, den K\u00f6nig zu ehren;", "tokens": ["War", "es", "ver\u00b7zeih\u00b7lich", ".", "Doch", "lie\u00df", "er", "ihn", "los", ",", "den", "K\u00f6\u00b7nig", "zu", "eh\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$.", "KON", "VVFIN", "PPER", "PPER", "PTKVZ", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.76": {"text": "Denn am Leben zu strafen geh\u00f6rt dem K\u00f6nig alleine.", "tokens": ["Denn", "am", "Le\u00b7ben", "zu", "stra\u00b7fen", "ge\u00b7h\u00f6rt", "dem", "K\u00f6\u00b7nig", "al\u00b7lei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "PTKZU", "VVINF", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.77": {"text": "So gerecht er auch sei und \u00dcbeltaten verwehret.", "tokens": ["So", "ge\u00b7recht", "er", "auch", "sei", "und", "\u00dc\u00b7bel\u00b7ta\u00b7ten", "ver\u00b7weh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "VAFIN", "KON", "NN", "VVFIN", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.78": {"text": "Denn seitdem des K\u00f6nigs Friede verk\u00fcndiget worden,", "tokens": ["Denn", "seit\u00b7dem", "des", "K\u00f6\u00b7nigs", "Frie\u00b7de", "ver\u00b7k\u00fcn\u00b7di\u00b7get", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ART", "NN", "NN", "VVPP", "VAPP", "$,"], "meter": "----+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.79": {"text": "H\u00e4lt sich niemand wie er. Er hat sein Leben ver\u00e4ndert,", "tokens": ["H\u00e4lt", "sich", "nie\u00b7mand", "wie", "er", ".", "Er", "hat", "sein", "Le\u00b7ben", "ver\u00b7\u00e4n\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIS", "KOKOM", "PPER", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}, "line.80": {"text": "Speiset nur einmal des Tags, lebt wie ein Klausner, kasteit sich,", "tokens": ["Spei\u00b7set", "nur", "ein\u00b7mal", "des", "Tags", ",", "lebt", "wie", "ein", "Klaus\u00b7ner", ",", "kas\u00b7teit", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "$,", "VVFIN", "KOKOM", "ART", "NN", "$,", "VVFIN", "PRF", "$,"], "meter": "+--+--+-+-+-+--", "measure": "elegiambus"}, "line.81": {"text": "Tr\u00e4gt ein h\u00e4renes Kleid auf blo\u00dfem Leibe und hat schon", "tokens": ["Tr\u00e4gt", "ein", "h\u00e4\u00b7re\u00b7nes", "Kleid", "auf", "blo\u00b7\u00dfem", "Lei\u00b7be", "und", "hat", "schon"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "KON", "VAFIN", "ADV"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.82": {"text": "Lange von Wildbret und zahmem Fleische sich g\u00e4nzlich enthalten,", "tokens": ["Lan\u00b7ge", "von", "Wild\u00b7bret", "und", "zah\u00b7mem", "Flei\u00b7sche", "sich", "g\u00e4nz\u00b7lich", "ent\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "KON", "ADJA", "NN", "PRF", "ADJD", "VVPP", "$,"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.83": {"text": "Wie mir noch gestern einer erz\u00e4hlte, der bei ihm gewesen.", "tokens": ["Wie", "mir", "noch", "ge\u00b7stern", "ei\u00b7ner", "er\u00b7z\u00e4hl\u00b7te", ",", "der", "bei", "ihm", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "PIS", "VVFIN", "$,", "PRELS", "APPR", "PPER", "VAPP", "$."], "meter": "--+--+--+-+-+-+-", "measure": "anapaest.tri.plus"}, "line.84": {"text": "Malepartus, sein Schlo\u00df, hat er verlassen und baut sich", "tokens": ["Ma\u00b7le\u00b7par\u00b7tus", ",", "sein", "Schlo\u00df", ",", "hat", "er", "ver\u00b7las\u00b7sen", "und", "baut", "sich"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "VAFIN", "PPER", "VVINF", "KON", "VVFIN", "PRF"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.85": {"text": "Eine Klause zur Wohnung. Wie er so mager geworden,", "tokens": ["Ei\u00b7ne", "Klau\u00b7se", "zur", "Woh\u00b7nung", ".", "Wie", "er", "so", "ma\u00b7ger", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "PWAV", "PPER", "ADV", "ADJD", "VAPP", "$,"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.86": {"text": "Bleich von Hunger und Durst und andern strengeren Bu\u00dfen,", "tokens": ["Bleich", "von", "Hun\u00b7ger", "und", "Durst", "und", "an\u00b7dern", "stren\u00b7ge\u00b7ren", "Bu\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "KON", "NN", "KON", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.87": {"text": "Die er reuig ertr\u00e4gt, das werdet Ihr selber erfahren.", "tokens": ["Die", "er", "reu\u00b7ig", "er\u00b7tr\u00e4gt", ",", "das", "wer\u00b7det", "Ihr", "sel\u00b7ber", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "$,", "PDS", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.88": {"text": "Denn was kann es ihm schaden, da\u00df hier ihn jeder verklaget?", "tokens": ["Denn", "was", "kann", "es", "ihm", "scha\u00b7den", ",", "da\u00df", "hier", "ihn", "je\u00b7der", "ver\u00b7kla\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "PPER", "PPER", "VVINF", "$,", "KOUS", "ADV", "PPER", "PIS", "VVFIN", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.89": {"text": "Kommt er hieher, so f\u00fchrt er sein Recht aus und macht sie zuschanden.\u00ab", "tokens": ["Kommt", "er", "hie\u00b7her", ",", "so", "f\u00fchrt", "er", "sein", "Recht", "aus", "und", "macht", "sie", "zu\u00b7schan\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PAV", "$,", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "KON", "VVFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}}, "stanza.18": {"line.1": {"text": "Als nun Grimbart geendigt, erschien zu gro\u00dfem Erstaunen", "tokens": ["Als", "nun", "Grim\u00b7bart", "ge\u00b7en\u00b7digt", ",", "er\u00b7schien", "zu", "gro\u00b7\u00dfem", "Er\u00b7stau\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NE", "VVPP", "$,", "VVFIN", "APPR", "ADJA", "NN"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Henning, der Hahn, mit seinem Geschlecht. Auf trauriger Bahre,", "tokens": ["Hen\u00b7ning", ",", "der", "Hahn", ",", "mit", "sei\u00b7nem", "Ge\u00b7schlecht", ".", "Auf", "trau\u00b7ri\u00b7ger", "Bah\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$.", "APPR", "ADJA", "NN", "$,"], "meter": "---+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ohne Hals und Kopf, ward eine Henne getragen,", "tokens": ["Oh\u00b7ne", "Hals", "und", "Kopf", ",", "ward", "ei\u00b7ne", "Hen\u00b7ne", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.4": {"text": "Kratzfu\u00df war es, die beste der eierlegenden Hennen.", "tokens": ["Kratz\u00b7fu\u00df", "war", "es", ",", "die", "bes\u00b7te", "der", "ei\u00b7er\u00b7le\u00b7gen\u00b7den", "Hen\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "ART", "ADJA", "ART", "ADJA", "NN", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Ach, es flo\u00df ihr Blut, und Reineke hatt es vergossen!", "tokens": ["Ach", ",", "es", "flo\u00df", "ihr", "Blut", ",", "und", "Rei\u00b7ne\u00b7ke", "hatt", "es", "ver\u00b7gos\u00b7sen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "NN", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.6": {"text": "Jetzo sollt es der K\u00f6nig erfahren. Als Henning, der wackre,", "tokens": ["Jet\u00b7zo", "sollt", "es", "der", "K\u00f6\u00b7nig", "er\u00b7fah\u00b7ren", ".", "Als", "Hen\u00b7ning", ",", "der", "wack\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$.", "KOUS", "NE", "$,", "PRELS", "VVFIN", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.7": {"text": "Vor dem K\u00f6nig erschien, mit h\u00f6chstbetr\u00fcbter Geb\u00e4rde,", "tokens": ["Vor", "dem", "K\u00f6\u00b7nig", "er\u00b7schien", ",", "mit", "h\u00f6chst\u00b7be\u00b7tr\u00fcb\u00b7ter", "Ge\u00b7b\u00e4r\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.8": {"text": "Kamen mit ihm zwei H\u00e4hne, die gleichfalls trauerten. Kreyant", "tokens": ["Ka\u00b7men", "mit", "ihm", "zwei", "H\u00e4h\u00b7ne", ",", "die", "gleich\u00b7falls", "trau\u00b7er\u00b7ten", ".", "Krey\u00b7ant"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["NN", "APPR", "PPER", "CARD", "NN", "$,", "PRELS", "ADV", "VVFIN", "$.", "NN"], "meter": "+-+--+--+-+---+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Hie\u00df der eine, kein besserer Hahn war irgend zu finden", "tokens": ["Hie\u00df", "der", "ei\u00b7ne", ",", "kein", "bes\u00b7se\u00b7rer", "Hahn", "war", "ir\u00b7gend", "zu", "fin\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ART", "$,", "PIAT", "ADJA", "NN", "VAFIN", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+---+-+--+-", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Zwischen Holland und Frankreich; der andere durft ihm zur Seite", "tokens": ["Zwi\u00b7schen", "Hol\u00b7land", "und", "Fran\u00b7kreich", ";", "der", "an\u00b7de\u00b7re", "durft", "ihm", "zur", "Sei\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "NE", "$.", "ART", "ADJA", "VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.11": {"text": "Stehen, Kantart genannt, ein stracker, k\u00fchner Geselle;", "tokens": ["Ste\u00b7hen", ",", "Kan\u00b7tart", "ge\u00b7nannt", ",", "ein", "stra\u00b7cker", ",", "k\u00fch\u00b7ner", "Ge\u00b7sel\u00b7le", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VVPP", "$,", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.12": {"text": "Beide trugen ein brennendes Licht: sie waren die Br\u00fcder", "tokens": ["Bei\u00b7de", "tru\u00b7gen", "ein", "bren\u00b7nen\u00b7des", "Licht", ":", "sie", "wa\u00b7ren", "die", "Br\u00fc\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "$.", "PPER", "VAFIN", "ART", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.13": {"text": "Der ermordeten Frau. Sie riefen \u00fcber den M\u00f6rder", "tokens": ["Der", "er\u00b7mor\u00b7de\u00b7ten", "Frau", ".", "Sie", "rie\u00b7fen", "\u00fc\u00b7ber", "den", "M\u00f6r\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.14": {"text": "Ach und Weh! Es trugen die Bahr zwei j\u00fcngere H\u00e4hne,", "tokens": ["Ach", "und", "Weh", "!", "Es", "tru\u00b7gen", "die", "Bahr", "zwei", "j\u00fcn\u00b7ge\u00b7re", "H\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KON", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "CARD", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.15": {"text": "Und man konnte von fern die Jammerklage vernehmen.", "tokens": ["Und", "man", "konn\u00b7te", "von", "fern", "die", "Jam\u00b7mer\u00b7kla\u00b7ge", "ver\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "APPR", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.16": {"text": "Henning sprach: \u00bbWir klagen den unersetzlichen Schaden,", "tokens": ["Hen\u00b7ning", "sprach", ":", "\u00bb", "Wir", "kla\u00b7gen", "den", "un\u00b7er\u00b7setz\u00b7li\u00b7chen", "Scha\u00b7den", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.17": {"text": "Gn\u00e4digster Herr und K\u00f6nig! Erbarmt Euch, wie ich verletzt bin,", "tokens": ["Gn\u00e4\u00b7digs\u00b7ter", "Herr", "und", "K\u00f6\u00b7nig", "!", "Er\u00b7barmt", "Euch", ",", "wie", "ich", "ver\u00b7letzt", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$.", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+--+-++-+-", "measure": "iambic.septa.relaxed"}, "line.18": {"text": "Meine Kinder und ich. Hier seht Ihr Reinekens Werke!", "tokens": ["Mei\u00b7ne", "Kin\u00b7der", "und", "ich", ".", "Hier", "seht", "Ihr", "Rei\u00b7ne\u00b7kens", "Wer\u00b7ke", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPER", "$.", "ADV", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.19": {"text": "Als der Winter vorbei und Laub und Blumen und Bl\u00fcten", "tokens": ["Als", "der", "Win\u00b7ter", "vor\u00b7bei", "und", "Laub", "und", "Blu\u00b7men", "und", "Bl\u00fc\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PTKVZ", "KON", "NN", "KON", "NN", "KON", "NN"], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Uns zur Fr\u00f6hlichkeit riefen, erfreut ich mich meines Geschlechtes,", "tokens": ["Uns", "zur", "Fr\u00f6h\u00b7lich\u00b7keit", "rie\u00b7fen", ",", "er\u00b7freut", "ich", "mich", "mei\u00b7nes", "Ge\u00b7schlech\u00b7tes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "PRF", "PPOSAT", "NN", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.21": {"text": "Zehen junge S\u00f6hne, mit vierzehn T\u00f6chtern, sie waren", "tokens": ["Ze\u00b7hen", "jun\u00b7ge", "S\u00f6h\u00b7ne", ",", "mit", "vier\u00b7zehn", "T\u00f6ch\u00b7tern", ",", "sie", "wa\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["CARD", "ADJA", "NN", "$,", "APPR", "CARD", "NN", "$,", "PPER", "VAFIN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.22": {"text": "Voller Lust zu leben; mein Weib, die treffliche Henne,", "tokens": ["Vol\u00b7ler", "Lust", "zu", "le\u00b7ben", ";", "mein", "Weib", ",", "die", "treff\u00b7li\u00b7che", "Hen\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKZU", "VVINF", "$.", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.23": {"text": "Hatte sie alle zusammen in ", "tokens": ["Hat\u00b7te", "sie", "al\u00b7le", "zu\u00b7sam\u00b7men", "in"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PIS", "ADV", "APPR"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.24": {"text": "Alle waren so stark und wohl zufrieden, sie fanden", "tokens": ["Al\u00b7le", "wa\u00b7ren", "so", "stark", "und", "wohl", "zu\u00b7frie\u00b7den", ",", "sie", "fan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "KON", "ADV", "ADJD", "$,", "PPER", "VVFIN"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.25": {"text": "Ihre t\u00e4gliche Nahrung an wohlgesicherter St\u00e4tte.", "tokens": ["Ih\u00b7re", "t\u00e4g\u00b7li\u00b7che", "Nah\u00b7rung", "an", "wohl\u00b7ge\u00b7si\u00b7cher\u00b7ter", "St\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.26": {"text": "Reichen M\u00f6nchen geh\u00f6rte der Hof, uns schirmte die Mauer,", "tokens": ["Rei\u00b7chen", "M\u00f6n\u00b7chen", "ge\u00b7h\u00f6r\u00b7te", "der", "Hof", ",", "uns", "schirm\u00b7te", "die", "Mau\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.27": {"text": "Und sechs gro\u00dfe Hunde, die wackern Genossen des Hauses,", "tokens": ["Und", "sechs", "gro\u00b7\u00dfe", "Hun\u00b7de", ",", "die", "wa\u00b7ckern", "Ge\u00b7nos\u00b7sen", "des", "Hau\u00b7ses", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "Liebten meine Kinder und wachten \u00fcber ihr Leben;", "tokens": ["Lieb\u00b7ten", "mei\u00b7ne", "Kin\u00b7der", "und", "wach\u00b7ten", "\u00fc\u00b7ber", "ihr", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.29": {"text": "Reineken aber, den Dieb, verdro\u00df es, da\u00df wir in Frieden", "tokens": ["Rei\u00b7ne\u00b7ken", "a\u00b7ber", ",", "den", "Dieb", ",", "ver\u00b7dro\u00df", "es", ",", "da\u00df", "wir", "in", "Frie\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADV", "$,", "ART", "NN", "$,", "VVFIN", "PPER", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "+--+--+-+--+-+-", "measure": "dactylic.di.plus"}, "line.30": {"text": "Gl\u00fcckliche Tage verlebten und seine R\u00e4nke vermieden.", "tokens": ["Gl\u00fcck\u00b7li\u00b7che", "Ta\u00b7ge", "ver\u00b7leb\u00b7ten", "und", "sei\u00b7ne", "R\u00e4n\u00b7ke", "ver\u00b7mie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.31": {"text": "Immer schlich er bei Nacht um die Mauer und lauschte beim Tore;", "tokens": ["Im\u00b7mer", "schlich", "er", "bei", "Nacht", "um", "die", "Mau\u00b7er", "und", "lauschte", "beim", "To\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPR", "NN", "APPR", "ART", "NN", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "--+--+--+--+-+-", "measure": "anapaest.tetra.plus"}, "line.32": {"text": "Aber die Hunde bemerkten's; da mocht er laufen! Sie fa\u00dften", "tokens": ["A\u00b7ber", "die", "Hun\u00b7de", "be\u00b7merk\u00b7ten's", ";", "da", "mocht", "er", "lau\u00b7fen", "!", "Sie", "fa\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "VVINF", "$.", "PPER", "VVFIN"], "meter": "+--+---+-+-+--+-", "measure": "dactylic.di.plus"}, "line.33": {"text": "Wacker ihn endlich einmal und ruckten das Fell ihm zusammen;", "tokens": ["Wa\u00b7cker", "ihn", "end\u00b7lich", "ein\u00b7mal", "und", "ruck\u00b7ten", "das", "Fell", "ihm", "zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "KON", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.34": {"text": "Doch er rettete sich und lie\u00df uns ein Weilchen in Ruhe.", "tokens": ["Doch", "er", "ret\u00b7te\u00b7te", "sich", "und", "lie\u00df", "uns", "ein", "Weil\u00b7chen", "in", "Ru\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "KON", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "Aber nun h\u00f6ret mich an! Es w\u00e4hrte nicht lange, so kam er", "tokens": ["A\u00b7ber", "nun", "h\u00f6\u00b7ret", "mich", "an", "!", "Es", "w\u00e4hr\u00b7te", "nicht", "lan\u00b7ge", ",", "so", "kam", "er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "PTKNEG", "ADV", "$,", "ADV", "VVFIN", "PPER"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.36": {"text": "Als ein Klausner und brachte mir Brief und Siegel. Ich kannt es:", "tokens": ["Als", "ein", "Klaus\u00b7ner", "und", "brach\u00b7te", "mir", "Brief", "und", "Sie\u00b7gel", ".", "Ich", "kannt", "es", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "VVFIN", "PPER", "NN", "KON", "NN", "$.", "PPER", "VVFIN", "PPER", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.37": {"text": "Euer Siegel sah ich am Briefe; da fand ich geschrieben,", "tokens": ["Eu\u00b7er", "Sie\u00b7gel", "sah", "ich", "am", "Brie\u00b7fe", ";", "da", "fand", "ich", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPRART", "NN", "$.", "ADV", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+---+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.38": {"text": "Da\u00df Ihr festen Frieden so Tieren als V\u00f6geln verk\u00fcndigt.", "tokens": ["Da\u00df", "Ihr", "fes\u00b7ten", "Frie\u00b7den", "so", "Tie\u00b7ren", "als", "V\u00f6\u00b7geln", "ver\u00b7k\u00fcn\u00b7digt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADV", "NN", "KOUS", "NN", "VVPP", "$."], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.39": {"text": "Und er zeigte mir an: er sei ein Klausner geworden,", "tokens": ["Und", "er", "zeig\u00b7te", "mir", "an", ":", "er", "sei", "ein", "Klaus\u00b7ner", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VAFIN", "ART", "NN", "VAPP", "$,"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.40": {"text": "Habe strenge Gel\u00fcbde getan, die S\u00fcnden zu b\u00fc\u00dfen,", "tokens": ["Ha\u00b7be", "stren\u00b7ge", "Ge\u00b7l\u00fcb\u00b7de", "ge\u00b7tan", ",", "die", "S\u00fcn\u00b7den", "zu", "b\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVPP", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.41": {"text": "Deren Schuld er leider bekenne. Da habe nun keiner", "tokens": ["De\u00b7ren", "Schuld", "er", "lei\u00b7der", "be\u00b7ken\u00b7ne", ".", "Da", "ha\u00b7be", "nun", "kei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "NN", "PPER", "ADV", "VVFIN", "$.", "ADV", "VAFIN", "ADV", "PIS"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.42": {"text": "Mehr vor ihm sich zu f\u00fcrchten. Er habe heilig gelobet,", "tokens": ["Mehr", "vor", "ihm", "sich", "zu", "f\u00fcrch\u00b7ten", ".", "Er", "ha\u00b7be", "hei\u00b7lig", "ge\u00b7lo\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PRF", "PTKZU", "VVINF", "$.", "PPER", "VAFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.43": {"text": "Nimmermehr Fleisch zu genie\u00dfen. Er lie\u00df mich die Kutte beschauen,", "tokens": ["Nim\u00b7mer\u00b7mehr", "Fleisch", "zu", "ge\u00b7nie\u00b7\u00dfen", ".", "Er", "lie\u00df", "mich", "die", "Kut\u00b7te", "be\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PTKZU", "VVINF", "$.", "PPER", "VVFIN", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.44": {"text": "Zeigte sein Skapulier. Daneben wies er ein Zeugnis,", "tokens": ["Zeig\u00b7te", "sein", "Ska\u00b7pu\u00b7lier", ".", "Da\u00b7ne\u00b7ben", "wies", "er", "ein", "Zeug\u00b7nis", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$.", "PAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.45": {"text": "Das ihm der Prior gestellt, und, um mich sicher zu machen,", "tokens": ["Das", "ihm", "der", "Pri\u00b7or", "ge\u00b7stellt", ",", "und", ",", "um", "mich", "si\u00b7cher", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVPP", "$,", "KON", "$,", "KOUI", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.46": {"text": "Unter der Kutte ein h\u00e4renes Kleid. Dann ging er und sagte:", "tokens": ["Un\u00b7ter", "der", "Kut\u00b7te", "ein", "h\u00e4\u00b7re\u00b7nes", "Kleid", ".", "Dann", "ging", "er", "und", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$.", "ADV", "VVFIN", "PPER", "KON", "VVFIN", "$."], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.47": {"text": "\u203agott dem Herren seid mir befohlen! ich habe noch vieles", "tokens": ["\u203a", "gott", "dem", "Her\u00b7ren", "seid", "mir", "be\u00b7foh\u00b7len", "!", "ich", "ha\u00b7be", "noch", "vie\u00b7les"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "NN", "ART", "NN", "VAFIN", "PPER", "VVPP", "$.", "PPER", "VAFIN", "ADV", "PIS"], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.48": {"text": "Heute zu tun! ich habe die Sext und die None zu lesen", "tokens": ["Heu\u00b7te", "zu", "tun", "!", "ich", "ha\u00b7be", "die", "Sext", "und", "die", "No\u00b7ne", "zu", "le\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PTKZU", "VVINF", "$.", "PPER", "VAFIN", "ART", "NN", "KON", "ART", "NN", "PTKZU", "VVINF"], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.49": {"text": "Und die Vesper dazu.\u2039 Er las im Gehen und dachte", "tokens": ["Und", "die", "Ves\u00b7per", "da\u00b7zu", ".", "\u2039", "Er", "las", "im", "Ge\u00b7hen", "und", "dach\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PTKVZ", "$.", "$(", "PPER", "VVFIN", "APPRART", "NN", "KON", "VVFIN"], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.50": {"text": "Vieles B\u00f6se sich aus, er sann auf unser Verderben.", "tokens": ["Vie\u00b7les", "B\u00f6\u00b7se", "sich", "aus", ",", "er", "sann", "auf", "un\u00b7ser", "Ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PRF", "PTKVZ", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.51": {"text": "Ich mit erheitertem Herzen erz\u00e4hlte geschwinde den Kindern", "tokens": ["Ich", "mit", "er\u00b7hei\u00b7ter\u00b7tem", "Her\u00b7zen", "er\u00b7z\u00e4hl\u00b7te", "ge\u00b7schwin\u00b7de", "den", "Kin\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ADJA", "NN", "VVFIN", "ADJA", "ART", "NN"], "meter": "-+-+--+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.52": {"text": "Eures Briefes fr\u00f6hliche Botschaft, es freuten sich alle.", "tokens": ["Eu\u00b7res", "Brie\u00b7fes", "fr\u00f6h\u00b7li\u00b7che", "Bot\u00b7schaft", ",", "es", "freu\u00b7ten", "sich", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,", "PPER", "VVFIN", "PRF", "PIS", "$."], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.53": {"text": "Da nun Reineke Klausner geworden, so hatten wir weiter", "tokens": ["Da", "nun", "Rei\u00b7ne\u00b7ke", "Klaus\u00b7ner", "ge\u00b7wor\u00b7den", ",", "so", "hat\u00b7ten", "wir", "wei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "NE", "NN", "VAPP", "$,", "ADV", "VAFIN", "PPER", "ADV"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.54": {"text": "Keine Sorge noch Furcht. Ich ging mit ihnen zusammen", "tokens": ["Kei\u00b7ne", "Sor\u00b7ge", "noch", "Furcht", ".", "Ich", "ging", "mit", "ih\u00b7nen", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "ADV", "NN", "$.", "PPER", "VVFIN", "APPR", "PPER", "PTKVZ"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.55": {"text": "Vor die Mauer hinaus, wir freuten uns alle der Freiheit.", "tokens": ["Vor", "die", "Mau\u00b7er", "hin\u00b7aus", ",", "wir", "freu\u00b7ten", "uns", "al\u00b7le", "der", "Frei\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APZR", "$,", "PPER", "VVFIN", "PPER", "PIS", "ART", "NN", "$."], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.56": {"text": "Hinterlistig; da sprang er hervor und verrannt uns die Pforte;", "tokens": ["Hin\u00b7ter\u00b7lis\u00b7tig", ";", "da", "sprang", "er", "her\u00b7vor", "und", "ver\u00b7rannt", "uns", "die", "Pfor\u00b7te", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.57": {"text": "Meiner S\u00f6hne sch\u00f6nsten ergriff er und schleppt' ihn von dannen,", "tokens": ["Mei\u00b7ner", "S\u00f6h\u00b7ne", "sch\u00f6ns\u00b7ten", "er\u00b7griff", "er", "und", "schleppt'", "ihn", "von", "dan\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "APPR", "ADV", "$,"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.58": {"text": "Und nun war kein Rat, nachdem er sie einmal gekostet;", "tokens": ["Und", "nun", "war", "kein", "Rat", ",", "nach\u00b7dem", "er", "sie", "ein\u00b7mal", "ge\u00b7kos\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIAT", "NN", "$,", "KOUS", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "--+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.59": {"text": "Immer versucht' er es wieder; und weder J\u00e4ger noch Hunde", "tokens": ["Im\u00b7mer", "ver\u00b7sucht'", "er", "es", "wie\u00b7der", ";", "und", "we\u00b7der", "J\u00e4\u00b7ger", "noch", "Hun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "$.", "KON", "KON", "NN", "ADV", "NN"], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.60": {"text": "Konnten vor seinen R\u00e4nken bei Tag und Nacht uns bewahren.", "tokens": ["Konn\u00b7ten", "vor", "sei\u00b7nen", "R\u00e4n\u00b7ken", "bei", "Tag", "und", "Nacht", "uns", "be\u00b7wah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "PPER", "VVINF", "$."], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.61": {"text": "So entri\u00df er mir nun fast alle Kinder; von zwanzig", "tokens": ["So", "ent\u00b7ri\u00df", "er", "mir", "nun", "fast", "al\u00b7le", "Kin\u00b7der", ";", "von", "zwan\u00b7zig"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ADV", "PIAT", "NN", "$.", "APPR", "CARD"], "meter": "--+---+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.62": {"text": "Bin ich auf f\u00fcnfe gebracht, die andern raubt' er mir alle.", "tokens": ["Bin", "ich", "auf", "f\u00fcn\u00b7fe", "ge\u00b7bracht", ",", "die", "an\u00b7dern", "raubt'", "er", "mir", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "CARD", "VVPP", "$,", "PRELS", "PIS", "VVFIN", "PPER", "PPER", "PIS", "$."], "meter": "+-++--+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.63": {"text": "Oh, erbarmt Euch des bittern Schmerzes! Er t\u00f6tete gestern", "tokens": ["Oh", ",", "er\u00b7barmt", "Euch", "des", "bit\u00b7tern", "Schmer\u00b7zes", "!", "Er", "t\u00f6\u00b7te\u00b7te", "ge\u00b7stern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "ADV"], "meter": "+-+--+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.64": {"text": "Meine Tochter, es haben die Hunde den Leichnam gerettet.", "tokens": ["Mei\u00b7ne", "Toch\u00b7ter", ",", "es", "ha\u00b7ben", "die", "Hun\u00b7de", "den", "Leich\u00b7nam", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.65": {"text": "Seht, hier liegt sie! Er hat es getan, oh! nehmt es zu Herzen!\u00ab", "tokens": ["Seht", ",", "hier", "liegt", "sie", "!", "Er", "hat", "es", "ge\u00b7tan", ",", "oh", "!", "nehmt", "es", "zu", "Her\u00b7zen", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$,", "ADV", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "PPER", "VVPP", "$,", "FM", "$.", "VVFIN", "PPER", "APPR", "NN", "$.", "$("], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}}, "stanza.19": {"line.1": {"text": "Und der K\u00f6nig begann: \u00bbKommt n\u00e4her, Grimbart, und sehet,", "tokens": ["Und", "der", "K\u00f6\u00b7nig", "be\u00b7gann", ":", "\u00bb", "Kommt", "n\u00e4\u00b7her", ",", "Grim\u00b7bart", ",", "und", "se\u00b7het", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$.", "$(", "VVIMP", "ADJD", "$,", "NE", "$,", "KON", "VVFIN", "$,"], "meter": "--+--+-+-++-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Also fastet der Klausner, und so beweist er die Bu\u00dfe!", "tokens": ["Al\u00b7so", "fas\u00b7tet", "der", "Klaus\u00b7ner", ",", "und", "so", "be\u00b7weist", "er", "die", "Bu\u00b7\u00dfe", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KON", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Leb ich noch aber ein Jahr, so soll es ihn wahrlich gereuen!", "tokens": ["Leb", "ich", "noch", "a\u00b7ber", "ein", "Jahr", ",", "so", "soll", "es", "ihn", "wahr\u00b7lich", "ge\u00b7reu\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "ART", "NN", "$,", "ADV", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Doch was helfen die Worte! Vernehmet, trauriger Henning:", "tokens": ["Doch", "was", "hel\u00b7fen", "die", "Wor\u00b7te", "!", "Ver\u00b7neh\u00b7met", ",", "trau\u00b7ri\u00b7ger", "Hen\u00b7ning", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ART", "NN", "$.", "VVFIN", "$,", "ADJA", "NN", "$."], "meter": "+-+--+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Eurer Tochter ermangl' es an nichts, was irgend den Toten", "tokens": ["Eu\u00b7rer", "Toch\u00b7ter", "er\u00b7mangl'", "es", "an", "nichts", ",", "was", "ir\u00b7gend", "den", "To\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "PIS", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.6": {"text": "Nur zu Rechte geschieht. Ich la\u00df ihr Vigilie singen,", "tokens": ["Nur", "zu", "Rech\u00b7te", "ge\u00b7schieht", ".", "Ich", "la\u00df", "ihr", "Vi\u00b7gi\u00b7lie", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Sie mit gro\u00dfer Ehre zur Erde bestatten; dann wollen", "tokens": ["Sie", "mit", "gro\u00b7\u00dfer", "Eh\u00b7re", "zur", "Er\u00b7de", "be\u00b7stat\u00b7ten", ";", "dann", "wol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "APPR", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$.", "ADV", "VMFIN"], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Wir mit diesen Herren des Mordes Strafe bedenken.\u00ab", "tokens": ["Wir", "mit", "die\u00b7sen", "Her\u00b7ren", "des", "Mor\u00b7des", "Stra\u00b7fe", "be\u00b7den\u00b7ken", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "APPR", "PDAT", "NN", "ART", "NN", "NN", "VVINF", "$.", "$("], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.20": {"line.1": {"text": "Da gebot der K\u00f6nig, man solle Vigilie singen.", "tokens": ["Da", "ge\u00b7bot", "der", "K\u00f6\u00b7nig", ",", "man", "sol\u00b7le", "Vi\u00b7gi\u00b7lie", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "PIS", "PIAT", "NN", "VVINF", "$."], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Domino placebo begann die Gemeine, sie sangen", "tokens": ["Do\u00b7mi\u00b7no", "pla\u00b7ce\u00b7bo", "be\u00b7gann", "die", "Ge\u00b7mei\u00b7ne", ",", "sie", "san\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "NE", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN"], "meter": "+--+-+-+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Alle Verse davon. Ich k\u00f6nnte ferner erz\u00e4hlen,", "tokens": ["Al\u00b7le", "Ver\u00b7se", "da\u00b7von", ".", "Ich", "k\u00f6nn\u00b7te", "fer\u00b7ner", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKVZ", "$.", "PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.4": {"text": "Wer die Lektion gesungen und wer die Responsen;", "tokens": ["Wer", "die", "Lek\u00b7ti\u00b7on", "ge\u00b7sun\u00b7gen", "und", "wer", "die", "Res\u00b7pon\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVPP", "KON", "PWS", "ART", "NN", "$."], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}, "line.5": {"text": "Aber es w\u00e4hrte zu lang, ich la\u00df es lieber bewenden.", "tokens": ["A\u00b7ber", "es", "w\u00e4hr\u00b7te", "zu", "lang", ",", "ich", "la\u00df", "es", "lie\u00b7ber", "be\u00b7wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKA", "ADJD", "$,", "PPER", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.6": {"text": "In ein Grab ward die Leiche gelegt und dr\u00fcber ein sch\u00f6ner", "tokens": ["In", "ein", "Grab", "ward", "die", "Lei\u00b7che", "ge\u00b7legt", "und", "dr\u00fc\u00b7ber", "ein", "sch\u00f6\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "NN", "VVPP", "KON", "PAV", "ART", "ADJA"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.7": {"text": "Marmorstein, poliert wie ein Glas, gehauen im Viereck,", "tokens": ["Mar\u00b7mor\u00b7stein", ",", "po\u00b7liert", "wie", "ein", "Glas", ",", "ge\u00b7hau\u00b7en", "im", "Vier\u00b7eck", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "KOKOM", "ART", "NN", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.8": {"text": "Gro\u00df und dick, und oben darauf war deutlich zu lesen:", "tokens": ["Gro\u00df", "und", "dick", ",", "und", "o\u00b7ben", "da\u00b7rauf", "war", "deut\u00b7lich", "zu", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$,", "KON", "ADV", "PAV", "VAFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.9": {"text": "\u00bbkratzefu\u00df, Tochter Hennings des Hahns, die beste der Hennen,", "tokens": ["\u00bb", "krat\u00b7ze\u00b7fu\u00df", ",", "Toch\u00b7ter", "Hen\u00b7nings", "des", "Hahns", ",", "die", "bes\u00b7te", "der", "Hen\u00b7nen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "NN", "NE", "ART", "NN", "$,", "ART", "ADJA", "ART", "NN", "$,"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.10": {"text": "Legte viel Eier ins Nest und wu\u00dfte kl\u00fcglich zu scharren.", "tokens": ["Leg\u00b7te", "viel", "Ei\u00b7er", "ins", "Nest", "und", "wu\u00df\u00b7te", "kl\u00fcg\u00b7lich", "zu", "schar\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPRART", "NN", "KON", "VVFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.11": {"text": "Ach, hier liegt sie! durch Reinekens Mord den Ihren genommen.", "tokens": ["Ach", ",", "hier", "liegt", "sie", "!", "durch", "Rei\u00b7ne\u00b7kens", "Mord", "den", "Ih\u00b7ren", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PPER", "$.", "APPR", "NN", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.12": {"text": "Alle Welt soll erfahren, wie b\u00f6s und falsch er gehandelt,", "tokens": ["Al\u00b7le", "Welt", "soll", "er\u00b7fah\u00b7ren", ",", "wie", "b\u00f6s", "und", "falsch", "er", "ge\u00b7han\u00b7delt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "VVINF", "$,", "PWAV", "ADJD", "KON", "ADJD", "PPER", "VVPP", "$,"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.13": {"text": "Und die Tote beklagen.\u00ab So lautete, was man geschrieben.", "tokens": ["Und", "die", "To\u00b7te", "be\u00b7kla\u00b7gen", ".", "\u00ab", "So", "lau\u00b7te\u00b7te", ",", "was", "man", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$.", "$(", "ADV", "VVFIN", "$,", "PRELS", "PIS", "VVPP", "$."], "meter": "--+--+--+-+-+-+-", "measure": "anapaest.tri.plus"}, "line.14": {"text": "Rat mit ihnen zu halten, wie er den Frevel bestrafte,", "tokens": ["Rat", "mit", "ih\u00b7nen", "zu", "hal\u00b7ten", ",", "wie", "er", "den", "Fre\u00b7vel", "be\u00b7straf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PTKZU", "VVINF", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.15": {"text": "Der so kl\u00e4rlich vor ihn und seine Herren gebracht war.", "tokens": ["Der", "so", "kl\u00e4r\u00b7lich", "vor", "ihn", "und", "sei\u00b7ne", "Her\u00b7ren", "ge\u00b7bracht", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "APPR", "PPER", "KON", "PPOSAT", "NN", "VVPP", "VAFIN", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.16": {"text": "Und sie rieten zuletzt: man habe dem listigen Frevler", "tokens": ["Und", "sie", "rie\u00b7ten", "zu\u00b7letzt", ":", "man", "ha\u00b7be", "dem", "lis\u00b7ti\u00b7gen", "Frev\u00b7ler"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$.", "PIS", "VAFIN", "ART", "ADJA", "NN"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.17": {"text": "Einen Boten zu senden, da\u00df er um Liebes und Leides", "tokens": ["Ei\u00b7nen", "Bo\u00b7ten", "zu", "sen\u00b7den", ",", "da\u00df", "er", "um", "Lie\u00b7bes", "und", "Lei\u00b7des"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "KOUS", "PPER", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.18": {"text": "Nicht sich entz\u00f6ge, er solle sich stellen am Hofe des K\u00f6nigs", "tokens": ["Nicht", "sich", "ent\u00b7z\u00f6\u00b7ge", ",", "er", "sol\u00b7le", "sich", "stel\u00b7len", "am", "Ho\u00b7fe", "des", "K\u00f6\u00b7nigs"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "PRF", "VVFIN", "$,", "PPER", "VMFIN", "PRF", "VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.19": {"text": "An dem Tage der Herrn, wenn sie zun\u00e4chst sich versammeln;", "tokens": ["An", "dem", "Ta\u00b7ge", "der", "Herrn", ",", "wenn", "sie", "zu\u00b7n\u00e4chst", "sich", "ver\u00b7sam\u00b7meln", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "KOUS", "PPER", "ADV", "PRF", "VVINF", "$."], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.20": {"text": "Braun, den B\u00e4ren, ernannte man aber zum Boten. Der K\u00f6nig", "tokens": ["Braun", ",", "den", "B\u00e4\u00b7ren", ",", "er\u00b7nann\u00b7te", "man", "a\u00b7ber", "zum", "Bo\u00b7ten", ".", "Der", "K\u00f6\u00b7nig"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "$,", "ART", "NN", "$,", "VVFIN", "PIS", "ADV", "APPRART", "NN", "$.", "ART", "NN"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.21": {"text": "Sprach zu Braun, dem B\u00e4ren: \u00bbIch sag es, Euer Gebieter,", "tokens": ["Sprach", "zu", "Braun", ",", "dem", "B\u00e4\u00b7ren", ":", "\u00bb", "Ich", "sag", "es", ",", "Eu\u00b7er", "Ge\u00b7bie\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$,", "ART", "NN", "$.", "$(", "PPER", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.22": {"text": "Da\u00df Ihr mit Flei\u00df die Botschaft verrichtet! Doch rat ich zur Vorsicht:", "tokens": ["Da\u00df", "Ihr", "mit", "Flei\u00df", "die", "Bot\u00b7schaft", "ver\u00b7rich\u00b7tet", "!", "Doch", "rat", "ich", "zur", "Vor\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ART", "NN", "VVPP", "$.", "KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "---+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Denn es ist Reineke falsch und boshaft, allerlei Listen", "tokens": ["Denn", "es", "ist", "Rei\u00b7ne\u00b7ke", "falsch", "und", "bos\u00b7haft", ",", "al\u00b7ler\u00b7lei", "Lis\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "NN", "ADJD", "KON", "ADJD", "$,", "PIAT", "NN"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.24": {"text": "Wird er gebrauchen, er wird Euch schmeicheln, er wird Euch bel\u00fcgen,", "tokens": ["Wird", "er", "ge\u00b7brau\u00b7chen", ",", "er", "wird", "Euch", "schmei\u00b7cheln", ",", "er", "wird", "Euch", "be\u00b7l\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVINF", "$,", "PPER", "VAFIN", "PPER", "VVINF", "$,", "PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.25": {"text": "Hintergehen, wie er nur kann.\u00ab \u2013 \u00bbMitnichten\u00ab, versetzte", "tokens": ["Hin\u00b7ter\u00b7ge\u00b7hen", ",", "wie", "er", "nur", "kann", ".", "\u00ab", "\u2013", "\u00bb", "Mit\u00b7nich\u00b7ten", "\u00ab", ",", "ver\u00b7setz\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "word"], "pos": ["VVIZU", "$,", "PWAV", "PPER", "ADV", "VMFIN", "$.", "$(", "$(", "$(", "NN", "$(", "$,", "VVFIN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.26": {"text": "Zuversichtlich der B\u00e4r, \u00bbbleibt ruhig! Sollt er sich irgend", "tokens": ["Zu\u00b7ver\u00b7sicht\u00b7lich", "der", "B\u00e4r", ",", "\u00bb", "bleibt", "ru\u00b7hig", "!", "Sollt", "er", "sich", "ir\u00b7gend"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "$(", "VVFIN", "ADJD", "$.", "VMFIN", "PPER", "PRF", "ADV"], "meter": "+-+--++--+--+-", "measure": "trochaic.hexa.relaxed"}, "line.27": {"text": "Nur vermessen und mir zum Hohne das mindeste wagen,", "tokens": ["Nur", "ver\u00b7mes\u00b7sen", "und", "mir", "zum", "Hoh\u00b7ne", "das", "min\u00b7des\u00b7te", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "KON", "PPER", "APPRART", "NN", "ART", "ADJA", "VVINF", "$,"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.28": {"text": "Seht, ich schw\u00f6r es bei Gott! der m\u00f6ge mich strafen, wofern ich", "tokens": ["Seht", ",", "ich", "schw\u00f6r", "es", "bei", "Gott", "!", "der", "m\u00f6\u00b7ge", "mich", "stra\u00b7fen", ",", "wo\u00b7fern", "ich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "VVFIN", "PPER", "APPR", "NN", "$.", "ART", "VMFIN", "PPER", "VVFIN", "$,", "KOUS", "PPER"], "meter": "--+--+-+--+-+-+", "measure": "anapaest.di.plus"}, "line.29": {"text": "Ihm nicht grimmig verg\u00f6lte, da\u00df er zu bleiben nicht w\u00fc\u00dfte.\u00ab", "tokens": ["Ihm", "nicht", "grim\u00b7mig", "ver\u00b7g\u00f6l\u00b7te", ",", "da\u00df", "er", "zu", "blei\u00b7ben", "nicht", "w\u00fc\u00df\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PTKNEG", "ADJD", "VVFIN", "$,", "KOUS", "PPER", "PTKZU", "VVINF", "PTKNEG", "VVFIN", "$.", "$("], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}}}}}