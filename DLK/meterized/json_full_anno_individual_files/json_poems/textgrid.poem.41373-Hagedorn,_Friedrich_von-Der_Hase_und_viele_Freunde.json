{"textgrid.poem.41373": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der Hase und viele Freunde", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wo soll man \u00e4chte Freundschaft finden?", "tokens": ["Wo", "soll", "man", "\u00e4ch\u00b7te", "Freund\u00b7schaft", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIS", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Lockwort klingt doch gar zu fein,", "tokens": ["Das", "Lock\u00b7wort", "klingt", "doch", "gar", "zu", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kann, die Herzen zu verbinden,", "tokens": ["Und", "kann", ",", "die", "Her\u00b7zen", "zu", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Anla\u00df sch\u00f6nster Hoffnung sein.", "tokens": ["Der", "An\u00b7la\u00df", "sch\u00f6ns\u00b7ter", "Hoff\u00b7nung", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man pflegt den milden Stein der Weisen", "tokens": ["Man", "pflegt", "den", "mil\u00b7den", "Stein", "der", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Uns, als ein Wunder, anzupreisen.", "tokens": ["Uns", ",", "als", "ein", "Wun\u00b7der", ",", "an\u00b7zu\u00b7prei\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "$,", "KOUS", "ART", "NN", "$,", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man lehrt, er mache mehr, als reich:", "tokens": ["Man", "lehrt", ",", "er", "ma\u00b7che", "mehr", ",", "als", "reich", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "$,", "KOUS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "F\u00fcrwahr, ihm ist die Freundschaft gleich.", "tokens": ["F\u00fcr\u00b7wahr", ",", "ihm", "ist", "die", "Freund\u00b7schaft", "gleich", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ein jeder, der in diesen Jahren", "tokens": ["Ein", "je\u00b7der", ",", "der", "in", "die\u00b7sen", "Jah\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "$,", "PRELS", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mir ohne Lachen widerspricht,", "tokens": ["Mir", "oh\u00b7ne", "La\u00b7chen", "wi\u00b7der\u00b7spricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist gl\u00fccklich, falls er nicht erfahren,", "tokens": ["Ist", "gl\u00fcck\u00b7lich", ",", "falls", "er", "nicht", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "KOUS", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie oft man Treu' und Glauben bricht.", "tokens": ["Wie", "oft", "man", "Treu'", "und", "Glau\u00b7ben", "bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIS", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wird er den Vorzug nur erwerben,", "tokens": ["Wird", "er", "den", "Vor\u00b7zug", "nur", "er\u00b7wer\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In diesem s\u00fc\u00dfen Wahn zu sterben;", "tokens": ["In", "die\u00b7sem", "s\u00fc\u00b7\u00dfen", "Wahn", "zu", "ster\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So soll einst seines Grabes Stein", "tokens": ["So", "soll", "einst", "sei\u00b7nes", "Gra\u00b7bes", "Stein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Welt ein seltnes Denkmal sein.", "tokens": ["Der", "Welt", "ein", "selt\u00b7nes", "Denk\u00b7mal", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein H\u00e4schen von beliebten Sitten,", "tokens": ["Ein", "H\u00e4\u00b7schen", "von", "be\u00b7lieb\u00b7ten", "Sit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein kleines Thier von schneller Kunst,", "tokens": ["Ein", "klei\u00b7nes", "Thier", "von", "schnel\u00b7ler", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erhielt durch Schmeicheln und durch Bitten", "tokens": ["Er\u00b7hielt", "durch", "Schmei\u00b7cheln", "und", "durch", "Bit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verschiedner Thiere Lob und Gunst.", "tokens": ["Ver\u00b7schied\u00b7ner", "Thie\u00b7re", "Lob", "und", "Gunst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Hasen hatten ja vorzeiten", "tokens": ["Die", "Ha\u00b7sen", "hat\u00b7ten", "ja", "vor\u00b7zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Weit mehr, als jetzo, zu bedeuten.", "tokens": ["Weit", "mehr", ",", "als", "jet\u00b7zo", ",", "zu", "be\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "KOUS", "ADV", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Als keiner unsern Stutzern glich,", "tokens": ["Als", "kei\u00b7ner", "un\u00b7sern", "Stut\u00b7zern", "glich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da war auch keiner l\u00e4cherlich.", "tokens": ["Da", "war", "auch", "kei\u00b7ner", "l\u00e4\u00b7cher\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Er wandte sich zu allen Freunden,", "tokens": ["Er", "wand\u00b7te", "sich", "zu", "al\u00b7len", "Freun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Um ihren Beitritt zu erflehn,", "tokens": ["Um", "ih\u00b7ren", "Bei\u00b7tritt", "zu", "er\u00b7flehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Hunden, seinen \u00e4rgsten Feinden,", "tokens": ["Den", "Hun\u00b7den", ",", "sei\u00b7nen", "\u00e4rgs\u00b7ten", "Fein\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu steuren, oder zu entgehn.", "tokens": ["Zu", "steu\u00b7ren", ",", "o\u00b7der", "zu", "ent\u00b7gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man sprach: Dein Leben zu erhalten", "tokens": ["Man", "sprach", ":", "Dein", "Le\u00b7ben", "zu", "er\u00b7hal\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$.", "PPOSAT", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Soll unser Eifer nie erkalten;", "tokens": ["Soll", "un\u00b7ser", "Ei\u00b7fer", "nie", "er\u00b7kal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der deinem Balg ein H\u00e4rchen kr\u00fcmmt,", "tokens": ["Der", "dei\u00b7nem", "Balg", "ein", "H\u00e4r\u00b7chen", "kr\u00fcmmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dem ist von uns der Tod bestimmt.", "tokens": ["Dem", "ist", "von", "uns", "der", "Tod", "be\u00b7stimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der muntre H\u00e4nsel ist zufrieden,", "tokens": ["Der", "mun\u00b7tre", "H\u00e4n\u00b7sel", "ist", "zu\u00b7frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und sch\u00e4tzt sich gro\u00dfen Hansen gleich.", "tokens": ["Und", "sch\u00e4tzt", "sich", "gro\u00b7\u00dfen", "Han\u00b7sen", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Sicherheit, die ihm beschieden,", "tokens": ["Die", "Si\u00b7cher\u00b7heit", ",", "die", "ihm", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vertauscht er um kein K\u00f6nigreich.", "tokens": ["Ver\u00b7tauscht", "er", "um", "kein", "K\u00f6\u00b7nig\u00b7reich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihn will so mancher Beistand sch\u00fctzen;", "tokens": ["Ihn", "will", "so", "man\u00b7cher", "Bei\u00b7stand", "sch\u00fct\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was darf er nun in Aengsten sitzen?", "tokens": ["Was", "darf", "er", "nun", "in", "A\u00b7engs\u00b7ten", "sit\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "APPR", "NE", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Nein, unter vieler Starken Hut", "tokens": ["Nein", ",", "un\u00b7ter", "vie\u00b7ler", "Star\u00b7ken", "Hut"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "APPR", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Fehlt es auch Hasen nicht an Muth.", "tokens": ["Fehlt", "es", "auch", "Ha\u00b7sen", "nicht", "an", "Muth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NN", "PTKNEG", "APPR", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Er lebet ohne Noth und Sorgen,", "tokens": ["Er", "le\u00b7bet", "oh\u00b7ne", "Noth", "und", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So unverzagt, als ungest\u00f6rt,", "tokens": ["So", "un\u00b7ver\u00b7zagt", ",", "als", "un\u00b7ge\u00b7st\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weil sich mit jedem sch\u00f6nen Morgen,", "tokens": ["Weil", "sich", "mit", "je\u00b7dem", "sch\u00f6\u00b7nen", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit jedem Thau sein Fr\u00fchst\u00fcck mehrt.", "tokens": ["Mit", "je\u00b7dem", "Thau", "sein", "Fr\u00fch\u00b7st\u00fcck", "mehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sein rascher Lauf verl\u00e4\u00dft die W\u00e4lder,", "tokens": ["Sein", "ra\u00b7scher", "Lauf", "ver\u00b7l\u00e4\u00dft", "die", "W\u00e4l\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durchstreicht die Triften und die Felder,", "tokens": ["Durch\u00b7streicht", "die", "Trif\u00b7ten", "und", "die", "Fel\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Wo in begl\u00fcckter Sicherheit", "tokens": ["Wo", "in", "be\u00b7gl\u00fcck\u00b7ter", "Si\u00b7cher\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ihn Gras und Laub und Frucht erfreut.", "tokens": ["Ihn", "Gras", "und", "Laub", "und", "Frucht", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wie oft verg\u00e4llt erw\u00fcnschte Stunden", "tokens": ["Wie", "oft", "ver\u00b7g\u00e4llt", "er\u00b7w\u00fcnschte", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Verha\u00dfter Stunden Ungemach!", "tokens": ["Ver\u00b7ha\u00df\u00b7ter", "Stun\u00b7den", "Un\u00b7ge\u00b7mach", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein J\u00e4ger eilt mit schlauen Hunden", "tokens": ["Ein", "J\u00e4\u00b7ger", "eilt", "mit", "schlau\u00b7en", "Hun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Spur des armen H\u00e4nsels nach.", "tokens": ["Der", "Spur", "des", "ar\u00b7men", "H\u00e4n\u00b7sels", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hier ist kein Freund, ihm jetzt zu rathen:", "tokens": ["Hier", "ist", "kein", "Freund", ",", "ihm", "jetzt", "zu", "ra\u00b7then", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Er f\u00e4hrt, er l\u00e4uft durch Busch und Saaten,", "tokens": ["Er", "f\u00e4hrt", ",", "er", "l\u00e4uft", "durch", "Busch", "und", "Saa\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Er dr\u00fcckt sich oft, so gut er kann;", "tokens": ["Er", "dr\u00fcckt", "sich", "oft", ",", "so", "gut", "er", "kann", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "$,", "ADV", "ADJD", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch alle Hunde schlagen an.", "tokens": ["Doch", "al\u00b7le", "Hun\u00b7de", "schla\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Er rennt, und setzt durch Forst und Stege:", "tokens": ["Er", "rennt", ",", "und", "setzt", "durch", "Forst", "und", "Ste\u00b7ge", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Absprung aber hilft ihm nicht.", "tokens": ["Sein", "Ab\u00b7sprung", "a\u00b7ber", "hilft", "ihm", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch endlich k\u00f6mmt, auf einem Wege,", "tokens": ["Doch", "end\u00b7lich", "k\u00f6mmt", ",", "auf", "ei\u00b7nem", "We\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Freund, das Pferd, ihm zu Gesicht.", "tokens": ["Sein", "Freund", ",", "das", "Pferd", ",", "ihm", "zu", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "$,", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er sagt: Dies tolle Hetzenreuten", "tokens": ["Er", "sagt", ":", "Dies", "tol\u00b7le", "Het\u00b7zen\u00b7reu\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Scheint meinen Tod mir anzudeuten.", "tokens": ["Scheint", "mei\u00b7nen", "Tod", "mir", "an\u00b7zu\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch nimmt mich nur dein R\u00fccken auf,", "tokens": ["Doch", "nimmt", "mich", "nur", "dein", "R\u00fc\u00b7cken", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So sp\u00fcrt kein St\u00f6ber meinen Lauf.", "tokens": ["So", "sp\u00fcrt", "kein", "St\u00f6\u00b7ber", "mei\u00b7nen", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Das Pferd versetzt: Mein Herr, ich sehe", "tokens": ["Das", "Pferd", "ver\u00b7setzt", ":", "Mein", "Herr", ",", "ich", "se\u00b7he"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVPP", "$.", "PPOSAT", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des Unfalls Gr\u00f6\u00dfe noch nicht ein.", "tokens": ["Des", "Un\u00b7falls", "Gr\u00f6\u00b7\u00dfe", "noch", "nicht", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So mancher Freund ist in der N\u00e4he,", "tokens": ["So", "man\u00b7cher", "Freund", "ist", "in", "der", "N\u00e4\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und jeder wird behilflich sein.", "tokens": ["Und", "je\u00b7der", "wird", "be\u00b7hilf\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Treu' erleichtert M\u00fch' und B\u00fcrde;", "tokens": ["Die", "Treu'", "er\u00b7leich\u00b7tert", "M\u00fch'", "und", "B\u00fcr\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie wissen, wie ich dienen w\u00fcrde:", "tokens": ["Sie", "wis\u00b7sen", ",", "wie", "ich", "die\u00b7nen", "w\u00fcr\u00b7de", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So aber wohnt nicht weit von hier", "tokens": ["So", "a\u00b7ber", "wohnt", "nicht", "weit", "von", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PTKNEG", "ADJD", "APPR", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein ungleich st\u00e4rkrer Freund, der Stier.", "tokens": ["Ein", "un\u00b7gleich", "st\u00e4r\u00b7krer", "Freund", ",", "der", "Stier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Er eilt durch Haide, Busch und Hecken,", "tokens": ["Er", "eilt", "durch", "Hai\u00b7de", ",", "Busch", "und", "He\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und fleht den Stier um Rettung an.", "tokens": ["Und", "fleht", "den", "Stier", "um", "Ret\u00b7tung", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der spricht: Ich will nur frei entdecken,", "tokens": ["Der", "spricht", ":", "Ich", "will", "nur", "frei", "ent\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "PPER", "VMFIN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Warum ich dir nicht helfen kann.", "tokens": ["Wa\u00b7rum", "ich", "dir", "nicht", "hel\u00b7fen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du kennest meiner Freundschaft Triebe;", "tokens": ["Du", "ken\u00b7nest", "mei\u00b7ner", "Freund\u00b7schaft", "Trie\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jedoch die Freundschaft weicht der Liebe.", "tokens": ["Je\u00b7doch", "die", "Freund\u00b7schaft", "weicht", "der", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dort l\u00e4\u00dft sich meine Sch\u00f6ne sehn.", "tokens": ["Dort", "l\u00e4\u00dft", "sich", "mei\u00b7ne", "Sch\u00f6\u00b7ne", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du mu\u00dft zu jener Ziege gehn.", "tokens": ["Du", "mu\u00dft", "zu", "je\u00b7ner", "Zie\u00b7ge", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Die Ziege h\u00f6rt des Hasen Klagen,", "tokens": ["Die", "Zie\u00b7ge", "h\u00f6rt", "des", "Ha\u00b7sen", "Kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit angenommner Traurigkeit,", "tokens": ["Mit", "an\u00b7ge\u00b7nomm\u00b7ner", "Trau\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und h\u00e4lt, ihm alles abzuschlagen,", "tokens": ["Und", "h\u00e4lt", ",", "ihm", "al\u00b7les", "ab\u00b7zu\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "PIS", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich zu der Ausflucht schon bereit.", "tokens": ["Sich", "zu", "der", "Aus\u00b7flucht", "schon", "be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie meckert: Dich jetzt aufzunehmen,", "tokens": ["Sie", "me\u00b7ckert", ":", "Dich", "jetzt", "auf\u00b7zu\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wird jenes Schaf sich bald bequemen.", "tokens": ["Wird", "je\u00b7nes", "Schaf", "sich", "bald", "be\u00b7que\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "PRF", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dir ist ja seine Gutheit kund.", "tokens": ["Dir", "ist", "ja", "sei\u00b7ne", "Gut\u00b7heit", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mir, leider! ist der R\u00fccken wund.", "tokens": ["Mir", ",", "lei\u00b7der", "!", "ist", "der", "R\u00fc\u00b7cken", "wund", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "$.", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Der Arme flieht mit bangen Schritten,", "tokens": ["Der", "Ar\u00b7me", "flieht", "mit", "ban\u00b7gen", "Schrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sucht, und erreicht das ferne Schaf,", "tokens": ["Sucht", ",", "und", "er\u00b7reicht", "das", "fer\u00b7ne", "Schaf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das, unbewegt bei seinen Bitten,", "tokens": ["Das", ",", "un\u00b7be\u00b7wegt", "bei", "sei\u00b7nen", "Bit\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An Furcht den Fl\u00fcchtling \u00fcbertraf.", "tokens": ["An", "Furcht", "den", "Fl\u00fccht\u00b7ling", "\u00fc\u00b7bert\u00b7raf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es klagt: Vor Feinden dich zu sch\u00fctzen,", "tokens": ["Es", "klagt", ":", "Vor", "Fein\u00b7den", "dich", "zu", "sch\u00fct\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wird meine Schw\u00e4che wenig n\u00fctzen.", "tokens": ["Wird", "mei\u00b7ne", "Schw\u00e4\u00b7che", "we\u00b7nig", "n\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ich zittre ja so sehr, als du;", "tokens": ["Ich", "zitt\u00b7re", "ja", "so", "sehr", ",", "als", "du", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "$,", "KOUS", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch eile jenem F\u00fcllen zu.", "tokens": ["Doch", "ei\u00b7le", "je\u00b7nem", "F\u00fcl\u00b7len", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Das sprach: Wenn wir jetzt Beistand h\u00e4tten,", "tokens": ["Das", "sprach", ":", "Wenn", "wir", "jetzt", "Bei\u00b7stand", "h\u00e4t\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "KOUS", "PPER", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So trotzt' ich gerne der Gewalt.", "tokens": ["So", "trotzt'", "ich", "ger\u00b7ne", "der", "Ge\u00b7walt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bin zu jung, dich zu erretten,", "tokens": ["Ich", "bin", "zu", "jung", ",", "dich", "zu", "er\u00b7ret\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und mein Herr Vater ist zu alt.", "tokens": ["Und", "mein", "Herr", "Va\u00b7ter", "ist", "zu", "alt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VAFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich sehe schon die Hunde kommen:", "tokens": ["Ich", "se\u00b7he", "schon", "die", "Hun\u00b7de", "kom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nur frischen Muth und Lauf genommen!", "tokens": ["Nur", "fri\u00b7schen", "Muth", "und", "Lauf", "ge\u00b7nom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch, wenn dein Tod uns trennen soll,", "tokens": ["Doch", ",", "wenn", "dein", "Tod", "uns", "tren\u00b7nen", "soll", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPOSAT", "NN", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Geliebter H\u00e4nsel, fahre wohl!", "tokens": ["Ge\u00b7lieb\u00b7ter", "H\u00e4n\u00b7sel", ",", "fah\u00b7re", "wohl", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wo soll man \u00e4chte Freundschaft finden?", "tokens": ["Wo", "soll", "man", "\u00e4ch\u00b7te", "Freund\u00b7schaft", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIS", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Lockwort klingt doch gar zu fein,", "tokens": ["Das", "Lock\u00b7wort", "klingt", "doch", "gar", "zu", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kann, die Herzen zu verbinden,", "tokens": ["Und", "kann", ",", "die", "Her\u00b7zen", "zu", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Anla\u00df sch\u00f6nster Hoffnung sein.", "tokens": ["Der", "An\u00b7la\u00df", "sch\u00f6ns\u00b7ter", "Hoff\u00b7nung", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man pflegt den milden Stein der Weisen", "tokens": ["Man", "pflegt", "den", "mil\u00b7den", "Stein", "der", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Uns, als ein Wunder, anzupreisen.", "tokens": ["Uns", ",", "als", "ein", "Wun\u00b7der", ",", "an\u00b7zu\u00b7prei\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "$,", "KOUS", "ART", "NN", "$,", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man lehrt, er mache mehr, als reich:", "tokens": ["Man", "lehrt", ",", "er", "ma\u00b7che", "mehr", ",", "als", "reich", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "$,", "KOUS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "F\u00fcrwahr, ihm ist die Freundschaft gleich.", "tokens": ["F\u00fcr\u00b7wahr", ",", "ihm", "ist", "die", "Freund\u00b7schaft", "gleich", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Ein jeder, der in diesen Jahren", "tokens": ["Ein", "je\u00b7der", ",", "der", "in", "die\u00b7sen", "Jah\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "$,", "PRELS", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mir ohne Lachen widerspricht,", "tokens": ["Mir", "oh\u00b7ne", "La\u00b7chen", "wi\u00b7der\u00b7spricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist gl\u00fccklich, falls er nicht erfahren,", "tokens": ["Ist", "gl\u00fcck\u00b7lich", ",", "falls", "er", "nicht", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "KOUS", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie oft man Treu' und Glauben bricht.", "tokens": ["Wie", "oft", "man", "Treu'", "und", "Glau\u00b7ben", "bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIS", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wird er den Vorzug nur erwerben,", "tokens": ["Wird", "er", "den", "Vor\u00b7zug", "nur", "er\u00b7wer\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In diesem s\u00fc\u00dfen Wahn zu sterben;", "tokens": ["In", "die\u00b7sem", "s\u00fc\u00b7\u00dfen", "Wahn", "zu", "ster\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So soll einst seines Grabes Stein", "tokens": ["So", "soll", "einst", "sei\u00b7nes", "Gra\u00b7bes", "Stein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Welt ein seltnes Denkmal sein.", "tokens": ["Der", "Welt", "ein", "selt\u00b7nes", "Denk\u00b7mal", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Ein H\u00e4schen von beliebten Sitten,", "tokens": ["Ein", "H\u00e4\u00b7schen", "von", "be\u00b7lieb\u00b7ten", "Sit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein kleines Thier von schneller Kunst,", "tokens": ["Ein", "klei\u00b7nes", "Thier", "von", "schnel\u00b7ler", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erhielt durch Schmeicheln und durch Bitten", "tokens": ["Er\u00b7hielt", "durch", "Schmei\u00b7cheln", "und", "durch", "Bit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verschiedner Thiere Lob und Gunst.", "tokens": ["Ver\u00b7schied\u00b7ner", "Thie\u00b7re", "Lob", "und", "Gunst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Hasen hatten ja vorzeiten", "tokens": ["Die", "Ha\u00b7sen", "hat\u00b7ten", "ja", "vor\u00b7zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Weit mehr, als jetzo, zu bedeuten.", "tokens": ["Weit", "mehr", ",", "als", "jet\u00b7zo", ",", "zu", "be\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "KOUS", "ADV", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Als keiner unsern Stutzern glich,", "tokens": ["Als", "kei\u00b7ner", "un\u00b7sern", "Stut\u00b7zern", "glich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da war auch keiner l\u00e4cherlich.", "tokens": ["Da", "war", "auch", "kei\u00b7ner", "l\u00e4\u00b7cher\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Er wandte sich zu allen Freunden,", "tokens": ["Er", "wand\u00b7te", "sich", "zu", "al\u00b7len", "Freun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Um ihren Beitritt zu erflehn,", "tokens": ["Um", "ih\u00b7ren", "Bei\u00b7tritt", "zu", "er\u00b7flehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Hunden, seinen \u00e4rgsten Feinden,", "tokens": ["Den", "Hun\u00b7den", ",", "sei\u00b7nen", "\u00e4rgs\u00b7ten", "Fein\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu steuren, oder zu entgehn.", "tokens": ["Zu", "steu\u00b7ren", ",", "o\u00b7der", "zu", "ent\u00b7gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man sprach: Dein Leben zu erhalten", "tokens": ["Man", "sprach", ":", "Dein", "Le\u00b7ben", "zu", "er\u00b7hal\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$.", "PPOSAT", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Soll unser Eifer nie erkalten;", "tokens": ["Soll", "un\u00b7ser", "Ei\u00b7fer", "nie", "er\u00b7kal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der deinem Balg ein H\u00e4rchen kr\u00fcmmt,", "tokens": ["Der", "dei\u00b7nem", "Balg", "ein", "H\u00e4r\u00b7chen", "kr\u00fcmmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dem ist von uns der Tod bestimmt.", "tokens": ["Dem", "ist", "von", "uns", "der", "Tod", "be\u00b7stimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Der muntre H\u00e4nsel ist zufrieden,", "tokens": ["Der", "mun\u00b7tre", "H\u00e4n\u00b7sel", "ist", "zu\u00b7frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und sch\u00e4tzt sich gro\u00dfen Hansen gleich.", "tokens": ["Und", "sch\u00e4tzt", "sich", "gro\u00b7\u00dfen", "Han\u00b7sen", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Sicherheit, die ihm beschieden,", "tokens": ["Die", "Si\u00b7cher\u00b7heit", ",", "die", "ihm", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vertauscht er um kein K\u00f6nigreich.", "tokens": ["Ver\u00b7tauscht", "er", "um", "kein", "K\u00f6\u00b7nig\u00b7reich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihn will so mancher Beistand sch\u00fctzen;", "tokens": ["Ihn", "will", "so", "man\u00b7cher", "Bei\u00b7stand", "sch\u00fct\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was darf er nun in Aengsten sitzen?", "tokens": ["Was", "darf", "er", "nun", "in", "A\u00b7engs\u00b7ten", "sit\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "APPR", "NE", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Nein, unter vieler Starken Hut", "tokens": ["Nein", ",", "un\u00b7ter", "vie\u00b7ler", "Star\u00b7ken", "Hut"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "APPR", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Fehlt es auch Hasen nicht an Muth.", "tokens": ["Fehlt", "es", "auch", "Ha\u00b7sen", "nicht", "an", "Muth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NN", "PTKNEG", "APPR", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.19": {"line.1": {"text": "Er lebet ohne Noth und Sorgen,", "tokens": ["Er", "le\u00b7bet", "oh\u00b7ne", "Noth", "und", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So unverzagt, als ungest\u00f6rt,", "tokens": ["So", "un\u00b7ver\u00b7zagt", ",", "als", "un\u00b7ge\u00b7st\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weil sich mit jedem sch\u00f6nen Morgen,", "tokens": ["Weil", "sich", "mit", "je\u00b7dem", "sch\u00f6\u00b7nen", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit jedem Thau sein Fr\u00fchst\u00fcck mehrt.", "tokens": ["Mit", "je\u00b7dem", "Thau", "sein", "Fr\u00fch\u00b7st\u00fcck", "mehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sein rascher Lauf verl\u00e4\u00dft die W\u00e4lder,", "tokens": ["Sein", "ra\u00b7scher", "Lauf", "ver\u00b7l\u00e4\u00dft", "die", "W\u00e4l\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durchstreicht die Triften und die Felder,", "tokens": ["Durch\u00b7streicht", "die", "Trif\u00b7ten", "und", "die", "Fel\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Wo in begl\u00fcckter Sicherheit", "tokens": ["Wo", "in", "be\u00b7gl\u00fcck\u00b7ter", "Si\u00b7cher\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ihn Gras und Laub und Frucht erfreut.", "tokens": ["Ihn", "Gras", "und", "Laub", "und", "Frucht", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Wie oft verg\u00e4llt erw\u00fcnschte Stunden", "tokens": ["Wie", "oft", "ver\u00b7g\u00e4llt", "er\u00b7w\u00fcnschte", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Verha\u00dfter Stunden Ungemach!", "tokens": ["Ver\u00b7ha\u00df\u00b7ter", "Stun\u00b7den", "Un\u00b7ge\u00b7mach", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein J\u00e4ger eilt mit schlauen Hunden", "tokens": ["Ein", "J\u00e4\u00b7ger", "eilt", "mit", "schlau\u00b7en", "Hun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Spur des armen H\u00e4nsels nach.", "tokens": ["Der", "Spur", "des", "ar\u00b7men", "H\u00e4n\u00b7sels", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hier ist kein Freund, ihm jetzt zu rathen:", "tokens": ["Hier", "ist", "kein", "Freund", ",", "ihm", "jetzt", "zu", "ra\u00b7then", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Er f\u00e4hrt, er l\u00e4uft durch Busch und Saaten,", "tokens": ["Er", "f\u00e4hrt", ",", "er", "l\u00e4uft", "durch", "Busch", "und", "Saa\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Er dr\u00fcckt sich oft, so gut er kann;", "tokens": ["Er", "dr\u00fcckt", "sich", "oft", ",", "so", "gut", "er", "kann", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "$,", "ADV", "ADJD", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch alle Hunde schlagen an.", "tokens": ["Doch", "al\u00b7le", "Hun\u00b7de", "schla\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Er rennt, und setzt durch Forst und Stege:", "tokens": ["Er", "rennt", ",", "und", "setzt", "durch", "Forst", "und", "Ste\u00b7ge", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Absprung aber hilft ihm nicht.", "tokens": ["Sein", "Ab\u00b7sprung", "a\u00b7ber", "hilft", "ihm", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch endlich k\u00f6mmt, auf einem Wege,", "tokens": ["Doch", "end\u00b7lich", "k\u00f6mmt", ",", "auf", "ei\u00b7nem", "We\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Freund, das Pferd, ihm zu Gesicht.", "tokens": ["Sein", "Freund", ",", "das", "Pferd", ",", "ihm", "zu", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "$,", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er sagt: Dies tolle Hetzenreuten", "tokens": ["Er", "sagt", ":", "Dies", "tol\u00b7le", "Het\u00b7zen\u00b7reu\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Scheint meinen Tod mir anzudeuten.", "tokens": ["Scheint", "mei\u00b7nen", "Tod", "mir", "an\u00b7zu\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch nimmt mich nur dein R\u00fccken auf,", "tokens": ["Doch", "nimmt", "mich", "nur", "dein", "R\u00fc\u00b7cken", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So sp\u00fcrt kein St\u00f6ber meinen Lauf.", "tokens": ["So", "sp\u00fcrt", "kein", "St\u00f6\u00b7ber", "mei\u00b7nen", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Das Pferd versetzt: Mein Herr, ich sehe", "tokens": ["Das", "Pferd", "ver\u00b7setzt", ":", "Mein", "Herr", ",", "ich", "se\u00b7he"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVPP", "$.", "PPOSAT", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des Unfalls Gr\u00f6\u00dfe noch nicht ein.", "tokens": ["Des", "Un\u00b7falls", "Gr\u00f6\u00b7\u00dfe", "noch", "nicht", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So mancher Freund ist in der N\u00e4he,", "tokens": ["So", "man\u00b7cher", "Freund", "ist", "in", "der", "N\u00e4\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und jeder wird behilflich sein.", "tokens": ["Und", "je\u00b7der", "wird", "be\u00b7hilf\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Treu' erleichtert M\u00fch' und B\u00fcrde;", "tokens": ["Die", "Treu'", "er\u00b7leich\u00b7tert", "M\u00fch'", "und", "B\u00fcr\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie wissen, wie ich dienen w\u00fcrde:", "tokens": ["Sie", "wis\u00b7sen", ",", "wie", "ich", "die\u00b7nen", "w\u00fcr\u00b7de", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So aber wohnt nicht weit von hier", "tokens": ["So", "a\u00b7ber", "wohnt", "nicht", "weit", "von", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PTKNEG", "ADJD", "APPR", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein ungleich st\u00e4rkrer Freund, der Stier.", "tokens": ["Ein", "un\u00b7gleich", "st\u00e4r\u00b7krer", "Freund", ",", "der", "Stier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Er eilt durch Haide, Busch und Hecken,", "tokens": ["Er", "eilt", "durch", "Hai\u00b7de", ",", "Busch", "und", "He\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und fleht den Stier um Rettung an.", "tokens": ["Und", "fleht", "den", "Stier", "um", "Ret\u00b7tung", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der spricht: Ich will nur frei entdecken,", "tokens": ["Der", "spricht", ":", "Ich", "will", "nur", "frei", "ent\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "PPER", "VMFIN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Warum ich dir nicht helfen kann.", "tokens": ["Wa\u00b7rum", "ich", "dir", "nicht", "hel\u00b7fen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du kennest meiner Freundschaft Triebe;", "tokens": ["Du", "ken\u00b7nest", "mei\u00b7ner", "Freund\u00b7schaft", "Trie\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jedoch die Freundschaft weicht der Liebe.", "tokens": ["Je\u00b7doch", "die", "Freund\u00b7schaft", "weicht", "der", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dort l\u00e4\u00dft sich meine Sch\u00f6ne sehn.", "tokens": ["Dort", "l\u00e4\u00dft", "sich", "mei\u00b7ne", "Sch\u00f6\u00b7ne", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du mu\u00dft zu jener Ziege gehn.", "tokens": ["Du", "mu\u00dft", "zu", "je\u00b7ner", "Zie\u00b7ge", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Die Ziege h\u00f6rt des Hasen Klagen,", "tokens": ["Die", "Zie\u00b7ge", "h\u00f6rt", "des", "Ha\u00b7sen", "Kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit angenommner Traurigkeit,", "tokens": ["Mit", "an\u00b7ge\u00b7nomm\u00b7ner", "Trau\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und h\u00e4lt, ihm alles abzuschlagen,", "tokens": ["Und", "h\u00e4lt", ",", "ihm", "al\u00b7les", "ab\u00b7zu\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "PIS", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich zu der Ausflucht schon bereit.", "tokens": ["Sich", "zu", "der", "Aus\u00b7flucht", "schon", "be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie meckert: Dich jetzt aufzunehmen,", "tokens": ["Sie", "me\u00b7ckert", ":", "Dich", "jetzt", "auf\u00b7zu\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wird jenes Schaf sich bald bequemen.", "tokens": ["Wird", "je\u00b7nes", "Schaf", "sich", "bald", "be\u00b7que\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "PRF", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dir ist ja seine Gutheit kund.", "tokens": ["Dir", "ist", "ja", "sei\u00b7ne", "Gut\u00b7heit", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mir, leider! ist der R\u00fccken wund.", "tokens": ["Mir", ",", "lei\u00b7der", "!", "ist", "der", "R\u00fc\u00b7cken", "wund", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "$.", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Der Arme flieht mit bangen Schritten,", "tokens": ["Der", "Ar\u00b7me", "flieht", "mit", "ban\u00b7gen", "Schrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sucht, und erreicht das ferne Schaf,", "tokens": ["Sucht", ",", "und", "er\u00b7reicht", "das", "fer\u00b7ne", "Schaf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das, unbewegt bei seinen Bitten,", "tokens": ["Das", ",", "un\u00b7be\u00b7wegt", "bei", "sei\u00b7nen", "Bit\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An Furcht den Fl\u00fcchtling \u00fcbertraf.", "tokens": ["An", "Furcht", "den", "Fl\u00fccht\u00b7ling", "\u00fc\u00b7bert\u00b7raf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es klagt: Vor Feinden dich zu sch\u00fctzen,", "tokens": ["Es", "klagt", ":", "Vor", "Fein\u00b7den", "dich", "zu", "sch\u00fct\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wird meine Schw\u00e4che wenig n\u00fctzen.", "tokens": ["Wird", "mei\u00b7ne", "Schw\u00e4\u00b7che", "we\u00b7nig", "n\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ich zittre ja so sehr, als du;", "tokens": ["Ich", "zitt\u00b7re", "ja", "so", "sehr", ",", "als", "du", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "$,", "KOUS", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch eile jenem F\u00fcllen zu.", "tokens": ["Doch", "ei\u00b7le", "je\u00b7nem", "F\u00fcl\u00b7len", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Das sprach: Wenn wir jetzt Beistand h\u00e4tten,", "tokens": ["Das", "sprach", ":", "Wenn", "wir", "jetzt", "Bei\u00b7stand", "h\u00e4t\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "KOUS", "PPER", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So trotzt' ich gerne der Gewalt.", "tokens": ["So", "trotzt'", "ich", "ger\u00b7ne", "der", "Ge\u00b7walt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bin zu jung, dich zu erretten,", "tokens": ["Ich", "bin", "zu", "jung", ",", "dich", "zu", "er\u00b7ret\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und mein Herr Vater ist zu alt.", "tokens": ["Und", "mein", "Herr", "Va\u00b7ter", "ist", "zu", "alt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VAFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich sehe schon die Hunde kommen:", "tokens": ["Ich", "se\u00b7he", "schon", "die", "Hun\u00b7de", "kom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nur frischen Muth und Lauf genommen!", "tokens": ["Nur", "fri\u00b7schen", "Muth", "und", "Lauf", "ge\u00b7nom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch, wenn dein Tod uns trennen soll,", "tokens": ["Doch", ",", "wenn", "dein", "Tod", "uns", "tren\u00b7nen", "soll", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPOSAT", "NN", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Geliebter H\u00e4nsel, fahre wohl!", "tokens": ["Ge\u00b7lieb\u00b7ter", "H\u00e4n\u00b7sel", ",", "fah\u00b7re", "wohl", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}