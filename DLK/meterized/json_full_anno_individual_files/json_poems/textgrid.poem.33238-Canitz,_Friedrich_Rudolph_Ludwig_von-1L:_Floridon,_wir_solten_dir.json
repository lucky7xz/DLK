{"textgrid.poem.33238": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Floridon, wir solten dir", "genre": "verse", "period": "N.A.", "pub_year": 1676, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Floridon, wir solten dir", "tokens": ["Flo\u00b7ri\u00b7don", ",", "wir", "sol\u00b7ten", "dir"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PPER", "VMFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Billig so ein Denck-Mahl setzen,", "tokens": ["Bil\u00b7lig", "so", "ein", "Den\u00b7ck\u00b7Mahl", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Da\u00df gar nichts desselben Zier", "tokens": ["Da\u00df", "gar", "nichts", "des\u00b7sel\u00b7ben", "Zier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIS", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00e4hig w\u00e4re zu verletzen;", "tokens": ["F\u00e4\u00b7hig", "w\u00e4\u00b7re", "zu", "ver\u00b7let\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil das Gl\u00fcck mit deiner Kunst", "tokens": ["Weil", "das", "Gl\u00fcck", "mit", "dei\u00b7ner", "Kunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen solchen Bund geschlossen,", "tokens": ["Ei\u00b7nen", "sol\u00b7chen", "Bund", "ge\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df, durch ihrer beyder Gunst,", "tokens": ["Da\u00df", ",", "durch", "ih\u00b7rer", "bey\u00b7der", "Gunst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "PPOSAT", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Du den Fl\u00fcgel abgeschossen.", "tokens": ["Du", "den", "Fl\u00fc\u00b7gel", "ab\u00b7ge\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Aber, es kan nicht bestehn", "tokens": ["A\u00b7ber", ",", "es", "kan", "nicht", "be\u00b7stehn"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Was aus unsrer Feder rinnet;", "tokens": ["Was", "aus", "uns\u00b7rer", "Fe\u00b7der", "rin\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Pfleget nicht schnell zu vergehn,", "tokens": ["Pfle\u00b7get", "nicht", "schnell", "zu", "ver\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ein schwacher Geist ersinnet?", "tokens": ["Was", "ein", "schwa\u00b7cher", "Geist", "er\u00b7sin\u00b7net", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Du kennst keine Niedrigkeit,", "tokens": ["Du", "kennst", "kei\u00b7ne", "Nied\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und wir kleben an der Erden;", "tokens": ["Und", "wir", "kle\u00b7ben", "an", "der", "Er\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Drum wird besser anderweit", "tokens": ["Drum", "wird", "bes\u00b7ser", "an\u00b7der\u00b7weit"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ADJD", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Deine That gepriesen werden.", "tokens": ["Dei\u00b7ne", "That", "ge\u00b7prie\u00b7sen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Zwickau wird den sch\u00f6nen Schu\u00df", "tokens": ["Zwi\u00b7ckau", "wird", "den", "sch\u00f6\u00b7nen", "Schu\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "Freudig in sein Zeit-Buch schreiben,", "tokens": ["Freu\u00b7dig", "in", "sein", "Zeit\u00b7Buch", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "An dem gelben Pleissen-Flu\u00df", "tokens": ["An", "dem", "gel\u00b7ben", "Pleis\u00b7sen\u00b7Flu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird er unvergessen bleiben.", "tokens": ["Wird", "er", "un\u00b7ver\u00b7ges\u00b7sen", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weimar hat dir zuerkannt", "tokens": ["Wei\u00b7mar", "hat", "dir", "zu\u00b7er\u00b7kannt"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Immer-gr\u00fcne Sieges-Kronen,", "tokens": ["Im\u00b7mer\u00b7gr\u00fc\u00b7ne", "Sie\u00b7ges\u00b7Kro\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und dein andres Vaterland", "tokens": ["Und", "dein", "and\u00b7res", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Zeitz, wird deine Kunst belohnen.", "tokens": ["Zeitz", ",", "wird", "dei\u00b7ne", "Kunst", "be\u00b7loh\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VAFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Dannoch wisse, da\u00df auch wir,", "tokens": ["Dan\u00b7noch", "wis\u00b7se", ",", "da\u00df", "auch", "wir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "ADV", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir, der Ausbund deiner Treuen,", "tokens": ["Wir", ",", "der", "Aus\u00b7bund", "dei\u00b7ner", "Treu\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Uns bey unsern Linden hier", "tokens": ["Uns", "bey", "un\u00b7sern", "Lin\u00b7den", "hier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uber dieses Gl\u00fcck erfreuen,", "tokens": ["U\u00b7ber", "die\u00b7ses", "Gl\u00fcck", "er\u00b7freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Das dich aus der finstern Nacht", "tokens": ["Das", "dich", "aus", "der", "fins\u00b7tern", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "Der Verg\u00e4nglichkeit entrissen,", "tokens": ["Der", "Ver\u00b7g\u00e4ng\u00b7lich\u00b7keit", "ent\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "So, da\u00df manches Siegers Pracht", "tokens": ["So", ",", "da\u00df", "man\u00b7ches", "Sie\u00b7gers", "Pracht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PIS", "NE", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Deinem Ruhm wird weichen m\u00fcssen.", "tokens": ["Dei\u00b7nem", "Ruhm", "wird", "wei\u00b7chen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Giebt man uns ein Gl\u00e4\u00dfgen Wein,", "tokens": ["Giebt", "man", "uns", "ein", "Gl\u00e4\u00df\u00b7gen", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wann wir in der Rose sitzen,", "tokens": ["Wann", "wir", "in", "der", "Ro\u00b7se", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mu\u00df es die Gesundheit seyn", "tokens": ["Mu\u00df", "es", "die", "Ge\u00b7sund\u00b7heit", "seyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "NN", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Des ber\u00fchmten Vogel-Sch\u00fctzen,", "tokens": ["Des", "be\u00b7r\u00fchm\u00b7ten", "Vo\u00b7gel\u00b7Sch\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der die Ehre hat gehabt", "tokens": ["Der", "die", "Eh\u00b7re", "hat", "ge\u00b7habt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VAFIN", "VAPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen Fl\u00fcgel zu bestreiten,", "tokens": ["Ei\u00b7nen", "Fl\u00fc\u00b7gel", "zu", "be\u00b7strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und drauf lassen wir den Abt", "tokens": ["Und", "drauf", "las\u00b7sen", "wir", "den", "Abt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Auf dein Wohlergehen reuten.", "tokens": ["Auf", "dein", "Woh\u00b7ler\u00b7ge\u00b7hen", "reu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Fragt uns einer, ob wir nicht", "tokens": ["Fragt", "uns", "ei\u00b7ner", ",", "ob", "wir", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PIS", "$,", "KOUS", "PPER", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Etwas neues wo geh\u00f6ret?", "tokens": ["Et\u00b7was", "neu\u00b7es", "wo", "ge\u00b7h\u00f6\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "PWAV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was man vom Turenne spricht,", "tokens": ["Was", "man", "vom", "Tu\u00b7ren\u00b7ne", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Ob er noch die Pfaltz verst\u00f6ret?", "tokens": ["Ob", "er", "noch", "die", "Pfaltz", "ver\u00b7st\u00f6\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Tr\u00e4gt er den Bescheid davon:", "tokens": ["Tr\u00e4gt", "er", "den", "Be\u00b7scheid", "da\u00b7von", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df wir anders nichts vernommen,", "tokens": ["Da\u00df", "wir", "an\u00b7ders", "nichts", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Als da\u00df unser Floridon", "tokens": ["Als", "da\u00df", "un\u00b7ser", "Flo\u00b7ri\u00b7don"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Drey\u00dfig G\u00fclden j\u00fcngst bekommen.", "tokens": ["Drey\u00b7\u00dfig", "G\u00fcl\u00b7den", "j\u00fcngst", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Unterdessen schicke dich", "tokens": ["Un\u00b7ter\u00b7des\u00b7sen", "schi\u00b7cke", "dich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieses Geld wohl anzulegen,", "tokens": ["Die\u00b7ses", "Geld", "wohl", "an\u00b7zu\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADV", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Glaub uns, sonst verzehrt es sich,", "tokens": ["Glaub", "uns", ",", "sonst", "ver\u00b7zehrt", "es", "sich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ADV", "VVFIN", "PPER", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und bringt weder Gl\u00fcck noch Seegen.", "tokens": ["Und", "bringt", "we\u00b7der", "Gl\u00fcck", "noch", "See\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "NN", "ADV", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Gieb uns allen einen Schmau\u00df,", "tokens": ["Gieb", "uns", "al\u00b7len", "ei\u00b7nen", "Schmau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PIS", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df wir doch von deinem Schiessen,", "tokens": ["Da\u00df", "wir", "doch", "von", "dei\u00b7nem", "Schies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Komst du wieder her nach Hau\u00df,", "tokens": ["Komst", "du", "wie\u00b7der", "her", "nach", "Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Gleichwohl etwas mit geniessen.", "tokens": ["Gleich\u00b7wohl", "et\u00b7was", "mit", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Eile, wehrter Floridon,", "tokens": ["Ei\u00b7le", ",", "wehr\u00b7ter", "Flo\u00b7ri\u00b7don", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weg aus deinem Schwanen-Neste,", "tokens": ["Weg", "aus", "dei\u00b7nem", "Schwa\u00b7nen\u00b7Nes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Komm, dann unser Helikon", "tokens": ["Komm", ",", "dann", "un\u00b7ser", "He\u00b7li\u00b7kon"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schm\u00fccket sich aufs allerbeste.", "tokens": ["Schm\u00fc\u00b7cket", "sich", "aufs", "al\u00b7ler\u00b7bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPRART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ph\u00f6bus selbst ist hertzlich froh,", "tokens": ["Ph\u00f6\u00b7bus", "selbst", "ist", "hertz\u00b7lich", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VAFIN", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und erwartet, mit Verlangen,", "tokens": ["Und", "er\u00b7war\u00b7tet", ",", "mit", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wann du komst von dubenroh,", "tokens": ["Wann", "du", "komst", "von", "du\u00b7ben\u00b7roh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "APPR", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Dich, nach W\u00fcrden, zu empfangen.", "tokens": ["Dich", ",", "nach", "W\u00fcr\u00b7den", ",", "zu", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "APPR", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Nun! wir wollen bi\u00df dahin", "tokens": ["Nun", "!", "wir", "wol\u00b7len", "bi\u00df", "da\u00b7hin"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$.", "PPER", "VMFIN", "ADV", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsern Gl\u00fcckwunsch auch versparen,", "tokens": ["Un\u00b7sern", "Gl\u00fcck\u00b7wunsch", "auch", "ver\u00b7spa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wann von Schiessen und Gewinn", "tokens": ["Wann", "von", "Schies\u00b7sen", "und", "Ge\u00b7winn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wir gewi\u00dfre Post erfahren.", "tokens": ["Wir", "ge\u00b7wi\u00df\u00b7re", "Post", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dann soll unsre gantze Schaar", "tokens": ["Dann", "soll", "uns\u00b7re", "gant\u00b7ze", "Schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPOSAT", "ADJA", "NN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "Sich, nach M\u00f6glichkeit, bem\u00fchen,", "tokens": ["Sich", ",", "nach", "M\u00f6g\u00b7lich\u00b7keit", ",", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "$,", "APPR", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Um dein zierlich-krauses Haar", "tokens": ["Um", "dein", "zier\u00b7lich\u00b7krau\u00b7ses", "Haar"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Einen Lorbeer-Crantz zu ziehen.", "tokens": ["Ei\u00b7nen", "Lor\u00b7beer\u00b7Crantz", "zu", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Floridon, wir solten dir", "tokens": ["Flo\u00b7ri\u00b7don", ",", "wir", "sol\u00b7ten", "dir"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PPER", "VMFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Billig so ein Denck-Mahl setzen,", "tokens": ["Bil\u00b7lig", "so", "ein", "Den\u00b7ck\u00b7Mahl", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Da\u00df gar nichts desselben Zier", "tokens": ["Da\u00df", "gar", "nichts", "des\u00b7sel\u00b7ben", "Zier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIS", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00e4hig w\u00e4re zu verletzen;", "tokens": ["F\u00e4\u00b7hig", "w\u00e4\u00b7re", "zu", "ver\u00b7let\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil das Gl\u00fcck mit deiner Kunst", "tokens": ["Weil", "das", "Gl\u00fcck", "mit", "dei\u00b7ner", "Kunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen solchen Bund geschlossen,", "tokens": ["Ei\u00b7nen", "sol\u00b7chen", "Bund", "ge\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df, durch ihrer beyder Gunst,", "tokens": ["Da\u00df", ",", "durch", "ih\u00b7rer", "bey\u00b7der", "Gunst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "PPOSAT", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Du den Fl\u00fcgel abgeschossen.", "tokens": ["Du", "den", "Fl\u00fc\u00b7gel", "ab\u00b7ge\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Aber, es kan nicht bestehn", "tokens": ["A\u00b7ber", ",", "es", "kan", "nicht", "be\u00b7stehn"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Was aus unsrer Feder rinnet;", "tokens": ["Was", "aus", "uns\u00b7rer", "Fe\u00b7der", "rin\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Pfleget nicht schnell zu vergehn,", "tokens": ["Pfle\u00b7get", "nicht", "schnell", "zu", "ver\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ein schwacher Geist ersinnet?", "tokens": ["Was", "ein", "schwa\u00b7cher", "Geist", "er\u00b7sin\u00b7net", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Du kennst keine Niedrigkeit,", "tokens": ["Du", "kennst", "kei\u00b7ne", "Nied\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und wir kleben an der Erden;", "tokens": ["Und", "wir", "kle\u00b7ben", "an", "der", "Er\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Drum wird besser anderweit", "tokens": ["Drum", "wird", "bes\u00b7ser", "an\u00b7der\u00b7weit"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ADJD", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Deine That gepriesen werden.", "tokens": ["Dei\u00b7ne", "That", "ge\u00b7prie\u00b7sen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Zwickau wird den sch\u00f6nen Schu\u00df", "tokens": ["Zwi\u00b7ckau", "wird", "den", "sch\u00f6\u00b7nen", "Schu\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "Freudig in sein Zeit-Buch schreiben,", "tokens": ["Freu\u00b7dig", "in", "sein", "Zeit\u00b7Buch", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "An dem gelben Pleissen-Flu\u00df", "tokens": ["An", "dem", "gel\u00b7ben", "Pleis\u00b7sen\u00b7Flu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird er unvergessen bleiben.", "tokens": ["Wird", "er", "un\u00b7ver\u00b7ges\u00b7sen", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weimar hat dir zuerkannt", "tokens": ["Wei\u00b7mar", "hat", "dir", "zu\u00b7er\u00b7kannt"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Immer-gr\u00fcne Sieges-Kronen,", "tokens": ["Im\u00b7mer\u00b7gr\u00fc\u00b7ne", "Sie\u00b7ges\u00b7Kro\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und dein andres Vaterland", "tokens": ["Und", "dein", "and\u00b7res", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Zeitz, wird deine Kunst belohnen.", "tokens": ["Zeitz", ",", "wird", "dei\u00b7ne", "Kunst", "be\u00b7loh\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VAFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Dannoch wisse, da\u00df auch wir,", "tokens": ["Dan\u00b7noch", "wis\u00b7se", ",", "da\u00df", "auch", "wir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "ADV", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir, der Ausbund deiner Treuen,", "tokens": ["Wir", ",", "der", "Aus\u00b7bund", "dei\u00b7ner", "Treu\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Uns bey unsern Linden hier", "tokens": ["Uns", "bey", "un\u00b7sern", "Lin\u00b7den", "hier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uber dieses Gl\u00fcck erfreuen,", "tokens": ["U\u00b7ber", "die\u00b7ses", "Gl\u00fcck", "er\u00b7freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Das dich aus der finstern Nacht", "tokens": ["Das", "dich", "aus", "der", "fins\u00b7tern", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "Der Verg\u00e4nglichkeit entrissen,", "tokens": ["Der", "Ver\u00b7g\u00e4ng\u00b7lich\u00b7keit", "ent\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "So, da\u00df manches Siegers Pracht", "tokens": ["So", ",", "da\u00df", "man\u00b7ches", "Sie\u00b7gers", "Pracht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PIS", "NE", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Deinem Ruhm wird weichen m\u00fcssen.", "tokens": ["Dei\u00b7nem", "Ruhm", "wird", "wei\u00b7chen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Giebt man uns ein Gl\u00e4\u00dfgen Wein,", "tokens": ["Giebt", "man", "uns", "ein", "Gl\u00e4\u00df\u00b7gen", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wann wir in der Rose sitzen,", "tokens": ["Wann", "wir", "in", "der", "Ro\u00b7se", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mu\u00df es die Gesundheit seyn", "tokens": ["Mu\u00df", "es", "die", "Ge\u00b7sund\u00b7heit", "seyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "NN", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Des ber\u00fchmten Vogel-Sch\u00fctzen,", "tokens": ["Des", "be\u00b7r\u00fchm\u00b7ten", "Vo\u00b7gel\u00b7Sch\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der die Ehre hat gehabt", "tokens": ["Der", "die", "Eh\u00b7re", "hat", "ge\u00b7habt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VAFIN", "VAPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen Fl\u00fcgel zu bestreiten,", "tokens": ["Ei\u00b7nen", "Fl\u00fc\u00b7gel", "zu", "be\u00b7strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und drauf lassen wir den Abt", "tokens": ["Und", "drauf", "las\u00b7sen", "wir", "den", "Abt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Auf dein Wohlergehen reuten.", "tokens": ["Auf", "dein", "Woh\u00b7ler\u00b7ge\u00b7hen", "reu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Fragt uns einer, ob wir nicht", "tokens": ["Fragt", "uns", "ei\u00b7ner", ",", "ob", "wir", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PIS", "$,", "KOUS", "PPER", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Etwas neues wo geh\u00f6ret?", "tokens": ["Et\u00b7was", "neu\u00b7es", "wo", "ge\u00b7h\u00f6\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "PWAV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was man vom Turenne spricht,", "tokens": ["Was", "man", "vom", "Tu\u00b7ren\u00b7ne", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Ob er noch die Pfaltz verst\u00f6ret?", "tokens": ["Ob", "er", "noch", "die", "Pfaltz", "ver\u00b7st\u00f6\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Tr\u00e4gt er den Bescheid davon:", "tokens": ["Tr\u00e4gt", "er", "den", "Be\u00b7scheid", "da\u00b7von", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df wir anders nichts vernommen,", "tokens": ["Da\u00df", "wir", "an\u00b7ders", "nichts", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Als da\u00df unser Floridon", "tokens": ["Als", "da\u00df", "un\u00b7ser", "Flo\u00b7ri\u00b7don"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Drey\u00dfig G\u00fclden j\u00fcngst bekommen.", "tokens": ["Drey\u00b7\u00dfig", "G\u00fcl\u00b7den", "j\u00fcngst", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Unterdessen schicke dich", "tokens": ["Un\u00b7ter\u00b7des\u00b7sen", "schi\u00b7cke", "dich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieses Geld wohl anzulegen,", "tokens": ["Die\u00b7ses", "Geld", "wohl", "an\u00b7zu\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADV", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Glaub uns, sonst verzehrt es sich,", "tokens": ["Glaub", "uns", ",", "sonst", "ver\u00b7zehrt", "es", "sich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ADV", "VVFIN", "PPER", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und bringt weder Gl\u00fcck noch Seegen.", "tokens": ["Und", "bringt", "we\u00b7der", "Gl\u00fcck", "noch", "See\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "NN", "ADV", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Gieb uns allen einen Schmau\u00df,", "tokens": ["Gieb", "uns", "al\u00b7len", "ei\u00b7nen", "Schmau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PIS", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df wir doch von deinem Schiessen,", "tokens": ["Da\u00df", "wir", "doch", "von", "dei\u00b7nem", "Schies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Komst du wieder her nach Hau\u00df,", "tokens": ["Komst", "du", "wie\u00b7der", "her", "nach", "Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Gleichwohl etwas mit geniessen.", "tokens": ["Gleich\u00b7wohl", "et\u00b7was", "mit", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Eile, wehrter Floridon,", "tokens": ["Ei\u00b7le", ",", "wehr\u00b7ter", "Flo\u00b7ri\u00b7don", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weg aus deinem Schwanen-Neste,", "tokens": ["Weg", "aus", "dei\u00b7nem", "Schwa\u00b7nen\u00b7Nes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Komm, dann unser Helikon", "tokens": ["Komm", ",", "dann", "un\u00b7ser", "He\u00b7li\u00b7kon"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schm\u00fccket sich aufs allerbeste.", "tokens": ["Schm\u00fc\u00b7cket", "sich", "aufs", "al\u00b7ler\u00b7bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPRART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ph\u00f6bus selbst ist hertzlich froh,", "tokens": ["Ph\u00f6\u00b7bus", "selbst", "ist", "hertz\u00b7lich", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VAFIN", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und erwartet, mit Verlangen,", "tokens": ["Und", "er\u00b7war\u00b7tet", ",", "mit", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wann du komst von dubenroh,", "tokens": ["Wann", "du", "komst", "von", "du\u00b7ben\u00b7roh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "APPR", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Dich, nach W\u00fcrden, zu empfangen.", "tokens": ["Dich", ",", "nach", "W\u00fcr\u00b7den", ",", "zu", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "APPR", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Nun! wir wollen bi\u00df dahin", "tokens": ["Nun", "!", "wir", "wol\u00b7len", "bi\u00df", "da\u00b7hin"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$.", "PPER", "VMFIN", "ADV", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsern Gl\u00fcckwunsch auch versparen,", "tokens": ["Un\u00b7sern", "Gl\u00fcck\u00b7wunsch", "auch", "ver\u00b7spa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wann von Schiessen und Gewinn", "tokens": ["Wann", "von", "Schies\u00b7sen", "und", "Ge\u00b7winn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wir gewi\u00dfre Post erfahren.", "tokens": ["Wir", "ge\u00b7wi\u00df\u00b7re", "Post", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dann soll unsre gantze Schaar", "tokens": ["Dann", "soll", "uns\u00b7re", "gant\u00b7ze", "Schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPOSAT", "ADJA", "NN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "Sich, nach M\u00f6glichkeit, bem\u00fchen,", "tokens": ["Sich", ",", "nach", "M\u00f6g\u00b7lich\u00b7keit", ",", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "$,", "APPR", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Um dein zierlich-krauses Haar", "tokens": ["Um", "dein", "zier\u00b7lich\u00b7krau\u00b7ses", "Haar"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Einen Lorbeer-Crantz zu ziehen.", "tokens": ["Ei\u00b7nen", "Lor\u00b7beer\u00b7Crantz", "zu", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}