{"textgrid.poem.37937": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Das Weltende", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ob ich gleich kein Schatz nicht hab,", "tokens": ["Ob", "ich", "gleich", "kein", "Schatz", "nicht", "hab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "PTKNEG", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Will ich schon ein finden,", "tokens": ["Will", "ich", "schon", "ein", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Geh ichs G\u00e4\u00dflein auf und ab,", "tokens": ["Geh", "ichs", "G\u00e4\u00df\u00b7lein", "auf", "und", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis zur gro\u00dfen Linden.", "tokens": ["Bis", "zur", "gro\u00b7\u00dfen", "Lin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "ADJA", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Als ich zu der Linden kam,", "tokens": ["Als", "ich", "zu", "der", "Lin\u00b7den", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NE", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sa\u00df mein Schatz daneben:", "tokens": ["Sa\u00df", "mein", "Schatz", "da\u00b7ne\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PAV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbgr\u00fc\u00df dich Gott, herzlieber Schatz!", "tokens": ["\u00bb", "gr\u00fc\u00df", "dich", "Gott", ",", "herz\u00b7lie\u00b7ber", "Schatz", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo bist du gewesen?\u00ab", "tokens": ["Wo", "bist", "du", "ge\u00b7we\u00b7sen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "VAPP", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.3": {"line.1": {"text": "\u00bbschatz, wo ich gewesen bin,", "tokens": ["\u00bb", "schatz", ",", "wo", "ich", "ge\u00b7we\u00b7sen", "bin", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PWAV", "PPER", "VAPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Darf ich dir wohl sagen,", "tokens": ["Darf", "ich", "dir", "wohl", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "War in fremde Lande hin,", "tokens": ["War", "in", "frem\u00b7de", "Lan\u00b7de", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hab gar viel erfahren.", "tokens": ["Hab", "gar", "viel", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Sah am Ende von der Welt,", "tokens": ["Sah", "am", "En\u00b7de", "von", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie die Bretter pa\u00dften,", "tokens": ["Wie", "die", "Bret\u00b7ter", "pa\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Noch die alten Monden hell", "tokens": ["Noch", "die", "al\u00b7ten", "Mon\u00b7den", "hell"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "All in einem Kasten.", "tokens": ["All", "in", "ei\u00b7nem", "Kas\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Sahn wie schlechte Fischtuch aus,", "tokens": ["Sahn", "wie", "schlech\u00b7te", "Fischtuch", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sonne kam gegangen,", "tokens": ["Son\u00b7ne", "kam", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Tipte nur ein wenig drauf,", "tokens": ["Tip\u00b7te", "nur", "ein", "we\u00b7nig", "drauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Brannt mich wie mit Zangen.", "tokens": ["Brannt", "mich", "wie", "mit", "Zan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "H\u00e4tt ich einen Schritt gethan,", "tokens": ["H\u00e4tt", "ich", "ei\u00b7nen", "Schritt", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4tt ich nichts mehr funden,", "tokens": ["H\u00e4tt", "ich", "nichts", "mehr", "fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sage nun mein Liebchen an", "tokens": ["Sa\u00b7ge", "nun", "mein", "Lieb\u00b7chen", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PPOSAT", "NN", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie du dich befunden.\u00ab", "tokens": ["Wie", "du", "dich", "be\u00b7fun\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVPP", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "\u00bbich befand mich in dem Thal,", "tokens": ["\u00bb", "ich", "be\u00b7fand", "mich", "in", "dem", "Thal", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sa\u00dfen da zwey Hasen,", "tokens": ["Sa\u00b7\u00dfen", "da", "zwey", "Ha\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "CARD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Fra\u00dfen ab das gr\u00fcne Gras", "tokens": ["Fra\u00b7\u00dfen", "ab", "das", "gr\u00fc\u00b7ne", "Gras"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis zum d\u00fcrren Rasen.", "tokens": ["Bis", "zum", "d\u00fcr\u00b7ren", "Ra\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "In der kalten Wintersnacht,", "tokens": ["In", "der", "kal\u00b7ten", "Win\u00b7ter\u00b7snacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lie\u00dfest du mich sitzen,", "tokens": ["Lie\u00b7\u00dfest", "du", "mich", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ey mein schwarzbraun Aeugelein,", "tokens": ["Ey", "mein", "schwarz\u00b7braun", "A\u00b7e\u00b7u\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Must du Wasser schwitzen.", "tokens": ["Must", "du", "Was\u00b7ser", "schwit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Darum reis' in Sommernacht,", "tokens": ["Da\u00b7rum", "reis'", "in", "Som\u00b7mer\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur zu aller Welt Ende,", "tokens": ["Nur", "zu", "al\u00b7ler", "Welt", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Wer sich gar zu lustig macht,", "tokens": ["Wer", "sich", "gar", "zu", "lus\u00b7tig", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADV", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nimmt ein schlechtes Ende.\u00ab", "tokens": ["Nimmt", "ein", "schlech\u00b7tes", "En\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Ob ich gleich kein Schatz nicht hab,", "tokens": ["Ob", "ich", "gleich", "kein", "Schatz", "nicht", "hab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "PTKNEG", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Will ich schon ein finden,", "tokens": ["Will", "ich", "schon", "ein", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Geh ichs G\u00e4\u00dflein auf und ab,", "tokens": ["Geh", "ichs", "G\u00e4\u00df\u00b7lein", "auf", "und", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis zur gro\u00dfen Linden.", "tokens": ["Bis", "zur", "gro\u00b7\u00dfen", "Lin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "ADJA", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Als ich zu der Linden kam,", "tokens": ["Als", "ich", "zu", "der", "Lin\u00b7den", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NE", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sa\u00df mein Schatz daneben:", "tokens": ["Sa\u00df", "mein", "Schatz", "da\u00b7ne\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PAV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbgr\u00fc\u00df dich Gott, herzlieber Schatz!", "tokens": ["\u00bb", "gr\u00fc\u00df", "dich", "Gott", ",", "herz\u00b7lie\u00b7ber", "Schatz", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo bist du gewesen?\u00ab", "tokens": ["Wo", "bist", "du", "ge\u00b7we\u00b7sen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "VAPP", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.12": {"line.1": {"text": "\u00bbschatz, wo ich gewesen bin,", "tokens": ["\u00bb", "schatz", ",", "wo", "ich", "ge\u00b7we\u00b7sen", "bin", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PWAV", "PPER", "VAPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Darf ich dir wohl sagen,", "tokens": ["Darf", "ich", "dir", "wohl", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "War in fremde Lande hin,", "tokens": ["War", "in", "frem\u00b7de", "Lan\u00b7de", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hab gar viel erfahren.", "tokens": ["Hab", "gar", "viel", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Sah am Ende von der Welt,", "tokens": ["Sah", "am", "En\u00b7de", "von", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie die Bretter pa\u00dften,", "tokens": ["Wie", "die", "Bret\u00b7ter", "pa\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Noch die alten Monden hell", "tokens": ["Noch", "die", "al\u00b7ten", "Mon\u00b7den", "hell"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "All in einem Kasten.", "tokens": ["All", "in", "ei\u00b7nem", "Kas\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Sahn wie schlechte Fischtuch aus,", "tokens": ["Sahn", "wie", "schlech\u00b7te", "Fischtuch", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sonne kam gegangen,", "tokens": ["Son\u00b7ne", "kam", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Tipte nur ein wenig drauf,", "tokens": ["Tip\u00b7te", "nur", "ein", "we\u00b7nig", "drauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Brannt mich wie mit Zangen.", "tokens": ["Brannt", "mich", "wie", "mit", "Zan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "H\u00e4tt ich einen Schritt gethan,", "tokens": ["H\u00e4tt", "ich", "ei\u00b7nen", "Schritt", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4tt ich nichts mehr funden,", "tokens": ["H\u00e4tt", "ich", "nichts", "mehr", "fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sage nun mein Liebchen an", "tokens": ["Sa\u00b7ge", "nun", "mein", "Lieb\u00b7chen", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PPOSAT", "NN", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie du dich befunden.\u00ab", "tokens": ["Wie", "du", "dich", "be\u00b7fun\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVPP", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "\u00bbich befand mich in dem Thal,", "tokens": ["\u00bb", "ich", "be\u00b7fand", "mich", "in", "dem", "Thal", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sa\u00dfen da zwey Hasen,", "tokens": ["Sa\u00b7\u00dfen", "da", "zwey", "Ha\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "CARD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Fra\u00dfen ab das gr\u00fcne Gras", "tokens": ["Fra\u00b7\u00dfen", "ab", "das", "gr\u00fc\u00b7ne", "Gras"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis zum d\u00fcrren Rasen.", "tokens": ["Bis", "zum", "d\u00fcr\u00b7ren", "Ra\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "In der kalten Wintersnacht,", "tokens": ["In", "der", "kal\u00b7ten", "Win\u00b7ter\u00b7snacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lie\u00dfest du mich sitzen,", "tokens": ["Lie\u00b7\u00dfest", "du", "mich", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ey mein schwarzbraun Aeugelein,", "tokens": ["Ey", "mein", "schwarz\u00b7braun", "A\u00b7e\u00b7u\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Must du Wasser schwitzen.", "tokens": ["Must", "du", "Was\u00b7ser", "schwit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.18": {"line.1": {"text": "Darum reis' in Sommernacht,", "tokens": ["Da\u00b7rum", "reis'", "in", "Som\u00b7mer\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur zu aller Welt Ende,", "tokens": ["Nur", "zu", "al\u00b7ler", "Welt", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Wer sich gar zu lustig macht,", "tokens": ["Wer", "sich", "gar", "zu", "lus\u00b7tig", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADV", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nimmt ein schlechtes Ende.\u00ab", "tokens": ["Nimmt", "ein", "schlech\u00b7tes", "En\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}