{"dta.poem.18908": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "An Jhre F\u00fcrstl: Gnad:  \n  &c.   Herren Bernhard Hertzogen  \n zu Sachsen   &c.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Printz/ dessen verdienst doch noch gr\u00f6sser dan dein", "tokens": ["Printz", "/", "des\u00b7sen", "ver\u00b7dienst", "doch", "noch", "gr\u00f6s\u00b7ser", "dan", "dein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "PDS", "VVFIN", "ADV", "ADV", "ADJD", "ADV", "PPOSAT"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "prey\u00df/", "tokens": ["prey\u00df", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Wiewol dein wahres lob die himmel selbs kaum", "tokens": ["Wie\u00b7wol", "dein", "wah\u00b7res", "lob", "die", "him\u00b7mel", "selbs", "kaum"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "gr\u00e4ntzen;", "tokens": ["gr\u00e4nt\u00b7zen", ";"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Fahr fort/ O grosser Held/ vn\u0303 vnserm feind bewei\u00df", "tokens": ["Fahr", "fort", "/", "O", "gros\u00b7ser", "Held", "/", "v\u00f1", "vn\u00b7serm", "feind", "be\u00b7wei\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$(", "NE", "ADJA", "NN", "$(", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df die plitz deines schwerts mehr dan des Ad-", "tokens": ["Da\u00df", "die", "plitz", "dei\u00b7nes", "schwerts", "mehr", "dan", "des", "Ad"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "ADV", "ADV", "ADV", "ART", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "lers gl\u00e4ntzen.", "tokens": ["lers", "gl\u00e4nt\u00b7zen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.2": {"line.1": {"text": "Je mehr der dolle feind auff alle grobe wei\u00df", "tokens": ["Je", "mehr", "der", "dol\u00b7le", "feind", "auff", "al\u00b7le", "gro\u00b7be", "wei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "APPR", "PIAT", "ADJA", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Will seinen Sig vnd pracht durch vnsern fall er-", "tokens": ["Will", "sei\u00b7nen", "Sig", "vnd", "pracht", "durch", "vn\u00b7sern", "fall", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "g\u00e4ntzen;", "tokens": ["g\u00e4nt\u00b7zen", ";"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Jemehr lehr du sie/ Held/ gerecht/ starck/ fromb", "tokens": ["Je\u00b7mehr", "lehr", "du", "sie", "/", "Held", "/", "ge\u00b7recht", "/", "starck", "/", "fromb"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$(", "NN", "$(", "ADJD", "$(", "ADJD", "$(", "XY"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "vnd wei\u00df/", "tokens": ["vnd", "wei\u00df", "/"], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Da\u00df nur dein haupt allein wehrt jhrer Lorbeer-", "tokens": ["Da\u00df", "nur", "dein", "haupt", "al\u00b7lein", "wehrt", "jhrer", "Lor\u00b7beer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "ADV", "VVFIN", "PPOSAT", "TRUNC"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.7": {"text": "Cr\u00e4ntzen.", "tokens": ["Cr\u00e4nt\u00b7zen", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.3": {"line.1": {"text": "Jedoch/ weil vnsre forcht/ als dein muht/ billich gro\u00df/", "tokens": ["Je\u00b7doch", "/", "weil", "vns\u00b7re", "forcht", "/", "als", "dein", "muht", "/", "bil\u00b7lich", "gro\u00df", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PPER", "VVFIN", "$(", "KOUS", "PPOSAT", "VVFIN", "$(", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So h\u00f6r auch vnsern Raht Dich vnd Vns zube-", "tokens": ["So", "h\u00f6r", "auch", "vn\u00b7sern", "Raht", "Dich", "vnd", "Vns", "zu\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "PPER", "KON", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wahren/", "tokens": ["wah\u00b7ren", "/"], "token_info": ["word", "punct"], "pos": ["VVINF", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Vnd f\u00f6rcht mit Vns dein hertz/ vil zu gro\u00df/ vil", "tokens": ["Vnd", "f\u00f6rcht", "mit", "Vns", "dein", "hertz", "/", "vil", "zu", "gro\u00df", "/", "vil"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PPOSAT", "NN", "$(", "ADV", "PTKA", "ADJD", "$(", "XY"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "zu blo\u00df.", "tokens": ["zu", "blo\u00df", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "ADV", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.4": {"line.1": {"text": "Dan wer erkennet nicht/ wan du stehts mit gefahren", "tokens": ["Dan", "wer", "er\u00b7ken\u00b7net", "nicht", "/", "wan", "du", "stehts", "mit", "ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PWS", "VVFIN", "PTKNEG", "$(", "PWAV", "PPER", "VVFIN", "APPR", "VVPP"], "meter": "+--+-++-++-+-", "measure": "iambic.septa.invert"}, "line.2": {"text": "Erquickest deinen muht/ da\u00df du an muht gleich-", "tokens": ["Er\u00b7qui\u00b7ckest", "dei\u00b7nen", "muht", "/", "da\u00df", "du", "an", "muht", "gleich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "VVFIN", "$(", "KOUS", "PPER", "APPR", "VVFIN", "TRUNC"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "lo\u00df", "tokens": ["lo\u00df"], "token_info": ["word"], "pos": ["PTKVZ"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Kanst keinen gr\u00f6ssern feind dan dein hertz selbs", "tokens": ["Kanst", "kei\u00b7nen", "gr\u00f6s\u00b7sern", "feind", "dan", "dein", "hertz", "selbs"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIAT", "ADJA", "NN", "ADV", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "erfahren?", "tokens": ["er\u00b7fah\u00b7ren", "?"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}}}}