{"textgrid.poem.42835": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Das Original", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin sehr dagegen,", "tokens": ["Ich", "bin", "sehr", "da\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PAV", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Da\u00df sich ungelegen", "tokens": ["Da\u00df", "sich", "un\u00b7ge\u00b7le\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PRF", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Jemand aufdr\u00e4ngt.", "tokens": ["Je\u00b7mand", "auf\u00b7dr\u00e4ngt", "."], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Aber meinen Segen", "tokens": ["A\u00b7ber", "mei\u00b7nen", "Se\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Hat, wer eines Wortspiels wegen", "tokens": ["Hat", ",", "wer", "ei\u00b7nes", "Wort\u00b7spiels", "we\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "$,", "PWS", "ART", "NN", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich zum Beispiel aufh\u00e4ngt.", "tokens": ["Sich", "zum", "Bei\u00b7spiel", "auf\u00b7h\u00e4ngt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "VVPP", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.2": {"line.1": {"text": "Ich bin darin ganz besonders eigen,", "tokens": ["Ich", "bin", "da\u00b7rin", "ganz", "be\u00b7son\u00b7ders", "ei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Denn ich sehe vieles weit voraus.", "tokens": ["Denn", "ich", "se\u00b7he", "vie\u00b7les", "weit", "vo\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Nur ich kann das immer nicht so zeigen. \u2013", "tokens": ["Nur", "ich", "kann", "das", "im\u00b7mer", "nicht", "so", "zei\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PPER", "VMFIN", "PDS", "ADV", "PTKNEG", "ADV", "VVINF", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Nie betritt ein blinder Mann mein Haus,", "tokens": ["Nie", "be\u00b7tritt", "ein", "blin\u00b7der", "Mann", "mein", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wenigstens nicht meine R\u00e4ume,", "tokens": ["We\u00b7nigs\u00b7tens", "nicht", "mei\u00b7ne", "R\u00e4u\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ich einmal eines Nachts in Schweden", "tokens": ["Weil", "ich", "ein\u00b7mal", "ei\u00b7nes", "Nachts", "in", "Schwe\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADV", "APPR", "NE"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Tr\u00e4umte \u2013 und ich kenne meine Tr\u00e4ume \u2013", "tokens": ["Tr\u00e4um\u00b7te", "\u2013", "und", "ich", "ken\u00b7ne", "mei\u00b7ne", "Tr\u00e4u\u00b7me", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KON", "PPER", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Nein, wir wollen lieber andres reden.", "tokens": ["Nein", ",", "wir", "wol\u00b7len", "lie\u00b7ber", "and\u00b7res", "re\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "ADV", "PIS", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Wenn ich mal wo so betrunken war,", "tokens": ["Wenn", "ich", "mal", "wo", "so", "be\u00b7trun\u00b7ken", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PWAV", "ADV", "ADJD", "VAFIN", "$,"], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie ich f\u00fcr gew\u00f6hnlich niemals bin,", "tokens": ["Wie", "ich", "f\u00fcr", "ge\u00b7w\u00f6hn\u00b7lich", "nie\u00b7mals", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJD", "ADV", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Geh' ich dorthin nie mehr hin;", "tokens": ["Geh'", "ich", "dor\u00b7thin", "nie", "mehr", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Darin bin ich sonderbar.", "tokens": ["Da\u00b7rin", "bin", "ich", "son\u00b7der\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und ich trinke, wenn ich vor Gesch\u00e4ften", "tokens": ["Und", "ich", "trin\u00b7ke", ",", "wenn", "ich", "vor", "Ge\u00b7sch\u00e4f\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Stehe, \u00fcberhaupt so gut wie nichts,", "tokens": ["Ste\u00b7he", ",", "\u00fc\u00b7ber\u00b7haupt", "so", "gut", "wie", "nichts", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ADV", "ADJD", "KOKOM", "PIS", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Denn ich stehe so gewissen Kr\u00e4ften", "tokens": ["Denn", "ich", "ste\u00b7he", "so", "ge\u00b7wis\u00b7sen", "Kr\u00e4f\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Nahe. Und der Ausdruck des Gesichts", "tokens": ["Na\u00b7he", ".", "Und", "der", "Aus\u00b7druck", "des", "Ge\u00b7sichts"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "KON", "ART", "NN", "ART", "NN"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.9": {"text": "Wechselt stets bei mir in Intervallen.", "tokens": ["Wech\u00b7selt", "stets", "bei", "mir", "in", "In\u00b7ter\u00b7val\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "Ist dir das und andres an mir aufgefallen?", "tokens": ["Ist", "dir", "das", "und", "and\u00b7res", "an", "mir", "auf\u00b7ge\u00b7fal\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "KON", "PIS", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.5": {"line.1": {"text": "Nun, ich wei\u00df: Ich passe nicht ins Leben,", "tokens": ["Nun", ",", "ich", "wei\u00df", ":", "Ich", "pas\u00b7se", "nicht", "ins", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "PTKNEG", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Weil ich hungern kann. Ich werde nie", "tokens": ["Weil", "ich", "hun\u00b7gern", "kann", ".", "Ich", "wer\u00b7de", "nie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN", "$.", "PPER", "VAFIN", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Mein Geheimstes jemals Leuten preisgeben,", "tokens": ["Mein", "Ge\u00b7heims\u00b7tes", "je\u00b7mals", "Leu\u00b7ten", "preis\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "NN", "VVFIN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Die nicht gro\u00df sein k\u00f6nnen oder die", "tokens": ["Die", "nicht", "gro\u00df", "sein", "k\u00f6n\u00b7nen", "o\u00b7der", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "ADJD", "VAINF", "VMFIN", "KON", "ART"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Eng am Gelde h\u00e4ngen.", "tokens": ["Eng", "am", "Gel\u00b7de", "h\u00e4n\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Warum sollte ich mich denen aufdr\u00e4ngen!", "tokens": ["Wa\u00b7rum", "soll\u00b7te", "ich", "mich", "de\u00b7nen", "auf\u00b7dr\u00e4n\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "PDS", "VVINF", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Willst du, bitte, nun mal andre Leute", "tokens": ["Willst", "du", ",", "bit\u00b7te", ",", "nun", "mal", "and\u00b7re", "Leu\u00b7te"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "$,", "PTKANT", "$,", "ADV", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ganz diskret befragen,", "tokens": ["Ganz", "dis\u00b7kret", "be\u00b7fra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Was sie \u00fcber mich und meine Meinung sagen", "tokens": ["Was", "sie", "\u00fc\u00b7ber", "mich", "und", "mei\u00b7ne", "Mei\u00b7nung", "sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "PPER", "KON", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Und was ich f\u00fcr sie bedeute.", "tokens": ["Und", "was", "ich", "f\u00fcr", "sie", "be\u00b7deu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Gelt, du wei\u00dft, da\u00df ich nicht gern verspreche,", "tokens": ["Gelt", ",", "du", "wei\u00dft", ",", "da\u00df", "ich", "nicht", "gern", "ver\u00b7spre\u00b7che", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Wei\u00dft auch, da\u00df ich etwas halten kann?", "tokens": ["Wei\u00dft", "auch", ",", "da\u00df", "ich", "et\u00b7was", "hal\u00b7ten", "kann", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PPER", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und \u2013 \u2013 \u2013 Genug! Du bist mein Mann! \u2013", "tokens": ["Und", "\u2013", "\u2013", "\u2013", "Ge\u00b7nug", "!", "Du", "bist", "mein", "Mann", "!", "\u2013"], "token_info": ["word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "$(", "$(", "$(", "ADV", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lebe wohl! \u2013 Zahl' ich \u2013 zahlst du die Zeche?", "tokens": ["Le\u00b7be", "wohl", "!", "\u2013", "Zahl'", "ich", "\u2013", "zahlst", "du", "die", "Ze\u00b7che", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "$(", "VVIMP", "PPER", "$(", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.8": {"line.1": {"text": "Ich bin sehr dagegen,", "tokens": ["Ich", "bin", "sehr", "da\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PAV", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Da\u00df sich ungelegen", "tokens": ["Da\u00df", "sich", "un\u00b7ge\u00b7le\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PRF", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Jemand aufdr\u00e4ngt.", "tokens": ["Je\u00b7mand", "auf\u00b7dr\u00e4ngt", "."], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Aber meinen Segen", "tokens": ["A\u00b7ber", "mei\u00b7nen", "Se\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Hat, wer eines Wortspiels wegen", "tokens": ["Hat", ",", "wer", "ei\u00b7nes", "Wort\u00b7spiels", "we\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "$,", "PWS", "ART", "NN", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich zum Beispiel aufh\u00e4ngt.", "tokens": ["Sich", "zum", "Bei\u00b7spiel", "auf\u00b7h\u00e4ngt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "VVPP", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.9": {"line.1": {"text": "Ich bin darin ganz besonders eigen,", "tokens": ["Ich", "bin", "da\u00b7rin", "ganz", "be\u00b7son\u00b7ders", "ei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Denn ich sehe vieles weit voraus.", "tokens": ["Denn", "ich", "se\u00b7he", "vie\u00b7les", "weit", "vo\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Nur ich kann das immer nicht so zeigen. \u2013", "tokens": ["Nur", "ich", "kann", "das", "im\u00b7mer", "nicht", "so", "zei\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PPER", "VMFIN", "PDS", "ADV", "PTKNEG", "ADV", "VVINF", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Nie betritt ein blinder Mann mein Haus,", "tokens": ["Nie", "be\u00b7tritt", "ein", "blin\u00b7der", "Mann", "mein", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wenigstens nicht meine R\u00e4ume,", "tokens": ["We\u00b7nigs\u00b7tens", "nicht", "mei\u00b7ne", "R\u00e4u\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ich einmal eines Nachts in Schweden", "tokens": ["Weil", "ich", "ein\u00b7mal", "ei\u00b7nes", "Nachts", "in", "Schwe\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADV", "APPR", "NE"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Tr\u00e4umte \u2013 und ich kenne meine Tr\u00e4ume \u2013", "tokens": ["Tr\u00e4um\u00b7te", "\u2013", "und", "ich", "ken\u00b7ne", "mei\u00b7ne", "Tr\u00e4u\u00b7me", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KON", "PPER", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Nein, wir wollen lieber andres reden.", "tokens": ["Nein", ",", "wir", "wol\u00b7len", "lie\u00b7ber", "and\u00b7res", "re\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "ADV", "PIS", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.11": {"line.1": {"text": "Wenn ich mal wo so betrunken war,", "tokens": ["Wenn", "ich", "mal", "wo", "so", "be\u00b7trun\u00b7ken", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PWAV", "ADV", "ADJD", "VAFIN", "$,"], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie ich f\u00fcr gew\u00f6hnlich niemals bin,", "tokens": ["Wie", "ich", "f\u00fcr", "ge\u00b7w\u00f6hn\u00b7lich", "nie\u00b7mals", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJD", "ADV", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Geh' ich dorthin nie mehr hin;", "tokens": ["Geh'", "ich", "dor\u00b7thin", "nie", "mehr", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Darin bin ich sonderbar.", "tokens": ["Da\u00b7rin", "bin", "ich", "son\u00b7der\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und ich trinke, wenn ich vor Gesch\u00e4ften", "tokens": ["Und", "ich", "trin\u00b7ke", ",", "wenn", "ich", "vor", "Ge\u00b7sch\u00e4f\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Stehe, \u00fcberhaupt so gut wie nichts,", "tokens": ["Ste\u00b7he", ",", "\u00fc\u00b7ber\u00b7haupt", "so", "gut", "wie", "nichts", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ADV", "ADJD", "KOKOM", "PIS", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Denn ich stehe so gewissen Kr\u00e4ften", "tokens": ["Denn", "ich", "ste\u00b7he", "so", "ge\u00b7wis\u00b7sen", "Kr\u00e4f\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Nahe. Und der Ausdruck des Gesichts", "tokens": ["Na\u00b7he", ".", "Und", "der", "Aus\u00b7druck", "des", "Ge\u00b7sichts"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "KON", "ART", "NN", "ART", "NN"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.9": {"text": "Wechselt stets bei mir in Intervallen.", "tokens": ["Wech\u00b7selt", "stets", "bei", "mir", "in", "In\u00b7ter\u00b7val\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "Ist dir das und andres an mir aufgefallen?", "tokens": ["Ist", "dir", "das", "und", "and\u00b7res", "an", "mir", "auf\u00b7ge\u00b7fal\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "KON", "PIS", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.12": {"line.1": {"text": "Nun, ich wei\u00df: Ich passe nicht ins Leben,", "tokens": ["Nun", ",", "ich", "wei\u00df", ":", "Ich", "pas\u00b7se", "nicht", "ins", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "PTKNEG", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Weil ich hungern kann. Ich werde nie", "tokens": ["Weil", "ich", "hun\u00b7gern", "kann", ".", "Ich", "wer\u00b7de", "nie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN", "$.", "PPER", "VAFIN", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Mein Geheimstes jemals Leuten preisgeben,", "tokens": ["Mein", "Ge\u00b7heims\u00b7tes", "je\u00b7mals", "Leu\u00b7ten", "preis\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "NN", "VVFIN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Die nicht gro\u00df sein k\u00f6nnen oder die", "tokens": ["Die", "nicht", "gro\u00df", "sein", "k\u00f6n\u00b7nen", "o\u00b7der", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "ADJD", "VAINF", "VMFIN", "KON", "ART"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Eng am Gelde h\u00e4ngen.", "tokens": ["Eng", "am", "Gel\u00b7de", "h\u00e4n\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Warum sollte ich mich denen aufdr\u00e4ngen!", "tokens": ["Wa\u00b7rum", "soll\u00b7te", "ich", "mich", "de\u00b7nen", "auf\u00b7dr\u00e4n\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "PDS", "VVINF", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.13": {"line.1": {"text": "Willst du, bitte, nun mal andre Leute", "tokens": ["Willst", "du", ",", "bit\u00b7te", ",", "nun", "mal", "and\u00b7re", "Leu\u00b7te"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "$,", "PTKANT", "$,", "ADV", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ganz diskret befragen,", "tokens": ["Ganz", "dis\u00b7kret", "be\u00b7fra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Was sie \u00fcber mich und meine Meinung sagen", "tokens": ["Was", "sie", "\u00fc\u00b7ber", "mich", "und", "mei\u00b7ne", "Mei\u00b7nung", "sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "PPER", "KON", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Und was ich f\u00fcr sie bedeute.", "tokens": ["Und", "was", "ich", "f\u00fcr", "sie", "be\u00b7deu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Gelt, du wei\u00dft, da\u00df ich nicht gern verspreche,", "tokens": ["Gelt", ",", "du", "wei\u00dft", ",", "da\u00df", "ich", "nicht", "gern", "ver\u00b7spre\u00b7che", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Wei\u00dft auch, da\u00df ich etwas halten kann?", "tokens": ["Wei\u00dft", "auch", ",", "da\u00df", "ich", "et\u00b7was", "hal\u00b7ten", "kann", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PPER", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und \u2013 \u2013 \u2013 Genug! Du bist mein Mann! \u2013", "tokens": ["Und", "\u2013", "\u2013", "\u2013", "Ge\u00b7nug", "!", "Du", "bist", "mein", "Mann", "!", "\u2013"], "token_info": ["word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "$(", "$(", "$(", "ADV", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lebe wohl! \u2013 Zahl' ich \u2013 zahlst du die Zeche?", "tokens": ["Le\u00b7be", "wohl", "!", "\u2013", "Zahl'", "ich", "\u2013", "zahlst", "du", "die", "Ze\u00b7che", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "$(", "VVIMP", "PPER", "$(", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}}}}