{"textgrid.poem.63903": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "Letzter Wille", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun schon in den letzten Z\u00fcgen", "tokens": ["Nun", "schon", "in", "den", "letz\u00b7ten", "Z\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mit erloschnem Augensterne", "tokens": ["Mit", "er\u00b7lo\u00b7schnem", "Au\u00b7gens\u00b7ter\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sehn wir das Jahrhundert liegen,", "tokens": ["Sehn", "wir", "das", "Jahr\u00b7hun\u00b7dert", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn sein St\u00fcndlein ist nicht ferne.", "tokens": ["Denn", "sein", "St\u00fcnd\u00b7lein", "ist", "nicht", "fer\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Harrend auf der Greisin Sterben", "tokens": ["Har\u00b7rend", "auf", "der", "Grei\u00b7sin", "Ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nahn dem harten Todesbette,", "tokens": ["Nahn", "dem", "har\u00b7ten", "To\u00b7des\u00b7bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Streitend, wer sie mag beerben", "tokens": ["Strei\u00b7tend", ",", "wer", "sie", "mag", "be\u00b7er\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "PWS", "PPER", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihre Kinder um die Wette.", "tokens": ["Ih\u00b7re", "Kin\u00b7der", "um", "die", "Wet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wen'ge nur vergie\u00dfen Tr\u00e4nen,", "tokens": ["Wen'\u00b7ge", "nur", "ver\u00b7gie\u00b7\u00dfen", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Denkend ihrer Lieb' und Treue,", "tokens": ["Den\u00b7kend", "ih\u00b7rer", "Lieb'", "und", "Treu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da die meisten kindisch w\u00e4hnen,", "tokens": ["Da", "die", "meis\u00b7ten", "kin\u00b7disch", "w\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weitaus sch\u00f6ner sei das Neue.", "tokens": ["Weit\u00b7aus", "sch\u00f6\u00b7ner", "sei", "das", "Neu\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Und sie grollen mit der Alten,", "tokens": ["Und", "sie", "grol\u00b7len", "mit", "der", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df sie oftmals mehr versprochen,", "tokens": ["Da\u00df", "sie", "oft\u00b7mals", "mehr", "ver\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als am Ende sie gehalten,", "tokens": ["Als", "am", "En\u00b7de", "sie", "ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch noch manches sonst verbrochen.", "tokens": ["Auch", "noch", "man\u00b7ches", "sonst", "ver\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Und die Dunkelm\u00e4nner kneifen,", "tokens": ["Und", "die", "Dun\u00b7kel\u00b7m\u00e4n\u00b7ner", "knei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df sie st\u00fcrmisch sich ger\u00fchret,", "tokens": ["Da\u00df", "sie", "st\u00fcr\u00b7misch", "sich", "ge\u00b7r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PRF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Um die Fesseln abzustreifen,", "tokens": ["Um", "die", "Fes\u00b7seln", "ab\u00b7zu\u00b7strei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die die Geister eng umschn\u00fcret.", "tokens": ["Die", "die", "Geis\u00b7ter", "eng", "um\u00b7schn\u00fc\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Pl\u00f6tzlich, furchtbar anzuschauen,", "tokens": ["Pl\u00f6tz\u00b7lich", ",", "furcht\u00b7bar", "an\u00b7zu\u00b7schau\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Richtet sich empor die Alte.", "tokens": ["Rich\u00b7tet", "sich", "em\u00b7por", "die", "Al\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKVZ", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwischen silberwei\u00dfen Brauen", "tokens": ["Zwi\u00b7schen", "sil\u00b7ber\u00b7wei\u00b7\u00dfen", "Brau\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Furcht sich tief die dunkle Falte.", "tokens": ["Furcht", "sich", "tief", "die", "dunk\u00b7le", "Fal\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Im entf\u00e4rbten Angesichte", "tokens": ["Im", "ent\u00b7f\u00e4rb\u00b7ten", "An\u00b7ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist's als ob ein Zornblitz glimme.", "tokens": ["Ist's", "als", "ob", "ein", "Zorn\u00b7blitz", "glim\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schweigt, ihr t\u00f6richt kecken Wichte!", "tokens": ["Schweigt", ",", "ihr", "t\u00f6\u00b7richt", "ke\u00b7cken", "Wich\u00b7te", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Ruft sie laut mit heisrer Stimme.", "tokens": ["Ruft", "sie", "laut", "mit", "heis\u00b7rer", "Stim\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Jeden Nachruf sollt ihr sparen,", "tokens": ["Je\u00b7den", "Nach\u00b7ruf", "sollt", "ihr", "spa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles Preisen, Schelten, L\u00e4stern.", "tokens": ["Al\u00b7les", "Prei\u00b7sen", ",", "Schel\u00b7ten", ",", "L\u00e4s\u00b7tern", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PIAT", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht das Heute kann erfahren,", "tokens": ["Nicht", "das", "Heu\u00b7te", "kann", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was bedeuten mag das Gestern.", "tokens": ["Was", "be\u00b7deu\u00b7ten", "mag", "das", "Ge\u00b7stern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVINF", "VMFIN", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "Darum keine Narrenspr\u00fcche", "tokens": ["Da\u00b7rum", "kei\u00b7ne", "Nar\u00b7ren\u00b7spr\u00fc\u00b7che"], "token_info": ["word", "word", "word"], "pos": ["PAV", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Haltet mir am offnen Grabe,", "tokens": ["Hal\u00b7tet", "mir", "am", "off\u00b7nen", "Gra\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weder Segen, weder Fl\u00fcche,", "tokens": ["We\u00b7der", "Se\u00b7gen", ",", "we\u00b7der", "Fl\u00fc\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da ich einen Wunsch nur habe:", "tokens": ["Da", "ich", "ei\u00b7nen", "Wunsch", "nur", "ha\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Da\u00df auf meinem Leichensteine", "tokens": ["Da\u00df", "auf", "mei\u00b7nem", "Lei\u00b7chen\u00b7stei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stehen soll das Wort zu lesen,", "tokens": ["Ste\u00b7hen", "soll", "das", "Wort", "zu", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wahrlich Ruhm genug dies eine:", "tokens": ["Wahr\u00b7lich", "Ruhm", "ge\u00b7nug", "dies", "ei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "PDS", "ART", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Was mir Gro\u00dfes sonst gelungen,", "tokens": ["Was", "mir", "Gro\u00b7\u00dfes", "sonst", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tritt zur\u00fcck vor diesem Namen.", "tokens": ["Tritt", "zu\u00b7r\u00fcck", "vor", "die\u00b7sem", "Na\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun, ihr Alten und ihr Jungen,", "tokens": ["Nun", ",", "ihr", "Al\u00b7ten", "und", "ihr", "Jun\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gute Nacht! \u2013 und damit Amen.", "tokens": ["Gu\u00b7te", "Nacht", "!", "\u2013", "und", "da\u00b7mit", "A\u00b7men", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "$(", "KON", "PAV", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Nun schon in den letzten Z\u00fcgen", "tokens": ["Nun", "schon", "in", "den", "letz\u00b7ten", "Z\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mit erloschnem Augensterne", "tokens": ["Mit", "er\u00b7lo\u00b7schnem", "Au\u00b7gens\u00b7ter\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sehn wir das Jahrhundert liegen,", "tokens": ["Sehn", "wir", "das", "Jahr\u00b7hun\u00b7dert", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn sein St\u00fcndlein ist nicht ferne.", "tokens": ["Denn", "sein", "St\u00fcnd\u00b7lein", "ist", "nicht", "fer\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Harrend auf der Greisin Sterben", "tokens": ["Har\u00b7rend", "auf", "der", "Grei\u00b7sin", "Ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nahn dem harten Todesbette,", "tokens": ["Nahn", "dem", "har\u00b7ten", "To\u00b7des\u00b7bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Streitend, wer sie mag beerben", "tokens": ["Strei\u00b7tend", ",", "wer", "sie", "mag", "be\u00b7er\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "PWS", "PPER", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihre Kinder um die Wette.", "tokens": ["Ih\u00b7re", "Kin\u00b7der", "um", "die", "Wet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Wen'ge nur vergie\u00dfen Tr\u00e4nen,", "tokens": ["Wen'\u00b7ge", "nur", "ver\u00b7gie\u00b7\u00dfen", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Denkend ihrer Lieb' und Treue,", "tokens": ["Den\u00b7kend", "ih\u00b7rer", "Lieb'", "und", "Treu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da die meisten kindisch w\u00e4hnen,", "tokens": ["Da", "die", "meis\u00b7ten", "kin\u00b7disch", "w\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weitaus sch\u00f6ner sei das Neue.", "tokens": ["Weit\u00b7aus", "sch\u00f6\u00b7ner", "sei", "das", "Neu\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Und sie grollen mit der Alten,", "tokens": ["Und", "sie", "grol\u00b7len", "mit", "der", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df sie oftmals mehr versprochen,", "tokens": ["Da\u00df", "sie", "oft\u00b7mals", "mehr", "ver\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als am Ende sie gehalten,", "tokens": ["Als", "am", "En\u00b7de", "sie", "ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch noch manches sonst verbrochen.", "tokens": ["Auch", "noch", "man\u00b7ches", "sonst", "ver\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Und die Dunkelm\u00e4nner kneifen,", "tokens": ["Und", "die", "Dun\u00b7kel\u00b7m\u00e4n\u00b7ner", "knei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df sie st\u00fcrmisch sich ger\u00fchret,", "tokens": ["Da\u00df", "sie", "st\u00fcr\u00b7misch", "sich", "ge\u00b7r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PRF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Um die Fesseln abzustreifen,", "tokens": ["Um", "die", "Fes\u00b7seln", "ab\u00b7zu\u00b7strei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die die Geister eng umschn\u00fcret.", "tokens": ["Die", "die", "Geis\u00b7ter", "eng", "um\u00b7schn\u00fc\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Pl\u00f6tzlich, furchtbar anzuschauen,", "tokens": ["Pl\u00f6tz\u00b7lich", ",", "furcht\u00b7bar", "an\u00b7zu\u00b7schau\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Richtet sich empor die Alte.", "tokens": ["Rich\u00b7tet", "sich", "em\u00b7por", "die", "Al\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKVZ", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwischen silberwei\u00dfen Brauen", "tokens": ["Zwi\u00b7schen", "sil\u00b7ber\u00b7wei\u00b7\u00dfen", "Brau\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Furcht sich tief die dunkle Falte.", "tokens": ["Furcht", "sich", "tief", "die", "dunk\u00b7le", "Fal\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Im entf\u00e4rbten Angesichte", "tokens": ["Im", "ent\u00b7f\u00e4rb\u00b7ten", "An\u00b7ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist's als ob ein Zornblitz glimme.", "tokens": ["Ist's", "als", "ob", "ein", "Zorn\u00b7blitz", "glim\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schweigt, ihr t\u00f6richt kecken Wichte!", "tokens": ["Schweigt", ",", "ihr", "t\u00f6\u00b7richt", "ke\u00b7cken", "Wich\u00b7te", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Ruft sie laut mit heisrer Stimme.", "tokens": ["Ruft", "sie", "laut", "mit", "heis\u00b7rer", "Stim\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Jeden Nachruf sollt ihr sparen,", "tokens": ["Je\u00b7den", "Nach\u00b7ruf", "sollt", "ihr", "spa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles Preisen, Schelten, L\u00e4stern.", "tokens": ["Al\u00b7les", "Prei\u00b7sen", ",", "Schel\u00b7ten", ",", "L\u00e4s\u00b7tern", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PIAT", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht das Heute kann erfahren,", "tokens": ["Nicht", "das", "Heu\u00b7te", "kann", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was bedeuten mag das Gestern.", "tokens": ["Was", "be\u00b7deu\u00b7ten", "mag", "das", "Ge\u00b7stern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVINF", "VMFIN", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.20": {"line.1": {"text": "Darum keine Narrenspr\u00fcche", "tokens": ["Da\u00b7rum", "kei\u00b7ne", "Nar\u00b7ren\u00b7spr\u00fc\u00b7che"], "token_info": ["word", "word", "word"], "pos": ["PAV", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Haltet mir am offnen Grabe,", "tokens": ["Hal\u00b7tet", "mir", "am", "off\u00b7nen", "Gra\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weder Segen, weder Fl\u00fcche,", "tokens": ["We\u00b7der", "Se\u00b7gen", ",", "we\u00b7der", "Fl\u00fc\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da ich einen Wunsch nur habe:", "tokens": ["Da", "ich", "ei\u00b7nen", "Wunsch", "nur", "ha\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Da\u00df auf meinem Leichensteine", "tokens": ["Da\u00df", "auf", "mei\u00b7nem", "Lei\u00b7chen\u00b7stei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stehen soll das Wort zu lesen,", "tokens": ["Ste\u00b7hen", "soll", "das", "Wort", "zu", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wahrlich Ruhm genug dies eine:", "tokens": ["Wahr\u00b7lich", "Ruhm", "ge\u00b7nug", "dies", "ei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "PDS", "ART", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Was mir Gro\u00dfes sonst gelungen,", "tokens": ["Was", "mir", "Gro\u00b7\u00dfes", "sonst", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tritt zur\u00fcck vor diesem Namen.", "tokens": ["Tritt", "zu\u00b7r\u00fcck", "vor", "die\u00b7sem", "Na\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun, ihr Alten und ihr Jungen,", "tokens": ["Nun", ",", "ihr", "Al\u00b7ten", "und", "ihr", "Jun\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gute Nacht! \u2013 und damit Amen.", "tokens": ["Gu\u00b7te", "Nacht", "!", "\u2013", "und", "da\u00b7mit", "A\u00b7men", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "$(", "KON", "PAV", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}