{"textgrid.poem.52241": {"metadata": {"author": {"name": "Freiligrath, Ferdinand", "birth": "N.A.", "death": "N.A."}, "title": "Zwei Flaggen", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Schiff der Mosel auf dem Rhein!", "tokens": ["Ein", "Schiff", "der", "Mo\u00b7sel", "auf", "dem", "Rhein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ART", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Es kam zu Berg \u2013 die Pferde keuchten!", "tokens": ["Es", "kam", "zu", "Berg", "\u2013", "die", "Pfer\u00b7de", "keuch\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$(", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Am Vordermast mit hellem Schein", "tokens": ["Am", "Vor\u00b7der\u00b7mast", "mit", "hel\u00b7lem", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sah ich die Flagge leuchten!", "tokens": ["Sah", "ich", "die", "Flag\u00b7ge", "leuch\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Lang wallend flog sie \u00fcbers Boot \u2013", "tokens": ["Lang", "wal\u00b7lend", "flog", "sie", "\u00fc\u00b7bers", "Boot", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VVFIN", "PPER", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Stattliche Farben, frisch und munter!", "tokens": ["Statt\u00b7li\u00b7che", "Far\u00b7ben", ",", "frisch", "und", "mun\u00b7ter", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "So wahr ich lebe: Blau, Wei\u00df, Rot!", "tokens": ["So", "wahr", "ich", "le\u00b7be", ":", "Blau", ",", "Wei\u00df", ",", "Rot", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "$.", "NN", "$,", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und grad' am Flaggenstock herunter!", "tokens": ["Und", "grad'", "am", "Flag\u00b7gen\u00b7stock", "her\u00b7un\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Anhielt ich staunend meinen Fu\u00df;", "tokens": ["An\u00b7hielt", "ich", "stau\u00b7nend", "mei\u00b7nen", "Fu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da drang vom Schiff zu meinem Ohre", "tokens": ["Da", "drang", "vom", "Schiff", "zu", "mei\u00b7nem", "Oh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Stolzlustig ein Franzosengru\u00df:", "tokens": ["Stolz\u00b7lus\u00b7tig", "ein", "Fran\u00b7zo\u00b7sen\u00b7gru\u00df", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbja doch, schau' her \u2013 die Trikolore!\u00ab", "tokens": ["\u00bb", "ja", "doch", ",", "schau'", "her", "\u2013", "die", "Tri\u00b7ko\u00b7lo\u00b7re", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "VVFIN", "PTKVZ", "$(", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ei, dacht ich zornig, seid nur still!", "tokens": ["Ei", ",", "dacht", "ich", "zor\u00b7nig", ",", "seid", "nur", "still", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "ADJD", "$,", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird doch noch deutsch bei euch gesprochen!", "tokens": ["Wird", "doch", "noch", "deutsch", "bei", "euch", "ge\u00b7spro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Lothringisch Volk von Thionville", "tokens": ["Loth\u00b7rin\u00b7gisch", "Volk", "von", "Thi\u00b7on\u00b7vil\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sollt' also nicht auf Frankreich pochen!", "tokens": ["Sollt'", "al\u00b7so", "nicht", "auf", "Fran\u00b7kreich", "po\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PTKNEG", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Somit den Wimpel lie\u00df ich ziehn;", "tokens": ["So\u00b7mit", "den", "Wim\u00b7pel", "lie\u00df", "ich", "ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bald schon verbargen ihn die Zweige.", "tokens": ["Bald", "schon", "ver\u00b7bar\u00b7gen", "ihn", "die", "Zwei\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bin ihm auf dem Rhein nicht gr\u00fcn,", "tokens": ["Ich", "bin", "ihm", "auf", "dem", "Rhein", "nicht", "gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ART", "NE", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des ist der liebe Gott mein Zeuge!", "tokens": ["Des", "ist", "der", "lie\u00b7be", "Gott", "mein", "Zeu\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und wollt' er anders auf ihn wehn,", "tokens": ["Und", "wollt'", "er", "an\u00b7ders", "auf", "ihn", "wehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als friedlich von beladnem Schiffe:", "tokens": ["Als", "fried\u00b7lich", "von", "be\u00b7lad\u00b7nem", "Schif\u00b7fe", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ich w\u00fcrde mit ihm Treffen stehn,", "tokens": ["Ich", "w\u00fcr\u00b7de", "mit", "ihm", "Tref\u00b7fen", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn zu den Schwertern Deutschland griffe!", "tokens": ["Wenn", "zu", "den", "Schwer\u00b7tern", "Deutschland", "grif\u00b7fe", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.4": {"line.1": {"text": "Das H\u00f6chste bleiben Land und Herd!", "tokens": ["Das", "H\u00f6chs\u00b7te", "blei\u00b7ben", "Land", "und", "Herd", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch sonst \u2013 kein Wort von blindem Hasse!", "tokens": ["Doch", "sonst", "\u2013", "kein", "Wort", "von", "blin\u00b7dem", "Has\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "PIAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auch uns ist dieses Banner wert:", "tokens": ["Auch", "uns", "ist", "die\u00b7ses", "Ban\u00b7ner", "wert", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es brach de Freiheit eine Gasse!", "tokens": ["Es", "brach", "de", "Frei\u00b7heit", "ei\u00b7ne", "Gas\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Noch ist es feucht von Juliblut \u2013", "tokens": ["Noch", "ist", "es", "feucht", "von", "Ju\u00b7lib\u00b7lut", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nennt eins, das edler und verwegner!", "tokens": ["Nennt", "eins", ",", "das", "ed\u00b7ler", "und", "ver\u00b7weg\u00b7ner", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "ART", "ADJA", "KON", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Drum: sind wir auch auf unsrer Hut,", "tokens": ["Drum", ":", "sind", "wir", "auch", "auf", "uns\u00b7rer", "Hut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$.", "VAFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ist uns gerecht doch solch ein Gegner!", "tokens": ["Ist", "uns", "ge\u00b7recht", "doch", "solch", "ein", "Geg\u00b7ner", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADV", "PIAT", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und runzeln wir ihm auch die Braun,", "tokens": ["Und", "run\u00b7zeln", "wir", "ihm", "auch", "die", "Braun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sagen doch: Ein wackrer K\u00e4mpfer! \u2013", "tokens": ["Wir", "sa\u00b7gen", "doch", ":", "Ein", "wack\u00b7rer", "K\u00e4mp\u00b7fer", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denselben Tag im Abendgraun", "tokens": ["Den\u00b7sel\u00b7ben", "Tag", "im", "A\u00b7bend\u00b7graun"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fuhr noch stromab ein K\u00f6lner D\u00e4mpfer.", "tokens": ["Fuhr", "noch", "stro\u00b7mab", "ein", "K\u00f6l\u00b7ner", "D\u00e4mp\u00b7fer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Dem flog, vom Winde flott geschwellt,", "tokens": ["Dem", "flog", ",", "vom", "Win\u00b7de", "flott", "ge\u00b7schwellt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "APPRART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Breit \u00fcbern Bord der Aar von Preu\u00dfen;", "tokens": ["Breit", "\u00fc\u00b7bern", "Bord", "der", "Aar", "von", "Preu\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Daneben, schwarz im gelben Feld,", "tokens": ["Da\u00b7ne\u00b7ben", ",", "schwarz", "im", "gel\u00b7ben", "Feld", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADJD", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Doppeladler aller Reu\u00dfen!", "tokens": ["Der", "Dop\u00b7pe\u00b7lad\u00b7ler", "al\u00b7ler", "Reu\u00b7\u00dfen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Derselbe schwarze, der zerfleischt", "tokens": ["Der\u00b7sel\u00b7be", "schwar\u00b7ze", ",", "der", "zer\u00b7fleischt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "ADJA", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den wei\u00dfen j\u00fcngst als gute Beute;", "tokens": ["Den", "wei\u00b7\u00dfen", "j\u00fcngst", "als", "gu\u00b7te", "Beu\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "KOUS", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Derselbe, der das Dach umkreischt", "tokens": ["Der\u00b7sel\u00b7be", ",", "der", "das", "Dach", "um\u00b7kreischt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "$,", "PRELS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wildfreier Bergbewohner heute;", "tokens": ["Wild\u00b7frei\u00b7er", "Berg\u00b7be\u00b7woh\u00b7ner", "heu\u00b7te", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "$."], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Derselbe, der von seinem Pol", "tokens": ["Der\u00b7sel\u00b7be", ",", "der", "von", "sei\u00b7nem", "Pol"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "$,", "PRELS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Rundsp\u00e4ht mit immer k\u00fchnerm Dr\u00e4uen,", "tokens": ["Rund\u00b7sp\u00e4ht", "mit", "im\u00b7mer", "k\u00fch\u00b7nerm", "Dr\u00e4u\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und, als der Despotie Symbol,", "tokens": ["Und", ",", "als", "der", "Des\u00b7po\u00b7tie", "Sym\u00b7bol", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Feind und verha\u00dft ist allen Freien!", "tokens": ["Feind", "und", "ver\u00b7ha\u00dft", "ist", "al\u00b7len", "Frei\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VAFIN", "PIAT", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Derselbe, der zu dieser Frist", "tokens": ["Der\u00b7sel\u00b7be", ",", "der", "zu", "die\u00b7ser", "Frist"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "$,", "PRELS", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als B\u00fcttel haust auf unsern Grenzen;", "tokens": ["Als", "B\u00fct\u00b7tel", "haust", "auf", "un\u00b7sern", "Gren\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der gegendeutsch und undeutsch ist,", "tokens": ["Der", "ge\u00b7gen\u00b7deutsch", "und", "un\u00b7deutsch", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und dem wir dennoch feig scherwenzen;", "tokens": ["Und", "dem", "wir", "den\u00b7noch", "feig", "scher\u00b7wen\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der nur aus Schlauheit eng und fest", "tokens": ["Der", "nur", "aus", "Schlau\u00b7heit", "eng", "und", "fest"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Adler diesseits sich verb\u00fcndet", "tokens": ["Den", "Ad\u00b7ler", "dies\u00b7seits", "sich", "ver\u00b7b\u00fcn\u00b7det"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PRF", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und keck in jedem deutschen Nest", "tokens": ["Und", "keck", "in", "je\u00b7dem", "deut\u00b7schen", "Nest"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Filial des eignen gr\u00fcndet!", "tokens": ["Ein", "Fi\u00b7li\u00b7al", "des", "eig\u00b7nen", "gr\u00fcn\u00b7det", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Derselbe! \u2013 Drum auch dieses Tal", "tokens": ["Der\u00b7sel\u00b7be", "!", "\u2013", "Drum", "auch", "die\u00b7ses", "Tal"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "$.", "$(", "PAV", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durchstrich er heut und diese Reben!", "tokens": ["Durch\u00b7strich", "er", "heut", "und", "die\u00b7se", "Re\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ADV", "KON", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Von einem deutschen Filial", "tokens": ["Von", "ei\u00b7nem", "deut\u00b7schen", "Fi\u00b7li\u00b7al"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nahm er den Flug nach Holland eben!", "tokens": ["Nahm", "er", "den", "Flug", "nach", "Hol\u00b7land", "e\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NE", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Drum auch mit freudigem Geklapp", "tokens": ["Drum", "auch", "mit", "freu\u00b7di\u00b7gem", "Ge\u00b7klapp"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schwirrt' unser Adler ihm entgegen!", "tokens": ["Schwirrt'", "un\u00b7ser", "Ad\u00b7ler", "ihm", "ent\u00b7ge\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Drum sausten beide auch stromab,", "tokens": ["Drum", "saus\u00b7ten", "bei\u00b7de", "auch", "stro\u00b7mab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Als ob \u2013 nach ", "tokens": ["Als", "ob", "\u2013", "nach"], "token_info": ["word", "word", "punct", "word"], "pos": ["KOUS", "KOUS", "$(", "APPR"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.9": {"line.1": {"text": "Hinblickt' ich knirschend \u00fcbern Strand: \u2013", "tokens": ["Hin\u00b7blickt'", "ich", "knir\u00b7schend", "\u00fc\u00b7bern", "Strand", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O Deutschland, du im Dienst der Steppe,", "tokens": ["O", "Deutschland", ",", "du", "im", "Dienst", "der", "Step\u00b7pe", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPER", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du mit Sibirien Hand in Hand,", "tokens": ["Du", "mit", "Si\u00b7bi\u00b7ri\u00b7en", "Hand", "in", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Du tragend des Kalm\u00fccken Schleppe!", "tokens": ["Du", "tra\u00b7gend", "des", "Kal\u00b7m\u00fc\u00b7cken", "Schlep\u00b7pe", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du vor dem Polenm\u00f6rder Zar", "tokens": ["Du", "vor", "dem", "Po\u00b7len\u00b7m\u00f6r\u00b7der", "Zar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In Unterw\u00fcrfigkeit zerflie\u00dfend!", "tokens": ["In", "Un\u00b7ter\u00b7w\u00fcr\u00b7fig\u00b7keit", "zer\u00b7flie\u00b7\u00dfend", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du seinen Sohn und seine Aar", "tokens": ["Du", "sei\u00b7nen", "Sohn", "und", "sei\u00b7ne", "Aar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mit B\u00f6llerschu\u00df am Rhein begr\u00fc\u00dfend!", "tokens": ["Mit", "B\u00f6l\u00b7ler\u00b7schu\u00df", "am", "Rhein", "be\u00b7gr\u00fc\u00b7\u00dfend", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NE", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ei, wie das girrt und kokettiert!", "tokens": ["Ei", ",", "wie", "das", "girrt", "und", "ko\u00b7ket\u00b7tiert", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PDS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ei, wie das um sich wirft mit K\u00fcssen!", "tokens": ["Ei", ",", "wie", "das", "um", "sich", "wirft", "mit", "K\u00fcs\u00b7sen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "APPR", "PRF", "VVFIN", "APPR", "NN", "$."], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Gl\u00fcck auf den Weg! Wohin er f\u00fchrt,", "tokens": ["Gl\u00fcck", "auf", "den", "Weg", "!", "Wo\u00b7hin", "er", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$.", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wir warten's ab \u2013 Weh, da\u00df wir m\u00fcssen!", "tokens": ["Wir", "war\u00b7ten's", "ab", "\u2013", "Weh", ",", "da\u00df", "wir", "m\u00fcs\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKVZ", "$(", "NN", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Gl\u00fcck zu! Doch das sagt euch der Rhein:", "tokens": ["Gl\u00fcck", "zu", "!", "Doch", "das", "sagt", "euch", "der", "Rhein", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "KON", "PDS", "VVFIN", "PPER", "ART", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Ob die Monarchen Freundschaft treiben \u2013", "tokens": ["Ob", "die", "Mon\u00b7ar\u00b7chen", "Freund\u00b7schaft", "trei\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "VVINF", "$("], "meter": "-+++-+-+-", "measure": "unknown.measure.penta"}, "line.7": {"text": "Die V\u00f6lker werden Feinde sein,", "tokens": ["Die", "V\u00f6l\u00b7ker", "wer\u00b7den", "Fein\u00b7de", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die V\u00f6lker werden Feinde bleiben!", "tokens": ["Die", "V\u00f6l\u00b7ker", "wer\u00b7den", "Fein\u00b7de", "blei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Geduld'ger Strom! du tr\u00e4gst und wiegst", "tokens": ["Ge\u00b7duld'\u00b7ger", "Strom", "!", "du", "tr\u00e4gst", "und", "wiegst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "PPER", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Franken Banner und des Slawen!", "tokens": ["Des", "Fran\u00b7ken", "Ban\u00b7ner", "und", "des", "Sla\u00b7wen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df du ein ", "tokens": ["Da\u00df", "du", "ein"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "In jeder Bucht, in jedem Hafen!", "tokens": ["In", "je\u00b7der", "Bucht", ",", "in", "je\u00b7dem", "Ha\u00b7fen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein einig deutsches, das \u2013 bereit,", "tokens": ["Ein", "ei\u00b7nig", "deut\u00b7sches", ",", "das", "\u2013", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "$,", "PRELS", "$(", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn alzu frech der Hahne kr\u00e4hte! \u2013", "tokens": ["Wenn", "al\u00b7zu", "frech", "der", "Hah\u00b7ne", "kr\u00e4h\u00b7te", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PTKA", "ADJD", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Stolz und beherzt zu gleicher Zeit", "tokens": ["Stolz", "und", "be\u00b7herzt", "zu", "glei\u00b7cher", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "ADJD", "APPR", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Des Russenadlers Gunst verschm\u00e4hte!", "tokens": ["Des", "Rus\u00b7se\u00b7nad\u00b7lers", "Gunst", "ver\u00b7schm\u00e4h\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ein Schiff der Mosel auf dem Rhein!", "tokens": ["Ein", "Schiff", "der", "Mo\u00b7sel", "auf", "dem", "Rhein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ART", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Es kam zu Berg \u2013 die Pferde keuchten!", "tokens": ["Es", "kam", "zu", "Berg", "\u2013", "die", "Pfer\u00b7de", "keuch\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$(", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Am Vordermast mit hellem Schein", "tokens": ["Am", "Vor\u00b7der\u00b7mast", "mit", "hel\u00b7lem", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sah ich die Flagge leuchten!", "tokens": ["Sah", "ich", "die", "Flag\u00b7ge", "leuch\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Lang wallend flog sie \u00fcbers Boot \u2013", "tokens": ["Lang", "wal\u00b7lend", "flog", "sie", "\u00fc\u00b7bers", "Boot", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VVFIN", "PPER", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Stattliche Farben, frisch und munter!", "tokens": ["Statt\u00b7li\u00b7che", "Far\u00b7ben", ",", "frisch", "und", "mun\u00b7ter", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "So wahr ich lebe: Blau, Wei\u00df, Rot!", "tokens": ["So", "wahr", "ich", "le\u00b7be", ":", "Blau", ",", "Wei\u00df", ",", "Rot", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "$.", "NN", "$,", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und grad' am Flaggenstock herunter!", "tokens": ["Und", "grad'", "am", "Flag\u00b7gen\u00b7stock", "her\u00b7un\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Anhielt ich staunend meinen Fu\u00df;", "tokens": ["An\u00b7hielt", "ich", "stau\u00b7nend", "mei\u00b7nen", "Fu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da drang vom Schiff zu meinem Ohre", "tokens": ["Da", "drang", "vom", "Schiff", "zu", "mei\u00b7nem", "Oh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Stolzlustig ein Franzosengru\u00df:", "tokens": ["Stolz\u00b7lus\u00b7tig", "ein", "Fran\u00b7zo\u00b7sen\u00b7gru\u00df", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbja doch, schau' her \u2013 die Trikolore!\u00ab", "tokens": ["\u00bb", "ja", "doch", ",", "schau'", "her", "\u2013", "die", "Tri\u00b7ko\u00b7lo\u00b7re", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "VVFIN", "PTKVZ", "$(", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ei, dacht ich zornig, seid nur still!", "tokens": ["Ei", ",", "dacht", "ich", "zor\u00b7nig", ",", "seid", "nur", "still", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "ADJD", "$,", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird doch noch deutsch bei euch gesprochen!", "tokens": ["Wird", "doch", "noch", "deutsch", "bei", "euch", "ge\u00b7spro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Lothringisch Volk von Thionville", "tokens": ["Loth\u00b7rin\u00b7gisch", "Volk", "von", "Thi\u00b7on\u00b7vil\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sollt' also nicht auf Frankreich pochen!", "tokens": ["Sollt'", "al\u00b7so", "nicht", "auf", "Fran\u00b7kreich", "po\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PTKNEG", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Somit den Wimpel lie\u00df ich ziehn;", "tokens": ["So\u00b7mit", "den", "Wim\u00b7pel", "lie\u00df", "ich", "ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bald schon verbargen ihn die Zweige.", "tokens": ["Bald", "schon", "ver\u00b7bar\u00b7gen", "ihn", "die", "Zwei\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bin ihm auf dem Rhein nicht gr\u00fcn,", "tokens": ["Ich", "bin", "ihm", "auf", "dem", "Rhein", "nicht", "gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ART", "NE", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des ist der liebe Gott mein Zeuge!", "tokens": ["Des", "ist", "der", "lie\u00b7be", "Gott", "mein", "Zeu\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und wollt' er anders auf ihn wehn,", "tokens": ["Und", "wollt'", "er", "an\u00b7ders", "auf", "ihn", "wehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als friedlich von beladnem Schiffe:", "tokens": ["Als", "fried\u00b7lich", "von", "be\u00b7lad\u00b7nem", "Schif\u00b7fe", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ich w\u00fcrde mit ihm Treffen stehn,", "tokens": ["Ich", "w\u00fcr\u00b7de", "mit", "ihm", "Tref\u00b7fen", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn zu den Schwertern Deutschland griffe!", "tokens": ["Wenn", "zu", "den", "Schwer\u00b7tern", "Deutschland", "grif\u00b7fe", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.15": {"line.1": {"text": "Das H\u00f6chste bleiben Land und Herd!", "tokens": ["Das", "H\u00f6chs\u00b7te", "blei\u00b7ben", "Land", "und", "Herd", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch sonst \u2013 kein Wort von blindem Hasse!", "tokens": ["Doch", "sonst", "\u2013", "kein", "Wort", "von", "blin\u00b7dem", "Has\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "PIAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auch uns ist dieses Banner wert:", "tokens": ["Auch", "uns", "ist", "die\u00b7ses", "Ban\u00b7ner", "wert", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es brach de Freiheit eine Gasse!", "tokens": ["Es", "brach", "de", "Frei\u00b7heit", "ei\u00b7ne", "Gas\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Noch ist es feucht von Juliblut \u2013", "tokens": ["Noch", "ist", "es", "feucht", "von", "Ju\u00b7lib\u00b7lut", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nennt eins, das edler und verwegner!", "tokens": ["Nennt", "eins", ",", "das", "ed\u00b7ler", "und", "ver\u00b7weg\u00b7ner", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "ART", "ADJA", "KON", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Drum: sind wir auch auf unsrer Hut,", "tokens": ["Drum", ":", "sind", "wir", "auch", "auf", "uns\u00b7rer", "Hut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$.", "VAFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ist uns gerecht doch solch ein Gegner!", "tokens": ["Ist", "uns", "ge\u00b7recht", "doch", "solch", "ein", "Geg\u00b7ner", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADV", "PIAT", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Und runzeln wir ihm auch die Braun,", "tokens": ["Und", "run\u00b7zeln", "wir", "ihm", "auch", "die", "Braun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sagen doch: Ein wackrer K\u00e4mpfer! \u2013", "tokens": ["Wir", "sa\u00b7gen", "doch", ":", "Ein", "wack\u00b7rer", "K\u00e4mp\u00b7fer", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denselben Tag im Abendgraun", "tokens": ["Den\u00b7sel\u00b7ben", "Tag", "im", "A\u00b7bend\u00b7graun"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fuhr noch stromab ein K\u00f6lner D\u00e4mpfer.", "tokens": ["Fuhr", "noch", "stro\u00b7mab", "ein", "K\u00f6l\u00b7ner", "D\u00e4mp\u00b7fer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Dem flog, vom Winde flott geschwellt,", "tokens": ["Dem", "flog", ",", "vom", "Win\u00b7de", "flott", "ge\u00b7schwellt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "APPRART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Breit \u00fcbern Bord der Aar von Preu\u00dfen;", "tokens": ["Breit", "\u00fc\u00b7bern", "Bord", "der", "Aar", "von", "Preu\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Daneben, schwarz im gelben Feld,", "tokens": ["Da\u00b7ne\u00b7ben", ",", "schwarz", "im", "gel\u00b7ben", "Feld", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADJD", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Doppeladler aller Reu\u00dfen!", "tokens": ["Der", "Dop\u00b7pe\u00b7lad\u00b7ler", "al\u00b7ler", "Reu\u00b7\u00dfen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Derselbe schwarze, der zerfleischt", "tokens": ["Der\u00b7sel\u00b7be", "schwar\u00b7ze", ",", "der", "zer\u00b7fleischt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "ADJA", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den wei\u00dfen j\u00fcngst als gute Beute;", "tokens": ["Den", "wei\u00b7\u00dfen", "j\u00fcngst", "als", "gu\u00b7te", "Beu\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "KOUS", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Derselbe, der das Dach umkreischt", "tokens": ["Der\u00b7sel\u00b7be", ",", "der", "das", "Dach", "um\u00b7kreischt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "$,", "PRELS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wildfreier Bergbewohner heute;", "tokens": ["Wild\u00b7frei\u00b7er", "Berg\u00b7be\u00b7woh\u00b7ner", "heu\u00b7te", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "$."], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Derselbe, der von seinem Pol", "tokens": ["Der\u00b7sel\u00b7be", ",", "der", "von", "sei\u00b7nem", "Pol"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "$,", "PRELS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Rundsp\u00e4ht mit immer k\u00fchnerm Dr\u00e4uen,", "tokens": ["Rund\u00b7sp\u00e4ht", "mit", "im\u00b7mer", "k\u00fch\u00b7nerm", "Dr\u00e4u\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und, als der Despotie Symbol,", "tokens": ["Und", ",", "als", "der", "Des\u00b7po\u00b7tie", "Sym\u00b7bol", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Feind und verha\u00dft ist allen Freien!", "tokens": ["Feind", "und", "ver\u00b7ha\u00dft", "ist", "al\u00b7len", "Frei\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VAFIN", "PIAT", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.18": {"line.1": {"text": "Derselbe, der zu dieser Frist", "tokens": ["Der\u00b7sel\u00b7be", ",", "der", "zu", "die\u00b7ser", "Frist"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "$,", "PRELS", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als B\u00fcttel haust auf unsern Grenzen;", "tokens": ["Als", "B\u00fct\u00b7tel", "haust", "auf", "un\u00b7sern", "Gren\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der gegendeutsch und undeutsch ist,", "tokens": ["Der", "ge\u00b7gen\u00b7deutsch", "und", "un\u00b7deutsch", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und dem wir dennoch feig scherwenzen;", "tokens": ["Und", "dem", "wir", "den\u00b7noch", "feig", "scher\u00b7wen\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der nur aus Schlauheit eng und fest", "tokens": ["Der", "nur", "aus", "Schlau\u00b7heit", "eng", "und", "fest"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Adler diesseits sich verb\u00fcndet", "tokens": ["Den", "Ad\u00b7ler", "dies\u00b7seits", "sich", "ver\u00b7b\u00fcn\u00b7det"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PRF", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und keck in jedem deutschen Nest", "tokens": ["Und", "keck", "in", "je\u00b7dem", "deut\u00b7schen", "Nest"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Filial des eignen gr\u00fcndet!", "tokens": ["Ein", "Fi\u00b7li\u00b7al", "des", "eig\u00b7nen", "gr\u00fcn\u00b7det", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Derselbe! \u2013 Drum auch dieses Tal", "tokens": ["Der\u00b7sel\u00b7be", "!", "\u2013", "Drum", "auch", "die\u00b7ses", "Tal"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "$.", "$(", "PAV", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durchstrich er heut und diese Reben!", "tokens": ["Durch\u00b7strich", "er", "heut", "und", "die\u00b7se", "Re\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ADV", "KON", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Von einem deutschen Filial", "tokens": ["Von", "ei\u00b7nem", "deut\u00b7schen", "Fi\u00b7li\u00b7al"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nahm er den Flug nach Holland eben!", "tokens": ["Nahm", "er", "den", "Flug", "nach", "Hol\u00b7land", "e\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NE", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Drum auch mit freudigem Geklapp", "tokens": ["Drum", "auch", "mit", "freu\u00b7di\u00b7gem", "Ge\u00b7klapp"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schwirrt' unser Adler ihm entgegen!", "tokens": ["Schwirrt'", "un\u00b7ser", "Ad\u00b7ler", "ihm", "ent\u00b7ge\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Drum sausten beide auch stromab,", "tokens": ["Drum", "saus\u00b7ten", "bei\u00b7de", "auch", "stro\u00b7mab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Als ob \u2013 nach ", "tokens": ["Als", "ob", "\u2013", "nach"], "token_info": ["word", "word", "punct", "word"], "pos": ["KOUS", "KOUS", "$(", "APPR"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.20": {"line.1": {"text": "Hinblickt' ich knirschend \u00fcbern Strand: \u2013", "tokens": ["Hin\u00b7blickt'", "ich", "knir\u00b7schend", "\u00fc\u00b7bern", "Strand", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O Deutschland, du im Dienst der Steppe,", "tokens": ["O", "Deutschland", ",", "du", "im", "Dienst", "der", "Step\u00b7pe", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPER", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du mit Sibirien Hand in Hand,", "tokens": ["Du", "mit", "Si\u00b7bi\u00b7ri\u00b7en", "Hand", "in", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Du tragend des Kalm\u00fccken Schleppe!", "tokens": ["Du", "tra\u00b7gend", "des", "Kal\u00b7m\u00fc\u00b7cken", "Schlep\u00b7pe", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du vor dem Polenm\u00f6rder Zar", "tokens": ["Du", "vor", "dem", "Po\u00b7len\u00b7m\u00f6r\u00b7der", "Zar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In Unterw\u00fcrfigkeit zerflie\u00dfend!", "tokens": ["In", "Un\u00b7ter\u00b7w\u00fcr\u00b7fig\u00b7keit", "zer\u00b7flie\u00b7\u00dfend", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Du seinen Sohn und seine Aar", "tokens": ["Du", "sei\u00b7nen", "Sohn", "und", "sei\u00b7ne", "Aar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mit B\u00f6llerschu\u00df am Rhein begr\u00fc\u00dfend!", "tokens": ["Mit", "B\u00f6l\u00b7ler\u00b7schu\u00df", "am", "Rhein", "be\u00b7gr\u00fc\u00b7\u00dfend", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NE", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Ei, wie das girrt und kokettiert!", "tokens": ["Ei", ",", "wie", "das", "girrt", "und", "ko\u00b7ket\u00b7tiert", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PDS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ei, wie das um sich wirft mit K\u00fcssen!", "tokens": ["Ei", ",", "wie", "das", "um", "sich", "wirft", "mit", "K\u00fcs\u00b7sen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "APPR", "PRF", "VVFIN", "APPR", "NN", "$."], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Gl\u00fcck auf den Weg! Wohin er f\u00fchrt,", "tokens": ["Gl\u00fcck", "auf", "den", "Weg", "!", "Wo\u00b7hin", "er", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$.", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wir warten's ab \u2013 Weh, da\u00df wir m\u00fcssen!", "tokens": ["Wir", "war\u00b7ten's", "ab", "\u2013", "Weh", ",", "da\u00df", "wir", "m\u00fcs\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKVZ", "$(", "NN", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Gl\u00fcck zu! Doch das sagt euch der Rhein:", "tokens": ["Gl\u00fcck", "zu", "!", "Doch", "das", "sagt", "euch", "der", "Rhein", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "KON", "PDS", "VVFIN", "PPER", "ART", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Ob die Monarchen Freundschaft treiben \u2013", "tokens": ["Ob", "die", "Mon\u00b7ar\u00b7chen", "Freund\u00b7schaft", "trei\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "VVINF", "$("], "meter": "-+++-+-+-", "measure": "unknown.measure.penta"}, "line.7": {"text": "Die V\u00f6lker werden Feinde sein,", "tokens": ["Die", "V\u00f6l\u00b7ker", "wer\u00b7den", "Fein\u00b7de", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die V\u00f6lker werden Feinde bleiben!", "tokens": ["Die", "V\u00f6l\u00b7ker", "wer\u00b7den", "Fein\u00b7de", "blei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Geduld'ger Strom! du tr\u00e4gst und wiegst", "tokens": ["Ge\u00b7duld'\u00b7ger", "Strom", "!", "du", "tr\u00e4gst", "und", "wiegst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "PPER", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Franken Banner und des Slawen!", "tokens": ["Des", "Fran\u00b7ken", "Ban\u00b7ner", "und", "des", "Sla\u00b7wen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df du ein ", "tokens": ["Da\u00df", "du", "ein"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "In jeder Bucht, in jedem Hafen!", "tokens": ["In", "je\u00b7der", "Bucht", ",", "in", "je\u00b7dem", "Ha\u00b7fen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein einig deutsches, das \u2013 bereit,", "tokens": ["Ein", "ei\u00b7nig", "deut\u00b7sches", ",", "das", "\u2013", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "$,", "PRELS", "$(", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn alzu frech der Hahne kr\u00e4hte! \u2013", "tokens": ["Wenn", "al\u00b7zu", "frech", "der", "Hah\u00b7ne", "kr\u00e4h\u00b7te", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PTKA", "ADJD", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Stolz und beherzt zu gleicher Zeit", "tokens": ["Stolz", "und", "be\u00b7herzt", "zu", "glei\u00b7cher", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "ADJD", "APPR", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Des Russenadlers Gunst verschm\u00e4hte!", "tokens": ["Des", "Rus\u00b7se\u00b7nad\u00b7lers", "Gunst", "ver\u00b7schm\u00e4h\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}