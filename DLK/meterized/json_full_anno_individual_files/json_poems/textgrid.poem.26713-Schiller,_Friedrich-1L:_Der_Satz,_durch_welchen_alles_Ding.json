{"textgrid.poem.26713": {"metadata": {"author": {"name": "Schiller, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Satz, durch welchen alles Ding", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Satz, durch welchen alles Ding", "tokens": ["Der", "Satz", ",", "durch", "wel\u00b7chen", "al\u00b7les", "Ding"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "PWAT", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bestand und Form empfangen,", "tokens": ["Be\u00b7stand", "und", "Form", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Kloben, woran Zeus den Ring", "tokens": ["Der", "Klo\u00b7ben", ",", "wo\u00b7ran", "Zeus", "den", "Ring"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "NE", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Welt, die sonst in Scherben ging,", "tokens": ["Der", "Welt", ",", "die", "sonst", "in", "Scher\u00b7ben", "ging", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vorsichtig aufgehangen,", "tokens": ["Vor\u00b7sich\u00b7tig", "auf\u00b7ge\u00b7han\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Den nenn ich einen gro\u00dfen Geist,", "tokens": ["Den", "nenn", "ich", "ei\u00b7nen", "gro\u00b7\u00dfen", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der mir ergr\u00fcndet, wie er hei\u00dft,", "tokens": ["Der", "mir", "er\u00b7gr\u00fcn\u00b7det", ",", "wie", "er", "hei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Er hei\u00dft: Zehn ist nicht Zw\u00f6lfe.", "tokens": ["Er", "hei\u00dft", ":", "Zehn", "ist", "nicht", "Zw\u00f6l\u00b7fe", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "CARD", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Der Schnee macht kalt, das Feuer brennt,", "tokens": ["Der", "Schnee", "macht", "kalt", ",", "das", "Feu\u00b7er", "brennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Mensch geht auf zwei F\u00fc\u00dfen,", "tokens": ["Der", "Mensch", "geht", "auf", "zwei", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Sonne scheint am Firmament,", "tokens": ["Die", "Son\u00b7ne", "scheint", "am", "Fir\u00b7ma\u00b7ment", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das kann, wer auch nicht Logik kennt,", "tokens": ["Das", "kann", ",", "wer", "auch", "nicht", "Lo\u00b7gik", "kennt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "$,", "PWS", "ADV", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durch seine Sinne wissen.", "tokens": ["Durch", "sei\u00b7ne", "Sin\u00b7ne", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Doch wer Metaphysik studiert,", "tokens": ["Doch", "wer", "Me\u00b7ta\u00b7phy\u00b7sik", "stu\u00b7diert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der wei\u00df, da\u00df, wer verbrennt, nicht friert,", "tokens": ["Der", "wei\u00df", ",", "da\u00df", ",", "wer", "ver\u00b7brennt", ",", "nicht", "friert", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KOUS", "$,", "PWS", "VVFIN", "$,", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wei\u00df, da\u00df das Nasse feuchtet", "tokens": ["Wei\u00df", ",", "da\u00df", "das", "Nas\u00b7se", "feuch\u00b7tet"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Und da\u00df das Helle leuchtet.", "tokens": ["Und", "da\u00df", "das", "Hel\u00b7le", "leuch\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Homerus singt sein Hochgedicht,", "tokens": ["Ho\u00b7me\u00b7rus", "singt", "sein", "Hoch\u00b7ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Der Held besteht Gefahren,", "tokens": ["Der", "Held", "be\u00b7steht", "Ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der brave Mann tut seine Pflicht", "tokens": ["Der", "bra\u00b7ve", "Mann", "tut", "sei\u00b7ne", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und tat sie, ich verhehl es nicht,", "tokens": ["Und", "tat", "sie", ",", "ich", "ver\u00b7hehl", "es", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Eh noch Weltweise waren;", "tokens": ["Eh", "noch", "Welt\u00b7wei\u00b7se", "wa\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "VAFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Doch hat Genie und Herz vollbracht,", "tokens": ["Doch", "hat", "Ge\u00b7nie", "und", "Herz", "voll\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Sogleich wird auch von diesen", "tokens": ["Sog\u00b7leich", "wird", "auch", "von", "die\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "PDAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Die M\u00f6glichkeit bewiesen.", "tokens": ["Die", "M\u00f6g\u00b7lich\u00b7keit", "be\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Im Leben gilt der St\u00e4rke Recht,", "tokens": ["Im", "Le\u00b7ben", "gilt", "der", "St\u00e4r\u00b7ke", "Recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Schwachen trotzt der K\u00fchne,", "tokens": ["Dem", "Schwa\u00b7chen", "trotzt", "der", "K\u00fch\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wer nicht gebieten kann, ist Knecht,", "tokens": ["Wer", "nicht", "ge\u00b7bie\u00b7ten", "kann", ",", "ist", "Knecht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVINF", "VMFIN", "$,", "VAFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sonst geht es ganz ertr\u00e4glich schlecht", "tokens": ["Sonst", "geht", "es", "ganz", "er\u00b7tr\u00e4g\u00b7lich", "schlecht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auf dieser Erdenb\u00fchne.", "tokens": ["Auf", "die\u00b7ser", "Er\u00b7den\u00b7b\u00fch\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Doch wie es w\u00e4re, fing der Plan", "tokens": ["Doch", "wie", "es", "w\u00e4\u00b7re", ",", "fing", "der", "Plan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "VAFIN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der Welt nur erst von vornen an,", "tokens": ["Der", "Welt", "nur", "erst", "von", "vor\u00b7nen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ist in Moralsystemen", "tokens": ["Ist", "in", "Mo\u00b7ral\u00b7sys\u00b7te\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "APPR", "NN"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.9": {"text": "Ausf\u00fchrlich zu vernehmen.", "tokens": ["Aus\u00b7f\u00fchr\u00b7lich", "zu", "ver\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbder Mensch bedarf des Menschen sehr", "tokens": ["\u00bb", "der", "Mensch", "be\u00b7darf", "des", "Men\u00b7schen", "sehr"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu seinem gro\u00dfen Ziele,", "tokens": ["Zu", "sei\u00b7nem", "gro\u00b7\u00dfen", "Zie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nur in dem Ganzen wirket er,", "tokens": ["Nur", "in", "dem", "Gan\u00b7zen", "wir\u00b7ket", "er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Viel Tropfen geben erst das Meer,", "tokens": ["Viel", "Trop\u00b7fen", "ge\u00b7ben", "erst", "das", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Viel Wasser treibt die M\u00fchle.", "tokens": ["Viel", "Was\u00b7ser", "treibt", "die", "M\u00fch\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Drum flieht der wilden W\u00f6lfe Stand", "tokens": ["Drum", "flieht", "der", "wil\u00b7den", "W\u00f6l\u00b7fe", "Stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und kn\u00fcpft des Staates daurend Band.\u00ab", "tokens": ["Und", "kn\u00fcpft", "des", "Staa\u00b7tes", "dau\u00b7rend", "Band", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VVPP", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So lehren vom Katheder", "tokens": ["So", "leh\u00b7ren", "vom", "Ka\u00b7the\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "NN"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.9": {"text": "Herr Pufendorf und Feder.", "tokens": ["Herr", "Pu\u00b7fen\u00b7dorf", "und", "Fe\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Doch weil, was ein Professor spricht,", "tokens": ["Doch", "weil", ",", "was", "ein", "Pro\u00b7fes\u00b7sor", "spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht gleich zu allen dringet,", "tokens": ["Nicht", "gleich", "zu", "al\u00b7len", "drin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So \u00fcbt Natur die Mutterpflicht", "tokens": ["So", "\u00fcbt", "Na\u00b7tur", "die", "Mut\u00b7ter\u00b7pflicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sorgt, da\u00df nie die Kette bricht", "tokens": ["Und", "sorgt", ",", "da\u00df", "nie", "die", "Ket\u00b7te", "bricht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und da\u00df der Reif nie springet.", "tokens": ["Und", "da\u00df", "der", "Reif", "nie", "sprin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Einstweilen, bis den Bau der Welt", "tokens": ["Einst\u00b7wei\u00b7len", ",", "bis", "den", "Bau", "der", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Philosophie zusammenh\u00e4lt,", "tokens": ["Phi\u00b7lo\u00b7so\u00b7phie", "zu\u00b7sam\u00b7men\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Erh\u00e4lt sie das Getriebe", "tokens": ["Er\u00b7h\u00e4lt", "sie", "das", "Ge\u00b7trie\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Durch Hunger und durch Liebe.", "tokens": ["Durch", "Hun\u00b7ger", "und", "durch", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Der Satz, durch welchen alles Ding", "tokens": ["Der", "Satz", ",", "durch", "wel\u00b7chen", "al\u00b7les", "Ding"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "PWAT", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bestand und Form empfangen,", "tokens": ["Be\u00b7stand", "und", "Form", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Kloben, woran Zeus den Ring", "tokens": ["Der", "Klo\u00b7ben", ",", "wo\u00b7ran", "Zeus", "den", "Ring"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "NE", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Welt, die sonst in Scherben ging,", "tokens": ["Der", "Welt", ",", "die", "sonst", "in", "Scher\u00b7ben", "ging", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vorsichtig aufgehangen,", "tokens": ["Vor\u00b7sich\u00b7tig", "auf\u00b7ge\u00b7han\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Den nenn ich einen gro\u00dfen Geist,", "tokens": ["Den", "nenn", "ich", "ei\u00b7nen", "gro\u00b7\u00dfen", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der mir ergr\u00fcndet, wie er hei\u00dft,", "tokens": ["Der", "mir", "er\u00b7gr\u00fcn\u00b7det", ",", "wie", "er", "hei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Er hei\u00dft: Zehn ist nicht Zw\u00f6lfe.", "tokens": ["Er", "hei\u00dft", ":", "Zehn", "ist", "nicht", "Zw\u00f6l\u00b7fe", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "CARD", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Der Schnee macht kalt, das Feuer brennt,", "tokens": ["Der", "Schnee", "macht", "kalt", ",", "das", "Feu\u00b7er", "brennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Mensch geht auf zwei F\u00fc\u00dfen,", "tokens": ["Der", "Mensch", "geht", "auf", "zwei", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Sonne scheint am Firmament,", "tokens": ["Die", "Son\u00b7ne", "scheint", "am", "Fir\u00b7ma\u00b7ment", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das kann, wer auch nicht Logik kennt,", "tokens": ["Das", "kann", ",", "wer", "auch", "nicht", "Lo\u00b7gik", "kennt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "$,", "PWS", "ADV", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durch seine Sinne wissen.", "tokens": ["Durch", "sei\u00b7ne", "Sin\u00b7ne", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Doch wer Metaphysik studiert,", "tokens": ["Doch", "wer", "Me\u00b7ta\u00b7phy\u00b7sik", "stu\u00b7diert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der wei\u00df, da\u00df, wer verbrennt, nicht friert,", "tokens": ["Der", "wei\u00df", ",", "da\u00df", ",", "wer", "ver\u00b7brennt", ",", "nicht", "friert", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KOUS", "$,", "PWS", "VVFIN", "$,", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wei\u00df, da\u00df das Nasse feuchtet", "tokens": ["Wei\u00df", ",", "da\u00df", "das", "Nas\u00b7se", "feuch\u00b7tet"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Und da\u00df das Helle leuchtet.", "tokens": ["Und", "da\u00df", "das", "Hel\u00b7le", "leuch\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Homerus singt sein Hochgedicht,", "tokens": ["Ho\u00b7me\u00b7rus", "singt", "sein", "Hoch\u00b7ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Der Held besteht Gefahren,", "tokens": ["Der", "Held", "be\u00b7steht", "Ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der brave Mann tut seine Pflicht", "tokens": ["Der", "bra\u00b7ve", "Mann", "tut", "sei\u00b7ne", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und tat sie, ich verhehl es nicht,", "tokens": ["Und", "tat", "sie", ",", "ich", "ver\u00b7hehl", "es", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Eh noch Weltweise waren;", "tokens": ["Eh", "noch", "Welt\u00b7wei\u00b7se", "wa\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "VAFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Doch hat Genie und Herz vollbracht,", "tokens": ["Doch", "hat", "Ge\u00b7nie", "und", "Herz", "voll\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Sogleich wird auch von diesen", "tokens": ["Sog\u00b7leich", "wird", "auch", "von", "die\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "PDAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Die M\u00f6glichkeit bewiesen.", "tokens": ["Die", "M\u00f6g\u00b7lich\u00b7keit", "be\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Im Leben gilt der St\u00e4rke Recht,", "tokens": ["Im", "Le\u00b7ben", "gilt", "der", "St\u00e4r\u00b7ke", "Recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Schwachen trotzt der K\u00fchne,", "tokens": ["Dem", "Schwa\u00b7chen", "trotzt", "der", "K\u00fch\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wer nicht gebieten kann, ist Knecht,", "tokens": ["Wer", "nicht", "ge\u00b7bie\u00b7ten", "kann", ",", "ist", "Knecht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVINF", "VMFIN", "$,", "VAFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sonst geht es ganz ertr\u00e4glich schlecht", "tokens": ["Sonst", "geht", "es", "ganz", "er\u00b7tr\u00e4g\u00b7lich", "schlecht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auf dieser Erdenb\u00fchne.", "tokens": ["Auf", "die\u00b7ser", "Er\u00b7den\u00b7b\u00fch\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Doch wie es w\u00e4re, fing der Plan", "tokens": ["Doch", "wie", "es", "w\u00e4\u00b7re", ",", "fing", "der", "Plan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "VAFIN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der Welt nur erst von vornen an,", "tokens": ["Der", "Welt", "nur", "erst", "von", "vor\u00b7nen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ist in Moralsystemen", "tokens": ["Ist", "in", "Mo\u00b7ral\u00b7sys\u00b7te\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "APPR", "NN"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.9": {"text": "Ausf\u00fchrlich zu vernehmen.", "tokens": ["Aus\u00b7f\u00fchr\u00b7lich", "zu", "ver\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "\u00bbder Mensch bedarf des Menschen sehr", "tokens": ["\u00bb", "der", "Mensch", "be\u00b7darf", "des", "Men\u00b7schen", "sehr"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu seinem gro\u00dfen Ziele,", "tokens": ["Zu", "sei\u00b7nem", "gro\u00b7\u00dfen", "Zie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nur in dem Ganzen wirket er,", "tokens": ["Nur", "in", "dem", "Gan\u00b7zen", "wir\u00b7ket", "er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Viel Tropfen geben erst das Meer,", "tokens": ["Viel", "Trop\u00b7fen", "ge\u00b7ben", "erst", "das", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Viel Wasser treibt die M\u00fchle.", "tokens": ["Viel", "Was\u00b7ser", "treibt", "die", "M\u00fch\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Drum flieht der wilden W\u00f6lfe Stand", "tokens": ["Drum", "flieht", "der", "wil\u00b7den", "W\u00f6l\u00b7fe", "Stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und kn\u00fcpft des Staates daurend Band.\u00ab", "tokens": ["Und", "kn\u00fcpft", "des", "Staa\u00b7tes", "dau\u00b7rend", "Band", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VVPP", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So lehren vom Katheder", "tokens": ["So", "leh\u00b7ren", "vom", "Ka\u00b7the\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "NN"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.9": {"text": "Herr Pufendorf und Feder.", "tokens": ["Herr", "Pu\u00b7fen\u00b7dorf", "und", "Fe\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Doch weil, was ein Professor spricht,", "tokens": ["Doch", "weil", ",", "was", "ein", "Pro\u00b7fes\u00b7sor", "spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht gleich zu allen dringet,", "tokens": ["Nicht", "gleich", "zu", "al\u00b7len", "drin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So \u00fcbt Natur die Mutterpflicht", "tokens": ["So", "\u00fcbt", "Na\u00b7tur", "die", "Mut\u00b7ter\u00b7pflicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sorgt, da\u00df nie die Kette bricht", "tokens": ["Und", "sorgt", ",", "da\u00df", "nie", "die", "Ket\u00b7te", "bricht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und da\u00df der Reif nie springet.", "tokens": ["Und", "da\u00df", "der", "Reif", "nie", "sprin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Einstweilen, bis den Bau der Welt", "tokens": ["Einst\u00b7wei\u00b7len", ",", "bis", "den", "Bau", "der", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Philosophie zusammenh\u00e4lt,", "tokens": ["Phi\u00b7lo\u00b7so\u00b7phie", "zu\u00b7sam\u00b7men\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Erh\u00e4lt sie das Getriebe", "tokens": ["Er\u00b7h\u00e4lt", "sie", "das", "Ge\u00b7trie\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Durch Hunger und durch Liebe.", "tokens": ["Durch", "Hun\u00b7ger", "und", "durch", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}