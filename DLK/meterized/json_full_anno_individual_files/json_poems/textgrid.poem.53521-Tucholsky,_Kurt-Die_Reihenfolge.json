{"textgrid.poem.53521": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Die Reihenfolge", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie war das neulich eigent\u00fcmlich!", "tokens": ["Wie", "war", "das", "neu\u00b7lich", "ei\u00b7gen\u00b7t\u00fcm\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PDS", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich ging im Wald so f\u00fcr mich hin,", "tokens": ["Ich", "ging", "im", "Wald", "so", "f\u00fcr", "mich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und alles, was durchaus nicht ziemlich,", "tokens": ["und", "al\u00b7les", ",", "was", "durc\u00b7haus", "nicht", "ziem\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dr\u00e4ngt sich mir dauernd in den Sinn.", "tokens": ["dr\u00e4ngt", "sich", "mir", "dau\u00b7ernd", "in", "den", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Da liegt, in heiterm Flug geboren,", "tokens": ["Da", "liegt", ",", "in", "hei\u00b7term", "Flug", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ganz wei\u00df, gekr\u00fcmmt und weich wie Wachs", "tokens": ["ganz", "wei\u00df", ",", "ge\u00b7kr\u00fcmmt", "und", "weich", "wie", "Wachs"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "VVPP", "KON", "ADJD", "KOKOM", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u2013 das hat gewi\u00df ein Spatz verloren \u2013", "tokens": ["\u2013", "das", "hat", "ge\u00b7wi\u00df", "ein", "Spatz", "ver\u00b7lo\u00b7ren", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein kleiner Klacks.", "tokens": ["ein", "klei\u00b7ner", "Klacks", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Und tiefer in des Waldes Hallen", "tokens": ["Und", "tie\u00b7fer", "in", "des", "Wal\u00b7des", "Hal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "liegt hingerollt, soweit ich seh,", "tokens": ["liegt", "hin\u00b7ge\u00b7rollt", ",", "so\u00b7weit", "ich", "seh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u2013 das lie\u00df wohl eine Ziege fallen \u2013", "tokens": ["\u2013", "das", "lie\u00df", "wohl", "ei\u00b7ne", "Zie\u00b7ge", "fal\u00b7len", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein halbes Pfund Kaffee.", "tokens": ["ein", "hal\u00b7bes", "Pfund", "Kaf\u00b7fee", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+--", "measure": "unknown.measure.di"}}, "stanza.4": {"line.1": {"text": "Und wie sich das so weiter machte,", "tokens": ["Und", "wie", "sich", "das", "so", "wei\u00b7ter", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "PDS", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "besah ich einen neuen Fund:", "tokens": ["be\u00b7sah", "ich", "ei\u00b7nen", "neu\u00b7en", "Fund", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u2013 hier stand einst eine Kuh und dachte \u2013", "tokens": ["\u2013", "hier", "stand", "einst", "ei\u00b7ne", "Kuh", "und", "dach\u00b7te", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADV", "ART", "NN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein Fladen, gro\u00df und rund.", "tokens": ["ein", "Fla\u00b7den", ",", "gro\u00df", "und", "rund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Und hat denn alles sich verschworen?", "tokens": ["Und", "hat", "denn", "al\u00b7les", "sich", "ver\u00b7schwo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIS", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da liegt im T\u00fcmpel, dran ich ging,", "tokens": ["Da", "liegt", "im", "T\u00fcm\u00b7pel", ",", "dran", "ich", "ging", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "$,", "PAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u2013 das hat gewi\u00df ein Ochs verloren \u2013", "tokens": ["\u2013", "das", "hat", "ge\u00b7wi\u00df", "ein", "Ochs", "ver\u00b7lo\u00b7ren", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein Buch von Keyserling.", "tokens": ["ein", "Buch", "von", "Key\u00b7ser\u00b7ling", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Wie war das neulich eigent\u00fcmlich!", "tokens": ["Wie", "war", "das", "neu\u00b7lich", "ei\u00b7gen\u00b7t\u00fcm\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PDS", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich ging im Wald so f\u00fcr mich hin,", "tokens": ["Ich", "ging", "im", "Wald", "so", "f\u00fcr", "mich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und alles, was durchaus nicht ziemlich,", "tokens": ["und", "al\u00b7les", ",", "was", "durc\u00b7haus", "nicht", "ziem\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dr\u00e4ngt sich mir dauernd in den Sinn.", "tokens": ["dr\u00e4ngt", "sich", "mir", "dau\u00b7ernd", "in", "den", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Da liegt, in heiterm Flug geboren,", "tokens": ["Da", "liegt", ",", "in", "hei\u00b7term", "Flug", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ganz wei\u00df, gekr\u00fcmmt und weich wie Wachs", "tokens": ["ganz", "wei\u00df", ",", "ge\u00b7kr\u00fcmmt", "und", "weich", "wie", "Wachs"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "VVPP", "KON", "ADJD", "KOKOM", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u2013 das hat gewi\u00df ein Spatz verloren \u2013", "tokens": ["\u2013", "das", "hat", "ge\u00b7wi\u00df", "ein", "Spatz", "ver\u00b7lo\u00b7ren", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein kleiner Klacks.", "tokens": ["ein", "klei\u00b7ner", "Klacks", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Und tiefer in des Waldes Hallen", "tokens": ["Und", "tie\u00b7fer", "in", "des", "Wal\u00b7des", "Hal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "liegt hingerollt, soweit ich seh,", "tokens": ["liegt", "hin\u00b7ge\u00b7rollt", ",", "so\u00b7weit", "ich", "seh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u2013 das lie\u00df wohl eine Ziege fallen \u2013", "tokens": ["\u2013", "das", "lie\u00df", "wohl", "ei\u00b7ne", "Zie\u00b7ge", "fal\u00b7len", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein halbes Pfund Kaffee.", "tokens": ["ein", "hal\u00b7bes", "Pfund", "Kaf\u00b7fee", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+--", "measure": "unknown.measure.di"}}, "stanza.9": {"line.1": {"text": "Und wie sich das so weiter machte,", "tokens": ["Und", "wie", "sich", "das", "so", "wei\u00b7ter", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "PDS", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "besah ich einen neuen Fund:", "tokens": ["be\u00b7sah", "ich", "ei\u00b7nen", "neu\u00b7en", "Fund", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u2013 hier stand einst eine Kuh und dachte \u2013", "tokens": ["\u2013", "hier", "stand", "einst", "ei\u00b7ne", "Kuh", "und", "dach\u00b7te", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADV", "ART", "NN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein Fladen, gro\u00df und rund.", "tokens": ["ein", "Fla\u00b7den", ",", "gro\u00df", "und", "rund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und hat denn alles sich verschworen?", "tokens": ["Und", "hat", "denn", "al\u00b7les", "sich", "ver\u00b7schwo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIS", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da liegt im T\u00fcmpel, dran ich ging,", "tokens": ["Da", "liegt", "im", "T\u00fcm\u00b7pel", ",", "dran", "ich", "ging", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "$,", "PAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u2013 das hat gewi\u00df ein Ochs verloren \u2013", "tokens": ["\u2013", "das", "hat", "ge\u00b7wi\u00df", "ein", "Ochs", "ver\u00b7lo\u00b7ren", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein Buch von Keyserling.", "tokens": ["ein", "Buch", "von", "Key\u00b7ser\u00b7ling", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}