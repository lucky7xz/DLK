{"textgrid.poem.65993": {"metadata": {"author": {"name": "Falke, Gustav", "birth": "N.A.", "death": "N.A."}, "title": "1L: Fastnachtsverse w\u00fcnschen Sie, verehrter Doktor?", "genre": "verse", "period": "N.A.", "pub_year": 1884, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Fastnachtsverse w\u00fcnschen Sie, verehrter Doktor?", "tokens": ["Fast\u00b7nachts\u00b7ver\u00b7se", "w\u00fcn\u00b7schen", "Sie", ",", "ver\u00b7ehr\u00b7ter", "Dok\u00b7tor", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Leider hab ich nichts dergleichen mehr auf Lager,", "tokens": ["Lei\u00b7der", "hab", "ich", "nichts", "derg\u00b7lei\u00b7chen", "mehr", "auf", "La\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "PIS", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Meine Muse, die in diesen Tagen dreimal", "tokens": ["Mei\u00b7ne", "Mu\u00b7se", ",", "die", "in", "die\u00b7sen", "Ta\u00b7gen", "drei\u00b7mal"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "APPR", "PDAT", "NN", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Schon ich darum anging, aber ist ein spr\u00f6des,", "tokens": ["Schon", "ich", "da\u00b7rum", "an\u00b7ging", ",", "a\u00b7ber", "ist", "ein", "spr\u00f6\u00b7des", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PAV", "VVFIN", "$,", "ADV", "VAFIN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Knauseriges Frauenzimmer, voller Launen,", "tokens": ["Knau\u00b7se\u00b7ri\u00b7ges", "Frau\u00b7en\u00b7zim\u00b7mer", ",", "vol\u00b7ler", "Lau\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Wie ja alle Evast\u00f6chter, und seit vielen", "tokens": ["Wie", "ja", "al\u00b7le", "E\u00b7vas\u00b7t\u00f6ch\u00b7ter", ",", "und", "seit", "vie\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "PIAT", "NN", "$,", "KON", "APPR", "PIAT"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Wochen wendet schon die \u00bbHimmlische\u00ab mir schmollend", "tokens": ["Wo\u00b7chen", "wen\u00b7det", "schon", "die", "\u00bb", "Himm\u00b7li\u00b7sche", "\u00ab", "mir", "schmol\u00b7lend"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "ART", "$(", "NN", "$(", "PPER", "ADJD"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Ihren \u00bbhehren\u00ab R\u00fccken zu. Was fang ich an jetzt?", "tokens": ["Ih\u00b7ren", "\u00bb", "heh\u00b7ren", "\u00ab", "R\u00fc\u00b7cken", "zu", ".", "Was", "fang", "ich", "an", "jetzt", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$(", "VVINF", "$(", "NN", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "APPR", "ADV", "$."], "meter": "+-+-+---+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Giebt es Mitleidswerteres als einen Dichter,", "tokens": ["Giebt", "es", "Mit\u00b7leids\u00b7wer\u00b7te\u00b7res", "als", "ei\u00b7nen", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Dem die Muse den ber\u00fchmten Kuss verweigert?", "tokens": ["Dem", "die", "Mu\u00b7se", "den", "be\u00b7r\u00fchm\u00b7ten", "Kuss", "ver\u00b7wei\u00b7gert", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.2": {"line.1": {"text": "Viele zwar von meinen Herrn \u00bbBerufskollegen\u00ab", "tokens": ["Vie\u00b7le", "zwar", "von", "mei\u00b7nen", "Herrn", "\u00bb", "Be\u00b7rufs\u00b7kol\u00b7le\u00b7gen", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "ADV", "APPR", "PPOSAT", "NN", "$(", "NN", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Wissen sich in solchem Falle schon zu tr\u00f6sten", "tokens": ["Wis\u00b7sen", "sich", "in", "sol\u00b7chem", "Fal\u00b7le", "schon", "zu", "tr\u00f6s\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "PIAT", "NN", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Und versuchen's kecklich ohne ihre Muse,", "tokens": ["Und", "ver\u00b7su\u00b7chen's", "keck\u00b7lich", "oh\u00b7ne", "ih\u00b7re", "Mu\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Und die Menge merkt es, beim Apoll, den glatten", "tokens": ["Und", "die", "Men\u00b7ge", "merkt", "es", ",", "beim", "A\u00b7poll", ",", "den", "glat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "$,", "APPRART", "NN", "$,", "ART", "ADJA"], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Feinen Versen, die ins Ohr wie \u00d6l ihr tr\u00e4ufeln,", "tokens": ["Fei\u00b7nen", "Ver\u00b7sen", ",", "die", "ins", "Ohr", "wie", "\u00d6l", "ihr", "tr\u00e4u\u00b7feln", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PRELS", "APPRART", "NN", "KOKOM", "NE", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Manchmal nimmer an, dass sie der Herr Verfasser", "tokens": ["Manch\u00b7mal", "nim\u00b7mer", "an", ",", "dass", "sie", "der", "Herr", "Ver\u00b7fas\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "\u00bbganz allein\u00ab gedichtet, ohne h\u00f6here H\u00fclfe.", "tokens": ["\u00bb", "ganz", "al\u00b7lein", "\u00ab", "ge\u00b7dich\u00b7tet", ",", "oh\u00b7ne", "h\u00f6\u00b7he\u00b7re", "H\u00fcl\u00b7fe", "."], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$(", "VVPP", "$,", "KOUI", "ADJA", "NN", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.8": {"text": "Ich doch kann nicht eine einzige Zeile schreiben,", "tokens": ["Ich", "doch", "kann", "nicht", "ei\u00b7ne", "ein\u00b7zi\u00b7ge", "Zei\u00b7le", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+----+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Wenn die gute Muse mit mir \u00bbmault\u00ab, und gar noch", "tokens": ["Wenn", "die", "gu\u00b7te", "Mu\u00b7se", "mit", "mir", "\u00bb", "mault", "\u00ab", ",", "und", "gar", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "PPER", "$(", "VVFIN", "$(", "$,", "KON", "ADV", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Faschingsverse \u2013 nein, dazu bedarf's der ganzen", "tokens": ["Fa\u00b7schings\u00b7ver\u00b7se", "\u2013", "nein", ",", "da\u00b7zu", "be\u00b7da\u00b7rf's", "der", "gan\u00b7zen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$(", "PTKANT", "$,", "PAV", "VVFIN", "ART", "ADJA"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.11": {"text": "N\u00e4rrisch \u00fcberm\u00fctigen Laune, die mit buntem", "tokens": ["N\u00e4r\u00b7risch", "\u00fc\u00b7berm\u00b7\u00fc\u00b7ti\u00b7gen", "Lau\u00b7ne", ",", "die", "mit", "bun\u00b7tem"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "ADJA", "NN", "$,", "PRELS", "APPR", "ADJA"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.12": {"text": "Flitter sich beh\u00e4ngt, hinweg zu t\u00e4uschen kl\u00fcglich,", "tokens": ["Flit\u00b7ter", "sich", "be\u00b7h\u00e4ngt", ",", "hin\u00b7weg", "zu", "t\u00e4u\u00b7schen", "kl\u00fcg\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "VVFIN", "$,", "ADV", "PTKZU", "VVINF", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "Sich auf Stunden dieses Lebens graues Elend,", "tokens": ["Sich", "auf", "Stun\u00b7den", "die\u00b7ses", "Le\u00b7bens", "grau\u00b7es", "E\u00b7lend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "PDAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "Oder auch bedarf's des grauen Elends selber,", "tokens": ["O\u00b7der", "auch", "be\u00b7da\u00b7rf's", "des", "grau\u00b7en", "E\u00b7lends", "sel\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.15": {"text": "Aschermittwochstimmung, die in Sack und Asche", "tokens": ["A\u00b7scher\u00b7mitt\u00b7wochs\u00b7tim\u00b7mung", ",", "die", "in", "Sack", "und", "A\u00b7sche"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.16": {"text": "Und mit h\u00e4ngenden Ohren Bu\u00dfelieder dichtet.", "tokens": ["Und", "mit", "h\u00e4n\u00b7gen\u00b7den", "Oh\u00b7ren", "Bu\u00b7\u00dfe\u00b7lie\u00b7der", "dich\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.17": {"text": "Beides liegt mir fern. Ganz n\u00fcchtern werkelt\u00e4glich", "tokens": ["Bei\u00b7des", "liegt", "mir", "fern", ".", "Ganz", "n\u00fcch\u00b7tern", "wer\u00b7kel\u00b7t\u00e4g\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "ADJD", "ADJD"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.18": {"text": "Trott ich meines Lebens immer gleichen Pflichtweg,", "tokens": ["Trott", "ich", "mei\u00b7nes", "Le\u00b7bens", "im\u00b7mer", "glei\u00b7chen", "Pflicht\u00b7weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.19": {"text": "Der mich abseits f\u00fchrt von Maskeradens\u00e4len.", "tokens": ["Der", "mich", "ab\u00b7seits", "f\u00fchrt", "von", "Mas\u00b7ke\u00b7ra\u00b7den\u00b7s\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.3": {"line.1": {"text": "Ach, wie lange schon ist's her, dass mich auch einmal", "tokens": ["Ach", ",", "wie", "lan\u00b7ge", "schon", "ist's", "her", ",", "dass", "mich", "auch", "ein\u00b7mal"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PWAV", "ADV", "ADV", "NE", "PTKVZ", "$,", "KOUS", "PPER", "ADV", "ADV"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Einer Maske klug gew\u00e4hlte H\u00fclle freundlich", "tokens": ["Ei\u00b7ner", "Mas\u00b7ke", "klug", "ge\u00b7w\u00e4hl\u00b7te", "H\u00fcl\u00b7le", "freund\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "ADJA", "NN", "ADJD"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Barg vor meiner lieben N\u00e4chsten Sp\u00e4herblicken,", "tokens": ["Barg", "vor", "mei\u00b7ner", "lie\u00b7ben", "N\u00e4chs\u00b7ten", "Sp\u00e4\u00b7her\u00b7bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Dass der wei\u00dfe, kreuzbestickte Rittermantel,", "tokens": ["Dass", "der", "wei\u00b7\u00dfe", ",", "kreuz\u00b7be\u00b7stick\u00b7te", "Rit\u00b7ter\u00b7man\u00b7tel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Und der kecke Hut mit weithinwallender Feder,", "tokens": ["Und", "der", "ke\u00b7cke", "Hut", "mit", "weit\u00b7hin\u00b7wal\u00b7len\u00b7der", "Fe\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "--+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und der Degen und die gro\u00dfen Sporenstiefel,", "tokens": ["Und", "der", "De\u00b7gen", "und", "die", "gro\u00b7\u00dfen", "Spo\u00b7rens\u00b7tie\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Diese ganze Heldenmummerei, mich einmal", "tokens": ["Die\u00b7se", "gan\u00b7ze", "Hel\u00b7den\u00b7mum\u00b7me\u00b7rei", ",", "mich", "ein\u00b7mal"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "$,", "PPER", "ADV"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.8": {"text": "Wenige sch\u00f6ne G\u00f6tterstunden lie\u00df vergessen,", "tokens": ["We\u00b7ni\u00b7ge", "sch\u00f6\u00b7ne", "G\u00f6t\u00b7ter\u00b7stun\u00b7den", "lie\u00df", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "VVPP", "$,"], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.9": {"text": "Dass mit vielen tausend Adamss\u00f6hnen sonst ich", "tokens": ["Dass", "mit", "vie\u00b7len", "tau\u00b7send", "A\u00b7dams\u00b7s\u00f6h\u00b7nen", "sonst", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIAT", "CARD", "NN", "ADV", "PPER"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Ohne Rittermantel muss mein Kreuzlein tragen.", "tokens": ["Oh\u00b7ne", "Rit\u00b7ter\u00b7man\u00b7tel", "muss", "mein", "Kreuz\u00b7lein", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.4": {"line.1": {"text": "Nun, man tr\u00e4gt es schon. Kommt einmal doch die Stunde,", "tokens": ["Nun", ",", "man", "tr\u00e4gt", "es", "schon", ".", "Kommt", "ein\u00b7mal", "doch", "die", "Stun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PIS", "VVFIN", "PPER", "ADV", "$.", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Wo auch dieses Kreuz mit anderm, wie entlieh'nes", "tokens": ["Wo", "auch", "die\u00b7ses", "Kreuz", "mit", "an\u00b7derm", ",", "wie", "ent\u00b7lieh'\u00b7nes"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ADV", "PDAT", "NN", "APPR", "PIS", "$,", "PWAV", "NE"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Faschingsballkost\u00fcm, dem gro\u00dfen Allesleiher", "tokens": ["Fa\u00b7schings\u00b7ball\u00b7kos\u00b7t\u00fcm", ",", "dem", "gro\u00b7\u00dfen", "Al\u00b7les\u00b7lei\u00b7her"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Wieder wir zur\u00fcck in die Garderobe liefern.", "tokens": ["Wie\u00b7der", "wir", "zu\u00b7r\u00fcck", "in", "die", "Gar\u00b7de\u00b7ro\u00b7be", "lie\u00b7fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKVZ", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "Masken! Larven! Ach, wir tragen alle Tage,", "tokens": ["Mas\u00b7ken", "!", "Lar\u00b7ven", "!", "Ach", ",", "wir", "tra\u00b7gen", "al\u00b7le", "Ta\u00b7ge", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "ITJ", "$,", "PPER", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Nicht zum Fasching nur, die wunderlichsten H\u00fcllen.", "tokens": ["Nicht", "zum", "Fa\u00b7sching", "nur", ",", "die", "wun\u00b7der\u00b7lichs\u00b7ten", "H\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "ADV", "$,", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Masken! Larven! Bis die Stunde schl\u00e4gt, Erl\u00f6sung", "tokens": ["Mas\u00b7ken", "!", "Lar\u00b7ven", "!", "Bis", "die", "Stun\u00b7de", "schl\u00e4gt", ",", "Er\u00b7l\u00f6\u00b7sung"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["NN", "$.", "NN", "$.", "APPR", "ART", "NN", "VVFIN", "$,", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Schl\u00e4gt? und alle H\u00fcllen fallen. Oder geht es", "tokens": ["Schl\u00e4gt", "?", "und", "al\u00b7le", "H\u00fcl\u00b7len", "fal\u00b7len", ".", "O\u00b7der", "geht", "es"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$.", "KON", "PIAT", "NN", "VVINF", "$.", "KON", "VVFIN", "PPER"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Weiter dr\u00fcben, weiter so in aller, aller", "tokens": ["Wei\u00b7ter", "dr\u00fc\u00b7ben", ",", "wei\u00b7ter", "so", "in", "al\u00b7ler", ",", "al\u00b7ler"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "$,", "ADV", "ADV", "APPR", "PIAT", "$,", "PIAT"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Ewigkeit? Ein immer neues Mausern? Immer", "tokens": ["E\u00b7wig\u00b7keit", "?", "Ein", "im\u00b7mer", "neu\u00b7es", "Mau\u00b7sern", "?", "Im\u00b7mer"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["NN", "$.", "ART", "ADV", "ADJA", "NN", "$.", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Nur ein Kleiderwechseln?", "tokens": ["Nur", "ein", "Klei\u00b7der\u00b7wech\u00b7seln", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Aber werter Doktor,", "tokens": ["A\u00b7ber", "wer\u00b7ter", "Dok\u00b7tor", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Welche alte, abgedroschne Kinderfragen", "tokens": ["Wel\u00b7che", "al\u00b7te", ",", "ab\u00b7ge\u00b7droschne", "Kin\u00b7der\u00b7fra\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PWAT", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.10": {"text": "Stell ich. Sehen Sie, so geht es mir nun, wenn ich", "tokens": ["Stell", "ich", ".", "Se\u00b7hen", "Sie", ",", "so", "geht", "es", "mir", "nun", ",", "wenn", "ich"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "PPER", "$.", "VVFIN", "PPER", "$,", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$,", "KOUS", "PPER"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.11": {"text": "Ohne den ber\u00fchmten Musenkuss Episteln", "tokens": ["Oh\u00b7ne", "den", "be\u00b7r\u00fchm\u00b7ten", "Mu\u00b7sen\u00b7kuss", "E\u00b7pis\u00b7teln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Schreib, wie jene Afterdichter, jene kleinen", "tokens": ["Schreib", ",", "wie", "je\u00b7ne", "Af\u00b7ter\u00b7dich\u00b7ter", ",", "je\u00b7ne", "klei\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PWAV", "PDAT", "NN", "$,", "PDAT", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "Flinken Fexen unseres lyrischen Parnasses,", "tokens": ["Flin\u00b7ken", "Fe\u00b7xen", "un\u00b7se\u00b7res", "ly\u00b7ri\u00b7schen", "Par\u00b7nas\u00b7ses", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.14": {"text": "Die sich ihre lyrische Begeistrung jeweils,", "tokens": ["Die", "sich", "ih\u00b7re", "ly\u00b7ri\u00b7sche", "Be\u00b7geis\u00b7trung", "je\u00b7weils", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PPOSAT", "ADJA", "NN", "ADV", "$,"], "meter": "---+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Wenn nicht anders, holen her aus dem Kalender.", "tokens": ["Wenn", "nicht", "an\u00b7ders", ",", "ho\u00b7len", "her", "aus", "dem", "Ka\u00b7len\u00b7der", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADV", "$,", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Darum Schluss denn, keine lahme Zeile weiter.", "tokens": ["Da\u00b7rum", "Schluss", "denn", ",", "kei\u00b7ne", "lah\u00b7me", "Zei\u00b7le", "wei\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "ADV", "$,", "PIAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Fort vom Schreibtisch, von dem heute sehr missbrauchten,", "tokens": ["Fort", "vom", "Schreib\u00b7tisch", ",", "von", "dem", "heu\u00b7te", "sehr", "miss\u00b7brauch\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$,", "APPR", "PRELS", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "An den Fl\u00fcgel. Aufgeschlagen winkt vom Pult mir", "tokens": ["An", "den", "Fl\u00fc\u00b7gel", ".", "Auf\u00b7ge\u00b7schla\u00b7gen", "winkt", "vom", "Pult", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "NN", "VVFIN", "APPRART", "NN", "PPER"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Robert Schumanns immer junges, fr\u00fchlingshaftes,", "tokens": ["Ro\u00b7bert", "Schu\u00b7manns", "im\u00b7mer", "jun\u00b7ges", ",", "fr\u00fch\u00b7lings\u00b7haf\u00b7tes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "NE", "ADV", "ADJA", "$,", "ADJA", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Buntes Faschingsstr\u00e4u\u00dfchen: \u00bbPapillons\u00ab benamset.", "tokens": ["Bun\u00b7tes", "Fa\u00b7schings\u00b7str\u00e4u\u00df\u00b7chen", ":", "\u00bb", "Pa\u00b7pil\u00b7lons", "\u00ab", "be\u00b7nam\u00b7set", "."], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$.", "$(", "NN", "$(", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Wenn die Finger mit den Tasten Zwiesprach halten:", "tokens": ["Wenn", "die", "Fin\u00b7ger", "mit", "den", "Tas\u00b7ten", "Zwie\u00b7sprach", "hal\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Druck und Gegendruck, auf leises F\u00fchlen Antwort,", "tokens": ["Druck", "und", "Ge\u00b7gen\u00b7druck", ",", "auf", "lei\u00b7ses", "F\u00fch\u00b7len", "Ant\u00b7wort", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Dann vielleicht, dass sachte, von den herzensechten", "tokens": ["Dann", "viel\u00b7leicht", ",", "dass", "sach\u00b7te", ",", "von", "den", "her\u00b7zen\u00b7sech\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "PDS", "VVFIN", "$,", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "T\u00f6nen Schumanns angelockt, die Muse hinter", "tokens": ["T\u00f6\u00b7nen", "Schu\u00b7manns", "an\u00b7ge\u00b7lockt", ",", "die", "Mu\u00b7se", "hin\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "VVPP", "$,", "ART", "NN", "APPR"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Meinen Stuhl sich stellt und lauscht, denn Schumann liebt sie,", "tokens": ["Mei\u00b7nen", "Stuhl", "sich", "stellt", "und", "lauscht", ",", "denn", "Schu\u00b7mann", "liebt", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRF", "VVFIN", "KON", "VVFIN", "$,", "KON", "NE", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Und dass sie zum Lohn hernach vielleicht ein Verschen", "tokens": ["Und", "dass", "sie", "zum", "Lohn", "her\u00b7nach", "viel\u00b7leicht", "ein", "Ver\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPRART", "NN", "ADV", "ADV", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Wieder mir ins Ohr mit ihrem wunderbaren", "tokens": ["Wie\u00b7der", "mir", "ins", "Ohr", "mit", "ih\u00b7rem", "wun\u00b7der\u00b7ba\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "APPRART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "L\u00e4cheln, wie von einer andern Welt her, fl\u00fcstert.", "tokens": ["L\u00e4\u00b7cheln", ",", "wie", "von", "ei\u00b7ner", "an\u00b7dern", "Welt", "her", ",", "fl\u00fcs\u00b7tert", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "PWAV", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "Thut sie's, schreib sofort ich's nieder auf mein bestes", "tokens": ["Thut", "sie's", ",", "schreib", "so\u00b7fort", "ich's", "nie\u00b7der", "auf", "mein", "bes\u00b7tes"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "VVFIN", "ADV", "PIS", "PTKVZ", "APPR", "PPOSAT", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.15": {"text": "Wei\u00dfestes Papier und schick es \u00bbeingeschrieben\u00ab", "tokens": ["Wei\u00b7\u00dfes\u00b7tes", "Pa\u00b7pier", "und", "schick", "es", "\u00bb", "ein\u00b7ge\u00b7schrie\u00b7ben", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "KON", "VVFIN", "PPER", "$(", "VVIZU", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.16": {"text": "Schleunigst an die Redaktion mit n\u00e4chster Post.", "tokens": ["Schleu\u00b7nigst", "an", "die", "Re\u00b7dak\u00b7ti\u00b7on", "mit", "n\u00e4chs\u00b7ter", "Post", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "Fastnachtsverse w\u00fcnschen Sie, verehrter Doktor?", "tokens": ["Fast\u00b7nachts\u00b7ver\u00b7se", "w\u00fcn\u00b7schen", "Sie", ",", "ver\u00b7ehr\u00b7ter", "Dok\u00b7tor", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Leider hab ich nichts dergleichen mehr auf Lager,", "tokens": ["Lei\u00b7der", "hab", "ich", "nichts", "derg\u00b7lei\u00b7chen", "mehr", "auf", "La\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "PIS", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Meine Muse, die in diesen Tagen dreimal", "tokens": ["Mei\u00b7ne", "Mu\u00b7se", ",", "die", "in", "die\u00b7sen", "Ta\u00b7gen", "drei\u00b7mal"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "APPR", "PDAT", "NN", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Schon ich darum anging, aber ist ein spr\u00f6des,", "tokens": ["Schon", "ich", "da\u00b7rum", "an\u00b7ging", ",", "a\u00b7ber", "ist", "ein", "spr\u00f6\u00b7des", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PAV", "VVFIN", "$,", "ADV", "VAFIN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Knauseriges Frauenzimmer, voller Launen,", "tokens": ["Knau\u00b7se\u00b7ri\u00b7ges", "Frau\u00b7en\u00b7zim\u00b7mer", ",", "vol\u00b7ler", "Lau\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Wie ja alle Evast\u00f6chter, und seit vielen", "tokens": ["Wie", "ja", "al\u00b7le", "E\u00b7vas\u00b7t\u00f6ch\u00b7ter", ",", "und", "seit", "vie\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "PIAT", "NN", "$,", "KON", "APPR", "PIAT"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Wochen wendet schon die \u00bbHimmlische\u00ab mir schmollend", "tokens": ["Wo\u00b7chen", "wen\u00b7det", "schon", "die", "\u00bb", "Himm\u00b7li\u00b7sche", "\u00ab", "mir", "schmol\u00b7lend"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "ART", "$(", "NN", "$(", "PPER", "ADJD"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Ihren \u00bbhehren\u00ab R\u00fccken zu. Was fang ich an jetzt?", "tokens": ["Ih\u00b7ren", "\u00bb", "heh\u00b7ren", "\u00ab", "R\u00fc\u00b7cken", "zu", ".", "Was", "fang", "ich", "an", "jetzt", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$(", "VVINF", "$(", "NN", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "APPR", "ADV", "$."], "meter": "+-+-+---+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Giebt es Mitleidswerteres als einen Dichter,", "tokens": ["Giebt", "es", "Mit\u00b7leids\u00b7wer\u00b7te\u00b7res", "als", "ei\u00b7nen", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Dem die Muse den ber\u00fchmten Kuss verweigert?", "tokens": ["Dem", "die", "Mu\u00b7se", "den", "be\u00b7r\u00fchm\u00b7ten", "Kuss", "ver\u00b7wei\u00b7gert", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.8": {"line.1": {"text": "Viele zwar von meinen Herrn \u00bbBerufskollegen\u00ab", "tokens": ["Vie\u00b7le", "zwar", "von", "mei\u00b7nen", "Herrn", "\u00bb", "Be\u00b7rufs\u00b7kol\u00b7le\u00b7gen", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "ADV", "APPR", "PPOSAT", "NN", "$(", "NN", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Wissen sich in solchem Falle schon zu tr\u00f6sten", "tokens": ["Wis\u00b7sen", "sich", "in", "sol\u00b7chem", "Fal\u00b7le", "schon", "zu", "tr\u00f6s\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "PIAT", "NN", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Und versuchen's kecklich ohne ihre Muse,", "tokens": ["Und", "ver\u00b7su\u00b7chen's", "keck\u00b7lich", "oh\u00b7ne", "ih\u00b7re", "Mu\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Und die Menge merkt es, beim Apoll, den glatten", "tokens": ["Und", "die", "Men\u00b7ge", "merkt", "es", ",", "beim", "A\u00b7poll", ",", "den", "glat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "$,", "APPRART", "NN", "$,", "ART", "ADJA"], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Feinen Versen, die ins Ohr wie \u00d6l ihr tr\u00e4ufeln,", "tokens": ["Fei\u00b7nen", "Ver\u00b7sen", ",", "die", "ins", "Ohr", "wie", "\u00d6l", "ihr", "tr\u00e4u\u00b7feln", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PRELS", "APPRART", "NN", "KOKOM", "NE", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Manchmal nimmer an, dass sie der Herr Verfasser", "tokens": ["Manch\u00b7mal", "nim\u00b7mer", "an", ",", "dass", "sie", "der", "Herr", "Ver\u00b7fas\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "\u00bbganz allein\u00ab gedichtet, ohne h\u00f6here H\u00fclfe.", "tokens": ["\u00bb", "ganz", "al\u00b7lein", "\u00ab", "ge\u00b7dich\u00b7tet", ",", "oh\u00b7ne", "h\u00f6\u00b7he\u00b7re", "H\u00fcl\u00b7fe", "."], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$(", "VVPP", "$,", "KOUI", "ADJA", "NN", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.8": {"text": "Ich doch kann nicht eine einzige Zeile schreiben,", "tokens": ["Ich", "doch", "kann", "nicht", "ei\u00b7ne", "ein\u00b7zi\u00b7ge", "Zei\u00b7le", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+----+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Wenn die gute Muse mit mir \u00bbmault\u00ab, und gar noch", "tokens": ["Wenn", "die", "gu\u00b7te", "Mu\u00b7se", "mit", "mir", "\u00bb", "mault", "\u00ab", ",", "und", "gar", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "PPER", "$(", "VVFIN", "$(", "$,", "KON", "ADV", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Faschingsverse \u2013 nein, dazu bedarf's der ganzen", "tokens": ["Fa\u00b7schings\u00b7ver\u00b7se", "\u2013", "nein", ",", "da\u00b7zu", "be\u00b7da\u00b7rf's", "der", "gan\u00b7zen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$(", "PTKANT", "$,", "PAV", "VVFIN", "ART", "ADJA"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.11": {"text": "N\u00e4rrisch \u00fcberm\u00fctigen Laune, die mit buntem", "tokens": ["N\u00e4r\u00b7risch", "\u00fc\u00b7berm\u00b7\u00fc\u00b7ti\u00b7gen", "Lau\u00b7ne", ",", "die", "mit", "bun\u00b7tem"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "ADJA", "NN", "$,", "PRELS", "APPR", "ADJA"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.12": {"text": "Flitter sich beh\u00e4ngt, hinweg zu t\u00e4uschen kl\u00fcglich,", "tokens": ["Flit\u00b7ter", "sich", "be\u00b7h\u00e4ngt", ",", "hin\u00b7weg", "zu", "t\u00e4u\u00b7schen", "kl\u00fcg\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "VVFIN", "$,", "ADV", "PTKZU", "VVINF", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "Sich auf Stunden dieses Lebens graues Elend,", "tokens": ["Sich", "auf", "Stun\u00b7den", "die\u00b7ses", "Le\u00b7bens", "grau\u00b7es", "E\u00b7lend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "PDAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "Oder auch bedarf's des grauen Elends selber,", "tokens": ["O\u00b7der", "auch", "be\u00b7da\u00b7rf's", "des", "grau\u00b7en", "E\u00b7lends", "sel\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.15": {"text": "Aschermittwochstimmung, die in Sack und Asche", "tokens": ["A\u00b7scher\u00b7mitt\u00b7wochs\u00b7tim\u00b7mung", ",", "die", "in", "Sack", "und", "A\u00b7sche"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.16": {"text": "Und mit h\u00e4ngenden Ohren Bu\u00dfelieder dichtet.", "tokens": ["Und", "mit", "h\u00e4n\u00b7gen\u00b7den", "Oh\u00b7ren", "Bu\u00b7\u00dfe\u00b7lie\u00b7der", "dich\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.17": {"text": "Beides liegt mir fern. Ganz n\u00fcchtern werkelt\u00e4glich", "tokens": ["Bei\u00b7des", "liegt", "mir", "fern", ".", "Ganz", "n\u00fcch\u00b7tern", "wer\u00b7kel\u00b7t\u00e4g\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "ADJD", "ADJD"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.18": {"text": "Trott ich meines Lebens immer gleichen Pflichtweg,", "tokens": ["Trott", "ich", "mei\u00b7nes", "Le\u00b7bens", "im\u00b7mer", "glei\u00b7chen", "Pflicht\u00b7weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.19": {"text": "Der mich abseits f\u00fchrt von Maskeradens\u00e4len.", "tokens": ["Der", "mich", "ab\u00b7seits", "f\u00fchrt", "von", "Mas\u00b7ke\u00b7ra\u00b7den\u00b7s\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.9": {"line.1": {"text": "Ach, wie lange schon ist's her, dass mich auch einmal", "tokens": ["Ach", ",", "wie", "lan\u00b7ge", "schon", "ist's", "her", ",", "dass", "mich", "auch", "ein\u00b7mal"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PWAV", "ADV", "ADV", "NE", "PTKVZ", "$,", "KOUS", "PPER", "ADV", "ADV"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Einer Maske klug gew\u00e4hlte H\u00fclle freundlich", "tokens": ["Ei\u00b7ner", "Mas\u00b7ke", "klug", "ge\u00b7w\u00e4hl\u00b7te", "H\u00fcl\u00b7le", "freund\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "ADJA", "NN", "ADJD"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Barg vor meiner lieben N\u00e4chsten Sp\u00e4herblicken,", "tokens": ["Barg", "vor", "mei\u00b7ner", "lie\u00b7ben", "N\u00e4chs\u00b7ten", "Sp\u00e4\u00b7her\u00b7bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Dass der wei\u00dfe, kreuzbestickte Rittermantel,", "tokens": ["Dass", "der", "wei\u00b7\u00dfe", ",", "kreuz\u00b7be\u00b7stick\u00b7te", "Rit\u00b7ter\u00b7man\u00b7tel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Und der kecke Hut mit weithinwallender Feder,", "tokens": ["Und", "der", "ke\u00b7cke", "Hut", "mit", "weit\u00b7hin\u00b7wal\u00b7len\u00b7der", "Fe\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "--+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und der Degen und die gro\u00dfen Sporenstiefel,", "tokens": ["Und", "der", "De\u00b7gen", "und", "die", "gro\u00b7\u00dfen", "Spo\u00b7rens\u00b7tie\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Diese ganze Heldenmummerei, mich einmal", "tokens": ["Die\u00b7se", "gan\u00b7ze", "Hel\u00b7den\u00b7mum\u00b7me\u00b7rei", ",", "mich", "ein\u00b7mal"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "$,", "PPER", "ADV"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.8": {"text": "Wenige sch\u00f6ne G\u00f6tterstunden lie\u00df vergessen,", "tokens": ["We\u00b7ni\u00b7ge", "sch\u00f6\u00b7ne", "G\u00f6t\u00b7ter\u00b7stun\u00b7den", "lie\u00df", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "VVPP", "$,"], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.9": {"text": "Dass mit vielen tausend Adamss\u00f6hnen sonst ich", "tokens": ["Dass", "mit", "vie\u00b7len", "tau\u00b7send", "A\u00b7dams\u00b7s\u00f6h\u00b7nen", "sonst", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIAT", "CARD", "NN", "ADV", "PPER"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Ohne Rittermantel muss mein Kreuzlein tragen.", "tokens": ["Oh\u00b7ne", "Rit\u00b7ter\u00b7man\u00b7tel", "muss", "mein", "Kreuz\u00b7lein", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.10": {"line.1": {"text": "Nun, man tr\u00e4gt es schon. Kommt einmal doch die Stunde,", "tokens": ["Nun", ",", "man", "tr\u00e4gt", "es", "schon", ".", "Kommt", "ein\u00b7mal", "doch", "die", "Stun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PIS", "VVFIN", "PPER", "ADV", "$.", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Wo auch dieses Kreuz mit anderm, wie entlieh'nes", "tokens": ["Wo", "auch", "die\u00b7ses", "Kreuz", "mit", "an\u00b7derm", ",", "wie", "ent\u00b7lieh'\u00b7nes"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ADV", "PDAT", "NN", "APPR", "PIS", "$,", "PWAV", "NE"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Faschingsballkost\u00fcm, dem gro\u00dfen Allesleiher", "tokens": ["Fa\u00b7schings\u00b7ball\u00b7kos\u00b7t\u00fcm", ",", "dem", "gro\u00b7\u00dfen", "Al\u00b7les\u00b7lei\u00b7her"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Wieder wir zur\u00fcck in die Garderobe liefern.", "tokens": ["Wie\u00b7der", "wir", "zu\u00b7r\u00fcck", "in", "die", "Gar\u00b7de\u00b7ro\u00b7be", "lie\u00b7fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKVZ", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.11": {"line.1": {"text": "Masken! Larven! Ach, wir tragen alle Tage,", "tokens": ["Mas\u00b7ken", "!", "Lar\u00b7ven", "!", "Ach", ",", "wir", "tra\u00b7gen", "al\u00b7le", "Ta\u00b7ge", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "ITJ", "$,", "PPER", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Nicht zum Fasching nur, die wunderlichsten H\u00fcllen.", "tokens": ["Nicht", "zum", "Fa\u00b7sching", "nur", ",", "die", "wun\u00b7der\u00b7lichs\u00b7ten", "H\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "ADV", "$,", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Masken! Larven! Bis die Stunde schl\u00e4gt, Erl\u00f6sung", "tokens": ["Mas\u00b7ken", "!", "Lar\u00b7ven", "!", "Bis", "die", "Stun\u00b7de", "schl\u00e4gt", ",", "Er\u00b7l\u00f6\u00b7sung"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["NN", "$.", "NN", "$.", "APPR", "ART", "NN", "VVFIN", "$,", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Schl\u00e4gt? und alle H\u00fcllen fallen. Oder geht es", "tokens": ["Schl\u00e4gt", "?", "und", "al\u00b7le", "H\u00fcl\u00b7len", "fal\u00b7len", ".", "O\u00b7der", "geht", "es"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$.", "KON", "PIAT", "NN", "VVINF", "$.", "KON", "VVFIN", "PPER"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Weiter dr\u00fcben, weiter so in aller, aller", "tokens": ["Wei\u00b7ter", "dr\u00fc\u00b7ben", ",", "wei\u00b7ter", "so", "in", "al\u00b7ler", ",", "al\u00b7ler"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "$,", "ADV", "ADV", "APPR", "PIAT", "$,", "PIAT"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Ewigkeit? Ein immer neues Mausern? Immer", "tokens": ["E\u00b7wig\u00b7keit", "?", "Ein", "im\u00b7mer", "neu\u00b7es", "Mau\u00b7sern", "?", "Im\u00b7mer"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["NN", "$.", "ART", "ADV", "ADJA", "NN", "$.", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Nur ein Kleiderwechseln?", "tokens": ["Nur", "ein", "Klei\u00b7der\u00b7wech\u00b7seln", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Aber werter Doktor,", "tokens": ["A\u00b7ber", "wer\u00b7ter", "Dok\u00b7tor", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Welche alte, abgedroschne Kinderfragen", "tokens": ["Wel\u00b7che", "al\u00b7te", ",", "ab\u00b7ge\u00b7droschne", "Kin\u00b7der\u00b7fra\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PWAT", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.10": {"text": "Stell ich. Sehen Sie, so geht es mir nun, wenn ich", "tokens": ["Stell", "ich", ".", "Se\u00b7hen", "Sie", ",", "so", "geht", "es", "mir", "nun", ",", "wenn", "ich"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "PPER", "$.", "VVFIN", "PPER", "$,", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$,", "KOUS", "PPER"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.11": {"text": "Ohne den ber\u00fchmten Musenkuss Episteln", "tokens": ["Oh\u00b7ne", "den", "be\u00b7r\u00fchm\u00b7ten", "Mu\u00b7sen\u00b7kuss", "E\u00b7pis\u00b7teln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Schreib, wie jene Afterdichter, jene kleinen", "tokens": ["Schreib", ",", "wie", "je\u00b7ne", "Af\u00b7ter\u00b7dich\u00b7ter", ",", "je\u00b7ne", "klei\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PWAV", "PDAT", "NN", "$,", "PDAT", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "Flinken Fexen unseres lyrischen Parnasses,", "tokens": ["Flin\u00b7ken", "Fe\u00b7xen", "un\u00b7se\u00b7res", "ly\u00b7ri\u00b7schen", "Par\u00b7nas\u00b7ses", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.14": {"text": "Die sich ihre lyrische Begeistrung jeweils,", "tokens": ["Die", "sich", "ih\u00b7re", "ly\u00b7ri\u00b7sche", "Be\u00b7geis\u00b7trung", "je\u00b7weils", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PPOSAT", "ADJA", "NN", "ADV", "$,"], "meter": "---+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Wenn nicht anders, holen her aus dem Kalender.", "tokens": ["Wenn", "nicht", "an\u00b7ders", ",", "ho\u00b7len", "her", "aus", "dem", "Ka\u00b7len\u00b7der", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADV", "$,", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.12": {"line.1": {"text": "Darum Schluss denn, keine lahme Zeile weiter.", "tokens": ["Da\u00b7rum", "Schluss", "denn", ",", "kei\u00b7ne", "lah\u00b7me", "Zei\u00b7le", "wei\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "ADV", "$,", "PIAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Fort vom Schreibtisch, von dem heute sehr missbrauchten,", "tokens": ["Fort", "vom", "Schreib\u00b7tisch", ",", "von", "dem", "heu\u00b7te", "sehr", "miss\u00b7brauch\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$,", "APPR", "PRELS", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "An den Fl\u00fcgel. Aufgeschlagen winkt vom Pult mir", "tokens": ["An", "den", "Fl\u00fc\u00b7gel", ".", "Auf\u00b7ge\u00b7schla\u00b7gen", "winkt", "vom", "Pult", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "NN", "VVFIN", "APPRART", "NN", "PPER"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Robert Schumanns immer junges, fr\u00fchlingshaftes,", "tokens": ["Ro\u00b7bert", "Schu\u00b7manns", "im\u00b7mer", "jun\u00b7ges", ",", "fr\u00fch\u00b7lings\u00b7haf\u00b7tes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "NE", "ADV", "ADJA", "$,", "ADJA", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Buntes Faschingsstr\u00e4u\u00dfchen: \u00bbPapillons\u00ab benamset.", "tokens": ["Bun\u00b7tes", "Fa\u00b7schings\u00b7str\u00e4u\u00df\u00b7chen", ":", "\u00bb", "Pa\u00b7pil\u00b7lons", "\u00ab", "be\u00b7nam\u00b7set", "."], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$.", "$(", "NN", "$(", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Wenn die Finger mit den Tasten Zwiesprach halten:", "tokens": ["Wenn", "die", "Fin\u00b7ger", "mit", "den", "Tas\u00b7ten", "Zwie\u00b7sprach", "hal\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Druck und Gegendruck, auf leises F\u00fchlen Antwort,", "tokens": ["Druck", "und", "Ge\u00b7gen\u00b7druck", ",", "auf", "lei\u00b7ses", "F\u00fch\u00b7len", "Ant\u00b7wort", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Dann vielleicht, dass sachte, von den herzensechten", "tokens": ["Dann", "viel\u00b7leicht", ",", "dass", "sach\u00b7te", ",", "von", "den", "her\u00b7zen\u00b7sech\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "PDS", "VVFIN", "$,", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "T\u00f6nen Schumanns angelockt, die Muse hinter", "tokens": ["T\u00f6\u00b7nen", "Schu\u00b7manns", "an\u00b7ge\u00b7lockt", ",", "die", "Mu\u00b7se", "hin\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "VVPP", "$,", "ART", "NN", "APPR"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Meinen Stuhl sich stellt und lauscht, denn Schumann liebt sie,", "tokens": ["Mei\u00b7nen", "Stuhl", "sich", "stellt", "und", "lauscht", ",", "denn", "Schu\u00b7mann", "liebt", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRF", "VVFIN", "KON", "VVFIN", "$,", "KON", "NE", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Und dass sie zum Lohn hernach vielleicht ein Verschen", "tokens": ["Und", "dass", "sie", "zum", "Lohn", "her\u00b7nach", "viel\u00b7leicht", "ein", "Ver\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPRART", "NN", "ADV", "ADV", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Wieder mir ins Ohr mit ihrem wunderbaren", "tokens": ["Wie\u00b7der", "mir", "ins", "Ohr", "mit", "ih\u00b7rem", "wun\u00b7der\u00b7ba\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "APPRART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "L\u00e4cheln, wie von einer andern Welt her, fl\u00fcstert.", "tokens": ["L\u00e4\u00b7cheln", ",", "wie", "von", "ei\u00b7ner", "an\u00b7dern", "Welt", "her", ",", "fl\u00fcs\u00b7tert", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "PWAV", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "Thut sie's, schreib sofort ich's nieder auf mein bestes", "tokens": ["Thut", "sie's", ",", "schreib", "so\u00b7fort", "ich's", "nie\u00b7der", "auf", "mein", "bes\u00b7tes"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "VVFIN", "ADV", "PIS", "PTKVZ", "APPR", "PPOSAT", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.15": {"text": "Wei\u00dfestes Papier und schick es \u00bbeingeschrieben\u00ab", "tokens": ["Wei\u00b7\u00dfes\u00b7tes", "Pa\u00b7pier", "und", "schick", "es", "\u00bb", "ein\u00b7ge\u00b7schrie\u00b7ben", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "KON", "VVFIN", "PPER", "$(", "VVIZU", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.16": {"text": "Schleunigst an die Redaktion mit n\u00e4chster Post.", "tokens": ["Schleu\u00b7nigst", "an", "die", "Re\u00b7dak\u00b7ti\u00b7on", "mit", "n\u00e4chs\u00b7ter", "Post", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}}}}}