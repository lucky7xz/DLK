{"dta.poem.4034": {"metadata": {"author": {"name": "H\u00f6lderlin, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Der Abschied .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1826", "urn": "urn:nbn:de:kobv:b4-200905197104", "language": ["de:0.99"], "booktitle": "H\u00f6lderlin, Friedrich: Gedichte. Stuttgart u. a., 1826."}, "poem": {"stanza.1": {"line.1": {"text": "Trennen wollten wir uns? w\u00e4hnten es gut und klug?", "tokens": ["Tren\u00b7nen", "woll\u00b7ten", "wir", "uns", "?", "w\u00e4hn\u00b7ten", "es", "gut", "und", "klug", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PRF", "$.", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Da wirs thaten, warum schreckte, wie Mord, die", "tokens": ["Da", "wirs", "tha\u00b7ten", ",", "wa\u00b7rum", "schreck\u00b7te", ",", "wie", "Mord", ",", "die"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "PWAV", "VVFIN", "$,", "PWAV", "NN", "$,", "PRELS"], "meter": "----+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "That?", "tokens": ["That", "?"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Ach! wir kennen uns wenig,", "tokens": ["Ach", "!", "wir", "ken\u00b7nen", "uns", "we\u00b7nig", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PPER", "VVFIN", "PPER", "PIS", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Denn es waltet ein Gott in uns.", "tokens": ["Denn", "es", "wal\u00b7tet", "ein", "Gott", "in", "uns", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "APPR", "PPER", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.2": {"line.1": {"text": "Den verrathen? ach ihn, welcher uns alles erst,", "tokens": ["Den", "ver\u00b7ra\u00b7then", "?", "ach", "ihn", ",", "wel\u00b7cher", "uns", "al\u00b7les", "erst", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVPP", "$.", "XY", "PPER", "$,", "PRELS", "PPER", "PIS", "ADV", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Sinn und Leben erschuf, ihn, den beseelenden", "tokens": ["Sinn", "und", "Le\u00b7ben", "er\u00b7schuf", ",", "ihn", ",", "den", "be\u00b7see\u00b7len\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "KON", "NN", "VVFIN", "$,", "PPER", "$,", "ART", "ADJA"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Schutzgott unserer Liebe,", "tokens": ["Schutz\u00b7gott", "un\u00b7se\u00b7rer", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Die\u00df, die\u00df Eine vermag ich nicht.", "tokens": ["Die\u00df", ",", "die\u00df", "Ei\u00b7ne", "ver\u00b7mag", "ich", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PDS", "PIS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.3": {"line.1": {"text": "Aber anderen Fehl denket der Menschen Sinn,", "tokens": ["A\u00b7ber", "an\u00b7de\u00b7ren", "Fehl", "den\u00b7ket", "der", "Men\u00b7schen", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Andern ehernen Dienst \u00fcbt er und anders Recht,", "tokens": ["An\u00b7dern", "e\u00b7her\u00b7nen", "Dienst", "\u00fcbt", "er", "und", "an\u00b7ders", "Recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "ADJA", "NN", "VVFIN", "PPER", "KON", "ADV", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Und es fordert die Seele", "tokens": ["Und", "es", "for\u00b7dert", "die", "See\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Tag f\u00fcr Tag der Gebrauch uns ab.", "tokens": ["Tag", "f\u00fcr", "Tag", "der", "Ge\u00b7brauch", "uns", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.4": {"line.1": {"text": "Wohl! ich wu\u00dft' es zuvor. Seit der gewurzelte", "tokens": ["Wohl", "!", "ich", "wu\u00dft'", "es", "zu\u00b7vor", ".", "Seit", "der", "ge\u00b7wur\u00b7zel\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$.", "PPER", "VVFIN", "PPER", "ADV", "$.", "APPR", "ART", "ADJA"], "meter": "+-+-+-+--++-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Allentzweiende Ha\u00df G\u00f6tter und Menschen trennt,", "tokens": ["Al\u00b7lent\u00b7zwei\u00b7en\u00b7de", "Ha\u00df", "G\u00f6t\u00b7ter", "und", "Men\u00b7schen", "trennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+--++--+-+", "measure": "asklepiade"}, "line.3": {"text": "Mu\u00df, mit Blut sie zu s\u00fchnen,", "tokens": ["Mu\u00df", ",", "mit", "Blut", "sie", "zu", "s\u00fch\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Mu\u00df der Liebenden Herz vergehn.", "tokens": ["Mu\u00df", "der", "Lie\u00b7ben\u00b7den", "Herz", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.5": {"line.1": {"text": "La\u00df mich schweigen! o la\u00df nimmer von nun an mich", "tokens": ["La\u00df", "mich", "schwei\u00b7gen", "!", "o", "la\u00df", "nim\u00b7mer", "von", "nun", "an", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "VVINF", "$.", "FM", "FM", "ADV", "APPR", "ADV", "APPR", "PPER"], "meter": "+-+---+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Dieses T\u00f6dtliche sehn, da\u00df ich im Frieden doch", "tokens": ["Die\u00b7ses", "T\u00f6dt\u00b7li\u00b7che", "sehn", ",", "da\u00df", "ich", "im", "Frie\u00b7den", "doch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VVINF", "$,", "KOUS", "PPER", "APPRART", "NN", "ADV"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Hin ins Einsame ziehe,", "tokens": ["Hin", "ins", "Ein\u00b7sa\u00b7me", "zie\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und noch unser der Abschied sey!", "tokens": ["Und", "noch", "un\u00b7ser", "der", "Ab\u00b7schied", "sey", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "ART", "NN", "VAFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Reich die Schale mir selbst, da\u00df ich des rettenden", "tokens": ["Reich", "die", "Scha\u00b7le", "mir", "selbst", ",", "da\u00df", "ich", "des", "ret\u00b7ten\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "PPER", "ADV", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "+-+--+-+-+--", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Heil'gen Giftes genug, da\u00df ich des Lethetranks", "tokens": ["Heil'\u00b7gen", "Gif\u00b7tes", "ge\u00b7nug", ",", "da\u00df", "ich", "des", "Le\u00b7the\u00b7tranks"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADV", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Mit Dir trinke, da\u00df alles", "tokens": ["Mit", "Dir", "trin\u00b7ke", ",", "da\u00df", "al\u00b7les"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "$,", "KOUS", "PIS"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ha\u00df und Liebe vergessen sey!", "tokens": ["Ha\u00df", "und", "Lie\u00b7be", "ver\u00b7ges\u00b7sen", "sey", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "VAFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.7": {"line.1": {"text": "Hingehn will ich. Vielleicht seh' ich in langer Zeit", "tokens": ["Hin\u00b7gehn", "will", "ich", ".", "Viel\u00b7leicht", "seh'", "ich", "in", "lan\u00b7ger", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVINF", "VMFIN", "PPER", "$.", "ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Diotima! Dich hier. Aber verblutet ist", "tokens": ["Dio\u00b7ti\u00b7ma", "!", "Dich", "hier", ".", "A\u00b7ber", "ver\u00b7blu\u00b7tet", "ist"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$.", "PPER", "ADV", "$.", "KON", "VVPP", "VAFIN"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Dann das W\u00fcnschen und friedlich", "tokens": ["Dann", "das", "W\u00fcn\u00b7schen", "und", "fried\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "KON", "ADJD"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Gleich den Seligen, fremd sind wir.", "tokens": ["Gleich", "den", "Se\u00b7li\u00b7gen", ",", "fremd", "sind", "wir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADJD", "VAFIN", "PPER", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.8": {"line.1": {"text": "Und ein ruhig Gespr\u00e4ch f\u00fchret uns auf und ab,", "tokens": ["Und", "ein", "ru\u00b7hig", "Ge\u00b7spr\u00e4ch", "f\u00fch\u00b7ret", "uns", "auf", "und", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJD", "NN", "VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sinnend, z\u00f6gernd, doch itzt fa\u00dft die Vergessenen", "tokens": ["Sin\u00b7nend", ",", "z\u00f6\u00b7gernd", ",", "doch", "itzt", "fa\u00dft", "die", "Ver\u00b7ges\u00b7se\u00b7nen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "VVPP", "$,", "ADV", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+--+--", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Hier die Stelle des Abschieds,", "tokens": ["Hier", "die", "Stel\u00b7le", "des", "Ab\u00b7schieds", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Es erwarmet ein Herz in uns,", "tokens": ["Es", "er\u00b7war\u00b7met", "ein", "Herz", "in", "uns", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPER", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.9": {"line.1": {"text": "Staunend seh' ich dich an, Stimmen und s\u00fc\u00dfen Sang,", "tokens": ["Stau\u00b7nend", "seh'", "ich", "dich", "an", ",", "Stim\u00b7men", "und", "s\u00fc\u00b7\u00dfen", "Sang", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PRF", "PTKVZ", "$,", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Wie aus voriger Zeit, h\u00f6r' ich und Saitenspiel,", "tokens": ["Wie", "aus", "vo\u00b7ri\u00b7ger", "Zeit", ",", "h\u00f6r'", "ich", "und", "Sai\u00b7ten\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "NN", "$,", "VVFIN", "PPER", "KON", "NN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und befreiet in Flammen", "tokens": ["Und", "be\u00b7frei\u00b7et", "in", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Fliegt in L\u00fcfte der Geist uns auf.", "tokens": ["Fliegt", "in", "L\u00fcf\u00b7te", "der", "Geist", "uns", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}