{"textgrid.poem.57524": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ach Freund! so war f\u00fcr dich kein sp\u00e4ter Ziel zu hoffen?", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ach Freund! so war f\u00fcr dich kein sp\u00e4ter Ziel zu hoffen?", "tokens": ["Ach", "Freund", "!", "so", "war", "f\u00fcr", "dich", "kein", "sp\u00e4\u00b7ter", "Ziel", "zu", "hof\u00b7fen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "ADV", "VAFIN", "APPR", "PPER", "PIAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O unverhoffter Schmerz, der unsre Brust betroffen!", "tokens": ["O", "un\u00b7ver\u00b7hoff\u00b7ter", "Schmerz", ",", "der", "uns\u00b7re", "Brust", "be\u00b7trof\u00b7fen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcnf Tage sahen dich gesund und krank und bla\u00df,", "tokens": ["F\u00fcnf", "Ta\u00b7ge", "sa\u00b7hen", "dich", "ge\u00b7sund", "und", "krank", "und", "bla\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und auf der Baare stehn. Ach! wer gedachte das,", "tokens": ["Und", "auf", "der", "Baa\u00b7re", "stehn", ".", "Ach", "!", "wer", "ge\u00b7dach\u00b7te", "das", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$.", "ITJ", "$.", "PWS", "VVFIN", "PDS", "$,"], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Als du vor kurzer Zeit bey guten Freunden sa\u00dfest,", "tokens": ["Als", "du", "vor", "kur\u00b7zer", "Zeit", "bey", "gu\u00b7ten", "Freun\u00b7den", "sa\u00b7\u00dfest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und in erlaubter Lust die letzte Mahlzeit a\u00dfest?", "tokens": ["Und", "in", "er\u00b7laub\u00b7ter", "Lust", "die", "letz\u00b7te", "Mahl\u00b7zeit", "a\u00b7\u00dfest", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die letzte, wo du dich in dieser Welt ergetzt,", "tokens": ["Die", "letz\u00b7te", ",", "wo", "du", "dich", "in", "die\u00b7ser", "Welt", "er\u00b7getzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PWAV", "PPER", "PRF", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und wo der Traurigste den Gram beyseite setzt;", "tokens": ["Und", "wo", "der", "Trau\u00b7rigs\u00b7te", "den", "Gram", "bey\u00b7sei\u00b7te", "setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.9": {"text": "Die letzte, wo dein Mund gelachet und gescherzet,", "tokens": ["Die", "letz\u00b7te", ",", "wo", "dein", "Mund", "ge\u00b7la\u00b7chet", "und", "ge\u00b7scher\u00b7zet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PWAV", "PPOSAT", "NN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und keiner das besorgt, was uns nunmehro schmerzet.", "tokens": ["Und", "kei\u00b7ner", "das", "be\u00b7sorgt", ",", "was", "uns", "nun\u00b7meh\u00b7ro", "schmer\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ART", "ADJD", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was thut der P\u00f6bel nun, den sonst dein Geist gest\u00f6rt?", "tokens": ["Was", "thut", "der", "P\u00f6\u00b7bel", "nun", ",", "den", "sonst", "dein", "Geist", "ge\u00b7st\u00f6rt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "ADV", "$,", "PRELS", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er lacht und freuet sich, wenn er uns klagen h\u00f6rt;", "tokens": ["Er", "lacht", "und", "freu\u00b7et", "sich", ",", "wenn", "er", "uns", "kla\u00b7gen", "h\u00f6rt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PRF", "$,", "KOUS", "PPER", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und glaubt, nun sey es Zeit, da deine Lippen schweigen,", "tokens": ["Und", "glaubt", ",", "nun", "sey", "es", "Zeit", ",", "da", "dei\u00b7ne", "Lip\u00b7pen", "schwei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "NN", "$,", "KOUS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den alten Groll einmal ganz ungescheut zu zeigen.", "tokens": ["Den", "al\u00b7ten", "Groll", "ein\u00b7mal", "ganz", "un\u00b7ge\u00b7scheut", "zu", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie sonst der k\u00fchne Leu, der ganze W\u00e4lder schreckt,", "tokens": ["Wie", "sonst", "der", "k\u00fch\u00b7ne", "Leu", ",", "der", "gan\u00b7ze", "W\u00e4l\u00b7der", "schreckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nach welchem, weil er lebt, kein Thier die Klauen streckt,", "tokens": ["Nach", "wel\u00b7chem", ",", "weil", "er", "lebt", ",", "kein", "Thier", "die", "Klau\u00b7en", "streckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "$,", "KOUS", "PPER", "VVFIN", "$,", "PIAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn er erstarrt und stirbt und seine Kr\u00e4fte scheiden,", "tokens": ["Wenn", "er", "er\u00b7starrt", "und", "stirbt", "und", "sei\u00b7ne", "Kr\u00e4f\u00b7te", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "KON", "VVFIN", "KON", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auch feiger Hasen Spott und Uebermuth mu\u00df leiden.", "tokens": ["Auch", "fei\u00b7ger", "Ha\u00b7sen", "Spott", "und", "Ue\u00b7ber\u00b7muth", "mu\u00df", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "NN", "KON", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So lang er lebend war, schien auch der Wiederhall", "tokens": ["So", "lang", "er", "le\u00b7bend", "war", ",", "schien", "auch", "der", "Wie\u00b7der\u00b7hall"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "ADJD", "VAFIN", "$,", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von seiner Stimme, schon ein harter Donnerknall:", "tokens": ["Von", "sei\u00b7ner", "Stim\u00b7me", ",", "schon", "ein", "har\u00b7ter", "Don\u00b7ner\u00b7knall", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch itzt hat alles Herz, sich frech an ihn zu wagen,", "tokens": ["Doch", "itzt", "hat", "al\u00b7les", "Herz", ",", "sich", "frech", "an", "ihn", "zu", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIAT", "NN", "$,", "PRF", "ADJD", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Itzt will kein fauler Hund an seiner Kraft verzagen.", "tokens": ["Itzt", "will", "kein", "fau\u00b7ler", "Hund", "an", "sei\u00b7ner", "Kraft", "ver\u00b7za\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Allein, wie geht es zu, Freund! der du uns ergetzt,", "tokens": ["Al\u00b7lein", ",", "wie", "geht", "es", "zu", ",", "Freund", "!", "der", "du", "uns", "er\u00b7getzt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "VVFIN", "PPER", "PTKVZ", "$,", "NN", "$.", "ART", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da\u00df man im Leben dich so f\u00fcrchterlich gesch\u00e4tzt?", "tokens": ["Da\u00df", "man", "im", "Le\u00b7ben", "dich", "so", "f\u00fcrch\u00b7ter\u00b7lich", "ge\u00b7sch\u00e4tzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und da\u00df der P\u00f6bel sich nicht l\u00e4nger kann enthalten,", "tokens": ["Und", "da\u00df", "der", "P\u00f6\u00b7bel", "sich", "nicht", "l\u00e4n\u00b7ger", "kann", "ent\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PRF", "PTKNEG", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In unser Klagelied sein L\u00e4stern einzuschalten?", "tokens": ["In", "un\u00b7ser", "Kla\u00b7ge\u00b7lied", "sein", "L\u00e4s\u00b7tern", "ein\u00b7zu\u00b7schal\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sein schwarzes Thun hat Schuld, da\u00df er die Billigkeit,", "tokens": ["Sein", "schwar\u00b7zes", "Thun", "hat", "Schuld", ",", "da\u00df", "er", "die", "Bil\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "NN", "$,", "KOUS", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die deinen Mund belebt, so wie das Licht gescheut.", "tokens": ["Die", "dei\u00b7nen", "Mund", "be\u00b7lebt", ",", "so", "wie", "das", "Licht", "ge\u00b7scheut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$,", "ADV", "KOKOM", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Daher entstund die Furcht, du m\u00f6chtest Maal und Flecken,", "tokens": ["Da\u00b7her", "ent\u00b7stund", "die", "Furcht", ",", "du", "m\u00f6ch\u00b7test", "Maal", "und", "Fle\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "$,", "PPER", "VMFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die er zu sehr geliebt, durch deinen Witz entdecken.", "tokens": ["Die", "er", "zu", "sehr", "ge\u00b7liebt", ",", "durch", "dei\u00b7nen", "Witz", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADV", "VVPP", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dein Blick durchdrang die Nacht, darinn die Thorheit wohnt,", "tokens": ["Dein", "Blick", "durch\u00b7drang", "die", "Nacht", ",", "da\u00b7rinn", "die", "Thor\u00b7heit", "wohnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$,", "PAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die tausend Laster heckt, und gern im Dunkeln thront.", "tokens": ["Die", "tau\u00b7send", "Las\u00b7ter", "heckt", ",", "und", "gern", "im", "Dun\u00b7keln", "thront", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "VVFIN", "$,", "KON", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Umsonst war sie bedacht, ihr l\u00e4cherlich Bem\u00fchen,", "tokens": ["Um\u00b7sonst", "war", "sie", "be\u00b7dacht", ",", "ihr", "l\u00e4\u00b7cher\u00b7lich", "Be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,", "PPER", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Das sie f\u00fcr Klugheit h\u00e4lt, dir g\u00e4nzlich zu entziehen.", "tokens": ["Das", "sie", "f\u00fcr", "Klug\u00b7heit", "h\u00e4lt", ",", "dir", "g\u00e4nz\u00b7lich", "zu", "ent\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "VVFIN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Dein allzuscharfer Sinn erforschte bald den Grund:", "tokens": ["Dein", "all\u00b7zu\u00b7schar\u00b7fer", "Sinn", "er\u00b7forschte", "bald", "den", "Grund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.14": {"text": "Und ein gesalznes Wort that oft dein Urtheil kund,", "tokens": ["Und", "ein", "ge\u00b7salz\u00b7nes", "Wort", "that", "oft", "dein", "Ur\u00b7theil", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und wu\u00dfte mit Vernunft, in ungereimten Werken,", "tokens": ["Und", "wu\u00df\u00b7te", "mit", "Ver\u00b7nunft", ",", "in", "un\u00b7ge\u00b7reim\u00b7ten", "Wer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den Tadel, der sie traf, recht sinnreich anzumerken.", "tokens": ["Den", "Ta\u00b7del", ",", "der", "sie", "traf", ",", "recht", "sinn\u00b7reich", "an\u00b7zu\u00b7mer\u00b7ken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Das war dein Fehler, Freund! die\u00df scheute mancher Thor,", "tokens": ["Das", "war", "dein", "Feh\u00b7ler", ",", "Freund", "!", "die\u00df", "scheu\u00b7te", "man\u00b7cher", "Thor", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$,", "NN", "$.", "PDS", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die\u00df r\u00fcckte dir der Schwarm der Lasterhaften vor;", "tokens": ["Die\u00df", "r\u00fcck\u00b7te", "dir", "der", "Schwarm", "der", "Las\u00b7ter\u00b7haf\u00b7ten", "vor", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der selbst so witzig ist, da ihn doch Balken dr\u00fccken,", "tokens": ["Der", "selbst", "so", "wit\u00b7zig", "ist", ",", "da", "ihn", "doch", "Bal\u00b7ken", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem N\u00e4chsten, der ihn straft, auch Splitter vorzur\u00fccken.", "tokens": ["Dem", "N\u00e4chs\u00b7ten", ",", "der", "ihn", "straft", ",", "auch", "Split\u00b7ter", "vor\u00b7zu\u00b7r\u00fc\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADJD", "$,", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durchgeht, dafern ihr wollt, die Gassen unsrer Stadt,", "tokens": ["Durch\u00b7geht", ",", "da\u00b7fern", "ihr", "wollt", ",", "die", "Gas\u00b7sen", "uns\u00b7rer", "Stadt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "VMFIN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und fraget jedermann, der nur zwo Lippen hat,", "tokens": ["Und", "fra\u00b7get", "je\u00b7der\u00b7mann", ",", "der", "nur", "zwo", "Lip\u00b7pen", "hat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "$,", "PRELS", "ADV", "CARD", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie dieser Nachbar hei\u00dft? was er f\u00fcr Titel f\u00fchret?", "tokens": ["Wie", "die\u00b7ser", "Nach\u00b7bar", "hei\u00dft", "?", "was", "er", "f\u00fcr", "Ti\u00b7tel", "f\u00fch\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NN", "VVFIN", "$.", "PWS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Womit er sich erh\u00e4lt? wie er sein Haus regieret?", "tokens": ["Wo\u00b7mit", "er", "sich", "er\u00b7h\u00e4lt", "?", "wie", "er", "sein", "Haus", "re\u00b7gie\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVFIN", "$.", "PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ob ihn sein Weib auch ehrt? wie Sohn und Tochter lebt?", "tokens": ["Ob", "ihn", "sein", "Weib", "auch", "ehrt", "?", "wie", "Sohn", "und", "Toch\u00b7ter", "lebt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$.", "PWAV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was er bereits erlangt? wornach er k\u00fcnftig strebt?", "tokens": ["Was", "er", "be\u00b7reits", "er\u00b7langt", "?", "wor\u00b7nach", "er", "k\u00fcnf\u00b7tig", "strebt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "$.", "PWAV", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und was dergleichen mehr f\u00fcr Fragen fallen k\u00f6nnen;", "tokens": ["Und", "was", "derg\u00b7lei\u00b7chen", "mehr", "f\u00fcr", "Fra\u00b7gen", "fal\u00b7len", "k\u00f6n\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "APPR", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenn man der L\u00e4sterung ein offnes Ohr will g\u00f6nnen.", "tokens": ["Wenn", "man", "der", "L\u00e4s\u00b7te\u00b7rung", "ein", "off\u00b7nes", "Ohr", "will", "g\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Da wird der gr\u00f6\u00dfte Thor, der noch sich selbst nicht kennt,", "tokens": ["Da", "wird", "der", "gr\u00f6\u00df\u00b7te", "Thor", ",", "der", "noch", "sich", "selbst", "nicht", "kennt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "PRF", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Kaum seinen Namen weis, recht ausspricht, oder nennt,", "tokens": ["Kaum", "sei\u00b7nen", "Na\u00b7men", "weis", ",", "recht", "aus\u00b7spricht", ",", "o\u00b7der", "nennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKVZ", "$,", "ADJD", "VVPP", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Doch seines Nachbars Thun, Stand, Wesen und Bem\u00fchen", "tokens": ["Doch", "sei\u00b7nes", "Nach\u00b7bars", "Thun", ",", "Stand", ",", "We\u00b7sen", "und", "Be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Aufs unbarmherzigste durch seine Hechel ziehen.", "tokens": ["Aufs", "un\u00b7barm\u00b7her\u00b7zigs\u00b7te", "durch", "sei\u00b7ne", "He\u00b7chel", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "Die\u00df ist die alte Pest, die alles angesteckt;", "tokens": ["Die\u00df", "ist", "die", "al\u00b7te", "Pest", ",", "die", "al\u00b7les", "an\u00b7ge\u00b7steckt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die durch ihr Schm\u00e4hen oft die Gro\u00dfmuth selbst erschreckt;", "tokens": ["Die", "durch", "ihr", "Schm\u00e4\u00b7hen", "oft", "die", "Gro\u00df\u00b7muth", "selbst", "er\u00b7schreckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wenn sie gar nichts weis, der Tugend Schuld zu geben,", "tokens": ["Und", "wenn", "sie", "gar", "nichts", "weis", ",", "der", "Tu\u00b7gend", "Schuld", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PIS", "PTKVZ", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die gr\u00f6bsten L\u00fcgen speyt, ihr etwas anzukleben.", "tokens": ["Die", "gr\u00f6bs\u00b7ten", "L\u00fc\u00b7gen", "speyt", ",", "ihr", "et\u00b7was", "an\u00b7zu\u00b7kle\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PPER", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was einer ausgeheckt und h\u00e4misch vorgebracht,", "tokens": ["Was", "ei\u00b7ner", "aus\u00b7ge\u00b7heckt", "und", "h\u00e4\u00b7misch", "vor\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVPP", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird in der ganzen Stadt viel tausendmal belacht,", "tokens": ["Wird", "in", "der", "gan\u00b7zen", "Stadt", "viel", "tau\u00b7send\u00b7mal", "be\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vergr\u00f6\u00dfert, umgekehrt, vergiftet und verg\u00e4llet:", "tokens": ["Ver\u00b7gr\u00f6\u00b7\u00dfert", ",", "um\u00b7ge\u00b7kehrt", ",", "ver\u00b7gif\u00b7tet", "und", "ver\u00b7g\u00e4l\u00b7let", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "$,", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie sonst ein Schneeball w\u00e4chst, der vom Gebirge f\u00e4llet.", "tokens": ["Wie", "sonst", "ein", "Schnee\u00b7ball", "w\u00e4chst", ",", "der", "vom", "Ge\u00b7bir\u00b7ge", "f\u00e4l\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVFIN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So klein er anfangs ist, so gr\u00e4ulich w\u00e4chst er an,", "tokens": ["So", "klein", "er", "an\u00b7fangs", "ist", ",", "so", "gr\u00e4u\u00b7lich", "w\u00e4chst", "er", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "VAFIN", "$,", "ADV", "ADJD", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Indem er tiefer rollt, und nirgends ruhen kann;", "tokens": ["In\u00b7dem", "er", "tie\u00b7fer", "rollt", ",", "und", "nir\u00b7gends", "ru\u00b7hen", "kann", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN", "$,", "KON", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Bis endlich solch ein Klump, der Mensch und Thiere schrecket,", "tokens": ["Bis", "end\u00b7lich", "solch", "ein", "Klump", ",", "der", "Mensch", "und", "Thie\u00b7re", "schre\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ein ganzes Thal erf\u00fcllt, und Feld und Dorf bedecket.", "tokens": ["Ein", "gan\u00b7zes", "Thal", "er\u00b7f\u00fcllt", ",", "und", "Feld", "und", "Dorf", "be\u00b7de\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,", "KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Besch\u00e4mte, durch ein Bild von sonderbarer Art,", "tokens": ["Be\u00b7sch\u00e4m\u00b7te", ",", "durch", "ein", "Bild", "von", "son\u00b7der\u00b7ba\u00b7rer", "Art", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die schwarze L\u00e4sterung, die sich an ihm gerieben:", "tokens": ["Die", "schwar\u00b7ze", "L\u00e4s\u00b7te\u00b7rung", ",", "die", "sich", "an", "ihm", "ge\u00b7rie\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PRF", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Denn anders dacht er nicht die Rach an ihr zu \u00fcben.", "tokens": ["Denn", "an\u00b7ders", "dacht", "er", "nicht", "die", "Rach", "an", "ihr", "zu", "\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er malte rechter Hand den dummen ", "tokens": ["Er", "mal\u00b7te", "rech\u00b7ter", "Hand", "den", "dum\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "An dem das Eselsohr den ungeschliffnen Sinn", "tokens": ["An", "dem", "das", "E\u00b7sel\u00b7sohr", "den", "un\u00b7ge\u00b7schliff\u00b7nen", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und schn\u00f6den Vorwitz wies; zwey Weiber ihm zur Seiten,", "tokens": ["Und", "schn\u00f6\u00b7den", "Vor\u00b7witz", "wies", ";", "zwey", "Wei\u00b7ber", "ihm", "zur", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$.", "CARD", "NN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dadurch den Unverstand und Argwohn anzudeuten.", "tokens": ["Da\u00b7durch", "den", "Un\u00b7ver\u00b7stand", "und", "Arg\u00b7wohn", "an\u00b7zu\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "KON", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zu diesem eilte nun die schn\u00f6de L\u00e4stersucht,", "tokens": ["Zu", "die\u00b7sem", "eil\u00b7te", "nun", "die", "schn\u00f6\u00b7de", "L\u00e4s\u00b7ter\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein sch\u00f6n geschm\u00fccktes Weib; die sonder Scham und Zucht", "tokens": ["Ein", "sch\u00f6n", "ge\u00b7schm\u00fcck\u00b7tes", "Weib", ";", "die", "son\u00b7der", "Scham", "und", "Zucht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Halbrasend vorw\u00e4rts strebt, und zornig im Gesichte", "tokens": ["Hal\u00b7bra\u00b7send", "vor\u00b7w\u00e4rts", "strebt", ",", "und", "zor\u00b7nig", "im", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "VVFIN", "$,", "KON", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die ihre Linke tr\u00e4gt; indem die wilde Glut", "tokens": ["Die", "ih\u00b7re", "Lin\u00b7ke", "tr\u00e4gt", ";", "in\u00b7dem", "die", "wil\u00b7de", "Glut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$.", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sie ganz verschmelzt und fri\u00dft, und ihr fast Schaden thut.", "tokens": ["Sie", "ganz", "ver\u00b7schmelzt", "und", "fri\u00dft", ",", "und", "ihr", "fast", "Scha\u00b7den", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "KON", "VVFIN", "$,", "KON", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Rechte schleppt das Haupt der Unschuld bey den Haaren;", "tokens": ["Die", "Rech\u00b7te", "schleppt", "das", "Haupt", "der", "Un\u00b7schuld", "bey", "den", "Haa\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die einem J\u00fcngling gleicht, der ihren Grimm erfahren.", "tokens": ["Die", "ei\u00b7nem", "J\u00fcng\u00b7ling", "gleicht", ",", "der", "ih\u00b7ren", "Grimm", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$,", "PRELS", "PPOSAT", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Er streckt der Arme Paar, so hoch er immer kann,", "tokens": ["Er", "streckt", "der", "Ar\u00b7me", "Paar", ",", "so", "hoch", "er", "im\u00b7mer", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,", "ADV", "ADJD", "PPER", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und rufft des Himmels Schutz um H\u00fclf und Beystand an.", "tokens": ["Und", "rufft", "des", "Him\u00b7mels", "Schutz", "um", "H\u00fclf", "und", "Beys\u00b7tand", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Es geht ein Mann vorher, mit eingefallnen Wangen,", "tokens": ["Es", "geht", "ein", "Mann", "vor\u00b7her", ",", "mit", "ein\u00b7ge\u00b7fall\u00b7nen", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ganz bla\u00df und abgezehrt, wie die, so was begangen.", "tokens": ["Ganz", "bla\u00df", "und", "ab\u00b7ge\u00b7zehrt", ",", "wie", "die", ",", "so", "was", "be\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVPP", "$,", "PWAV", "ART", "$,", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sein Namen hei\u00dft der Neid. Er d\u00fcrstet recht nach Schmach.", "tokens": ["Sein", "Na\u00b7men", "hei\u00dft", "der", "Neid", ".", "Er", "d\u00fcrs\u00b7tet", "recht", "nach", "Schmach", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Von hinten treten ihm zwey andre Weiber nach,", "tokens": ["Von", "hin\u00b7ten", "tre\u00b7ten", "ihm", "zwey", "and\u00b7re", "Wei\u00b7ber", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "CARD", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Als Arglist und Betrug, die L\u00e4sterung zu schm\u00fccken.", "tokens": ["Als", "Arg\u00b7list", "und", "Be\u00b7trug", ",", "die", "L\u00e4s\u00b7te\u00b7rung", "zu", "schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Am Ende l\u00e4\u00dft sich nur die Reue noch erblicken;", "tokens": ["Am", "En\u00b7de", "l\u00e4\u00dft", "sich", "nur", "die", "Reu\u00b7e", "noch", "er\u00b7bli\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PRF", "ADV", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sie tr\u00e4gt ein Trauerkleid, sieht thr\u00e4nend hinterw\u00e4rts,", "tokens": ["Sie", "tr\u00e4gt", "ein", "Trau\u00b7er\u00b7kleid", ",", "sieht", "thr\u00e4\u00b7nend", "hin\u00b7ter\u00b7w\u00e4rts", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "VVFIN", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und klaget voller Scham der Wahrheit ihren Schmerz,", "tokens": ["Und", "kla\u00b7get", "vol\u00b7ler", "Scham", "der", "Wahr\u00b7heit", "ih\u00b7ren", "Schmerz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die ganz von weitem folgt. So war das Bild erfunden,", "tokens": ["Die", "ganz", "von", "wei\u00b7tem", "folgt", ".", "So", "war", "das", "Bild", "er\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PIS", "VVFIN", "$.", "ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Womit ", "tokens": ["Wo\u00b7mit"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.7": {"line.1": {"text": "O! st\u00fcnd er wieder auf, und k\u00e4m in unsre Stadt,", "tokens": ["O", "!", "st\u00fcnd", "er", "wie\u00b7der", "auf", ",", "und", "k\u00e4m", "in", "uns\u00b7re", "Stadt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo seines Pinsels noch so mancher n\u00f6thig hat:", "tokens": ["Wo", "sei\u00b7nes", "Pin\u00b7sels", "noch", "so", "man\u00b7cher", "n\u00f6\u00b7thig", "hat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADV", "ADV", "PIAT", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was w\u00fcrd' er nicht auch hier der armen Unschuld dienen,", "tokens": ["Was", "w\u00fcrd'", "er", "nicht", "auch", "hier", "der", "ar\u00b7men", "Un\u00b7schuld", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die von der L\u00e4stersucht oft unterdr\u00fcckt geschienen!", "tokens": ["Die", "von", "der", "L\u00e4s\u00b7ter\u00b7sucht", "oft", "un\u00b7ter\u00b7dr\u00fcckt", "ge\u00b7schie\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gleichwohl, da jeder Thor sich selbst zum Richter setzt,", "tokens": ["Gleich\u00b7wohl", ",", "da", "je\u00b7der", "Thor", "sich", "selbst", "zum", "Rich\u00b7ter", "setzt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIAT", "NN", "PRF", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den N\u00e4chsten nicht einmal verh\u00f6rungsw\u00fcrdig sch\u00e4tzt,", "tokens": ["Den", "N\u00e4chs\u00b7ten", "nicht", "ein\u00b7mal", "ver\u00b7h\u00f6\u00b7rungs\u00b7w\u00fcr\u00b7dig", "sch\u00e4tzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und hinterr\u00fccks verdammt, will man sich noch beklagen,", "tokens": ["Und", "hin\u00b7ter\u00b7r\u00fccks", "ver\u00b7dammt", ",", "will", "man", "sich", "noch", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$,", "VMFIN", "PIS", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn Kluge hier und dar die trockne Wahrheit sagen;", "tokens": ["Wenn", "Klu\u00b7ge", "hier", "und", "dar", "die", "trock\u00b7ne", "Wahr\u00b7heit", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "KON", "PAV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn M\u00e4nner, deren Wort mit Salz gew\u00fcrzet ist,", "tokens": ["Wenn", "M\u00e4n\u00b7ner", ",", "de\u00b7ren", "Wort", "mit", "Salz", "ge\u00b7w\u00fcr\u00b7zet", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PRELAT", "NN", "APPR", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von deren Lippen nur Vernunft und Wahrheit flie\u00dft,", "tokens": ["Von", "de\u00b7ren", "Lip\u00b7pen", "nur", "Ver\u00b7nunft", "und", "Wahr\u00b7heit", "flie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "ADV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Thorheit ihrer Zeit zuweilen mit belachen,", "tokens": ["Die", "Thor\u00b7heit", "ih\u00b7rer", "Zeit", "zu\u00b7wei\u00b7len", "mit", "be\u00b7la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Doch nie, wie andre thun, aus L\u00fcgen Wahrheit machen.", "tokens": ["Doch", "nie", ",", "wie", "and\u00b7re", "thun", ",", "aus", "L\u00fc\u00b7gen", "Wahr\u00b7heit", "ma\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "PIS", "VVINF", "$,", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "So war nun ", "tokens": ["So", "war", "nun"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Nichts anders, als die Frucht von Wahrheit und Verstand.", "tokens": ["Nichts", "an\u00b7ders", ",", "als", "die", "Frucht", "von", "Wahr\u00b7heit", "und", "Ver\u00b7stand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "$,", "KOUS", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer hat ihn je geh\u00f6rt der wahren Tugend spotten?", "tokens": ["Wer", "hat", "ihn", "je", "ge\u00b7h\u00f6rt", "der", "wah\u00b7ren", "Tu\u00b7gend", "spot\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVFIN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer ist so unversch\u00e4mt, da\u00df er ihn zu den Rotten", "tokens": ["Wer", "ist", "so", "un\u00b7ver\u00b7sch\u00e4mt", ",", "da\u00df", "er", "ihn", "zu", "den", "Rot\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "ADJD", "$,", "KOUS", "PPER", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Glaubenssp\u00f6tter z\u00e4hlt, die Gott und Schrift verschm\u00e4hn?", "tokens": ["Der", "Glau\u00b7bens\u00b7sp\u00f6t\u00b7ter", "z\u00e4hlt", ",", "die", "Gott", "und", "Schrift", "ver\u00b7schm\u00e4hn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer hat ihn in der Zahl der Schm\u00e4uchler je gesehn,", "tokens": ["Wer", "hat", "ihn", "in", "der", "Zahl", "der", "Schm\u00e4uch\u00b7ler", "je", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die um ein fettes Maul, um Hoffnung, Gunst und Gaben,", "tokens": ["Die", "um", "ein", "fet\u00b7tes", "Maul", ",", "um", "Hoff\u00b7nung", ",", "Gunst", "und", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "$,", "KOUI", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Thoren schn\u00f6des Thun so oft verg\u00f6ttert haben?", "tokens": ["Der", "Tho\u00b7ren", "schn\u00f6\u00b7des", "Thun", "so", "oft", "ver\u00b7g\u00f6t\u00b7tert", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "O nein! er that es nicht! von solcher Sclaverey", "tokens": ["O", "nein", "!", "er", "that", "es", "nicht", "!", "von", "sol\u00b7cher", "Scla\u00b7ve\u00b7rey"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PTKANT", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$.", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "War sein erhabner Geist und edler Griffel frey;", "tokens": ["War", "sein", "er\u00b7hab\u00b7ner", "Geist", "und", "ed\u00b7ler", "Grif\u00b7fel", "frey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sein Griffel, der auch oft der Gro\u00dfen nicht geschonet,", "tokens": ["Sein", "Grif\u00b7fel", ",", "der", "auch", "oft", "der", "Gro\u00b7\u00dfen", "nicht", "ge\u00b7scho\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "ADV", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und ihre Fehler nie mit falschem Ruhm belohnet.", "tokens": ["Und", "ih\u00b7re", "Feh\u00b7ler", "nie", "mit", "fal\u00b7schem", "Ruhm", "be\u00b7loh\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Sein Griffel, der so sch\u00f6n, so rein, so lebhaft schrieb,", "tokens": ["Sein", "Grif\u00b7fel", ",", "der", "so", "sch\u00f6n", ",", "so", "rein", ",", "so", "leb\u00b7haft", "schrieb", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df er der deutschen Welt ein deutlich Muster blieb,", "tokens": ["Da\u00df", "er", "der", "deut\u00b7schen", "Welt", "ein", "deut\u00b7lich", "Mus\u00b7ter", "blieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wie man recht schreiben soll, wenn man mit Witz will schreiben,", "tokens": ["Wie", "man", "recht", "schrei\u00b7ben", "soll", ",", "wenn", "man", "mit", "Witz", "will", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "VVINF", "VMFIN", "$,", "KOUS", "PIS", "APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und unsrer Sprache Schmuck bis auf das H\u00f6chste treiben.", "tokens": ["Und", "uns\u00b7rer", "Spra\u00b7che", "Schmuck", "bis", "auf", "das", "H\u00f6chs\u00b7te", "trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "APPR", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der gro\u00dfe ", "tokens": ["Der", "gro\u00b7\u00dfe"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.18": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.19": {"text": "Da\u00df ihn die sp\u00e4te Zeit, die dieses Buch wird kennen,", "tokens": ["Da\u00df", "ihn", "die", "sp\u00e4\u00b7te", "Zeit", ",", "die", "die\u00b7ses", "Buch", "wird", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$,", "PRELS", "PDAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Den deutschen ", "tokens": ["Den", "deut\u00b7schen"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.9": {"line.1": {"text": "Die\u00df ist dein wahres Lob, zu fr\u00fch erbla\u00dfter Freund!", "tokens": ["Die\u00df", "ist", "dein", "wah\u00b7res", "Lob", ",", "zu", "fr\u00fch", "er\u00b7bla\u00df\u00b7ter", "Freund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,", "PTKA", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein Lob, das dir vieleicht zu hoch getrieben scheint,", "tokens": ["Ein", "Lob", ",", "das", "dir", "vie\u00b7leicht", "zu", "hoch", "ge\u00b7trie\u00b7ben", "scheint", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "PTKA", "ADJD", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch mir zu klein bed\u00fcnkt. Dein aufgewecktes Wesen,", "tokens": ["Doch", "mir", "zu", "klein", "be\u00b7d\u00fcnkt", ".", "Dein", "auf\u00b7ge\u00b7weck\u00b7tes", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKA", "ADJD", "VVPP", "$.", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das uns dein Umgang wies, war edel und erlesen.", "tokens": ["Das", "uns", "dein", "Um\u00b7gang", "wies", ",", "war", "e\u00b7del", "und", "er\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PPOSAT", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein witzerf\u00fcllter Mund schien Frankreich, Rom, Athen", "tokens": ["Dein", "wit\u00b7zer\u00b7f\u00fcll\u00b7ter", "Mund", "schien", "Fran\u00b7kreich", ",", "Rom", ",", "A\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "NE", "$,", "NE", "$,", "NE"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.6": {"text": "An Artigkeit und Salz und Anmuth gleich zu gehn.", "tokens": ["An", "Ar\u00b7tig\u00b7keit", "und", "Salz", "und", "An\u00b7muth", "gleich", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ihr Freunde! sammlet doch sein Scherzen und sein Lachen:", "tokens": ["Ihr", "Freun\u00b7de", "!", "samm\u00b7let", "doch", "sein", "Scher\u00b7zen", "und", "sein", "La\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So wird noch ", "tokens": ["So", "wird", "noch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Und Leipzig r\u00fchmlich seyn: das seiner Kinder Preis,", "tokens": ["Und", "Leip\u00b7zig", "r\u00fchm\u00b7lich", "seyn", ":", "das", "sei\u00b7ner", "Kin\u00b7der", "Preis", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADJD", "VAINF", "$.", "ART", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Aus Neid, nicht allemal nach Werth zu sch\u00e4tzen weis;", "tokens": ["Aus", "Neid", ",", "nicht", "al\u00b7le\u00b7mal", "nach", "Werth", "zu", "sch\u00e4t\u00b7zen", "weis", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PTKNEG", "ADV", "APPR", "NN", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und oft bey W\u00e4lschen sucht, bey Franzen und bey Britten,", "tokens": ["Und", "oft", "bey", "W\u00e4l\u00b7schen", "sucht", ",", "bey", "Fran\u00b7zen", "und", "bey", "Brit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVFIN", "$,", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Worinn es ihnen selbst den Vorzug abgestritten.", "tokens": ["Wo\u00b7rinn", "es", "ih\u00b7nen", "selbst", "den", "Vor\u00b7zug", "ab\u00b7ge\u00b7strit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Wo bleibet noch dein Tod, dem dein gesetzter Muth", "tokens": ["Wo", "blei\u00b7bet", "noch", "dein", "Tod", ",", "dem", "dein", "ge\u00b7setz\u00b7ter", "Muth"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ADV", "PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Getrost entgegen gieng; als dir dein eignes Blut,", "tokens": ["Ge\u00b7trost", "ent\u00b7ge\u00b7gen", "gieng", ";", "als", "dir", "dein", "eig\u00b7nes", "Blut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPO", "VVFIN", "$.", "KOUS", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der edle Lebenssaft, des Lebens Ende dr\u00e4ute?", "tokens": ["Der", "ed\u00b7le", "Le\u00b7bens\u00b7saft", ",", "des", "Le\u00b7bens", "En\u00b7de", "dr\u00e4u\u00b7te", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer sah, da\u00df hier dein Geist sein nahes Sterben scheute?", "tokens": ["Wer", "sah", ",", "da\u00df", "hier", "dein", "Geist", "sein", "na\u00b7hes", "Ster\u00b7ben", "scheu\u00b7te", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "ADV", "PPOSAT", "NN", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du stelltest deinen Sinn in Gottes Herz und Sinn!", "tokens": ["Du", "stell\u00b7test", "dei\u00b7nen", "Sinn", "in", "Got\u00b7tes", "Herz", "und", "Sinn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Darauf entwich dein Geist; und zweifelsfrey dahin,", "tokens": ["Da\u00b7rauf", "ent\u00b7wich", "dein", "Geist", ";", "und", "zwei\u00b7fels\u00b7frey", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "PPOSAT", "NN", "$.", "KON", "CARD", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo die Gerechten stehn, die so, wie du hiernieden,", "tokens": ["Wo", "die", "Ge\u00b7rech\u00b7ten", "stehn", ",", "die", "so", ",", "wie", "du", "hier\u00b7nie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVINF", "$,", "PRELS", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "In fester Zuversicht auf Gottes Huld verschieden.", "tokens": ["In", "fes\u00b7ter", "Zu\u00b7ver\u00b7sicht", "auf", "Got\u00b7tes", "Huld", "ver\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Geneu\u00df der Herrlichkeit, die dir bestimmet ist,", "tokens": ["Ge\u00b7neu\u00df", "der", "Herr\u00b7lich\u00b7keit", ",", "die", "dir", "be\u00b7stim\u00b7met", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und glaube, da\u00df du hier ganz unverge\u00dflich bist;", "tokens": ["Und", "glau\u00b7be", ",", "da\u00df", "du", "hier", "ganz", "un\u00b7ver\u00b7ge\u00df\u00b7lich", "bist", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So lange man nicht wird von klugen Federn schweigen,", "tokens": ["So", "lan\u00b7ge", "man", "nicht", "wird", "von", "klu\u00b7gen", "Fe\u00b7dern", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKNEG", "VAFIN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und deine Schriften noch von deinem Geiste zeugen.", "tokens": ["Und", "dei\u00b7ne", "Schrif\u00b7ten", "noch", "von", "dei\u00b7nem", "Geis\u00b7te", "zeu\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Ach Freund! so war f\u00fcr dich kein sp\u00e4ter Ziel zu hoffen?", "tokens": ["Ach", "Freund", "!", "so", "war", "f\u00fcr", "dich", "kein", "sp\u00e4\u00b7ter", "Ziel", "zu", "hof\u00b7fen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "ADV", "VAFIN", "APPR", "PPER", "PIAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O unverhoffter Schmerz, der unsre Brust betroffen!", "tokens": ["O", "un\u00b7ver\u00b7hoff\u00b7ter", "Schmerz", ",", "der", "uns\u00b7re", "Brust", "be\u00b7trof\u00b7fen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcnf Tage sahen dich gesund und krank und bla\u00df,", "tokens": ["F\u00fcnf", "Ta\u00b7ge", "sa\u00b7hen", "dich", "ge\u00b7sund", "und", "krank", "und", "bla\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und auf der Baare stehn. Ach! wer gedachte das,", "tokens": ["Und", "auf", "der", "Baa\u00b7re", "stehn", ".", "Ach", "!", "wer", "ge\u00b7dach\u00b7te", "das", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$.", "ITJ", "$.", "PWS", "VVFIN", "PDS", "$,"], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Als du vor kurzer Zeit bey guten Freunden sa\u00dfest,", "tokens": ["Als", "du", "vor", "kur\u00b7zer", "Zeit", "bey", "gu\u00b7ten", "Freun\u00b7den", "sa\u00b7\u00dfest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und in erlaubter Lust die letzte Mahlzeit a\u00dfest?", "tokens": ["Und", "in", "er\u00b7laub\u00b7ter", "Lust", "die", "letz\u00b7te", "Mahl\u00b7zeit", "a\u00b7\u00dfest", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die letzte, wo du dich in dieser Welt ergetzt,", "tokens": ["Die", "letz\u00b7te", ",", "wo", "du", "dich", "in", "die\u00b7ser", "Welt", "er\u00b7getzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PWAV", "PPER", "PRF", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und wo der Traurigste den Gram beyseite setzt;", "tokens": ["Und", "wo", "der", "Trau\u00b7rigs\u00b7te", "den", "Gram", "bey\u00b7sei\u00b7te", "setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.9": {"text": "Die letzte, wo dein Mund gelachet und gescherzet,", "tokens": ["Die", "letz\u00b7te", ",", "wo", "dein", "Mund", "ge\u00b7la\u00b7chet", "und", "ge\u00b7scher\u00b7zet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PWAV", "PPOSAT", "NN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und keiner das besorgt, was uns nunmehro schmerzet.", "tokens": ["Und", "kei\u00b7ner", "das", "be\u00b7sorgt", ",", "was", "uns", "nun\u00b7meh\u00b7ro", "schmer\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ART", "ADJD", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Was thut der P\u00f6bel nun, den sonst dein Geist gest\u00f6rt?", "tokens": ["Was", "thut", "der", "P\u00f6\u00b7bel", "nun", ",", "den", "sonst", "dein", "Geist", "ge\u00b7st\u00f6rt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "ADV", "$,", "PRELS", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er lacht und freuet sich, wenn er uns klagen h\u00f6rt;", "tokens": ["Er", "lacht", "und", "freu\u00b7et", "sich", ",", "wenn", "er", "uns", "kla\u00b7gen", "h\u00f6rt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PRF", "$,", "KOUS", "PPER", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und glaubt, nun sey es Zeit, da deine Lippen schweigen,", "tokens": ["Und", "glaubt", ",", "nun", "sey", "es", "Zeit", ",", "da", "dei\u00b7ne", "Lip\u00b7pen", "schwei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "NN", "$,", "KOUS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den alten Groll einmal ganz ungescheut zu zeigen.", "tokens": ["Den", "al\u00b7ten", "Groll", "ein\u00b7mal", "ganz", "un\u00b7ge\u00b7scheut", "zu", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie sonst der k\u00fchne Leu, der ganze W\u00e4lder schreckt,", "tokens": ["Wie", "sonst", "der", "k\u00fch\u00b7ne", "Leu", ",", "der", "gan\u00b7ze", "W\u00e4l\u00b7der", "schreckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nach welchem, weil er lebt, kein Thier die Klauen streckt,", "tokens": ["Nach", "wel\u00b7chem", ",", "weil", "er", "lebt", ",", "kein", "Thier", "die", "Klau\u00b7en", "streckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "$,", "KOUS", "PPER", "VVFIN", "$,", "PIAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn er erstarrt und stirbt und seine Kr\u00e4fte scheiden,", "tokens": ["Wenn", "er", "er\u00b7starrt", "und", "stirbt", "und", "sei\u00b7ne", "Kr\u00e4f\u00b7te", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "KON", "VVFIN", "KON", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auch feiger Hasen Spott und Uebermuth mu\u00df leiden.", "tokens": ["Auch", "fei\u00b7ger", "Ha\u00b7sen", "Spott", "und", "Ue\u00b7ber\u00b7muth", "mu\u00df", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "NN", "KON", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So lang er lebend war, schien auch der Wiederhall", "tokens": ["So", "lang", "er", "le\u00b7bend", "war", ",", "schien", "auch", "der", "Wie\u00b7der\u00b7hall"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "ADJD", "VAFIN", "$,", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von seiner Stimme, schon ein harter Donnerknall:", "tokens": ["Von", "sei\u00b7ner", "Stim\u00b7me", ",", "schon", "ein", "har\u00b7ter", "Don\u00b7ner\u00b7knall", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch itzt hat alles Herz, sich frech an ihn zu wagen,", "tokens": ["Doch", "itzt", "hat", "al\u00b7les", "Herz", ",", "sich", "frech", "an", "ihn", "zu", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIAT", "NN", "$,", "PRF", "ADJD", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Itzt will kein fauler Hund an seiner Kraft verzagen.", "tokens": ["Itzt", "will", "kein", "fau\u00b7ler", "Hund", "an", "sei\u00b7ner", "Kraft", "ver\u00b7za\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Allein, wie geht es zu, Freund! der du uns ergetzt,", "tokens": ["Al\u00b7lein", ",", "wie", "geht", "es", "zu", ",", "Freund", "!", "der", "du", "uns", "er\u00b7getzt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "VVFIN", "PPER", "PTKVZ", "$,", "NN", "$.", "ART", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da\u00df man im Leben dich so f\u00fcrchterlich gesch\u00e4tzt?", "tokens": ["Da\u00df", "man", "im", "Le\u00b7ben", "dich", "so", "f\u00fcrch\u00b7ter\u00b7lich", "ge\u00b7sch\u00e4tzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und da\u00df der P\u00f6bel sich nicht l\u00e4nger kann enthalten,", "tokens": ["Und", "da\u00df", "der", "P\u00f6\u00b7bel", "sich", "nicht", "l\u00e4n\u00b7ger", "kann", "ent\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PRF", "PTKNEG", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In unser Klagelied sein L\u00e4stern einzuschalten?", "tokens": ["In", "un\u00b7ser", "Kla\u00b7ge\u00b7lied", "sein", "L\u00e4s\u00b7tern", "ein\u00b7zu\u00b7schal\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sein schwarzes Thun hat Schuld, da\u00df er die Billigkeit,", "tokens": ["Sein", "schwar\u00b7zes", "Thun", "hat", "Schuld", ",", "da\u00df", "er", "die", "Bil\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "NN", "$,", "KOUS", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die deinen Mund belebt, so wie das Licht gescheut.", "tokens": ["Die", "dei\u00b7nen", "Mund", "be\u00b7lebt", ",", "so", "wie", "das", "Licht", "ge\u00b7scheut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$,", "ADV", "KOKOM", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Daher entstund die Furcht, du m\u00f6chtest Maal und Flecken,", "tokens": ["Da\u00b7her", "ent\u00b7stund", "die", "Furcht", ",", "du", "m\u00f6ch\u00b7test", "Maal", "und", "Fle\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "$,", "PPER", "VMFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die er zu sehr geliebt, durch deinen Witz entdecken.", "tokens": ["Die", "er", "zu", "sehr", "ge\u00b7liebt", ",", "durch", "dei\u00b7nen", "Witz", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADV", "VVPP", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dein Blick durchdrang die Nacht, darinn die Thorheit wohnt,", "tokens": ["Dein", "Blick", "durch\u00b7drang", "die", "Nacht", ",", "da\u00b7rinn", "die", "Thor\u00b7heit", "wohnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$,", "PAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die tausend Laster heckt, und gern im Dunkeln thront.", "tokens": ["Die", "tau\u00b7send", "Las\u00b7ter", "heckt", ",", "und", "gern", "im", "Dun\u00b7keln", "thront", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "VVFIN", "$,", "KON", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Umsonst war sie bedacht, ihr l\u00e4cherlich Bem\u00fchen,", "tokens": ["Um\u00b7sonst", "war", "sie", "be\u00b7dacht", ",", "ihr", "l\u00e4\u00b7cher\u00b7lich", "Be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,", "PPER", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Das sie f\u00fcr Klugheit h\u00e4lt, dir g\u00e4nzlich zu entziehen.", "tokens": ["Das", "sie", "f\u00fcr", "Klug\u00b7heit", "h\u00e4lt", ",", "dir", "g\u00e4nz\u00b7lich", "zu", "ent\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "VVFIN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Dein allzuscharfer Sinn erforschte bald den Grund:", "tokens": ["Dein", "all\u00b7zu\u00b7schar\u00b7fer", "Sinn", "er\u00b7forschte", "bald", "den", "Grund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.14": {"text": "Und ein gesalznes Wort that oft dein Urtheil kund,", "tokens": ["Und", "ein", "ge\u00b7salz\u00b7nes", "Wort", "that", "oft", "dein", "Ur\u00b7theil", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und wu\u00dfte mit Vernunft, in ungereimten Werken,", "tokens": ["Und", "wu\u00df\u00b7te", "mit", "Ver\u00b7nunft", ",", "in", "un\u00b7ge\u00b7reim\u00b7ten", "Wer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den Tadel, der sie traf, recht sinnreich anzumerken.", "tokens": ["Den", "Ta\u00b7del", ",", "der", "sie", "traf", ",", "recht", "sinn\u00b7reich", "an\u00b7zu\u00b7mer\u00b7ken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Das war dein Fehler, Freund! die\u00df scheute mancher Thor,", "tokens": ["Das", "war", "dein", "Feh\u00b7ler", ",", "Freund", "!", "die\u00df", "scheu\u00b7te", "man\u00b7cher", "Thor", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$,", "NN", "$.", "PDS", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die\u00df r\u00fcckte dir der Schwarm der Lasterhaften vor;", "tokens": ["Die\u00df", "r\u00fcck\u00b7te", "dir", "der", "Schwarm", "der", "Las\u00b7ter\u00b7haf\u00b7ten", "vor", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der selbst so witzig ist, da ihn doch Balken dr\u00fccken,", "tokens": ["Der", "selbst", "so", "wit\u00b7zig", "ist", ",", "da", "ihn", "doch", "Bal\u00b7ken", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem N\u00e4chsten, der ihn straft, auch Splitter vorzur\u00fccken.", "tokens": ["Dem", "N\u00e4chs\u00b7ten", ",", "der", "ihn", "straft", ",", "auch", "Split\u00b7ter", "vor\u00b7zu\u00b7r\u00fc\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADJD", "$,", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durchgeht, dafern ihr wollt, die Gassen unsrer Stadt,", "tokens": ["Durch\u00b7geht", ",", "da\u00b7fern", "ihr", "wollt", ",", "die", "Gas\u00b7sen", "uns\u00b7rer", "Stadt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "VMFIN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und fraget jedermann, der nur zwo Lippen hat,", "tokens": ["Und", "fra\u00b7get", "je\u00b7der\u00b7mann", ",", "der", "nur", "zwo", "Lip\u00b7pen", "hat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "$,", "PRELS", "ADV", "CARD", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie dieser Nachbar hei\u00dft? was er f\u00fcr Titel f\u00fchret?", "tokens": ["Wie", "die\u00b7ser", "Nach\u00b7bar", "hei\u00dft", "?", "was", "er", "f\u00fcr", "Ti\u00b7tel", "f\u00fch\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NN", "VVFIN", "$.", "PWS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Womit er sich erh\u00e4lt? wie er sein Haus regieret?", "tokens": ["Wo\u00b7mit", "er", "sich", "er\u00b7h\u00e4lt", "?", "wie", "er", "sein", "Haus", "re\u00b7gie\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVFIN", "$.", "PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ob ihn sein Weib auch ehrt? wie Sohn und Tochter lebt?", "tokens": ["Ob", "ihn", "sein", "Weib", "auch", "ehrt", "?", "wie", "Sohn", "und", "Toch\u00b7ter", "lebt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$.", "PWAV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was er bereits erlangt? wornach er k\u00fcnftig strebt?", "tokens": ["Was", "er", "be\u00b7reits", "er\u00b7langt", "?", "wor\u00b7nach", "er", "k\u00fcnf\u00b7tig", "strebt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "$.", "PWAV", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und was dergleichen mehr f\u00fcr Fragen fallen k\u00f6nnen;", "tokens": ["Und", "was", "derg\u00b7lei\u00b7chen", "mehr", "f\u00fcr", "Fra\u00b7gen", "fal\u00b7len", "k\u00f6n\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "APPR", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenn man der L\u00e4sterung ein offnes Ohr will g\u00f6nnen.", "tokens": ["Wenn", "man", "der", "L\u00e4s\u00b7te\u00b7rung", "ein", "off\u00b7nes", "Ohr", "will", "g\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Da wird der gr\u00f6\u00dfte Thor, der noch sich selbst nicht kennt,", "tokens": ["Da", "wird", "der", "gr\u00f6\u00df\u00b7te", "Thor", ",", "der", "noch", "sich", "selbst", "nicht", "kennt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "PRF", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Kaum seinen Namen weis, recht ausspricht, oder nennt,", "tokens": ["Kaum", "sei\u00b7nen", "Na\u00b7men", "weis", ",", "recht", "aus\u00b7spricht", ",", "o\u00b7der", "nennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKVZ", "$,", "ADJD", "VVPP", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Doch seines Nachbars Thun, Stand, Wesen und Bem\u00fchen", "tokens": ["Doch", "sei\u00b7nes", "Nach\u00b7bars", "Thun", ",", "Stand", ",", "We\u00b7sen", "und", "Be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Aufs unbarmherzigste durch seine Hechel ziehen.", "tokens": ["Aufs", "un\u00b7barm\u00b7her\u00b7zigs\u00b7te", "durch", "sei\u00b7ne", "He\u00b7chel", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.15": {"line.1": {"text": "Die\u00df ist die alte Pest, die alles angesteckt;", "tokens": ["Die\u00df", "ist", "die", "al\u00b7te", "Pest", ",", "die", "al\u00b7les", "an\u00b7ge\u00b7steckt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die durch ihr Schm\u00e4hen oft die Gro\u00dfmuth selbst erschreckt;", "tokens": ["Die", "durch", "ihr", "Schm\u00e4\u00b7hen", "oft", "die", "Gro\u00df\u00b7muth", "selbst", "er\u00b7schreckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wenn sie gar nichts weis, der Tugend Schuld zu geben,", "tokens": ["Und", "wenn", "sie", "gar", "nichts", "weis", ",", "der", "Tu\u00b7gend", "Schuld", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PIS", "PTKVZ", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die gr\u00f6bsten L\u00fcgen speyt, ihr etwas anzukleben.", "tokens": ["Die", "gr\u00f6bs\u00b7ten", "L\u00fc\u00b7gen", "speyt", ",", "ihr", "et\u00b7was", "an\u00b7zu\u00b7kle\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PPER", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was einer ausgeheckt und h\u00e4misch vorgebracht,", "tokens": ["Was", "ei\u00b7ner", "aus\u00b7ge\u00b7heckt", "und", "h\u00e4\u00b7misch", "vor\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVPP", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird in der ganzen Stadt viel tausendmal belacht,", "tokens": ["Wird", "in", "der", "gan\u00b7zen", "Stadt", "viel", "tau\u00b7send\u00b7mal", "be\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vergr\u00f6\u00dfert, umgekehrt, vergiftet und verg\u00e4llet:", "tokens": ["Ver\u00b7gr\u00f6\u00b7\u00dfert", ",", "um\u00b7ge\u00b7kehrt", ",", "ver\u00b7gif\u00b7tet", "und", "ver\u00b7g\u00e4l\u00b7let", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "$,", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie sonst ein Schneeball w\u00e4chst, der vom Gebirge f\u00e4llet.", "tokens": ["Wie", "sonst", "ein", "Schnee\u00b7ball", "w\u00e4chst", ",", "der", "vom", "Ge\u00b7bir\u00b7ge", "f\u00e4l\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVFIN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So klein er anfangs ist, so gr\u00e4ulich w\u00e4chst er an,", "tokens": ["So", "klein", "er", "an\u00b7fangs", "ist", ",", "so", "gr\u00e4u\u00b7lich", "w\u00e4chst", "er", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "VAFIN", "$,", "ADV", "ADJD", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Indem er tiefer rollt, und nirgends ruhen kann;", "tokens": ["In\u00b7dem", "er", "tie\u00b7fer", "rollt", ",", "und", "nir\u00b7gends", "ru\u00b7hen", "kann", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN", "$,", "KON", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Bis endlich solch ein Klump, der Mensch und Thiere schrecket,", "tokens": ["Bis", "end\u00b7lich", "solch", "ein", "Klump", ",", "der", "Mensch", "und", "Thie\u00b7re", "schre\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ein ganzes Thal erf\u00fcllt, und Feld und Dorf bedecket.", "tokens": ["Ein", "gan\u00b7zes", "Thal", "er\u00b7f\u00fcllt", ",", "und", "Feld", "und", "Dorf", "be\u00b7de\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,", "KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Besch\u00e4mte, durch ein Bild von sonderbarer Art,", "tokens": ["Be\u00b7sch\u00e4m\u00b7te", ",", "durch", "ein", "Bild", "von", "son\u00b7der\u00b7ba\u00b7rer", "Art", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die schwarze L\u00e4sterung, die sich an ihm gerieben:", "tokens": ["Die", "schwar\u00b7ze", "L\u00e4s\u00b7te\u00b7rung", ",", "die", "sich", "an", "ihm", "ge\u00b7rie\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PRF", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Denn anders dacht er nicht die Rach an ihr zu \u00fcben.", "tokens": ["Denn", "an\u00b7ders", "dacht", "er", "nicht", "die", "Rach", "an", "ihr", "zu", "\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er malte rechter Hand den dummen ", "tokens": ["Er", "mal\u00b7te", "rech\u00b7ter", "Hand", "den", "dum\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "An dem das Eselsohr den ungeschliffnen Sinn", "tokens": ["An", "dem", "das", "E\u00b7sel\u00b7sohr", "den", "un\u00b7ge\u00b7schliff\u00b7nen", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und schn\u00f6den Vorwitz wies; zwey Weiber ihm zur Seiten,", "tokens": ["Und", "schn\u00f6\u00b7den", "Vor\u00b7witz", "wies", ";", "zwey", "Wei\u00b7ber", "ihm", "zur", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$.", "CARD", "NN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dadurch den Unverstand und Argwohn anzudeuten.", "tokens": ["Da\u00b7durch", "den", "Un\u00b7ver\u00b7stand", "und", "Arg\u00b7wohn", "an\u00b7zu\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "KON", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zu diesem eilte nun die schn\u00f6de L\u00e4stersucht,", "tokens": ["Zu", "die\u00b7sem", "eil\u00b7te", "nun", "die", "schn\u00f6\u00b7de", "L\u00e4s\u00b7ter\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein sch\u00f6n geschm\u00fccktes Weib; die sonder Scham und Zucht", "tokens": ["Ein", "sch\u00f6n", "ge\u00b7schm\u00fcck\u00b7tes", "Weib", ";", "die", "son\u00b7der", "Scham", "und", "Zucht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Halbrasend vorw\u00e4rts strebt, und zornig im Gesichte", "tokens": ["Hal\u00b7bra\u00b7send", "vor\u00b7w\u00e4rts", "strebt", ",", "und", "zor\u00b7nig", "im", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "VVFIN", "$,", "KON", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die ihre Linke tr\u00e4gt; indem die wilde Glut", "tokens": ["Die", "ih\u00b7re", "Lin\u00b7ke", "tr\u00e4gt", ";", "in\u00b7dem", "die", "wil\u00b7de", "Glut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$.", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sie ganz verschmelzt und fri\u00dft, und ihr fast Schaden thut.", "tokens": ["Sie", "ganz", "ver\u00b7schmelzt", "und", "fri\u00dft", ",", "und", "ihr", "fast", "Scha\u00b7den", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "KON", "VVFIN", "$,", "KON", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Rechte schleppt das Haupt der Unschuld bey den Haaren;", "tokens": ["Die", "Rech\u00b7te", "schleppt", "das", "Haupt", "der", "Un\u00b7schuld", "bey", "den", "Haa\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die einem J\u00fcngling gleicht, der ihren Grimm erfahren.", "tokens": ["Die", "ei\u00b7nem", "J\u00fcng\u00b7ling", "gleicht", ",", "der", "ih\u00b7ren", "Grimm", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$,", "PRELS", "PPOSAT", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Er streckt der Arme Paar, so hoch er immer kann,", "tokens": ["Er", "streckt", "der", "Ar\u00b7me", "Paar", ",", "so", "hoch", "er", "im\u00b7mer", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,", "ADV", "ADJD", "PPER", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und rufft des Himmels Schutz um H\u00fclf und Beystand an.", "tokens": ["Und", "rufft", "des", "Him\u00b7mels", "Schutz", "um", "H\u00fclf", "und", "Beys\u00b7tand", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Es geht ein Mann vorher, mit eingefallnen Wangen,", "tokens": ["Es", "geht", "ein", "Mann", "vor\u00b7her", ",", "mit", "ein\u00b7ge\u00b7fall\u00b7nen", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ganz bla\u00df und abgezehrt, wie die, so was begangen.", "tokens": ["Ganz", "bla\u00df", "und", "ab\u00b7ge\u00b7zehrt", ",", "wie", "die", ",", "so", "was", "be\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVPP", "$,", "PWAV", "ART", "$,", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sein Namen hei\u00dft der Neid. Er d\u00fcrstet recht nach Schmach.", "tokens": ["Sein", "Na\u00b7men", "hei\u00dft", "der", "Neid", ".", "Er", "d\u00fcrs\u00b7tet", "recht", "nach", "Schmach", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Von hinten treten ihm zwey andre Weiber nach,", "tokens": ["Von", "hin\u00b7ten", "tre\u00b7ten", "ihm", "zwey", "and\u00b7re", "Wei\u00b7ber", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "CARD", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Als Arglist und Betrug, die L\u00e4sterung zu schm\u00fccken.", "tokens": ["Als", "Arg\u00b7list", "und", "Be\u00b7trug", ",", "die", "L\u00e4s\u00b7te\u00b7rung", "zu", "schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Am Ende l\u00e4\u00dft sich nur die Reue noch erblicken;", "tokens": ["Am", "En\u00b7de", "l\u00e4\u00dft", "sich", "nur", "die", "Reu\u00b7e", "noch", "er\u00b7bli\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PRF", "ADV", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sie tr\u00e4gt ein Trauerkleid, sieht thr\u00e4nend hinterw\u00e4rts,", "tokens": ["Sie", "tr\u00e4gt", "ein", "Trau\u00b7er\u00b7kleid", ",", "sieht", "thr\u00e4\u00b7nend", "hin\u00b7ter\u00b7w\u00e4rts", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "VVFIN", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und klaget voller Scham der Wahrheit ihren Schmerz,", "tokens": ["Und", "kla\u00b7get", "vol\u00b7ler", "Scham", "der", "Wahr\u00b7heit", "ih\u00b7ren", "Schmerz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die ganz von weitem folgt. So war das Bild erfunden,", "tokens": ["Die", "ganz", "von", "wei\u00b7tem", "folgt", ".", "So", "war", "das", "Bild", "er\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PIS", "VVFIN", "$.", "ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Womit ", "tokens": ["Wo\u00b7mit"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.17": {"line.1": {"text": "O! st\u00fcnd er wieder auf, und k\u00e4m in unsre Stadt,", "tokens": ["O", "!", "st\u00fcnd", "er", "wie\u00b7der", "auf", ",", "und", "k\u00e4m", "in", "uns\u00b7re", "Stadt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo seines Pinsels noch so mancher n\u00f6thig hat:", "tokens": ["Wo", "sei\u00b7nes", "Pin\u00b7sels", "noch", "so", "man\u00b7cher", "n\u00f6\u00b7thig", "hat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADV", "ADV", "PIAT", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was w\u00fcrd' er nicht auch hier der armen Unschuld dienen,", "tokens": ["Was", "w\u00fcrd'", "er", "nicht", "auch", "hier", "der", "ar\u00b7men", "Un\u00b7schuld", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die von der L\u00e4stersucht oft unterdr\u00fcckt geschienen!", "tokens": ["Die", "von", "der", "L\u00e4s\u00b7ter\u00b7sucht", "oft", "un\u00b7ter\u00b7dr\u00fcckt", "ge\u00b7schie\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gleichwohl, da jeder Thor sich selbst zum Richter setzt,", "tokens": ["Gleich\u00b7wohl", ",", "da", "je\u00b7der", "Thor", "sich", "selbst", "zum", "Rich\u00b7ter", "setzt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIAT", "NN", "PRF", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den N\u00e4chsten nicht einmal verh\u00f6rungsw\u00fcrdig sch\u00e4tzt,", "tokens": ["Den", "N\u00e4chs\u00b7ten", "nicht", "ein\u00b7mal", "ver\u00b7h\u00f6\u00b7rungs\u00b7w\u00fcr\u00b7dig", "sch\u00e4tzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und hinterr\u00fccks verdammt, will man sich noch beklagen,", "tokens": ["Und", "hin\u00b7ter\u00b7r\u00fccks", "ver\u00b7dammt", ",", "will", "man", "sich", "noch", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$,", "VMFIN", "PIS", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn Kluge hier und dar die trockne Wahrheit sagen;", "tokens": ["Wenn", "Klu\u00b7ge", "hier", "und", "dar", "die", "trock\u00b7ne", "Wahr\u00b7heit", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "KON", "PAV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn M\u00e4nner, deren Wort mit Salz gew\u00fcrzet ist,", "tokens": ["Wenn", "M\u00e4n\u00b7ner", ",", "de\u00b7ren", "Wort", "mit", "Salz", "ge\u00b7w\u00fcr\u00b7zet", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PRELAT", "NN", "APPR", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von deren Lippen nur Vernunft und Wahrheit flie\u00dft,", "tokens": ["Von", "de\u00b7ren", "Lip\u00b7pen", "nur", "Ver\u00b7nunft", "und", "Wahr\u00b7heit", "flie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "ADV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Thorheit ihrer Zeit zuweilen mit belachen,", "tokens": ["Die", "Thor\u00b7heit", "ih\u00b7rer", "Zeit", "zu\u00b7wei\u00b7len", "mit", "be\u00b7la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Doch nie, wie andre thun, aus L\u00fcgen Wahrheit machen.", "tokens": ["Doch", "nie", ",", "wie", "and\u00b7re", "thun", ",", "aus", "L\u00fc\u00b7gen", "Wahr\u00b7heit", "ma\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "PIS", "VVINF", "$,", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "So war nun ", "tokens": ["So", "war", "nun"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Nichts anders, als die Frucht von Wahrheit und Verstand.", "tokens": ["Nichts", "an\u00b7ders", ",", "als", "die", "Frucht", "von", "Wahr\u00b7heit", "und", "Ver\u00b7stand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "$,", "KOUS", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer hat ihn je geh\u00f6rt der wahren Tugend spotten?", "tokens": ["Wer", "hat", "ihn", "je", "ge\u00b7h\u00f6rt", "der", "wah\u00b7ren", "Tu\u00b7gend", "spot\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVFIN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer ist so unversch\u00e4mt, da\u00df er ihn zu den Rotten", "tokens": ["Wer", "ist", "so", "un\u00b7ver\u00b7sch\u00e4mt", ",", "da\u00df", "er", "ihn", "zu", "den", "Rot\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "ADJD", "$,", "KOUS", "PPER", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Glaubenssp\u00f6tter z\u00e4hlt, die Gott und Schrift verschm\u00e4hn?", "tokens": ["Der", "Glau\u00b7bens\u00b7sp\u00f6t\u00b7ter", "z\u00e4hlt", ",", "die", "Gott", "und", "Schrift", "ver\u00b7schm\u00e4hn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer hat ihn in der Zahl der Schm\u00e4uchler je gesehn,", "tokens": ["Wer", "hat", "ihn", "in", "der", "Zahl", "der", "Schm\u00e4uch\u00b7ler", "je", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die um ein fettes Maul, um Hoffnung, Gunst und Gaben,", "tokens": ["Die", "um", "ein", "fet\u00b7tes", "Maul", ",", "um", "Hoff\u00b7nung", ",", "Gunst", "und", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "$,", "KOUI", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Thoren schn\u00f6des Thun so oft verg\u00f6ttert haben?", "tokens": ["Der", "Tho\u00b7ren", "schn\u00f6\u00b7des", "Thun", "so", "oft", "ver\u00b7g\u00f6t\u00b7tert", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "O nein! er that es nicht! von solcher Sclaverey", "tokens": ["O", "nein", "!", "er", "that", "es", "nicht", "!", "von", "sol\u00b7cher", "Scla\u00b7ve\u00b7rey"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PTKANT", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$.", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "War sein erhabner Geist und edler Griffel frey;", "tokens": ["War", "sein", "er\u00b7hab\u00b7ner", "Geist", "und", "ed\u00b7ler", "Grif\u00b7fel", "frey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sein Griffel, der auch oft der Gro\u00dfen nicht geschonet,", "tokens": ["Sein", "Grif\u00b7fel", ",", "der", "auch", "oft", "der", "Gro\u00b7\u00dfen", "nicht", "ge\u00b7scho\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "ADV", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und ihre Fehler nie mit falschem Ruhm belohnet.", "tokens": ["Und", "ih\u00b7re", "Feh\u00b7ler", "nie", "mit", "fal\u00b7schem", "Ruhm", "be\u00b7loh\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Sein Griffel, der so sch\u00f6n, so rein, so lebhaft schrieb,", "tokens": ["Sein", "Grif\u00b7fel", ",", "der", "so", "sch\u00f6n", ",", "so", "rein", ",", "so", "leb\u00b7haft", "schrieb", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df er der deutschen Welt ein deutlich Muster blieb,", "tokens": ["Da\u00df", "er", "der", "deut\u00b7schen", "Welt", "ein", "deut\u00b7lich", "Mus\u00b7ter", "blieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wie man recht schreiben soll, wenn man mit Witz will schreiben,", "tokens": ["Wie", "man", "recht", "schrei\u00b7ben", "soll", ",", "wenn", "man", "mit", "Witz", "will", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "VVINF", "VMFIN", "$,", "KOUS", "PIS", "APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und unsrer Sprache Schmuck bis auf das H\u00f6chste treiben.", "tokens": ["Und", "uns\u00b7rer", "Spra\u00b7che", "Schmuck", "bis", "auf", "das", "H\u00f6chs\u00b7te", "trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "APPR", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der gro\u00dfe ", "tokens": ["Der", "gro\u00b7\u00dfe"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.18": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.19": {"text": "Da\u00df ihn die sp\u00e4te Zeit, die dieses Buch wird kennen,", "tokens": ["Da\u00df", "ihn", "die", "sp\u00e4\u00b7te", "Zeit", ",", "die", "die\u00b7ses", "Buch", "wird", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$,", "PRELS", "PDAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Den deutschen ", "tokens": ["Den", "deut\u00b7schen"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.19": {"line.1": {"text": "Die\u00df ist dein wahres Lob, zu fr\u00fch erbla\u00dfter Freund!", "tokens": ["Die\u00df", "ist", "dein", "wah\u00b7res", "Lob", ",", "zu", "fr\u00fch", "er\u00b7bla\u00df\u00b7ter", "Freund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,", "PTKA", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein Lob, das dir vieleicht zu hoch getrieben scheint,", "tokens": ["Ein", "Lob", ",", "das", "dir", "vie\u00b7leicht", "zu", "hoch", "ge\u00b7trie\u00b7ben", "scheint", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "PTKA", "ADJD", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch mir zu klein bed\u00fcnkt. Dein aufgewecktes Wesen,", "tokens": ["Doch", "mir", "zu", "klein", "be\u00b7d\u00fcnkt", ".", "Dein", "auf\u00b7ge\u00b7weck\u00b7tes", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKA", "ADJD", "VVPP", "$.", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das uns dein Umgang wies, war edel und erlesen.", "tokens": ["Das", "uns", "dein", "Um\u00b7gang", "wies", ",", "war", "e\u00b7del", "und", "er\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PPOSAT", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein witzerf\u00fcllter Mund schien Frankreich, Rom, Athen", "tokens": ["Dein", "wit\u00b7zer\u00b7f\u00fcll\u00b7ter", "Mund", "schien", "Fran\u00b7kreich", ",", "Rom", ",", "A\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "NE", "$,", "NE", "$,", "NE"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.6": {"text": "An Artigkeit und Salz und Anmuth gleich zu gehn.", "tokens": ["An", "Ar\u00b7tig\u00b7keit", "und", "Salz", "und", "An\u00b7muth", "gleich", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ihr Freunde! sammlet doch sein Scherzen und sein Lachen:", "tokens": ["Ihr", "Freun\u00b7de", "!", "samm\u00b7let", "doch", "sein", "Scher\u00b7zen", "und", "sein", "La\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So wird noch ", "tokens": ["So", "wird", "noch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Und Leipzig r\u00fchmlich seyn: das seiner Kinder Preis,", "tokens": ["Und", "Leip\u00b7zig", "r\u00fchm\u00b7lich", "seyn", ":", "das", "sei\u00b7ner", "Kin\u00b7der", "Preis", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADJD", "VAINF", "$.", "ART", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Aus Neid, nicht allemal nach Werth zu sch\u00e4tzen weis;", "tokens": ["Aus", "Neid", ",", "nicht", "al\u00b7le\u00b7mal", "nach", "Werth", "zu", "sch\u00e4t\u00b7zen", "weis", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PTKNEG", "ADV", "APPR", "NN", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und oft bey W\u00e4lschen sucht, bey Franzen und bey Britten,", "tokens": ["Und", "oft", "bey", "W\u00e4l\u00b7schen", "sucht", ",", "bey", "Fran\u00b7zen", "und", "bey", "Brit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVFIN", "$,", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Worinn es ihnen selbst den Vorzug abgestritten.", "tokens": ["Wo\u00b7rinn", "es", "ih\u00b7nen", "selbst", "den", "Vor\u00b7zug", "ab\u00b7ge\u00b7strit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Wo bleibet noch dein Tod, dem dein gesetzter Muth", "tokens": ["Wo", "blei\u00b7bet", "noch", "dein", "Tod", ",", "dem", "dein", "ge\u00b7setz\u00b7ter", "Muth"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ADV", "PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Getrost entgegen gieng; als dir dein eignes Blut,", "tokens": ["Ge\u00b7trost", "ent\u00b7ge\u00b7gen", "gieng", ";", "als", "dir", "dein", "eig\u00b7nes", "Blut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPO", "VVFIN", "$.", "KOUS", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der edle Lebenssaft, des Lebens Ende dr\u00e4ute?", "tokens": ["Der", "ed\u00b7le", "Le\u00b7bens\u00b7saft", ",", "des", "Le\u00b7bens", "En\u00b7de", "dr\u00e4u\u00b7te", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer sah, da\u00df hier dein Geist sein nahes Sterben scheute?", "tokens": ["Wer", "sah", ",", "da\u00df", "hier", "dein", "Geist", "sein", "na\u00b7hes", "Ster\u00b7ben", "scheu\u00b7te", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "ADV", "PPOSAT", "NN", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du stelltest deinen Sinn in Gottes Herz und Sinn!", "tokens": ["Du", "stell\u00b7test", "dei\u00b7nen", "Sinn", "in", "Got\u00b7tes", "Herz", "und", "Sinn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Darauf entwich dein Geist; und zweifelsfrey dahin,", "tokens": ["Da\u00b7rauf", "ent\u00b7wich", "dein", "Geist", ";", "und", "zwei\u00b7fels\u00b7frey", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "PPOSAT", "NN", "$.", "KON", "CARD", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo die Gerechten stehn, die so, wie du hiernieden,", "tokens": ["Wo", "die", "Ge\u00b7rech\u00b7ten", "stehn", ",", "die", "so", ",", "wie", "du", "hier\u00b7nie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVINF", "$,", "PRELS", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "In fester Zuversicht auf Gottes Huld verschieden.", "tokens": ["In", "fes\u00b7ter", "Zu\u00b7ver\u00b7sicht", "auf", "Got\u00b7tes", "Huld", "ver\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Geneu\u00df der Herrlichkeit, die dir bestimmet ist,", "tokens": ["Ge\u00b7neu\u00df", "der", "Herr\u00b7lich\u00b7keit", ",", "die", "dir", "be\u00b7stim\u00b7met", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und glaube, da\u00df du hier ganz unverge\u00dflich bist;", "tokens": ["Und", "glau\u00b7be", ",", "da\u00df", "du", "hier", "ganz", "un\u00b7ver\u00b7ge\u00df\u00b7lich", "bist", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So lange man nicht wird von klugen Federn schweigen,", "tokens": ["So", "lan\u00b7ge", "man", "nicht", "wird", "von", "klu\u00b7gen", "Fe\u00b7dern", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PTKNEG", "VAFIN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und deine Schriften noch von deinem Geiste zeugen.", "tokens": ["Und", "dei\u00b7ne", "Schrif\u00b7ten", "noch", "von", "dei\u00b7nem", "Geis\u00b7te", "zeu\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}