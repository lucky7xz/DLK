{"textgrid.poem.37334": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es hat einmal, so wird gesagt,", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es hat einmal, so wird gesagt,", "tokens": ["Es", "hat", "ein\u00b7mal", ",", "so", "wird", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der L\u00f6we mit dem Wolf gejagt.", "tokens": ["Der", "L\u00f6\u00b7we", "mit", "dem", "Wolf", "ge\u00b7jagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "ART", "NE", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da haben sie vereint erlegt", "tokens": ["Da", "ha\u00b7ben", "sie", "ver\u00b7eint", "er\u00b7legt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Wildschwein, stark und gut gepflegt.", "tokens": ["Ein", "Wild\u00b7schwein", ",", "stark", "und", "gut", "ge\u00b7pflegt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Doch als es ans Verteilen ging,", "tokens": ["Doch", "als", "es", "ans", "Ver\u00b7tei\u00b7len", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "D\u00fcnkt das dem Wolf ein mi\u00dflich Ding.", "tokens": ["D\u00fcnkt", "das", "dem", "Wolf", "ein", "mi\u00df\u00b7lich", "Ding", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ART", "NE", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der L\u00f6we sprach: Was gr\u00fcbelst du?", "tokens": ["Der", "L\u00f6\u00b7we", "sprach", ":", "Was", "gr\u00fc\u00b7belst", "du", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Glaubst du, es geht nicht redlich zu?", "tokens": ["Glaubst", "du", ",", "es", "geht", "nicht", "red\u00b7lich", "zu", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VVFIN", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dort kommt der Fuchs, er mag entscheiden,", "tokens": ["Dort", "kommt", "der", "Fuchs", ",", "er", "mag", "ent\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was jedem zukommt von uns beiden.", "tokens": ["Was", "je\u00b7dem", "zu\u00b7kommt", "von", "uns", "bei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "APPR", "PPER", "PIAT", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Gut, sagt der Wolf, dem solch ein Freund", "tokens": ["Gut", ",", "sagt", "der", "Wolf", ",", "dem", "solch", "ein", "Freund"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "VVFIN", "ART", "NE", "$,", "PRELS", "PIAT", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Richter gar nicht \u00fcbel scheint.", "tokens": ["Als", "Rich\u00b7ter", "gar", "nicht", "\u00fc\u00b7bel", "scheint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der L\u00f6we winkt dem Fuchs sogleich:", "tokens": ["Der", "L\u00f6\u00b7we", "winkt", "dem", "Fuchs", "sog\u00b7leich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ART", "NE", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Herr Doktor, das ist was f\u00fcr Euch.", "tokens": ["Herr", "Dok\u00b7tor", ",", "das", "ist", "was", "f\u00fcr", "Euch", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PDS", "VAFIN", "PIS", "APPR", "PPER", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Hier dieses j\u00fcngst erlegte Schwein,", "tokens": ["Hier", "die\u00b7ses", "j\u00fcngst", "er\u00b7leg\u00b7te", "Schwein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bedenkt es wohl, ist mein und sein.", "tokens": ["Be\u00b7denkt", "es", "wohl", ",", "ist", "mein", "und", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "VAFIN", "PPOSAT", "KON", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich fa\u00dft es vorn, er griff es hinten;", "tokens": ["Ich", "fa\u00dft", "es", "vorn", ",", "er", "griff", "es", "hin\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jetzt teilt es uns, doch ohne Finten.", "tokens": ["Jetzt", "teilt", "es", "uns", ",", "doch", "oh\u00b7ne", "Fin\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Der Fuchs war ein Jurist von Fach.", "tokens": ["Der", "Fuchs", "war", "ein", "Ju\u00b7rist", "von", "Fach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Sehr einfach, spricht er, liegt die Sach.", "tokens": ["Sehr", "ein\u00b7fach", ",", "spricht", "er", ",", "liegt", "die", "Sach", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "VVFIN", "PPER", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Vorderteil, ob viel, ob wenig,", "tokens": ["Das", "Vor\u00b7der\u00b7teil", ",", "ob", "viel", ",", "ob", "we\u00b7nig", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PIS", "$,", "KOUS", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Erh\u00e4lt mit Fug und Recht der K\u00f6nig.", "tokens": ["Er\u00b7h\u00e4lt", "mit", "Fug", "und", "Recht", "der", "K\u00f6\u00b7nig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dir aber, Vetter Isegrim,", "tokens": ["Dir", "a\u00b7ber", ",", "Vet\u00b7ter", "I\u00b7seg\u00b7rim", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geb\u00fchrt das Hinterteil. Da nimm!", "tokens": ["Ge\u00b7b\u00fchrt", "das", "Hin\u00b7ter\u00b7teil", ".", "Da", "nimm", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "$.", "ADV", "VVIMP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Bei diesem Wort trennt er genau", "tokens": ["Bei", "die\u00b7sem", "Wort", "trennt", "er", "ge\u00b7nau"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "ADJD"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Das Schw\u00e4nzlein hinten von der Sau.", "tokens": ["Das", "Schw\u00e4nz\u00b7lein", "hin\u00b7ten", "von", "der", "Sau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indes der Wolf verschm\u00e4ht die Beute,", "tokens": ["In\u00b7des", "der", "Wolf", "ver\u00b7schm\u00e4ht", "die", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verneigt sich kurz und geht beiseite.", "tokens": ["Ver\u00b7neigt", "sich", "kurz", "und", "geht", "bei\u00b7sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "KON", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Fuchs, sprach der L\u00f6we, bleibt bei mir.", "tokens": ["Fuchs", ",", "sprach", "der", "L\u00f6\u00b7we", ",", "bleibt", "bei", "mir", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "ART", "NE", "$,", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von heut an seid Ihr Gro\u00dfvezier.", "tokens": ["Von", "heut", "an", "seid", "Ihr", "Gro\u00df\u00b7ve\u00b7zier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Es hat einmal, so wird gesagt,", "tokens": ["Es", "hat", "ein\u00b7mal", ",", "so", "wird", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der L\u00f6we mit dem Wolf gejagt.", "tokens": ["Der", "L\u00f6\u00b7we", "mit", "dem", "Wolf", "ge\u00b7jagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "ART", "NE", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da haben sie vereint erlegt", "tokens": ["Da", "ha\u00b7ben", "sie", "ver\u00b7eint", "er\u00b7legt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Wildschwein, stark und gut gepflegt.", "tokens": ["Ein", "Wild\u00b7schwein", ",", "stark", "und", "gut", "ge\u00b7pflegt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Doch als es ans Verteilen ging,", "tokens": ["Doch", "als", "es", "ans", "Ver\u00b7tei\u00b7len", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "D\u00fcnkt das dem Wolf ein mi\u00dflich Ding.", "tokens": ["D\u00fcnkt", "das", "dem", "Wolf", "ein", "mi\u00df\u00b7lich", "Ding", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ART", "NE", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der L\u00f6we sprach: Was gr\u00fcbelst du?", "tokens": ["Der", "L\u00f6\u00b7we", "sprach", ":", "Was", "gr\u00fc\u00b7belst", "du", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Glaubst du, es geht nicht redlich zu?", "tokens": ["Glaubst", "du", ",", "es", "geht", "nicht", "red\u00b7lich", "zu", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VVFIN", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dort kommt der Fuchs, er mag entscheiden,", "tokens": ["Dort", "kommt", "der", "Fuchs", ",", "er", "mag", "ent\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was jedem zukommt von uns beiden.", "tokens": ["Was", "je\u00b7dem", "zu\u00b7kommt", "von", "uns", "bei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "APPR", "PPER", "PIAT", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.12": {"line.1": {"text": "Gut, sagt der Wolf, dem solch ein Freund", "tokens": ["Gut", ",", "sagt", "der", "Wolf", ",", "dem", "solch", "ein", "Freund"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "VVFIN", "ART", "NE", "$,", "PRELS", "PIAT", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Richter gar nicht \u00fcbel scheint.", "tokens": ["Als", "Rich\u00b7ter", "gar", "nicht", "\u00fc\u00b7bel", "scheint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Der L\u00f6we winkt dem Fuchs sogleich:", "tokens": ["Der", "L\u00f6\u00b7we", "winkt", "dem", "Fuchs", "sog\u00b7leich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ART", "NE", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Herr Doktor, das ist was f\u00fcr Euch.", "tokens": ["Herr", "Dok\u00b7tor", ",", "das", "ist", "was", "f\u00fcr", "Euch", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PDS", "VAFIN", "PIS", "APPR", "PPER", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Hier dieses j\u00fcngst erlegte Schwein,", "tokens": ["Hier", "die\u00b7ses", "j\u00fcngst", "er\u00b7leg\u00b7te", "Schwein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bedenkt es wohl, ist mein und sein.", "tokens": ["Be\u00b7denkt", "es", "wohl", ",", "ist", "mein", "und", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "VAFIN", "PPOSAT", "KON", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich fa\u00dft es vorn, er griff es hinten;", "tokens": ["Ich", "fa\u00dft", "es", "vorn", ",", "er", "griff", "es", "hin\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jetzt teilt es uns, doch ohne Finten.", "tokens": ["Jetzt", "teilt", "es", "uns", ",", "doch", "oh\u00b7ne", "Fin\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Der Fuchs war ein Jurist von Fach.", "tokens": ["Der", "Fuchs", "war", "ein", "Ju\u00b7rist", "von", "Fach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Sehr einfach, spricht er, liegt die Sach.", "tokens": ["Sehr", "ein\u00b7fach", ",", "spricht", "er", ",", "liegt", "die", "Sach", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "VVFIN", "PPER", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Vorderteil, ob viel, ob wenig,", "tokens": ["Das", "Vor\u00b7der\u00b7teil", ",", "ob", "viel", ",", "ob", "we\u00b7nig", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PIS", "$,", "KOUS", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Erh\u00e4lt mit Fug und Recht der K\u00f6nig.", "tokens": ["Er\u00b7h\u00e4lt", "mit", "Fug", "und", "Recht", "der", "K\u00f6\u00b7nig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dir aber, Vetter Isegrim,", "tokens": ["Dir", "a\u00b7ber", ",", "Vet\u00b7ter", "I\u00b7seg\u00b7rim", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geb\u00fchrt das Hinterteil. Da nimm!", "tokens": ["Ge\u00b7b\u00fchrt", "das", "Hin\u00b7ter\u00b7teil", ".", "Da", "nimm", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "$.", "ADV", "VVIMP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Bei diesem Wort trennt er genau", "tokens": ["Bei", "die\u00b7sem", "Wort", "trennt", "er", "ge\u00b7nau"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "ADJD"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Das Schw\u00e4nzlein hinten von der Sau.", "tokens": ["Das", "Schw\u00e4nz\u00b7lein", "hin\u00b7ten", "von", "der", "Sau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indes der Wolf verschm\u00e4ht die Beute,", "tokens": ["In\u00b7des", "der", "Wolf", "ver\u00b7schm\u00e4ht", "die", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verneigt sich kurz und geht beiseite.", "tokens": ["Ver\u00b7neigt", "sich", "kurz", "und", "geht", "bei\u00b7sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "KON", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Fuchs, sprach der L\u00f6we, bleibt bei mir.", "tokens": ["Fuchs", ",", "sprach", "der", "L\u00f6\u00b7we", ",", "bleibt", "bei", "mir", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "ART", "NE", "$,", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von heut an seid Ihr Gro\u00dfvezier.", "tokens": ["Von", "heut", "an", "seid", "Ihr", "Gro\u00df\u00b7ve\u00b7zier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}