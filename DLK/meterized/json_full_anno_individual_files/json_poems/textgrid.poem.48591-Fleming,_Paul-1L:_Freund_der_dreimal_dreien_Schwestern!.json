{"textgrid.poem.48591": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "1L: Freund der dreimal dreien Schwestern!", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Freund der dreimal dreien Schwestern!", "tokens": ["Freund", "der", "drei\u00b7mal", "drei\u00b7en", "Schwes\u00b7tern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADV", "CARD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan es wol geschehen sein,", "tokens": ["Kan", "es", "wol", "ge\u00b7sche\u00b7hen", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wie du mich berichtetst gestern,", "tokens": ["wie", "du", "mich", "be\u00b7rich\u00b7tetst", "ge\u00b7stern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVFIN", "ADV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "als ich gienge zu dir ein,", "tokens": ["als", "ich", "gien\u00b7ge", "zu", "dir", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df der ", "tokens": ["da\u00df", "der"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "mir und meiner Feldschalmei?", "tokens": ["mir", "und", "mei\u00b7ner", "Feld\u00b7schal\u00b7mei", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ist denn nun mein Dorfgeheule", "tokens": ["Ist", "denn", "nun", "mein", "Dorf\u00b7ge\u00b7heu\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auch bis in die Stadt erschallt,", "tokens": ["auch", "bis", "in", "die", "Stadt", "er\u00b7schallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der ich mich doch, wie ein' Eule,", "tokens": ["der", "ich", "mich", "doch", ",", "wie", "ein'", "Eu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "ADV", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "stets im Wald' und Finsterm halt'?", "tokens": ["stets", "im", "Wald'", "und", "Fins\u00b7term", "halt'", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hat denn auch der F\u00fcrst erh\u00f6rt", "tokens": ["Hat", "denn", "auch", "der", "F\u00fcrst", "er\u00b7h\u00f6rt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "das, was Pan die Bauren lehrt?", "tokens": ["das", ",", "was", "Pan", "die", "Bau\u00b7ren", "lehrt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "NE", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Nun, ich mu\u00df es dir zwar gl\u00e4uben,", "tokens": ["Nun", ",", "ich", "mu\u00df", "es", "dir", "zwar", "gl\u00e4u\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "doch ich bin des Orts nicht wert,", "tokens": ["doch", "ich", "bin", "des", "Orts", "nicht", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der ich billich solte bleiben", "tokens": ["der", "ich", "bil\u00b7lich", "sol\u00b7te", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "stets um meine H\u00fcrd' und Herd'.", "tokens": ["stets", "um", "mei\u00b7ne", "H\u00fcrd'", "und", "Herd'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich will gehen in die Stadt,", "tokens": ["Ich", "will", "ge\u00b7hen", "in", "die", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da man mich gelobet hat.", "tokens": ["da", "man", "mich", "ge\u00b7lo\u00b7bet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "W\u00e4r' ich doch nur schon zur St\u00e4tte,", "tokens": ["W\u00e4r'", "ich", "doch", "nur", "schon", "zur", "St\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da der kluge ", "tokens": ["da", "der", "klu\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "spielet auf der g\u00fcldnen Fl\u00f6te", "tokens": ["spie\u00b7let", "auf", "der", "g\u00fcld\u00b7nen", "Fl\u00f6\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "um der strengen ", "tokens": ["um", "der", "stren\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "um den Ort, da er und du", "tokens": ["um", "den", "Ort", ",", "da", "er", "und", "du"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "PPER", "KON", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "euren Leiern nicht la\u00dft Ruh'!", "tokens": ["eu\u00b7ren", "Lei\u00b7ern", "nicht", "la\u00dft", "Ruh'", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich zwar, der ich, recht zu sagen,", "tokens": ["Ich", "zwar", ",", "der", "ich", ",", "recht", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PRELS", "PPER", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "eine Gans bei Schw\u00e4nen bin,", "tokens": ["ei\u00b7ne", "Gans", "bei", "Schw\u00e4\u00b7nen", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "scheue mich zu euch zu wagen,", "tokens": ["scheu\u00b7e", "mich", "zu", "euch", "zu", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "doch verlangt mich sehr dahin.", "tokens": ["doch", "ver\u00b7langt", "mich", "sehr", "da\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "K\u00f6nt' ich gleich nicht stimmen drein,", "tokens": ["K\u00f6nt'", "ich", "gleich", "nicht", "stim\u00b7men", "drein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PTKNEG", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "doch w\u00fcrd' ich halb selig sein.", "tokens": ["doch", "w\u00fcrd'", "ich", "halb", "se\u00b7lig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ADJD", "VAINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "Weg mit dem, der stets nur lieget", "tokens": ["Weg", "mit", "dem", ",", "der", "stets", "nur", "lie\u00b7get"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "$,", "PRELS", "ADV", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bei der faulen Ofenbank!", "tokens": ["bei", "der", "fau\u00b7len", "O\u00b7fen\u00b7bank", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sich zu Gelehrten f\u00fcget,", "tokens": ["Wer", "sich", "zu", "Ge\u00b7lehr\u00b7ten", "f\u00fc\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "wird gelehrt, verdienet Dank.", "tokens": ["wird", "ge\u00b7lehrt", ",", "ver\u00b7die\u00b7net", "Dank", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "VVFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Di\u00df ist meines Lobes Ziel,", "tokens": ["Di\u00df", "ist", "mei\u00b7nes", "Lo\u00b7bes", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df ich stets mehr lernen will.", "tokens": ["da\u00df", "ich", "stets", "mehr", "ler\u00b7nen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Freund der dreimal dreien Schwestern!", "tokens": ["Freund", "der", "drei\u00b7mal", "drei\u00b7en", "Schwes\u00b7tern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADV", "CARD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan es wol geschehen sein,", "tokens": ["Kan", "es", "wol", "ge\u00b7sche\u00b7hen", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wie du mich berichtetst gestern,", "tokens": ["wie", "du", "mich", "be\u00b7rich\u00b7tetst", "ge\u00b7stern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVFIN", "ADV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "als ich gienge zu dir ein,", "tokens": ["als", "ich", "gien\u00b7ge", "zu", "dir", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df der ", "tokens": ["da\u00df", "der"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "mir und meiner Feldschalmei?", "tokens": ["mir", "und", "mei\u00b7ner", "Feld\u00b7schal\u00b7mei", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Ist denn nun mein Dorfgeheule", "tokens": ["Ist", "denn", "nun", "mein", "Dorf\u00b7ge\u00b7heu\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auch bis in die Stadt erschallt,", "tokens": ["auch", "bis", "in", "die", "Stadt", "er\u00b7schallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der ich mich doch, wie ein' Eule,", "tokens": ["der", "ich", "mich", "doch", ",", "wie", "ein'", "Eu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "ADV", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "stets im Wald' und Finsterm halt'?", "tokens": ["stets", "im", "Wald'", "und", "Fins\u00b7term", "halt'", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hat denn auch der F\u00fcrst erh\u00f6rt", "tokens": ["Hat", "denn", "auch", "der", "F\u00fcrst", "er\u00b7h\u00f6rt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "das, was Pan die Bauren lehrt?", "tokens": ["das", ",", "was", "Pan", "die", "Bau\u00b7ren", "lehrt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "NE", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Nun, ich mu\u00df es dir zwar gl\u00e4uben,", "tokens": ["Nun", ",", "ich", "mu\u00df", "es", "dir", "zwar", "gl\u00e4u\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "doch ich bin des Orts nicht wert,", "tokens": ["doch", "ich", "bin", "des", "Orts", "nicht", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der ich billich solte bleiben", "tokens": ["der", "ich", "bil\u00b7lich", "sol\u00b7te", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "stets um meine H\u00fcrd' und Herd'.", "tokens": ["stets", "um", "mei\u00b7ne", "H\u00fcrd'", "und", "Herd'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich will gehen in die Stadt,", "tokens": ["Ich", "will", "ge\u00b7hen", "in", "die", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da man mich gelobet hat.", "tokens": ["da", "man", "mich", "ge\u00b7lo\u00b7bet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "W\u00e4r' ich doch nur schon zur St\u00e4tte,", "tokens": ["W\u00e4r'", "ich", "doch", "nur", "schon", "zur", "St\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da der kluge ", "tokens": ["da", "der", "klu\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "spielet auf der g\u00fcldnen Fl\u00f6te", "tokens": ["spie\u00b7let", "auf", "der", "g\u00fcld\u00b7nen", "Fl\u00f6\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "um der strengen ", "tokens": ["um", "der", "stren\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "um den Ort, da er und du", "tokens": ["um", "den", "Ort", ",", "da", "er", "und", "du"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "PPER", "KON", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "euren Leiern nicht la\u00dft Ruh'!", "tokens": ["eu\u00b7ren", "Lei\u00b7ern", "nicht", "la\u00dft", "Ruh'", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ich zwar, der ich, recht zu sagen,", "tokens": ["Ich", "zwar", ",", "der", "ich", ",", "recht", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PRELS", "PPER", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "eine Gans bei Schw\u00e4nen bin,", "tokens": ["ei\u00b7ne", "Gans", "bei", "Schw\u00e4\u00b7nen", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "scheue mich zu euch zu wagen,", "tokens": ["scheu\u00b7e", "mich", "zu", "euch", "zu", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "doch verlangt mich sehr dahin.", "tokens": ["doch", "ver\u00b7langt", "mich", "sehr", "da\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "K\u00f6nt' ich gleich nicht stimmen drein,", "tokens": ["K\u00f6nt'", "ich", "gleich", "nicht", "stim\u00b7men", "drein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PTKNEG", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "doch w\u00fcrd' ich halb selig sein.", "tokens": ["doch", "w\u00fcrd'", "ich", "halb", "se\u00b7lig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ADJD", "VAINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.12": {"line.1": {"text": "Weg mit dem, der stets nur lieget", "tokens": ["Weg", "mit", "dem", ",", "der", "stets", "nur", "lie\u00b7get"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "$,", "PRELS", "ADV", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bei der faulen Ofenbank!", "tokens": ["bei", "der", "fau\u00b7len", "O\u00b7fen\u00b7bank", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sich zu Gelehrten f\u00fcget,", "tokens": ["Wer", "sich", "zu", "Ge\u00b7lehr\u00b7ten", "f\u00fc\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "wird gelehrt, verdienet Dank.", "tokens": ["wird", "ge\u00b7lehrt", ",", "ver\u00b7die\u00b7net", "Dank", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "VVFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Di\u00df ist meines Lobes Ziel,", "tokens": ["Di\u00df", "ist", "mei\u00b7nes", "Lo\u00b7bes", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df ich stets mehr lernen will.", "tokens": ["da\u00df", "ich", "stets", "mehr", "ler\u00b7nen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}