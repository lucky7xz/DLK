{"textgrid.poem.65883": {"metadata": {"author": {"name": "Shakespeare, William", "birth": "N.A.", "death": "N.A."}, "title": "William Shakespeare", "genre": "verse", "period": "N.A.", "pub_year": 1590, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn Liebchen spricht, da\u00df nie ihr Herz erkalte,", "tokens": ["Wenn", "Lieb\u00b7chen", "spricht", ",", "da\u00df", "nie", "ihr", "Herz", "er\u00b7kal\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "$,", "KOUS", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So glaub' ich ihr, wenn sie es schon erfand;", "tokens": ["So", "glaub'", "ich", "ihr", ",", "wenn", "sie", "es", "schon", "er\u00b7fand", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "KOUS", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Damit sie mich f\u00fcr einen Neuling halte,", "tokens": ["Da\u00b7mit", "sie", "mich", "f\u00fcr", "ei\u00b7nen", "Neu\u00b7ling", "hal\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit Listen dieser Welt noch unbekannt.", "tokens": ["Mit", "Lis\u00b7ten", "die\u00b7ser", "Welt", "noch", "un\u00b7be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PDAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So, irrig w\u00e4hnend, da\u00df sie jung mich w\u00e4hne,", "tokens": ["So", ",", "ir\u00b7rig", "w\u00e4h\u00b7nend", ",", "da\u00df", "sie", "jung", "mich", "w\u00e4h\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJD", "VVPP", "$,", "KOUS", "PPER", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wiewohl sie wei\u00df, mein Fr\u00fchling ist dahin,", "tokens": ["Wie\u00b7wohl", "sie", "wei\u00df", ",", "mein", "Fr\u00fch\u00b7ling", "ist", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PPOSAT", "NN", "VAFIN", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Leugn' ich's ihr nicht in ihre falschen Z\u00e4hne,", "tokens": ["Leugn'", "ich's", "ihr", "nicht", "in", "ih\u00b7re", "fal\u00b7schen", "Z\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "PPER", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und beiderseits verbirgt sich wahrer Sinn.", "tokens": ["Und", "bei\u00b7der\u00b7seits", "ver\u00b7birgt", "sich", "wah\u00b7rer", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Doch warum sagt sie nicht, da\u00df sie nicht treu?", "tokens": ["Doch", "wa\u00b7rum", "sagt", "sie", "nicht", ",", "da\u00df", "sie", "nicht", "treu", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Warum nicht ich, da\u00df einst ich jung gewesen?", "tokens": ["Wa\u00b7rum", "nicht", "ich", ",", "da\u00df", "einst", "ich", "jung", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "PPER", "$,", "KOUS", "ADV", "PPER", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "O, Amors Lieblingslust ist Heuchelei,", "tokens": ["O", ",", "A\u00b7mors", "Lieb\u00b7lings\u00b7lust", "ist", "Heu\u00b7che\u00b7lei", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Und Lieb' in Jahren mag nicht Jahreszahlen lesen.", "tokens": ["Und", "Lieb'", "in", "Jah\u00b7ren", "mag", "nicht", "Jah\u00b7res\u00b7zah\u00b7len", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "VMFIN", "PTKNEG", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Darum bel\u00fcg' ich sie, bel\u00fcgt sie mich,", "tokens": ["Da\u00b7rum", "be\u00b7l\u00fcg'", "ich", "sie", ",", "be\u00b7l\u00fcgt", "sie", "mich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "$,", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Und unsre L\u00fcgens\u00fcnden schmeicheln sich.", "tokens": ["Und", "uns\u00b7re", "L\u00fc\u00b7gen\u00b7s\u00fcn\u00b7den", "schmei\u00b7cheln", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Zwei Flammen hab' ich, die im Doppelbann,", "tokens": ["Zwei", "Flam\u00b7men", "hab'", "ich", ",", "die", "im", "Dop\u00b7pel\u00b7bann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "$,", "PRELS", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie Geister, zwischen Trost und Qual mich lassen darben:", "tokens": ["Wie", "Geis\u00b7ter", ",", "zwi\u00b7schen", "Trost", "und", "Qual", "mich", "las\u00b7sen", "dar\u00b7ben", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "APPR", "NN", "KON", "NN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der bess're Engel ist ein sch\u00f6ner Mann,", "tokens": ["Der", "bess'\u00b7re", "En\u00b7gel", "ist", "ein", "sch\u00f6\u00b7ner", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der schlimmere Geist ein Weib von b\u00f6sen Farben.", "tokens": ["Der", "schlim\u00b7me\u00b7re", "Geist", "ein", "Weib", "von", "b\u00f6\u00b7sen", "Far\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Mein weiblich Unheil, bald dem Pfuhl mich zu gesellen,", "tokens": ["Mein", "weib\u00b7lich", "Un\u00b7heil", ",", "bald", "dem", "Pfuhl", "mich", "zu", "ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADV", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Lockt meinen guten Engel von mir fort:", "tokens": ["Lockt", "mei\u00b7nen", "gu\u00b7ten", "En\u00b7gel", "von", "mir", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Zum Teufel m\u00f6chte sie den Heiligen entstellen;", "tokens": ["Zum", "Teu\u00b7fel", "m\u00f6ch\u00b7te", "sie", "den", "Hei\u00b7li\u00b7gen", "ent\u00b7stel\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dem Reinen kost ihr falsches Schmeichelwort.", "tokens": ["Dem", "Rei\u00b7nen", "kost", "ihr", "fal\u00b7sches", "Schmei\u00b7chel\u00b7wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und, ob mein Engel nun schon eingefeindet,", "tokens": ["Und", ",", "ob", "mein", "En\u00b7gel", "nun", "schon", "ein\u00b7ge\u00b7fein\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Besorg' ich; \u2013 zwar nicht v\u00f6llig ist's bekannt; \u2013", "tokens": ["Be\u00b7sor\u00b7g'", "ich", ";", "\u2013", "zwar", "nicht", "v\u00f6l\u00b7lig", "ist's", "be\u00b7kannt", ";", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "ADV", "PTKNEG", "ADJD", "VAFIN", "ADJD", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.11": {"text": "Doch, da mich beide fliehn, und beide sich befreundet,", "tokens": ["Doch", ",", "da", "mich", "bei\u00b7de", "fliehn", ",", "und", "bei\u00b7de", "sich", "be\u00b7freun\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PIS", "VVINF", "$,", "KON", "PIS", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "F\u00fcrcht' ich, ein Engel ward des andern H\u00f6llenbrand.", "tokens": ["F\u00fcrcht'", "ich", ",", "ein", "En\u00b7gel", "ward", "des", "an\u00b7dern", "H\u00f6l\u00b7len\u00b7brand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und wie es steh', ich kann es nicht vermuten,", "tokens": ["Und", "wie", "es", "steh'", ",", "ich", "kann", "es", "nicht", "ver\u00b7mu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Als bis mein b\u00f6ser Geist verschlingt den guten.", "tokens": ["Als", "bis", "mein", "b\u00f6\u00b7ser", "Geist", "ver\u00b7schlingt", "den", "gu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Hat deiner Augen Himmelsredemacht,", "tokens": ["Hat", "dei\u00b7ner", "Au\u00b7gen", "Him\u00b7mels\u00b7re\u00b7de\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die keine Welt bestreiten wird mit Gr\u00fcnden,", "tokens": ["Die", "kei\u00b7ne", "Welt", "be\u00b7strei\u00b7ten", "wird", "mit", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mein Herz zu diesem Meineid nicht gebracht?", "tokens": ["Mein", "Herz", "zu", "die\u00b7sem", "Mei\u00b7neid", "nicht", "ge\u00b7bracht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PDAT", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Um dich gebrochne Schw\u00fcre sind nicht S\u00fcnden.", "tokens": ["Um", "dich", "ge\u00b7broch\u00b7ne", "Schw\u00fc\u00b7re", "sind", "nicht", "S\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "VVFIN", "NN", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ein Weib verschwur ich; aber da\u00df ich nicht", "tokens": ["Ein", "Weib", "ver\u00b7schwur", "ich", ";", "a\u00b7ber", "da\u00df", "ich", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "ADV", "KOUS", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Dich ", "tokens": ["Dich"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Mein Eid war irdisch, du ein himmlisch Licht.", "tokens": ["Mein", "Eid", "war", "ir\u00b7disch", ",", "du", "ein", "himm\u00b7lisch", "Licht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPER", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Von aller Schuld befreit mich dein Erh\u00f6ren.", "tokens": ["Von", "al\u00b7ler", "Schuld", "be\u00b7freit", "mich", "dein", "Er\u00b7h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Mein Eid war Hauch; Hauch ist ein Dunst: so saugest", "tokens": ["Mein", "Eid", "war", "Hauch", ";", "Hauch", "ist", "ein", "Dunst", ":", "so", "sau\u00b7gest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$.", "NN", "VAFIN", "ART", "NN", "$.", "ADV", "VVFIN"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Du sch\u00f6ne Sonne meiner Erdenbahn", "tokens": ["Du", "sch\u00f6\u00b7ne", "Son\u00b7ne", "mei\u00b7ner", "Er\u00b7den\u00b7bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Dies dunstige Gel\u00fcbd' in dich, verhauchest,", "tokens": ["Dies", "duns\u00b7ti\u00b7ge", "Ge\u00b7l\u00fcbd'", "in", "dich", ",", "ver\u00b7hau\u00b7chest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "APPR", "PPER", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Zerrei\u00dfest es; ich hab' nicht Teil daran.", "tokens": ["Zer\u00b7rei\u00b7\u00dfest", "es", ";", "ich", "hab'", "nicht", "Teil", "da\u00b7ran", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VAFIN", "PTKNEG", "NN", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und h\u00e4tt ich's auch gebrochen, welcher Tor", "tokens": ["Und", "h\u00e4tt", "ich's", "auch", "ge\u00b7bro\u00b7chen", ",", "wel\u00b7cher", "Tor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "PIS", "ADV", "VVPP", "$,", "PWAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Z\u00f6g einen Schwur dem Paradiese vor?", "tokens": ["Z\u00f6g", "ei\u00b7nen", "Schwur", "dem", "Pa\u00b7ra\u00b7die\u00b7se", "vor", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "An einem Bache sa\u00df die reizende Cythere,", "tokens": ["An", "ei\u00b7nem", "Ba\u00b7che", "sa\u00df", "die", "rei\u00b7zen\u00b7de", "Cy\u00b7the\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Von ihrem jungen Freund Adonis hoch entz\u00fcckt.", "tokens": ["Von", "ih\u00b7rem", "jun\u00b7gen", "Freund", "A\u00b7do\u00b7nis", "hoch", "ent\u00b7z\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NE", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit manchem s\u00fc\u00dfen Blick lieb\u00e4ugelt ihm die Hehre,", "tokens": ["Mit", "man\u00b7chem", "s\u00fc\u00b7\u00dfen", "Blick", "lie\u00b7b\u00e4u\u00b7gelt", "ihm", "die", "Heh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit Blicken wie nur sie, der Sch\u00f6nheit F\u00fcrstin, blickt.", "tokens": ["Mit", "Bli\u00b7cken", "wie", "nur", "sie", ",", "der", "Sch\u00f6n\u00b7heit", "F\u00fcrs\u00b7tin", ",", "blickt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "KOKOM", "ADV", "PPER", "$,", "ART", "NN", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dem Ohr zur Lust erz\u00e4hlt sie M\u00e4rlein ihm,", "tokens": ["Dem", "Ohr", "zur", "Lust", "er\u00b7z\u00e4hlt", "sie", "M\u00e4r\u00b7lein", "ihm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "PPER", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Zeigt Liebliches, die Augen zu versuchen;", "tokens": ["Zeigt", "Lieb\u00b7li\u00b7ches", ",", "die", "Au\u00b7gen", "zu", "ver\u00b7su\u00b7chen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ber\u00fchrt ihn hie und da, sein Herz an sich zu ziehn:", "tokens": ["Be\u00b7r\u00fchrt", "ihn", "hie", "und", "da", ",", "sein", "Herz", "an", "sich", "zu", "ziehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KON", "ADV", "$,", "PPOSAT", "NN", "APPR", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So schmeichelndes Getast wird oft das Grab der Tugend. \u2013", "tokens": ["So", "schmei\u00b7cheln\u00b7des", "Ge\u00b7tast", "wird", "oft", "das", "Grab", "der", "Tu\u00b7gend", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch, ob den fr\u00fchen Jahren Sinn gebricht,", "tokens": ["Doch", ",", "ob", "den", "fr\u00fc\u00b7hen", "Jah\u00b7ren", "Sinn", "ge\u00b7bricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "ADJA", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ob er verschm\u00e4het ihr verbl\u00fcmtes Deuten,", "tokens": ["Ob", "er", "ver\u00b7schm\u00e4\u00b7het", "ihr", "ver\u00b7bl\u00fcm\u00b7tes", "Deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Der junge Gr\u00fcndling schluckt den Hamen nicht,", "tokens": ["Der", "jun\u00b7ge", "Gr\u00fcnd\u00b7ling", "schluckt", "den", "Ha\u00b7men", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Und lacht und spottet aller Artigkeiten.", "tokens": ["Und", "lacht", "und", "spot\u00b7tet", "al\u00b7ler", "Ar\u00b7tig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Da fiel die gn\u00e4d'ge G\u00f6ttin r\u00fccklings hin:", "tokens": ["Da", "fiel", "die", "gn\u00e4d'\u00b7ge", "G\u00f6t\u00b7tin", "r\u00fcck\u00b7lings", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Und er sprang auf und lief. \u2013 O Eigensinn!", "tokens": ["Und", "er", "sprang", "auf", "und", "lief", ".", "\u2013", "O", "Ei\u00b7gen\u00b7sinn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "$.", "$(", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Lehrt Liebe Meineid mich, wie soll ich Liebe schw\u00f6ren?", "tokens": ["Lehrt", "Lie\u00b7be", "Mei\u00b7neid", "mich", ",", "wie", "soll", "ich", "Lie\u00b7be", "schw\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "NN", "PPER", "$,", "PWAV", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O Sch\u00f6nheit, sie allein h\u00e4lt Liebestreu im Flor!", "tokens": ["O", "Sch\u00f6n\u00b7heit", ",", "sie", "al\u00b7lein", "h\u00e4lt", "Lie\u00b7be\u00b7streu", "im", "Flor", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "ADV", "VVFIN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie auch mir selber falsch, treu will ich dir geh\u00f6ren.", "tokens": ["Wie", "auch", "mir", "sel\u00b7ber", "falsch", ",", "treu", "will", "ich", "dir", "ge\u00b7h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "ADV", "ADJD", "$,", "ADJD", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dies Wort, mir eichenfest, scheint dir ein schwankes Rohr.", "tokens": ["Dies", "Wort", ",", "mir", "ei\u00b7chen\u00b7fest", ",", "scheint", "dir", "ein", "schwan\u00b7kes", "Rohr", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$,", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Betrachtung l\u00e4\u00dft ihr Buch und forscht in deinen Augen,", "tokens": ["Be\u00b7trach\u00b7tung", "l\u00e4\u00dft", "ihr", "Buch", "und", "forscht", "in", "dei\u00b7nen", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo alle Wonne lebt, die nur die Kunst erschleu\u00dft.", "tokens": ["Wo", "al\u00b7le", "Won\u00b7ne", "lebt", ",", "die", "nur", "die", "Kunst", "er\u00b7schleu\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "$,", "PRELS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist Kenntnis Ziel, du kannst statt aller Kenntnis taugen:", "tokens": ["Ist", "Kennt\u00b7nis", "Ziel", ",", "du", "kannst", "statt", "al\u00b7ler", "Kennt\u00b7nis", "tau\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NN", "$,", "PPER", "VMFIN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Am weisesten der Mund, der dich am besten preist.", "tokens": ["Am", "wei\u00b7ses\u00b7ten", "der", "Mund", ",", "der", "dich", "am", "bes\u00b7ten", "preist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ART", "NN", "$,", "PRELS", "PRF", "APPRART", "ADJA", "NN", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.9": {"text": "Wer unger\u00fchrt dich s\u00e4h, die roh'ste Seele h\u00e4tt' er.", "tokens": ["Wer", "un\u00b7ge\u00b7r\u00fchrt", "dich", "s\u00e4h", ",", "die", "roh'\u00b7ste", "See\u00b7le", "h\u00e4tt'", "er", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "VAFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df du ein Wunder mir, kommt meinem Ruf zu gut.", "tokens": ["Da\u00df", "du", "ein", "Wun\u00b7der", "mir", ",", "kommt", "mei\u00b7nem", "Ruf", "zu", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PPER", "$,", "VVFIN", "PPOSAT", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dein Aug' ist Jovis Blitz, dein Laut sein drohend Wetter;", "tokens": ["Dein", "Aug'", "ist", "Jo\u00b7vis", "Blitz", ",", "dein", "Laut", "sein", "dro\u00b7hend", "Wet\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NE", "NN", "$,", "PPOSAT", "APPR", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Doch, ohne Zorn, Musik und sanfte Lebensglut.", "tokens": ["Doch", ",", "oh\u00b7ne", "Zorn", ",", "Mu\u00b7sik", "und", "sanf\u00b7te", "Le\u00b7bens\u00b7glut", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUI", "NN", "$,", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "O, himmlisch wie du bist, verleugne dich nicht so,", "tokens": ["O", ",", "himm\u00b7lisch", "wie", "du", "bist", ",", "ver\u00b7leug\u00b7ne", "dich", "nicht", "so", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "KOKOM", "PPER", "VAFIN", "$,", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und singe Himmels Lob so irdisch rauh und roh.", "tokens": ["Und", "sin\u00b7ge", "Him\u00b7mels", "Lob", "so", "ir\u00b7disch", "rauh", "und", "roh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NN", "ADV", "ADJD", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Kaum war der Tau vom Fr\u00fchlicht aufgetrunken,", "tokens": ["Kaum", "war", "der", "Tau", "vom", "Fr\u00fch\u00b7licht", "auf\u00b7ge\u00b7trun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kaum ruht die Herd' umz\u00e4unt im Schattendach,", "tokens": ["Kaum", "ruht", "die", "Herd'", "um\u00b7z\u00e4unt", "im", "Schat\u00b7ten\u00b7dach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als Cypria, in Liebe ganz versunken,", "tokens": ["Als", "Cyp\u00b7ria", ",", "in", "Lie\u00b7be", "ganz", "ver\u00b7sun\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$,", "APPR", "NN", "ADV", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Voll Sehnsucht des Adonis harrt' am Bach,", "tokens": ["Voll", "Sehn\u00b7sucht", "des", "A\u00b7do\u00b7nis", "harrt'", "am", "Bach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Bei einem Weidenbaum. Adonis war", "tokens": ["Bei", "ei\u00b7nem", "Wei\u00b7den\u00b7baum", ".", "A\u00b7do\u00b7nis", "war"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "NE", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Im Bach gewohnt sein Feuer abzuk\u00fchlen.", "tokens": ["Im", "Bach", "ge\u00b7wohnt", "sein", "Feu\u00b7er", "ab\u00b7zu\u00b7k\u00fch\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Hei\u00df schien die Sonne, hei\u00dfer noch f\u00fcrwahr", "tokens": ["Hei\u00df", "schien", "die", "Son\u00b7ne", ",", "hei\u00b7\u00dfer", "noch", "f\u00fcr\u00b7wahr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "$,", "ADJA", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Die seiner harrt'; oft pflegt' er dort zu spielen.", "tokens": ["Die", "sei\u00b7ner", "harrt'", ";", "oft", "pflegt'", "er", "dort", "zu", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und sieh! er kommt, und wirft den Mantel ab,", "tokens": ["Und", "sieh", "!", "er", "kommt", ",", "und", "wirft", "den", "Man\u00b7tel", "ab", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$.", "PPER", "VVFIN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Steht mutternackt auf gr\u00fcnem Wiesenplan.", "tokens": ["Steht", "mut\u00b7ter\u00b7nackt", "auf", "gr\u00fc\u00b7nem", "Wie\u00b7sen\u00b7plan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Mit Herrscheraugen blickt die Sonn' herab;", "tokens": ["Mit", "Herr\u00b7scher\u00b7au\u00b7gen", "blickt", "die", "Sonn'", "her\u00b7ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Noch br\u00fcnstiger blickt ihn die G\u00f6ttin an.", "tokens": ["Noch", "br\u00fcns\u00b7ti\u00b7ger", "blickt", "ihn", "die", "G\u00f6t\u00b7tin", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Kaum sah er sie, sprang er hinab. Sie sprach:", "tokens": ["Kaum", "sah", "er", "sie", ",", "sprang", "er", "hin\u00b7ab", ".", "Sie", "sprach", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "\u00bbo Jupiter! O w\u00e4r' ich doch der Bach!\u00ab", "tokens": ["\u00bb", "o", "Ju\u00b7pi\u00b7ter", "!", "O", "w\u00e4r'", "ich", "doch", "der", "Bach", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "NN", "$.", "NE", "VAFIN", "PPER", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Mein Lieb ist sch\u00f6n, doch nicht so sch\u00f6n als schn\u00f6de:", "tokens": ["Mein", "Lieb", "ist", "sch\u00f6n", ",", "doch", "nicht", "so", "sch\u00f6n", "als", "schn\u00f6\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "ADV", "PTKNEG", "ADV", "ADJD", "KOKOM", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie Tauben sanft, doch schlangenglatt und frostig;", "tokens": ["Wie", "Tau\u00b7ben", "sanft", ",", "doch", "schlan\u00b7gen\u00b7glatt", "und", "fros\u00b7tig", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Heller als Glas, und doch wie Glas so spr\u00f6de,", "tokens": ["Hel\u00b7ler", "als", "Glas", ",", "und", "doch", "wie", "Glas", "so", "spr\u00f6\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "NN", "$,", "KON", "ADV", "KOKOM", "NN", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Weicher als Wachs, und doch wie Eisen rostig:", "tokens": ["Wei\u00b7cher", "als", "Wachs", ",", "und", "doch", "wie", "Ei\u00b7sen", "ros\u00b7tig", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "NN", "$,", "KON", "ADV", "KOKOM", "NN", "ADJD", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "Ein wenig bleich, mit etwas Rosenr\u00f6te,", "tokens": ["Ein", "we\u00b7nig", "bleich", ",", "mit", "et\u00b7was", "Ro\u00b7sen\u00b7r\u00f6\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So sch\u00f6n wie keine, und so falsch wie jede.", "tokens": ["So", "sch\u00f6n", "wie", "kei\u00b7ne", ",", "und", "so", "falsch", "wie", "je\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "PIAT", "$,", "KON", "ADV", "ADJD", "KOKOM", "PIAT", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Wie hat sie mich mit Lippen schier verschlungen,", "tokens": ["Wie", "hat", "sie", "mich", "mit", "Lip\u00b7pen", "schier", "ver\u00b7schlun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PRF", "APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf jeden Ku\u00df ein Heer von Liebesschw\u00fcren.", "tokens": ["Auf", "je\u00b7den", "Ku\u00df", "ein", "Heer", "von", "Lie\u00b7bes\u00b7schw\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie hat sie mich mit M\u00e4rchen eingesungen,", "tokens": ["Wie", "hat", "sie", "mich", "mit", "M\u00e4r\u00b7chen", "ein\u00b7ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PRF", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als br\u00e4ch' ihr Herz, das meine zu verlieren!", "tokens": ["Als", "br\u00e4ch'", "ihr", "Herz", ",", "das", "mei\u00b7ne", "zu", "ver\u00b7lie\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und doch, im Schwung der h\u00f6chsten Seelenfl\u00fcge", "tokens": ["Und", "doch", ",", "im", "Schwung", "der", "h\u00f6chs\u00b7ten", "See\u00b7len\u00b7fl\u00fc\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "APPRART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ward Eid und Treu und Tr\u00e4n' und alles L\u00fcge.", "tokens": ["Ward", "Eid", "und", "Treu", "und", "Tr\u00e4n'", "und", "al\u00b7les", "L\u00fc\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "KON", "NN", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Sie brannt' in Liebe wie das Stroh in Flammen,", "tokens": ["Sie", "brannt'", "in", "Lie\u00b7be", "wie", "das", "Stroh", "in", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KOKOM", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verbrannt' in Liebe schnell wie Stroh verbrennet,", "tokens": ["Ver\u00b7brannt'", "in", "Lie\u00b7be", "schnell", "wie", "Stroh", "ver\u00b7bren\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADJD", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Erbaute Lieb', und ri\u00df sie wild zusammen;", "tokens": ["Er\u00b7bau\u00b7te", "Lieb'", ",", "und", "ri\u00df", "sie", "wild", "zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schwur ew'ge Lieb', und hat sie rasch zertrennet.", "tokens": ["Schwur", "ew'\u00b7ge", "Lieb'", ",", "und", "hat", "sie", "rasch", "zer\u00b7tren\u00b7net", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "$,", "KON", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Soll sie als Buhl', als Liebchen mir gefallen,", "tokens": ["Soll", "sie", "als", "Buhl'", ",", "als", "Lieb\u00b7chen", "mir", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KOUS", "NN", "$,", "KOUS", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Zu schlecht zum guten, und gering in allem?", "tokens": ["Zu", "schlecht", "zum", "gu\u00b7ten", ",", "und", "ge\u00b7ring", "in", "al\u00b7lem", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "APPRART", "ADJA", "$,", "KON", "ADJD", "APPR", "PIS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Der Morgen l\u00e4chelte: die sch\u00f6ne Venus war", "tokens": ["Der", "Mor\u00b7gen", "l\u00e4\u00b7chel\u00b7te", ":", "die", "sch\u00f6\u00b7ne", "Ve\u00b7nus", "war"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.3": {"text": "Vor Kummer bleicher als ihr schneewei\u00df Taubenpaar,", "tokens": ["Vor", "Kum\u00b7mer", "blei\u00b7cher", "als", "ihr", "schnee\u00b7wei\u00df", "Tau\u00b7ben\u00b7paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "KOKOM", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des wilden Springinsfeld Adonis wegen.", "tokens": ["Des", "wil\u00b7den", "Sprin\u00b7gins\u00b7feld", "A\u00b7do\u00b7nis", "we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "APPR", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie tritt auf einen j\u00e4hen Holm. Geschwind", "tokens": ["Sie", "tritt", "auf", "ei\u00b7nen", "j\u00e4\u00b7hen", "Holm", ".", "Ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$.", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sieht sie den Knaben nahn mit Horn und Hunde.", "tokens": ["Sieht", "sie", "den", "Kna\u00b7ben", "nahn", "mit", "Horn", "und", "Hun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJA", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die Gute warnt ihn, mehr als wohlgesinnt:", "tokens": ["Die", "Gu\u00b7te", "warnt", "ihn", ",", "mehr", "als", "wohl\u00b7ge\u00b7sinnt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "PIAT", "KOKOM", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "\u00bbo weiche nicht von diesem sichern Grunde.", "tokens": ["\u00bb", "o", "wei\u00b7che", "nicht", "von", "die\u00b7sem", "si\u00b7chern", "Grun\u00b7de", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "ADJA", "PTKNEG", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Wohl eher sah ich schon so holden Kleinen", "tokens": ["Wohl", "e\u00b7her", "sah", "ich", "schon", "so", "hol\u00b7den", "Klei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Von einem Eber schwer verletzt im Tal,", "tokens": ["Von", "ei\u00b7nem", "E\u00b7ber", "schwer", "ver\u00b7letzt", "im", "Tal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJD", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Tief in der H\u00fcft', ein Anblick war's zum Weinen;", "tokens": ["Tief", "in", "der", "H\u00fcft'", ",", "ein", "An\u00b7blick", "wa\u00b7r's", "zum", "Wei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$,", "ART", "NN", "VAFIN", "APPRART", "NN", "$."], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.12": {"text": "Sieh meine H\u00fcfte, sieh, hier war das Mal.\u00ab", "tokens": ["Sieh", "mei\u00b7ne", "H\u00fcf\u00b7te", ",", "sieh", ",", "hier", "war", "das", "Mal", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "VVFIN", "$,", "ADV", "VAFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Sie zeigt es ihm, und er wird rot und flieht,", "tokens": ["Sie", "zeigt", "es", "ihm", ",", "und", "er", "wird", "rot", "und", "flieht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPER", "$,", "KON", "PPER", "VAFIN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Weil er mehr Wunden dort als eine sieht.", "tokens": ["Weil", "er", "mehr", "Wun\u00b7den", "dort", "als", "ei\u00b7ne", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "ADV", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Lieb R\u00f6slein, vor der Zeit gepfl\u00fcckt, zu bald erblichen,", "tokens": ["Lieb", "R\u00f6s\u00b7lein", ",", "vor", "der", "Zeit", "ge\u00b7pfl\u00fcckt", ",", "zu", "bald", "er\u00b7bli\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "APPR", "ART", "NN", "VVPP", "$,", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gepfl\u00fcckt als zarte Knosp', im Lenz erblichen; ach,", "tokens": ["Ge\u00b7pfl\u00fcckt", "als", "zar\u00b7te", "Knosp'", ",", "im", "Lenz", "er\u00b7bli\u00b7chen", ";", "ach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVPP", "KOKOM", "ADJA", "NN", "$,", "APPRART", "NN", "VVINF", "$.", "XY", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des Ostens Perle du, vom Moder fr\u00fch beschlichen,", "tokens": ["Des", "Os\u00b7tens", "Per\u00b7le", "du", ",", "vom", "Mo\u00b7der", "fr\u00fch", "be\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "$,", "APPRART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "O Kleinod, das so schnell des Todes Stachel stach,", "tokens": ["O", "Klei\u00b7nod", ",", "das", "so", "schnell", "des", "To\u00b7des", "Sta\u00b7chel", "stach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "ADV", "ADJD", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie gr\u00fcne Pflaumen, die in Windes Wallen", "tokens": ["Wie", "gr\u00fc\u00b7ne", "Pflau\u00b7men", ",", "die", "in", "Win\u00b7des", "Wal\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "NN", "$,", "PRELS", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Eh' sie der Herbst gereift, vom Baume fallen.", "tokens": ["Eh'", "sie", "der", "Herbst", "ge\u00b7reift", ",", "vom", "Bau\u00b7me", "fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Ich wein' um dich, der doch nicht Anla\u00df hat:", "tokens": ["Ich", "wein'", "um", "dich", ",", "der", "doch", "nicht", "An\u00b7la\u00df", "hat", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "PRELS", "ADV", "PTKNEG", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Warum? Im Testament hast du mich \u00fcbergangen;", "tokens": ["Wa\u00b7rum", "?", "Im", "Tes\u00b7ta\u00b7ment", "hast", "du", "mich", "\u00fc\u00b7ber\u00b7gan\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "APPRART", "NN", "VAFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und mir doch mehr vermacht, als je ich von dir bat:", "tokens": ["Und", "mir", "doch", "mehr", "ver\u00b7macht", ",", "als", "je", "ich", "von", "dir", "bat", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADV", "VVPP", "$,", "KOUS", "ADV", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Warum? Nie hab' ich dich um etwas angegangen.", "tokens": ["Wa\u00b7rum", "?", "Nie", "hab'", "ich", "dich", "um", "et\u00b7was", "an\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "ADV", "VAFIN", "PPER", "PRF", "APPR", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und doch, verzeih mein Herz! ich mu\u00df mich fassen:", "tokens": ["Und", "doch", ",", "ver\u00b7zeih", "mein", "Herz", "!", "ich", "mu\u00df", "mich", "fas\u00b7sen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "VVIMP", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Dein Mi\u00dfvergn\u00fcgen hast du mir verlassen.", "tokens": ["Dein", "Mi\u00df\u00b7ver\u00b7gn\u00fc\u00b7gen", "hast", "du", "mir", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Saures Alter, frohe Jugend", "tokens": ["Sau\u00b7res", "Al\u00b7ter", ",", "fro\u00b7he", "Ju\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nnen nicht zusammen dauern:", "tokens": ["K\u00f6n\u00b7nen", "nicht", "zu\u00b7sam\u00b7men", "dau\u00b7ern", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jugend ist voll muntrer Launen,", "tokens": ["Ju\u00b7gend", "ist", "voll", "mun\u00b7trer", "Lau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alter voller Sorg' und Qual.", "tokens": ["Al\u00b7ter", "vol\u00b7ler", "Sor\u00b7g'", "und", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Jugend wie ein Sommermorgen,", "tokens": ["Ju\u00b7gend", "wie", "ein", "Som\u00b7mer\u00b7mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Alter gleicht den Winterschauern.", "tokens": ["Al\u00b7ter", "gleicht", "den", "Win\u00b7ter\u00b7schau\u00b7ern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Jugend pranget wie der Sommer,", "tokens": ["Ju\u00b7gend", "pran\u00b7get", "wie", "der", "Som\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Alter winterd\u00fcrr und kahl.", "tokens": ["Al\u00b7ter", "win\u00b7ter\u00b7d\u00fcrr", "und", "kahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Wenn der Jugend Scherze frommen,", "tokens": ["Wenn", "der", "Ju\u00b7gend", "Scher\u00b7ze", "from\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Alters Odem bleibt beklommen.", "tokens": ["Al\u00b7ters", "O\u00b7dem", "bleibt", "be\u00b7klom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Jugend eilet, Alter schleicht.", "tokens": ["Ju\u00b7gend", "ei\u00b7let", ",", "Al\u00b7ter", "schleicht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Jugend feurig, k\u00fchn, verwegen,", "tokens": ["Ju\u00b7gend", "feu\u00b7rig", ",", "k\u00fchn", ",", "ver\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "ADJD", "$,", "ADJD", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Alter lahm, will nur sich pflegen;", "tokens": ["Al\u00b7ter", "lahm", ",", "will", "nur", "sich", "pfle\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "VMFIN", "ADV", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Jugend sch\u00e4umet, Alter keucht.", "tokens": ["Ju\u00b7gend", "sch\u00e4u\u00b7met", ",", "Al\u00b7ter", "keucht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Jugend, Jugend, dich umfang' ich:", "tokens": ["Ju\u00b7gend", ",", "Ju\u00b7gend", ",", "dich", "um\u00b7fang'", "ich", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Alter, Alter, vor dir bang' ich.", "tokens": ["Al\u00b7ter", ",", "Al\u00b7ter", ",", "vor", "dir", "bang'", "ich", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "APPR", "PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "O mein Lieb, mein Lieb ist jung.", "tokens": ["O", "mein", "Lieb", ",", "mein", "Lieb", "ist", "jung", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "Alter schlag' ich in die Winde:", "tokens": ["Al\u00b7ter", "schlag'", "ich", "in", "die", "Win\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "S\u00fc\u00dfer Sch\u00e4fer, komm geschwinde!", "tokens": ["S\u00fc\u00b7\u00dfer", "Sch\u00e4\u00b7fer", ",", "komm", "ge\u00b7schwin\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "VVFIN", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Eilest lang mir nicht genung.", "tokens": ["Ei\u00b7lest", "lang", "mir", "nicht", "ge\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Sch\u00f6nheit, o eitles Gl\u00fcck, wie bald verloren!", "tokens": ["Sch\u00f6n\u00b7heit", ",", "o", "eit\u00b7les", "Gl\u00fcck", ",", "wie", "bald", "ver\u00b7lo\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "FM", "ADJA", "NN", "$,", "PWAV", "ADV", "VVPP", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Du bist ein bunter Schmelz, der schnell verfliegt,", "tokens": ["Du", "bist", "ein", "bun\u00b7ter", "Schmelz", ",", "der", "schnell", "ver\u00b7fliegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Bl\u00fcmlein fr\u00fch dahin, so wie geboren,", "tokens": ["Ein", "Bl\u00fcm\u00b7lein", "fr\u00fch", "da\u00b7hin", ",", "so", "wie", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PAV", "$,", "ADV", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein m\u00fcrbes Glas, das in der Hand zerbricht.", "tokens": ["Ein", "m\u00fcr\u00b7bes", "Glas", ",", "das", "in", "der", "Hand", "zer\u00b7bricht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Schmelze, Blume, Glas, hinf\u00e4llig eitles Gl\u00fcck,", "tokens": ["Schmel\u00b7ze", ",", "Blu\u00b7me", ",", "Glas", ",", "hin\u00b7f\u00e4l\u00b7lig", "eit\u00b7les", "Gl\u00fcck", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Verwelkt, verschwunden, tot im Augenblick.", "tokens": ["Ver\u00b7welkt", ",", "ver\u00b7schwun\u00b7den", ",", "tot", "im", "Au\u00b7gen\u00b7blick", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "$,", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Und wie verlornes Gl\u00fcck sich selten findet,", "tokens": ["Und", "wie", "ver\u00b7lor\u00b7nes", "Gl\u00fcck", "sich", "sel\u00b7ten", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJA", "NN", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verflognen Schmelz kein Reiben wiederbringt,", "tokens": ["Ver\u00b7flog\u00b7nen", "Schmelz", "kein", "Rei\u00b7ben", "wie\u00b7der\u00b7bringt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verwelkte Blume tot zur Erde schwindet,", "tokens": ["Ver\u00b7welk\u00b7te", "Blu\u00b7me", "tot", "zur", "Er\u00b7de", "schwin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zerbrochnes Glas kein Kitt zusammenzwingt:", "tokens": ["Zer\u00b7broch\u00b7nes", "Glas", "kein", "Kitt", "zu\u00b7sam\u00b7men\u00b7zwingt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So kann befleckte Sch\u00f6nheit nichts erneuen,", "tokens": ["So", "kann", "be\u00b7fleck\u00b7te", "Sch\u00f6n\u00b7heit", "nichts", "er\u00b7neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADJA", "NN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nicht M\u00fchen, Sorgen, Schminken, Arzeneien.", "tokens": ["Nicht", "M\u00fc\u00b7hen", ",", "Sor\u00b7gen", ",", "Schmin\u00b7ken", ",", "Ar\u00b7ze\u00b7nei\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PTKNEG", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "\u00bbgut' Nacht! Ruh' sanft!\u00ab \u2013 Ach, beides mir verleidet!", "tokens": ["\u00bb", "gut'", "Nacht", "!", "Ruh'", "sanft", "!", "\u00ab", "\u2013", "Ach", ",", "bei\u00b7des", "mir", "ver\u00b7lei\u00b7det", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$.", "NN", "ADJD", "$.", "$(", "$(", "ITJ", "$,", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie beut mir gute Nacht, die meine Ruh verscheucht", "tokens": ["Sie", "beut", "mir", "gu\u00b7te", "Nacht", ",", "die", "mei\u00b7ne", "Ruh", "ver\u00b7scheucht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und in mein Bett mich treibt mit Qualen \u00fcberbreitet,", "tokens": ["Und", "in", "mein", "Bett", "mich", "treibt", "mit", "Qua\u00b7len", "\u00fc\u00b7berb\u00b7rei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "PPER", "VVFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo meines Ungl\u00fccks Zweifel mich beschleicht.", "tokens": ["Wo", "mei\u00b7nes", "Un\u00b7gl\u00fccks", "Zwei\u00b7fel", "mich", "be\u00b7schleicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbleb' wohl\u00ab, sprach sie, \u00bbgut' Nacht! Wir sehn uns morgen.\u00ab \u2013", "tokens": ["\u00bb", "leb'", "wohl", "\u00ab", ",", "sprach", "sie", ",", "\u00bb", "gut'", "Nacht", "!", "Wir", "sehn", "uns", "mor\u00b7gen", ".", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "VVIMP", "ADV", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "ADJA", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "$.", "$(", "$("], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Wohlleben konnt' ich nicht; ich a\u00df zu Nacht mit Sorgen.", "tokens": ["Wohl\u00b7le\u00b7ben", "konnt'", "ich", "nicht", ";", "ich", "a\u00df", "zu", "Nacht", "mit", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PTKNEG", "$.", "PPER", "VVFIN", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Doch als wir schieden, l\u00e4chelt' sie so s\u00fc\u00df:", "tokens": ["Doch", "als", "wir", "schie\u00b7den", ",", "l\u00e4\u00b7chelt'", "sie", "so", "s\u00fc\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "War's Freundschaft oder Hohn? Ich mag's nicht deuten:", "tokens": ["Wa\u00b7r's", "Freund\u00b7schaft", "o\u00b7der", "Hohn", "?", "Ich", "mag's", "nicht", "deu\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "$.", "PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Vielleicht vor Freuden, da\u00df sie mich verstie\u00df?", "tokens": ["Viel\u00b7leicht", "vor", "Freu\u00b7den", ",", "da\u00df", "sie", "mich", "ver\u00b7stie\u00df", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Vielleicht mich Irren wieder hin zu leiten?", "tokens": ["Viel\u00b7leicht", "mich", "Ir\u00b7ren", "wie\u00b7der", "hin", "zu", "lei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "NN", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Irr! Auf uns luft'ge Schemen pa\u00dft das Wort;", "tokens": ["Irr", "!", "Auf", "uns", "luft'\u00b7ge", "Sche\u00b7men", "pa\u00dft", "das", "Wort", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "APPR", "PPER", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wir m\u00fch'n uns viel, und heben nie den Hort.", "tokens": ["Wir", "m\u00fch'n", "uns", "viel", ",", "und", "he\u00b7ben", "nie", "den", "Hort", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "$,", "KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Wie starrt' ich unverwandt nach Osten hin!", "tokens": ["Wie", "starrt'", "ich", "un\u00b7ver\u00b7wandt", "nach", "Os\u00b7ten", "hin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADJD", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mein Herz z\u00fcrnt mit der Uhr; das fr\u00fche Licht", "tokens": ["Mein", "Herz", "z\u00fcrnt", "mit", "der", "Uhr", ";", "das", "fr\u00fc\u00b7he", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erweckt aus tr\u00e4gem Schlummer jeden Sinn:", "tokens": ["Er\u00b7weckt", "aus", "tr\u00e4\u00b7gem", "Schlum\u00b7mer", "je\u00b7den", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der eignen Augen Zeugnis glaub' ich nicht;", "tokens": ["Der", "eig\u00b7nen", "Au\u00b7gen", "Zeug\u00b7nis", "glaub'", "ich", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich sitze lauschend, horch' auf Philomelen,", "tokens": ["Ich", "sit\u00b7ze", "lau\u00b7schend", ",", "horch'", "auf", "Phi\u00b7lo\u00b7me\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und wollt', es w\u00e4r ein Lied aus Lerchenkehlen:", "tokens": ["Und", "wollt'", ",", "es", "w\u00e4r", "ein", "Lied", "aus", "Ler\u00b7chen\u00b7keh\u00b7len", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "PPER", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Und zwingt die lichtlos bange Nacht zur Flucht;", "tokens": ["Und", "zwingt", "die", "licht\u00b7los", "ban\u00b7ge", "Nacht", "zur", "Flucht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJD", "ADV", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und, flieht die Nacht, eil' ich zu meiner Trauten;", "tokens": ["Und", ",", "flieht", "die", "Nacht", ",", "eil'", "ich", "zu", "mei\u00b7ner", "Trau\u00b7ten", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "ART", "NN", "$,", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dort findet Herz und Auge, was es sucht.", "tokens": ["Dort", "fin\u00b7det", "Herz", "und", "Au\u00b7ge", ",", "was", "es", "sucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sorg' ist in Lust verwandelt, Lust hegt Sorgen,", "tokens": ["Sor\u00b7g'", "ist", "in", "Lust", "ver\u00b7wan\u00b7delt", ",", "Lust", "hegt", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "NN", "VVPP", "$,", "NN", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Denn seufzend sagte sie zu mir: \u00bbKomm morgen!\u00ab", "tokens": ["Denn", "seuf\u00b7zend", "sag\u00b7te", "sie", "zu", "mir", ":", "\u00bb", "Komm", "mor\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPR", "PPER", "$.", "$(", "VVFIN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "W\u00e4r' ich mit ihr, zu schnell w\u00e4r' Nacht entflohn;", "tokens": ["W\u00e4r'", "ich", "mit", "ihr", ",", "zu", "schnell", "w\u00e4r'", "Nacht", "ent\u00b7flohn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "$,", "PTKA", "ADJD", "VAFIN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nun aber reih'n Minuten sich an Stunden:", "tokens": ["Nun", "a\u00b7ber", "reih'n", "Mi\u00b7nu\u00b7ten", "sich", "an", "Stun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "NN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Minuten werden Monden mir zum Hohn.", "tokens": ["Mi\u00b7nu\u00b7ten", "wer\u00b7den", "Mon\u00b7den", "mir", "zum", "Hohn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Nicht mir, o Tag! den Blumen scheine drunten.", "tokens": ["Nicht", "mir", ",", "o", "Tag", "!", "den", "Blu\u00b7men", "schei\u00b7ne", "drun\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPER", "$,", "FM", "NN", "$.", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Flieh, Nacht! Komm, lieber Tag! La\u00df Nacht uns borgen;", "tokens": ["Flieh", ",", "Nacht", "!", "Komm", ",", "lie\u00b7ber", "Tag", "!", "La\u00df", "Nacht", "uns", "bor\u00b7gen", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "VVFIN", "$,", "ADV", "NN", "$.", "VVIMP", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und, Nacht, sei kurz, erhole dich am Morgen.", "tokens": ["Und", ",", "Nacht", ",", "sei", "kurz", ",", "er\u00b7ho\u00b7le", "dich", "am", "Mor\u00b7gen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "$,", "VAFIN", "ADJD", "$,", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Liebe (ach wer steht ihr bei!", "tokens": ["Lie\u00b7be", "(", "ach", "wer", "steht", "ihr", "bei", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ITJ", "PWS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Immer frisch und jung im Mai)", "tokens": ["Im\u00b7mer", "frisch", "und", "jung", "im", "Mai", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "APPRART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sah umbuhlt von Zephyrs Wehen", "tokens": ["Sah", "um\u00b7buhlt", "von", "Ze\u00b7phyrs", "We\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wundersch\u00f6nes Bl\u00fcmlein stehen.", "tokens": ["Wun\u00b7der\u00b7sch\u00f6\u00b7nes", "Bl\u00fcm\u00b7lein", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Durch die samtnen Bl\u00e4tter schien", "tokens": ["Durch", "die", "samt\u00b7nen", "Bl\u00e4t\u00b7ter", "schien"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Unsichtbar der Wind zu ziehn,", "tokens": ["Un\u00b7sicht\u00b7bar", "der", "Wind", "zu", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df sich totkrank der Verliebte", "tokens": ["Da\u00df", "sich", "tot\u00b7krank", "der", "Ver\u00b7lieb\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ADJD", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Nicht wie Luft zu sein betr\u00fcbte,", "tokens": ["Nicht", "wie", "Luft", "zu", "sein", "be\u00b7tr\u00fcb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOKOM", "NN", "PTKZU", "VAINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "\u00bbluft\u00ab, sprach er, \u00bbwie darfst du schl\u00fcrfen!", "tokens": ["\u00bb", "luft", "\u00ab", ",", "sprach", "er", ",", "\u00bb", "wie", "darfst", "du", "schl\u00fcr\u00b7fen", "!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "PWAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "M\u00f6cht' ich, Luft, so jubeln d\u00fcrfen!", "tokens": ["M\u00f6cht'", "ich", ",", "Luft", ",", "so", "ju\u00b7beln", "d\u00fcr\u00b7fen", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "NN", "$,", "ADV", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Aber ach, dich nie zu brechen", "tokens": ["A\u00b7ber", "ach", ",", "dich", "nie", "zu", "bre\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "XY", "$,", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Gab die Hand dir das Versprechen!", "tokens": ["Gab", "die", "Hand", "dir", "das", "Ver\u00b7spre\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Jugendschwur, wie ich dich b\u00fc\u00dfe!", "tokens": ["Ju\u00b7gend\u00b7schwur", ",", "wie", "ich", "dich", "b\u00fc\u00b7\u00dfe", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Jugend pfl\u00fcckt so gern das S\u00fc\u00dfe.", "tokens": ["Ju\u00b7gend", "pfl\u00fcckt", "so", "gern", "das", "S\u00fc\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Nenn' es S\u00fcnde nicht in mir,", "tokens": ["Nenn'", "es", "S\u00fcn\u00b7de", "nicht", "in", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "PTKNEG", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Brech' ich mein Gel\u00fcbde dir.", "tokens": ["Brech'", "ich", "mein", "Ge\u00b7l\u00fcb\u00b7de", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Schw\u00fcr' doch Zeus, in dich verloren,", "tokens": ["Schw\u00fcr'", "doch", "Zeus", ",", "in", "dich", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "NE", "$,", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Seine Juno glich den Mohren;", "tokens": ["Sei\u00b7ne", "Ju\u00b7no", "glich", "den", "Moh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "M\u00f6chte Zeus nicht l\u00e4nger, nein,", "tokens": ["M\u00f6ch\u00b7te", "Zeus", "nicht", "l\u00e4n\u00b7ger", ",", "nein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "NE", "PTKNEG", "ADJD", "$,", "PTKANT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "Dir zuliebe sterblich sein.\u00ab", "tokens": ["Dir", "zu\u00b7lie\u00b7be", "sterb\u00b7lich", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "VAINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Wenn du die Sch\u00f6ne willst erreichen,", "tokens": ["Wenn", "du", "die", "Sch\u00f6\u00b7ne", "willst", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Wild, das schu\u00dfrecht vor dir sitzt,", "tokens": ["Das", "Wild", ",", "das", "schu\u00df\u00b7recht", "vor", "dir", "sitzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VVFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann sch\u00fctze dich Vernunft vor Streichen,", "tokens": ["Dann", "sch\u00fct\u00b7ze", "dich", "Ver\u00b7nunft", "vor", "Strei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So gut sie blinde Liebe sch\u00fctzt.", "tokens": ["So", "gut", "sie", "blin\u00b7de", "Lie\u00b7be", "sch\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein kluger Rat, er w\u00e4r' dir n\u00f6tig;", "tokens": ["Ein", "klu\u00b7ger", "Rat", ",", "er", "w\u00e4r'", "dir", "n\u00f6\u00b7tig", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Doch sei er nicht zu jung, noch ledig.", "tokens": ["Doch", "sei", "er", "nicht", "zu", "jung", ",", "noch", "le\u00b7dig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "PTKA", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Und bringst du nun dein Spr\u00fcchlein an,", "tokens": ["Und", "bringst", "du", "nun", "dein", "Spr\u00fcch\u00b7lein", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df glatter Zungen Wortgeflinker:", "tokens": ["La\u00df", "glat\u00b7ter", "Zun\u00b7gen", "Wort\u00b7ge\u00b7flin\u00b7ker", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sonst merkt sie Trug, du hast vertan;", "tokens": ["Sonst", "merkt", "sie", "Trug", ",", "du", "hast", "ver\u00b7tan", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Lahme wittert leicht den Hinker.", "tokens": ["Der", "Lah\u00b7me", "wit\u00b7tert", "leicht", "den", "Hin\u00b7ker", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sprich nur: Dich lieb' ich, treu und schlicht,", "tokens": ["Sprich", "nur", ":", "Dich", "lieb'", "ich", ",", "treu", "und", "schlicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "PPER", "VVFIN", "PPER", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und setz' ihr Sch\u00f6nes hell ins Licht.", "tokens": ["Und", "setz'", "ihr", "Sch\u00f6\u00b7nes", "hell", "ins", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Und schmollt sie gleich und senkt den Blick,", "tokens": ["Und", "schmollt", "sie", "gleich", "und", "senkt", "den", "Blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor Abend noch gibt sich dies Toben:", "tokens": ["Vor", "A\u00b7bend", "noch", "gibt", "sich", "dies", "To\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVFIN", "PRF", "PDS", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Dann w\u00fcnscht sie dich zu sp\u00e4t zur\u00fcck,", "tokens": ["Dann", "w\u00fcnscht", "sie", "dich", "zu", "sp\u00e4t", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKA", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bereut, da\u00df sie ihr Gl\u00fcck verschoben;", "tokens": ["Be\u00b7reut", ",", "da\u00df", "sie", "ihr", "Gl\u00fcck", "ver\u00b7scho\u00b7ben", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zweimal verlangt sie, eh' es tagt,", "tokens": ["Zwei\u00b7mal", "ver\u00b7langt", "sie", ",", "eh'", "es", "tagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach dem, was sie mit Hohn versagt.", "tokens": ["Nach", "dem", ",", "was", "sie", "mit", "Hohn", "ver\u00b7sagt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "La\u00df sie nur ringen, keifen, zanken,", "tokens": ["La\u00df", "sie", "nur", "rin\u00b7gen", ",", "kei\u00b7fen", ",", "zan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich mit dir messen, schelten, schm\u00e4hn;", "tokens": ["Sich", "mit", "dir", "mes\u00b7sen", ",", "schel\u00b7ten", ",", "schm\u00e4hn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PRF", "APPR", "PPER", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die schwache Kraft wird endlich wanken,", "tokens": ["Die", "schwa\u00b7che", "Kraft", "wird", "end\u00b7lich", "wan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie wird gewitzigt eingestehn:", "tokens": ["Sie", "wird", "ge\u00b7wit\u00b7zigt", "ein\u00b7ge\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "W\u00e4r' Weib so stark als Mann geboren,", "tokens": ["W\u00e4r'", "Weib", "so", "stark", "als", "Mann", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "ADJD", "KOKOM", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Du h\u00e4ttest, meiner Treu, verloren!", "tokens": ["Du", "h\u00e4t\u00b7test", ",", "mei\u00b7ner", "Treu", ",", "ver\u00b7lo\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPOSAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Und ihren W\u00fcnschen allerweise", "tokens": ["Und", "ih\u00b7ren", "W\u00fcn\u00b7schen", "al\u00b7ler\u00b7wei\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit vollen H\u00e4nden komm zuvor:", "tokens": ["Mit", "vol\u00b7len", "H\u00e4n\u00b7den", "komm", "zu\u00b7vor", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df dein Verdienst sich hell erweise,", "tokens": ["Da\u00df", "dein", "Ver\u00b7dienst", "sich", "hell", "er\u00b7wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "La\u00df aufgehn, klingl' ihr um das Ohr.", "tokens": ["La\u00df", "auf\u00b7gehn", ",", "klingl'", "ihr", "um", "das", "Ohr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVIZU", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die st\u00e4rkste Festung, Turm und Mau'r", "tokens": ["Die", "st\u00e4rks\u00b7te", "Fes\u00b7tung", ",", "Turm", "und", "Mau'r"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ergibt sich goldnem Regenschau'r.", "tokens": ["Er\u00b7gibt", "sich", "gold\u00b7nem", "Re\u00b7gen\u00b7schau'", "r."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["VVFIN", "PRF", "ADJA", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Sei immerdar ihr treuer Knecht,", "tokens": ["Sei", "im\u00b7mer\u00b7dar", "ihr", "treu\u00b7er", "Knecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Werben ehrlich und bescheiden:", "tokens": ["Dein", "Wer\u00b7ben", "ehr\u00b7lich", "und", "be\u00b7schei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So lang sie dir nicht ungerecht,", "tokens": ["So", "lang", "sie", "dir", "nicht", "un\u00b7ge\u00b7recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "La\u00df dich zum Wechsel nicht verleiten.", "tokens": ["La\u00df", "dich", "zum", "Wech\u00b7sel", "nicht", "ver\u00b7lei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPRART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Verdrie\u00dfe dich kein gutes Wort,", "tokens": ["Ver\u00b7drie\u00b7\u00dfe", "dich", "kein", "gu\u00b7tes", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und stie\u00dfe sie dich zehnmal fort.", "tokens": ["Und", "stie\u00b7\u00dfe", "sie", "dich", "zehn\u00b7mal", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Wie Frauenlist sich r\u00e4nkevoll", "tokens": ["Wie", "Frau\u00b7en\u00b7list", "sich", "r\u00e4n\u00b7ke\u00b7voll"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "PRF", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit falschem Au\u00dfenschein umzieht,", "tokens": ["Mit", "fal\u00b7schem", "Au\u00b7\u00dfen\u00b7schein", "um\u00b7zieht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "All' ihre Schlich' und Launen soll", "tokens": ["All'", "ih\u00b7re", "Schlich'", "und", "Lau\u00b7nen", "soll"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "PPOSAT", "NN", "KON", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Hahn nicht wissen, der sie tritt.", "tokens": ["Der", "Hahn", "nicht", "wis\u00b7sen", ",", "der", "sie", "tritt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hat man dir nicht schon oft bericht':", "tokens": ["Hat", "man", "dir", "nicht", "schon", "oft", "be\u00b7richt'", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PPER", "PTKNEG", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Weiber-Nein hat leicht Gewicht?", "tokens": ["Ein", "Wei\u00b7ber\u00b7\u00b7N\u00b7ein", "hat", "leicht", "Ge\u00b7wicht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.29": {"line.1": {"text": "Bedenk, mit M\u00e4nnern ficht kein Weib", "tokens": ["Be\u00b7denk", ",", "mit", "M\u00e4n\u00b7nern", "ficht", "kein", "Weib"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "NN", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Um M\u00e4rtyrtum, es ficht um S\u00fcnden.", "tokens": ["Um", "M\u00e4r\u00b7tyr\u00b7tum", ",", "es", "ficht", "um", "S\u00fcn\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn Zeit und Alter sie best\u00e4ubt,", "tokens": ["Wenn", "Zeit", "und", "Al\u00b7ter", "sie", "be\u00b7st\u00e4ubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beim Kreuz! dann liegt ihr Himmel hinten.", "tokens": ["Beim", "Kreuz", "!", "dann", "liegt", "ihr", "Him\u00b7mel", "hin\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "ADV", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "G\u00e4b's nichts als K\u00fcss' im Bett, f\u00fcrwahr,", "tokens": ["G\u00e4b's", "nichts", "als", "K\u00fcss'", "im", "Bett", ",", "f\u00fcr\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PIS", "KOKOM", "NN", "APPRART", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Weib ging mit Weib zum Traualtar.", "tokens": ["Weib", "ging", "mit", "Weib", "zum", "Trau\u00b7al\u00b7tar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "APPRART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.30": {"line.1": {"text": "Doch still! genug, und schon zuviel,", "tokens": ["Doch", "still", "!", "ge\u00b7nug", ",", "und", "schon", "zu\u00b7viel", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "ADV", "$,", "KON", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df mich mein M\u00e4dchen nicht vernimmt,", "tokens": ["Da\u00df", "mich", "mein", "M\u00e4d\u00b7chen", "nicht", "ver\u00b7nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In's Ohr mir raunt: \u00bbNun schweige still!\u00ab", "tokens": ["In's", "Ohr", "mir", "raunt", ":", "\u00bb", "Nun", "schwei\u00b7ge", "still", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und meine Zunge zahmer stimmt. \u2013", "tokens": ["Und", "mei\u00b7ne", "Zun\u00b7ge", "zah\u00b7mer", "stimmt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch wird sie rot, (traut meinem Lied),", "tokens": ["Doch", "wird", "sie", "rot", ",", "(", "traut", "mei\u00b7nem", "Lied", ")", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "$(", "VVFIN", "PPOSAT", "NN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn sie sich so verraten sieht.", "tokens": ["Wenn", "sie", "sich", "so", "ver\u00b7ra\u00b7ten", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Wenn Liebchen spricht, da\u00df nie ihr Herz erkalte,", "tokens": ["Wenn", "Lieb\u00b7chen", "spricht", ",", "da\u00df", "nie", "ihr", "Herz", "er\u00b7kal\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "$,", "KOUS", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So glaub' ich ihr, wenn sie es schon erfand;", "tokens": ["So", "glaub'", "ich", "ihr", ",", "wenn", "sie", "es", "schon", "er\u00b7fand", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "KOUS", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Damit sie mich f\u00fcr einen Neuling halte,", "tokens": ["Da\u00b7mit", "sie", "mich", "f\u00fcr", "ei\u00b7nen", "Neu\u00b7ling", "hal\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit Listen dieser Welt noch unbekannt.", "tokens": ["Mit", "Lis\u00b7ten", "die\u00b7ser", "Welt", "noch", "un\u00b7be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PDAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So, irrig w\u00e4hnend, da\u00df sie jung mich w\u00e4hne,", "tokens": ["So", ",", "ir\u00b7rig", "w\u00e4h\u00b7nend", ",", "da\u00df", "sie", "jung", "mich", "w\u00e4h\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJD", "VVPP", "$,", "KOUS", "PPER", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wiewohl sie wei\u00df, mein Fr\u00fchling ist dahin,", "tokens": ["Wie\u00b7wohl", "sie", "wei\u00df", ",", "mein", "Fr\u00fch\u00b7ling", "ist", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PPOSAT", "NN", "VAFIN", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Leugn' ich's ihr nicht in ihre falschen Z\u00e4hne,", "tokens": ["Leugn'", "ich's", "ihr", "nicht", "in", "ih\u00b7re", "fal\u00b7schen", "Z\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "PPER", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und beiderseits verbirgt sich wahrer Sinn.", "tokens": ["Und", "bei\u00b7der\u00b7seits", "ver\u00b7birgt", "sich", "wah\u00b7rer", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Doch warum sagt sie nicht, da\u00df sie nicht treu?", "tokens": ["Doch", "wa\u00b7rum", "sagt", "sie", "nicht", ",", "da\u00df", "sie", "nicht", "treu", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Warum nicht ich, da\u00df einst ich jung gewesen?", "tokens": ["Wa\u00b7rum", "nicht", "ich", ",", "da\u00df", "einst", "ich", "jung", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "PPER", "$,", "KOUS", "ADV", "PPER", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "O, Amors Lieblingslust ist Heuchelei,", "tokens": ["O", ",", "A\u00b7mors", "Lieb\u00b7lings\u00b7lust", "ist", "Heu\u00b7che\u00b7lei", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Und Lieb' in Jahren mag nicht Jahreszahlen lesen.", "tokens": ["Und", "Lieb'", "in", "Jah\u00b7ren", "mag", "nicht", "Jah\u00b7res\u00b7zah\u00b7len", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "VMFIN", "PTKNEG", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Darum bel\u00fcg' ich sie, bel\u00fcgt sie mich,", "tokens": ["Da\u00b7rum", "be\u00b7l\u00fcg'", "ich", "sie", ",", "be\u00b7l\u00fcgt", "sie", "mich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "$,", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Und unsre L\u00fcgens\u00fcnden schmeicheln sich.", "tokens": ["Und", "uns\u00b7re", "L\u00fc\u00b7gen\u00b7s\u00fcn\u00b7den", "schmei\u00b7cheln", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Zwei Flammen hab' ich, die im Doppelbann,", "tokens": ["Zwei", "Flam\u00b7men", "hab'", "ich", ",", "die", "im", "Dop\u00b7pel\u00b7bann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "$,", "PRELS", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie Geister, zwischen Trost und Qual mich lassen darben:", "tokens": ["Wie", "Geis\u00b7ter", ",", "zwi\u00b7schen", "Trost", "und", "Qual", "mich", "las\u00b7sen", "dar\u00b7ben", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "APPR", "NN", "KON", "NN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der bess're Engel ist ein sch\u00f6ner Mann,", "tokens": ["Der", "bess'\u00b7re", "En\u00b7gel", "ist", "ein", "sch\u00f6\u00b7ner", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der schlimmere Geist ein Weib von b\u00f6sen Farben.", "tokens": ["Der", "schlim\u00b7me\u00b7re", "Geist", "ein", "Weib", "von", "b\u00f6\u00b7sen", "Far\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Mein weiblich Unheil, bald dem Pfuhl mich zu gesellen,", "tokens": ["Mein", "weib\u00b7lich", "Un\u00b7heil", ",", "bald", "dem", "Pfuhl", "mich", "zu", "ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADV", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Lockt meinen guten Engel von mir fort:", "tokens": ["Lockt", "mei\u00b7nen", "gu\u00b7ten", "En\u00b7gel", "von", "mir", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Zum Teufel m\u00f6chte sie den Heiligen entstellen;", "tokens": ["Zum", "Teu\u00b7fel", "m\u00f6ch\u00b7te", "sie", "den", "Hei\u00b7li\u00b7gen", "ent\u00b7stel\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dem Reinen kost ihr falsches Schmeichelwort.", "tokens": ["Dem", "Rei\u00b7nen", "kost", "ihr", "fal\u00b7sches", "Schmei\u00b7chel\u00b7wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und, ob mein Engel nun schon eingefeindet,", "tokens": ["Und", ",", "ob", "mein", "En\u00b7gel", "nun", "schon", "ein\u00b7ge\u00b7fein\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Besorg' ich; \u2013 zwar nicht v\u00f6llig ist's bekannt; \u2013", "tokens": ["Be\u00b7sor\u00b7g'", "ich", ";", "\u2013", "zwar", "nicht", "v\u00f6l\u00b7lig", "ist's", "be\u00b7kannt", ";", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "ADV", "PTKNEG", "ADJD", "VAFIN", "ADJD", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.11": {"text": "Doch, da mich beide fliehn, und beide sich befreundet,", "tokens": ["Doch", ",", "da", "mich", "bei\u00b7de", "fliehn", ",", "und", "bei\u00b7de", "sich", "be\u00b7freun\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PIS", "VVINF", "$,", "KON", "PIS", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "F\u00fcrcht' ich, ein Engel ward des andern H\u00f6llenbrand.", "tokens": ["F\u00fcrcht'", "ich", ",", "ein", "En\u00b7gel", "ward", "des", "an\u00b7dern", "H\u00f6l\u00b7len\u00b7brand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und wie es steh', ich kann es nicht vermuten,", "tokens": ["Und", "wie", "es", "steh'", ",", "ich", "kann", "es", "nicht", "ver\u00b7mu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Als bis mein b\u00f6ser Geist verschlingt den guten.", "tokens": ["Als", "bis", "mein", "b\u00f6\u00b7ser", "Geist", "ver\u00b7schlingt", "den", "gu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "Hat deiner Augen Himmelsredemacht,", "tokens": ["Hat", "dei\u00b7ner", "Au\u00b7gen", "Him\u00b7mels\u00b7re\u00b7de\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die keine Welt bestreiten wird mit Gr\u00fcnden,", "tokens": ["Die", "kei\u00b7ne", "Welt", "be\u00b7strei\u00b7ten", "wird", "mit", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mein Herz zu diesem Meineid nicht gebracht?", "tokens": ["Mein", "Herz", "zu", "die\u00b7sem", "Mei\u00b7neid", "nicht", "ge\u00b7bracht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PDAT", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Um dich gebrochne Schw\u00fcre sind nicht S\u00fcnden.", "tokens": ["Um", "dich", "ge\u00b7broch\u00b7ne", "Schw\u00fc\u00b7re", "sind", "nicht", "S\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "VVFIN", "NN", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ein Weib verschwur ich; aber da\u00df ich nicht", "tokens": ["Ein", "Weib", "ver\u00b7schwur", "ich", ";", "a\u00b7ber", "da\u00df", "ich", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "ADV", "KOUS", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Dich ", "tokens": ["Dich"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Mein Eid war irdisch, du ein himmlisch Licht.", "tokens": ["Mein", "Eid", "war", "ir\u00b7disch", ",", "du", "ein", "himm\u00b7lisch", "Licht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPER", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Von aller Schuld befreit mich dein Erh\u00f6ren.", "tokens": ["Von", "al\u00b7ler", "Schuld", "be\u00b7freit", "mich", "dein", "Er\u00b7h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Mein Eid war Hauch; Hauch ist ein Dunst: so saugest", "tokens": ["Mein", "Eid", "war", "Hauch", ";", "Hauch", "ist", "ein", "Dunst", ":", "so", "sau\u00b7gest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$.", "NN", "VAFIN", "ART", "NN", "$.", "ADV", "VVFIN"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Du sch\u00f6ne Sonne meiner Erdenbahn", "tokens": ["Du", "sch\u00f6\u00b7ne", "Son\u00b7ne", "mei\u00b7ner", "Er\u00b7den\u00b7bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Dies dunstige Gel\u00fcbd' in dich, verhauchest,", "tokens": ["Dies", "duns\u00b7ti\u00b7ge", "Ge\u00b7l\u00fcbd'", "in", "dich", ",", "ver\u00b7hau\u00b7chest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "APPR", "PPER", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Zerrei\u00dfest es; ich hab' nicht Teil daran.", "tokens": ["Zer\u00b7rei\u00b7\u00dfest", "es", ";", "ich", "hab'", "nicht", "Teil", "da\u00b7ran", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VAFIN", "PTKNEG", "NN", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und h\u00e4tt ich's auch gebrochen, welcher Tor", "tokens": ["Und", "h\u00e4tt", "ich's", "auch", "ge\u00b7bro\u00b7chen", ",", "wel\u00b7cher", "Tor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "PIS", "ADV", "VVPP", "$,", "PWAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Z\u00f6g einen Schwur dem Paradiese vor?", "tokens": ["Z\u00f6g", "ei\u00b7nen", "Schwur", "dem", "Pa\u00b7ra\u00b7die\u00b7se", "vor", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "An einem Bache sa\u00df die reizende Cythere,", "tokens": ["An", "ei\u00b7nem", "Ba\u00b7che", "sa\u00df", "die", "rei\u00b7zen\u00b7de", "Cy\u00b7the\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Von ihrem jungen Freund Adonis hoch entz\u00fcckt.", "tokens": ["Von", "ih\u00b7rem", "jun\u00b7gen", "Freund", "A\u00b7do\u00b7nis", "hoch", "ent\u00b7z\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NE", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit manchem s\u00fc\u00dfen Blick lieb\u00e4ugelt ihm die Hehre,", "tokens": ["Mit", "man\u00b7chem", "s\u00fc\u00b7\u00dfen", "Blick", "lie\u00b7b\u00e4u\u00b7gelt", "ihm", "die", "Heh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit Blicken wie nur sie, der Sch\u00f6nheit F\u00fcrstin, blickt.", "tokens": ["Mit", "Bli\u00b7cken", "wie", "nur", "sie", ",", "der", "Sch\u00f6n\u00b7heit", "F\u00fcrs\u00b7tin", ",", "blickt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "KOKOM", "ADV", "PPER", "$,", "ART", "NN", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dem Ohr zur Lust erz\u00e4hlt sie M\u00e4rlein ihm,", "tokens": ["Dem", "Ohr", "zur", "Lust", "er\u00b7z\u00e4hlt", "sie", "M\u00e4r\u00b7lein", "ihm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "PPER", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Zeigt Liebliches, die Augen zu versuchen;", "tokens": ["Zeigt", "Lieb\u00b7li\u00b7ches", ",", "die", "Au\u00b7gen", "zu", "ver\u00b7su\u00b7chen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ber\u00fchrt ihn hie und da, sein Herz an sich zu ziehn:", "tokens": ["Be\u00b7r\u00fchrt", "ihn", "hie", "und", "da", ",", "sein", "Herz", "an", "sich", "zu", "ziehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KON", "ADV", "$,", "PPOSAT", "NN", "APPR", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So schmeichelndes Getast wird oft das Grab der Tugend. \u2013", "tokens": ["So", "schmei\u00b7cheln\u00b7des", "Ge\u00b7tast", "wird", "oft", "das", "Grab", "der", "Tu\u00b7gend", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch, ob den fr\u00fchen Jahren Sinn gebricht,", "tokens": ["Doch", ",", "ob", "den", "fr\u00fc\u00b7hen", "Jah\u00b7ren", "Sinn", "ge\u00b7bricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "ADJA", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ob er verschm\u00e4het ihr verbl\u00fcmtes Deuten,", "tokens": ["Ob", "er", "ver\u00b7schm\u00e4\u00b7het", "ihr", "ver\u00b7bl\u00fcm\u00b7tes", "Deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Der junge Gr\u00fcndling schluckt den Hamen nicht,", "tokens": ["Der", "jun\u00b7ge", "Gr\u00fcnd\u00b7ling", "schluckt", "den", "Ha\u00b7men", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Und lacht und spottet aller Artigkeiten.", "tokens": ["Und", "lacht", "und", "spot\u00b7tet", "al\u00b7ler", "Ar\u00b7tig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Da fiel die gn\u00e4d'ge G\u00f6ttin r\u00fccklings hin:", "tokens": ["Da", "fiel", "die", "gn\u00e4d'\u00b7ge", "G\u00f6t\u00b7tin", "r\u00fcck\u00b7lings", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Und er sprang auf und lief. \u2013 O Eigensinn!", "tokens": ["Und", "er", "sprang", "auf", "und", "lief", ".", "\u2013", "O", "Ei\u00b7gen\u00b7sinn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "$.", "$(", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Lehrt Liebe Meineid mich, wie soll ich Liebe schw\u00f6ren?", "tokens": ["Lehrt", "Lie\u00b7be", "Mei\u00b7neid", "mich", ",", "wie", "soll", "ich", "Lie\u00b7be", "schw\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "NN", "PPER", "$,", "PWAV", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O Sch\u00f6nheit, sie allein h\u00e4lt Liebestreu im Flor!", "tokens": ["O", "Sch\u00f6n\u00b7heit", ",", "sie", "al\u00b7lein", "h\u00e4lt", "Lie\u00b7be\u00b7streu", "im", "Flor", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "ADV", "VVFIN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie auch mir selber falsch, treu will ich dir geh\u00f6ren.", "tokens": ["Wie", "auch", "mir", "sel\u00b7ber", "falsch", ",", "treu", "will", "ich", "dir", "ge\u00b7h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "ADV", "ADJD", "$,", "ADJD", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dies Wort, mir eichenfest, scheint dir ein schwankes Rohr.", "tokens": ["Dies", "Wort", ",", "mir", "ei\u00b7chen\u00b7fest", ",", "scheint", "dir", "ein", "schwan\u00b7kes", "Rohr", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$,", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Betrachtung l\u00e4\u00dft ihr Buch und forscht in deinen Augen,", "tokens": ["Be\u00b7trach\u00b7tung", "l\u00e4\u00dft", "ihr", "Buch", "und", "forscht", "in", "dei\u00b7nen", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo alle Wonne lebt, die nur die Kunst erschleu\u00dft.", "tokens": ["Wo", "al\u00b7le", "Won\u00b7ne", "lebt", ",", "die", "nur", "die", "Kunst", "er\u00b7schleu\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "$,", "PRELS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist Kenntnis Ziel, du kannst statt aller Kenntnis taugen:", "tokens": ["Ist", "Kennt\u00b7nis", "Ziel", ",", "du", "kannst", "statt", "al\u00b7ler", "Kennt\u00b7nis", "tau\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NN", "$,", "PPER", "VMFIN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Am weisesten der Mund, der dich am besten preist.", "tokens": ["Am", "wei\u00b7ses\u00b7ten", "der", "Mund", ",", "der", "dich", "am", "bes\u00b7ten", "preist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ART", "NN", "$,", "PRELS", "PRF", "APPRART", "ADJA", "NN", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.9": {"text": "Wer unger\u00fchrt dich s\u00e4h, die roh'ste Seele h\u00e4tt' er.", "tokens": ["Wer", "un\u00b7ge\u00b7r\u00fchrt", "dich", "s\u00e4h", ",", "die", "roh'\u00b7ste", "See\u00b7le", "h\u00e4tt'", "er", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "VAFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df du ein Wunder mir, kommt meinem Ruf zu gut.", "tokens": ["Da\u00df", "du", "ein", "Wun\u00b7der", "mir", ",", "kommt", "mei\u00b7nem", "Ruf", "zu", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PPER", "$,", "VVFIN", "PPOSAT", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dein Aug' ist Jovis Blitz, dein Laut sein drohend Wetter;", "tokens": ["Dein", "Aug'", "ist", "Jo\u00b7vis", "Blitz", ",", "dein", "Laut", "sein", "dro\u00b7hend", "Wet\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NE", "NN", "$,", "PPOSAT", "APPR", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Doch, ohne Zorn, Musik und sanfte Lebensglut.", "tokens": ["Doch", ",", "oh\u00b7ne", "Zorn", ",", "Mu\u00b7sik", "und", "sanf\u00b7te", "Le\u00b7bens\u00b7glut", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUI", "NN", "$,", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "O, himmlisch wie du bist, verleugne dich nicht so,", "tokens": ["O", ",", "himm\u00b7lisch", "wie", "du", "bist", ",", "ver\u00b7leug\u00b7ne", "dich", "nicht", "so", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "KOKOM", "PPER", "VAFIN", "$,", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und singe Himmels Lob so irdisch rauh und roh.", "tokens": ["Und", "sin\u00b7ge", "Him\u00b7mels", "Lob", "so", "ir\u00b7disch", "rauh", "und", "roh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NN", "ADV", "ADJD", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Kaum war der Tau vom Fr\u00fchlicht aufgetrunken,", "tokens": ["Kaum", "war", "der", "Tau", "vom", "Fr\u00fch\u00b7licht", "auf\u00b7ge\u00b7trun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kaum ruht die Herd' umz\u00e4unt im Schattendach,", "tokens": ["Kaum", "ruht", "die", "Herd'", "um\u00b7z\u00e4unt", "im", "Schat\u00b7ten\u00b7dach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als Cypria, in Liebe ganz versunken,", "tokens": ["Als", "Cyp\u00b7ria", ",", "in", "Lie\u00b7be", "ganz", "ver\u00b7sun\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$,", "APPR", "NN", "ADV", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Voll Sehnsucht des Adonis harrt' am Bach,", "tokens": ["Voll", "Sehn\u00b7sucht", "des", "A\u00b7do\u00b7nis", "harrt'", "am", "Bach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Bei einem Weidenbaum. Adonis war", "tokens": ["Bei", "ei\u00b7nem", "Wei\u00b7den\u00b7baum", ".", "A\u00b7do\u00b7nis", "war"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "NE", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Im Bach gewohnt sein Feuer abzuk\u00fchlen.", "tokens": ["Im", "Bach", "ge\u00b7wohnt", "sein", "Feu\u00b7er", "ab\u00b7zu\u00b7k\u00fch\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Hei\u00df schien die Sonne, hei\u00dfer noch f\u00fcrwahr", "tokens": ["Hei\u00df", "schien", "die", "Son\u00b7ne", ",", "hei\u00b7\u00dfer", "noch", "f\u00fcr\u00b7wahr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "$,", "ADJA", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Die seiner harrt'; oft pflegt' er dort zu spielen.", "tokens": ["Die", "sei\u00b7ner", "harrt'", ";", "oft", "pflegt'", "er", "dort", "zu", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und sieh! er kommt, und wirft den Mantel ab,", "tokens": ["Und", "sieh", "!", "er", "kommt", ",", "und", "wirft", "den", "Man\u00b7tel", "ab", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$.", "PPER", "VVFIN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Steht mutternackt auf gr\u00fcnem Wiesenplan.", "tokens": ["Steht", "mut\u00b7ter\u00b7nackt", "auf", "gr\u00fc\u00b7nem", "Wie\u00b7sen\u00b7plan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Mit Herrscheraugen blickt die Sonn' herab;", "tokens": ["Mit", "Herr\u00b7scher\u00b7au\u00b7gen", "blickt", "die", "Sonn'", "her\u00b7ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Noch br\u00fcnstiger blickt ihn die G\u00f6ttin an.", "tokens": ["Noch", "br\u00fcns\u00b7ti\u00b7ger", "blickt", "ihn", "die", "G\u00f6t\u00b7tin", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Kaum sah er sie, sprang er hinab. Sie sprach:", "tokens": ["Kaum", "sah", "er", "sie", ",", "sprang", "er", "hin\u00b7ab", ".", "Sie", "sprach", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "\u00bbo Jupiter! O w\u00e4r' ich doch der Bach!\u00ab", "tokens": ["\u00bb", "o", "Ju\u00b7pi\u00b7ter", "!", "O", "w\u00e4r'", "ich", "doch", "der", "Bach", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "NN", "$.", "NE", "VAFIN", "PPER", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.37": {"line.1": {"text": "Mein Lieb ist sch\u00f6n, doch nicht so sch\u00f6n als schn\u00f6de:", "tokens": ["Mein", "Lieb", "ist", "sch\u00f6n", ",", "doch", "nicht", "so", "sch\u00f6n", "als", "schn\u00f6\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "ADV", "PTKNEG", "ADV", "ADJD", "KOKOM", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie Tauben sanft, doch schlangenglatt und frostig;", "tokens": ["Wie", "Tau\u00b7ben", "sanft", ",", "doch", "schlan\u00b7gen\u00b7glatt", "und", "fros\u00b7tig", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Heller als Glas, und doch wie Glas so spr\u00f6de,", "tokens": ["Hel\u00b7ler", "als", "Glas", ",", "und", "doch", "wie", "Glas", "so", "spr\u00f6\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "NN", "$,", "KON", "ADV", "KOKOM", "NN", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Weicher als Wachs, und doch wie Eisen rostig:", "tokens": ["Wei\u00b7cher", "als", "Wachs", ",", "und", "doch", "wie", "Ei\u00b7sen", "ros\u00b7tig", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "NN", "$,", "KON", "ADV", "KOKOM", "NN", "ADJD", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "Ein wenig bleich, mit etwas Rosenr\u00f6te,", "tokens": ["Ein", "we\u00b7nig", "bleich", ",", "mit", "et\u00b7was", "Ro\u00b7sen\u00b7r\u00f6\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So sch\u00f6n wie keine, und so falsch wie jede.", "tokens": ["So", "sch\u00f6n", "wie", "kei\u00b7ne", ",", "und", "so", "falsch", "wie", "je\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "PIAT", "$,", "KON", "ADV", "ADJD", "KOKOM", "PIAT", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.38": {"line.1": {"text": "Wie hat sie mich mit Lippen schier verschlungen,", "tokens": ["Wie", "hat", "sie", "mich", "mit", "Lip\u00b7pen", "schier", "ver\u00b7schlun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PRF", "APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf jeden Ku\u00df ein Heer von Liebesschw\u00fcren.", "tokens": ["Auf", "je\u00b7den", "Ku\u00df", "ein", "Heer", "von", "Lie\u00b7bes\u00b7schw\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie hat sie mich mit M\u00e4rchen eingesungen,", "tokens": ["Wie", "hat", "sie", "mich", "mit", "M\u00e4r\u00b7chen", "ein\u00b7ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PRF", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als br\u00e4ch' ihr Herz, das meine zu verlieren!", "tokens": ["Als", "br\u00e4ch'", "ihr", "Herz", ",", "das", "mei\u00b7ne", "zu", "ver\u00b7lie\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und doch, im Schwung der h\u00f6chsten Seelenfl\u00fcge", "tokens": ["Und", "doch", ",", "im", "Schwung", "der", "h\u00f6chs\u00b7ten", "See\u00b7len\u00b7fl\u00fc\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "APPRART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ward Eid und Treu und Tr\u00e4n' und alles L\u00fcge.", "tokens": ["Ward", "Eid", "und", "Treu", "und", "Tr\u00e4n'", "und", "al\u00b7les", "L\u00fc\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "KON", "NN", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.39": {"line.1": {"text": "Sie brannt' in Liebe wie das Stroh in Flammen,", "tokens": ["Sie", "brannt'", "in", "Lie\u00b7be", "wie", "das", "Stroh", "in", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KOKOM", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verbrannt' in Liebe schnell wie Stroh verbrennet,", "tokens": ["Ver\u00b7brannt'", "in", "Lie\u00b7be", "schnell", "wie", "Stroh", "ver\u00b7bren\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADJD", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Erbaute Lieb', und ri\u00df sie wild zusammen;", "tokens": ["Er\u00b7bau\u00b7te", "Lieb'", ",", "und", "ri\u00df", "sie", "wild", "zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schwur ew'ge Lieb', und hat sie rasch zertrennet.", "tokens": ["Schwur", "ew'\u00b7ge", "Lieb'", ",", "und", "hat", "sie", "rasch", "zer\u00b7tren\u00b7net", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "$,", "KON", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Soll sie als Buhl', als Liebchen mir gefallen,", "tokens": ["Soll", "sie", "als", "Buhl'", ",", "als", "Lieb\u00b7chen", "mir", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KOUS", "NN", "$,", "KOUS", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Zu schlecht zum guten, und gering in allem?", "tokens": ["Zu", "schlecht", "zum", "gu\u00b7ten", ",", "und", "ge\u00b7ring", "in", "al\u00b7lem", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "APPRART", "ADJA", "$,", "KON", "ADJD", "APPR", "PIS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.40": {"line.1": {"text": "Der Morgen l\u00e4chelte: die sch\u00f6ne Venus war", "tokens": ["Der", "Mor\u00b7gen", "l\u00e4\u00b7chel\u00b7te", ":", "die", "sch\u00f6\u00b7ne", "Ve\u00b7nus", "war"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.3": {"text": "Vor Kummer bleicher als ihr schneewei\u00df Taubenpaar,", "tokens": ["Vor", "Kum\u00b7mer", "blei\u00b7cher", "als", "ihr", "schnee\u00b7wei\u00df", "Tau\u00b7ben\u00b7paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "KOKOM", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des wilden Springinsfeld Adonis wegen.", "tokens": ["Des", "wil\u00b7den", "Sprin\u00b7gins\u00b7feld", "A\u00b7do\u00b7nis", "we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "APPR", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie tritt auf einen j\u00e4hen Holm. Geschwind", "tokens": ["Sie", "tritt", "auf", "ei\u00b7nen", "j\u00e4\u00b7hen", "Holm", ".", "Ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$.", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sieht sie den Knaben nahn mit Horn und Hunde.", "tokens": ["Sieht", "sie", "den", "Kna\u00b7ben", "nahn", "mit", "Horn", "und", "Hun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJA", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die Gute warnt ihn, mehr als wohlgesinnt:", "tokens": ["Die", "Gu\u00b7te", "warnt", "ihn", ",", "mehr", "als", "wohl\u00b7ge\u00b7sinnt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "PIAT", "KOKOM", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "\u00bbo weiche nicht von diesem sichern Grunde.", "tokens": ["\u00bb", "o", "wei\u00b7che", "nicht", "von", "die\u00b7sem", "si\u00b7chern", "Grun\u00b7de", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "ADJA", "PTKNEG", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Wohl eher sah ich schon so holden Kleinen", "tokens": ["Wohl", "e\u00b7her", "sah", "ich", "schon", "so", "hol\u00b7den", "Klei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Von einem Eber schwer verletzt im Tal,", "tokens": ["Von", "ei\u00b7nem", "E\u00b7ber", "schwer", "ver\u00b7letzt", "im", "Tal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJD", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Tief in der H\u00fcft', ein Anblick war's zum Weinen;", "tokens": ["Tief", "in", "der", "H\u00fcft'", ",", "ein", "An\u00b7blick", "wa\u00b7r's", "zum", "Wei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$,", "ART", "NN", "VAFIN", "APPRART", "NN", "$."], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.12": {"text": "Sieh meine H\u00fcfte, sieh, hier war das Mal.\u00ab", "tokens": ["Sieh", "mei\u00b7ne", "H\u00fcf\u00b7te", ",", "sieh", ",", "hier", "war", "das", "Mal", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "VVFIN", "$,", "ADV", "VAFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Sie zeigt es ihm, und er wird rot und flieht,", "tokens": ["Sie", "zeigt", "es", "ihm", ",", "und", "er", "wird", "rot", "und", "flieht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPER", "$,", "KON", "PPER", "VAFIN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Weil er mehr Wunden dort als eine sieht.", "tokens": ["Weil", "er", "mehr", "Wun\u00b7den", "dort", "als", "ei\u00b7ne", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "ADV", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.41": {"line.1": {"text": "Lieb R\u00f6slein, vor der Zeit gepfl\u00fcckt, zu bald erblichen,", "tokens": ["Lieb", "R\u00f6s\u00b7lein", ",", "vor", "der", "Zeit", "ge\u00b7pfl\u00fcckt", ",", "zu", "bald", "er\u00b7bli\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "APPR", "ART", "NN", "VVPP", "$,", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gepfl\u00fcckt als zarte Knosp', im Lenz erblichen; ach,", "tokens": ["Ge\u00b7pfl\u00fcckt", "als", "zar\u00b7te", "Knosp'", ",", "im", "Lenz", "er\u00b7bli\u00b7chen", ";", "ach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVPP", "KOKOM", "ADJA", "NN", "$,", "APPRART", "NN", "VVINF", "$.", "XY", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des Ostens Perle du, vom Moder fr\u00fch beschlichen,", "tokens": ["Des", "Os\u00b7tens", "Per\u00b7le", "du", ",", "vom", "Mo\u00b7der", "fr\u00fch", "be\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "$,", "APPRART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "O Kleinod, das so schnell des Todes Stachel stach,", "tokens": ["O", "Klei\u00b7nod", ",", "das", "so", "schnell", "des", "To\u00b7des", "Sta\u00b7chel", "stach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "ADV", "ADJD", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie gr\u00fcne Pflaumen, die in Windes Wallen", "tokens": ["Wie", "gr\u00fc\u00b7ne", "Pflau\u00b7men", ",", "die", "in", "Win\u00b7des", "Wal\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "NN", "$,", "PRELS", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Eh' sie der Herbst gereift, vom Baume fallen.", "tokens": ["Eh'", "sie", "der", "Herbst", "ge\u00b7reift", ",", "vom", "Bau\u00b7me", "fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.42": {"line.1": {"text": "Ich wein' um dich, der doch nicht Anla\u00df hat:", "tokens": ["Ich", "wein'", "um", "dich", ",", "der", "doch", "nicht", "An\u00b7la\u00df", "hat", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "PRELS", "ADV", "PTKNEG", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Warum? Im Testament hast du mich \u00fcbergangen;", "tokens": ["Wa\u00b7rum", "?", "Im", "Tes\u00b7ta\u00b7ment", "hast", "du", "mich", "\u00fc\u00b7ber\u00b7gan\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "APPRART", "NN", "VAFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und mir doch mehr vermacht, als je ich von dir bat:", "tokens": ["Und", "mir", "doch", "mehr", "ver\u00b7macht", ",", "als", "je", "ich", "von", "dir", "bat", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADV", "VVPP", "$,", "KOUS", "ADV", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Warum? Nie hab' ich dich um etwas angegangen.", "tokens": ["Wa\u00b7rum", "?", "Nie", "hab'", "ich", "dich", "um", "et\u00b7was", "an\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "ADV", "VAFIN", "PPER", "PRF", "APPR", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und doch, verzeih mein Herz! ich mu\u00df mich fassen:", "tokens": ["Und", "doch", ",", "ver\u00b7zeih", "mein", "Herz", "!", "ich", "mu\u00df", "mich", "fas\u00b7sen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "VVIMP", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Dein Mi\u00dfvergn\u00fcgen hast du mir verlassen.", "tokens": ["Dein", "Mi\u00df\u00b7ver\u00b7gn\u00fc\u00b7gen", "hast", "du", "mir", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.43": {"line.1": {"text": "Saures Alter, frohe Jugend", "tokens": ["Sau\u00b7res", "Al\u00b7ter", ",", "fro\u00b7he", "Ju\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nnen nicht zusammen dauern:", "tokens": ["K\u00f6n\u00b7nen", "nicht", "zu\u00b7sam\u00b7men", "dau\u00b7ern", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jugend ist voll muntrer Launen,", "tokens": ["Ju\u00b7gend", "ist", "voll", "mun\u00b7trer", "Lau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alter voller Sorg' und Qual.", "tokens": ["Al\u00b7ter", "vol\u00b7ler", "Sor\u00b7g'", "und", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Jugend wie ein Sommermorgen,", "tokens": ["Ju\u00b7gend", "wie", "ein", "Som\u00b7mer\u00b7mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Alter gleicht den Winterschauern.", "tokens": ["Al\u00b7ter", "gleicht", "den", "Win\u00b7ter\u00b7schau\u00b7ern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Jugend pranget wie der Sommer,", "tokens": ["Ju\u00b7gend", "pran\u00b7get", "wie", "der", "Som\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Alter winterd\u00fcrr und kahl.", "tokens": ["Al\u00b7ter", "win\u00b7ter\u00b7d\u00fcrr", "und", "kahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Wenn der Jugend Scherze frommen,", "tokens": ["Wenn", "der", "Ju\u00b7gend", "Scher\u00b7ze", "from\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Alters Odem bleibt beklommen.", "tokens": ["Al\u00b7ters", "O\u00b7dem", "bleibt", "be\u00b7klom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Jugend eilet, Alter schleicht.", "tokens": ["Ju\u00b7gend", "ei\u00b7let", ",", "Al\u00b7ter", "schleicht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Jugend feurig, k\u00fchn, verwegen,", "tokens": ["Ju\u00b7gend", "feu\u00b7rig", ",", "k\u00fchn", ",", "ver\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "ADJD", "$,", "ADJD", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Alter lahm, will nur sich pflegen;", "tokens": ["Al\u00b7ter", "lahm", ",", "will", "nur", "sich", "pfle\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "VMFIN", "ADV", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Jugend sch\u00e4umet, Alter keucht.", "tokens": ["Ju\u00b7gend", "sch\u00e4u\u00b7met", ",", "Al\u00b7ter", "keucht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Jugend, Jugend, dich umfang' ich:", "tokens": ["Ju\u00b7gend", ",", "Ju\u00b7gend", ",", "dich", "um\u00b7fang'", "ich", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Alter, Alter, vor dir bang' ich.", "tokens": ["Al\u00b7ter", ",", "Al\u00b7ter", ",", "vor", "dir", "bang'", "ich", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "APPR", "PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "O mein Lieb, mein Lieb ist jung.", "tokens": ["O", "mein", "Lieb", ",", "mein", "Lieb", "ist", "jung", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "Alter schlag' ich in die Winde:", "tokens": ["Al\u00b7ter", "schlag'", "ich", "in", "die", "Win\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "S\u00fc\u00dfer Sch\u00e4fer, komm geschwinde!", "tokens": ["S\u00fc\u00b7\u00dfer", "Sch\u00e4\u00b7fer", ",", "komm", "ge\u00b7schwin\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "VVFIN", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Eilest lang mir nicht genung.", "tokens": ["Ei\u00b7lest", "lang", "mir", "nicht", "ge\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Sch\u00f6nheit, o eitles Gl\u00fcck, wie bald verloren!", "tokens": ["Sch\u00f6n\u00b7heit", ",", "o", "eit\u00b7les", "Gl\u00fcck", ",", "wie", "bald", "ver\u00b7lo\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "FM", "ADJA", "NN", "$,", "PWAV", "ADV", "VVPP", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Du bist ein bunter Schmelz, der schnell verfliegt,", "tokens": ["Du", "bist", "ein", "bun\u00b7ter", "Schmelz", ",", "der", "schnell", "ver\u00b7fliegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Bl\u00fcmlein fr\u00fch dahin, so wie geboren,", "tokens": ["Ein", "Bl\u00fcm\u00b7lein", "fr\u00fch", "da\u00b7hin", ",", "so", "wie", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PAV", "$,", "ADV", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein m\u00fcrbes Glas, das in der Hand zerbricht.", "tokens": ["Ein", "m\u00fcr\u00b7bes", "Glas", ",", "das", "in", "der", "Hand", "zer\u00b7bricht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Schmelze, Blume, Glas, hinf\u00e4llig eitles Gl\u00fcck,", "tokens": ["Schmel\u00b7ze", ",", "Blu\u00b7me", ",", "Glas", ",", "hin\u00b7f\u00e4l\u00b7lig", "eit\u00b7les", "Gl\u00fcck", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Verwelkt, verschwunden, tot im Augenblick.", "tokens": ["Ver\u00b7welkt", ",", "ver\u00b7schwun\u00b7den", ",", "tot", "im", "Au\u00b7gen\u00b7blick", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "$,", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.45": {"line.1": {"text": "Und wie verlornes Gl\u00fcck sich selten findet,", "tokens": ["Und", "wie", "ver\u00b7lor\u00b7nes", "Gl\u00fcck", "sich", "sel\u00b7ten", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJA", "NN", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verflognen Schmelz kein Reiben wiederbringt,", "tokens": ["Ver\u00b7flog\u00b7nen", "Schmelz", "kein", "Rei\u00b7ben", "wie\u00b7der\u00b7bringt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verwelkte Blume tot zur Erde schwindet,", "tokens": ["Ver\u00b7welk\u00b7te", "Blu\u00b7me", "tot", "zur", "Er\u00b7de", "schwin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zerbrochnes Glas kein Kitt zusammenzwingt:", "tokens": ["Zer\u00b7broch\u00b7nes", "Glas", "kein", "Kitt", "zu\u00b7sam\u00b7men\u00b7zwingt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So kann befleckte Sch\u00f6nheit nichts erneuen,", "tokens": ["So", "kann", "be\u00b7fleck\u00b7te", "Sch\u00f6n\u00b7heit", "nichts", "er\u00b7neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADJA", "NN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nicht M\u00fchen, Sorgen, Schminken, Arzeneien.", "tokens": ["Nicht", "M\u00fc\u00b7hen", ",", "Sor\u00b7gen", ",", "Schmin\u00b7ken", ",", "Ar\u00b7ze\u00b7nei\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PTKNEG", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.46": {"line.1": {"text": "\u00bbgut' Nacht! Ruh' sanft!\u00ab \u2013 Ach, beides mir verleidet!", "tokens": ["\u00bb", "gut'", "Nacht", "!", "Ruh'", "sanft", "!", "\u00ab", "\u2013", "Ach", ",", "bei\u00b7des", "mir", "ver\u00b7lei\u00b7det", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$.", "NN", "ADJD", "$.", "$(", "$(", "ITJ", "$,", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie beut mir gute Nacht, die meine Ruh verscheucht", "tokens": ["Sie", "beut", "mir", "gu\u00b7te", "Nacht", ",", "die", "mei\u00b7ne", "Ruh", "ver\u00b7scheucht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und in mein Bett mich treibt mit Qualen \u00fcberbreitet,", "tokens": ["Und", "in", "mein", "Bett", "mich", "treibt", "mit", "Qua\u00b7len", "\u00fc\u00b7berb\u00b7rei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "PPER", "VVFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo meines Ungl\u00fccks Zweifel mich beschleicht.", "tokens": ["Wo", "mei\u00b7nes", "Un\u00b7gl\u00fccks", "Zwei\u00b7fel", "mich", "be\u00b7schleicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbleb' wohl\u00ab, sprach sie, \u00bbgut' Nacht! Wir sehn uns morgen.\u00ab \u2013", "tokens": ["\u00bb", "leb'", "wohl", "\u00ab", ",", "sprach", "sie", ",", "\u00bb", "gut'", "Nacht", "!", "Wir", "sehn", "uns", "mor\u00b7gen", ".", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "VVIMP", "ADV", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "ADJA", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "$.", "$(", "$("], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Wohlleben konnt' ich nicht; ich a\u00df zu Nacht mit Sorgen.", "tokens": ["Wohl\u00b7le\u00b7ben", "konnt'", "ich", "nicht", ";", "ich", "a\u00df", "zu", "Nacht", "mit", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PTKNEG", "$.", "PPER", "VVFIN", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.47": {"line.1": {"text": "Doch als wir schieden, l\u00e4chelt' sie so s\u00fc\u00df:", "tokens": ["Doch", "als", "wir", "schie\u00b7den", ",", "l\u00e4\u00b7chelt'", "sie", "so", "s\u00fc\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "War's Freundschaft oder Hohn? Ich mag's nicht deuten:", "tokens": ["Wa\u00b7r's", "Freund\u00b7schaft", "o\u00b7der", "Hohn", "?", "Ich", "mag's", "nicht", "deu\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "$.", "PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Vielleicht vor Freuden, da\u00df sie mich verstie\u00df?", "tokens": ["Viel\u00b7leicht", "vor", "Freu\u00b7den", ",", "da\u00df", "sie", "mich", "ver\u00b7stie\u00df", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Vielleicht mich Irren wieder hin zu leiten?", "tokens": ["Viel\u00b7leicht", "mich", "Ir\u00b7ren", "wie\u00b7der", "hin", "zu", "lei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "NN", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Irr! Auf uns luft'ge Schemen pa\u00dft das Wort;", "tokens": ["Irr", "!", "Auf", "uns", "luft'\u00b7ge", "Sche\u00b7men", "pa\u00dft", "das", "Wort", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "APPR", "PPER", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wir m\u00fch'n uns viel, und heben nie den Hort.", "tokens": ["Wir", "m\u00fch'n", "uns", "viel", ",", "und", "he\u00b7ben", "nie", "den", "Hort", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "$,", "KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.48": {"line.1": {"text": "Wie starrt' ich unverwandt nach Osten hin!", "tokens": ["Wie", "starrt'", "ich", "un\u00b7ver\u00b7wandt", "nach", "Os\u00b7ten", "hin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADJD", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mein Herz z\u00fcrnt mit der Uhr; das fr\u00fche Licht", "tokens": ["Mein", "Herz", "z\u00fcrnt", "mit", "der", "Uhr", ";", "das", "fr\u00fc\u00b7he", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erweckt aus tr\u00e4gem Schlummer jeden Sinn:", "tokens": ["Er\u00b7weckt", "aus", "tr\u00e4\u00b7gem", "Schlum\u00b7mer", "je\u00b7den", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der eignen Augen Zeugnis glaub' ich nicht;", "tokens": ["Der", "eig\u00b7nen", "Au\u00b7gen", "Zeug\u00b7nis", "glaub'", "ich", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich sitze lauschend, horch' auf Philomelen,", "tokens": ["Ich", "sit\u00b7ze", "lau\u00b7schend", ",", "horch'", "auf", "Phi\u00b7lo\u00b7me\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und wollt', es w\u00e4r ein Lied aus Lerchenkehlen:", "tokens": ["Und", "wollt'", ",", "es", "w\u00e4r", "ein", "Lied", "aus", "Ler\u00b7chen\u00b7keh\u00b7len", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "PPER", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.49": {"line.1": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Und zwingt die lichtlos bange Nacht zur Flucht;", "tokens": ["Und", "zwingt", "die", "licht\u00b7los", "ban\u00b7ge", "Nacht", "zur", "Flucht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJD", "ADV", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und, flieht die Nacht, eil' ich zu meiner Trauten;", "tokens": ["Und", ",", "flieht", "die", "Nacht", ",", "eil'", "ich", "zu", "mei\u00b7ner", "Trau\u00b7ten", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "ART", "NN", "$,", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dort findet Herz und Auge, was es sucht.", "tokens": ["Dort", "fin\u00b7det", "Herz", "und", "Au\u00b7ge", ",", "was", "es", "sucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sorg' ist in Lust verwandelt, Lust hegt Sorgen,", "tokens": ["Sor\u00b7g'", "ist", "in", "Lust", "ver\u00b7wan\u00b7delt", ",", "Lust", "hegt", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "NN", "VVPP", "$,", "NN", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Denn seufzend sagte sie zu mir: \u00bbKomm morgen!\u00ab", "tokens": ["Denn", "seuf\u00b7zend", "sag\u00b7te", "sie", "zu", "mir", ":", "\u00bb", "Komm", "mor\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPR", "PPER", "$.", "$(", "VVFIN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.50": {"line.1": {"text": "W\u00e4r' ich mit ihr, zu schnell w\u00e4r' Nacht entflohn;", "tokens": ["W\u00e4r'", "ich", "mit", "ihr", ",", "zu", "schnell", "w\u00e4r'", "Nacht", "ent\u00b7flohn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "$,", "PTKA", "ADJD", "VAFIN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nun aber reih'n Minuten sich an Stunden:", "tokens": ["Nun", "a\u00b7ber", "reih'n", "Mi\u00b7nu\u00b7ten", "sich", "an", "Stun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "NN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Minuten werden Monden mir zum Hohn.", "tokens": ["Mi\u00b7nu\u00b7ten", "wer\u00b7den", "Mon\u00b7den", "mir", "zum", "Hohn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Nicht mir, o Tag! den Blumen scheine drunten.", "tokens": ["Nicht", "mir", ",", "o", "Tag", "!", "den", "Blu\u00b7men", "schei\u00b7ne", "drun\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPER", "$,", "FM", "NN", "$.", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Flieh, Nacht! Komm, lieber Tag! La\u00df Nacht uns borgen;", "tokens": ["Flieh", ",", "Nacht", "!", "Komm", ",", "lie\u00b7ber", "Tag", "!", "La\u00df", "Nacht", "uns", "bor\u00b7gen", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "VVFIN", "$,", "ADV", "NN", "$.", "VVIMP", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und, Nacht, sei kurz, erhole dich am Morgen.", "tokens": ["Und", ",", "Nacht", ",", "sei", "kurz", ",", "er\u00b7ho\u00b7le", "dich", "am", "Mor\u00b7gen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "$,", "VAFIN", "ADJD", "$,", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.51": {"line.1": {"text": "Liebe (ach wer steht ihr bei!", "tokens": ["Lie\u00b7be", "(", "ach", "wer", "steht", "ihr", "bei", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ITJ", "PWS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Immer frisch und jung im Mai)", "tokens": ["Im\u00b7mer", "frisch", "und", "jung", "im", "Mai", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "APPRART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sah umbuhlt von Zephyrs Wehen", "tokens": ["Sah", "um\u00b7buhlt", "von", "Ze\u00b7phyrs", "We\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wundersch\u00f6nes Bl\u00fcmlein stehen.", "tokens": ["Wun\u00b7der\u00b7sch\u00f6\u00b7nes", "Bl\u00fcm\u00b7lein", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Durch die samtnen Bl\u00e4tter schien", "tokens": ["Durch", "die", "samt\u00b7nen", "Bl\u00e4t\u00b7ter", "schien"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Unsichtbar der Wind zu ziehn,", "tokens": ["Un\u00b7sicht\u00b7bar", "der", "Wind", "zu", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df sich totkrank der Verliebte", "tokens": ["Da\u00df", "sich", "tot\u00b7krank", "der", "Ver\u00b7lieb\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ADJD", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Nicht wie Luft zu sein betr\u00fcbte,", "tokens": ["Nicht", "wie", "Luft", "zu", "sein", "be\u00b7tr\u00fcb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOKOM", "NN", "PTKZU", "VAINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "\u00bbluft\u00ab, sprach er, \u00bbwie darfst du schl\u00fcrfen!", "tokens": ["\u00bb", "luft", "\u00ab", ",", "sprach", "er", ",", "\u00bb", "wie", "darfst", "du", "schl\u00fcr\u00b7fen", "!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "PWAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "M\u00f6cht' ich, Luft, so jubeln d\u00fcrfen!", "tokens": ["M\u00f6cht'", "ich", ",", "Luft", ",", "so", "ju\u00b7beln", "d\u00fcr\u00b7fen", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "NN", "$,", "ADV", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Aber ach, dich nie zu brechen", "tokens": ["A\u00b7ber", "ach", ",", "dich", "nie", "zu", "bre\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "XY", "$,", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Gab die Hand dir das Versprechen!", "tokens": ["Gab", "die", "Hand", "dir", "das", "Ver\u00b7spre\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Jugendschwur, wie ich dich b\u00fc\u00dfe!", "tokens": ["Ju\u00b7gend\u00b7schwur", ",", "wie", "ich", "dich", "b\u00fc\u00b7\u00dfe", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Jugend pfl\u00fcckt so gern das S\u00fc\u00dfe.", "tokens": ["Ju\u00b7gend", "pfl\u00fcckt", "so", "gern", "das", "S\u00fc\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Nenn' es S\u00fcnde nicht in mir,", "tokens": ["Nenn'", "es", "S\u00fcn\u00b7de", "nicht", "in", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "PTKNEG", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Brech' ich mein Gel\u00fcbde dir.", "tokens": ["Brech'", "ich", "mein", "Ge\u00b7l\u00fcb\u00b7de", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Schw\u00fcr' doch Zeus, in dich verloren,", "tokens": ["Schw\u00fcr'", "doch", "Zeus", ",", "in", "dich", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "NE", "$,", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Seine Juno glich den Mohren;", "tokens": ["Sei\u00b7ne", "Ju\u00b7no", "glich", "den", "Moh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "M\u00f6chte Zeus nicht l\u00e4nger, nein,", "tokens": ["M\u00f6ch\u00b7te", "Zeus", "nicht", "l\u00e4n\u00b7ger", ",", "nein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "NE", "PTKNEG", "ADJD", "$,", "PTKANT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "Dir zuliebe sterblich sein.\u00ab", "tokens": ["Dir", "zu\u00b7lie\u00b7be", "sterb\u00b7lich", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "VAINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "Wenn du die Sch\u00f6ne willst erreichen,", "tokens": ["Wenn", "du", "die", "Sch\u00f6\u00b7ne", "willst", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Wild, das schu\u00dfrecht vor dir sitzt,", "tokens": ["Das", "Wild", ",", "das", "schu\u00df\u00b7recht", "vor", "dir", "sitzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VVFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann sch\u00fctze dich Vernunft vor Streichen,", "tokens": ["Dann", "sch\u00fct\u00b7ze", "dich", "Ver\u00b7nunft", "vor", "Strei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So gut sie blinde Liebe sch\u00fctzt.", "tokens": ["So", "gut", "sie", "blin\u00b7de", "Lie\u00b7be", "sch\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein kluger Rat, er w\u00e4r' dir n\u00f6tig;", "tokens": ["Ein", "klu\u00b7ger", "Rat", ",", "er", "w\u00e4r'", "dir", "n\u00f6\u00b7tig", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Doch sei er nicht zu jung, noch ledig.", "tokens": ["Doch", "sei", "er", "nicht", "zu", "jung", ",", "noch", "le\u00b7dig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "PTKA", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Und bringst du nun dein Spr\u00fcchlein an,", "tokens": ["Und", "bringst", "du", "nun", "dein", "Spr\u00fcch\u00b7lein", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df glatter Zungen Wortgeflinker:", "tokens": ["La\u00df", "glat\u00b7ter", "Zun\u00b7gen", "Wort\u00b7ge\u00b7flin\u00b7ker", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sonst merkt sie Trug, du hast vertan;", "tokens": ["Sonst", "merkt", "sie", "Trug", ",", "du", "hast", "ver\u00b7tan", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Lahme wittert leicht den Hinker.", "tokens": ["Der", "Lah\u00b7me", "wit\u00b7tert", "leicht", "den", "Hin\u00b7ker", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sprich nur: Dich lieb' ich, treu und schlicht,", "tokens": ["Sprich", "nur", ":", "Dich", "lieb'", "ich", ",", "treu", "und", "schlicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "PPER", "VVFIN", "PPER", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und setz' ihr Sch\u00f6nes hell ins Licht.", "tokens": ["Und", "setz'", "ihr", "Sch\u00f6\u00b7nes", "hell", "ins", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Und schmollt sie gleich und senkt den Blick,", "tokens": ["Und", "schmollt", "sie", "gleich", "und", "senkt", "den", "Blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor Abend noch gibt sich dies Toben:", "tokens": ["Vor", "A\u00b7bend", "noch", "gibt", "sich", "dies", "To\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVFIN", "PRF", "PDS", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Dann w\u00fcnscht sie dich zu sp\u00e4t zur\u00fcck,", "tokens": ["Dann", "w\u00fcnscht", "sie", "dich", "zu", "sp\u00e4t", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKA", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bereut, da\u00df sie ihr Gl\u00fcck verschoben;", "tokens": ["Be\u00b7reut", ",", "da\u00df", "sie", "ihr", "Gl\u00fcck", "ver\u00b7scho\u00b7ben", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zweimal verlangt sie, eh' es tagt,", "tokens": ["Zwei\u00b7mal", "ver\u00b7langt", "sie", ",", "eh'", "es", "tagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach dem, was sie mit Hohn versagt.", "tokens": ["Nach", "dem", ",", "was", "sie", "mit", "Hohn", "ver\u00b7sagt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "La\u00df sie nur ringen, keifen, zanken,", "tokens": ["La\u00df", "sie", "nur", "rin\u00b7gen", ",", "kei\u00b7fen", ",", "zan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich mit dir messen, schelten, schm\u00e4hn;", "tokens": ["Sich", "mit", "dir", "mes\u00b7sen", ",", "schel\u00b7ten", ",", "schm\u00e4hn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PRF", "APPR", "PPER", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die schwache Kraft wird endlich wanken,", "tokens": ["Die", "schwa\u00b7che", "Kraft", "wird", "end\u00b7lich", "wan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie wird gewitzigt eingestehn:", "tokens": ["Sie", "wird", "ge\u00b7wit\u00b7zigt", "ein\u00b7ge\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "W\u00e4r' Weib so stark als Mann geboren,", "tokens": ["W\u00e4r'", "Weib", "so", "stark", "als", "Mann", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "ADJD", "KOKOM", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Du h\u00e4ttest, meiner Treu, verloren!", "tokens": ["Du", "h\u00e4t\u00b7test", ",", "mei\u00b7ner", "Treu", ",", "ver\u00b7lo\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPOSAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Und ihren W\u00fcnschen allerweise", "tokens": ["Und", "ih\u00b7ren", "W\u00fcn\u00b7schen", "al\u00b7ler\u00b7wei\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit vollen H\u00e4nden komm zuvor:", "tokens": ["Mit", "vol\u00b7len", "H\u00e4n\u00b7den", "komm", "zu\u00b7vor", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df dein Verdienst sich hell erweise,", "tokens": ["Da\u00df", "dein", "Ver\u00b7dienst", "sich", "hell", "er\u00b7wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "La\u00df aufgehn, klingl' ihr um das Ohr.", "tokens": ["La\u00df", "auf\u00b7gehn", ",", "klingl'", "ihr", "um", "das", "Ohr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVIZU", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die st\u00e4rkste Festung, Turm und Mau'r", "tokens": ["Die", "st\u00e4rks\u00b7te", "Fes\u00b7tung", ",", "Turm", "und", "Mau'r"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ergibt sich goldnem Regenschau'r.", "tokens": ["Er\u00b7gibt", "sich", "gold\u00b7nem", "Re\u00b7gen\u00b7schau'", "r."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["VVFIN", "PRF", "ADJA", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Sei immerdar ihr treuer Knecht,", "tokens": ["Sei", "im\u00b7mer\u00b7dar", "ihr", "treu\u00b7er", "Knecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Werben ehrlich und bescheiden:", "tokens": ["Dein", "Wer\u00b7ben", "ehr\u00b7lich", "und", "be\u00b7schei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So lang sie dir nicht ungerecht,", "tokens": ["So", "lang", "sie", "dir", "nicht", "un\u00b7ge\u00b7recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "La\u00df dich zum Wechsel nicht verleiten.", "tokens": ["La\u00df", "dich", "zum", "Wech\u00b7sel", "nicht", "ver\u00b7lei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPRART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Verdrie\u00dfe dich kein gutes Wort,", "tokens": ["Ver\u00b7drie\u00b7\u00dfe", "dich", "kein", "gu\u00b7tes", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und stie\u00dfe sie dich zehnmal fort.", "tokens": ["Und", "stie\u00b7\u00dfe", "sie", "dich", "zehn\u00b7mal", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Wie Frauenlist sich r\u00e4nkevoll", "tokens": ["Wie", "Frau\u00b7en\u00b7list", "sich", "r\u00e4n\u00b7ke\u00b7voll"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "PRF", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit falschem Au\u00dfenschein umzieht,", "tokens": ["Mit", "fal\u00b7schem", "Au\u00b7\u00dfen\u00b7schein", "um\u00b7zieht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "All' ihre Schlich' und Launen soll", "tokens": ["All'", "ih\u00b7re", "Schlich'", "und", "Lau\u00b7nen", "soll"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "PPOSAT", "NN", "KON", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Hahn nicht wissen, der sie tritt.", "tokens": ["Der", "Hahn", "nicht", "wis\u00b7sen", ",", "der", "sie", "tritt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hat man dir nicht schon oft bericht':", "tokens": ["Hat", "man", "dir", "nicht", "schon", "oft", "be\u00b7richt'", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PPER", "PTKNEG", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Weiber-Nein hat leicht Gewicht?", "tokens": ["Ein", "Wei\u00b7ber\u00b7\u00b7N\u00b7ein", "hat", "leicht", "Ge\u00b7wicht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.59": {"line.1": {"text": "Bedenk, mit M\u00e4nnern ficht kein Weib", "tokens": ["Be\u00b7denk", ",", "mit", "M\u00e4n\u00b7nern", "ficht", "kein", "Weib"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "NN", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Um M\u00e4rtyrtum, es ficht um S\u00fcnden.", "tokens": ["Um", "M\u00e4r\u00b7tyr\u00b7tum", ",", "es", "ficht", "um", "S\u00fcn\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn Zeit und Alter sie best\u00e4ubt,", "tokens": ["Wenn", "Zeit", "und", "Al\u00b7ter", "sie", "be\u00b7st\u00e4ubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beim Kreuz! dann liegt ihr Himmel hinten.", "tokens": ["Beim", "Kreuz", "!", "dann", "liegt", "ihr", "Him\u00b7mel", "hin\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "ADV", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "G\u00e4b's nichts als K\u00fcss' im Bett, f\u00fcrwahr,", "tokens": ["G\u00e4b's", "nichts", "als", "K\u00fcss'", "im", "Bett", ",", "f\u00fcr\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PIS", "KOKOM", "NN", "APPRART", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Weib ging mit Weib zum Traualtar.", "tokens": ["Weib", "ging", "mit", "Weib", "zum", "Trau\u00b7al\u00b7tar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "APPRART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.60": {"line.1": {"text": "Doch still! genug, und schon zuviel,", "tokens": ["Doch", "still", "!", "ge\u00b7nug", ",", "und", "schon", "zu\u00b7viel", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "ADV", "$,", "KON", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df mich mein M\u00e4dchen nicht vernimmt,", "tokens": ["Da\u00df", "mich", "mein", "M\u00e4d\u00b7chen", "nicht", "ver\u00b7nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In's Ohr mir raunt: \u00bbNun schweige still!\u00ab", "tokens": ["In's", "Ohr", "mir", "raunt", ":", "\u00bb", "Nun", "schwei\u00b7ge", "still", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und meine Zunge zahmer stimmt. \u2013", "tokens": ["Und", "mei\u00b7ne", "Zun\u00b7ge", "zah\u00b7mer", "stimmt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch wird sie rot, (traut meinem Lied),", "tokens": ["Doch", "wird", "sie", "rot", ",", "(", "traut", "mei\u00b7nem", "Lied", ")", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "$(", "VVFIN", "PPOSAT", "NN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn sie sich so verraten sieht.", "tokens": ["Wenn", "sie", "sich", "so", "ver\u00b7ra\u00b7ten", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}