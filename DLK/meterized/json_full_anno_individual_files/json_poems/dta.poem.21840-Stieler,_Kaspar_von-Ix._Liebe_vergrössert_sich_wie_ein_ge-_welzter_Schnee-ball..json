{"dta.poem.21840": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "Ix.  \n  Liebe vergr\u00f6ssert sich/ wie ein ge-  \n welzter Schnee-ball.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Ich wil euch Wunder-Dinge sagen/", "tokens": ["Ich", "wil", "euch", "Wun\u00b7der\u00b7Din\u00b7ge", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wie sich die Liebe pflegt zujagen", "tokens": ["wie", "sich", "die", "Lie\u00b7be", "pflegt", "zu\u00b7ja\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "ART", "NN", "VVFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und w\u00e4chset jeden Augen-wink.", "tokens": ["und", "w\u00e4ch\u00b7set", "je\u00b7den", "Au\u00b7gen\u00b7wink", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Indehm sie wie ein Steubchen scheinet/", "tokens": ["In\u00b7dehm", "sie", "wie", "ein", "Steubc\u00b7hen", "schei\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOKOM", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "wird sie ein Berg/ eh man es meinet.", "tokens": ["wird", "sie", "ein", "Berg", "/", "eh", "man", "es", "mei\u00b7net", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$(", "KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ist dieses nicht ein Wunder-ding?", "tokens": ["Ist", "die\u00b7ses", "nicht", "ein", "Wun\u00b7der\u00b7ding", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "So bald die Jungfer wird gesehen/", "tokens": ["So", "bald", "die", "Jung\u00b7fer", "wird", "ge\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "pflegt man ihr k\u00fcnstlich nachzugehen.", "tokens": ["pflegt", "man", "ihr", "k\u00fcnst\u00b7lich", "nach\u00b7zu\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "ADJD", "VVIZU", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Kein einig Blikkchen streichet fort", "tokens": ["Kein", "ei\u00b7nig", "Blikk\u00b7chen", "strei\u00b7chet", "fort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJD", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df man sie listig zu bewegen/", "tokens": ["da\u00df", "man", "sie", "lis\u00b7tig", "zu", "be\u00b7we\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "nicht alles Orts ihr geh entgegen", "tokens": ["nicht", "al\u00b7les", "Orts", "ihr", "geh", "ent\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "PIAT", "NN", "PPER", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und wechsle Lieb und Liebes-wort\u2019.", "tokens": ["und", "wechs\u00b7le", "Lieb", "und", "Lie\u00b7bes\u00b7wort'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Auff Rede folget Wieder-rede.", "tokens": ["Auff", "Re\u00b7de", "fol\u00b7get", "Wie\u00b7der\u00b7re\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Weibes-bild ist je so bl\u00f6de/", "tokens": ["Kein", "Wei\u00b7bes\u00b7bild", "ist", "je", "so", "bl\u00f6\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADV", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die auff den Gru\u00df-nicht danken solt\u2019.", "tokens": ["die", "auff", "den", "Gru\u00df\u00b7nicht", "dan\u00b7ken", "solt'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Alsdenn (h\u00e4lt ja die Zunge feste)", "tokens": ["Als\u00b7denn", "(", "h\u00e4lt", "ja", "die", "Zun\u00b7ge", "fes\u00b7te", ")"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "VVFIN", "ADV", "ART", "NN", "ADJA", "$("], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "und zeuget/ was das Herz gewollt.", "tokens": ["und", "zeu\u00b7get", "/", "was", "das", "Herz", "ge\u00b7wollt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "PWS", "ART", "NN", "VMPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "So bald des Buhlers Weis\u2019 und Sitten", "tokens": ["So", "bald", "des", "Buh\u00b7lers", "Weis'", "und", "Sit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Sch\u00e4menden Gem\u00fcht bestritten/", "tokens": ["der", "Sch\u00e4\u00b7men\u00b7den", "Ge\u00b7m\u00fcht", "be\u00b7strit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und nu die Scheu wird schlecht geachtt.", "tokens": ["und", "nu", "die", "Scheu", "wird", "schlecht", "ge\u00b7achtt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem geht es an ein lieblen scherzen/", "tokens": ["Dem", "geht", "es", "an", "ein", "lieb\u00b7len", "scher\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "an Hand-Fu\u00df-drukken/ k\u00fcssen/ herzen/", "tokens": ["an", "Han\u00b7dFu\u00df\u00b7druk\u00b7ken", "/", "k\u00fcs\u00b7sen", "/", "her\u00b7zen", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$(", "VVINF", "$(", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So ist der rechte Grund gemacht.", "tokens": ["So", "ist", "der", "rech\u00b7te", "Grund", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Bald wird man mehr und mehr gemeine.", "tokens": ["Bald", "wird", "man", "mehr", "und", "mehr", "ge\u00b7mei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "KON", "PIAT", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Man achtet Ehr und Schande kleine.", "tokens": ["Man", "ach\u00b7tet", "Ehr", "und", "Schan\u00b7de", "klei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "KON", "NN", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das schlechtste heist: Ein Griff in Zucht.", "tokens": ["Das", "schlechts\u00b7te", "heist", ":", "Ein", "Griff", "in", "Zucht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was ferner folgt/ darff ich nicht singen/", "tokens": ["Was", "fer\u00b7ner", "folgt", "/", "darff", "ich", "nicht", "sin\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$(", "VMFIN", "PPER", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "es m\u00f6chte mich in Argwohn bringen/", "tokens": ["es", "m\u00f6ch\u00b7te", "mich", "in", "Arg\u00b7wohn", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "ich h\u00e4tt\u2019 es etwa selbst versucht.", "tokens": ["ich", "h\u00e4tt'", "es", "et\u00b7wa", "selbst", "ver\u00b7sucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}