{"dta.poem.875": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "LxII.  Auff den Sontag der in den letzten/  \n Weltzeiten sich/ begehenden Tr\u00fcbseligkeiten/  \n vnd dabey der Au\u00dferwehlten/ bey vnd in Christo em-  \n pfindenden S\u00fcssigkeiten: oder am 25. Sontag nach  \n dem Fest der H. Dreyeinigkeit/  Matth.  24.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Je l\u00e4nger jemand lebt/ auff diesem Rund der Erden/ ", "tokens": ["Je", "l\u00e4n\u00b7ger", "je\u00b7mand", "lebt", "/", "auff", "die\u00b7sem", "Rund", "der", "Er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PIS", "VVFIN", "$(", "APPR", "PDAT", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Je mehr er von der Welt empfindet Angst vnd Pein.", "tokens": ["Je", "mehr", "er", "von", "der", "Welt", "emp\u00b7fin\u00b7det", "Angst", "vnd", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "ART", "NN", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jetzt geht es so daher/ da\u00df auch die harten Stein/", "tokens": ["Jetzt", "geht", "es", "so", "da\u00b7her", "/", "da\u00df", "auch", "die", "har\u00b7ten", "Stein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PAV", "$(", "KOUS", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Balcken im Gesperr/ gleich trawrige Gebehrden", "tokens": ["Die", "Bal\u00b7cken", "im", "Ge\u00b7sperr", "/", "gleich", "traw\u00b7ri\u00b7ge", "Ge\u00b7behr\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "$(", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Vnd Klagelassen gehn. Die Gottes-H\u00e4user werden", "tokens": ["Vnd", "Kla\u00b7ge\u00b7las\u00b7sen", "gehn", ".", "Die", "Got\u00b7tes\u00b7H\u00e4u\u00b7ser", "wer\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "VVINF", "$.", "ART", "NN", "VAINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vergrewelt vnd entweiht. St\u00e4tt vnd auch L\u00e4nder seyn", "tokens": ["Ver\u00b7gre\u00b7welt", "vnd", "ent\u00b7weiht", ".", "St\u00e4tt", "vnd", "auch", "L\u00e4n\u00b7der", "seyn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "KON", "VVFIN", "$.", "NN", "KON", "ADV", "NN", "VAINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von Menschen au\u00df geleert. Mir zittert Marck vnd Bein/", "tokens": ["Von", "Men\u00b7schen", "au\u00df", "ge\u00b7leert", ".", "Mir", "zit\u00b7tert", "Marck", "vnd", "Bein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "VVPP", "$.", "PPER", "VVFIN", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn ich daran gedenck/ wie da\u00df mit Wag-vnd Pferden/", "tokens": ["Wenn", "ich", "da\u00b7ran", "ge\u00b7denck", "/", "wie", "da\u00df", "mit", "Wag\u00b7\u00b7vnd", "Pfer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "NN", "$(", "KOKOM", "KOUS", "APPR", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Das rasend-tolle Volck das Land hat vber h\u00e4ufft/", "tokens": ["Das", "ra\u00b7sen\u00b7dtol\u00b7le", "Volck", "das", "Land", "hat", "vber", "h\u00e4ufft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VAFIN", "APPR", "NN", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Oelend Jammer-Meer/ das so viel Leut ers\u00e4ufft.", "tokens": ["O\u00b7e\u00b7lend", "Jam\u00b7mer\u00b7Meer", "/", "das", "so", "viel", "Leut", "er\u00b7s\u00e4ufft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "PDS", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch/ Au\u00dferwehlte Schaar/ steh fest/ vnd nicht verzage/", "tokens": ["Doch", "/", "Au\u00b7\u00dfer\u00b7wehl\u00b7te", "Schaar", "/", "steh", "fest", "/", "vnd", "nicht", "ver\u00b7za\u00b7ge", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$(", "ADJA", "NN", "$(", "VVFIN", "PTKVZ", "$(", "KON", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Dein JESVS lebet noch; nim an die Adlers wei\u00df/", "tokens": ["Dein", "JeSVS", "le\u00b7bet", "noch", ";", "nim", "an", "die", "Ad\u00b7lers", "wei\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "ADV", "$.", "ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Zwing dich im Glauben auff vnd nach dem Himmel-rei\u00df.", "tokens": ["Zwing", "dich", "im", "Glau\u00b7ben", "auff", "vnd", "nach", "dem", "Him\u00b7mel\u00b7rei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "APPR", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da hastu tausend Frewd an statt empfundner Plage.", "tokens": ["Da", "has\u00b7tu", "tau\u00b7send", "Frewd", "an", "statt", "emp\u00b7fund\u00b7ner", "Pla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "CARD", "NN", "APPR", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}