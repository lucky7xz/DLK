{"textgrid.poem.57475": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ihr B\u00fcrger der gelehrten H\u00fcgel,", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr B\u00fcrger der gelehrten H\u00fcgel,", "tokens": ["Ihr", "B\u00fcr\u00b7ger", "der", "ge\u00b7lehr\u00b7ten", "H\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo vormals Witz und Geist entspro\u00df:", "tokens": ["Wo", "vor\u00b7mals", "Witz", "und", "Geist", "ent\u00b7spro\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo Pegasus mit schnellem Fl\u00fcgel", "tokens": ["Wo", "Pe\u00b7ga\u00b7sus", "mit", "schnel\u00b7lem", "Fl\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch die getheilten L\u00fcfte scho\u00df.", "tokens": ["Durch", "die", "ge\u00b7theil\u00b7ten", "L\u00fcf\u00b7te", "scho\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr Sch\u00fcler kluger Castalinnen,", "tokens": ["Ihr", "Sch\u00fc\u00b7ler", "klu\u00b7ger", "Cas\u00b7ta\u00b7lin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Seht uns nur nicht ver\u00e4chtlich an;", "tokens": ["Seht", "uns", "nur", "nicht", "ver\u00b7\u00e4cht\u00b7lich", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wi\u00dft, da\u00df auch unsrer Berge Zinnen", "tokens": ["Wi\u00dft", ",", "da\u00df", "auch", "uns\u00b7rer", "Ber\u00b7ge", "Zin\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sich euch zu Trotz hervorgethan:", "tokens": ["Sich", "euch", "zu", "Trotz", "her\u00b7vor\u00b7ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es quillt aus neuerfundnen K\u00fcnsten", "tokens": ["Es", "quillt", "aus", "neu\u00b7er\u00b7fund\u00b7nen", "K\u00fcns\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ein neuer Strom von Dichterd\u00fcnsten.", "tokens": ["Ein", "neu\u00b7er", "Strom", "von", "Dich\u00b7ter\u00b7d\u00fcns\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Du Vater, matter Pieriden!", "tokens": ["Du", "Va\u00b7ter", ",", "mat\u00b7ter", "Pie\u00b7ri\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "O H\u00fcbner, deiner Zeiten Preis!", "tokens": ["O", "H\u00fcb\u00b7ner", ",", "dei\u00b7ner", "Zei\u00b7ten", "Preis", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Komm, hilf mir seltne Reime schmieden,", "tokens": ["Komm", ",", "hilf", "mir", "selt\u00b7ne", "Rei\u00b7me", "schmie\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVIMP", "PPER", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil Ph\u00f6bus nicht den Kunstgriff weis.", "tokens": ["Weil", "Ph\u00f6\u00b7bus", "nicht", "den", "Kunst\u00b7griff", "weis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dein theures Handbuch sey mein Meister,", "tokens": ["Dein", "theu\u00b7res", "Hand\u00b7buch", "sey", "mein", "Meis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn Witz und Einfall mir entweicht:", "tokens": ["Wenn", "Witz", "und", "Ein\u00b7fall", "mir", "ent\u00b7weicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Denn du bereicherst ja die Geister,", "tokens": ["Denn", "du", "be\u00b7rei\u00b7cherst", "ja", "die", "Geis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die sich das Musenchor verscheucht.", "tokens": ["Die", "sich", "das", "Mu\u00b7sen\u00b7chor", "ver\u00b7scheucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Drum la\u00df aus weitgesuchten Reimen,", "tokens": ["Drum", "la\u00df", "aus", "weit\u00b7ge\u00b7such\u00b7ten", "Rei\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mir manchen fremden Ausdruck keimen!", "tokens": ["Mir", "man\u00b7chen", "frem\u00b7den", "Aus\u00b7druck", "kei\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Gepriesen sey dein Wortregister!", "tokens": ["Ge\u00b7prie\u00b7sen", "sey", "dein", "Wort\u00b7re\u00b7gis\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das uns der T\u00f6ne Sippschaft weist,", "tokens": ["Das", "uns", "der", "T\u00f6\u00b7ne", "Sipp\u00b7schaft", "weist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn man, wie Simson die Philister,", "tokens": ["Wenn", "man", ",", "wie", "Sim\u00b7son", "die", "Phi\u00b7lis\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PWAV", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die W\u00f6rter auf einander schmei\u00dft.", "tokens": ["Die", "W\u00f6r\u00b7ter", "auf", "ein\u00b7an\u00b7der", "schmei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erst bei\u00dft sich Bav die stumpfen N\u00e4gel,", "tokens": ["Erst", "bei\u00dft", "sich", "Bav", "die", "stump\u00b7fen", "N\u00e4\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NE", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sein Einfall stockt, sein Geist ist todt:", "tokens": ["Sein", "Ein\u00b7fall", "stockt", ",", "sein", "Geist", "ist", "todt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kaum bl\u00e4st dein Rath in seine Segel,", "tokens": ["Kaum", "bl\u00e4st", "dein", "Rath", "in", "sei\u00b7ne", "Se\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So lacht ihm schon ein Morgenroth,", "tokens": ["So", "lacht", "ihm", "schon", "ein", "Mor\u00b7gen\u00b7roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und kurz, er tr\u00e4gt die Hippokrene", "tokens": ["Und", "kurz", ",", "er", "tr\u00e4gt", "die", "Hip\u00b7po\u00b7kre\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Von deinem Alphabeth zu Lehne.", "tokens": ["Von", "dei\u00b7nem", "Al\u00b7pha\u00b7be\u00b7th", "zu", "Leh\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Wie mancher Geist wird in der Ode,", "tokens": ["Wie", "man\u00b7cher", "Geist", "wird", "in", "der", "O\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Darinn Verwirrung Tugend ist,", "tokens": ["Da\u00b7rinn", "Ver\u00b7wir\u00b7rung", "Tu\u00b7gend", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Im andern Absatz schon marode;", "tokens": ["Im", "an\u00b7dern", "Ab\u00b7satz", "schon", "ma\u00b7ro\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Wo du nicht sein Erretter bist.", "tokens": ["Wo", "du", "nicht", "sein", "Er\u00b7ret\u00b7ter", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKNEG", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Doch fragt er dich, als sein Orakel,", "tokens": ["Doch", "fragt", "er", "dich", ",", "als", "sein", "O\u00b7ra\u00b7kel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "$,", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "So flie\u00dft sein Vers, wie Rhodanus.", "tokens": ["So", "flie\u00dft", "sein", "Vers", ",", "wie", "Rho\u00b7da\u00b7nus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "PWAV", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und wenn Orbil, mit Ruth und Bakel,", "tokens": ["Und", "wenn", "Or\u00b7bil", ",", "mit", "Ruth", "und", "Ba\u00b7kel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Der Sch\u00fcler R\u00fccken gerben mu\u00df:", "tokens": ["Der", "Sch\u00fc\u00b7ler", "R\u00fc\u00b7cken", "ger\u00b7ben", "mu\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "So fehlt dem armen Schulminister", "tokens": ["So", "fehlt", "dem", "ar\u00b7men", "Schul\u00b7mi\u00b7nis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Nichts, als dein g\u00fcldnes Reimturnister.", "tokens": ["Nichts", ",", "als", "dein", "g\u00fcld\u00b7nes", "Reim\u00b7tur\u00b7nis\u00b7ter", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wie daurt ihr mich, ihr alten Dichter!", "tokens": ["Wie", "daurt", "ihr", "mich", ",", "ihr", "al\u00b7ten", "Dich\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Griechenland und Rom verkl\u00e4rt:", "tokens": ["Die", "Grie\u00b7chen\u00b7land", "und", "Rom", "ver\u00b7kl\u00e4rt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr reimtet nicht, drum hat kein Trichter", "tokens": ["Ihr", "reim\u00b7tet", "nicht", ",", "drum", "hat", "kein", "Trich\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PAV", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den leeren Schedeln Trost gew\u00e4hrt.", "tokens": ["Den", "lee\u00b7ren", "Sche\u00b7deln", "Trost", "ge\u00b7w\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch h\u00e4ttet ihr der Zeilen Schw\u00e4nze,", "tokens": ["Doch", "h\u00e4t\u00b7tet", "ihr", "der", "Zei\u00b7len", "Schw\u00e4n\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gleich jenen F\u00fcchsen, recht verkn\u00fcpft;", "tokens": ["Gleich", "je\u00b7nen", "F\u00fcch\u00b7sen", ",", "recht", "ver\u00b7kn\u00fcpft", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "$,", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So w\u00e4ren euch die Epheukr\u00e4nze", "tokens": ["So", "w\u00e4\u00b7ren", "euch", "die", "E\u00b7pheu\u00b7kr\u00e4n\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Von selbsten auf den Kopf geh\u00fcpft.", "tokens": ["Von", "selbs\u00b7ten", "auf", "den", "Kopf", "ge\u00b7h\u00fcpft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und den erkri\u00dfnen Weisheitsspr\u00fcchen", "tokens": ["Und", "den", "er\u00b7kri\u00df\u00b7nen", "Weis\u00b7heits\u00b7spr\u00fc\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "W\u00e4r auch die Pythia gewichen.", "tokens": ["W\u00e4r", "auch", "die", "Py\u00b7thia", "ge\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "---+--+-", "measure": "iambic.di.relaxed"}}, "stanza.5": {"line.1": {"text": "Ach schimpft nicht die Postillenreiter,", "tokens": ["Ach", "schimpft", "nicht", "die", "Pos\u00b7til\u00b7len\u00b7rei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Helden aus der Concordanz.", "tokens": ["Die", "Hel\u00b7den", "aus", "der", "Con\u00b7cor\u00b7danz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein neuer Poesie-Gefreyter", "tokens": ["Ein", "neu\u00b7er", "Po\u00b7e\u00b7sie\u00b7Ge\u00b7frey\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Sucht in den Reimen Witz und Glanz.", "tokens": ["Sucht", "in", "den", "Rei\u00b7men", "Witz", "und", "Glanz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er reitet H\u00fcbners Sylbenf\u00e4cher,", "tokens": ["Er", "rei\u00b7tet", "H\u00fcb\u00b7ners", "Syl\u00b7ben\u00b7f\u00e4\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die trifft er nie Gedankenleer:", "tokens": ["Die", "trifft", "er", "nie", "Ge\u00b7dan\u00b7ken\u00b7leer", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hier sch\u00f6pft er Witz mit vollem Becher,", "tokens": ["Hier", "sch\u00f6pft", "er", "Witz", "mit", "vol\u00b7lem", "Be\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So wird ihm kein Gedichte schwer.", "tokens": ["So", "wird", "ihm", "kein", "Ge\u00b7dich\u00b7te", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und sonder M\u00e4nnlings Vorrathskammern", "tokens": ["Und", "son\u00b7der", "M\u00e4nn\u00b7lings", "Vor\u00b7raths\u00b7kam\u00b7mern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ist jeder Dichter zu bejammern.", "tokens": ["Ist", "je\u00b7der", "Dich\u00b7ter", "zu", "be\u00b7jam\u00b7mern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Nur weg Vernunft, mit deinen Fesseln,", "tokens": ["Nur", "weg", "Ver\u00b7nunft", ",", "mit", "dei\u00b7nen", "Fes\u00b7seln", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Sie hindern freyer Geister Schwung.", "tokens": ["Sie", "hin\u00b7dern", "frey\u00b7er", "Geis\u00b7ter", "Schwung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "In deiner Schranken festen Sesseln", "tokens": ["In", "dei\u00b7ner", "Schran\u00b7ken", "fes\u00b7ten", "Ses\u00b7seln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Wagt niemand einen k\u00fchnen Sprung.", "tokens": ["Wagt", "nie\u00b7mand", "ei\u00b7nen", "k\u00fch\u00b7nen", "Sprung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ein feiger Knabe l\u00e4\u00dft sich g\u00e4ngeln;", "tokens": ["Ein", "fei\u00b7ger", "Kna\u00b7be", "l\u00e4\u00dft", "sich", "g\u00e4n\u00b7geln", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Ein starker Fu\u00df geht frisch einher.", "tokens": ["Ein", "star\u00b7ker", "Fu\u00df", "geht", "frisch", "ein\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Nur Icarus fliegt, gleich den Engeln,", "tokens": ["Nur", "I\u00b7ca\u00b7rus", "fliegt", ",", "gleich", "den", "En\u00b7geln", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.18": {"text": "Im Hohen \u00fcber Land und Meer.", "tokens": ["Im", "Ho\u00b7hen", "\u00fc\u00b7ber", "Land", "und", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "So mu\u00df man auch, auf H\u00fcbners Schwingen,", "tokens": ["So", "mu\u00df", "man", "auch", ",", "auf", "H\u00fcb\u00b7ners", "Schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "$,", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Bis an das blaue Sterndach dringen.", "tokens": ["Bis", "an", "das", "blau\u00b7e", "Stern\u00b7dach", "drin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Gesetzt ich schriebe von der Leyer,", "tokens": ["Ge\u00b7setzt", "ich", "schrie\u00b7be", "von", "der", "Le\u00b7yer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und w\u00fc\u00dfte weiter nicht, wohin?", "tokens": ["Und", "w\u00fc\u00df\u00b7te", "wei\u00b7ter", "nicht", ",", "wo\u00b7hin", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "$,", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein H\u00fcbner tr\u00e4nkt mich mit Tockeyer:", "tokens": ["Mein", "H\u00fcb\u00b7ner", "tr\u00e4nkt", "mich", "mit", "To\u00b7cke\u00b7yer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie froh wird da mein matter Sinn!", "tokens": ["Wie", "froh", "wird", "da", "mein", "mat\u00b7ter", "Sinn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gesetzt ich s\u00e4nge von der Cither,", "tokens": ["Ge\u00b7setzt", "ich", "s\u00e4n\u00b7ge", "von", "der", "Cit\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und stutzte gleichsam bey dem Reim:", "tokens": ["Und", "stutz\u00b7te", "gleich\u00b7sam", "bey", "dem", "Reim", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gleich br\u00e4chte H\u00fcbner mir ein Gitter,", "tokens": ["Gleich", "br\u00e4ch\u00b7te", "H\u00fcb\u00b7ner", "mir", "ein", "Git\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und labte mich mit Honigseim!", "tokens": ["Und", "lab\u00b7te", "mich", "mit", "Ho\u00b7ni\u00b7gseim", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ja k\u00e4m ich irgend auf die Musen:", "tokens": ["Ja", "k\u00e4m", "ich", "ir\u00b7gend", "auf", "die", "Mu\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So f\u00e4nd ich Trost an ihrem Busen.", "tokens": ["So", "f\u00e4nd", "ich", "Trost", "an", "ih\u00b7rem", "Bu\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Kurz, Reime sind der Dichter Fl\u00fcgel,", "tokens": ["Kurz", ",", "Rei\u00b7me", "sind", "der", "Dich\u00b7ter", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NN", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und kleiner Geister Steckenpferd,", "tokens": ["Und", "klei\u00b7ner", "Geis\u00b7ter", "Ste\u00b7cken\u00b7pferd", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Stuffen zu dem Pindush\u00fcgel,", "tokens": ["Die", "Stuf\u00b7fen", "zu", "dem", "Pin\u00b7dus\u00b7h\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und der Gedanken Vogelheerd.", "tokens": ["Und", "der", "Ge\u00b7dan\u00b7ken", "Vo\u00b7gel\u00b7heerd", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sind des hohen Geistes Eimer;", "tokens": ["Sie", "sind", "des", "ho\u00b7hen", "Geis\u00b7tes", "Ei\u00b7mer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Netz, so manchen Einfall f\u00e4ngt,", "tokens": ["Ein", "Netz", ",", "so", "man\u00b7chen", "Ein\u00b7fall", "f\u00e4ngt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dadurch ein wohlge\u00fcbter Reimer", "tokens": ["Da\u00b7durch", "ein", "wohl\u00b7ge\u00b7\u00fcb\u00b7ter", "Rei\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Fast alles in die Zeilen dr\u00e4ngt;", "tokens": ["Fast", "al\u00b7les", "in", "die", "Zei\u00b7len", "dr\u00e4ngt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und will kein Fl\u00fcgelro\u00df dir traben:", "tokens": ["Und", "will", "kein", "Fl\u00fc\u00b7gel\u00b7ro\u00df", "dir", "tra\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So kannst du Witz aus H\u00fcbnern graben.", "tokens": ["So", "kannst", "du", "Witz", "aus", "H\u00fcb\u00b7nern", "gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ihr B\u00fcrger der gelehrten H\u00fcgel,", "tokens": ["Ihr", "B\u00fcr\u00b7ger", "der", "ge\u00b7lehr\u00b7ten", "H\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo vormals Witz und Geist entspro\u00df:", "tokens": ["Wo", "vor\u00b7mals", "Witz", "und", "Geist", "ent\u00b7spro\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo Pegasus mit schnellem Fl\u00fcgel", "tokens": ["Wo", "Pe\u00b7ga\u00b7sus", "mit", "schnel\u00b7lem", "Fl\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch die getheilten L\u00fcfte scho\u00df.", "tokens": ["Durch", "die", "ge\u00b7theil\u00b7ten", "L\u00fcf\u00b7te", "scho\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr Sch\u00fcler kluger Castalinnen,", "tokens": ["Ihr", "Sch\u00fc\u00b7ler", "klu\u00b7ger", "Cas\u00b7ta\u00b7lin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Seht uns nur nicht ver\u00e4chtlich an;", "tokens": ["Seht", "uns", "nur", "nicht", "ver\u00b7\u00e4cht\u00b7lich", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wi\u00dft, da\u00df auch unsrer Berge Zinnen", "tokens": ["Wi\u00dft", ",", "da\u00df", "auch", "uns\u00b7rer", "Ber\u00b7ge", "Zin\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sich euch zu Trotz hervorgethan:", "tokens": ["Sich", "euch", "zu", "Trotz", "her\u00b7vor\u00b7ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es quillt aus neuerfundnen K\u00fcnsten", "tokens": ["Es", "quillt", "aus", "neu\u00b7er\u00b7fund\u00b7nen", "K\u00fcns\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ein neuer Strom von Dichterd\u00fcnsten.", "tokens": ["Ein", "neu\u00b7er", "Strom", "von", "Dich\u00b7ter\u00b7d\u00fcns\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Du Vater, matter Pieriden!", "tokens": ["Du", "Va\u00b7ter", ",", "mat\u00b7ter", "Pie\u00b7ri\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "O H\u00fcbner, deiner Zeiten Preis!", "tokens": ["O", "H\u00fcb\u00b7ner", ",", "dei\u00b7ner", "Zei\u00b7ten", "Preis", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Komm, hilf mir seltne Reime schmieden,", "tokens": ["Komm", ",", "hilf", "mir", "selt\u00b7ne", "Rei\u00b7me", "schmie\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVIMP", "PPER", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil Ph\u00f6bus nicht den Kunstgriff weis.", "tokens": ["Weil", "Ph\u00f6\u00b7bus", "nicht", "den", "Kunst\u00b7griff", "weis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dein theures Handbuch sey mein Meister,", "tokens": ["Dein", "theu\u00b7res", "Hand\u00b7buch", "sey", "mein", "Meis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn Witz und Einfall mir entweicht:", "tokens": ["Wenn", "Witz", "und", "Ein\u00b7fall", "mir", "ent\u00b7weicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Denn du bereicherst ja die Geister,", "tokens": ["Denn", "du", "be\u00b7rei\u00b7cherst", "ja", "die", "Geis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die sich das Musenchor verscheucht.", "tokens": ["Die", "sich", "das", "Mu\u00b7sen\u00b7chor", "ver\u00b7scheucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Drum la\u00df aus weitgesuchten Reimen,", "tokens": ["Drum", "la\u00df", "aus", "weit\u00b7ge\u00b7such\u00b7ten", "Rei\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mir manchen fremden Ausdruck keimen!", "tokens": ["Mir", "man\u00b7chen", "frem\u00b7den", "Aus\u00b7druck", "kei\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Gepriesen sey dein Wortregister!", "tokens": ["Ge\u00b7prie\u00b7sen", "sey", "dein", "Wort\u00b7re\u00b7gis\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das uns der T\u00f6ne Sippschaft weist,", "tokens": ["Das", "uns", "der", "T\u00f6\u00b7ne", "Sipp\u00b7schaft", "weist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn man, wie Simson die Philister,", "tokens": ["Wenn", "man", ",", "wie", "Sim\u00b7son", "die", "Phi\u00b7lis\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PWAV", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die W\u00f6rter auf einander schmei\u00dft.", "tokens": ["Die", "W\u00f6r\u00b7ter", "auf", "ein\u00b7an\u00b7der", "schmei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erst bei\u00dft sich Bav die stumpfen N\u00e4gel,", "tokens": ["Erst", "bei\u00dft", "sich", "Bav", "die", "stump\u00b7fen", "N\u00e4\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NE", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sein Einfall stockt, sein Geist ist todt:", "tokens": ["Sein", "Ein\u00b7fall", "stockt", ",", "sein", "Geist", "ist", "todt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kaum bl\u00e4st dein Rath in seine Segel,", "tokens": ["Kaum", "bl\u00e4st", "dein", "Rath", "in", "sei\u00b7ne", "Se\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So lacht ihm schon ein Morgenroth,", "tokens": ["So", "lacht", "ihm", "schon", "ein", "Mor\u00b7gen\u00b7roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und kurz, er tr\u00e4gt die Hippokrene", "tokens": ["Und", "kurz", ",", "er", "tr\u00e4gt", "die", "Hip\u00b7po\u00b7kre\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Von deinem Alphabeth zu Lehne.", "tokens": ["Von", "dei\u00b7nem", "Al\u00b7pha\u00b7be\u00b7th", "zu", "Leh\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Wie mancher Geist wird in der Ode,", "tokens": ["Wie", "man\u00b7cher", "Geist", "wird", "in", "der", "O\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Darinn Verwirrung Tugend ist,", "tokens": ["Da\u00b7rinn", "Ver\u00b7wir\u00b7rung", "Tu\u00b7gend", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Im andern Absatz schon marode;", "tokens": ["Im", "an\u00b7dern", "Ab\u00b7satz", "schon", "ma\u00b7ro\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Wo du nicht sein Erretter bist.", "tokens": ["Wo", "du", "nicht", "sein", "Er\u00b7ret\u00b7ter", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKNEG", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Doch fragt er dich, als sein Orakel,", "tokens": ["Doch", "fragt", "er", "dich", ",", "als", "sein", "O\u00b7ra\u00b7kel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "$,", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "So flie\u00dft sein Vers, wie Rhodanus.", "tokens": ["So", "flie\u00dft", "sein", "Vers", ",", "wie", "Rho\u00b7da\u00b7nus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "PWAV", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und wenn Orbil, mit Ruth und Bakel,", "tokens": ["Und", "wenn", "Or\u00b7bil", ",", "mit", "Ruth", "und", "Ba\u00b7kel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Der Sch\u00fcler R\u00fccken gerben mu\u00df:", "tokens": ["Der", "Sch\u00fc\u00b7ler", "R\u00fc\u00b7cken", "ger\u00b7ben", "mu\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "So fehlt dem armen Schulminister", "tokens": ["So", "fehlt", "dem", "ar\u00b7men", "Schul\u00b7mi\u00b7nis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Nichts, als dein g\u00fcldnes Reimturnister.", "tokens": ["Nichts", ",", "als", "dein", "g\u00fcld\u00b7nes", "Reim\u00b7tur\u00b7nis\u00b7ter", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Wie daurt ihr mich, ihr alten Dichter!", "tokens": ["Wie", "daurt", "ihr", "mich", ",", "ihr", "al\u00b7ten", "Dich\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Griechenland und Rom verkl\u00e4rt:", "tokens": ["Die", "Grie\u00b7chen\u00b7land", "und", "Rom", "ver\u00b7kl\u00e4rt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr reimtet nicht, drum hat kein Trichter", "tokens": ["Ihr", "reim\u00b7tet", "nicht", ",", "drum", "hat", "kein", "Trich\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PAV", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den leeren Schedeln Trost gew\u00e4hrt.", "tokens": ["Den", "lee\u00b7ren", "Sche\u00b7deln", "Trost", "ge\u00b7w\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch h\u00e4ttet ihr der Zeilen Schw\u00e4nze,", "tokens": ["Doch", "h\u00e4t\u00b7tet", "ihr", "der", "Zei\u00b7len", "Schw\u00e4n\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gleich jenen F\u00fcchsen, recht verkn\u00fcpft;", "tokens": ["Gleich", "je\u00b7nen", "F\u00fcch\u00b7sen", ",", "recht", "ver\u00b7kn\u00fcpft", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "$,", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So w\u00e4ren euch die Epheukr\u00e4nze", "tokens": ["So", "w\u00e4\u00b7ren", "euch", "die", "E\u00b7pheu\u00b7kr\u00e4n\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Von selbsten auf den Kopf geh\u00fcpft.", "tokens": ["Von", "selbs\u00b7ten", "auf", "den", "Kopf", "ge\u00b7h\u00fcpft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und den erkri\u00dfnen Weisheitsspr\u00fcchen", "tokens": ["Und", "den", "er\u00b7kri\u00df\u00b7nen", "Weis\u00b7heits\u00b7spr\u00fc\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "W\u00e4r auch die Pythia gewichen.", "tokens": ["W\u00e4r", "auch", "die", "Py\u00b7thia", "ge\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "---+--+-", "measure": "iambic.di.relaxed"}}, "stanza.12": {"line.1": {"text": "Ach schimpft nicht die Postillenreiter,", "tokens": ["Ach", "schimpft", "nicht", "die", "Pos\u00b7til\u00b7len\u00b7rei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Helden aus der Concordanz.", "tokens": ["Die", "Hel\u00b7den", "aus", "der", "Con\u00b7cor\u00b7danz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein neuer Poesie-Gefreyter", "tokens": ["Ein", "neu\u00b7er", "Po\u00b7e\u00b7sie\u00b7Ge\u00b7frey\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Sucht in den Reimen Witz und Glanz.", "tokens": ["Sucht", "in", "den", "Rei\u00b7men", "Witz", "und", "Glanz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er reitet H\u00fcbners Sylbenf\u00e4cher,", "tokens": ["Er", "rei\u00b7tet", "H\u00fcb\u00b7ners", "Syl\u00b7ben\u00b7f\u00e4\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die trifft er nie Gedankenleer:", "tokens": ["Die", "trifft", "er", "nie", "Ge\u00b7dan\u00b7ken\u00b7leer", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hier sch\u00f6pft er Witz mit vollem Becher,", "tokens": ["Hier", "sch\u00f6pft", "er", "Witz", "mit", "vol\u00b7lem", "Be\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So wird ihm kein Gedichte schwer.", "tokens": ["So", "wird", "ihm", "kein", "Ge\u00b7dich\u00b7te", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und sonder M\u00e4nnlings Vorrathskammern", "tokens": ["Und", "son\u00b7der", "M\u00e4nn\u00b7lings", "Vor\u00b7raths\u00b7kam\u00b7mern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ist jeder Dichter zu bejammern.", "tokens": ["Ist", "je\u00b7der", "Dich\u00b7ter", "zu", "be\u00b7jam\u00b7mern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Nur weg Vernunft, mit deinen Fesseln,", "tokens": ["Nur", "weg", "Ver\u00b7nunft", ",", "mit", "dei\u00b7nen", "Fes\u00b7seln", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Sie hindern freyer Geister Schwung.", "tokens": ["Sie", "hin\u00b7dern", "frey\u00b7er", "Geis\u00b7ter", "Schwung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "In deiner Schranken festen Sesseln", "tokens": ["In", "dei\u00b7ner", "Schran\u00b7ken", "fes\u00b7ten", "Ses\u00b7seln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Wagt niemand einen k\u00fchnen Sprung.", "tokens": ["Wagt", "nie\u00b7mand", "ei\u00b7nen", "k\u00fch\u00b7nen", "Sprung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ein feiger Knabe l\u00e4\u00dft sich g\u00e4ngeln;", "tokens": ["Ein", "fei\u00b7ger", "Kna\u00b7be", "l\u00e4\u00dft", "sich", "g\u00e4n\u00b7geln", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Ein starker Fu\u00df geht frisch einher.", "tokens": ["Ein", "star\u00b7ker", "Fu\u00df", "geht", "frisch", "ein\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Nur Icarus fliegt, gleich den Engeln,", "tokens": ["Nur", "I\u00b7ca\u00b7rus", "fliegt", ",", "gleich", "den", "En\u00b7geln", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.18": {"text": "Im Hohen \u00fcber Land und Meer.", "tokens": ["Im", "Ho\u00b7hen", "\u00fc\u00b7ber", "Land", "und", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "So mu\u00df man auch, auf H\u00fcbners Schwingen,", "tokens": ["So", "mu\u00df", "man", "auch", ",", "auf", "H\u00fcb\u00b7ners", "Schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "$,", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Bis an das blaue Sterndach dringen.", "tokens": ["Bis", "an", "das", "blau\u00b7e", "Stern\u00b7dach", "drin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Gesetzt ich schriebe von der Leyer,", "tokens": ["Ge\u00b7setzt", "ich", "schrie\u00b7be", "von", "der", "Le\u00b7yer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und w\u00fc\u00dfte weiter nicht, wohin?", "tokens": ["Und", "w\u00fc\u00df\u00b7te", "wei\u00b7ter", "nicht", ",", "wo\u00b7hin", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "$,", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein H\u00fcbner tr\u00e4nkt mich mit Tockeyer:", "tokens": ["Mein", "H\u00fcb\u00b7ner", "tr\u00e4nkt", "mich", "mit", "To\u00b7cke\u00b7yer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie froh wird da mein matter Sinn!", "tokens": ["Wie", "froh", "wird", "da", "mein", "mat\u00b7ter", "Sinn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gesetzt ich s\u00e4nge von der Cither,", "tokens": ["Ge\u00b7setzt", "ich", "s\u00e4n\u00b7ge", "von", "der", "Cit\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und stutzte gleichsam bey dem Reim:", "tokens": ["Und", "stutz\u00b7te", "gleich\u00b7sam", "bey", "dem", "Reim", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gleich br\u00e4chte H\u00fcbner mir ein Gitter,", "tokens": ["Gleich", "br\u00e4ch\u00b7te", "H\u00fcb\u00b7ner", "mir", "ein", "Git\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und labte mich mit Honigseim!", "tokens": ["Und", "lab\u00b7te", "mich", "mit", "Ho\u00b7ni\u00b7gseim", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ja k\u00e4m ich irgend auf die Musen:", "tokens": ["Ja", "k\u00e4m", "ich", "ir\u00b7gend", "auf", "die", "Mu\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So f\u00e4nd ich Trost an ihrem Busen.", "tokens": ["So", "f\u00e4nd", "ich", "Trost", "an", "ih\u00b7rem", "Bu\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Kurz, Reime sind der Dichter Fl\u00fcgel,", "tokens": ["Kurz", ",", "Rei\u00b7me", "sind", "der", "Dich\u00b7ter", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NN", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und kleiner Geister Steckenpferd,", "tokens": ["Und", "klei\u00b7ner", "Geis\u00b7ter", "Ste\u00b7cken\u00b7pferd", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Stuffen zu dem Pindush\u00fcgel,", "tokens": ["Die", "Stuf\u00b7fen", "zu", "dem", "Pin\u00b7dus\u00b7h\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und der Gedanken Vogelheerd.", "tokens": ["Und", "der", "Ge\u00b7dan\u00b7ken", "Vo\u00b7gel\u00b7heerd", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sind des hohen Geistes Eimer;", "tokens": ["Sie", "sind", "des", "ho\u00b7hen", "Geis\u00b7tes", "Ei\u00b7mer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Netz, so manchen Einfall f\u00e4ngt,", "tokens": ["Ein", "Netz", ",", "so", "man\u00b7chen", "Ein\u00b7fall", "f\u00e4ngt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dadurch ein wohlge\u00fcbter Reimer", "tokens": ["Da\u00b7durch", "ein", "wohl\u00b7ge\u00b7\u00fcb\u00b7ter", "Rei\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Fast alles in die Zeilen dr\u00e4ngt;", "tokens": ["Fast", "al\u00b7les", "in", "die", "Zei\u00b7len", "dr\u00e4ngt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und will kein Fl\u00fcgelro\u00df dir traben:", "tokens": ["Und", "will", "kein", "Fl\u00fc\u00b7gel\u00b7ro\u00df", "dir", "tra\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So kannst du Witz aus H\u00fcbnern graben.", "tokens": ["So", "kannst", "du", "Witz", "aus", "H\u00fcb\u00b7nern", "gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}