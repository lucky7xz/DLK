{"textgrid.poem.60753": {"metadata": {"author": {"name": "Platen, August von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich m\u00f6chte wieder wie ein junger Schw\u00e4rmer", "genre": "verse", "period": "N.A.", "pub_year": 1829, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich m\u00f6chte wieder wie ein junger Schw\u00e4rmer", "tokens": ["Ich", "m\u00f6ch\u00b7te", "wie\u00b7der", "wie", "ein", "jun\u00b7ger", "Schw\u00e4r\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf meinem Pegasus ein bi\u00dfchen reiten,", "tokens": ["Auf", "mei\u00b7nem", "Pe\u00b7ga\u00b7sus", "ein", "bi\u00df\u00b7chen", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch da die Zeit betr\u00fcbter wird und \u00e4rmer,", "tokens": ["Doch", "da", "die", "Zeit", "be\u00b7tr\u00fcb\u00b7ter", "wird", "und", "\u00e4r\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADJD", "VAFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So m\u00f6cht ich fliehn in fabelhafte Zeiten:", "tokens": ["So", "m\u00f6cht", "ich", "fliehn", "in", "fa\u00b7bel\u00b7haf\u00b7te", "Zei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich, der ich ehedem, an Jugend w\u00e4rmer,", "tokens": ["Ich", ",", "der", "ich", "e\u00b7he\u00b7dem", ",", "an", "Ju\u00b7gend", "w\u00e4r\u00b7mer", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "ADV", "$,", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Herunterstieg in spr\u00f6de Wirklichkeiten,", "tokens": ["Her\u00b7un\u00b7ter\u00b7stieg", "in", "spr\u00f6\u00b7de", "Wirk\u00b7lich\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und mit dem Unverstand begann zu turnen,", "tokens": ["Und", "mit", "dem", "Un\u00b7ver\u00b7stand", "be\u00b7gann", "zu", "tur\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Der stelzenhaft gespreizt sich auf Kothurnen.", "tokens": ["Der", "stel\u00b7zen\u00b7haft", "ge\u00b7spreizt", "sich", "auf", "Ko\u00b7thur\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ihr wendet weg von jenem Volk der Zwitter", "tokens": ["Ihr", "wen\u00b7det", "weg", "von", "je\u00b7nem", "Volk", "der", "Zwit\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PDAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die m\u00fcden Augen und ich mu\u00df es preisen,", "tokens": ["Die", "m\u00fc\u00b7den", "Au\u00b7gen", "und", "ich", "mu\u00df", "es", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "PPER", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und will, da viele mich verschrien als bitter,", "tokens": ["Und", "will", ",", "da", "vie\u00b7le", "mich", "ver\u00b7schri\u00b7en", "als", "bit\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Euch meine S\u00fc\u00dfigkeit einmal beweisen:", "tokens": ["Euch", "mei\u00b7ne", "S\u00fc\u00b7\u00dfig\u00b7keit", "ein\u00b7mal", "be\u00b7wei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Sonne bring ich nach dem Ungewitter,", "tokens": ["Die", "Son\u00b7ne", "bring", "ich", "nach", "dem", "Un\u00b7ge\u00b7wit\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Einladend euch, mit mir ein St\u00fcck zu reisen,", "tokens": ["Ein\u00b7la\u00b7dend", "euch", ",", "mit", "mir", "ein", "St\u00fcck", "zu", "rei\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "$,", "APPR", "PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ein M\u00e4rchen aus dem Orient zu lesen,", "tokens": ["Ein", "M\u00e4r\u00b7chen", "aus", "dem", "O\u00b7rient", "zu", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Der meiner Jugend schon so lieb gewesen!", "tokens": ["Der", "mei\u00b7ner", "Ju\u00b7gend", "schon", "so", "lieb", "ge\u00b7we\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "ADV", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und weil mir vorgeworfen ward, es w\u00e4re", "tokens": ["Und", "weil", "mir", "vor\u00b7ge\u00b7wor\u00b7fen", "ward", ",", "es", "w\u00e4\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVPP", "VAFIN", "$,", "PPER", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mein Vers zu gut f\u00fcr eure bl\u00f6den Ohren,", "tokens": ["Mein", "Vers", "zu", "gut", "f\u00fcr", "eu\u00b7re", "bl\u00f6\u00b7den", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKA", "ADJD", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und allzukunstreich meine ganze Sph\u00e4re,", "tokens": ["Und", "all\u00b7zu\u00b7kun\u00b7streich", "mei\u00b7ne", "gan\u00b7ze", "Sph\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil euch der Wein behagt unausgegoren,", "tokens": ["Weil", "euch", "der", "Wein", "be\u00b7hagt", "un\u00b7aus\u00b7ge\u00b7go\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Den sonst ich gern wohl durch Gedanken kl\u00e4re,", "tokens": ["Den", "sonst", "ich", "gern", "wohl", "durch", "Ge\u00b7dan\u00b7ken", "kl\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPER", "ADV", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So hab ich diesmal ein Gewand erkoren,", "tokens": ["So", "hab", "ich", "dies\u00b7mal", "ein", "Ge\u00b7wand", "er\u00b7ko\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ganz schlicht und einfach und bequem zu fassen,", "tokens": ["Ganz", "schlicht", "und", "ein\u00b7fach", "und", "be\u00b7quem", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Das kaum verh\u00fcllt den Stoff in keusche Massen.", "tokens": ["Das", "kaum", "ver\u00b7h\u00fcllt", "den", "Stoff", "in", "keu\u00b7sche", "Mas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Auch mir zuweilen macht's ein bi\u00dfchen Galle,", "tokens": ["Auch", "mir", "zu\u00b7wei\u00b7len", "macht's", "ein", "bi\u00df\u00b7chen", "Gal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df ich so wenig noch getan auf Erden,", "tokens": ["Da\u00df", "ich", "so", "we\u00b7nig", "noch", "ge\u00b7tan", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn ich euch im Ganzen nicht gefalle,", "tokens": ["Und", "wenn", "ich", "euch", "im", "Gan\u00b7zen", "nicht", "ge\u00b7fal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "APPRART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So f\u00fchr ich deshalb keineswegs Beschwerden;", "tokens": ["So", "f\u00fchr", "ich", "des\u00b7halb", "kei\u00b7nes\u00b7wegs", "Be\u00b7schwer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Doch w\u00fcnscht ich manchmal, wie die Andern alle,", "tokens": ["Doch", "w\u00fcnscht", "ich", "manch\u00b7mal", ",", "wie", "die", "An\u00b7dern", "al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "PWAV", "ART", "ADJA", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Zu euren Klassikern gez\u00e4hlt zu werden:", "tokens": ["Zu", "eu\u00b7ren", "Klas\u00b7si\u00b7kern", "ge\u00b7z\u00e4hlt", "zu", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die Ehre freilich ist ein bi\u00dfchen mager,", "tokens": ["Die", "Eh\u00b7re", "frei\u00b7lich", "ist", "ein", "bi\u00df\u00b7chen", "ma\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Denn wer ins H\u00f6rn bl\u00e4st, hei\u00dft sogleich ein Schwager.", "tokens": ["Denn", "wer", "ins", "H\u00f6rn", "bl\u00e4st", ",", "hei\u00dft", "sog\u00b7leich", "ein", "Schwa\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPRART", "NN", "VVFIN", "$,", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Drum hab ich euch dies neue Lied gesponnen,", "tokens": ["Drum", "hab", "ich", "euch", "dies", "neu\u00b7e", "Lied", "ge\u00b7spon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PPER", "PDS", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das weder Zeit mir noch Kritik verheere;", "tokens": ["Das", "we\u00b7der", "Zeit", "mir", "noch", "Kri\u00b7tik", "ver\u00b7hee\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "NN", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es ist, wofern mir unter w\u00e4rmern Sonnen", "tokens": ["Es", "ist", ",", "wo\u00b7fern", "mir", "un\u00b7ter", "w\u00e4r\u00b7mern", "Son\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gereift ein Lorbeer, seine reifste Beere:", "tokens": ["Ge\u00b7reift", "ein", "Lor\u00b7beer", ",", "sei\u00b7ne", "reifs\u00b7te", "Bee\u00b7re", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Im alten Siena hab ich's ausgesonnen;", "tokens": ["Im", "al\u00b7ten", "Sie\u00b7na", "hab", "ich's", "aus\u00b7ge\u00b7son\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NE", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und dann mit mir geschleppt an beide Meere;", "tokens": ["Und", "dann", "mit", "mir", "ge\u00b7schleppt", "an", "bei\u00b7de", "Mee\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPER", "VVPP", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und schlepp ich's weiter, bitt ich nicht zu staunen;", "tokens": ["Und", "schlepp", "ich's", "wei\u00b7ter", ",", "bitt", "ich", "nicht", "zu", "stau\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PTKVZ", "$,", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Denn h\u00e4ufig wechseln meine Reiselaunen.", "tokens": ["Denn", "h\u00e4u\u00b7fig", "wech\u00b7seln", "mei\u00b7ne", "Rei\u00b7se\u00b7lau\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Und weil so mancherlei den Geist verf\u00fchret,", "tokens": ["Und", "weil", "so", "man\u00b7cher\u00b7lei", "den", "Geist", "ver\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So wechsl' ich Aufenthalte gern und Ziele,", "tokens": ["So", "wechsl'", "ich", "Auf\u00b7ent\u00b7hal\u00b7te", "gern", "und", "Zie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "VVFIN", "ADV", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und unter Welschlands Firmament geb\u00fchret", "tokens": ["Und", "un\u00b7ter", "Wel\u00b7schlands", "Fir\u00b7ma\u00b7ment", "ge\u00b7b\u00fch\u00b7ret"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PWAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein bi\u00dfchen Tr\u00e4gheit, das bezeugen Viele:", "tokens": ["Ein", "bi\u00df\u00b7chen", "Tr\u00e4g\u00b7heit", ",", "das", "be\u00b7zeu\u00b7gen", "Vie\u00b7le", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PDS", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich habe mehr gedacht als ausgef\u00fchret,", "tokens": ["Ich", "ha\u00b7be", "mehr", "ge\u00b7dacht", "als", "aus\u00b7ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "KOKOM", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und h\u00e4tt ich alle jene Trauerspiele,", "tokens": ["Und", "h\u00e4tt", "ich", "al\u00b7le", "je\u00b7ne", "Trau\u00b7er\u00b7spie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIAT", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Zu denen ich den Plan gemacht, geschrieben,", "tokens": ["Zu", "de\u00b7nen", "ich", "den", "Plan", "ge\u00b7macht", ",", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ich w\u00e4re nicht so unber\u00fchmt geblieben!", "tokens": ["Ich", "w\u00e4\u00b7re", "nicht", "so", "un\u00b7be\u00b7r\u00fchmt", "ge\u00b7blie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Nie kann der Mensch, wieviel er auch vollende,", "tokens": ["Nie", "kann", "der", "Mensch", ",", "wie\u00b7viel", "er", "auch", "voll\u00b7en\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "$,", "PWAV", "PPER", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie k\u00fchn er sei, sich zeigen als ein Ganzes,", "tokens": ["Wie", "k\u00fchn", "er", "sei", ",", "sich", "zei\u00b7gen", "als", "ein", "Gan\u00b7zes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VAFIN", "$,", "PRF", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und was er ausf\u00fchrt, Gleicht es nicht am Ende", "tokens": ["Und", "was", "er", "aus\u00b7f\u00fchrt", ",", "Gleicht", "es", "nicht", "am", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "VVPP", "$,", "VVFIN", "PPER", "PTKNEG", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zerstreuten Blumen eines gro\u00dfen Kranzes?", "tokens": ["Zer\u00b7streu\u00b7ten", "Blu\u00b7men", "ei\u00b7nes", "gro\u00b7\u00dfen", "Kran\u00b7zes", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Drum Heil den Dichtern, deren reicher Spende", "tokens": ["Drum", "Heil", "den", "Dich\u00b7tern", ",", "de\u00b7ren", "rei\u00b7cher", "Spen\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "NN", "ART", "NN", "$,", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Deutschland verdankt den Gipfel seines Glanzes,", "tokens": ["Deutschland", "ver\u00b7dankt", "den", "Gip\u00b7fel", "sei\u00b7nes", "Glan\u00b7zes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Die nie mit Denken ihre Zeit verputzen,", "tokens": ["Die", "nie", "mit", "Den\u00b7ken", "ih\u00b7re", "Zeit", "ver\u00b7put\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und statt des Geistes blo\u00df die Feder nutzen!", "tokens": ["Und", "statt", "des", "Geis\u00b7tes", "blo\u00df", "die", "Fe\u00b7der", "nut\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Und will Begeistrung ihnen nicht erscheinen,", "tokens": ["Und", "will", "Be\u00b7geis\u00b7trung", "ih\u00b7nen", "nicht", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So hilft die Mokkafrucht, so hilft die Rebe:", "tokens": ["So", "hilft", "die", "Mok\u00b7ka\u00b7frucht", ",", "so", "hilft", "die", "Re\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Vom Trunk erhitzt und auf gel\u00e4hmten Beinen", "tokens": ["Vom", "Trunk", "er\u00b7hitzt", "und", "auf", "ge\u00b7l\u00e4hm\u00b7ten", "Bei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "H\u00e4lt sich der deutsche Pindus in der Schwebe;", "tokens": ["H\u00e4lt", "sich", "der", "deut\u00b7sche", "Pin\u00b7dus", "in", "der", "Schwe\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich z\u00e4hle mich hingegen zu den kleinen", "tokens": ["Ich", "z\u00e4h\u00b7le", "mich", "hin\u00b7ge\u00b7gen", "zu", "den", "klei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Poeten, der ich m\u00e4\u00dfig bin, und gebe", "tokens": ["Po\u00b7et\u00b7en", ",", "der", "ich", "m\u00e4\u00b7\u00dfig", "bin", ",", "und", "ge\u00b7be"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Mich ganz und gar f\u00fcr einen schlechten Prasser:", "tokens": ["Mich", "ganz", "und", "gar", "f\u00fcr", "ei\u00b7nen", "schlech\u00b7ten", "Pras\u00b7ser", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KON", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Auch misch ich t\u00e4glich meinen Wein mit Wasser.", "tokens": ["Auch", "misch", "ich", "t\u00e4g\u00b7lich", "mei\u00b7nen", "Wein", "mit", "Was\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADJD", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Drum konnt ich wenig eure Gunst gewinnen,", "tokens": ["Drum", "konnt", "ich", "we\u00b7nig", "eu\u00b7re", "Gunst", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Entz\u00fcnde nicht, da selbst ich nicht entz\u00fcndet,", "tokens": ["Ent\u00b7z\u00fcn\u00b7de", "nicht", ",", "da", "selbst", "ich", "nicht", "ent\u00b7z\u00fcn\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "KOUS", "ADV", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da meine Musen, als Begleiterinnen", "tokens": ["Da", "mei\u00b7ne", "Mu\u00b7sen", ",", "als", "Be\u00b7glei\u00b7te\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "KOUS", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Des Wahren, nie dem P\u00f6bel sich verb\u00fcndet.", "tokens": ["Des", "Wah\u00b7ren", ",", "nie", "dem", "P\u00f6\u00b7bel", "sich", "ver\u00b7b\u00fcn\u00b7det", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ART", "NN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es war ein allzu jugendlich Beginnen,", "tokens": ["Es", "war", "ein", "all\u00b7zu", "ju\u00b7gend\u00b7lich", "Be\u00b7gin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PTKA", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df ich, wie Joseph, meinen Traum verk\u00fcndet;", "tokens": ["Da\u00df", "ich", ",", "wie", "Jo\u00b7se\u00b7ph", ",", "mei\u00b7nen", "Traum", "ver\u00b7k\u00fcn\u00b7det", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PWAV", "NE", "$,", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Draus hat sich mir der Br\u00fcder Neid entsponnen,", "tokens": ["Draus", "hat", "sich", "mir", "der", "Br\u00fc\u00b7der", "Neid", "ent\u00b7spon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PRF", "PPER", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die gern mich w\u00fcrfen in den tiefsten Bronnen.", "tokens": ["Die", "gern", "mich", "w\u00fcr\u00b7fen", "in", "den", "tiefs\u00b7ten", "Bron\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Doch bis hieher zu weitentferntem Strande", "tokens": ["Doch", "bis", "hie\u00b7her", "zu", "wei\u00b7tent\u00b7fern\u00b7tem", "Stran\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kann Lieb und Ha\u00df den Dichter nicht beschreien!", "tokens": ["Kann", "Lieb", "und", "Ha\u00df", "den", "Dich\u00b7ter", "nicht", "be\u00b7schrei\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "KON", "NN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Hier mag er weilen, unzerstreut vom Tande,", "tokens": ["Hier", "mag", "er", "wei\u00b7len", ",", "un\u00b7zer\u00b7streut", "vom", "Tan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Vom bunten Wirrwarr deutscher Klatschereien;", "tokens": ["Vom", "bun\u00b7ten", "Wirr\u00b7warr", "deut\u00b7scher", "Klat\u00b7sche\u00b7rei\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Er konnte hier, in einem Zauberlande,", "tokens": ["Er", "konn\u00b7te", "hier", ",", "in", "ei\u00b7nem", "Zau\u00b7berl\u00b7an\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die bange Brust von jedem Schmerz befreien:", "tokens": ["Die", "ban\u00b7ge", "Brust", "von", "je\u00b7dem", "Schmerz", "be\u00b7frei\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Es steht bei dir, ihm vorzuziehn Lappalien,", "tokens": ["Es", "steht", "bei", "dir", ",", "ihm", "vor\u00b7zu\u00b7ziehn", "Lap\u00b7pa\u00b7li\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "PPER", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Du nordisch Volk, ihn aber sch\u00fctzt Italien!", "tokens": ["Du", "nor\u00b7disch", "Volk", ",", "ihn", "a\u00b7ber", "sch\u00fctzt", "I\u00b7ta\u00b7li\u00b7en", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "$,", "PPER", "ADV", "VVFIN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Deutschland verehrt zu vielerlei Pagoden,", "tokens": ["Deutschland", "ver\u00b7ehrt", "zu", "vie\u00b7ler\u00b7lei", "Pa\u00b7go\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und Einer stets bek\u00e4mpft des Andern Meinung:", "tokens": ["Und", "Ei\u00b7ner", "stets", "be\u00b7k\u00e4mpft", "des", "An\u00b7dern", "Mei\u00b7nung", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dies tr\u00fcbe Chaos tausendfacher Moden,", "tokens": ["Dies", "tr\u00fc\u00b7be", "Chaos", "tau\u00b7send\u00b7fa\u00b7cher", "Mo\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In welchem Punkte f\u00e4nd es je Vereinung?", "tokens": ["In", "wel\u00b7chem", "Punk\u00b7te", "f\u00e4nd", "es", "je", "Ver\u00b7ei\u00b7nung", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der Dichter steht auf einem solchen Boden", "tokens": ["Der", "Dich\u00b7ter", "steht", "auf", "ei\u00b7nem", "sol\u00b7chen", "Bo\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Gleich einer fremden sonderbarn Erscheinung:", "tokens": ["Gleich", "ei\u00b7ner", "frem\u00b7den", "son\u00b7der\u00b7barn", "Er\u00b7schei\u00b7nung", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Er h\u00f6rt das wilde Heer von ferne w\u00fcten,", "tokens": ["Er", "h\u00f6rt", "das", "wil\u00b7de", "Heer", "von", "fer\u00b7ne", "w\u00fc\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Erschrickt und flieht, und birgt sich unter Bl\u00fcten.", "tokens": ["Er\u00b7schrickt", "und", "flieht", ",", "und", "birgt", "sich", "un\u00b7ter", "Bl\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "$,", "KON", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Hier kann er froh sein und des Tags genie\u00dfen,", "tokens": ["Hier", "kann", "er", "froh", "sein", "und", "des", "Tags", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "KON", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dort m\u00fc\u00dft er frieren, Bu\u00dfe tun und darben;", "tokens": ["Dort", "m\u00fc\u00dft", "er", "frie\u00b7ren", ",", "Bu\u00b7\u00dfe", "tun", "und", "dar\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,", "NN", "VVINF", "KON", "PAV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Hier kann Gesang am reinsten sich ergie\u00dfen,", "tokens": ["Hier", "kann", "Ge\u00b7sang", "am", "reins\u00b7ten", "sich", "er\u00b7gie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "APPRART", "ADJA", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denn welche Dichter lebten hier und starben!", "tokens": ["Denn", "wel\u00b7che", "Dich\u00b7ter", "leb\u00b7ten", "hier", "und", "star\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "VVFIN", "ADV", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Drum kann zu fliehn er sich noch nicht entschlie\u00dfen", "tokens": ["Drum", "kann", "zu", "fliehn", "er", "sich", "noch", "nicht", "ent\u00b7schlie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PTKZU", "VVINF", "PPER", "PRF", "ADV", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das Reich des st\u00e4ten Lenzes und der Farben.", "tokens": ["Das", "Reich", "des", "st\u00e4\u00b7ten", "Len\u00b7zes", "und", "der", "Far\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Indessen w\u00fcnscht er sich geneigte Leser", "tokens": ["In\u00b7des\u00b7sen", "w\u00fcnscht", "er", "sich", "ge\u00b7neig\u00b7te", "Le\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Vom Strand der Donau bis zum Strand der Weser!", "tokens": ["Vom", "Strand", "der", "Do\u00b7nau", "bis", "zum", "Strand", "der", "We\u00b7ser", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NE", "APPR", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Zwar hie und da bewirkt er kein Behagen,", "tokens": ["Zwar", "hie", "und", "da", "be\u00b7wirkt", "er", "kein", "Be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADV", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Weil ihn die Mandarine streng verbieten;", "tokens": ["Weil", "ihn", "die", "Man\u00b7da\u00b7ri\u00b7ne", "streng", "ver\u00b7bie\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch, f\u00fcrcht ich, wird sie lange Weile plagen,", "tokens": ["Doch", ",", "f\u00fcrcht", "ich", ",", "wird", "sie", "lan\u00b7ge", "Wei\u00b7le", "pla\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn sie die Welt zur\u00fcckgef\u00fchrt auf Nieten.", "tokens": ["Wenn", "sie", "die", "Welt", "zu\u00b7r\u00fcck\u00b7ge\u00b7f\u00fchrt", "auf", "Nie\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Auch l\u00e4\u00dft sich Wahrheit nicht so leicht verjagen:", "tokens": ["Auch", "l\u00e4\u00dft", "sich", "Wahr\u00b7heit", "nicht", "so", "leicht", "ver\u00b7ja\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NN", "PTKNEG", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Johannes Hu\u00df und andre Ketzer brieten,", "tokens": ["Jo\u00b7han\u00b7nes", "Hu\u00df", "und", "and\u00b7re", "Ket\u00b7zer", "brie\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ihr Wort jedoch erklang von Ort zu Orte:", "tokens": ["Ihr", "Wort", "je\u00b7doch", "er\u00b7klang", "von", "Ort", "zu", "Or\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Welch eine Tugend ist die Kunst der Worte!", "tokens": ["Welch", "ei\u00b7ne", "Tu\u00b7gend", "ist", "die", "Kunst", "der", "Wor\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Zwar hier und da giebt's keine Demagogen;", "tokens": ["Zwar", "hier", "und", "da", "giebt's", "kei\u00b7ne", "De\u00b7ma\u00b7go\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADV", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch Seelen giebt's, durch Worte nicht erreichbar,", "tokens": ["Doch", "See\u00b7len", "giebt's", ",", "durch", "Wor\u00b7te", "nicht", "er\u00b7reich\u00b7bar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$,", "APPR", "NN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Mit siebenfachem Leder \u00fcberzogen,", "tokens": ["Mit", "sie\u00b7ben\u00b7fa\u00b7chem", "Le\u00b7der", "\u00fc\u00b7berz\u00b7o\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem Schild des Ajax im Homer vergleichbar.", "tokens": ["Dem", "Schild", "des", "A\u00b7jax", "im", "Ho\u00b7mer", "ver\u00b7gleich\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NE", "APPRART", "NE", "ADJD", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sie sind wie steile Klippen in den Wogen,", "tokens": ["Sie", "sind", "wie", "stei\u00b7le", "Klip\u00b7pen", "in", "den", "Wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Auf ewig hart, auf ewig unerweichbar:", "tokens": ["Auf", "e\u00b7wig", "hart", ",", "auf", "e\u00b7wig", "un\u00b7er\u00b7weich\u00b7bar", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJD", "$,", "APPR", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Es spritzt die Flut empor mit leisen Scherzen,", "tokens": ["Es", "spritzt", "die", "Flut", "em\u00b7por", "mit", "lei\u00b7sen", "Scher\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und schmiegt sich an, als h\u00e4tten Steine Herzen!", "tokens": ["Und", "schmiegt", "sich", "an", ",", "als", "h\u00e4t\u00b7ten", "Stei\u00b7ne", "Her\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKVZ", "$,", "KOUS", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Doch nun erz\u00e4hl ich, statt ein Grillenf\u00e4nger", "tokens": ["Doch", "nun", "er\u00b7z\u00e4hl", "ich", ",", "statt", "ein", "Gril\u00b7len\u00b7f\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,", "KOUI", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu scheinen euch und euch die Zeit zu rauben,", "tokens": ["Zu", "schei\u00b7nen", "euch", "und", "euch", "die", "Zeit", "zu", "rau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "KON", "PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wenn ihr mir anders noch ein St\u00fcndchen l\u00e4nger", "tokens": ["Wenn", "ihr", "mir", "an\u00b7ders", "noch", "ein", "St\u00fcnd\u00b7chen", "l\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "ART", "NN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zuh\u00f6ren wollt und meinen Worten Glauben,", "tokens": ["Zu\u00b7h\u00f6\u00b7ren", "wollt", "und", "mei\u00b7nen", "Wor\u00b7ten", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wenn anders je mich, wie Horaz den S\u00e4nger,", "tokens": ["Wenn", "an\u00b7ders", "je", "mich", ",", "wie", "Ho\u00b7raz", "den", "S\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PPER", "$,", "PWAV", "NE", "ART", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Als blondes Kind verliebte Turteltauben", "tokens": ["Als", "blon\u00b7des", "Kind", "ver\u00b7lieb\u00b7te", "Tur\u00b7tel\u00b7tau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Bestreut mit Lorbeer, den sie mit dem Schnabel", "tokens": ["Be\u00b7streut", "mit", "Lor\u00b7beer", ",", "den", "sie", "mit", "dem", "Schna\u00b7bel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "$,", "PRELS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "F\u00fcr mich gepfl\u00fcckt im sch\u00f6nen Land der Fabel.", "tokens": ["F\u00fcr", "mich", "ge\u00b7pfl\u00fcckt", "im", "sch\u00f6\u00b7nen", "Land", "der", "Fa\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Ich m\u00f6chte wieder wie ein junger Schw\u00e4rmer", "tokens": ["Ich", "m\u00f6ch\u00b7te", "wie\u00b7der", "wie", "ein", "jun\u00b7ger", "Schw\u00e4r\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf meinem Pegasus ein bi\u00dfchen reiten,", "tokens": ["Auf", "mei\u00b7nem", "Pe\u00b7ga\u00b7sus", "ein", "bi\u00df\u00b7chen", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch da die Zeit betr\u00fcbter wird und \u00e4rmer,", "tokens": ["Doch", "da", "die", "Zeit", "be\u00b7tr\u00fcb\u00b7ter", "wird", "und", "\u00e4r\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADJD", "VAFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So m\u00f6cht ich fliehn in fabelhafte Zeiten:", "tokens": ["So", "m\u00f6cht", "ich", "fliehn", "in", "fa\u00b7bel\u00b7haf\u00b7te", "Zei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich, der ich ehedem, an Jugend w\u00e4rmer,", "tokens": ["Ich", ",", "der", "ich", "e\u00b7he\u00b7dem", ",", "an", "Ju\u00b7gend", "w\u00e4r\u00b7mer", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "ADV", "$,", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Herunterstieg in spr\u00f6de Wirklichkeiten,", "tokens": ["Her\u00b7un\u00b7ter\u00b7stieg", "in", "spr\u00f6\u00b7de", "Wirk\u00b7lich\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und mit dem Unverstand begann zu turnen,", "tokens": ["Und", "mit", "dem", "Un\u00b7ver\u00b7stand", "be\u00b7gann", "zu", "tur\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Der stelzenhaft gespreizt sich auf Kothurnen.", "tokens": ["Der", "stel\u00b7zen\u00b7haft", "ge\u00b7spreizt", "sich", "auf", "Ko\u00b7thur\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Ihr wendet weg von jenem Volk der Zwitter", "tokens": ["Ihr", "wen\u00b7det", "weg", "von", "je\u00b7nem", "Volk", "der", "Zwit\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PDAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die m\u00fcden Augen und ich mu\u00df es preisen,", "tokens": ["Die", "m\u00fc\u00b7den", "Au\u00b7gen", "und", "ich", "mu\u00df", "es", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "PPER", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und will, da viele mich verschrien als bitter,", "tokens": ["Und", "will", ",", "da", "vie\u00b7le", "mich", "ver\u00b7schri\u00b7en", "als", "bit\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Euch meine S\u00fc\u00dfigkeit einmal beweisen:", "tokens": ["Euch", "mei\u00b7ne", "S\u00fc\u00b7\u00dfig\u00b7keit", "ein\u00b7mal", "be\u00b7wei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Sonne bring ich nach dem Ungewitter,", "tokens": ["Die", "Son\u00b7ne", "bring", "ich", "nach", "dem", "Un\u00b7ge\u00b7wit\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Einladend euch, mit mir ein St\u00fcck zu reisen,", "tokens": ["Ein\u00b7la\u00b7dend", "euch", ",", "mit", "mir", "ein", "St\u00fcck", "zu", "rei\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "$,", "APPR", "PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ein M\u00e4rchen aus dem Orient zu lesen,", "tokens": ["Ein", "M\u00e4r\u00b7chen", "aus", "dem", "O\u00b7rient", "zu", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Der meiner Jugend schon so lieb gewesen!", "tokens": ["Der", "mei\u00b7ner", "Ju\u00b7gend", "schon", "so", "lieb", "ge\u00b7we\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "ADV", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Und weil mir vorgeworfen ward, es w\u00e4re", "tokens": ["Und", "weil", "mir", "vor\u00b7ge\u00b7wor\u00b7fen", "ward", ",", "es", "w\u00e4\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVPP", "VAFIN", "$,", "PPER", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mein Vers zu gut f\u00fcr eure bl\u00f6den Ohren,", "tokens": ["Mein", "Vers", "zu", "gut", "f\u00fcr", "eu\u00b7re", "bl\u00f6\u00b7den", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKA", "ADJD", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und allzukunstreich meine ganze Sph\u00e4re,", "tokens": ["Und", "all\u00b7zu\u00b7kun\u00b7streich", "mei\u00b7ne", "gan\u00b7ze", "Sph\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil euch der Wein behagt unausgegoren,", "tokens": ["Weil", "euch", "der", "Wein", "be\u00b7hagt", "un\u00b7aus\u00b7ge\u00b7go\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Den sonst ich gern wohl durch Gedanken kl\u00e4re,", "tokens": ["Den", "sonst", "ich", "gern", "wohl", "durch", "Ge\u00b7dan\u00b7ken", "kl\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPER", "ADV", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So hab ich diesmal ein Gewand erkoren,", "tokens": ["So", "hab", "ich", "dies\u00b7mal", "ein", "Ge\u00b7wand", "er\u00b7ko\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ganz schlicht und einfach und bequem zu fassen,", "tokens": ["Ganz", "schlicht", "und", "ein\u00b7fach", "und", "be\u00b7quem", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Das kaum verh\u00fcllt den Stoff in keusche Massen.", "tokens": ["Das", "kaum", "ver\u00b7h\u00fcllt", "den", "Stoff", "in", "keu\u00b7sche", "Mas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Auch mir zuweilen macht's ein bi\u00dfchen Galle,", "tokens": ["Auch", "mir", "zu\u00b7wei\u00b7len", "macht's", "ein", "bi\u00df\u00b7chen", "Gal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df ich so wenig noch getan auf Erden,", "tokens": ["Da\u00df", "ich", "so", "we\u00b7nig", "noch", "ge\u00b7tan", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn ich euch im Ganzen nicht gefalle,", "tokens": ["Und", "wenn", "ich", "euch", "im", "Gan\u00b7zen", "nicht", "ge\u00b7fal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "APPRART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So f\u00fchr ich deshalb keineswegs Beschwerden;", "tokens": ["So", "f\u00fchr", "ich", "des\u00b7halb", "kei\u00b7nes\u00b7wegs", "Be\u00b7schwer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Doch w\u00fcnscht ich manchmal, wie die Andern alle,", "tokens": ["Doch", "w\u00fcnscht", "ich", "manch\u00b7mal", ",", "wie", "die", "An\u00b7dern", "al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "PWAV", "ART", "ADJA", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Zu euren Klassikern gez\u00e4hlt zu werden:", "tokens": ["Zu", "eu\u00b7ren", "Klas\u00b7si\u00b7kern", "ge\u00b7z\u00e4hlt", "zu", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die Ehre freilich ist ein bi\u00dfchen mager,", "tokens": ["Die", "Eh\u00b7re", "frei\u00b7lich", "ist", "ein", "bi\u00df\u00b7chen", "ma\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Denn wer ins H\u00f6rn bl\u00e4st, hei\u00dft sogleich ein Schwager.", "tokens": ["Denn", "wer", "ins", "H\u00f6rn", "bl\u00e4st", ",", "hei\u00dft", "sog\u00b7leich", "ein", "Schwa\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPRART", "NN", "VVFIN", "$,", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Drum hab ich euch dies neue Lied gesponnen,", "tokens": ["Drum", "hab", "ich", "euch", "dies", "neu\u00b7e", "Lied", "ge\u00b7spon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PPER", "PDS", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das weder Zeit mir noch Kritik verheere;", "tokens": ["Das", "we\u00b7der", "Zeit", "mir", "noch", "Kri\u00b7tik", "ver\u00b7hee\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "NN", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es ist, wofern mir unter w\u00e4rmern Sonnen", "tokens": ["Es", "ist", ",", "wo\u00b7fern", "mir", "un\u00b7ter", "w\u00e4r\u00b7mern", "Son\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gereift ein Lorbeer, seine reifste Beere:", "tokens": ["Ge\u00b7reift", "ein", "Lor\u00b7beer", ",", "sei\u00b7ne", "reifs\u00b7te", "Bee\u00b7re", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Im alten Siena hab ich's ausgesonnen;", "tokens": ["Im", "al\u00b7ten", "Sie\u00b7na", "hab", "ich's", "aus\u00b7ge\u00b7son\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NE", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und dann mit mir geschleppt an beide Meere;", "tokens": ["Und", "dann", "mit", "mir", "ge\u00b7schleppt", "an", "bei\u00b7de", "Mee\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPER", "VVPP", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und schlepp ich's weiter, bitt ich nicht zu staunen;", "tokens": ["Und", "schlepp", "ich's", "wei\u00b7ter", ",", "bitt", "ich", "nicht", "zu", "stau\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PTKVZ", "$,", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Denn h\u00e4ufig wechseln meine Reiselaunen.", "tokens": ["Denn", "h\u00e4u\u00b7fig", "wech\u00b7seln", "mei\u00b7ne", "Rei\u00b7se\u00b7lau\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Und weil so mancherlei den Geist verf\u00fchret,", "tokens": ["Und", "weil", "so", "man\u00b7cher\u00b7lei", "den", "Geist", "ver\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So wechsl' ich Aufenthalte gern und Ziele,", "tokens": ["So", "wechsl'", "ich", "Auf\u00b7ent\u00b7hal\u00b7te", "gern", "und", "Zie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "VVFIN", "ADV", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und unter Welschlands Firmament geb\u00fchret", "tokens": ["Und", "un\u00b7ter", "Wel\u00b7schlands", "Fir\u00b7ma\u00b7ment", "ge\u00b7b\u00fch\u00b7ret"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PWAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein bi\u00dfchen Tr\u00e4gheit, das bezeugen Viele:", "tokens": ["Ein", "bi\u00df\u00b7chen", "Tr\u00e4g\u00b7heit", ",", "das", "be\u00b7zeu\u00b7gen", "Vie\u00b7le", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PDS", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich habe mehr gedacht als ausgef\u00fchret,", "tokens": ["Ich", "ha\u00b7be", "mehr", "ge\u00b7dacht", "als", "aus\u00b7ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "KOKOM", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und h\u00e4tt ich alle jene Trauerspiele,", "tokens": ["Und", "h\u00e4tt", "ich", "al\u00b7le", "je\u00b7ne", "Trau\u00b7er\u00b7spie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIAT", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Zu denen ich den Plan gemacht, geschrieben,", "tokens": ["Zu", "de\u00b7nen", "ich", "den", "Plan", "ge\u00b7macht", ",", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ich w\u00e4re nicht so unber\u00fchmt geblieben!", "tokens": ["Ich", "w\u00e4\u00b7re", "nicht", "so", "un\u00b7be\u00b7r\u00fchmt", "ge\u00b7blie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Nie kann der Mensch, wieviel er auch vollende,", "tokens": ["Nie", "kann", "der", "Mensch", ",", "wie\u00b7viel", "er", "auch", "voll\u00b7en\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "$,", "PWAV", "PPER", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie k\u00fchn er sei, sich zeigen als ein Ganzes,", "tokens": ["Wie", "k\u00fchn", "er", "sei", ",", "sich", "zei\u00b7gen", "als", "ein", "Gan\u00b7zes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VAFIN", "$,", "PRF", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und was er ausf\u00fchrt, Gleicht es nicht am Ende", "tokens": ["Und", "was", "er", "aus\u00b7f\u00fchrt", ",", "Gleicht", "es", "nicht", "am", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "VVPP", "$,", "VVFIN", "PPER", "PTKNEG", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zerstreuten Blumen eines gro\u00dfen Kranzes?", "tokens": ["Zer\u00b7streu\u00b7ten", "Blu\u00b7men", "ei\u00b7nes", "gro\u00b7\u00dfen", "Kran\u00b7zes", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Drum Heil den Dichtern, deren reicher Spende", "tokens": ["Drum", "Heil", "den", "Dich\u00b7tern", ",", "de\u00b7ren", "rei\u00b7cher", "Spen\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "NN", "ART", "NN", "$,", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Deutschland verdankt den Gipfel seines Glanzes,", "tokens": ["Deutschland", "ver\u00b7dankt", "den", "Gip\u00b7fel", "sei\u00b7nes", "Glan\u00b7zes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Die nie mit Denken ihre Zeit verputzen,", "tokens": ["Die", "nie", "mit", "Den\u00b7ken", "ih\u00b7re", "Zeit", "ver\u00b7put\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und statt des Geistes blo\u00df die Feder nutzen!", "tokens": ["Und", "statt", "des", "Geis\u00b7tes", "blo\u00df", "die", "Fe\u00b7der", "nut\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Und will Begeistrung ihnen nicht erscheinen,", "tokens": ["Und", "will", "Be\u00b7geis\u00b7trung", "ih\u00b7nen", "nicht", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So hilft die Mokkafrucht, so hilft die Rebe:", "tokens": ["So", "hilft", "die", "Mok\u00b7ka\u00b7frucht", ",", "so", "hilft", "die", "Re\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Vom Trunk erhitzt und auf gel\u00e4hmten Beinen", "tokens": ["Vom", "Trunk", "er\u00b7hitzt", "und", "auf", "ge\u00b7l\u00e4hm\u00b7ten", "Bei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "H\u00e4lt sich der deutsche Pindus in der Schwebe;", "tokens": ["H\u00e4lt", "sich", "der", "deut\u00b7sche", "Pin\u00b7dus", "in", "der", "Schwe\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich z\u00e4hle mich hingegen zu den kleinen", "tokens": ["Ich", "z\u00e4h\u00b7le", "mich", "hin\u00b7ge\u00b7gen", "zu", "den", "klei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Poeten, der ich m\u00e4\u00dfig bin, und gebe", "tokens": ["Po\u00b7et\u00b7en", ",", "der", "ich", "m\u00e4\u00b7\u00dfig", "bin", ",", "und", "ge\u00b7be"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Mich ganz und gar f\u00fcr einen schlechten Prasser:", "tokens": ["Mich", "ganz", "und", "gar", "f\u00fcr", "ei\u00b7nen", "schlech\u00b7ten", "Pras\u00b7ser", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KON", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Auch misch ich t\u00e4glich meinen Wein mit Wasser.", "tokens": ["Auch", "misch", "ich", "t\u00e4g\u00b7lich", "mei\u00b7nen", "Wein", "mit", "Was\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADJD", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Drum konnt ich wenig eure Gunst gewinnen,", "tokens": ["Drum", "konnt", "ich", "we\u00b7nig", "eu\u00b7re", "Gunst", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Entz\u00fcnde nicht, da selbst ich nicht entz\u00fcndet,", "tokens": ["Ent\u00b7z\u00fcn\u00b7de", "nicht", ",", "da", "selbst", "ich", "nicht", "ent\u00b7z\u00fcn\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "KOUS", "ADV", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da meine Musen, als Begleiterinnen", "tokens": ["Da", "mei\u00b7ne", "Mu\u00b7sen", ",", "als", "Be\u00b7glei\u00b7te\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "KOUS", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Des Wahren, nie dem P\u00f6bel sich verb\u00fcndet.", "tokens": ["Des", "Wah\u00b7ren", ",", "nie", "dem", "P\u00f6\u00b7bel", "sich", "ver\u00b7b\u00fcn\u00b7det", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ART", "NN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es war ein allzu jugendlich Beginnen,", "tokens": ["Es", "war", "ein", "all\u00b7zu", "ju\u00b7gend\u00b7lich", "Be\u00b7gin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PTKA", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df ich, wie Joseph, meinen Traum verk\u00fcndet;", "tokens": ["Da\u00df", "ich", ",", "wie", "Jo\u00b7se\u00b7ph", ",", "mei\u00b7nen", "Traum", "ver\u00b7k\u00fcn\u00b7det", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PWAV", "NE", "$,", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Draus hat sich mir der Br\u00fcder Neid entsponnen,", "tokens": ["Draus", "hat", "sich", "mir", "der", "Br\u00fc\u00b7der", "Neid", "ent\u00b7spon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PRF", "PPER", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die gern mich w\u00fcrfen in den tiefsten Bronnen.", "tokens": ["Die", "gern", "mich", "w\u00fcr\u00b7fen", "in", "den", "tiefs\u00b7ten", "Bron\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Doch bis hieher zu weitentferntem Strande", "tokens": ["Doch", "bis", "hie\u00b7her", "zu", "wei\u00b7tent\u00b7fern\u00b7tem", "Stran\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kann Lieb und Ha\u00df den Dichter nicht beschreien!", "tokens": ["Kann", "Lieb", "und", "Ha\u00df", "den", "Dich\u00b7ter", "nicht", "be\u00b7schrei\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "KON", "NN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Hier mag er weilen, unzerstreut vom Tande,", "tokens": ["Hier", "mag", "er", "wei\u00b7len", ",", "un\u00b7zer\u00b7streut", "vom", "Tan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Vom bunten Wirrwarr deutscher Klatschereien;", "tokens": ["Vom", "bun\u00b7ten", "Wirr\u00b7warr", "deut\u00b7scher", "Klat\u00b7sche\u00b7rei\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Er konnte hier, in einem Zauberlande,", "tokens": ["Er", "konn\u00b7te", "hier", ",", "in", "ei\u00b7nem", "Zau\u00b7berl\u00b7an\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die bange Brust von jedem Schmerz befreien:", "tokens": ["Die", "ban\u00b7ge", "Brust", "von", "je\u00b7dem", "Schmerz", "be\u00b7frei\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Es steht bei dir, ihm vorzuziehn Lappalien,", "tokens": ["Es", "steht", "bei", "dir", ",", "ihm", "vor\u00b7zu\u00b7ziehn", "Lap\u00b7pa\u00b7li\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "PPER", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Du nordisch Volk, ihn aber sch\u00fctzt Italien!", "tokens": ["Du", "nor\u00b7disch", "Volk", ",", "ihn", "a\u00b7ber", "sch\u00fctzt", "I\u00b7ta\u00b7li\u00b7en", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "$,", "PPER", "ADV", "VVFIN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Deutschland verehrt zu vielerlei Pagoden,", "tokens": ["Deutschland", "ver\u00b7ehrt", "zu", "vie\u00b7ler\u00b7lei", "Pa\u00b7go\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und Einer stets bek\u00e4mpft des Andern Meinung:", "tokens": ["Und", "Ei\u00b7ner", "stets", "be\u00b7k\u00e4mpft", "des", "An\u00b7dern", "Mei\u00b7nung", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dies tr\u00fcbe Chaos tausendfacher Moden,", "tokens": ["Dies", "tr\u00fc\u00b7be", "Chaos", "tau\u00b7send\u00b7fa\u00b7cher", "Mo\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In welchem Punkte f\u00e4nd es je Vereinung?", "tokens": ["In", "wel\u00b7chem", "Punk\u00b7te", "f\u00e4nd", "es", "je", "Ver\u00b7ei\u00b7nung", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der Dichter steht auf einem solchen Boden", "tokens": ["Der", "Dich\u00b7ter", "steht", "auf", "ei\u00b7nem", "sol\u00b7chen", "Bo\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Gleich einer fremden sonderbarn Erscheinung:", "tokens": ["Gleich", "ei\u00b7ner", "frem\u00b7den", "son\u00b7der\u00b7barn", "Er\u00b7schei\u00b7nung", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Er h\u00f6rt das wilde Heer von ferne w\u00fcten,", "tokens": ["Er", "h\u00f6rt", "das", "wil\u00b7de", "Heer", "von", "fer\u00b7ne", "w\u00fc\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Erschrickt und flieht, und birgt sich unter Bl\u00fcten.", "tokens": ["Er\u00b7schrickt", "und", "flieht", ",", "und", "birgt", "sich", "un\u00b7ter", "Bl\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "$,", "KON", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Hier kann er froh sein und des Tags genie\u00dfen,", "tokens": ["Hier", "kann", "er", "froh", "sein", "und", "des", "Tags", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "KON", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dort m\u00fc\u00dft er frieren, Bu\u00dfe tun und darben;", "tokens": ["Dort", "m\u00fc\u00dft", "er", "frie\u00b7ren", ",", "Bu\u00b7\u00dfe", "tun", "und", "dar\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,", "NN", "VVINF", "KON", "PAV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Hier kann Gesang am reinsten sich ergie\u00dfen,", "tokens": ["Hier", "kann", "Ge\u00b7sang", "am", "reins\u00b7ten", "sich", "er\u00b7gie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "APPRART", "ADJA", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denn welche Dichter lebten hier und starben!", "tokens": ["Denn", "wel\u00b7che", "Dich\u00b7ter", "leb\u00b7ten", "hier", "und", "star\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "VVFIN", "ADV", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Drum kann zu fliehn er sich noch nicht entschlie\u00dfen", "tokens": ["Drum", "kann", "zu", "fliehn", "er", "sich", "noch", "nicht", "ent\u00b7schlie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PTKZU", "VVINF", "PPER", "PRF", "ADV", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das Reich des st\u00e4ten Lenzes und der Farben.", "tokens": ["Das", "Reich", "des", "st\u00e4\u00b7ten", "Len\u00b7zes", "und", "der", "Far\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Indessen w\u00fcnscht er sich geneigte Leser", "tokens": ["In\u00b7des\u00b7sen", "w\u00fcnscht", "er", "sich", "ge\u00b7neig\u00b7te", "Le\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Vom Strand der Donau bis zum Strand der Weser!", "tokens": ["Vom", "Strand", "der", "Do\u00b7nau", "bis", "zum", "Strand", "der", "We\u00b7ser", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NE", "APPR", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Zwar hie und da bewirkt er kein Behagen,", "tokens": ["Zwar", "hie", "und", "da", "be\u00b7wirkt", "er", "kein", "Be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADV", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Weil ihn die Mandarine streng verbieten;", "tokens": ["Weil", "ihn", "die", "Man\u00b7da\u00b7ri\u00b7ne", "streng", "ver\u00b7bie\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch, f\u00fcrcht ich, wird sie lange Weile plagen,", "tokens": ["Doch", ",", "f\u00fcrcht", "ich", ",", "wird", "sie", "lan\u00b7ge", "Wei\u00b7le", "pla\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn sie die Welt zur\u00fcckgef\u00fchrt auf Nieten.", "tokens": ["Wenn", "sie", "die", "Welt", "zu\u00b7r\u00fcck\u00b7ge\u00b7f\u00fchrt", "auf", "Nie\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Auch l\u00e4\u00dft sich Wahrheit nicht so leicht verjagen:", "tokens": ["Auch", "l\u00e4\u00dft", "sich", "Wahr\u00b7heit", "nicht", "so", "leicht", "ver\u00b7ja\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NN", "PTKNEG", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Johannes Hu\u00df und andre Ketzer brieten,", "tokens": ["Jo\u00b7han\u00b7nes", "Hu\u00df", "und", "and\u00b7re", "Ket\u00b7zer", "brie\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ihr Wort jedoch erklang von Ort zu Orte:", "tokens": ["Ihr", "Wort", "je\u00b7doch", "er\u00b7klang", "von", "Ort", "zu", "Or\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Welch eine Tugend ist die Kunst der Worte!", "tokens": ["Welch", "ei\u00b7ne", "Tu\u00b7gend", "ist", "die", "Kunst", "der", "Wor\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Zwar hier und da giebt's keine Demagogen;", "tokens": ["Zwar", "hier", "und", "da", "giebt's", "kei\u00b7ne", "De\u00b7ma\u00b7go\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADV", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch Seelen giebt's, durch Worte nicht erreichbar,", "tokens": ["Doch", "See\u00b7len", "giebt's", ",", "durch", "Wor\u00b7te", "nicht", "er\u00b7reich\u00b7bar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$,", "APPR", "NN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Mit siebenfachem Leder \u00fcberzogen,", "tokens": ["Mit", "sie\u00b7ben\u00b7fa\u00b7chem", "Le\u00b7der", "\u00fc\u00b7berz\u00b7o\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem Schild des Ajax im Homer vergleichbar.", "tokens": ["Dem", "Schild", "des", "A\u00b7jax", "im", "Ho\u00b7mer", "ver\u00b7gleich\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NE", "APPRART", "NE", "ADJD", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sie sind wie steile Klippen in den Wogen,", "tokens": ["Sie", "sind", "wie", "stei\u00b7le", "Klip\u00b7pen", "in", "den", "Wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Auf ewig hart, auf ewig unerweichbar:", "tokens": ["Auf", "e\u00b7wig", "hart", ",", "auf", "e\u00b7wig", "un\u00b7er\u00b7weich\u00b7bar", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJD", "$,", "APPR", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Es spritzt die Flut empor mit leisen Scherzen,", "tokens": ["Es", "spritzt", "die", "Flut", "em\u00b7por", "mit", "lei\u00b7sen", "Scher\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und schmiegt sich an, als h\u00e4tten Steine Herzen!", "tokens": ["Und", "schmiegt", "sich", "an", ",", "als", "h\u00e4t\u00b7ten", "Stei\u00b7ne", "Her\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKVZ", "$,", "KOUS", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Doch nun erz\u00e4hl ich, statt ein Grillenf\u00e4nger", "tokens": ["Doch", "nun", "er\u00b7z\u00e4hl", "ich", ",", "statt", "ein", "Gril\u00b7len\u00b7f\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,", "KOUI", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu scheinen euch und euch die Zeit zu rauben,", "tokens": ["Zu", "schei\u00b7nen", "euch", "und", "euch", "die", "Zeit", "zu", "rau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "KON", "PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wenn ihr mir anders noch ein St\u00fcndchen l\u00e4nger", "tokens": ["Wenn", "ihr", "mir", "an\u00b7ders", "noch", "ein", "St\u00fcnd\u00b7chen", "l\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "ART", "NN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zuh\u00f6ren wollt und meinen Worten Glauben,", "tokens": ["Zu\u00b7h\u00f6\u00b7ren", "wollt", "und", "mei\u00b7nen", "Wor\u00b7ten", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wenn anders je mich, wie Horaz den S\u00e4nger,", "tokens": ["Wenn", "an\u00b7ders", "je", "mich", ",", "wie", "Ho\u00b7raz", "den", "S\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PPER", "$,", "PWAV", "NE", "ART", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Als blondes Kind verliebte Turteltauben", "tokens": ["Als", "blon\u00b7des", "Kind", "ver\u00b7lieb\u00b7te", "Tur\u00b7tel\u00b7tau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Bestreut mit Lorbeer, den sie mit dem Schnabel", "tokens": ["Be\u00b7streut", "mit", "Lor\u00b7beer", ",", "den", "sie", "mit", "dem", "Schna\u00b7bel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "$,", "PRELS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "F\u00fcr mich gepfl\u00fcckt im sch\u00f6nen Land der Fabel.", "tokens": ["F\u00fcr", "mich", "ge\u00b7pfl\u00fcckt", "im", "sch\u00f6\u00b7nen", "Land", "der", "Fa\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}