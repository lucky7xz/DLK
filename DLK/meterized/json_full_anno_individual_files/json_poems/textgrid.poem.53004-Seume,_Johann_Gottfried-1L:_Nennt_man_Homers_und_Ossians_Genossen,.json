{"textgrid.poem.53004": {"metadata": {"author": {"name": "Seume, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nennt man Homers und Ossians Genossen,", "genre": "verse", "period": "N.A.", "pub_year": 1786, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nennt man Homers und Ossians Genossen,", "tokens": ["Nennt", "man", "Ho\u00b7mers", "und", "Os\u00b7si\u00b7ans", "Ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NE", "KON", "NE", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Von deren Lippen Honigseim", "tokens": ["Von", "de\u00b7ren", "Lip\u00b7pen", "Ho\u00b7ni\u00b7gseim"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Nectar oft in weisen Lehren flossen,", "tokens": ["Und", "Nec\u00b7tar", "oft", "in", "wei\u00b7sen", "Leh\u00b7ren", "flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nennt man auch einst den alten Gleim.", "tokens": ["Nennt", "man", "auch", "einst", "den", "al\u00b7ten", "Gleim", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Froh war als Greis, wie es der Mann gewesen,", "tokens": ["Froh", "war", "als", "Greis", ",", "wie", "es", "der", "Mann", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "KOKOM", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Harfner mit dem Silberhaar;", "tokens": ["Der", "Harf\u00b7ner", "mit", "dem", "Sil\u00b7ber\u00b7haar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sein Gesicht lie\u00df seine Seele lesen,", "tokens": ["Und", "sein", "Ge\u00b7sicht", "lie\u00df", "sei\u00b7ne", "See\u00b7le", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die hier schon in Verkl\u00e4rung war.", "tokens": ["Die", "hier", "schon", "in", "Ver\u00b7kl\u00e4\u00b7rung", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Nestor sah in vielen vielen Jahren", "tokens": ["Der", "Nes\u00b7tor", "sah", "in", "vie\u00b7len", "vie\u00b7len", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Geschlechter K\u00f6nige zum Ziel,", "tokens": ["Ge\u00b7schlech\u00b7ter", "K\u00f6\u00b7ni\u00b7ge", "zum", "Ziel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In Pomp und Schlacht, vor sich vor\u00fcber fahren;", "tokens": ["In", "Pomp", "und", "Schlacht", ",", "vor", "sich", "vor\u00b7\u00fc\u00b7ber", "fah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$,", "APPR", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und z\u00e4hlte, wer hier stand, hier fiel.", "tokens": ["Und", "z\u00e4hl\u00b7te", ",", "wer", "hier", "stand", ",", "hier", "fiel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "ADV", "VVFIN", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Hoch stieg der Ruhm von seines K\u00f6nigs Heere,", "tokens": ["Hoch", "stieg", "der", "Ruhm", "von", "sei\u00b7nes", "K\u00f6\u00b7nigs", "Hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Das in dem Sturm die Feinde schlug:", "tokens": ["Das", "in", "dem", "Sturm", "die", "Fein\u00b7de", "schlug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In Gleims Gedicht lebt ihre Heldenehre,", "tokens": ["In", "Gleims", "Ge\u00b7dicht", "lebt", "ih\u00b7re", "Hel\u00b7de\u00b7neh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das sie entgl\u00fcht zur Nachwelt trug.", "tokens": ["Das", "sie", "ent\u00b7gl\u00fcht", "zur", "Nach\u00b7welt", "trug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVFIN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Er sammelte mit Weisheit jede Bl\u00fcthe", "tokens": ["Er", "sam\u00b7mel\u00b7te", "mit", "Weis\u00b7heit", "je\u00b7de", "Bl\u00fc\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und flocht sie sinnreich in den Kranz,", "tokens": ["Und", "flocht", "sie", "sinn\u00b7reich", "in", "den", "Kranz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und reicht' ihn dann mit Freundlichkeit und G\u00fcte", "tokens": ["Und", "reicht'", "ihn", "dann", "mit", "Freund\u00b7lich\u00b7keit", "und", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den Freunden zu dem Reihentanz.", "tokens": ["Den", "Freun\u00b7den", "zu", "dem", "Rei\u00b7hen\u00b7tanz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Anakreon sang nicht mit h\u00f6herm Feuer", "tokens": ["A\u00b7nak\u00b7re\u00b7on", "sang", "nicht", "mit", "h\u00f6\u00b7herm", "Feu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Vom Seelenrausch in Lieb' und Wein;", "tokens": ["Vom", "See\u00b7len\u00b7rausch", "in", "Lieb'", "und", "Wein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Keines Geist war der Bet\u00e4ubung freyer,", "tokens": ["Und", "Kei\u00b7nes", "Geist", "war", "der", "Be\u00b7t\u00e4u\u00b7bung", "frey\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So sch\u00f6n \u00e4therisch und so rein.", "tokens": ["So", "sch\u00f6n", "\u00e4t\u00b7he\u00b7risch", "und", "so", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.7": {"line.1": {"text": "H\u00f6rt erst den Spruch, verme\u00dfne Sittenrichter;", "tokens": ["H\u00f6rt", "erst", "den", "Spruch", ",", "ver\u00b7me\u00df\u00b7ne", "Sit\u00b7ten\u00b7rich\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der M\u00e4onide Klopstock nennt", "tokens": ["Der", "M\u00e4o\u00b7ni\u00b7de", "Klops\u00b7tock", "nennt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "VVFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Den S\u00e4nger den ", "tokens": ["Den", "S\u00e4n\u00b7ger", "den"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ART"], "meter": "-+--", "measure": "dactylic.init"}, "line.4": {"text": "Die er am ganzen Pindus kennt.", "tokens": ["Die", "er", "am", "gan\u00b7zen", "Pin\u00b7dus", "kennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Und jedem Wort, das nicht vor keuschen Ohren", "tokens": ["Und", "je\u00b7dem", "Wort", ",", "das", "nicht", "vor", "keu\u00b7schen", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein \u00e4chtes B\u00fcrgerrecht bekam,", "tokens": ["Ein", "\u00e4ch\u00b7tes", "B\u00fcr\u00b7ger\u00b7recht", "be\u00b7kam", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hatt' er mit Zorn den Untergang geschworen;", "tokens": ["Hatt'", "er", "mit", "Zorn", "den", "Un\u00b7ter\u00b7gang", "ge\u00b7schwo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und schalt, wer dann in Schutz es nahm.", "tokens": ["Und", "schalt", ",", "wer", "dann", "in", "Schutz", "es", "nahm", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "ADV", "APPR", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Brecht, denn ihr thuts, ob dem was er gesungen,", "tokens": ["Brecht", ",", "denn", "ihr", "thuts", ",", "ob", "dem", "was", "er", "ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "PPER", "VVFIN", "$,", "KOUS", "ART", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mit eurem Krittlertadel los!", "tokens": ["Mit", "eu\u00b7rem", "Kritt\u00b7ler\u00b7ta\u00b7del", "los", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem Gr\u00f6\u00dften ist nicht jedes Lied gelungen;", "tokens": ["Dem", "Gr\u00f6\u00df\u00b7ten", "ist", "nicht", "je\u00b7des", "Lied", "ge\u00b7lun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sein reiner Menschenwerth war gro\u00df.", "tokens": ["Sein", "rei\u00b7ner", "Men\u00b7schen\u00b7werth", "war", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Man wird noch oft im Kreise sch\u00f6ner Seelen,", "tokens": ["Man", "wird", "noch", "oft", "im", "Krei\u00b7se", "sch\u00f6\u00b7ner", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADV", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die still und ernst ihn handeln sahn,", "tokens": ["Die", "still", "und", "ernst", "ihn", "han\u00b7deln", "sahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "VVFIN", "PPER", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Tief tief herauf der Reihe nach erz\u00e4hlen,", "tokens": ["Tief", "tief", "her\u00b7auf", "der", "Rei\u00b7he", "nach", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "ADV", "ART", "NN", "APPR", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was einst der alte Mann gethan.", "tokens": ["Was", "einst", "der", "al\u00b7te", "Mann", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ich schreibe stolz der Liste der Verehrer", "tokens": ["Ich", "schrei\u00b7be", "stolz", "der", "Lis\u00b7te", "der", "Ver\u00b7eh\u00b7rer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Mannes meinen Nahmen ein:", "tokens": ["Des", "Man\u00b7nes", "mei\u00b7nen", "Nah\u00b7men", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er war mein Freund, mein Vater und mein Lehrer;", "tokens": ["Er", "war", "mein", "Freund", ",", "mein", "Va\u00b7ter", "und", "mein", "Leh\u00b7rer", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und soll als Mensch mein Muster seyn.", "tokens": ["Und", "soll", "als", "Mensch", "mein", "Mus\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "KOUS", "NN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Fragt nicht, wie oft der Untersucher fehlte;", "tokens": ["Fragt", "nicht", ",", "wie", "oft", "der", "Un\u00b7ter\u00b7su\u00b7cher", "fehl\u00b7te", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PWAV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Menschen Handlung ist die Saat.", "tokens": ["Des", "Men\u00b7schen", "Hand\u00b7lung", "ist", "die", "Saat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Wage de\u00df, der unsre Stunden z\u00e4hlte,", "tokens": ["Der", "Wa\u00b7ge", "de\u00df", ",", "der", "uns\u00b7re", "Stun\u00b7den", "z\u00e4hl\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wiegt leicht das Wort, und schwer die That.", "tokens": ["Wiegt", "leicht", "das", "Wort", ",", "und", "schwer", "die", "That", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$,", "KON", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Ich dacht' an ihn, als \u00fcber Wolkensitzen", "tokens": ["Ich", "dacht'", "an", "ihn", ",", "als", "\u00fc\u00b7ber", "Wol\u00b7ken\u00b7sit\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "KOUS", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich an des \u00c4tna H\u00f6lle stand;", "tokens": ["Ich", "an", "des", "\u00c4t\u00b7na", "H\u00f6l\u00b7le", "stand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "An ihn, als ich mich durch die Felsenspitzen", "tokens": ["An", "ihn", ",", "als", "ich", "mich", "durch", "die", "Fel\u00b7sen\u00b7spit\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "KOUS", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Am Schneehaupt des Adula wand.", "tokens": ["Am", "Schnee\u00b7haupt", "des", "A\u00b7du\u00b7la", "wand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NE", "VVFIN", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Der Lenz beginnt; bald hofft' ich ihn zu sehen,", "tokens": ["Der", "Lenz", "be\u00b7ginnt", ";", "bald", "hofft'", "ich", "ihn", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den blinden S\u00e4nger, der mir rief;", "tokens": ["Den", "blin\u00b7den", "S\u00e4n\u00b7ger", ",", "der", "mir", "rief", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da h\u00f6rt' ich ernst die Trauerbothschaft wehen,", "tokens": ["Da", "h\u00f6rt'", "ich", "ernst", "die", "Trau\u00b7er\u00b7both\u00b7schaft", "we\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df er den Schlaf hin\u00fcber schlief.", "tokens": ["Da\u00df", "er", "den", "Schlaf", "hin\u00b7\u00fc\u00b7ber", "schlief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Als rauschte mir sein Fittich aus der Ferne,", "tokens": ["Als", "rauschte", "mir", "sein", "Fit\u00b7tich", "aus", "der", "Fer\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sah in die Welten ich empor:", "tokens": ["Sah", "in", "die", "Wel\u00b7ten", "ich", "em\u00b7por", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Einst such' ich dich auf deinem Heimathssterne,", "tokens": ["Einst", "such'", "ich", "dich", "auf", "dei\u00b7nem", "Hei\u00b7mathss\u00b7ter\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und finde mehr, als ich verlor.", "tokens": ["Und", "fin\u00b7de", "mehr", ",", "als", "ich", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Ein Andrer mag als Dichter h\u00f6her fliegen,", "tokens": ["Ein", "A\u00b7ndrer", "mag", "als", "Dich\u00b7ter", "h\u00f6\u00b7her", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "KOUS", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als seine heitre Muse stieg.", "tokens": ["Als", "sei\u00b7ne", "heit\u00b7re", "Mu\u00b7se", "stieg", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird einer ihn an Tugend \u00fcberwiegen?", "tokens": ["Wird", "ei\u00b7ner", "ihn", "an", "Tu\u00b7gend", "\u00fc\u00b7berw\u00b7ie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und dieses ist der sch\u00f6nre Sieg.", "tokens": ["Und", "die\u00b7ses", "ist", "der", "sch\u00f6n\u00b7re", "Sieg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Wenn ich als Greis am Knotenstocke wanke,", "tokens": ["Wenn", "ich", "als", "Greis", "am", "Kno\u00b7ten\u00b7sto\u00b7cke", "wan\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOUS", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zur\u00fcck und vorw\u00e4rts blicke, gibt", "tokens": ["Zu\u00b7r\u00fcck", "und", "vor\u00b7w\u00e4rts", "bli\u00b7cke", ",", "gibt"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PTKVZ", "KON", "ADV", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mir Jugendfreude der Gedanke,", "tokens": ["Mir", "Ju\u00b7gend\u00b7freu\u00b7de", "der", "Ge\u00b7dan\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df Gleim und Wei\u00dfe mich geliebt.", "tokens": ["Da\u00df", "Gleim", "und", "Wei\u00b7\u00dfe", "mich", "ge\u00b7liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Nennt man Homers und Ossians Genossen,", "tokens": ["Nennt", "man", "Ho\u00b7mers", "und", "Os\u00b7si\u00b7ans", "Ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NE", "KON", "NE", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Von deren Lippen Honigseim", "tokens": ["Von", "de\u00b7ren", "Lip\u00b7pen", "Ho\u00b7ni\u00b7gseim"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Nectar oft in weisen Lehren flossen,", "tokens": ["Und", "Nec\u00b7tar", "oft", "in", "wei\u00b7sen", "Leh\u00b7ren", "flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nennt man auch einst den alten Gleim.", "tokens": ["Nennt", "man", "auch", "einst", "den", "al\u00b7ten", "Gleim", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Froh war als Greis, wie es der Mann gewesen,", "tokens": ["Froh", "war", "als", "Greis", ",", "wie", "es", "der", "Mann", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "KOKOM", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Harfner mit dem Silberhaar;", "tokens": ["Der", "Harf\u00b7ner", "mit", "dem", "Sil\u00b7ber\u00b7haar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sein Gesicht lie\u00df seine Seele lesen,", "tokens": ["Und", "sein", "Ge\u00b7sicht", "lie\u00df", "sei\u00b7ne", "See\u00b7le", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die hier schon in Verkl\u00e4rung war.", "tokens": ["Die", "hier", "schon", "in", "Ver\u00b7kl\u00e4\u00b7rung", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Der Nestor sah in vielen vielen Jahren", "tokens": ["Der", "Nes\u00b7tor", "sah", "in", "vie\u00b7len", "vie\u00b7len", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Geschlechter K\u00f6nige zum Ziel,", "tokens": ["Ge\u00b7schlech\u00b7ter", "K\u00f6\u00b7ni\u00b7ge", "zum", "Ziel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In Pomp und Schlacht, vor sich vor\u00fcber fahren;", "tokens": ["In", "Pomp", "und", "Schlacht", ",", "vor", "sich", "vor\u00b7\u00fc\u00b7ber", "fah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$,", "APPR", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und z\u00e4hlte, wer hier stand, hier fiel.", "tokens": ["Und", "z\u00e4hl\u00b7te", ",", "wer", "hier", "stand", ",", "hier", "fiel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "ADV", "VVFIN", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Hoch stieg der Ruhm von seines K\u00f6nigs Heere,", "tokens": ["Hoch", "stieg", "der", "Ruhm", "von", "sei\u00b7nes", "K\u00f6\u00b7nigs", "Hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Das in dem Sturm die Feinde schlug:", "tokens": ["Das", "in", "dem", "Sturm", "die", "Fein\u00b7de", "schlug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In Gleims Gedicht lebt ihre Heldenehre,", "tokens": ["In", "Gleims", "Ge\u00b7dicht", "lebt", "ih\u00b7re", "Hel\u00b7de\u00b7neh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das sie entgl\u00fcht zur Nachwelt trug.", "tokens": ["Das", "sie", "ent\u00b7gl\u00fcht", "zur", "Nach\u00b7welt", "trug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVFIN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Er sammelte mit Weisheit jede Bl\u00fcthe", "tokens": ["Er", "sam\u00b7mel\u00b7te", "mit", "Weis\u00b7heit", "je\u00b7de", "Bl\u00fc\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und flocht sie sinnreich in den Kranz,", "tokens": ["Und", "flocht", "sie", "sinn\u00b7reich", "in", "den", "Kranz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und reicht' ihn dann mit Freundlichkeit und G\u00fcte", "tokens": ["Und", "reicht'", "ihn", "dann", "mit", "Freund\u00b7lich\u00b7keit", "und", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den Freunden zu dem Reihentanz.", "tokens": ["Den", "Freun\u00b7den", "zu", "dem", "Rei\u00b7hen\u00b7tanz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Anakreon sang nicht mit h\u00f6herm Feuer", "tokens": ["A\u00b7nak\u00b7re\u00b7on", "sang", "nicht", "mit", "h\u00f6\u00b7herm", "Feu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Vom Seelenrausch in Lieb' und Wein;", "tokens": ["Vom", "See\u00b7len\u00b7rausch", "in", "Lieb'", "und", "Wein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Keines Geist war der Bet\u00e4ubung freyer,", "tokens": ["Und", "Kei\u00b7nes", "Geist", "war", "der", "Be\u00b7t\u00e4u\u00b7bung", "frey\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So sch\u00f6n \u00e4therisch und so rein.", "tokens": ["So", "sch\u00f6n", "\u00e4t\u00b7he\u00b7risch", "und", "so", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.24": {"line.1": {"text": "H\u00f6rt erst den Spruch, verme\u00dfne Sittenrichter;", "tokens": ["H\u00f6rt", "erst", "den", "Spruch", ",", "ver\u00b7me\u00df\u00b7ne", "Sit\u00b7ten\u00b7rich\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der M\u00e4onide Klopstock nennt", "tokens": ["Der", "M\u00e4o\u00b7ni\u00b7de", "Klops\u00b7tock", "nennt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "VVFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Den S\u00e4nger den ", "tokens": ["Den", "S\u00e4n\u00b7ger", "den"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ART"], "meter": "-+--", "measure": "dactylic.init"}, "line.4": {"text": "Die er am ganzen Pindus kennt.", "tokens": ["Die", "er", "am", "gan\u00b7zen", "Pin\u00b7dus", "kennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Und jedem Wort, das nicht vor keuschen Ohren", "tokens": ["Und", "je\u00b7dem", "Wort", ",", "das", "nicht", "vor", "keu\u00b7schen", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein \u00e4chtes B\u00fcrgerrecht bekam,", "tokens": ["Ein", "\u00e4ch\u00b7tes", "B\u00fcr\u00b7ger\u00b7recht", "be\u00b7kam", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hatt' er mit Zorn den Untergang geschworen;", "tokens": ["Hatt'", "er", "mit", "Zorn", "den", "Un\u00b7ter\u00b7gang", "ge\u00b7schwo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und schalt, wer dann in Schutz es nahm.", "tokens": ["Und", "schalt", ",", "wer", "dann", "in", "Schutz", "es", "nahm", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "ADV", "APPR", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Brecht, denn ihr thuts, ob dem was er gesungen,", "tokens": ["Brecht", ",", "denn", "ihr", "thuts", ",", "ob", "dem", "was", "er", "ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "PPER", "VVFIN", "$,", "KOUS", "ART", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mit eurem Krittlertadel los!", "tokens": ["Mit", "eu\u00b7rem", "Kritt\u00b7ler\u00b7ta\u00b7del", "los", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem Gr\u00f6\u00dften ist nicht jedes Lied gelungen;", "tokens": ["Dem", "Gr\u00f6\u00df\u00b7ten", "ist", "nicht", "je\u00b7des", "Lied", "ge\u00b7lun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sein reiner Menschenwerth war gro\u00df.", "tokens": ["Sein", "rei\u00b7ner", "Men\u00b7schen\u00b7werth", "war", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Man wird noch oft im Kreise sch\u00f6ner Seelen,", "tokens": ["Man", "wird", "noch", "oft", "im", "Krei\u00b7se", "sch\u00f6\u00b7ner", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADV", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die still und ernst ihn handeln sahn,", "tokens": ["Die", "still", "und", "ernst", "ihn", "han\u00b7deln", "sahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "VVFIN", "PPER", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Tief tief herauf der Reihe nach erz\u00e4hlen,", "tokens": ["Tief", "tief", "her\u00b7auf", "der", "Rei\u00b7he", "nach", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "ADV", "ART", "NN", "APPR", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was einst der alte Mann gethan.", "tokens": ["Was", "einst", "der", "al\u00b7te", "Mann", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Ich schreibe stolz der Liste der Verehrer", "tokens": ["Ich", "schrei\u00b7be", "stolz", "der", "Lis\u00b7te", "der", "Ver\u00b7eh\u00b7rer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Mannes meinen Nahmen ein:", "tokens": ["Des", "Man\u00b7nes", "mei\u00b7nen", "Nah\u00b7men", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er war mein Freund, mein Vater und mein Lehrer;", "tokens": ["Er", "war", "mein", "Freund", ",", "mein", "Va\u00b7ter", "und", "mein", "Leh\u00b7rer", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und soll als Mensch mein Muster seyn.", "tokens": ["Und", "soll", "als", "Mensch", "mein", "Mus\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "KOUS", "NN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Fragt nicht, wie oft der Untersucher fehlte;", "tokens": ["Fragt", "nicht", ",", "wie", "oft", "der", "Un\u00b7ter\u00b7su\u00b7cher", "fehl\u00b7te", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PWAV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Menschen Handlung ist die Saat.", "tokens": ["Des", "Men\u00b7schen", "Hand\u00b7lung", "ist", "die", "Saat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Wage de\u00df, der unsre Stunden z\u00e4hlte,", "tokens": ["Der", "Wa\u00b7ge", "de\u00df", ",", "der", "uns\u00b7re", "Stun\u00b7den", "z\u00e4hl\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wiegt leicht das Wort, und schwer die That.", "tokens": ["Wiegt", "leicht", "das", "Wort", ",", "und", "schwer", "die", "That", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$,", "KON", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Ich dacht' an ihn, als \u00fcber Wolkensitzen", "tokens": ["Ich", "dacht'", "an", "ihn", ",", "als", "\u00fc\u00b7ber", "Wol\u00b7ken\u00b7sit\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "KOUS", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich an des \u00c4tna H\u00f6lle stand;", "tokens": ["Ich", "an", "des", "\u00c4t\u00b7na", "H\u00f6l\u00b7le", "stand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "An ihn, als ich mich durch die Felsenspitzen", "tokens": ["An", "ihn", ",", "als", "ich", "mich", "durch", "die", "Fel\u00b7sen\u00b7spit\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "KOUS", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Am Schneehaupt des Adula wand.", "tokens": ["Am", "Schnee\u00b7haupt", "des", "A\u00b7du\u00b7la", "wand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NE", "VVFIN", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}}, "stanza.31": {"line.1": {"text": "Der Lenz beginnt; bald hofft' ich ihn zu sehen,", "tokens": ["Der", "Lenz", "be\u00b7ginnt", ";", "bald", "hofft'", "ich", "ihn", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den blinden S\u00e4nger, der mir rief;", "tokens": ["Den", "blin\u00b7den", "S\u00e4n\u00b7ger", ",", "der", "mir", "rief", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da h\u00f6rt' ich ernst die Trauerbothschaft wehen,", "tokens": ["Da", "h\u00f6rt'", "ich", "ernst", "die", "Trau\u00b7er\u00b7both\u00b7schaft", "we\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df er den Schlaf hin\u00fcber schlief.", "tokens": ["Da\u00df", "er", "den", "Schlaf", "hin\u00b7\u00fc\u00b7ber", "schlief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Als rauschte mir sein Fittich aus der Ferne,", "tokens": ["Als", "rauschte", "mir", "sein", "Fit\u00b7tich", "aus", "der", "Fer\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sah in die Welten ich empor:", "tokens": ["Sah", "in", "die", "Wel\u00b7ten", "ich", "em\u00b7por", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Einst such' ich dich auf deinem Heimathssterne,", "tokens": ["Einst", "such'", "ich", "dich", "auf", "dei\u00b7nem", "Hei\u00b7mathss\u00b7ter\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und finde mehr, als ich verlor.", "tokens": ["Und", "fin\u00b7de", "mehr", ",", "als", "ich", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Ein Andrer mag als Dichter h\u00f6her fliegen,", "tokens": ["Ein", "A\u00b7ndrer", "mag", "als", "Dich\u00b7ter", "h\u00f6\u00b7her", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "KOUS", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als seine heitre Muse stieg.", "tokens": ["Als", "sei\u00b7ne", "heit\u00b7re", "Mu\u00b7se", "stieg", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird einer ihn an Tugend \u00fcberwiegen?", "tokens": ["Wird", "ei\u00b7ner", "ihn", "an", "Tu\u00b7gend", "\u00fc\u00b7berw\u00b7ie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und dieses ist der sch\u00f6nre Sieg.", "tokens": ["Und", "die\u00b7ses", "ist", "der", "sch\u00f6n\u00b7re", "Sieg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Wenn ich als Greis am Knotenstocke wanke,", "tokens": ["Wenn", "ich", "als", "Greis", "am", "Kno\u00b7ten\u00b7sto\u00b7cke", "wan\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOUS", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zur\u00fcck und vorw\u00e4rts blicke, gibt", "tokens": ["Zu\u00b7r\u00fcck", "und", "vor\u00b7w\u00e4rts", "bli\u00b7cke", ",", "gibt"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PTKVZ", "KON", "ADV", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mir Jugendfreude der Gedanke,", "tokens": ["Mir", "Ju\u00b7gend\u00b7freu\u00b7de", "der", "Ge\u00b7dan\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df Gleim und Wei\u00dfe mich geliebt.", "tokens": ["Da\u00df", "Gleim", "und", "Wei\u00b7\u00dfe", "mich", "ge\u00b7liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}