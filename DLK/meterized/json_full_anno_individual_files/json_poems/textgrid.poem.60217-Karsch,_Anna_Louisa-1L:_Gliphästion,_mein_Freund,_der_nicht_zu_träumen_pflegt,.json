{"textgrid.poem.60217": {"metadata": {"author": {"name": "Karsch, Anna Louisa", "birth": "N.A.", "death": "N.A."}, "title": "1L: Gliph\u00e4stion, mein Freund, der nicht zu tr\u00e4umen pflegt,", "genre": "verse", "period": "N.A.", "pub_year": 1761, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gliph\u00e4stion, mein Freund, der nicht zu tr\u00e4umen pflegt,", "tokens": ["Gli\u00b7ph\u00e4s\u00b7ti\u00b7on", ",", "mein", "Freund", ",", "der", "nicht", "zu", "tr\u00e4u\u00b7men", "pflegt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "PRELS", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht abergl\u00e4ubisch forscht, nicht Zeichendeuter fr\u00e4gt,", "tokens": ["Nicht", "a\u00b7berg\u00b7l\u00e4u\u00b7bisch", "forscht", ",", "nicht", "Zei\u00b7chen\u00b7deu\u00b7ter", "fr\u00e4gt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVPP", "$,", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Ku\u00df und Freuden nimmt, die ungeweissagt kommen;", "tokens": ["Der", "Ku\u00df", "und", "Freu\u00b7den", "nimmt", ",", "die", "un\u00b7ge\u00b7weis\u00b7sagt", "kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$,", "PRELS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gliph\u00e4stion, mein Freund, ist einer von den Frommen,", "tokens": ["Gli\u00b7ph\u00e4s\u00b7ti\u00b7on", ",", "mein", "Freund", ",", "ist", "ei\u00b7ner", "von", "den", "From\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "VAFIN", "ART", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Zeus, indem er schuf, sch\u00f6nherzig hat gemacht.", "tokens": ["Die", "Zeus", ",", "in\u00b7dem", "er", "schuf", ",", "sch\u00f6n\u00b7her\u00b7zig", "hat", "ge\u00b7macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Er lag in einer Winternacht", "tokens": ["Er", "lag", "in", "ei\u00b7ner", "Win\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im besten Schlaf, den je das Gastmahl noch gebracht,", "tokens": ["Im", "bes\u00b7ten", "Schlaf", ",", "den", "je", "das", "Gast\u00b7mahl", "noch", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "PRELS", "ADV", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo, mit dem Duft vom Wein, geselliges Vergn\u00fcgen", "tokens": ["Wo", ",", "mit", "dem", "Duft", "vom", "Wein", ",", "ge\u00b7sel\u00b7li\u00b7ges", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "$,", "APPR", "ART", "NN", "APPRART", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Freunden in den Kopf gestiegen,", "tokens": ["Den", "Freun\u00b7den", "in", "den", "Kopf", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und vom Gespr\u00e4ch ihr Herz berauscht gemacht.", "tokens": ["Und", "vom", "Ge\u00b7spr\u00e4ch", "ihr", "Herz", "be\u00b7rauscht", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "PPOSAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Er schlief so s\u00fc\u00df, als wie bey einem Wasserfalle,", "tokens": ["Er", "schlief", "so", "s\u00fc\u00df", ",", "als", "wie", "bey", "ei\u00b7nem", "Was\u00b7ser\u00b7fal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "KOUS", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "In welchem Gra\u00df, ein Wandrer schlafen liegt;", "tokens": ["In", "wel\u00b7chem", "Gra\u00df", ",", "ein", "Wand\u00b7rer", "schla\u00b7fen", "liegt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "$,", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Er sah im Traum Roms Helden alle", "tokens": ["Er", "sah", "im", "Traum", "Roms", "Hel\u00b7den", "al\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "NE", "NN", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und Griechenlandes, das so oft mit Rom gekriegt.", "tokens": ["Und", "Grie\u00b7chen\u00b7lan\u00b7des", ",", "das", "so", "oft", "mit", "Rom", "ge\u00b7kriegt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "ADV", "ADV", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der Luftcrey\u00df war, als wie in Fr\u00fchlingstagen heiter;", "tokens": ["Der", "Luft\u00b7crey\u00df", "war", ",", "als", "wie", "in", "Fr\u00fch\u00b7lings\u00b7ta\u00b7gen", "hei\u00b7ter", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "KOUS", "KOKOM", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Auf einmal aber ward prachtvolle Mahlerey", "tokens": ["Auf", "ein\u00b7mal", "a\u00b7ber", "ward", "pracht\u00b7vol\u00b7le", "Mah\u00b7le\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "VAFIN", "ADJA", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Von Wolken in der Luft, da zogen grosse Streiter", "tokens": ["Von", "Wol\u00b7ken", "in", "der", "Luft", ",", "da", "zo\u00b7gen", "gros\u00b7se", "Strei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$,", "ADV", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Mit gl\u00e4nzendem Gewehr vorbey.", "tokens": ["Mit", "gl\u00e4n\u00b7zen\u00b7dem", "Ge\u00b7wehr", "vor\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Macedonier, noch mehr bespr\u00fctzt mit Blute,", "tokens": ["Der", "Ma\u00b7ce\u00b7do\u00b7nier", ",", "noch", "mehr", "be\u00b7spr\u00fctzt", "mit", "Blu\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADV", "VVPP", "APPR", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Als beym niphatischen Geb\u00fcrge, wo", "tokens": ["Als", "beym", "ni\u00b7pha\u00b7ti\u00b7schen", "Ge\u00b7b\u00fcr\u00b7ge", ",", "wo"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "APPRART", "ADJA", "NN", "$,", "PWAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Perser, den er schlug, auf einer matten Stute", "tokens": ["Der", "Per\u00b7ser", ",", "den", "er", "schlug", ",", "auf", "ei\u00b7ner", "mat\u00b7ten", "Stu\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und \u00fcber Leichenberge noch entfloh.", "tokens": ["Und", "\u00fc\u00b7ber", "Lei\u00b7chen\u00b7ber\u00b7ge", "noch", "ent\u00b7floh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Noch siegbegieriger, als bey den Donnerschl\u00e4gen", "tokens": ["Noch", "sieg\u00b7be\u00b7gie\u00b7ri\u00b7ger", ",", "als", "bey", "den", "Don\u00b7ner\u00b7schl\u00e4\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo starker Sturm den schnell herabgego\u00dfnen Regen", "tokens": ["Wo", "star\u00b7ker", "Sturm", "den", "schnell", "her\u00b7ab\u00b7ge\u00b7go\u00df\u00b7nen", "Re\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "NN", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ans Ufer des Hydaspes schlug,", "tokens": ["Ans", "U\u00b7fer", "des", "Hy\u00b7das\u00b7pes", "schlug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Ein St\u00fcck des Ufers nahm, und eine Insel machte,", "tokens": ["Ein", "St\u00fcck", "des", "U\u00b7fers", "nahm", ",", "und", "ei\u00b7ne", "In\u00b7sel", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die in dem Flusse schwamm und den Erobrer trug,", "tokens": ["Die", "in", "dem", "Flus\u00b7se", "schwamm", "und", "den", "E\u00b7rob\u00b7rer", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der halb im Wasser stand, den Tod des Porus dachte,", "tokens": ["Der", "halb", "im", "Was\u00b7ser", "stand", ",", "den", "Tod", "des", "Po\u00b7rus", "dach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPRART", "NN", "VVFIN", "$,", "ART", "NN", "ART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und Wuth und Sieg her\u00fcber brachte.", "tokens": ["Und", "Wuth", "und", "Sieg", "her\u00b7\u00fc\u00b7ber", "brach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Noch pr\u00e4chtiger sah in dem Traum", "tokens": ["Noch", "pr\u00e4ch\u00b7ti\u00b7ger", "sah", "in", "dem", "Traum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Mein Freund ihn auf dem Thron des Persianers sitzen,", "tokens": ["Mein", "Freund", "ihn", "auf", "dem", "Thron", "des", "Per\u00b7si\u00b7a\u00b7ners", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gefangne K\u00f6nige zu seiner F\u00fcssen Raum,", "tokens": ["Ge\u00b7fang\u00b7ne", "K\u00f6\u00b7ni\u00b7ge", "zu", "sei\u00b7ner", "F\u00fcs\u00b7sen", "Raum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Nationen fliehn vor seines Auges Blitzen.", "tokens": ["Und", "Na\u00b7ti\u00b7o\u00b7nen", "fliehn", "vor", "sei\u00b7nes", "Au\u00b7ges", "Blit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Auch sah' er C\u00e4sarn, der, den Feinden zu entkommen,", "tokens": ["Auch", "sah'", "er", "C\u00e4\u00b7sarn", ",", "der", ",", "den", "Fein\u00b7den", "zu", "ent\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "$,", "PRELS", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sich aus dem kleinen Schiff geworfen in die See,", "tokens": ["Sich", "aus", "dem", "klei\u00b7nen", "Schiff", "ge\u00b7wor\u00b7fen", "in", "die", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit einer Hand fortruderte", "tokens": ["Mit", "ei\u00b7ner", "Hand", "for\u00b7tru\u00b7der\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und in der andern Hand, die Briefe festgenommen", "tokens": ["Und", "in", "der", "an\u00b7dern", "Hand", ",", "die", "Brie\u00b7fe", "fest\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Frey \u00fcber seinem Haupte tr\u00e4gt,", "tokens": ["Frey", "\u00fc\u00b7ber", "sei\u00b7nem", "Haup\u00b7te", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ans Trockne kommt, noch feucht vom Meere,", "tokens": ["Ans", "Trock\u00b7ne", "kommt", ",", "noch", "feucht", "vom", "Mee\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Den K\u00f6nig der Egypter schl\u00e4gt,", "tokens": ["Den", "K\u00f6\u00b7nig", "der", "E\u00b7gyp\u00b7ter", "schl\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und dann mit seinem Heldenheere", "tokens": ["Und", "dann", "mit", "sei\u00b7nem", "Hel\u00b7den\u00b7hee\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Bey Zella den Pharnaces sieht,", "tokens": ["Bey", "Zel\u00b7la", "den", "Phar\u00b7na\u00b7ces", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ART", "NN", "VVFIN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.10": {"text": "Schl\u00e4gt, \u00fcberwindet, und als Sieger weiter zieht.", "tokens": ["Schl\u00e4gt", ",", "\u00fc\u00b7berw\u00b7in\u00b7det", ",", "und", "als", "Sie\u00b7ger", "wei\u00b7ter", "zieht", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "KON", "KOUS", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Noch mehr! Es schilderte die wunderbare Wolke", "tokens": ["Noch", "mehr", "!", "Es", "schil\u00b7der\u00b7te", "die", "wun\u00b7der\u00b7ba\u00b7re", "Wol\u00b7ke"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den dritten pr\u00e4chtigen Triumph Pompejus ab,", "tokens": ["Den", "drit\u00b7ten", "pr\u00e4ch\u00b7ti\u00b7gen", "Tri\u00b7umph", "Pom\u00b7pe\u00b7jus", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "NE", "PTKVZ", "$,"], "meter": "-+-+--+-++-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und wie er Korn genug zu Rom dem armen Volke;", "tokens": ["Und", "wie", "er", "Korn", "ge\u00b7nug", "zu", "Rom", "dem", "ar\u00b7men", "Vol\u00b7ke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "NN", "ADV", "APPR", "NE", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie er die Sicherheit dem Meer vor R\u00e4ubern, gab.", "tokens": ["Wie", "er", "die", "Si\u00b7cher\u00b7heit", "dem", "Meer", "vor", "R\u00e4u\u00b7bern", ",", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ART", "NN", "APPR", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Da waren Hercules, Achill, und alle Helden", "tokens": ["Da", "wa\u00b7ren", "Her\u00b7cu\u00b7les", ",", "A\u00b7chill", ",", "und", "al\u00b7le", "Hel\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "$,", "ITJ", "$,", "KON", "PIAT", "NN"], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Des Alterthums, glorreicher vorgestellt,", "tokens": ["Des", "Al\u00b7ter\u00b7thums", ",", "glor\u00b7rei\u00b7cher", "vor\u00b7ge\u00b7stellt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als jemals die Geschichte melden,", "tokens": ["Als", "je\u00b7mals", "die", "Ge\u00b7schich\u00b7te", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und jemals noch ein K\u00fcnstler in der Welt", "tokens": ["Und", "je\u00b7mals", "noch", "ein", "K\u00fcnst\u00b7ler", "in", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Erobrer, Sieger, Triumphirer,", "tokens": ["E\u00b7rob\u00b7rer", ",", "Sie\u00b7ger", ",", "Tri\u00b7um\u00b7phi\u00b7rer", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mit kriegerischer Gluth im Antlitz vorgestellt.", "tokens": ["Mit", "krie\u00b7ge\u00b7ri\u00b7scher", "Gluth", "im", "Ant\u00b7litz", "vor\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mein Freund betrachtete die Bilder dieser F\u00fchrer,", "tokens": ["Mein", "Freund", "be\u00b7trach\u00b7te\u00b7te", "die", "Bil\u00b7der", "die\u00b7ser", "F\u00fch\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Rief sein Ged\u00e4chtni\u00df auf, und fand,", "tokens": ["Rief", "sein", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", "auf", ",", "und", "fand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df diese Mahlerey da nicht gezeichnet stand.", "tokens": ["Da\u00df", "die\u00b7se", "Mah\u00b7le\u00b7rey", "da", "nicht", "ge\u00b7zeich\u00b7net", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ADV", "PTKNEG", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Er staunte, dachte tief, bewunderte die Bilder,", "tokens": ["Er", "staun\u00b7te", ",", "dach\u00b7te", "tief", ",", "be\u00b7wun\u00b7der\u00b7te", "die", "Bil\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "ADJD", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als vom Olymp Minerva zu ihm kam,", "tokens": ["Als", "vom", "O\u00b7lymp", "Mi\u00b7ner\u00b7va", "zu", "ihm", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "NE", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Ihr feurig Auge blickte milder", "tokens": ["Ihr", "feu\u00b7rig", "Au\u00b7ge", "blick\u00b7te", "mil\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihn an, sie sprach, und er vernahm:", "tokens": ["Ihn", "an", ",", "sie", "sprach", ",", "und", "er", "ver\u00b7nahm", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbda\u00df diese Schaar von F\u00fchrern grosser Heere,", "tokens": ["\u00bb", "da\u00df", "die\u00b7se", "Schaar", "von", "F\u00fch\u00b7rern", "gros\u00b7ser", "Hee\u00b7re", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PDAT", "NN", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die Schilderey von einem Helden w\u00e4re,", "tokens": ["Die", "Schil\u00b7de\u00b7rey", "von", "ei\u00b7nem", "Hel\u00b7den", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Den Rom und den das Griechenland", "tokens": ["Den", "Rom", "und", "den", "das", "Grie\u00b7chen\u00b7land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "KON", "ART", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So gl\u00e4nzend nicht gehabt, und der f\u00fcr seine Staaten", "tokens": ["So", "gl\u00e4n\u00b7zend", "nicht", "ge\u00b7habt", ",", "und", "der", "f\u00fcr", "sei\u00b7ne", "Staa\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PTKNEG", "VAPP", "$,", "KON", "ART", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Allein so viel gethan, als alle diese thaten.\u00ab", "tokens": ["Al\u00b7lein", "so", "viel", "ge\u00b7than", ",", "als", "al\u00b7le", "die\u00b7se", "tha\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ADV", "VVPP", "$,", "KOUS", "PIS", "PDS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die G\u00f6ttin sprach es, und verschwand.", "tokens": ["Die", "G\u00f6t\u00b7tin", "sprach", "es", ",", "und", "ver\u00b7schwand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Und pl\u00f6tzlich stiessen Alexander,", "tokens": ["Und", "pl\u00f6tz\u00b7lich", "sties\u00b7sen", "A\u00b7lex\u00b7an\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und C\u00e4sar mit dem Speer und Schilden an einander,", "tokens": ["Und", "C\u00e4\u00b7sar", "mit", "dem", "Speer", "und", "Schil\u00b7den", "an", "ein\u00b7an\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "ART", "NN", "KON", "NN", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es ward ein stark Ger\u00e4usch; die Wolken trennten sich,", "tokens": ["Es", "ward", "ein", "stark", "Ge\u00b7r\u00e4usch", ";", "die", "Wol\u00b7ken", "trenn\u00b7ten", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "NN", "$.", "ART", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und mein erwachter Freund rief: Gro\u00df ist Friederich!", "tokens": ["Und", "mein", "er\u00b7wach\u00b7ter", "Freund", "rief", ":", "Gro\u00df", "ist", "Frie\u00b7de\u00b7rich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "$.", "ADJD", "VAFIN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Gliph\u00e4stion, mein Freund, der nicht zu tr\u00e4umen pflegt,", "tokens": ["Gli\u00b7ph\u00e4s\u00b7ti\u00b7on", ",", "mein", "Freund", ",", "der", "nicht", "zu", "tr\u00e4u\u00b7men", "pflegt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "PRELS", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht abergl\u00e4ubisch forscht, nicht Zeichendeuter fr\u00e4gt,", "tokens": ["Nicht", "a\u00b7berg\u00b7l\u00e4u\u00b7bisch", "forscht", ",", "nicht", "Zei\u00b7chen\u00b7deu\u00b7ter", "fr\u00e4gt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVPP", "$,", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Ku\u00df und Freuden nimmt, die ungeweissagt kommen;", "tokens": ["Der", "Ku\u00df", "und", "Freu\u00b7den", "nimmt", ",", "die", "un\u00b7ge\u00b7weis\u00b7sagt", "kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$,", "PRELS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gliph\u00e4stion, mein Freund, ist einer von den Frommen,", "tokens": ["Gli\u00b7ph\u00e4s\u00b7ti\u00b7on", ",", "mein", "Freund", ",", "ist", "ei\u00b7ner", "von", "den", "From\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "VAFIN", "ART", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Zeus, indem er schuf, sch\u00f6nherzig hat gemacht.", "tokens": ["Die", "Zeus", ",", "in\u00b7dem", "er", "schuf", ",", "sch\u00f6n\u00b7her\u00b7zig", "hat", "ge\u00b7macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Er lag in einer Winternacht", "tokens": ["Er", "lag", "in", "ei\u00b7ner", "Win\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im besten Schlaf, den je das Gastmahl noch gebracht,", "tokens": ["Im", "bes\u00b7ten", "Schlaf", ",", "den", "je", "das", "Gast\u00b7mahl", "noch", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "PRELS", "ADV", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo, mit dem Duft vom Wein, geselliges Vergn\u00fcgen", "tokens": ["Wo", ",", "mit", "dem", "Duft", "vom", "Wein", ",", "ge\u00b7sel\u00b7li\u00b7ges", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "$,", "APPR", "ART", "NN", "APPRART", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Freunden in den Kopf gestiegen,", "tokens": ["Den", "Freun\u00b7den", "in", "den", "Kopf", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und vom Gespr\u00e4ch ihr Herz berauscht gemacht.", "tokens": ["Und", "vom", "Ge\u00b7spr\u00e4ch", "ihr", "Herz", "be\u00b7rauscht", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "PPOSAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Er schlief so s\u00fc\u00df, als wie bey einem Wasserfalle,", "tokens": ["Er", "schlief", "so", "s\u00fc\u00df", ",", "als", "wie", "bey", "ei\u00b7nem", "Was\u00b7ser\u00b7fal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "KOUS", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "In welchem Gra\u00df, ein Wandrer schlafen liegt;", "tokens": ["In", "wel\u00b7chem", "Gra\u00df", ",", "ein", "Wand\u00b7rer", "schla\u00b7fen", "liegt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "$,", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Er sah im Traum Roms Helden alle", "tokens": ["Er", "sah", "im", "Traum", "Roms", "Hel\u00b7den", "al\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "NE", "NN", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und Griechenlandes, das so oft mit Rom gekriegt.", "tokens": ["Und", "Grie\u00b7chen\u00b7lan\u00b7des", ",", "das", "so", "oft", "mit", "Rom", "ge\u00b7kriegt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "ADV", "ADV", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der Luftcrey\u00df war, als wie in Fr\u00fchlingstagen heiter;", "tokens": ["Der", "Luft\u00b7crey\u00df", "war", ",", "als", "wie", "in", "Fr\u00fch\u00b7lings\u00b7ta\u00b7gen", "hei\u00b7ter", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "KOUS", "KOKOM", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Auf einmal aber ward prachtvolle Mahlerey", "tokens": ["Auf", "ein\u00b7mal", "a\u00b7ber", "ward", "pracht\u00b7vol\u00b7le", "Mah\u00b7le\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "VAFIN", "ADJA", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Von Wolken in der Luft, da zogen grosse Streiter", "tokens": ["Von", "Wol\u00b7ken", "in", "der", "Luft", ",", "da", "zo\u00b7gen", "gros\u00b7se", "Strei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$,", "ADV", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Mit gl\u00e4nzendem Gewehr vorbey.", "tokens": ["Mit", "gl\u00e4n\u00b7zen\u00b7dem", "Ge\u00b7wehr", "vor\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Der Macedonier, noch mehr bespr\u00fctzt mit Blute,", "tokens": ["Der", "Ma\u00b7ce\u00b7do\u00b7nier", ",", "noch", "mehr", "be\u00b7spr\u00fctzt", "mit", "Blu\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADV", "VVPP", "APPR", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Als beym niphatischen Geb\u00fcrge, wo", "tokens": ["Als", "beym", "ni\u00b7pha\u00b7ti\u00b7schen", "Ge\u00b7b\u00fcr\u00b7ge", ",", "wo"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "APPRART", "ADJA", "NN", "$,", "PWAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Perser, den er schlug, auf einer matten Stute", "tokens": ["Der", "Per\u00b7ser", ",", "den", "er", "schlug", ",", "auf", "ei\u00b7ner", "mat\u00b7ten", "Stu\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und \u00fcber Leichenberge noch entfloh.", "tokens": ["Und", "\u00fc\u00b7ber", "Lei\u00b7chen\u00b7ber\u00b7ge", "noch", "ent\u00b7floh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Noch siegbegieriger, als bey den Donnerschl\u00e4gen", "tokens": ["Noch", "sieg\u00b7be\u00b7gie\u00b7ri\u00b7ger", ",", "als", "bey", "den", "Don\u00b7ner\u00b7schl\u00e4\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo starker Sturm den schnell herabgego\u00dfnen Regen", "tokens": ["Wo", "star\u00b7ker", "Sturm", "den", "schnell", "her\u00b7ab\u00b7ge\u00b7go\u00df\u00b7nen", "Re\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "NN", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ans Ufer des Hydaspes schlug,", "tokens": ["Ans", "U\u00b7fer", "des", "Hy\u00b7das\u00b7pes", "schlug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Ein St\u00fcck des Ufers nahm, und eine Insel machte,", "tokens": ["Ein", "St\u00fcck", "des", "U\u00b7fers", "nahm", ",", "und", "ei\u00b7ne", "In\u00b7sel", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die in dem Flusse schwamm und den Erobrer trug,", "tokens": ["Die", "in", "dem", "Flus\u00b7se", "schwamm", "und", "den", "E\u00b7rob\u00b7rer", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der halb im Wasser stand, den Tod des Porus dachte,", "tokens": ["Der", "halb", "im", "Was\u00b7ser", "stand", ",", "den", "Tod", "des", "Po\u00b7rus", "dach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPRART", "NN", "VVFIN", "$,", "ART", "NN", "ART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und Wuth und Sieg her\u00fcber brachte.", "tokens": ["Und", "Wuth", "und", "Sieg", "her\u00b7\u00fc\u00b7ber", "brach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Noch pr\u00e4chtiger sah in dem Traum", "tokens": ["Noch", "pr\u00e4ch\u00b7ti\u00b7ger", "sah", "in", "dem", "Traum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Mein Freund ihn auf dem Thron des Persianers sitzen,", "tokens": ["Mein", "Freund", "ihn", "auf", "dem", "Thron", "des", "Per\u00b7si\u00b7a\u00b7ners", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gefangne K\u00f6nige zu seiner F\u00fcssen Raum,", "tokens": ["Ge\u00b7fang\u00b7ne", "K\u00f6\u00b7ni\u00b7ge", "zu", "sei\u00b7ner", "F\u00fcs\u00b7sen", "Raum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Nationen fliehn vor seines Auges Blitzen.", "tokens": ["Und", "Na\u00b7ti\u00b7o\u00b7nen", "fliehn", "vor", "sei\u00b7nes", "Au\u00b7ges", "Blit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Auch sah' er C\u00e4sarn, der, den Feinden zu entkommen,", "tokens": ["Auch", "sah'", "er", "C\u00e4\u00b7sarn", ",", "der", ",", "den", "Fein\u00b7den", "zu", "ent\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "$,", "PRELS", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sich aus dem kleinen Schiff geworfen in die See,", "tokens": ["Sich", "aus", "dem", "klei\u00b7nen", "Schiff", "ge\u00b7wor\u00b7fen", "in", "die", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit einer Hand fortruderte", "tokens": ["Mit", "ei\u00b7ner", "Hand", "for\u00b7tru\u00b7der\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und in der andern Hand, die Briefe festgenommen", "tokens": ["Und", "in", "der", "an\u00b7dern", "Hand", ",", "die", "Brie\u00b7fe", "fest\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Frey \u00fcber seinem Haupte tr\u00e4gt,", "tokens": ["Frey", "\u00fc\u00b7ber", "sei\u00b7nem", "Haup\u00b7te", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ans Trockne kommt, noch feucht vom Meere,", "tokens": ["Ans", "Trock\u00b7ne", "kommt", ",", "noch", "feucht", "vom", "Mee\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Den K\u00f6nig der Egypter schl\u00e4gt,", "tokens": ["Den", "K\u00f6\u00b7nig", "der", "E\u00b7gyp\u00b7ter", "schl\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und dann mit seinem Heldenheere", "tokens": ["Und", "dann", "mit", "sei\u00b7nem", "Hel\u00b7den\u00b7hee\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Bey Zella den Pharnaces sieht,", "tokens": ["Bey", "Zel\u00b7la", "den", "Phar\u00b7na\u00b7ces", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ART", "NN", "VVFIN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.10": {"text": "Schl\u00e4gt, \u00fcberwindet, und als Sieger weiter zieht.", "tokens": ["Schl\u00e4gt", ",", "\u00fc\u00b7berw\u00b7in\u00b7det", ",", "und", "als", "Sie\u00b7ger", "wei\u00b7ter", "zieht", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "KON", "KOUS", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Noch mehr! Es schilderte die wunderbare Wolke", "tokens": ["Noch", "mehr", "!", "Es", "schil\u00b7der\u00b7te", "die", "wun\u00b7der\u00b7ba\u00b7re", "Wol\u00b7ke"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den dritten pr\u00e4chtigen Triumph Pompejus ab,", "tokens": ["Den", "drit\u00b7ten", "pr\u00e4ch\u00b7ti\u00b7gen", "Tri\u00b7umph", "Pom\u00b7pe\u00b7jus", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "NE", "PTKVZ", "$,"], "meter": "-+-+--+-++-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und wie er Korn genug zu Rom dem armen Volke;", "tokens": ["Und", "wie", "er", "Korn", "ge\u00b7nug", "zu", "Rom", "dem", "ar\u00b7men", "Vol\u00b7ke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "NN", "ADV", "APPR", "NE", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie er die Sicherheit dem Meer vor R\u00e4ubern, gab.", "tokens": ["Wie", "er", "die", "Si\u00b7cher\u00b7heit", "dem", "Meer", "vor", "R\u00e4u\u00b7bern", ",", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ART", "NN", "APPR", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Da waren Hercules, Achill, und alle Helden", "tokens": ["Da", "wa\u00b7ren", "Her\u00b7cu\u00b7les", ",", "A\u00b7chill", ",", "und", "al\u00b7le", "Hel\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "$,", "ITJ", "$,", "KON", "PIAT", "NN"], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Des Alterthums, glorreicher vorgestellt,", "tokens": ["Des", "Al\u00b7ter\u00b7thums", ",", "glor\u00b7rei\u00b7cher", "vor\u00b7ge\u00b7stellt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als jemals die Geschichte melden,", "tokens": ["Als", "je\u00b7mals", "die", "Ge\u00b7schich\u00b7te", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und jemals noch ein K\u00fcnstler in der Welt", "tokens": ["Und", "je\u00b7mals", "noch", "ein", "K\u00fcnst\u00b7ler", "in", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Erobrer, Sieger, Triumphirer,", "tokens": ["E\u00b7rob\u00b7rer", ",", "Sie\u00b7ger", ",", "Tri\u00b7um\u00b7phi\u00b7rer", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mit kriegerischer Gluth im Antlitz vorgestellt.", "tokens": ["Mit", "krie\u00b7ge\u00b7ri\u00b7scher", "Gluth", "im", "Ant\u00b7litz", "vor\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mein Freund betrachtete die Bilder dieser F\u00fchrer,", "tokens": ["Mein", "Freund", "be\u00b7trach\u00b7te\u00b7te", "die", "Bil\u00b7der", "die\u00b7ser", "F\u00fch\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Rief sein Ged\u00e4chtni\u00df auf, und fand,", "tokens": ["Rief", "sein", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", "auf", ",", "und", "fand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df diese Mahlerey da nicht gezeichnet stand.", "tokens": ["Da\u00df", "die\u00b7se", "Mah\u00b7le\u00b7rey", "da", "nicht", "ge\u00b7zeich\u00b7net", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ADV", "PTKNEG", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Er staunte, dachte tief, bewunderte die Bilder,", "tokens": ["Er", "staun\u00b7te", ",", "dach\u00b7te", "tief", ",", "be\u00b7wun\u00b7der\u00b7te", "die", "Bil\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "ADJD", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als vom Olymp Minerva zu ihm kam,", "tokens": ["Als", "vom", "O\u00b7lymp", "Mi\u00b7ner\u00b7va", "zu", "ihm", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "NE", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Ihr feurig Auge blickte milder", "tokens": ["Ihr", "feu\u00b7rig", "Au\u00b7ge", "blick\u00b7te", "mil\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihn an, sie sprach, und er vernahm:", "tokens": ["Ihn", "an", ",", "sie", "sprach", ",", "und", "er", "ver\u00b7nahm", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbda\u00df diese Schaar von F\u00fchrern grosser Heere,", "tokens": ["\u00bb", "da\u00df", "die\u00b7se", "Schaar", "von", "F\u00fch\u00b7rern", "gros\u00b7ser", "Hee\u00b7re", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PDAT", "NN", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die Schilderey von einem Helden w\u00e4re,", "tokens": ["Die", "Schil\u00b7de\u00b7rey", "von", "ei\u00b7nem", "Hel\u00b7den", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Den Rom und den das Griechenland", "tokens": ["Den", "Rom", "und", "den", "das", "Grie\u00b7chen\u00b7land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "KON", "ART", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So gl\u00e4nzend nicht gehabt, und der f\u00fcr seine Staaten", "tokens": ["So", "gl\u00e4n\u00b7zend", "nicht", "ge\u00b7habt", ",", "und", "der", "f\u00fcr", "sei\u00b7ne", "Staa\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PTKNEG", "VAPP", "$,", "KON", "ART", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Allein so viel gethan, als alle diese thaten.\u00ab", "tokens": ["Al\u00b7lein", "so", "viel", "ge\u00b7than", ",", "als", "al\u00b7le", "die\u00b7se", "tha\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ADV", "VVPP", "$,", "KOUS", "PIS", "PDS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die G\u00f6ttin sprach es, und verschwand.", "tokens": ["Die", "G\u00f6t\u00b7tin", "sprach", "es", ",", "und", "ver\u00b7schwand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Und pl\u00f6tzlich stiessen Alexander,", "tokens": ["Und", "pl\u00f6tz\u00b7lich", "sties\u00b7sen", "A\u00b7lex\u00b7an\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und C\u00e4sar mit dem Speer und Schilden an einander,", "tokens": ["Und", "C\u00e4\u00b7sar", "mit", "dem", "Speer", "und", "Schil\u00b7den", "an", "ein\u00b7an\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "ART", "NN", "KON", "NN", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es ward ein stark Ger\u00e4usch; die Wolken trennten sich,", "tokens": ["Es", "ward", "ein", "stark", "Ge\u00b7r\u00e4usch", ";", "die", "Wol\u00b7ken", "trenn\u00b7ten", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "NN", "$.", "ART", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und mein erwachter Freund rief: Gro\u00df ist Friederich!", "tokens": ["Und", "mein", "er\u00b7wach\u00b7ter", "Freund", "rief", ":", "Gro\u00df", "ist", "Frie\u00b7de\u00b7rich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "$.", "ADJD", "VAFIN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}