{"textgrid.poem.37513": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Neuntens", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der heilige Antonius von Padua", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", "von", "Pa\u00b7dua"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "APPR", "NE"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Sa\u00df oftmals ganz alleinig da", "tokens": ["Sa\u00df", "oft\u00b7mals", "ganz", "al\u00b7lei\u00b7nig", "da"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und las bei seinem Heilgenschein", "tokens": ["Und", "las", "bei", "sei\u00b7nem", "Heil\u00b7gen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Meistens bis tief in die Nacht hinein. \u2013", "tokens": ["Meis\u00b7tens", "bis", "tief", "in", "die", "Nacht", "hin\u00b7ein", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ADJD", "APPR", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "Einst, als er wieder so sitzt und liest \u2013", "tokens": ["Einst", ",", "als", "er", "wie\u00b7der", "so", "sitzt", "und", "liest", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "ADV", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u2013 Auf einmal, so r\u00e4uspert sich was und niest;", "tokens": ["\u2013", "Auf", "ein\u00b7mal", ",", "so", "r\u00e4us\u00b7pert", "sich", "was", "und", "niest", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ADV", "$,", "ADV", "VVFIN", "PRF", "PWS", "KON", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und wie er sich umschaut, der fromme Mann,", "tokens": ["Und", "wie", "er", "sich", "um\u00b7schaut", ",", "der", "from\u00b7me", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PRF", "VVPP", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Schaut ihn ein h\u00fcbsches M\u00e4dchen an. \u2013 \u2013", "tokens": ["Schaut", "ihn", "ein", "h\u00fcb\u00b7sches", "M\u00e4d\u00b7chen", "an", ".", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u2013 Der heilige Antonius von Padua", "tokens": ["\u2013", "Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", "von", "Pa\u00b7dua"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADJA", "NE", "APPR", "NE"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "War aber ganz ruhig, als dies geschah.", "tokens": ["War", "a\u00b7ber", "ganz", "ru\u00b7hig", ",", "als", "dies", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "$,", "KOUS", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Er sprach: \u00bbSchau du nur immer zu,", "tokens": ["Er", "sprach", ":", "\u00bb", "Schau", "du", "nur", "im\u00b7mer", "zu", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "NN", "PPER", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.8": {"text": "Du st\u00f6rst mich nicht in meiner christlichen Ruh!\u00ab", "tokens": ["Du", "st\u00f6rst", "mich", "nicht", "in", "mei\u00b7ner", "christ\u00b7li\u00b7chen", "Ruh", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.3": {"line.1": {"text": "Als er nun wieder so ruhig sa\u00df", "tokens": ["Als", "er", "nun", "wie\u00b7der", "so", "ru\u00b7hig", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ADJD", "VVFIN"], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und weiter in seinem Buche las \u2013", "tokens": ["Und", "wei\u00b7ter", "in", "sei\u00b7nem", "Bu\u00b7che", "las", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Husch, husch! \u2013 so sp\u00fcrt er auf der Glatzen", "tokens": ["Husch", ",", "husch", "!", "\u2013", "so", "sp\u00fcrt", "er", "auf", "der", "Glat\u00b7zen"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "ADJD", "$.", "$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und hinterm Ohr ein Kribbelkratzen,", "tokens": ["Und", "hin\u00b7term", "Ohr", "ein", "Krib\u00b7bel\u00b7krat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df ihm dabei ganz sonderbar,", "tokens": ["Da\u00df", "ihm", "da\u00b7bei", "ganz", "son\u00b7der\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bald warm, bald kalt zumute war. \u2013", "tokens": ["Bald", "warm", ",", "bald", "kalt", "zu\u00b7mu\u00b7te", "war", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "ADV", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der heilige Antonius von Padua", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", "von", "Pa\u00b7dua"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "APPR", "NE"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.8": {"text": "War aber ganz ruhig, als dies geschah.", "tokens": ["War", "a\u00b7ber", "ganz", "ru\u00b7hig", ",", "als", "dies", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "$,", "KOUS", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Er sprach: \u00bbSo krabble du nur zu,", "tokens": ["Er", "sprach", ":", "\u00bb", "So", "krabb\u00b7le", "du", "nur", "zu", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Du st\u00f6rst mich nicht in meiner christlichen Ruh!\u00ab", "tokens": ["Du", "st\u00f6rst", "mich", "nicht", "in", "mei\u00b7ner", "christ\u00b7li\u00b7chen", "Ruh", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.4": {"line.1": {"text": "\u00bbna! \u2013 \u2013 Na!\u00ab \u2013 \u2013", "tokens": ["\u00bb", "na", "!", "\u2013", "\u2013", "Na", "!", "\u00ab", "\u2013", "\u2013"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["$(", "ITJ", "$.", "$(", "$(", "ITJ", "$.", "$(", "$(", "$("], "meter": "+-", "measure": "trochaic.single"}}, "stanza.5": {"line.1": {"text": "\u00bbna, na! \u2013 sag' ich!!!\u00ab \u2013", "tokens": ["\u00bb", "na", ",", "na", "!", "\u2013", "sag'", "ich", "!!!", "\u00ab", "\u2013"], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "ITJ", "$.", "$(", "VVIMP", "PPER", "$.", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "\u00bbhm! hm! \u2013 \u2013 hm! hm!!!\u00ab", "tokens": ["\u00bb", "hm", "!", "hm", "!", "\u2013", "\u2013", "hm", "!", "hm", "!!!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "NE", "$.", "NE", "$.", "$(", "$(", "NE", "$.", "NE", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Auf einmal aber \u2013 er wu\u00dfte nicht wie \u2013", "tokens": ["Auf", "ein\u00b7mal", "a\u00b7ber", "\u2013", "er", "wu\u00df\u00b7te", "nicht", "wie", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "$(", "PPER", "VVFIN", "PTKNEG", "KOKOM", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Setzt sich das M\u00e4del ihm gar aufs Knie", "tokens": ["Setzt", "sich", "das", "M\u00e4\u00b7del", "ihm", "gar", "aufs", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN", "PPER", "ADV", "APPRART", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Und gibt dem heiligen Antonius", "tokens": ["Und", "gibt", "dem", "hei\u00b7li\u00b7gen", "An\u00b7to\u00b7ni\u00b7us"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Links und rechts einen herzhaften Ku\u00df.", "tokens": ["Links", "und", "rechts", "ei\u00b7nen", "herz\u00b7haf\u00b7ten", "Ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "Der heilige Antonius von Padua", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", "von", "Pa\u00b7dua"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "APPR", "NE"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "War aber nicht ruhig, als dies geschah.", "tokens": ["War", "a\u00b7ber", "nicht", "ru\u00b7hig", ",", "als", "dies", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADJD", "$,", "KOUS", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er sprang empor, von Zorn entbrannt;", "tokens": ["Er", "sprang", "em\u00b7por", ",", "von", "Zorn", "ent\u00b7brannt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er nahm das Kreuz in seine Hand:", "tokens": ["Er", "nahm", "das", "Kreuz", "in", "sei\u00b7ne", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "\u00bbla\u00df ab von mir, unsaubrer Geist!", "tokens": ["\u00bb", "la\u00df", "ab", "von", "mir", ",", "un\u00b7sau\u00b7brer", "Geist", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PTKVZ", "APPR", "PPER", "$,", "PPOSAT", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Sei, wie du bist, wer du auch seist!!\u00ab", "tokens": ["Sei", ",", "wie", "du", "bist", ",", "wer", "du", "auch", "seist", "!!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PPER", "VAFIN", "$,", "PWS", "PPER", "ADV", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Puh!! \u2013 da sauste mit gro\u00dfem Rumor", "tokens": ["Puh", "!!", "\u2013", "da", "saus\u00b7te", "mit", "gro\u00b7\u00dfem", "Ru\u00b7mor"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "$(", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Der Satanas durchs Ofenrohr.", "tokens": ["Der", "Sa\u00b7ta\u00b7nas", "durchs", "O\u00b7fen\u00b7rohr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der heilige Antonius, ruhig und heiter,", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", ",", "ru\u00b7hig", "und", "hei\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Las aber in seinem Buche weiter! \u2013", "tokens": ["Las", "a\u00b7ber", "in", "sei\u00b7nem", "Bu\u00b7che", "wei\u00b7ter", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Oh, heil'ger Antonius von Padua,", "tokens": ["Oh", ",", "heil'\u00b7ger", "An\u00b7to\u00b7ni\u00b7us", "von", "Pa\u00b7dua", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADJA", "NE", "APPR", "NE", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Du kennst uns ja!", "tokens": ["Du", "kennst", "uns", "ja", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "So la\u00df uns denn auf dieser Erden", "tokens": ["So", "la\u00df", "uns", "denn", "auf", "die\u00b7ser", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch solche fromme Heilge werden!", "tokens": ["Auch", "sol\u00b7che", "from\u00b7me", "Heil\u00b7ge", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Der heilige Antonius von Padua", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", "von", "Pa\u00b7dua"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "APPR", "NE"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Sa\u00df oftmals ganz alleinig da", "tokens": ["Sa\u00df", "oft\u00b7mals", "ganz", "al\u00b7lei\u00b7nig", "da"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und las bei seinem Heilgenschein", "tokens": ["Und", "las", "bei", "sei\u00b7nem", "Heil\u00b7gen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Meistens bis tief in die Nacht hinein. \u2013", "tokens": ["Meis\u00b7tens", "bis", "tief", "in", "die", "Nacht", "hin\u00b7ein", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ADJD", "APPR", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.14": {"line.1": {"text": "Einst, als er wieder so sitzt und liest \u2013", "tokens": ["Einst", ",", "als", "er", "wie\u00b7der", "so", "sitzt", "und", "liest", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "ADV", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u2013 Auf einmal, so r\u00e4uspert sich was und niest;", "tokens": ["\u2013", "Auf", "ein\u00b7mal", ",", "so", "r\u00e4us\u00b7pert", "sich", "was", "und", "niest", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ADV", "$,", "ADV", "VVFIN", "PRF", "PWS", "KON", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und wie er sich umschaut, der fromme Mann,", "tokens": ["Und", "wie", "er", "sich", "um\u00b7schaut", ",", "der", "from\u00b7me", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PRF", "VVPP", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Schaut ihn ein h\u00fcbsches M\u00e4dchen an. \u2013 \u2013", "tokens": ["Schaut", "ihn", "ein", "h\u00fcb\u00b7sches", "M\u00e4d\u00b7chen", "an", ".", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u2013 Der heilige Antonius von Padua", "tokens": ["\u2013", "Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", "von", "Pa\u00b7dua"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADJA", "NE", "APPR", "NE"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "War aber ganz ruhig, als dies geschah.", "tokens": ["War", "a\u00b7ber", "ganz", "ru\u00b7hig", ",", "als", "dies", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "$,", "KOUS", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Er sprach: \u00bbSchau du nur immer zu,", "tokens": ["Er", "sprach", ":", "\u00bb", "Schau", "du", "nur", "im\u00b7mer", "zu", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "NN", "PPER", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.8": {"text": "Du st\u00f6rst mich nicht in meiner christlichen Ruh!\u00ab", "tokens": ["Du", "st\u00f6rst", "mich", "nicht", "in", "mei\u00b7ner", "christ\u00b7li\u00b7chen", "Ruh", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.15": {"line.1": {"text": "Als er nun wieder so ruhig sa\u00df", "tokens": ["Als", "er", "nun", "wie\u00b7der", "so", "ru\u00b7hig", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ADJD", "VVFIN"], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und weiter in seinem Buche las \u2013", "tokens": ["Und", "wei\u00b7ter", "in", "sei\u00b7nem", "Bu\u00b7che", "las", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Husch, husch! \u2013 so sp\u00fcrt er auf der Glatzen", "tokens": ["Husch", ",", "husch", "!", "\u2013", "so", "sp\u00fcrt", "er", "auf", "der", "Glat\u00b7zen"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "ADJD", "$.", "$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und hinterm Ohr ein Kribbelkratzen,", "tokens": ["Und", "hin\u00b7term", "Ohr", "ein", "Krib\u00b7bel\u00b7krat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df ihm dabei ganz sonderbar,", "tokens": ["Da\u00df", "ihm", "da\u00b7bei", "ganz", "son\u00b7der\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bald warm, bald kalt zumute war. \u2013", "tokens": ["Bald", "warm", ",", "bald", "kalt", "zu\u00b7mu\u00b7te", "war", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "ADV", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der heilige Antonius von Padua", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", "von", "Pa\u00b7dua"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "APPR", "NE"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.8": {"text": "War aber ganz ruhig, als dies geschah.", "tokens": ["War", "a\u00b7ber", "ganz", "ru\u00b7hig", ",", "als", "dies", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "$,", "KOUS", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Er sprach: \u00bbSo krabble du nur zu,", "tokens": ["Er", "sprach", ":", "\u00bb", "So", "krabb\u00b7le", "du", "nur", "zu", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Du st\u00f6rst mich nicht in meiner christlichen Ruh!\u00ab", "tokens": ["Du", "st\u00f6rst", "mich", "nicht", "in", "mei\u00b7ner", "christ\u00b7li\u00b7chen", "Ruh", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.16": {"line.1": {"text": "\u00bbna! \u2013 \u2013 Na!\u00ab \u2013 \u2013", "tokens": ["\u00bb", "na", "!", "\u2013", "\u2013", "Na", "!", "\u00ab", "\u2013", "\u2013"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["$(", "ITJ", "$.", "$(", "$(", "ITJ", "$.", "$(", "$(", "$("], "meter": "+-", "measure": "trochaic.single"}}, "stanza.17": {"line.1": {"text": "\u00bbna, na! \u2013 sag' ich!!!\u00ab \u2013", "tokens": ["\u00bb", "na", ",", "na", "!", "\u2013", "sag'", "ich", "!!!", "\u00ab", "\u2013"], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "ITJ", "$.", "$(", "VVIMP", "PPER", "$.", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.18": {"line.1": {"text": "\u00bbhm! hm! \u2013 \u2013 hm! hm!!!\u00ab", "tokens": ["\u00bb", "hm", "!", "hm", "!", "\u2013", "\u2013", "hm", "!", "hm", "!!!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "NE", "$.", "NE", "$.", "$(", "$(", "NE", "$.", "NE", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.19": {"line.1": {"text": "Auf einmal aber \u2013 er wu\u00dfte nicht wie \u2013", "tokens": ["Auf", "ein\u00b7mal", "a\u00b7ber", "\u2013", "er", "wu\u00df\u00b7te", "nicht", "wie", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "$(", "PPER", "VVFIN", "PTKNEG", "KOKOM", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Setzt sich das M\u00e4del ihm gar aufs Knie", "tokens": ["Setzt", "sich", "das", "M\u00e4\u00b7del", "ihm", "gar", "aufs", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN", "PPER", "ADV", "APPRART", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Und gibt dem heiligen Antonius", "tokens": ["Und", "gibt", "dem", "hei\u00b7li\u00b7gen", "An\u00b7to\u00b7ni\u00b7us"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Links und rechts einen herzhaften Ku\u00df.", "tokens": ["Links", "und", "rechts", "ei\u00b7nen", "herz\u00b7haf\u00b7ten", "Ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.20": {"line.1": {"text": "Der heilige Antonius von Padua", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", "von", "Pa\u00b7dua"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "APPR", "NE"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "War aber nicht ruhig, als dies geschah.", "tokens": ["War", "a\u00b7ber", "nicht", "ru\u00b7hig", ",", "als", "dies", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADJD", "$,", "KOUS", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er sprang empor, von Zorn entbrannt;", "tokens": ["Er", "sprang", "em\u00b7por", ",", "von", "Zorn", "ent\u00b7brannt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er nahm das Kreuz in seine Hand:", "tokens": ["Er", "nahm", "das", "Kreuz", "in", "sei\u00b7ne", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "\u00bbla\u00df ab von mir, unsaubrer Geist!", "tokens": ["\u00bb", "la\u00df", "ab", "von", "mir", ",", "un\u00b7sau\u00b7brer", "Geist", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PTKVZ", "APPR", "PPER", "$,", "PPOSAT", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Sei, wie du bist, wer du auch seist!!\u00ab", "tokens": ["Sei", ",", "wie", "du", "bist", ",", "wer", "du", "auch", "seist", "!!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PPER", "VAFIN", "$,", "PWS", "PPER", "ADV", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Puh!! \u2013 da sauste mit gro\u00dfem Rumor", "tokens": ["Puh", "!!", "\u2013", "da", "saus\u00b7te", "mit", "gro\u00b7\u00dfem", "Ru\u00b7mor"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "$(", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Der Satanas durchs Ofenrohr.", "tokens": ["Der", "Sa\u00b7ta\u00b7nas", "durchs", "O\u00b7fen\u00b7rohr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Der heilige Antonius, ruhig und heiter,", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", ",", "ru\u00b7hig", "und", "hei\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Las aber in seinem Buche weiter! \u2013", "tokens": ["Las", "a\u00b7ber", "in", "sei\u00b7nem", "Bu\u00b7che", "wei\u00b7ter", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.24": {"line.1": {"text": "Oh, heil'ger Antonius von Padua,", "tokens": ["Oh", ",", "heil'\u00b7ger", "An\u00b7to\u00b7ni\u00b7us", "von", "Pa\u00b7dua", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADJA", "NE", "APPR", "NE", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Du kennst uns ja!", "tokens": ["Du", "kennst", "uns", "ja", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "So la\u00df uns denn auf dieser Erden", "tokens": ["So", "la\u00df", "uns", "denn", "auf", "die\u00b7ser", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch solche fromme Heilge werden!", "tokens": ["Auch", "sol\u00b7che", "from\u00b7me", "Heil\u00b7ge", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}